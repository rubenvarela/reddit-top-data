{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Going by the recent S-1 filling from Instacart there is a tangible example of cost cutting.\nTheir Snowflake bill was $13M, $28M, $51M in 2020/21/22. 2023 bill will be $15M.\nWhat they did behind the scenes hasn\u2019t been revealed but I am pretty sure this isn\u2019t the first of such changes. If you know more about this, do share.\n\nHow is this community thinking about costs in these economic times? If you aren\u2019t focused on costs and already run pretty well, do share that too.", "author_fullname": "t2_fy6g58f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you lowering your data platform costs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162rlqg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693147290.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693145881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Going by the recent S-1 filling from Instacart there is a tangible example of cost cutting.\nTheir Snowflake bill was $13M, $28M, $51M in 2020/21/22. 2023 bill will be $15M.\nWhat they did behind the scenes hasn\u2019t been revealed but I am pretty sure this isn\u2019t the first of such changes. If you know more about this, do share.&lt;/p&gt;\n\n&lt;p&gt;How is this community thinking about costs in these economic times? If you aren\u2019t focused on costs and already run pretty well, do share that too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162rlqg", "is_robot_indexable": true, "report_reasons": null, "author": "WarriorData", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162rlqg/how_are_you_lowering_your_data_platform_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162rlqg/how_are_you_lowering_your_data_platform_costs/", "subreddit_subscribers": 125120, "created_utc": 1693145881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I just started my first junior data engineering position and I am already feeling stressed out on the first day and for the first week. As soon as I joined, I was already put on a project that is due in a couple of days. My manager does not have any knowledge of data engineering tools or concepts, so they have put me under a Senior Data Engineer. However, this Senior Data Engineer has not answered my questions or answered any emails of mine with questions that I have had about the project. When I finally met the Senior Engineer, they questioned why I was so slow in transferring data from one source to another. I am watching youtube tutorials like crazy because I want to keep this job and I want to produce results to keep the job. Is this normal for a Data Engineering team? Is there any advice that someone can give me? Is there a mentor within the Data Engineering community here that I can DM for more advice and guidance? Especially with the project that I am working on? Thank you. ", "author_fullname": "t2_imbxuehx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling Stressed about Junior Data Engineering position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162de5b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693101171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I just started my first junior data engineering position and I am already feeling stressed out on the first day and for the first week. As soon as I joined, I was already put on a project that is due in a couple of days. My manager does not have any knowledge of data engineering tools or concepts, so they have put me under a Senior Data Engineer. However, this Senior Data Engineer has not answered my questions or answered any emails of mine with questions that I have had about the project. When I finally met the Senior Engineer, they questioned why I was so slow in transferring data from one source to another. I am watching youtube tutorials like crazy because I want to keep this job and I want to produce results to keep the job. Is this normal for a Data Engineering team? Is there any advice that someone can give me? Is there a mentor within the Data Engineering community here that I can DM for more advice and guidance? Especially with the project that I am working on? Thank you. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "162de5b", "is_robot_indexable": true, "report_reasons": null, "author": "moviegover1234", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162de5b/feeling_stressed_about_junior_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162de5b/feeling_stressed_about_junior_data_engineering/", "subreddit_subscribers": 125120, "created_utc": 1693101171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ueuz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Just picked up this big boy for $1 at good will. Worth keeping? Wanted to get a refresher on Hive and cluster scaling for an interview, but this seems overkill and maybe outdated (4th edition is latest)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3yl6gmndiokb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b54db8c2cb5c3ba2c91c7edfba4af0e7be8f1838"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=11d1975fb54c57207602dee003b91e0c2a7b497e"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bfd1b994ba67027689a13442db4e9981c51aa717"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=953ae63527a6098a2e31e85325193400bfd9051b"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1bf61da3104cb1689d4f9285fcc508206b8c09b2"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2fce2ed9eff449f1442d5373fb0ee1ce5ac1ece2"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=695ebf26632deb1ae2cbc3a09643e9e1473f5816"}, "id": "3yl6gmndiokb1"}, "671hanndiokb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f75d90c6cfac68be8f44b843ff4f16c5175aa4c3"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d816822cbae4988398f32399ba28e2672951b3c"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15d82e4805fd56edc13a72115402752e540b25f6"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b045c9cb5f1d8c8a2fb88e40d81bb4c94c36fc7b"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d2647c04013e2b1c854a4b0325ba5d865073e905"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b06cbfff56bb631cfb4db095562d24d0cfde9a96"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=a9e0c2a82db988d7db0353413b47be489bc25b20"}, "id": "671hanndiokb1"}}, "name": "t3_162utkn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 23, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "671hanndiokb1", "id": 321269719}, {"media_id": "3yl6gmndiokb1", "id": 321269720}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kok4rdC7sms0Dp5D9QeDDh-r9BGAiYIf9p45EQySpek.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693153417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/162utkn", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162utkn", "is_robot_indexable": true, "report_reasons": null, "author": "uncomfortablepanda", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162utkn/just_picked_up_this_big_boy_for_1_at_good_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/162utkn", "subreddit_subscribers": 125120, "created_utc": 1693153417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title. Taking data engineer course currently and planning on going back for my Masters in computer science soon, will also be reading tons of data engineering guides and attending webinars for different softwares. But wanted to know what some of the biggest challenges to look out for are as a new engineer", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's one of the hardest things to adjust to as a new data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162p6ou", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693139446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title. Taking data engineer course currently and planning on going back for my Masters in computer science soon, will also be reading tons of data engineering guides and attending webinars for different softwares. But wanted to know what some of the biggest challenges to look out for are as a new engineer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "162p6ou", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162p6ou/whats_one_of_the_hardest_things_to_adjust_to_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162p6ou/whats_one_of_the_hardest_things_to_adjust_to_as_a/", "subreddit_subscribers": 125120, "created_utc": 1693139446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been looking for new opportunities for 2 months, and the market is absolutely the worst. \n20% of my applications received no response, 40% of them rejects. \nOf the remaining 40% that contacted me for screening rounds, 20% declined later, while the other 20% advanced to the next stages.\n\nPreparing has been incredibly challenging. I'm uncertain about where to focus my efforts.\nI've encountered rounds such as:\n1) Online tests/take-home assignments\n2) Hiring manager round\n3) Technical round\n4) Data pipeline design round (not Data modeling)\n5) Cultural fit round\n\nI'm torn about whether to prepare for DSA, or delve into data engineering topics like Data Quality, ETL, and Data Pipeline Design. Or work on side projects to showcase my skills. There are countless topics to cover and hundreds of details to remember. I'm feeling overwhelmed by the entire process.\n\nIf any of you are job hunting (especially in Europe), please share your experiences. It would be of great help to me. For those who aren't job hunting, how do you prepare for such challenges?", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Senior data engineer interview preparation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162lzf8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693129194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking for new opportunities for 2 months, and the market is absolutely the worst. \n20% of my applications received no response, 40% of them rejects. \nOf the remaining 40% that contacted me for screening rounds, 20% declined later, while the other 20% advanced to the next stages.&lt;/p&gt;\n\n&lt;p&gt;Preparing has been incredibly challenging. I&amp;#39;m uncertain about where to focus my efforts.\nI&amp;#39;ve encountered rounds such as:\n1) Online tests/take-home assignments\n2) Hiring manager round\n3) Technical round\n4) Data pipeline design round (not Data modeling)\n5) Cultural fit round&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m torn about whether to prepare for DSA, or delve into data engineering topics like Data Quality, ETL, and Data Pipeline Design. Or work on side projects to showcase my skills. There are countless topics to cover and hundreds of details to remember. I&amp;#39;m feeling overwhelmed by the entire process.&lt;/p&gt;\n\n&lt;p&gt;If any of you are job hunting (especially in Europe), please share your experiences. It would be of great help to me. For those who aren&amp;#39;t job hunting, how do you prepare for such challenges?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "162lzf8", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/162lzf8/senior_data_engineer_interview_preparation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162lzf8/senior_data_engineer_interview_preparation/", "subreddit_subscribers": 125120, "created_utc": 1693129194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Product Strategy | Becoming Metrics-First: Proven Models, Metric Model as a reflection, and Metric Model Enablement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162l3h4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1693126133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/the-data-product-strategy-becoming", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "162l3h4", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162l3h4/the_data_product_strategy_becoming_metricsfirst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/the-data-product-strategy-becoming", "subreddit_subscribers": 125120, "created_utc": 1693126133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have such a massive amount of tables in BQ that we dont keep track of how one table relates to  other or what columns a given table has.  Of course, we know the lineage of the data taking a look into some DAGs but is becoming increasingly difficult to have a global view.\n\nI suppose that in the beginning we had some care for this, at least for the core tables but after years of \"open policy\" for updating tables (we accept almost every request from Business Analyst ) is messy.\n\nI talked to the manger about this and he is aware of the problem but in his opinion even if we manually create a sort of UML diagram of the warehouse, it will soon become outdated.\n\nIs the database schema design fate to be forgotten once the WH becomes huge ?\n\nAnyone facing this issue? How to proceed ?", "author_fullname": "t2_4bchq4zo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to keep track of warehouse tables schemas in BQ ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162n23f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693132904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have such a massive amount of tables in BQ that we dont keep track of how one table relates to  other or what columns a given table has.  Of course, we know the lineage of the data taking a look into some DAGs but is becoming increasingly difficult to have a global view.&lt;/p&gt;\n\n&lt;p&gt;I suppose that in the beginning we had some care for this, at least for the core tables but after years of &amp;quot;open policy&amp;quot; for updating tables (we accept almost every request from Business Analyst ) is messy.&lt;/p&gt;\n\n&lt;p&gt;I talked to the manger about this and he is aware of the problem but in his opinion even if we manually create a sort of UML diagram of the warehouse, it will soon become outdated.&lt;/p&gt;\n\n&lt;p&gt;Is the database schema design fate to be forgotten once the WH becomes huge ?&lt;/p&gt;\n\n&lt;p&gt;Anyone facing this issue? How to proceed ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162n23f", "is_robot_indexable": true, "report_reasons": null, "author": "Grand-Theory", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162n23f/how_to_keep_track_of_warehouse_tables_schemas_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162n23f/how_to_keep_track_of_warehouse_tables_schemas_in/", "subreddit_subscribers": 125120, "created_utc": 1693132904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nI have an unique business problem I'm looking to tackle. To keep it short, I work with data that has strict residency requirements, so we're forced to keep databases in multiple \\[cloud provider\\] regions, which store specific customer data. We also give customers specialized schemas if they need more compute. As a result, we have 50+ targets between catalog/schema. When I want to query our production databases for ad-hoc requests, I essentially need to run the query 50+ times slightly modified (I use jinja templating to automate this)\n\nHowever, in the current system, this means that doing analysis across regions is essentially impossible, since the different databases can't interact with each other. We have attempted to solve this problem with Trino, but it's still doesn't exactly solve our needs, and it's expensive as hell for us to pay for the compute when that doesn't exactly solve the business need. \n\nI've been thinking about this problem for a few weeks, and I was thinking of essentially a piece of software that serves as a \"gateway\" to the other regions, so you send a query to this software, it transforms it into sql that our databases can understand, does calculation in the software, then streams the result to a warehouse / file / etc whatever. However, I think this is a little bit convoluted, because for example, if I'm doing a group by, I would need to pull all the ungrouped data from every region, union it, then do the grouping in the transformation software itself. \n\nI was looking at connectorx as a potential solution, but it doesn't support batch processing, and the volume of data I deal with is so massive that I'd prefer something that has async compute compatibility. Has anyone faced a similar problem and has any recommendations of how to solve this? I'd appreciate any insights :)", "author_fullname": "t2_v12atn7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solving the worst data residency problem by rewriting SQL transparently", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162b0kd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "287cf772-ac9d-11eb-aa84-0ead36cb44af", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693094573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I have an unique business problem I&amp;#39;m looking to tackle. To keep it short, I work with data that has strict residency requirements, so we&amp;#39;re forced to keep databases in multiple [cloud provider] regions, which store specific customer data. We also give customers specialized schemas if they need more compute. As a result, we have 50+ targets between catalog/schema. When I want to query our production databases for ad-hoc requests, I essentially need to run the query 50+ times slightly modified (I use jinja templating to automate this)&lt;/p&gt;\n\n&lt;p&gt;However, in the current system, this means that doing analysis across regions is essentially impossible, since the different databases can&amp;#39;t interact with each other. We have attempted to solve this problem with Trino, but it&amp;#39;s still doesn&amp;#39;t exactly solve our needs, and it&amp;#39;s expensive as hell for us to pay for the compute when that doesn&amp;#39;t exactly solve the business need. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been thinking about this problem for a few weeks, and I was thinking of essentially a piece of software that serves as a &amp;quot;gateway&amp;quot; to the other regions, so you send a query to this software, it transforms it into sql that our databases can understand, does calculation in the software, then streams the result to a warehouse / file / etc whatever. However, I think this is a little bit convoluted, because for example, if I&amp;#39;m doing a group by, I would need to pull all the ungrouped data from every region, union it, then do the grouping in the transformation software itself. &lt;/p&gt;\n\n&lt;p&gt;I was looking at connectorx as a potential solution, but it doesn&amp;#39;t support batch processing, and the volume of data I deal with is so massive that I&amp;#39;d prefer something that has async compute compatibility. Has anyone faced a similar problem and has any recommendations of how to solve this? I&amp;#39;d appreciate any insights :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data/Software Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162b0kd", "is_robot_indexable": true, "report_reasons": null, "author": "Dazzling-Reason-5140", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/162b0kd/solving_the_worst_data_residency_problem_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162b0kd/solving_the_worst_data_residency_problem_by/", "subreddit_subscribers": 125120, "created_utc": 1693094573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I've been poking around online and noticed there isn't a ton of talk about ingesting messy, unstructured data at **larger scale**. Got me wondering, anyone else been down this rabbit hole?\n\nWhen it comes to handling (ingestion/staging) all those unruly files in your data lake for stuff like Machine Learning or Reports (Especially lot more use cases coming up after LLM), how do you do it? \ud83e\udd14 For example, extracting information from drawing files.\n\nCurious to know how your data pipeline and jobs are all set up. Did you run into any big challenges wrangling that wild unstructured data? And what tools did you turn to fix the puzzle?\n\nLooking forward to hearing your stories and tips!", "author_fullname": "t2_3xh5j7zr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating data pipelines for unstructured big data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162tc16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693154858.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693149991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;ve been poking around online and noticed there isn&amp;#39;t a ton of talk about ingesting messy, unstructured data at &lt;strong&gt;larger scale&lt;/strong&gt;. Got me wondering, anyone else been down this rabbit hole?&lt;/p&gt;\n\n&lt;p&gt;When it comes to handling (ingestion/staging) all those unruly files in your data lake for stuff like Machine Learning or Reports (Especially lot more use cases coming up after LLM), how do you do it? \ud83e\udd14 For example, extracting information from drawing files.&lt;/p&gt;\n\n&lt;p&gt;Curious to know how your data pipeline and jobs are all set up. Did you run into any big challenges wrangling that wild unstructured data? And what tools did you turn to fix the puzzle?&lt;/p&gt;\n\n&lt;p&gt;Looking forward to hearing your stories and tips!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162tc16", "is_robot_indexable": true, "report_reasons": null, "author": "thedatumgirl", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162tc16/creating_data_pipelines_for_unstructured_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162tc16/creating_data_pipelines_for_unstructured_big_data/", "subreddit_subscribers": 125120, "created_utc": 1693149991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI am starting a personal project and wanted to use Apache Airflow to orchestrate the project pipelines.\n\nIn my previous experience, I setup a linux instance in my companies server to have Apache Airflow run 24/7.\n\nSince I dont have a server to run Apache Airflow, I was thinking to run in on Cloud. Which cloud provider should I go for in this project? I dont want to lose a lot of money (if it is possible to use a free tier it would be good)\n\nI wante to run the pipeline 24/7, every 5 minutes. I want to request an api that returns a object with 5 parameteres.\n\nDo you think i can go with a cloud based approach or it is best to run it locally in a linux machine?\n\nThank you very much", "author_fullname": "t2_6jg4a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to run Apache Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162zd6w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693164216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am starting a personal project and wanted to use Apache Airflow to orchestrate the project pipelines.&lt;/p&gt;\n\n&lt;p&gt;In my previous experience, I setup a linux instance in my companies server to have Apache Airflow run 24/7.&lt;/p&gt;\n\n&lt;p&gt;Since I dont have a server to run Apache Airflow, I was thinking to run in on Cloud. Which cloud provider should I go for in this project? I dont want to lose a lot of money (if it is possible to use a free tier it would be good)&lt;/p&gt;\n\n&lt;p&gt;I wante to run the pipeline 24/7, every 5 minutes. I want to request an api that returns a object with 5 parameteres.&lt;/p&gt;\n\n&lt;p&gt;Do you think i can go with a cloud based approach or it is best to run it locally in a linux machine?&lt;/p&gt;\n\n&lt;p&gt;Thank you very much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "162zd6w", "is_robot_indexable": true, "report_reasons": null, "author": "D1yzz", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162zd6w/best_way_to_run_apache_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162zd6w/best_way_to_run_apache_airflow/", "subreddit_subscribers": 125120, "created_utc": 1693164216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am curious what would be some good practices around using databricks and powerbi together. \n\nWe've been instructed by management and some tech teams to look into databricks as an interim solution.\n\nSo we've been looking at using databricks as connector to powerbi for pulling large amounts of data from AWS Athena/S3 into Powerbi.\n  \nWe have some SQL queries that pulls lots of data and join data together. Is it better to schedule databricks to run the query,  build/append to a table in athena then have powerbi pull from the table? Or is it fine to run SQL query in powerbi with databricks connector.\n\nI think the more correct approach would be to build the table but I might be wrong so I want hear from y'all.\n\nAlso, I might be wrong but it looks like databricks uses odbc right, we had issues with odbc failling in the past. Might that still exists?\n\nWhat are somethings would y'all advise to watch out for around databricks and using it as connector for powerbi? Something I notice it takes awhile for it to start up.", "author_fullname": "t2_16je8s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks and PowerBI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162xquo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693160245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am curious what would be some good practices around using databricks and powerbi together. &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve been instructed by management and some tech teams to look into databricks as an interim solution.&lt;/p&gt;\n\n&lt;p&gt;So we&amp;#39;ve been looking at using databricks as connector to powerbi for pulling large amounts of data from AWS Athena/S3 into Powerbi.&lt;/p&gt;\n\n&lt;p&gt;We have some SQL queries that pulls lots of data and join data together. Is it better to schedule databricks to run the query,  build/append to a table in athena then have powerbi pull from the table? Or is it fine to run SQL query in powerbi with databricks connector.&lt;/p&gt;\n\n&lt;p&gt;I think the more correct approach would be to build the table but I might be wrong so I want hear from y&amp;#39;all.&lt;/p&gt;\n\n&lt;p&gt;Also, I might be wrong but it looks like databricks uses odbc right, we had issues with odbc failling in the past. Might that still exists?&lt;/p&gt;\n\n&lt;p&gt;What are somethings would y&amp;#39;all advise to watch out for around databricks and using it as connector for powerbi? Something I notice it takes awhile for it to start up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162xquo", "is_robot_indexable": true, "report_reasons": null, "author": "wowzersboy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162xquo/databricks_and_powerbi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162xquo/databricks_and_powerbi/", "subreddit_subscribers": 125120, "created_utc": 1693160245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys!\nIm currently a software engineer with 2 years of experience (java). I\u2019ve feeling that something is missing. I would classify myself as average. I have really good problem solving and analytical skills and I like coding but most of the times I feel that I don\u2019t have what it takes to be a really good software engineer so I thought maybe Data Engineer would be better for me. I applied recently to a data role, but I feel anxious about the change. What do you guys think about this ?", "author_fullname": "t2_h85ckd4a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From SW engineer to Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1631jyw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693169217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys!\nIm currently a software engineer with 2 years of experience (java). I\u2019ve feeling that something is missing. I would classify myself as average. I have really good problem solving and analytical skills and I like coding but most of the times I feel that I don\u2019t have what it takes to be a really good software engineer so I thought maybe Data Engineer would be better for me. I applied recently to a data role, but I feel anxious about the change. What do you guys think about this ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1631jyw", "is_robot_indexable": true, "report_reasons": null, "author": "Hungry_Post_9891", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1631jyw/from_sw_engineer_to_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1631jyw/from_sw_engineer_to_data_engineer/", "subreddit_subscribers": 125120, "created_utc": 1693169217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nour company is currently evaluating the cost of using cloud ETL Tools like Databricks On AWS or Synapse on Azure and on prem native Tools like SSIS. Currently our partner told us that the trend is moving back from Cloud to On Prem due to cost reasons. After finding cloud to be more expensive than expected, Companies have began to move back to on prem for several cost optimization reasons. \n\nWhat is your experience and opinion on the matter? \n\nI still believe cloud to be the future but can't deny that cloud tools might be more expensive although I don't have an oversight regarding the costs.", "author_fullname": "t2_go0bd7txp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost factor of cloud vs on prem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162tynt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693151443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;our company is currently evaluating the cost of using cloud ETL Tools like Databricks On AWS or Synapse on Azure and on prem native Tools like SSIS. Currently our partner told us that the trend is moving back from Cloud to On Prem due to cost reasons. After finding cloud to be more expensive than expected, Companies have began to move back to on prem for several cost optimization reasons. &lt;/p&gt;\n\n&lt;p&gt;What is your experience and opinion on the matter? &lt;/p&gt;\n\n&lt;p&gt;I still believe cloud to be the future but can&amp;#39;t deny that cloud tools might be more expensive although I don&amp;#39;t have an oversight regarding the costs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162tynt", "is_robot_indexable": true, "report_reasons": null, "author": "SuccessfulCase4281", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162tynt/cost_factor_of_cloud_vs_on_prem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162tynt/cost_factor_of_cloud_vs_on_prem/", "subreddit_subscribers": 125120, "created_utc": 1693151443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know it's weirdly specific but I just want to ask. \n\nFor Data Engineers who work for shipping companies, what exactly do you do in your day to day job. \n\nHow often do you use SQL, Python, and building data lakes or data warehouse? \n\nHow do often do you talk with colleagues from different departments and upper management.", "author_fullname": "t2_5hcl0uoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineers that work for shipping companies.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162hhnb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693113460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it&amp;#39;s weirdly specific but I just want to ask. &lt;/p&gt;\n\n&lt;p&gt;For Data Engineers who work for shipping companies, what exactly do you do in your day to day job. &lt;/p&gt;\n\n&lt;p&gt;How often do you use SQL, Python, and building data lakes or data warehouse? &lt;/p&gt;\n\n&lt;p&gt;How do often do you talk with colleagues from different departments and upper management.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162hhnb", "is_robot_indexable": true, "report_reasons": null, "author": "Large-Relationship37", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162hhnb/data_engineers_that_work_for_shipping_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162hhnb/data_engineers_that_work_for_shipping_companies/", "subreddit_subscribers": 125120, "created_utc": 1693113460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello - I am a fairly new DE with 1 yr of experience. My director has been tasked with moving our data infrastructure to modern data stack. Can someone tell me what are the problems or gaps  that modern data stacks still haves and my company needs to watch out for? We are thinking Fivetran, Snowflake, DBT and looker. Some of the current problems that I face on a regular basis are inconsistent data formats, data structure changes in source systems making data integration really painful. Does fivetran help with that? Also, what are gaps in dbt with managing CDCs effectively? ", "author_fullname": "t2_v54v19cn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on Modern Data stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16295nq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693089849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello - I am a fairly new DE with 1 yr of experience. My director has been tasked with moving our data infrastructure to modern data stack. Can someone tell me what are the problems or gaps  that modern data stacks still haves and my company needs to watch out for? We are thinking Fivetran, Snowflake, DBT and looker. Some of the current problems that I face on a regular basis are inconsistent data formats, data structure changes in source systems making data integration really painful. Does fivetran help with that? Also, what are gaps in dbt with managing CDCs effectively? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16295nq", "is_robot_indexable": true, "report_reasons": null, "author": "NewDE2023", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16295nq/looking_for_advice_on_modern_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16295nq/looking_for_advice_on_modern_data_stack/", "subreddit_subscribers": 125120, "created_utc": 1693089849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "End-users in my project are a team of data scientists and analytics people. My sources are On-prem oracle, on-prem Db2 and Azure Cosmos db. End users are only interested in tabular format data for their analysis purposes. I need to present them data from all three sources integrated. Cosmos db containers have nested and very complex json structures running up to 5k to 10k lines for each item in the collection. Any suggestions on how to flatten them and integrate them with oracle/Db2? Another major question what would be the best place to load them so that they can access it easily using queries.", "author_fullname": "t2_b742rj0h7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cosmos db question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1628obw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693088677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;End-users in my project are a team of data scientists and analytics people. My sources are On-prem oracle, on-prem Db2 and Azure Cosmos db. End users are only interested in tabular format data for their analysis purposes. I need to present them data from all three sources integrated. Cosmos db containers have nested and very complex json structures running up to 5k to 10k lines for each item in the collection. Any suggestions on how to flatten them and integrate them with oracle/Db2? Another major question what would be the best place to load them so that they can access it easily using queries.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1628obw", "is_robot_indexable": true, "report_reasons": null, "author": "clakshminarasu", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1628obw/cosmos_db_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1628obw/cosmos_db_question/", "subreddit_subscribers": 125120, "created_utc": 1693088677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Finding datasets to practice data engineering is difficult. We work with data that updates frequently, but most public datasets are static. When starting a series of DBT tutorials I searched but couldn't find anything. So I created dbt-fake, a DBT project that generates a history of data and updates it daily. Anyone can use it to create their own data. Right now it is pretty basic with some simple sales data, but I will add more entities and data types for practice and for tutorials and videos.\n\nThis is free and I'm NOT trying to start a company. I just want good datasets to help teach data skills through videos and blog posts. Hopefully, other people find it useful for learning or creating their own helpful educational content. \n\nMy question: Outside of DBT, would making the generated data available be useful to anyone? If so, what format would be useful? I think making the BigQuery tables public would be good (and easy). Maybe a Kaggle dataset? Or Dolthub? Parquet files would be cool, but I'd need to host them and don't really want the complexity or cost. \n\nAn introduction [here](https://leo-godin.medium.com/learn-dbt-with-real-fake-data-68d6d21c3e8f).\n\nGithub repo [here](https://github.com/leogodin217/dbt-fake#generating-fake-data)", "author_fullname": "t2_8ov8i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone Interested in a Fake Data Generator for DBT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1633ark", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693173166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Finding datasets to practice data engineering is difficult. We work with data that updates frequently, but most public datasets are static. When starting a series of DBT tutorials I searched but couldn&amp;#39;t find anything. So I created dbt-fake, a DBT project that generates a history of data and updates it daily. Anyone can use it to create their own data. Right now it is pretty basic with some simple sales data, but I will add more entities and data types for practice and for tutorials and videos.&lt;/p&gt;\n\n&lt;p&gt;This is free and I&amp;#39;m NOT trying to start a company. I just want good datasets to help teach data skills through videos and blog posts. Hopefully, other people find it useful for learning or creating their own helpful educational content. &lt;/p&gt;\n\n&lt;p&gt;My question: Outside of DBT, would making the generated data available be useful to anyone? If so, what format would be useful? I think making the BigQuery tables public would be good (and easy). Maybe a Kaggle dataset? Or Dolthub? Parquet files would be cool, but I&amp;#39;d need to host them and don&amp;#39;t really want the complexity or cost. &lt;/p&gt;\n\n&lt;p&gt;An introduction &lt;a href=\"https://leo-godin.medium.com/learn-dbt-with-real-fake-data-68d6d21c3e8f\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Github repo &lt;a href=\"https://github.com/leogodin217/dbt-fake#generating-fake-data\"&gt;here&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GCd5K5PCIG7wqVrQF-1sSoUIvV_rBmD2baVAsLfGK-0.jpg?auto=webp&amp;s=63d8a25b86c08c9ab2b6e23f5720b6c5de7aeae6", "width": 830, "height": 268}, "resolutions": [{"url": "https://external-preview.redd.it/GCd5K5PCIG7wqVrQF-1sSoUIvV_rBmD2baVAsLfGK-0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca050322fe9e2157ebecc4acee400995b636b8e8", "width": 108, "height": 34}, {"url": "https://external-preview.redd.it/GCd5K5PCIG7wqVrQF-1sSoUIvV_rBmD2baVAsLfGK-0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e330b87dc6a724d369eb813f73fa56f3ce6fe04", "width": 216, "height": 69}, {"url": "https://external-preview.redd.it/GCd5K5PCIG7wqVrQF-1sSoUIvV_rBmD2baVAsLfGK-0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=acc15ee26e0254b20cd37c25f290e98b17ddb336", "width": 320, "height": 103}, {"url": "https://external-preview.redd.it/GCd5K5PCIG7wqVrQF-1sSoUIvV_rBmD2baVAsLfGK-0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2d5175c1c0159c847bfdfa2d6aeef96a592659c8", "width": 640, "height": 206}], "variants": {}, "id": "RWbJpOH8wKOC3ehVakAwH1hpYetip4HqE4EQV0ARpWA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1633ark", "is_robot_indexable": true, "report_reasons": null, "author": "leogodin217", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1633ark/anyone_interested_in_a_fake_data_generator_for_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1633ark/anyone_interested_in_a_fake_data_generator_for_dbt/", "subreddit_subscribers": 125120, "created_utc": 1693173166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, so I am currently getting close to finishing up a graduate internship at a big pharma company.  The internship was initially described to me and titled as a \"data pipeline engineer\", however, now that I've spent a number of months on the job, I'm not really sure how to describe it to future employers and was looking for some advice with this issue.\n\nSo, I work in a department that deals with early phase drug research.  The team I work with is involved with making available to the scientists large volumes of experimental data in a easy to visualize format through dashboards.\n\nThe bulk of my work was involved with a particular lab instrument that stored it's data in a SQL DB, but  which was only previously accessible via the instrument vendor's proprietary software.  That vendor's software was too inflexible and too limited in its capabilities for the type of analysis the scientists wanted to do with this data.  However, the SQL DB's schema was proprietary and they couldn't find a way to access the data without using the vendor's software.\n\nSo, my job was to try and figure out how the instrument's data was stored in the SQL DB and then create a dashboard that could access it directly and offer all the visualizations and analysis tools that the scientists needed.  It took a lot of investigating, but eventually I was able to figure out how the data was stored and how to extract it (it was stored in a SQL BLOB format, but it was compressed in binary file format and I had to use a hex editor to figure out the exact structure of the data and the hex offsets of where the various data streams begin and end.)\n\nIt actually took a surprisingly large amount of Python code and SQL embedded in the dashboard to make this all work.  The reason is that the data is very complex and there are a lot of variables in the DB that specify various aspects of the data.  These variables have to be looked up when the data is being looked up and various transformations have to be performed on the data prior to visualization.  The various visualizations had to have different options available and had to change depending on these variables.  The scientists also needed to be able to perform some transformations on the data through the dashboard and then export summary files that reflect these changes.\n\nTo me, a lot of the work was software engineering.  I basically had to recreate a lot of the functionality of a proprietary piece of software through dashboard visualization software.  The underlying transformations of the data required a lot of Python and SQL code.  I was undergrad comp sci major and I worked for year as a software engineer before go back to grad school for my data science master's.  So, a lot of the programming work reminded me of being a software engineer.  However, ultimately I was delivering a dashboard through a well-known piece of visualization software and that seems more like data engineering or data analytics work.\n\nAnyway, I was just curious if other's in data engineering had done work like this and what \"field\" you might think it falls into.\n\nThanks", "author_fullname": "t2_946ecf3o1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I working as a Data Engineer, a Data Analyst, or a Software Engineer? Not sure how to describe my current internship.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1631nrl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693172170.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693169448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, so I am currently getting close to finishing up a graduate internship at a big pharma company.  The internship was initially described to me and titled as a &amp;quot;data pipeline engineer&amp;quot;, however, now that I&amp;#39;ve spent a number of months on the job, I&amp;#39;m not really sure how to describe it to future employers and was looking for some advice with this issue.&lt;/p&gt;\n\n&lt;p&gt;So, I work in a department that deals with early phase drug research.  The team I work with is involved with making available to the scientists large volumes of experimental data in a easy to visualize format through dashboards.&lt;/p&gt;\n\n&lt;p&gt;The bulk of my work was involved with a particular lab instrument that stored it&amp;#39;s data in a SQL DB, but  which was only previously accessible via the instrument vendor&amp;#39;s proprietary software.  That vendor&amp;#39;s software was too inflexible and too limited in its capabilities for the type of analysis the scientists wanted to do with this data.  However, the SQL DB&amp;#39;s schema was proprietary and they couldn&amp;#39;t find a way to access the data without using the vendor&amp;#39;s software.&lt;/p&gt;\n\n&lt;p&gt;So, my job was to try and figure out how the instrument&amp;#39;s data was stored in the SQL DB and then create a dashboard that could access it directly and offer all the visualizations and analysis tools that the scientists needed.  It took a lot of investigating, but eventually I was able to figure out how the data was stored and how to extract it (it was stored in a SQL BLOB format, but it was compressed in binary file format and I had to use a hex editor to figure out the exact structure of the data and the hex offsets of where the various data streams begin and end.)&lt;/p&gt;\n\n&lt;p&gt;It actually took a surprisingly large amount of Python code and SQL embedded in the dashboard to make this all work.  The reason is that the data is very complex and there are a lot of variables in the DB that specify various aspects of the data.  These variables have to be looked up when the data is being looked up and various transformations have to be performed on the data prior to visualization.  The various visualizations had to have different options available and had to change depending on these variables.  The scientists also needed to be able to perform some transformations on the data through the dashboard and then export summary files that reflect these changes.&lt;/p&gt;\n\n&lt;p&gt;To me, a lot of the work was software engineering.  I basically had to recreate a lot of the functionality of a proprietary piece of software through dashboard visualization software.  The underlying transformations of the data required a lot of Python and SQL code.  I was undergrad comp sci major and I worked for year as a software engineer before go back to grad school for my data science master&amp;#39;s.  So, a lot of the programming work reminded me of being a software engineer.  However, ultimately I was delivering a dashboard through a well-known piece of visualization software and that seems more like data engineering or data analytics work.&lt;/p&gt;\n\n&lt;p&gt;Anyway, I was just curious if other&amp;#39;s in data engineering had done work like this and what &amp;quot;field&amp;quot; you might think it falls into.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1631nrl", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished-Day131", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1631nrl/am_i_working_as_a_data_engineer_a_data_analyst_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1631nrl/am_i_working_as_a_data_engineer_a_data_analyst_or/", "subreddit_subscribers": 125120, "created_utc": 1693169448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title. Either way, are both of their works related to Machine learning / neural networks somehow?\n\nContext: I finished a Master's studies focused on Machine learning and Data Analytics. I was told that if I'm not a PhD, I can still use my ML / AI knowledge as \"Data scientist / analyst\". Now I have a chance to be a \"Data engineer\" and I assumed they are similar, but after reading the job offer and interview it sounds closer database work instead. I don't know if the interviewer is dumbing things down since I indeed have no professional experience as Data engineer yet. I am fine with database work, but not as excited since it would be less related with my recent studies.\n\nI can post the text of the job description here, if it would make things clearer.", "author_fullname": "t2_1kqtx3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the job \"Data engineer\" similar to \"Data scientist / analyst\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16307wl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693166227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title. Either way, are both of their works related to Machine learning / neural networks somehow?&lt;/p&gt;\n\n&lt;p&gt;Context: I finished a Master&amp;#39;s studies focused on Machine learning and Data Analytics. I was told that if I&amp;#39;m not a PhD, I can still use my ML / AI knowledge as &amp;quot;Data scientist / analyst&amp;quot;. Now I have a chance to be a &amp;quot;Data engineer&amp;quot; and I assumed they are similar, but after reading the job offer and interview it sounds closer database work instead. I don&amp;#39;t know if the interviewer is dumbing things down since I indeed have no professional experience as Data engineer yet. I am fine with database work, but not as excited since it would be less related with my recent studies.&lt;/p&gt;\n\n&lt;p&gt;I can post the text of the job description here, if it would make things clearer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16307wl", "is_robot_indexable": true, "report_reasons": null, "author": "firzein", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16307wl/is_the_job_data_engineer_similar_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16307wl/is_the_job_data_engineer_similar_to_data/", "subreddit_subscribers": 125120, "created_utc": 1693166227.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The reason I don't like SQL over something like Pandas is because in Pandas/Python I can break down the complex transformations in small simpler components and they are easy to interact and debug with. In SQL my only option is to write stored procedures and yes in that I can also do the same but I think the ecosystem of interacting and debugging with data step by step is not as good as python. And it is something that we should have. Recently I was exploring snowpark and I felt it is a step in a right direction. It allows to me to write my query in multiple python statements and then it will transpile the whole thing into an SQL query.  \n\n\nGenerally in my mind I assume the tables/dataframes as 2 dimensional structures and Pandas API give much more intuitive and wide variety of constructs to explore that structure rather than SQL. What do you guys think?", "author_fullname": "t2_q27tep12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why I don't like SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162ig5h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.49, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693116758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The reason I don&amp;#39;t like SQL over something like Pandas is because in Pandas/Python I can break down the complex transformations in small simpler components and they are easy to interact and debug with. In SQL my only option is to write stored procedures and yes in that I can also do the same but I think the ecosystem of interacting and debugging with data step by step is not as good as python. And it is something that we should have. Recently I was exploring snowpark and I felt it is a step in a right direction. It allows to me to write my query in multiple python statements and then it will transpile the whole thing into an SQL query.  &lt;/p&gt;\n\n&lt;p&gt;Generally in my mind I assume the tables/dataframes as 2 dimensional structures and Pandas API give much more intuitive and wide variety of constructs to explore that structure rather than SQL. What do you guys think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162ig5h", "is_robot_indexable": true, "report_reasons": null, "author": "__albatross", "discussion_type": null, "num_comments": 79, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162ig5h/why_i_dont_like_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162ig5h/why_i_dont_like_sql/", "subreddit_subscribers": 125120, "created_utc": 1693116758.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}