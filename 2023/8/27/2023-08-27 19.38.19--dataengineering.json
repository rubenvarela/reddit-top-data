{"kind": "Listing", "data": {"after": null, "dist": 18, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Going by the recent S-1 filling from Instacart there is a tangible example of cost cutting.\nTheir Snowflake bill was $13M, $28M, $51M in 2020/21/22. 2023 bill will be $15M.\nWhat they did behind the scenes hasn\u2019t been revealed but I am pretty sure this isn\u2019t the first of such changes. If you know more about this, do share.\n\nHow is this community thinking about costs in these economic times? If you aren\u2019t focused on costs and already run pretty well, do share that too.", "author_fullname": "t2_fy6g58f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you lowering your data platform costs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162rlqg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693147290.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693145881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Going by the recent S-1 filling from Instacart there is a tangible example of cost cutting.\nTheir Snowflake bill was $13M, $28M, $51M in 2020/21/22. 2023 bill will be $15M.\nWhat they did behind the scenes hasn\u2019t been revealed but I am pretty sure this isn\u2019t the first of such changes. If you know more about this, do share.&lt;/p&gt;\n\n&lt;p&gt;How is this community thinking about costs in these economic times? If you aren\u2019t focused on costs and already run pretty well, do share that too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162rlqg", "is_robot_indexable": true, "report_reasons": null, "author": "WarriorData", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162rlqg/how_are_you_lowering_your_data_platform_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162rlqg/how_are_you_lowering_your_data_platform_costs/", "subreddit_subscribers": 125084, "created_utc": 1693145881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I just started my first junior data engineering position and I am already feeling stressed out on the first day and for the first week. As soon as I joined, I was already put on a project that is due in a couple of days. My manager does not have any knowledge of data engineering tools or concepts, so they have put me under a Senior Data Engineer. However, this Senior Data Engineer has not answered my questions or answered any emails of mine with questions that I have had about the project. When I finally met the Senior Engineer, they questioned why I was so slow in transferring data from one source to another. I am watching youtube tutorials like crazy because I want to keep this job and I want to produce results to keep the job. Is this normal for a Data Engineering team? Is there any advice that someone can give me? Is there a mentor within the Data Engineering community here that I can DM for more advice and guidance? Especially with the project that I am working on? Thank you. ", "author_fullname": "t2_imbxuehx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling Stressed about Junior Data Engineering position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162de5b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693101171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I just started my first junior data engineering position and I am already feeling stressed out on the first day and for the first week. As soon as I joined, I was already put on a project that is due in a couple of days. My manager does not have any knowledge of data engineering tools or concepts, so they have put me under a Senior Data Engineer. However, this Senior Data Engineer has not answered my questions or answered any emails of mine with questions that I have had about the project. When I finally met the Senior Engineer, they questioned why I was so slow in transferring data from one source to another. I am watching youtube tutorials like crazy because I want to keep this job and I want to produce results to keep the job. Is this normal for a Data Engineering team? Is there any advice that someone can give me? Is there a mentor within the Data Engineering community here that I can DM for more advice and guidance? Especially with the project that I am working on? Thank you. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "162de5b", "is_robot_indexable": true, "report_reasons": null, "author": "moviegover1234", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162de5b/feeling_stressed_about_junior_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162de5b/feeling_stressed_about_junior_data_engineering/", "subreddit_subscribers": 125084, "created_utc": 1693101171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been looking for new opportunities for 2 months, and the market is absolutely the worst. \n20% of my applications received no response, 40% of them rejects. \nOf the remaining 40% that contacted me for screening rounds, 20% declined later, while the other 20% advanced to the next stages.\n\nPreparing has been incredibly challenging. I'm uncertain about where to focus my efforts.\nI've encountered rounds such as:\n1) Online tests/take-home assignments\n2) Hiring manager round\n3) Technical round\n4) Data pipeline design round (not Data modeling)\n5) Cultural fit round\n\nI'm torn about whether to prepare for DSA, or delve into data engineering topics like Data Quality, ETL, and Data Pipeline Design. Or work on side projects to showcase my skills. There are countless topics to cover and hundreds of details to remember. I'm feeling overwhelmed by the entire process.\n\nIf any of you are job hunting (especially in Europe), please share your experiences. It would be of great help to me. For those who aren't job hunting, how do you prepare for such challenges?", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Senior data engineer interview preparation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162lzf8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693129194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking for new opportunities for 2 months, and the market is absolutely the worst. \n20% of my applications received no response, 40% of them rejects. \nOf the remaining 40% that contacted me for screening rounds, 20% declined later, while the other 20% advanced to the next stages.&lt;/p&gt;\n\n&lt;p&gt;Preparing has been incredibly challenging. I&amp;#39;m uncertain about where to focus my efforts.\nI&amp;#39;ve encountered rounds such as:\n1) Online tests/take-home assignments\n2) Hiring manager round\n3) Technical round\n4) Data pipeline design round (not Data modeling)\n5) Cultural fit round&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m torn about whether to prepare for DSA, or delve into data engineering topics like Data Quality, ETL, and Data Pipeline Design. Or work on side projects to showcase my skills. There are countless topics to cover and hundreds of details to remember. I&amp;#39;m feeling overwhelmed by the entire process.&lt;/p&gt;\n\n&lt;p&gt;If any of you are job hunting (especially in Europe), please share your experiences. It would be of great help to me. For those who aren&amp;#39;t job hunting, how do you prepare for such challenges?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "162lzf8", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/162lzf8/senior_data_engineer_interview_preparation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162lzf8/senior_data_engineer_interview_preparation/", "subreddit_subscribers": 125084, "created_utc": 1693129194.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_ueuz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Just picked up this big boy for $1 at good will. Worth keeping? Wanted to get a refresher on Hive and cluster scaling for an interview, but this seems overkill and maybe outdated (4th edition is latest)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3yl6gmndiokb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b54db8c2cb5c3ba2c91c7edfba4af0e7be8f1838"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=11d1975fb54c57207602dee003b91e0c2a7b497e"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bfd1b994ba67027689a13442db4e9981c51aa717"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=953ae63527a6098a2e31e85325193400bfd9051b"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1bf61da3104cb1689d4f9285fcc508206b8c09b2"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2fce2ed9eff449f1442d5373fb0ee1ce5ac1ece2"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/3yl6gmndiokb1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=695ebf26632deb1ae2cbc3a09643e9e1473f5816"}, "id": "3yl6gmndiokb1"}, "671hanndiokb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f75d90c6cfac68be8f44b843ff4f16c5175aa4c3"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d816822cbae4988398f32399ba28e2672951b3c"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=15d82e4805fd56edc13a72115402752e540b25f6"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b045c9cb5f1d8c8a2fb88e40d81bb4c94c36fc7b"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d2647c04013e2b1c854a4b0325ba5d865073e905"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b06cbfff56bb631cfb4db095562d24d0cfde9a96"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/671hanndiokb1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;s=a9e0c2a82db988d7db0353413b47be489bc25b20"}, "id": "671hanndiokb1"}}, "name": "t3_162utkn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 16, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "671hanndiokb1", "id": 321269719}, {"media_id": "3yl6gmndiokb1", "id": 321269720}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kok4rdC7sms0Dp5D9QeDDh-r9BGAiYIf9p45EQySpek.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693153417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/162utkn", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162utkn", "is_robot_indexable": true, "report_reasons": null, "author": "uncomfortablepanda", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162utkn/just_picked_up_this_big_boy_for_1_at_good_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/162utkn", "subreddit_subscribers": 125084, "created_utc": 1693153417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Title. Taking data engineer course currently and planning on going back for my Masters in computer science soon, will also be reading tons of data engineering guides and attending webinars for different softwares. But wanted to know what some of the biggest challenges to look out for are as a new engineer", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's one of the hardest things to adjust to as a new data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162p6ou", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693139446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title. Taking data engineer course currently and planning on going back for my Masters in computer science soon, will also be reading tons of data engineering guides and attending webinars for different softwares. But wanted to know what some of the biggest challenges to look out for are as a new engineer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "162p6ou", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162p6ou/whats_one_of_the_hardest_things_to_adjust_to_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162p6ou/whats_one_of_the_hardest_things_to_adjust_to_as_a/", "subreddit_subscribers": 125084, "created_utc": 1693139446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Data Product Strategy | Becoming Metrics-First: Proven Models, Metric Model as a reflection, and Metric Model Enablement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162l3h4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1693126133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/the-data-product-strategy-becoming", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "162l3h4", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162l3h4/the_data_product_strategy_becoming_metricsfirst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/the-data-product-strategy-becoming", "subreddit_subscribers": 125084, "created_utc": 1693126133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have such a massive amount of tables in BQ that we dont keep track of how one table relates to  other or what columns a given table has.  Of course, we know the lineage of the data taking a look into some DAGs but is becoming increasingly difficult to have a global view.\n\nI suppose that in the beginning we had some care for this, at least for the core tables but after years of \"open policy\" for updating tables (we accept almost every request from Business Analyst ) is messy.\n\nI talked to the manger about this and he is aware of the problem but in his opinion even if we manually create a sort of UML diagram of the warehouse, it will soon become outdated.\n\nIs the database schema design fate to be forgotten once the WH becomes huge ?\n\nAnyone facing this issue? How to proceed ?", "author_fullname": "t2_4bchq4zo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to keep track of warehouse tables schemas in BQ ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162n23f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693132904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have such a massive amount of tables in BQ that we dont keep track of how one table relates to  other or what columns a given table has.  Of course, we know the lineage of the data taking a look into some DAGs but is becoming increasingly difficult to have a global view.&lt;/p&gt;\n\n&lt;p&gt;I suppose that in the beginning we had some care for this, at least for the core tables but after years of &amp;quot;open policy&amp;quot; for updating tables (we accept almost every request from Business Analyst ) is messy.&lt;/p&gt;\n\n&lt;p&gt;I talked to the manger about this and he is aware of the problem but in his opinion even if we manually create a sort of UML diagram of the warehouse, it will soon become outdated.&lt;/p&gt;\n\n&lt;p&gt;Is the database schema design fate to be forgotten once the WH becomes huge ?&lt;/p&gt;\n\n&lt;p&gt;Anyone facing this issue? How to proceed ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162n23f", "is_robot_indexable": true, "report_reasons": null, "author": "Grand-Theory", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162n23f/how_to_keep_track_of_warehouse_tables_schemas_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162n23f/how_to_keep_track_of_warehouse_tables_schemas_in/", "subreddit_subscribers": 125084, "created_utc": 1693132904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nI have an unique business problem I'm looking to tackle. To keep it short, I work with data that has strict residency requirements, so we're forced to keep databases in multiple \\[cloud provider\\] regions, which store specific customer data. We also give customers specialized schemas if they need more compute. As a result, we have 50+ targets between catalog/schema. When I want to query our production databases for ad-hoc requests, I essentially need to run the query 50+ times slightly modified (I use jinja templating to automate this)\n\nHowever, in the current system, this means that doing analysis across regions is essentially impossible, since the different databases can't interact with each other. We have attempted to solve this problem with Trino, but it's still doesn't exactly solve our needs, and it's expensive as hell for us to pay for the compute when that doesn't exactly solve the business need. \n\nI've been thinking about this problem for a few weeks, and I was thinking of essentially a piece of software that serves as a \"gateway\" to the other regions, so you send a query to this software, it transforms it into sql that our databases can understand, does calculation in the software, then streams the result to a warehouse / file / etc whatever. However, I think this is a little bit convoluted, because for example, if I'm doing a group by, I would need to pull all the ungrouped data from every region, union it, then do the grouping in the transformation software itself. \n\nI was looking at connectorx as a potential solution, but it doesn't support batch processing, and the volume of data I deal with is so massive that I'd prefer something that has async compute compatibility. Has anyone faced a similar problem and has any recommendations of how to solve this? I'd appreciate any insights :)", "author_fullname": "t2_v12atn7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solving the worst data residency problem by rewriting SQL transparently", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162b0kd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "287cf772-ac9d-11eb-aa84-0ead36cb44af", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693094573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I have an unique business problem I&amp;#39;m looking to tackle. To keep it short, I work with data that has strict residency requirements, so we&amp;#39;re forced to keep databases in multiple [cloud provider] regions, which store specific customer data. We also give customers specialized schemas if they need more compute. As a result, we have 50+ targets between catalog/schema. When I want to query our production databases for ad-hoc requests, I essentially need to run the query 50+ times slightly modified (I use jinja templating to automate this)&lt;/p&gt;\n\n&lt;p&gt;However, in the current system, this means that doing analysis across regions is essentially impossible, since the different databases can&amp;#39;t interact with each other. We have attempted to solve this problem with Trino, but it&amp;#39;s still doesn&amp;#39;t exactly solve our needs, and it&amp;#39;s expensive as hell for us to pay for the compute when that doesn&amp;#39;t exactly solve the business need. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been thinking about this problem for a few weeks, and I was thinking of essentially a piece of software that serves as a &amp;quot;gateway&amp;quot; to the other regions, so you send a query to this software, it transforms it into sql that our databases can understand, does calculation in the software, then streams the result to a warehouse / file / etc whatever. However, I think this is a little bit convoluted, because for example, if I&amp;#39;m doing a group by, I would need to pull all the ungrouped data from every region, union it, then do the grouping in the transformation software itself. &lt;/p&gt;\n\n&lt;p&gt;I was looking at connectorx as a potential solution, but it doesn&amp;#39;t support batch processing, and the volume of data I deal with is so massive that I&amp;#39;d prefer something that has async compute compatibility. Has anyone faced a similar problem and has any recommendations of how to solve this? I&amp;#39;d appreciate any insights :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data/Software Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162b0kd", "is_robot_indexable": true, "report_reasons": null, "author": "Dazzling-Reason-5140", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/162b0kd/solving_the_worst_data_residency_problem_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162b0kd/solving_the_worst_data_residency_problem_by/", "subreddit_subscribers": 125084, "created_utc": 1693094573.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I've been poking around online and noticed there isn't a ton of talk about ingesting messy, unstructured data at **larger scale**. Got me wondering, anyone else been down this rabbit hole?\n\nWhen it comes to handling (ingestion/staging) all those unruly files in your data lake for stuff like Machine Learning or Reports (Especially lot more use cases coming up after LLM), how do you do it? \ud83e\udd14 For example, extracting information from drawing files.\n\nCurious to know how your data pipeline and jobs are all set up. Did you run into any big challenges wrangling that wild unstructured data? And what tools did you turn to fix the puzzle?\n\nLooking forward to hearing your stories and tips!", "author_fullname": "t2_3xh5j7zr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating data pipelines for unstructured big data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162tc16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693154858.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693149991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;ve been poking around online and noticed there isn&amp;#39;t a ton of talk about ingesting messy, unstructured data at &lt;strong&gt;larger scale&lt;/strong&gt;. Got me wondering, anyone else been down this rabbit hole?&lt;/p&gt;\n\n&lt;p&gt;When it comes to handling (ingestion/staging) all those unruly files in your data lake for stuff like Machine Learning or Reports (Especially lot more use cases coming up after LLM), how do you do it? \ud83e\udd14 For example, extracting information from drawing files.&lt;/p&gt;\n\n&lt;p&gt;Curious to know how your data pipeline and jobs are all set up. Did you run into any big challenges wrangling that wild unstructured data? And what tools did you turn to fix the puzzle?&lt;/p&gt;\n\n&lt;p&gt;Looking forward to hearing your stories and tips!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162tc16", "is_robot_indexable": true, "report_reasons": null, "author": "thedatumgirl", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162tc16/creating_data_pipelines_for_unstructured_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162tc16/creating_data_pipelines_for_unstructured_big_data/", "subreddit_subscribers": 125084, "created_utc": 1693149991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "#  Orchestrate Jupyter Notebooks with Dagster |  Jupyter Notebook | Schedule Notebooks with Dagster\n\n\ud83d\udcf7[**Blog**](https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;restrict_sr=1)\n\nVlog on how to integrate and orchestrate Jupyter Notebook with Dagster? | Dagster | Jupyter Notebook|\n\n[https://www.youtube.com/watch?v=0BgcFTfyl-E&amp;t](https://www.youtube.com/watch?v=0BgcFTfyl-E&amp;t)\n\nTopics covered:\n\n* Integrate Jupyter Notebook(s) with Dagster\n* Dagster Assets and Jobs\n* How to schedule Dagster Assets\n\nTech Stack: **Dagster, Jupyter Notebook, Python**", "author_fullname": "t2_vj0466m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to schedule Jupyter Notebooks with Dagster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16252qt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693080127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Orchestrate Jupyter Notebooks with Dagster |  Jupyter Notebook | Schedule Notebooks with Dagster&lt;/h1&gt;\n\n&lt;p&gt;\ud83d\udcf7&lt;a href=\"https://www.reddit.com/r/dataengineering/search?q=flair_name%3A%22Blog%22&amp;amp;restrict_sr=1\"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Vlog on how to integrate and orchestrate Jupyter Notebook with Dagster? | Dagster | Jupyter Notebook|&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=0BgcFTfyl-E&amp;amp;t\"&gt;https://www.youtube.com/watch?v=0BgcFTfyl-E&amp;amp;t&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics covered:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Integrate Jupyter Notebook(s) with Dagster&lt;/li&gt;\n&lt;li&gt;Dagster Assets and Jobs&lt;/li&gt;\n&lt;li&gt;How to schedule Dagster Assets&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Tech Stack: &lt;strong&gt;Dagster, Jupyter Notebook, Python&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9h7_X18QHHtG914mH2WCk_bD994XACtyhThfNumWwj0.jpg?auto=webp&amp;s=f8f3c5525bd5d1f51fc72693c7e80f051d43dcb7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/9h7_X18QHHtG914mH2WCk_bD994XACtyhThfNumWwj0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8be97701d7aafa1662fc6f770d2a6f8747e8a316", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/9h7_X18QHHtG914mH2WCk_bD994XACtyhThfNumWwj0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b73afbc13f9e6f3924ec01687f219a7025df3346", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/9h7_X18QHHtG914mH2WCk_bD994XACtyhThfNumWwj0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cb31a7cd88033b1063e6dd0b3d60c41245f4ccbf", "width": 320, "height": 240}], "variants": {}, "id": "YMCLxP0ZSE9Bac6yHvpte8BLDl_QBx5_XSE1o4hslEk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16252qt", "is_robot_indexable": true, "report_reasons": null, "author": "Either-Adeptness6638", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16252qt/how_to_schedule_jupyter_notebooks_with_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16252qt/how_to_schedule_jupyter_notebooks_with_dagster/", "subreddit_subscribers": 125084, "created_utc": 1693080127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know it's weirdly specific but I just want to ask. \n\nFor Data Engineers who work for shipping companies, what exactly do you do in your day to day job. \n\nHow often do you use SQL, Python, and building data lakes or data warehouse? \n\nHow do often do you talk with colleagues from different departments and upper management.", "author_fullname": "t2_5hcl0uoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineers that work for shipping companies.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162hhnb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693113460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it&amp;#39;s weirdly specific but I just want to ask. &lt;/p&gt;\n\n&lt;p&gt;For Data Engineers who work for shipping companies, what exactly do you do in your day to day job. &lt;/p&gt;\n\n&lt;p&gt;How often do you use SQL, Python, and building data lakes or data warehouse? &lt;/p&gt;\n\n&lt;p&gt;How do often do you talk with colleagues from different departments and upper management.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162hhnb", "is_robot_indexable": true, "report_reasons": null, "author": "Large-Relationship37", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162hhnb/data_engineers_that_work_for_shipping_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162hhnb/data_engineers_that_work_for_shipping_companies/", "subreddit_subscribers": 125084, "created_utc": 1693113460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello - I am a fairly new DE with 1 yr of experience. My director has been tasked with moving our data infrastructure to modern data stack. Can someone tell me what are the problems or gaps  that modern data stacks still haves and my company needs to watch out for? We are thinking Fivetran, Snowflake, DBT and looker. Some of the current problems that I face on a regular basis are inconsistent data formats, data structure changes in source systems making data integration really painful. Does fivetran help with that? Also, what are gaps in dbt with managing CDCs effectively? ", "author_fullname": "t2_v54v19cn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice on Modern Data stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16295nq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693089849.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello - I am a fairly new DE with 1 yr of experience. My director has been tasked with moving our data infrastructure to modern data stack. Can someone tell me what are the problems or gaps  that modern data stacks still haves and my company needs to watch out for? We are thinking Fivetran, Snowflake, DBT and looker. Some of the current problems that I face on a regular basis are inconsistent data formats, data structure changes in source systems making data integration really painful. Does fivetran help with that? Also, what are gaps in dbt with managing CDCs effectively? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16295nq", "is_robot_indexable": true, "report_reasons": null, "author": "NewDE2023", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16295nq/looking_for_advice_on_modern_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16295nq/looking_for_advice_on_modern_data_stack/", "subreddit_subscribers": 125084, "created_utc": 1693089849.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "End-users in my project are a team of data scientists and analytics people. My sources are On-prem oracle, on-prem Db2 and Azure Cosmos db. End users are only interested in tabular format data for their analysis purposes. I need to present them data from all three sources integrated. Cosmos db containers have nested and very complex json structures running up to 5k to 10k lines for each item in the collection. Any suggestions on how to flatten them and integrate them with oracle/Db2? Another major question what would be the best place to load them so that they can access it easily using queries.", "author_fullname": "t2_b742rj0h7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cosmos db question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1628obw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693088677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;End-users in my project are a team of data scientists and analytics people. My sources are On-prem oracle, on-prem Db2 and Azure Cosmos db. End users are only interested in tabular format data for their analysis purposes. I need to present them data from all three sources integrated. Cosmos db containers have nested and very complex json structures running up to 5k to 10k lines for each item in the collection. Any suggestions on how to flatten them and integrate them with oracle/Db2? Another major question what would be the best place to load them so that they can access it easily using queries.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1628obw", "is_robot_indexable": true, "report_reasons": null, "author": "clakshminarasu", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1628obw/cosmos_db_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1628obw/cosmos_db_question/", "subreddit_subscribers": 125084, "created_utc": 1693088677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does this sound like a data engineering position?\n\nTwo years after leaving, my previous company asked me to come back, and they were wondering if I\u2019d be interested in a position that isn\u2019t called \u201cdata engineer\u201d, but might meet some of the criteria?\n\nI\u2019m asking because I\u2019m interested in breaking into the data engineering field, and I\u2019m curious if these skills are niche or would have good carry over. For reference, I am a Data Analyst with 5+ yoe using Python (web scraping, pandas, numpy, regression libraries), sql (mainly querying but I have web scraped, cleaned data, and imported it into MySQL) and tableau. \n\nSkills:\n-  tableau connections to mongo database via the API. SQL being used here.\n- VueJs with vuetify for the UI elements (JSON).\n- Python for some batch scripting and data syncs between ECW and mongo\n\n\nThat\u2019s really the only description I\u2019ve gotten of the job so far. I\u2019m curious on what questions I could ask to get a better understanding.\n\nI\u2019m currently a Data Analyst", "author_fullname": "t2_6iptp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does this sound like a DE job or have any skill crossover?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1627yab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693087310.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693086950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does this sound like a data engineering position?&lt;/p&gt;\n\n&lt;p&gt;Two years after leaving, my previous company asked me to come back, and they were wondering if I\u2019d be interested in a position that isn\u2019t called \u201cdata engineer\u201d, but might meet some of the criteria?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m asking because I\u2019m interested in breaking into the data engineering field, and I\u2019m curious if these skills are niche or would have good carry over. For reference, I am a Data Analyst with 5+ yoe using Python (web scraping, pandas, numpy, regression libraries), sql (mainly querying but I have web scraped, cleaned data, and imported it into MySQL) and tableau. &lt;/p&gt;\n\n&lt;p&gt;Skills:\n-  tableau connections to mongo database via the API. SQL being used here.\n- VueJs with vuetify for the UI elements (JSON).\n- Python for some batch scripting and data syncs between ECW and mongo&lt;/p&gt;\n\n&lt;p&gt;That\u2019s really the only description I\u2019ve gotten of the job so far. I\u2019m curious on what questions I could ask to get a better understanding.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently a Data Analyst&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1627yab", "is_robot_indexable": true, "report_reasons": null, "author": "tits_mcgee_92", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1627yab/does_this_sound_like_a_de_job_or_have_any_skill/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1627yab/does_this_sound_like_a_de_job_or_have_any_skill/", "subreddit_subscribers": 125084, "created_utc": 1693086950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am curious what would be some good practices around using databricks and powerbi together. \n\nWe've been instructed by management and some tech teams to look into databricks as an interim solution.\n\nSo we've been looking at using databricks as connector to powerbi for pulling large amounts of data from AWS Athena/S3 into Powerbi.\n  \nWe have some SQL queries that pulls lots of data and join data together. Is it better to schedule databricks to run the query,  build/append to a table in athena then have powerbi pull from the table? Or is it fine to run SQL query in powerbi with databricks connector.\n\nI think the more correct approach would be to build the table but I might be wrong so I want hear from y'all.\n\nAlso, I might be wrong but it looks like databricks uses odbc right, we had issues with odbc failling in the past. Might that still exists?\n\nWhat are somethings would y'all advise to watch out for around databricks and using it as connector for powerbi? Something I notice it takes awhile for it to start up.", "author_fullname": "t2_16je8s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks and PowerBI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_162xquo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693160245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am curious what would be some good practices around using databricks and powerbi together. &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve been instructed by management and some tech teams to look into databricks as an interim solution.&lt;/p&gt;\n\n&lt;p&gt;So we&amp;#39;ve been looking at using databricks as connector to powerbi for pulling large amounts of data from AWS Athena/S3 into Powerbi.&lt;/p&gt;\n\n&lt;p&gt;We have some SQL queries that pulls lots of data and join data together. Is it better to schedule databricks to run the query,  build/append to a table in athena then have powerbi pull from the table? Or is it fine to run SQL query in powerbi with databricks connector.&lt;/p&gt;\n\n&lt;p&gt;I think the more correct approach would be to build the table but I might be wrong so I want hear from y&amp;#39;all.&lt;/p&gt;\n\n&lt;p&gt;Also, I might be wrong but it looks like databricks uses odbc right, we had issues with odbc failling in the past. Might that still exists?&lt;/p&gt;\n\n&lt;p&gt;What are somethings would y&amp;#39;all advise to watch out for around databricks and using it as connector for powerbi? Something I notice it takes awhile for it to start up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162xquo", "is_robot_indexable": true, "report_reasons": null, "author": "wowzersboy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162xquo/databricks_and_powerbi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162xquo/databricks_and_powerbi/", "subreddit_subscribers": 125084, "created_utc": 1693160245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nour company is currently evaluating the cost of using cloud ETL Tools like Databricks On AWS or Synapse on Azure and on prem native Tools like SSIS. Currently our partner told us that the trend is moving back from Cloud to On Prem due to cost reasons. After finding cloud to be more expensive than expected, Companies have began to move back to on prem for several cost optimization reasons. \n\nWhat is your experience and opinion on the matter? \n\nI still believe cloud to be the future but can't deny that cloud tools might be more expensive although I don't have an oversight regarding the costs.", "author_fullname": "t2_go0bd7txp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost factor of cloud vs on prem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162tynt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693151443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;our company is currently evaluating the cost of using cloud ETL Tools like Databricks On AWS or Synapse on Azure and on prem native Tools like SSIS. Currently our partner told us that the trend is moving back from Cloud to On Prem due to cost reasons. After finding cloud to be more expensive than expected, Companies have began to move back to on prem for several cost optimization reasons. &lt;/p&gt;\n\n&lt;p&gt;What is your experience and opinion on the matter? &lt;/p&gt;\n\n&lt;p&gt;I still believe cloud to be the future but can&amp;#39;t deny that cloud tools might be more expensive although I don&amp;#39;t have an oversight regarding the costs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162tynt", "is_robot_indexable": true, "report_reasons": null, "author": "SuccessfulCase4281", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162tynt/cost_factor_of_cloud_vs_on_prem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162tynt/cost_factor_of_cloud_vs_on_prem/", "subreddit_subscribers": 125084, "created_utc": 1693151443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have been operating an on-prem bought Oracle/ODI ODS/Cognos solution from a HigherEd ERP vendor for the last 10 yrs, and they just announced its end of life (EOL).\n\nWe\u2019re a heavily Microsoft institution and have been dabbling with a lightly-funded Azure Synapse environment for niche data needs.\n\nThis EOL is a gift as our BI platform seems woefully outdated, and we\u2019re reading up on Data Governance/Mesh/EA, looking at tools like Airflow, DBT, MS Fabric/PowerBI as potential stack-components to migrate our solution from the vendor-designed DW to a home-grown solution to satisfy integrations as well as BI. TBH, I\u2019m still trying to understand how these new tech components/concepts even work together, and how to approach migrating hundreds of reports built on a rat-king of layered transformations by the vendor, most layers aimed at performance (non-issue with our amount of data and compute needs if on Azure/Fabric).\n\nHas anyone here been through such a migration/modernization, bought-to-homegrown project? Any advise on the outset?", "author_fullname": "t2_f1kbimm96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DW Migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1624zve", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693079955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have been operating an on-prem bought Oracle/ODI ODS/Cognos solution from a HigherEd ERP vendor for the last 10 yrs, and they just announced its end of life (EOL).&lt;/p&gt;\n\n&lt;p&gt;We\u2019re a heavily Microsoft institution and have been dabbling with a lightly-funded Azure Synapse environment for niche data needs.&lt;/p&gt;\n\n&lt;p&gt;This EOL is a gift as our BI platform seems woefully outdated, and we\u2019re reading up on Data Governance/Mesh/EA, looking at tools like Airflow, DBT, MS Fabric/PowerBI as potential stack-components to migrate our solution from the vendor-designed DW to a home-grown solution to satisfy integrations as well as BI. TBH, I\u2019m still trying to understand how these new tech components/concepts even work together, and how to approach migrating hundreds of reports built on a rat-king of layered transformations by the vendor, most layers aimed at performance (non-issue with our amount of data and compute needs if on Azure/Fabric).&lt;/p&gt;\n\n&lt;p&gt;Has anyone here been through such a migration/modernization, bought-to-homegrown project? Any advise on the outset?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1624zve", "is_robot_indexable": true, "report_reasons": null, "author": "No-Database2068", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1624zve/dw_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1624zve/dw_migration/", "subreddit_subscribers": 125084, "created_utc": 1693079955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The reason I don't like SQL over something like Pandas is because in Pandas/Python I can break down the complex transformations in small simpler components and they are easy to interact and debug with. In SQL my only option is to write stored procedures and yes in that I can also do the same but I think the ecosystem of interacting and debugging with data step by step is not as good as python. And it is something that we should have. Recently I was exploring snowpark and I felt it is a step in a right direction. It allows to me to write my query in multiple python statements and then it will transpile the whole thing into an SQL query.  \n\n\nGenerally in my mind I assume the tables/dataframes as 2 dimensional structures and Pandas API give much more intuitive and wide variety of constructs to explore that structure rather than SQL. What do you guys think?", "author_fullname": "t2_q27tep12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why I don't like SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162ig5h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.46, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693116758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The reason I don&amp;#39;t like SQL over something like Pandas is because in Pandas/Python I can break down the complex transformations in small simpler components and they are easy to interact and debug with. In SQL my only option is to write stored procedures and yes in that I can also do the same but I think the ecosystem of interacting and debugging with data step by step is not as good as python. And it is something that we should have. Recently I was exploring snowpark and I felt it is a step in a right direction. It allows to me to write my query in multiple python statements and then it will transpile the whole thing into an SQL query.  &lt;/p&gt;\n\n&lt;p&gt;Generally in my mind I assume the tables/dataframes as 2 dimensional structures and Pandas API give much more intuitive and wide variety of constructs to explore that structure rather than SQL. What do you guys think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "162ig5h", "is_robot_indexable": true, "report_reasons": null, "author": "__albatross", "discussion_type": null, "num_comments": 76, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/162ig5h/why_i_dont_like_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/162ig5h/why_i_dont_like_sql/", "subreddit_subscribers": 125084, "created_utc": 1693116758.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}