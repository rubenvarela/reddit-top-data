{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve had dozens of interviews over the past 6 months and nobody has asked a single tech question or done a technical assessment. I think I\u2019ve got to the final round 6 times without any offers.\n\nWhat was the point of learning data science if employers are just going to judge me based on what spirit animal I would be or where I see myself in 10 years?\n\nIs it just who I\u2019ve been interviewing with or is this an overall theme?", "author_fullname": "t2_4q04yojj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why does nobody ask technical questions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1627l75", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 116, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 116, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693086078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve had dozens of interviews over the past 6 months and nobody has asked a single tech question or done a technical assessment. I think I\u2019ve got to the final round 6 times without any offers.&lt;/p&gt;\n\n&lt;p&gt;What was the point of learning data science if employers are just going to judge me based on what spirit animal I would be or where I see myself in 10 years?&lt;/p&gt;\n\n&lt;p&gt;Is it just who I\u2019ve been interviewing with or is this an overall theme?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1627l75", "is_robot_indexable": true, "report_reasons": null, "author": "CyHawkNerd", "discussion_type": null, "num_comments": 88, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1627l75/why_does_nobody_ask_technical_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1627l75/why_does_nobody_ask_technical_questions/", "subreddit_subscribers": 1017190, "created_utc": 1693086078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the worst questions you\u2019ve ever been asked in an interview? \n\nI had the worst interview of my life this week. So bad that I removed myself from consideration. It was with the CEO and the first three rounds of interviews went very well. These three questions were asked in this order:\n\n1. \u201cWhat is the hardest thing you\u2019ve ever had to do?\u201d\n2. \u201cI\u2019m not searching for a specific answer, but what is the second hardest thing you\u2019ve ever had to do?\u201d\n3. Put yourself in your manager\u2019s shoes and give me three reasons why you don\u2019t deserve a promotion. \n\nMan, what a weird set of questions.", "author_fullname": "t2_g7gx7tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Worst Interview Questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162ckok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 107, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 107, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693098785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the worst questions you\u2019ve ever been asked in an interview? &lt;/p&gt;\n\n&lt;p&gt;I had the worst interview of my life this week. So bad that I removed myself from consideration. It was with the CEO and the first three rounds of interviews went very well. These three questions were asked in this order:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;\u201cWhat is the hardest thing you\u2019ve ever had to do?\u201d&lt;/li&gt;\n&lt;li&gt;\u201cI\u2019m not searching for a specific answer, but what is the second hardest thing you\u2019ve ever had to do?\u201d&lt;/li&gt;\n&lt;li&gt;Put yourself in your manager\u2019s shoes and give me three reasons why you don\u2019t deserve a promotion. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Man, what a weird set of questions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162ckok", "is_robot_indexable": true, "report_reasons": null, "author": "jt97suu", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162ckok/worst_interview_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162ckok/worst_interview_questions/", "subreddit_subscribers": 1017190, "created_utc": 1693098785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I often find myself in conversation with people with little-to-no understanding of IT in general, and less of data science.\n\nI work as a data scientist that mostly have to do a lot of BA bullshit like speaking with stakeholders. I probably spend 75 percent of my time in meetings with internal stakeholders. \n\nMy trouble is that I sort of start out explaining what machine learning is and how we use statistical models to do X and Y for the company then explaining how I actually not do that for most of my time, seeing the life actually leaving the persons body so I just end up saying something along the lines of \u201cI press buttons and the computer goes brrr.\u201d\n\nHow do you guys handle these situations?\nKind regards\nSocially awkward data scientist", "author_fullname": "t2_g381bacdm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you tell people you do for a living?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162ioz4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693117621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I often find myself in conversation with people with little-to-no understanding of IT in general, and less of data science.&lt;/p&gt;\n\n&lt;p&gt;I work as a data scientist that mostly have to do a lot of BA bullshit like speaking with stakeholders. I probably spend 75 percent of my time in meetings with internal stakeholders. &lt;/p&gt;\n\n&lt;p&gt;My trouble is that I sort of start out explaining what machine learning is and how we use statistical models to do X and Y for the company then explaining how I actually not do that for most of my time, seeing the life actually leaving the persons body so I just end up saying something along the lines of \u201cI press buttons and the computer goes brrr.\u201d&lt;/p&gt;\n\n&lt;p&gt;How do you guys handle these situations?\nKind regards\nSocially awkward data scientist&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162ioz4", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_Belaja", "discussion_type": null, "num_comments": 105, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162ioz4/what_do_you_tell_people_you_do_for_a_living/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162ioz4/what_do_you_tell_people_you_do_for_a_living/", "subreddit_subscribers": 1017190, "created_utc": 1693117621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "With the advent of more and more dedicated advanced Data Science degrees, will PhD holders in \"general\" (non DS/ML/CS) areas stop being hired as DSs in the next few years?\n\nGiven the list of requirements I've seen on job listings, it appears that the times in which PhDs were hired due to their skills to learn and think analytically outside the box (if this ever was really a thing), are far in the past. It looks to me that, currently, even for entry-level jobs, the market favors people with the full stack of specific technical skills plus experience already under their arms. Put another way, freshly graduated PhDs are just not adecquate for entry-level jobs.\n\nApologies if the question isn't very well formulated. For context, I've noticed that some friends who recently finished their PhD (say math or physics) and are currently looking for DS roles, are pretty much being ignored by recruiters. What I'd like to understand is if this responds to global factors where everyone is being treated \"equally\" in difficult times, or if having a generalist PhD by itself is never gonna cut it again (if ever). Could online courses (not an online DS master!) still be relevant for these PhDs to get a job, or would PhD holders have to go back to school and do a DS master's should they decide to pursue this career for a lack of a better option?", "author_fullname": "t2_gajawaxj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will Data Science stop being a plan-B for generalist PhD holders?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162h8yh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693112668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the advent of more and more dedicated advanced Data Science degrees, will PhD holders in &amp;quot;general&amp;quot; (non DS/ML/CS) areas stop being hired as DSs in the next few years?&lt;/p&gt;\n\n&lt;p&gt;Given the list of requirements I&amp;#39;ve seen on job listings, it appears that the times in which PhDs were hired due to their skills to learn and think analytically outside the box (if this ever was really a thing), are far in the past. It looks to me that, currently, even for entry-level jobs, the market favors people with the full stack of specific technical skills plus experience already under their arms. Put another way, freshly graduated PhDs are just not adecquate for entry-level jobs.&lt;/p&gt;\n\n&lt;p&gt;Apologies if the question isn&amp;#39;t very well formulated. For context, I&amp;#39;ve noticed that some friends who recently finished their PhD (say math or physics) and are currently looking for DS roles, are pretty much being ignored by recruiters. What I&amp;#39;d like to understand is if this responds to global factors where everyone is being treated &amp;quot;equally&amp;quot; in difficult times, or if having a generalist PhD by itself is never gonna cut it again (if ever). Could online courses (not an online DS master!) still be relevant for these PhDs to get a job, or would PhD holders have to go back to school and do a DS master&amp;#39;s should they decide to pursue this career for a lack of a better option?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162h8yh", "is_robot_indexable": true, "report_reasons": null, "author": "SincopaDisonante", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162h8yh/will_data_science_stop_being_a_planb_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162h8yh/will_data_science_stop_being_a_planb_for/", "subreddit_subscribers": 1017190, "created_utc": 1693112668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So i am working as a junior data scientist in a financial company and i have been given a project to predict customers if they will invest in our bank or not. I have around 73 variables. These include demographic and their history on our banking app. I am currently using logistic and random forest but my model is giving very bad results on test data. Precision is 1 and recall is 0.\n\nThe train data is highly imbalanced so i am performing an undersampling technique where i take only those rows where the missing value count is less. According to my manager, i should have a higher recall and because this is my first project, i am kind of stuck in what more i can do. I have performed hyperparameter tuning but still the results on test data is very bad. \n\nTrain data: 97k for majority class and 25k for Minority\n\nTest data: 36M for majority class and 30k for Minority\n\nPlease let me know if you need more information in what i am doing or what i can do, any help is appreciated. ", "author_fullname": "t2_aohlpzsv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cant get my model right", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162lxcw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693128995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i am working as a junior data scientist in a financial company and i have been given a project to predict customers if they will invest in our bank or not. I have around 73 variables. These include demographic and their history on our banking app. I am currently using logistic and random forest but my model is giving very bad results on test data. Precision is 1 and recall is 0.&lt;/p&gt;\n\n&lt;p&gt;The train data is highly imbalanced so i am performing an undersampling technique where i take only those rows where the missing value count is less. According to my manager, i should have a higher recall and because this is my first project, i am kind of stuck in what more i can do. I have performed hyperparameter tuning but still the results on test data is very bad. &lt;/p&gt;\n\n&lt;p&gt;Train data: 97k for majority class and 25k for Minority&lt;/p&gt;\n\n&lt;p&gt;Test data: 36M for majority class and 30k for Minority&lt;/p&gt;\n\n&lt;p&gt;Please let me know if you need more information in what i am doing or what i can do, any help is appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162lxcw", "is_robot_indexable": true, "report_reasons": null, "author": "LieTechnical1662", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162lxcw/cant_get_my_model_right/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162lxcw/cant_get_my_model_right/", "subreddit_subscribers": 1017190, "created_utc": 1693128995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\\[Not sure if this breaking any rule or not, if it is, my apologies in advance\\]\n\nI am preparing for entry level position or internship position for Data Science/Machine Learning in the industry, is there a collection for such questions to prepare beforehand? Especially keeping with the fast changing industry standard?", "author_fullname": "t2_7lqv45ds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview questions for preparation for entry level position for Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1628bpa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693087824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[Not sure if this breaking any rule or not, if it is, my apologies in advance]&lt;/p&gt;\n\n&lt;p&gt;I am preparing for entry level position or internship position for Data Science/Machine Learning in the industry, is there a collection for such questions to prepare beforehand? Especially keeping with the fast changing industry standard?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1628bpa", "is_robot_indexable": true, "report_reasons": null, "author": "SmartPuppyy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1628bpa/interview_questions_for_preparation_for_entry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1628bpa/interview_questions_for_preparation_for_entry/", "subreddit_subscribers": 1017190, "created_utc": 1693087824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I'm a recent (5months ago) international graduate student and been actively looking for a job.\n\nI've been applying almost 1000+ position since last year and got about 10+ interviews and coding tests.\n\nI found this channel that's really active and helpful (before I didn't know about reddit enough).\n\nI'm looking for software engineer (not web dev position) / Data Science / ML position. However, I sometimes feel like my resume can't get even near hiring manager. (very few response rate)\n\nThus, I'm here to ask for help desperately. What I can improve, what to fix, etc.\n\nAny honest feedback (good &amp; bad) would be helpful for me! Thank you\n\nhttps://preview.redd.it/pi8swhy8zlkb1.png?width=657&amp;format=png&amp;auto=webp&amp;s=5d5ccc78bc8f834f5ba70907d37e3e24ce4d680d", "author_fullname": "t2_jkiaz6mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "May I ask you guys for honest, professional feedback?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"pi8swhy8zlkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 147, "x": 108, "u": "https://preview.redd.it/pi8swhy8zlkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0fcf63cc322c9b1ab495d4f2a0dfa64991aa8b02"}, {"y": 294, "x": 216, "u": "https://preview.redd.it/pi8swhy8zlkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4f8560e20c1cc2e0ae0591c810dea638e0dc10c2"}, {"y": 435, "x": 320, "u": "https://preview.redd.it/pi8swhy8zlkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3da95347867f14fa119202b590ca4eff9eedf023"}, {"y": 871, "x": 640, "u": "https://preview.redd.it/pi8swhy8zlkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e2184642d1118b6d0ff9d4411274418756552446"}], "s": {"y": 895, "x": 657, "u": "https://preview.redd.it/pi8swhy8zlkb1.png?width=657&amp;format=png&amp;auto=webp&amp;s=5d5ccc78bc8f834f5ba70907d37e3e24ce4d680d"}, "id": "pi8swhy8zlkb1"}}, "name": "t3_162k0jj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/JzmeLYOGKzAXrEbnIKaw7uN6Ra96D2ariTOEsTY1p64.jpg", "edited": 1693122763.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693122276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m a recent (5months ago) international graduate student and been actively looking for a job.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been applying almost 1000+ position since last year and got about 10+ interviews and coding tests.&lt;/p&gt;\n\n&lt;p&gt;I found this channel that&amp;#39;s really active and helpful (before I didn&amp;#39;t know about reddit enough).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for software engineer (not web dev position) / Data Science / ML position. However, I sometimes feel like my resume can&amp;#39;t get even near hiring manager. (very few response rate)&lt;/p&gt;\n\n&lt;p&gt;Thus, I&amp;#39;m here to ask for help desperately. What I can improve, what to fix, etc.&lt;/p&gt;\n\n&lt;p&gt;Any honest feedback (good &amp;amp; bad) would be helpful for me! Thank you&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pi8swhy8zlkb1.png?width=657&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5d5ccc78bc8f834f5ba70907d37e3e24ce4d680d\"&gt;https://preview.redd.it/pi8swhy8zlkb1.png?width=657&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5d5ccc78bc8f834f5ba70907d37e3e24ce4d680d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162k0jj", "is_robot_indexable": true, "report_reasons": null, "author": "Minimum_Ad_1634", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162k0jj/may_i_ask_you_guys_for_honest_professional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162k0jj/may_i_ask_you_guys_for_honest_professional/", "subreddit_subscribers": 1017190, "created_utc": 1693122276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**UK/European Question**\n\nI did an internship (FTSE 100 company) in 2nd year and got a return offer to either work ft as a Data Analyst or work as a Data Science apprenticeship where I work for 4 days and study for 1, after 21 months being awarded a MSc in Data Science &amp; AI.\n\nThe base salary is \u00a335K, I can work fully remotely although the office (free coffee and a nice skyscraper in central London) is a 45 mins commute on the underground from my family home .\n\nThe main drawbacks for me were the fact the awarding unis weren't great being Southampton Solent or Teeside and the fact it is 21 months - being the reason why I chose against it.There's also overlap with my BSc which is concerning. \n\nThe main pros are of course the money, not much need to live the academic lifestyle (no bank holidays &amp; weekends, being broke, revising &amp; studying 5-7 days a week), work experience and a free MSc (as opposed to 12.5K tuition and at least 10K on maintenance at either Uni of Bath or Notts for Data Science).\n\nTotal money lost could total 55K before tax. I also went to a good UG uni with King's College London doing Computer Science.\n\nHowever, I feel like I am being short-sighted and prioritising short-term pleasure cos I want to remote work on a Greek/Canary island for a few days instead of stressing in a library on a Saturday over a poorly taught module but therefore having a worse uni on my CV. Then again I've had a friend who did his MSc @ Imperial (BSc @ LSE) and he's not working at FAANG or Goldman or a big/well paying company as a Data Scientist so experience &gt; MSc uni name?\n\n**So MSc vs L7 Apprenticeship with MSc?**", "author_fullname": "t2_afxrmg3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "L7 Apprenticeship Worth it or Not?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162n7vr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693134105.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693133467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;UK/European Question&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I did an internship (FTSE 100 company) in 2nd year and got a return offer to either work ft as a Data Analyst or work as a Data Science apprenticeship where I work for 4 days and study for 1, after 21 months being awarded a MSc in Data Science &amp;amp; AI.&lt;/p&gt;\n\n&lt;p&gt;The base salary is \u00a335K, I can work fully remotely although the office (free coffee and a nice skyscraper in central London) is a 45 mins commute on the underground from my family home .&lt;/p&gt;\n\n&lt;p&gt;The main drawbacks for me were the fact the awarding unis weren&amp;#39;t great being Southampton Solent or Teeside and the fact it is 21 months - being the reason why I chose against it.There&amp;#39;s also overlap with my BSc which is concerning. &lt;/p&gt;\n\n&lt;p&gt;The main pros are of course the money, not much need to live the academic lifestyle (no bank holidays &amp;amp; weekends, being broke, revising &amp;amp; studying 5-7 days a week), work experience and a free MSc (as opposed to 12.5K tuition and at least 10K on maintenance at either Uni of Bath or Notts for Data Science).&lt;/p&gt;\n\n&lt;p&gt;Total money lost could total 55K before tax. I also went to a good UG uni with King&amp;#39;s College London doing Computer Science.&lt;/p&gt;\n\n&lt;p&gt;However, I feel like I am being short-sighted and prioritising short-term pleasure cos I want to remote work on a Greek/Canary island for a few days instead of stressing in a library on a Saturday over a poorly taught module but therefore having a worse uni on my CV. Then again I&amp;#39;ve had a friend who did his MSc @ Imperial (BSc @ LSE) and he&amp;#39;s not working at FAANG or Goldman or a big/well paying company as a Data Scientist so experience &amp;gt; MSc uni name?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;So MSc vs L7 Apprenticeship with MSc?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162n7vr", "is_robot_indexable": true, "report_reasons": null, "author": "Tall_Picture8290", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162n7vr/l7_apprenticeship_worth_it_or_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162n7vr/l7_apprenticeship_worth_it_or_not/", "subreddit_subscribers": 1017190, "created_utc": 1693133467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In my current organization , I am not getting any work , or even if I do , it is not a quality work. I suspected this pattern. So , I started applying externally and did not qualify for any job yet. It has been more than 1.5 year. My years of experience are increasing without actually having that experience. I have given n number of interviews. Every interview is kind of new thing. I am data analyst and in interview , some will go focussing on Adv.SQL, some on open ended business , product question , some on DSA , some on mathematical part of machine learning algorithms , some on DAG , ETL. I understand all of the topics pretty well except DSA but until I have a working experience , it is of no use in interview. I will be caught on some or the other topics. I feel there is a lot expected from data analyst /data scientist profile. I tend to forget things here and there. If I share my situation , everyone is like do some trainings on udemy , okay but it is like I am feeding more and more information. I feel tired , exhausted , and my confidence hit a rock bottom. I always have a fear of being kicked out and companies I interviewed and applied for has shown me my value. Does anyone have any actionable suggestions and feedback to improve my confidence to least, I will be happy to receive them", "author_fullname": "t2_3xqv8ii8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No Work, Rejection in Job search", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162on7r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693137901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my current organization , I am not getting any work , or even if I do , it is not a quality work. I suspected this pattern. So , I started applying externally and did not qualify for any job yet. It has been more than 1.5 year. My years of experience are increasing without actually having that experience. I have given n number of interviews. Every interview is kind of new thing. I am data analyst and in interview , some will go focussing on Adv.SQL, some on open ended business , product question , some on DSA , some on mathematical part of machine learning algorithms , some on DAG , ETL. I understand all of the topics pretty well except DSA but until I have a working experience , it is of no use in interview. I will be caught on some or the other topics. I feel there is a lot expected from data analyst /data scientist profile. I tend to forget things here and there. If I share my situation , everyone is like do some trainings on udemy , okay but it is like I am feeding more and more information. I feel tired , exhausted , and my confidence hit a rock bottom. I always have a fear of being kicked out and companies I interviewed and applied for has shown me my value. Does anyone have any actionable suggestions and feedback to improve my confidence to least, I will be happy to receive them&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162on7r", "is_robot_indexable": true, "report_reasons": null, "author": "Fit-Trifle492", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162on7r/no_work_rejection_in_job_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162on7r/no_work_rejection_in_job_search/", "subreddit_subscribers": 1017190, "created_utc": 1693137901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data Scientists or Data Analysts that work for shipping companies/ transportation companies. \n\nI know it's weirdly specific but I just want to ask. \n\nFor Data Scientists and Data Analysts who work for the above companies, what exactly do you do in your day to day job. \n\nHow often do you use SQL, Python, visualization tools etc? \n\nHow do often do you talk with colleagues from different departments and upper management.", "author_fullname": "t2_5hcl0uoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists and Data Analysts that work for shipping companies or transportation companies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162jmi9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693120879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Scientists or Data Analysts that work for shipping companies/ transportation companies. &lt;/p&gt;\n\n&lt;p&gt;I know it&amp;#39;s weirdly specific but I just want to ask. &lt;/p&gt;\n\n&lt;p&gt;For Data Scientists and Data Analysts who work for the above companies, what exactly do you do in your day to day job. &lt;/p&gt;\n\n&lt;p&gt;How often do you use SQL, Python, visualization tools etc? &lt;/p&gt;\n\n&lt;p&gt;How do often do you talk with colleagues from different departments and upper management.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162jmi9", "is_robot_indexable": true, "report_reasons": null, "author": "Large-Relationship37", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162jmi9/data_scientists_and_data_analysts_that_work_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162jmi9/data_scientists_and_data_analysts_that_work_for/", "subreddit_subscribers": 1017190, "created_utc": 1693120879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have 8500 unique pairs of city and state. I'd like to get their latitude and longitude. I tried using Nominatim as the geocoder, but hit a rate limit at 1000. Could you please suggest a free solution for bulk geocoding? My code so far:\n\n    import pandas as pd\n    from geopy.geocoders import Nominatim\n    \n    geolocator = Nominatim(user_agent=\"my_geocoder\")\n    \n    df = pd.read_csv(r'unique-locations.csv')\n    \n    df['latitude'] = None\n    df['longitude'] = None\n    \n    # Iterate through the DataFrame\n    for index, row in df.iterrows():\n        location = geolocator.geocode(f\"{row['LocationCity']}, {row['LocationState']}\")\n        \n        if location:\n            df.at[index, 'latitude'] = location.latitude\n            df.at[index, 'longitude'] = location.longitude\n\n&amp;#x200B;", "author_fullname": "t2_rvu8sqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestion for a geocoder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_162ymlr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693162407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 8500 unique pairs of city and state. I&amp;#39;d like to get their latitude and longitude. I tried using Nominatim as the geocoder, but hit a rate limit at 1000. Could you please suggest a free solution for bulk geocoding? My code so far:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pandas as pd\nfrom geopy.geocoders import Nominatim\n\ngeolocator = Nominatim(user_agent=&amp;quot;my_geocoder&amp;quot;)\n\ndf = pd.read_csv(r&amp;#39;unique-locations.csv&amp;#39;)\n\ndf[&amp;#39;latitude&amp;#39;] = None\ndf[&amp;#39;longitude&amp;#39;] = None\n\n# Iterate through the DataFrame\nfor index, row in df.iterrows():\n    location = geolocator.geocode(f&amp;quot;{row[&amp;#39;LocationCity&amp;#39;]}, {row[&amp;#39;LocationState&amp;#39;]}&amp;quot;)\n\n    if location:\n        df.at[index, &amp;#39;latitude&amp;#39;] = location.latitude\n        df.at[index, &amp;#39;longitude&amp;#39;] = location.longitude\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162ymlr", "is_robot_indexable": true, "report_reasons": null, "author": "babysharkdoodoodoo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162ymlr/suggestion_for_a_geocoder/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162ymlr/suggestion_for_a_geocoder/", "subreddit_subscribers": 1017190, "created_utc": 1693162407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am going to start an internship as a Data scientist/ML Engineer at a Solar Tech company. They mainly need me to add intelligence to their platform. These are the topics I figured would be relevant:  \n\n\nEnergy Consumption Forecasting, Optimizing Energy Distribution, Automated Anomaly Detection, Data Visualization and Dashboarding, Customer Segmentation, personalized recommendations to customers based on their usage patterns and preferences, and Solar Irradiance Forecasting.  \n\n\nI need some brushing up on the concepts and I am a little lost on what exactly I must brush up on. I know I will be heavily using Time series modeling for forecasting/prediction. What should i be focusing on revising? Should I also revise data engineering and MLOPs?  \n\n\nI would like a detailed list of what I need to go over.  \nThank you for the help!", "author_fullname": "t2_6it7lz4m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Application of DS/ML/DL in Solar energy sector?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_162xhmk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693159662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am going to start an internship as a Data scientist/ML Engineer at a Solar Tech company. They mainly need me to add intelligence to their platform. These are the topics I figured would be relevant:  &lt;/p&gt;\n\n&lt;p&gt;Energy Consumption Forecasting, Optimizing Energy Distribution, Automated Anomaly Detection, Data Visualization and Dashboarding, Customer Segmentation, personalized recommendations to customers based on their usage patterns and preferences, and Solar Irradiance Forecasting.  &lt;/p&gt;\n\n&lt;p&gt;I need some brushing up on the concepts and I am a little lost on what exactly I must brush up on. I know I will be heavily using Time series modeling for forecasting/prediction. What should i be focusing on revising? Should I also revise data engineering and MLOPs?  &lt;/p&gt;\n\n&lt;p&gt;I would like a detailed list of what I need to go over.&lt;br/&gt;\nThank you for the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162xhmk", "is_robot_indexable": true, "report_reasons": null, "author": "Professional_Bunch69", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162xhmk/application_of_dsmldl_in_solar_energy_sector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162xhmk/application_of_dsmldl_in_solar_energy_sector/", "subreddit_subscribers": 1017190, "created_utc": 1693159662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm given two dictionaries:  \n1. {'FirstName LastName': a facenet vector}. Any two vectors here which are close to each other in Euclidean distance are faces which resemble each other.  \n2. {'FirstName LastName 0-9': a vector of size 200} .\n\nI would like to find the \"correlation/connection\" between vectors from the second dictionary and facenet vectors but I struggle to find a good model which doesn't overfit.  Which model would you pick? \n\n(So far I tried Random Forest and some sorts of svm (with distances based on the distances between facenet vectors), both overfitting)", "author_fullname": "t2_t6tuznl6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Correlation between human properties", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162vvuh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693155929.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m given two dictionaries:&lt;br/&gt;\n1. {&amp;#39;FirstName LastName&amp;#39;: a facenet vector}. Any two vectors here which are close to each other in Euclidean distance are faces which resemble each other.&lt;br/&gt;\n2. {&amp;#39;FirstName LastName 0-9&amp;#39;: a vector of size 200} .&lt;/p&gt;\n\n&lt;p&gt;I would like to find the &amp;quot;correlation/connection&amp;quot; between vectors from the second dictionary and facenet vectors but I struggle to find a good model which doesn&amp;#39;t overfit.  Which model would you pick? &lt;/p&gt;\n\n&lt;p&gt;(So far I tried Random Forest and some sorts of svm (with distances based on the distances between facenet vectors), both overfitting)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162vvuh", "is_robot_indexable": true, "report_reasons": null, "author": "Inevitable-Sea-658", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162vvuh/correlation_between_human_properties/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162vvuh/correlation_between_human_properties/", "subreddit_subscribers": 1017190, "created_utc": 1693155929.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys\n\n* Before the Elon era of Twitter(X) I was running some large twitter scrapes grabbing 1000's of tweets per every X hours and doing some cool trend analysis on topics over a time series with that.\n* Since Elon era and the lockdown of scrapers and additional volume limitations through the API's I've had to drastically reduce the volume of data I obtain.\n* Because this is time series data and not wanting to waste the previous large sets of data I collected I want to combine the 2020-2022 data I collected and tack it onto the 2023 'Elon era' reduced data I now collect.\n\n**Problem**: If I just bolt the two sets together I'll it'll show massive volumes over the 2020-2022 periods then massively reduced volumes on the data sets when you reach 2023\n\n* Because I present this data in charted format with time series running left to right over the X axis it'll look like to the end user \"Lots of volume then not a lot of volume.\"\n* Is there a known technique or method for being able to 'normalize' this pre Elon era data which will help me in bringing the two sets together without the volume disparity affecting too much the end user perception of said data? Volume is as important as the time format in analysing this data.\n\nI'm completely self taught on data aspects so no doubt have some severe gaps in my fundamental knowledge on this type of thing so your insight is valuable and appreciated.\n\nThanks in advance.", "author_fullname": "t2_6mnzdcoh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to combine two data sets with big disparities in volume?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162l97a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693140282.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693126713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Before the Elon era of Twitter(X) I was running some large twitter scrapes grabbing 1000&amp;#39;s of tweets per every X hours and doing some cool trend analysis on topics over a time series with that.&lt;/li&gt;\n&lt;li&gt;Since Elon era and the lockdown of scrapers and additional volume limitations through the API&amp;#39;s I&amp;#39;ve had to drastically reduce the volume of data I obtain.&lt;/li&gt;\n&lt;li&gt;Because this is time series data and not wanting to waste the previous large sets of data I collected I want to combine the 2020-2022 data I collected and tack it onto the 2023 &amp;#39;Elon era&amp;#39; reduced data I now collect.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: If I just bolt the two sets together I&amp;#39;ll it&amp;#39;ll show massive volumes over the 2020-2022 periods then massively reduced volumes on the data sets when you reach 2023&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Because I present this data in charted format with time series running left to right over the X axis it&amp;#39;ll look like to the end user &amp;quot;Lots of volume then not a lot of volume.&amp;quot;&lt;/li&gt;\n&lt;li&gt;Is there a known technique or method for being able to &amp;#39;normalize&amp;#39; this pre Elon era data which will help me in bringing the two sets together without the volume disparity affecting too much the end user perception of said data? Volume is as important as the time format in analysing this data.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m completely self taught on data aspects so no doubt have some severe gaps in my fundamental knowledge on this type of thing so your insight is valuable and appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162l97a", "is_robot_indexable": true, "report_reasons": null, "author": "_DESTRUCTION", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162l97a/how_to_combine_two_data_sets_with_big_disparities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162l97a/how_to_combine_two_data_sets_with_big_disparities/", "subreddit_subscribers": 1017190, "created_utc": 1693126713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data analysis: DAX vs Python (pandas,numby,mathplotlib)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162dlpb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_qdgsb1r1", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "learnpython", "selftext": "Hi! \nI\u2019m recently learning and introducing into data analysis. I\u2019m actually practicing DAX expressions with my data. I\u2019m mainly using power query in excel for ETL process and then aggregations and iterating functions combining filter context with some basic expressions (CALCULATE, FILTER) in power pivot for excel. However now I\u2019m learning python basics and I\u2019d realized coding using python with some libraries (pandas, numbys, mathplotlib) could do the same or better job, besides the fact that also python allows automate some tasks. I\u2019m working with health data getting info from CSV files. The question is: should I move into python using some libs for data analysis or should I get deep into DAX and power query (M)?", "author_fullname": "t2_qdgsb1r1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data analysis: DAX vs Python (pandas,numby,mathplotlib)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learnpython", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162crnz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693099339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnpython", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! \nI\u2019m recently learning and introducing into data analysis. I\u2019m actually practicing DAX expressions with my data. I\u2019m mainly using power query in excel for ETL process and then aggregations and iterating functions combining filter context with some basic expressions (CALCULATE, FILTER) in power pivot for excel. However now I\u2019m learning python basics and I\u2019d realized coding using python with some libraries (pandas, numbys, mathplotlib) could do the same or better job, besides the fact that also python allows automate some tasks. I\u2019m working with health data getting info from CSV files. The question is: should I move into python using some libs for data analysis or should I get deep into DAX and power query (M)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8ot", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162crnz", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate_Sea_3254", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learnpython/comments/162crnz/data_analysis_dax_vs_python_pandasnumbymathplotlib/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/learnpython/comments/162crnz/data_analysis_dax_vs_python_pandasnumbymathplotlib/", "subreddit_subscribers": 737008, "created_utc": 1693099339.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1693101779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnpython", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/learnpython/comments/162crnz/data_analysis_dax_vs_python_pandasnumbymathplotlib/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162dlpb", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate_Sea_3254", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_162crnz", "author_flair_text_color": null, "permalink": "/r/datascience/comments/162dlpb/data_analysis_dax_vs_python_pandasnumbymathplotlib/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/learnpython/comments/162crnz/data_analysis_dax_vs_python_pandasnumbymathplotlib/", "subreddit_subscribers": 1017190, "created_utc": 1693101779.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello NLP practitioners,\n\nI am looking to build a simple chatbot which will serve a purpose of FAQ. The user can ask basic question about my product and the chatbot will provide answers.\n\nMy question is : Is LLM bases chatbot ideal for my use case or would be a case of killing the mosquito with an anvil?\n\nI am also concerned with 'model hallucination'. Will LLM based chatbot hallucinate and give the users wrong answers?\n\nWhat are my options? Go with a simple chatbot powered by transformer like BERT or Build a chatbot with LLM? \n\n&amp;#x200B;", "author_fullname": "t2_1umdosna", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is LLM based chatbot ideal when the goal is to provide facts to the users ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_162y91y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693161418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello NLP practitioners,&lt;/p&gt;\n\n&lt;p&gt;I am looking to build a simple chatbot which will serve a purpose of FAQ. The user can ask basic question about my product and the chatbot will provide answers.&lt;/p&gt;\n\n&lt;p&gt;My question is : Is LLM bases chatbot ideal for my use case or would be a case of killing the mosquito with an anvil?&lt;/p&gt;\n\n&lt;p&gt;I am also concerned with &amp;#39;model hallucination&amp;#39;. Will LLM based chatbot hallucinate and give the users wrong answers?&lt;/p&gt;\n\n&lt;p&gt;What are my options? Go with a simple chatbot powered by transformer like BERT or Build a chatbot with LLM? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162y91y", "is_robot_indexable": true, "report_reasons": null, "author": "venkarafa", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162y91y/is_llm_based_chatbot_ideal_when_the_goal_is_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162y91y/is_llm_based_chatbot_ideal_when_the_goal_is_to/", "subreddit_subscribers": 1017190, "created_utc": 1693161418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently, I am a software developer with both a Python and java background. Being highly interested in data science, I learned and built some projects, and I would like to switch to the data science field. I would like to create a convincing portfolio for the hiring team. \n\n&amp;#x200B;\n\nWhat is the best way to manage your personal data science projects as your portfolio?  \nI have some options in mind. Please let me know which one I should follow.\n\n&amp;#x200B;\n\n[View Poll](https://www.reddit.com/poll/162ruw9)", "author_fullname": "t2_5lfak2y6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162ruw9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693146514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently, I am a software developer with both a Python and java background. Being highly interested in data science, I learned and built some projects, and I would like to switch to the data science field. I would like to create a convincing portfolio for the hiring team. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What is the best way to manage your personal data science projects as your portfolio?&lt;br/&gt;\nI have some options in mind. Please let me know which one I should follow.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/162ruw9\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "162ruw9", "is_robot_indexable": true, "report_reasons": null, "author": "GJaggerjack", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1693405714912, "options": [{"text": "Creating all the projects in a single repository of github", "id": "24520901"}, {"text": "Creating projects in a individual repository (for each project) in github", "id": "24520902"}, {"text": "Creating projects in kaggle", "id": "24520903"}, {"text": "Creating projects in project of github", "id": "24520904"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 96, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162ruw9/data_science_portfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/162ruw9/data_science_portfolio/", "subreddit_subscribers": 1017190, "created_utc": 1693146514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! We are a group of 4th year students from Singapore Management University, majoring in Information Systems. We are collecting survey responses as part of our final year project, which aims to investigate a child's influence on their parents' diet choices. Ultimately, we wish to leverage these insights to suggest ways to better promote healthy eating within families l.\n\nThe survey should take less than 15 minutes and we would greatly appreciate your responses. \n\nBelow is the link for your reference: https://smusg.asia.qualtrics.com/jfe/form/SV_bEnU3Ffvy74k0ey", "author_fullname": "t2_6ei5kt8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Health Analytics Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162l0dl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693125823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! We are a group of 4th year students from Singapore Management University, majoring in Information Systems. We are collecting survey responses as part of our final year project, which aims to investigate a child&amp;#39;s influence on their parents&amp;#39; diet choices. Ultimately, we wish to leverage these insights to suggest ways to better promote healthy eating within families l.&lt;/p&gt;\n\n&lt;p&gt;The survey should take less than 15 minutes and we would greatly appreciate your responses. &lt;/p&gt;\n\n&lt;p&gt;Below is the link for your reference: &lt;a href=\"https://smusg.asia.qualtrics.com/jfe/form/SV_bEnU3Ffvy74k0ey\"&gt;https://smusg.asia.qualtrics.com/jfe/form/SV_bEnU3Ffvy74k0ey&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162l0dl", "is_robot_indexable": true, "report_reasons": null, "author": "jinnnramen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162l0dl/health_analytics_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162l0dl/health_analytics_project/", "subreddit_subscribers": 1017190, "created_utc": 1693125823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI have PDFs consisting of images of forms. I want to apply OCR and OMR on this images to extract the required data. I want to detect ticked checkboxes and extract the associated data to those checkboxes from these images. However, the current code is not able to detect the contours of the ticked checkbox.\n\nI am using `findcontours` to find contours and make bounding boxes around the checkboxes. This code is inspired from this [post](https://stackoverflow.com/questions/55763858/how-to-detect-and-find-checkboxes-in-a-form-using-python-opencv).  However, it is not able to detect the contours of the checkbox that is ticked. Here is the code and the image of the area in the form where I am applying the code. \n\n&amp;#x200B;\n\n[ Image of the region of the form with checkboxes and associated data ](https://preview.redd.it/zezn47w91jkb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=70c517e0eb2b745b711639cfe3f4ff5ecd621232)\n\n    gray = x_gray.copy() # Copy of the Grayscale image shared in this post \n    blur = cv2.GaussianBlur(gray, (3,3), 0)\n    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n    \n    # Find contours and filter using contour area filtering to remove noise\n    cnts, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n    AREA_THRESHOLD = 100\n    for c in cnts:\n        area = cv2.contourArea(c)\n        if area &lt; AREA_THRESHOLD:\n            cv2.drawContours(thresh, [c], -1, 0, -1)\n    \n    # Repair checkbox horizontal and vertical walls\n    repair_kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,1))\n    repair = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, repair_kernel1, iterations=1)\n    repair_kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (1,5))\n    repair = cv2.morphologyEx(repair, cv2.MORPH_CLOSE, repair_kernel2, iterations=1)\n    \n    # Detect checkboxes using shape approximation and aspect ratio filtering\n    checkbox_contours = []\n    cnts, _ = cv2.findContours(repair, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n    for c in cnts:\n        peri = cv2.arcLength(c, True)\n        approx = cv2.approxPolyDP(c, 0.035 * peri, True)\n        x,y,w,h = cv2.boundingRect(approx)\n        aspect_ratio = w / float(h)\n        if len(approx) == 4 and (aspect_ratio &gt;= 0.8 and aspect_ratio &lt;= 1.2):\n            cv2.rectangle(gray, (x, y), (x + w, y + h), (36,255,12), 3) #original\n            checkbox_contours.append(c)\n    \n    print('Checkboxes:', len(checkbox_contours))\n\n \n\nI have tried various values of the parameter `AREA_THRESHOLD` ranging from 10 - 200. However, I'm still not getting the expected result.\n\nIt would be really helpful if someone can help me with this problem.", "author_fullname": "t2_sq7rhmzy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to detect a ticked checkbox and extract the text associated to it from an image?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zezn47w91jkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=df46dbcacbb87736e528e3dbdb6bfc5d126d1c45"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4fe58afaa4c9ced4c55e60006eb8e18735452685"}, {"y": 116, "x": 320, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=818915627b0f8ac9a8fb9555c551e88184ff0b22"}, {"y": 233, "x": 640, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=281c44cb846692a1c020de84103ddf2d61f1307b"}, {"y": 350, "x": 960, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=02248f63cbadf1b53ccced790e40fc7722c222ed"}, {"y": 394, "x": 1080, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d56060f6f2a87097038599f429ce9c5465792c64"}], "s": {"y": 565, "x": 1546, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=70c517e0eb2b745b711639cfe3f4ff5ecd621232"}, "id": "zezn47w91jkb1"}}, "name": "t3_16283ok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BR9NB6Fvr_8UUHe0n9NcXWLt2z0-vaZBHk3y27t0Vmo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693087298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have PDFs consisting of images of forms. I want to apply OCR and OMR on this images to extract the required data. I want to detect ticked checkboxes and extract the associated data to those checkboxes from these images. However, the current code is not able to detect the contours of the ticked checkbox.&lt;/p&gt;\n\n&lt;p&gt;I am using &lt;code&gt;findcontours&lt;/code&gt; to find contours and make bounding boxes around the checkboxes. This code is inspired from this &lt;a href=\"https://stackoverflow.com/questions/55763858/how-to-detect-and-find-checkboxes-in-a-form-using-python-opencv\"&gt;post&lt;/a&gt;.  However, it is not able to detect the contours of the checkbox that is ticked. Here is the code and the image of the area in the form where I am applying the code. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zezn47w91jkb1.png?width=1546&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=70c517e0eb2b745b711639cfe3f4ff5ecd621232\"&gt; Image of the region of the form with checkboxes and associated data &lt;/a&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;gray = x_gray.copy() # Copy of the Grayscale image shared in this post \nblur = cv2.GaussianBlur(gray, (3,3), 0)\nthresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n\n# Find contours and filter using contour area filtering to remove noise\ncnts, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\nAREA_THRESHOLD = 100\nfor c in cnts:\n    area = cv2.contourArea(c)\n    if area &amp;lt; AREA_THRESHOLD:\n        cv2.drawContours(thresh, [c], -1, 0, -1)\n\n# Repair checkbox horizontal and vertical walls\nrepair_kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,1))\nrepair = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, repair_kernel1, iterations=1)\nrepair_kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (1,5))\nrepair = cv2.morphologyEx(repair, cv2.MORPH_CLOSE, repair_kernel2, iterations=1)\n\n# Detect checkboxes using shape approximation and aspect ratio filtering\ncheckbox_contours = []\ncnts, _ = cv2.findContours(repair, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\nfor c in cnts:\n    peri = cv2.arcLength(c, True)\n    approx = cv2.approxPolyDP(c, 0.035 * peri, True)\n    x,y,w,h = cv2.boundingRect(approx)\n    aspect_ratio = w / float(h)\n    if len(approx) == 4 and (aspect_ratio &amp;gt;= 0.8 and aspect_ratio &amp;lt;= 1.2):\n        cv2.rectangle(gray, (x, y), (x + w, y + h), (36,255,12), 3) #original\n        checkbox_contours.append(c)\n\nprint(&amp;#39;Checkboxes:&amp;#39;, len(checkbox_contours))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I have tried various values of the parameter &lt;code&gt;AREA_THRESHOLD&lt;/code&gt; ranging from 10 - 200. However, I&amp;#39;m still not getting the expected result.&lt;/p&gt;\n\n&lt;p&gt;It would be really helpful if someone can help me with this problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16283ok", "is_robot_indexable": true, "report_reasons": null, "author": "yishu17", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16283ok/how_to_detect_a_ticked_checkbox_and_extract_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16283ok/how_to_detect_a_ticked_checkbox_and_extract_the/", "subreddit_subscribers": 1017190, "created_utc": 1693087298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry if this isn\u2019t written particularly well, but currently I\u2019m very overwhelmed with the job search process and need to figure out how to optimize my time. Also I\u2019m probably catastrophizing, but I don\u2019t want to live in my parents\u2019 basement forever.\n\nSo I\u2019ve been looking for work in the US after leaving a position I had in the UK for 1.5 years mostly because I would not be allowed to keep it due to visa restrictions. I\u2019m concerned because I was getting a few calls back for interviews in the 2 months I was actively looking for work in the UK but I\u2019ve gotten complete silence since I\u2019ve moved back. This is especially bad because I\u2019m a US citizen so things should be easier for me here than they were there.\n\nI\u2019m concerned that my old job isn\u2019t doing me any favors in terms of experience because while my job title was \u201cData Scientist,\u201d I did very little in terms of actual analysis and absolutely no machine learning. I was mostly helping maintain and build data applications to host on AWS, but i don\u2019t think we did much in terms of ETL to the quality most companies who want a Data Engineer would want.\n\nI think my best bet at this point is to learn Power BI and Tableau to get an analyst position, but again, I never did any analysis in my previous position and I think I\u2019d lose to anybody who has actual work experience with these things. I have some projects from my master\u2019s program that plug some of the holes but in my hubris, I didn\u2019t manage to create anything new for the portfolio while I still had a job. I have several web tools that I managed to get working on GCP (just barely) but I can\u2019t get working anymore without refactoring a ton of stuff. Which is a problem because I need to decide if it\u2019s worth redeploying everything at all.\n\nI also also don\u2019t know how to explain the ever increasing gap in my employment. Do I just need to get on Fivver and start selling some cheap data analysis service there just to prove I\u2019m doing something productive? What if I mess up handling my customers and my ratings suffer so I can\u2019t put that work on my resume? I could also take some part time work tutoring again but wouldn\u2019t that make me look bad anyways because it\u2019s a step back?", "author_fullname": "t2_3o4ak2xl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wondering if my experience is inadequate for US job market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1624yex", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693079851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this isn\u2019t written particularly well, but currently I\u2019m very overwhelmed with the job search process and need to figure out how to optimize my time. Also I\u2019m probably catastrophizing, but I don\u2019t want to live in my parents\u2019 basement forever.&lt;/p&gt;\n\n&lt;p&gt;So I\u2019ve been looking for work in the US after leaving a position I had in the UK for 1.5 years mostly because I would not be allowed to keep it due to visa restrictions. I\u2019m concerned because I was getting a few calls back for interviews in the 2 months I was actively looking for work in the UK but I\u2019ve gotten complete silence since I\u2019ve moved back. This is especially bad because I\u2019m a US citizen so things should be easier for me here than they were there.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m concerned that my old job isn\u2019t doing me any favors in terms of experience because while my job title was \u201cData Scientist,\u201d I did very little in terms of actual analysis and absolutely no machine learning. I was mostly helping maintain and build data applications to host on AWS, but i don\u2019t think we did much in terms of ETL to the quality most companies who want a Data Engineer would want.&lt;/p&gt;\n\n&lt;p&gt;I think my best bet at this point is to learn Power BI and Tableau to get an analyst position, but again, I never did any analysis in my previous position and I think I\u2019d lose to anybody who has actual work experience with these things. I have some projects from my master\u2019s program that plug some of the holes but in my hubris, I didn\u2019t manage to create anything new for the portfolio while I still had a job. I have several web tools that I managed to get working on GCP (just barely) but I can\u2019t get working anymore without refactoring a ton of stuff. Which is a problem because I need to decide if it\u2019s worth redeploying everything at all.&lt;/p&gt;\n\n&lt;p&gt;I also also don\u2019t know how to explain the ever increasing gap in my employment. Do I just need to get on Fivver and start selling some cheap data analysis service there just to prove I\u2019m doing something productive? What if I mess up handling my customers and my ratings suffer so I can\u2019t put that work on my resume? I could also take some part time work tutoring again but wouldn\u2019t that make me look bad anyways because it\u2019s a step back?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1624yex", "is_robot_indexable": true, "report_reasons": null, "author": "GGPiggie", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1624yex/wondering_if_my_experience_is_inadequate_for_us/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1624yex/wondering_if_my_experience_is_inadequate_for_us/", "subreddit_subscribers": 1017190, "created_utc": 1693079851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am making a simple temperature model(for school assignment) and I collected some data from 1880 to 2016.\nI want to do forecasting after 2016 using ewma\nI am using google colab now.", "author_fullname": "t2_e3ef0gg3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to do forecasting using EWMA?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162vyll", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693156113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am making a simple temperature model(for school assignment) and I collected some data from 1880 to 2016.\nI want to do forecasting after 2016 using ewma\nI am using google colab now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162vyll", "is_robot_indexable": true, "report_reasons": null, "author": "PAKALOVER", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162vyll/how_to_do_forecasting_using_ewma/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162vyll/how_to_do_forecasting_using_ewma/", "subreddit_subscribers": 1017190, "created_utc": 1693156113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\n\nI work on a couple different r studio projects and was wondering if there was any possibility that I can for example get some work done, then when I\u2019m done save it so it gets uploaded to a one drive account that I can access from a different computer later on. I work personally on a mac but need to access it when I\u2019m out from home etc\u2026", "author_fullname": "t2_645b9mvb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File upload", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162mnw8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693131597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I work on a couple different r studio projects and was wondering if there was any possibility that I can for example get some work done, then when I\u2019m done save it so it gets uploaded to a one drive account that I can access from a different computer later on. I work personally on a mac but need to access it when I\u2019m out from home etc\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162mnw8", "is_robot_indexable": true, "report_reasons": null, "author": "jjnaude219", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162mnw8/file_upload/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162mnw8/file_upload/", "subreddit_subscribers": 1017190, "created_utc": 1693131597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I think the question says it all. I am considering doing masters in data science in uk and wondering what are the job opportunities there like after the degree. How easy it is to land a job in data science as a fresher being an international student and is it even possible?", "author_fullname": "t2_f31m67lx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How easy is to land a job in data science get a job as a fresher in the uk being an international student?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1626t17", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693084255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think the question says it all. I am considering doing masters in data science in uk and wondering what are the job opportunities there like after the degree. How easy it is to land a job in data science as a fresher being an international student and is it even possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1626t17", "is_robot_indexable": true, "report_reasons": null, "author": "ProfessionalOne272", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1626t17/how_easy_is_to_land_a_job_in_data_science_get_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1626t17/how_easy_is_to_land_a_job_in_data_science_get_a/", "subreddit_subscribers": 1017190, "created_utc": 1693084255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "https://youtube.com/shorts/rLoecC__oL4?si=aaiCATF2VQVdRuUs\n\nAnd here\n\nhttps://youtu.be/DHlkr2C03x4?si=deLRkY9W-OufIfFJ", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientists gets owned", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_162h6r1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.09, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693112475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://youtube.com/shorts/rLoecC__oL4?si=aaiCATF2VQVdRuUs\"&gt;https://youtube.com/shorts/rLoecC__oL4?si=aaiCATF2VQVdRuUs&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And here&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/DHlkr2C03x4?si=deLRkY9W-OufIfFJ\"&gt;https://youtu.be/DHlkr2C03x4?si=deLRkY9W-OufIfFJ&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bqCWyZKKhhn7NKMexZq-AuTMD7rQGm-u53AaKu10-XE.jpg?auto=webp&amp;s=a1d9f6f14b3e1fea341e37a8077ae4a3fd0ccb35", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/bqCWyZKKhhn7NKMexZq-AuTMD7rQGm-u53AaKu10-XE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1ee275129b61fbeeece375492317f7f88bafedc", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/bqCWyZKKhhn7NKMexZq-AuTMD7rQGm-u53AaKu10-XE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=898ed17be0555e1fa70f9acebdd55f334f9ff20c", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/bqCWyZKKhhn7NKMexZq-AuTMD7rQGm-u53AaKu10-XE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3ad14cfb125be27356e3857a0f81c2f3f13c1583", "width": 320, "height": 240}], "variants": {}, "id": "L9hulc6L93EFaXv2ZzFFjd7ALeZvginnXCPQ7uHq2uc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "162h6r1", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/162h6r1/data_scientists_gets_owned/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/162h6r1/data_scientists_gets_owned/", "subreddit_subscribers": 1017190, "created_utc": 1693112475.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}