{"kind": "Listing", "data": {"after": "t3_15yv5sb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just reflecting on my career and how fortunate I feel to have found something I really enjoy doing. \n\nI just think data is so important to civilization, and being able to build proper data pipelines, scalable infrastructure, and accessible data warehousing feels like my calling. \n\nGranted I\u2019ve only been doing this for 5 years, and obviously some days it just feels like work. Anyone feel the same or feel differently?", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you truly enjoy data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yz47k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 66, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 66, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692784162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just reflecting on my career and how fortunate I feel to have found something I really enjoy doing. &lt;/p&gt;\n\n&lt;p&gt;I just think data is so important to civilization, and being able to build proper data pipelines, scalable infrastructure, and accessible data warehousing feels like my calling. &lt;/p&gt;\n\n&lt;p&gt;Granted I\u2019ve only been doing this for 5 years, and obviously some days it just feels like work. Anyone feel the same or feel differently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15yz47k", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 70, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15yz47k/do_you_truly_enjoy_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yz47k/do_you_truly_enjoy_data_engineering/", "subreddit_subscribers": 124444, "created_utc": 1692784162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been hearing about a growing trend of professionals transitioning from machine learning roles to data engineering. If you're one of them, I'd love to hear your story. What motivated your shift? Was it the nature of the work, the tools, the opportunities, or something else? Sharing your experiences might shed light for others considering a similar transition.", "author_fullname": "t2_92gz2jax", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switching from Machine Learning to Data Engineering: What Sparked Your Change?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yv4bt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692771043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been hearing about a growing trend of professionals transitioning from machine learning roles to data engineering. If you&amp;#39;re one of them, I&amp;#39;d love to hear your story. What motivated your shift? Was it the nature of the work, the tools, the opportunities, or something else? Sharing your experiences might shed light for others considering a similar transition.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yv4bt", "is_robot_indexable": true, "report_reasons": null, "author": "lbluestone", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yv4bt/switching_from_machine_learning_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yv4bt/switching_from_machine_learning_to_data/", "subreddit_subscribers": 124444, "created_utc": 1692771043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious if anyone's had data engineering experience at bloomberg or similar. I'm debating taking an offer from bloomberg (UK) for a data engineer position, while currently working in fintech also as a data engineer.\n\nMy main concerns from having asked questions in the interview process is that the tech is very abstracted, high level, config based tools to build workflows and pipelines. I.e. I would not learn or touch any infra, cloud, spark. So basically just SQL, Python and bloomberg tools. Some tools (airflow, jenkins, kafka) are basically open source equivalents or actual open source tools with a bloomberg wrapper built by their software engineers, which is not as bad I guess.\n\nMy current position is kind of the opposite, a modern open source tech stack with Scala, spark, airflow, GCP, k8s, jenkins, terraform.\n\nCompanies these days seem so fixated on engineers having specific experience in X,Y,Z. I've even been rejected before because I didn't have serverless AWS experience. Are my concerns of using prop tech and lack of spark/cloud/infra valid or would it not matter when I eventually try move from bloomberg elsewhere? Is it a good name to have on the CV?", "author_fullname": "t2_642rl59c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering at Bloomberg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z7eva", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692805178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious if anyone&amp;#39;s had data engineering experience at bloomberg or similar. I&amp;#39;m debating taking an offer from bloomberg (UK) for a data engineer position, while currently working in fintech also as a data engineer.&lt;/p&gt;\n\n&lt;p&gt;My main concerns from having asked questions in the interview process is that the tech is very abstracted, high level, config based tools to build workflows and pipelines. I.e. I would not learn or touch any infra, cloud, spark. So basically just SQL, Python and bloomberg tools. Some tools (airflow, jenkins, kafka) are basically open source equivalents or actual open source tools with a bloomberg wrapper built by their software engineers, which is not as bad I guess.&lt;/p&gt;\n\n&lt;p&gt;My current position is kind of the opposite, a modern open source tech stack with Scala, spark, airflow, GCP, k8s, jenkins, terraform.&lt;/p&gt;\n\n&lt;p&gt;Companies these days seem so fixated on engineers having specific experience in X,Y,Z. I&amp;#39;ve even been rejected before because I didn&amp;#39;t have serverless AWS experience. Are my concerns of using prop tech and lack of spark/cloud/infra valid or would it not matter when I eventually try move from bloomberg elsewhere? Is it a good name to have on the CV?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15z7eva", "is_robot_indexable": true, "report_reasons": null, "author": "SentinelReborn", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z7eva/data_engineering_at_bloomberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z7eva/data_engineering_at_bloomberg/", "subreddit_subscribers": 124444, "created_utc": 1692805178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My colleague just wrote up an article on [LLM-based apps and how to use data engineering tools to help build them faster](https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/) that I found really insightful.\n\nIt contains a complete implementation\n\n* with scraping context data from a docs website\n* chunking it, getting embeddings via the openAI API\n* loading it into pinecone\n* and finally a simple Q&amp;A interface with streamlit on top of it\n\n**Here's a quick summary:**\n\n* LangChain and LlamaIndex are great tools for quick exploration\n* But aren't perfect for production-grade use\n* I think we all know the \"LangChain is pointless\" debate, but there's a lot of real meat to it, and Pat describes a few of them (a lot of LangChains extractors are super basic, 2-3 liners without retries etc.)\n* LLM applications are all about moving data, extracting and enriching data (creating embeddings!) are the most expensive ones of those steps\n* A bunch of data engineering tools are out there that make these two steps much easier, versionable, robust, and reproducible.\n* Meltano is one such tool and Pat implemented the above described pipeline with it\n\n**FWIW**: The GitHub project that comes with the post is super easy to run and super modular. I just tested it and was able to modify everything for my own application within 30 mins.", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LLM Apps Are Mostly Data Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z0ogw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692788855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My colleague just wrote up an article on &lt;a href=\"https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/\"&gt;LLM-based apps and how to use data engineering tools to help build them faster&lt;/a&gt; that I found really insightful.&lt;/p&gt;\n\n&lt;p&gt;It contains a complete implementation&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;with scraping context data from a docs website&lt;/li&gt;\n&lt;li&gt;chunking it, getting embeddings via the openAI API&lt;/li&gt;\n&lt;li&gt;loading it into pinecone&lt;/li&gt;\n&lt;li&gt;and finally a simple Q&amp;amp;A interface with streamlit on top of it&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Here&amp;#39;s a quick summary:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;LangChain and LlamaIndex are great tools for quick exploration&lt;/li&gt;\n&lt;li&gt;But aren&amp;#39;t perfect for production-grade use&lt;/li&gt;\n&lt;li&gt;I think we all know the &amp;quot;LangChain is pointless&amp;quot; debate, but there&amp;#39;s a lot of real meat to it, and Pat describes a few of them (a lot of LangChains extractors are super basic, 2-3 liners without retries etc.)&lt;/li&gt;\n&lt;li&gt;LLM applications are all about moving data, extracting and enriching data (creating embeddings!) are the most expensive ones of those steps&lt;/li&gt;\n&lt;li&gt;A bunch of data engineering tools are out there that make these two steps much easier, versionable, robust, and reproducible.&lt;/li&gt;\n&lt;li&gt;Meltano is one such tool and Pat implemented the above described pipeline with it&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;FWIW&lt;/strong&gt;: The GitHub project that comes with the post is super easy to run and super modular. I just tested it and was able to modify everything for my own application within 30 mins.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?auto=webp&amp;s=fc02ae969049700f816ec5973f65423a7d1d1ea7", "width": 2048, "height": 1365}, "resolutions": [{"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75fad2ff68a9a259f10874b9ae14b106c3dc10b0", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5bb8ed0d61a745ffba2145a2afd59060329df23b", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31f092f9ea961fca60f2bd41b3b2bca128f1b764", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7ea9c1fd2a442e2f882a977c349e052dd38e3d8a", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f7f9cbdb42b35eddc88336a41397ff952ff455c2", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=646b4a3168958ec2520a6910a70d921e302e3d03", "width": 1080, "height": 719}], "variants": {}, "id": "E08iLDz2f8z0dIDW6N3H1Mna-8Iqh0WwcWMLsrVaqWo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15z0ogw", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z0ogw/llm_apps_are_mostly_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z0ogw/llm_apps_are_mostly_data_pipelines/", "subreddit_subscribers": 124444, "created_utc": 1692788855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, wanted to introduce what we're building at Serra.\n\nWe're a python-based dbt alternative that takes a long-winded SQL script and summarizes its transforms with reusable, testable, scalable Spark objects.\n\nOur goal is to take what dbt did bringing software engineering best practices through jinja templating SQL and give the ability for more complex transforms in Spark. We move from SQL scripts to modular Pyspark transformers and connectors that you then in a configuration YML file.\n\n**(edit: swapped out the bad prior example of mapping but keeping it for the local run example)**\n\n&gt;~~This is our original SQL script in a Snowflake worksheet (only the T). All we're doing is one map transform, swapping out state names for their abbreviations\u2014but it's difficult to parametrize our actual mapping dictionary in pure SQL.~~  \n&gt;  \n&gt;~~Not shown is the extraction/loading process of actually getting the data to our Snowflake warehouse.~~\n\n**New example:** Calculate distance between columns in BigQuery SQL vs Serra\n\n&amp;#x200B;\n\n[BigQuery SQL Script](https://preview.redd.it/xrrqmbe9sxjb1.png?width=1770&amp;format=png&amp;auto=webp&amp;s=de25951567ab43dd54186d87122199428db72c14)\n\n&amp;#x200B;\n\nNot shown is the extraction/loading process of actually getting the data to our BigQuery warehouse.\n\nHere's the equivalent calling a GeoDistanceTransformer object in our framework.\n\n[GeoDistanceTransformer in Serra](https://preview.redd.it/6fy8vmm6sxjb1.png?width=490&amp;format=png&amp;auto=webp&amp;s=6fad365de11548beec305f2f4fb2e191451c8641)\n\nand a look at the actual implementation here:\n\n[GeoDistanceTransformer](https://preview.redd.it/cuurgdxmuxjb1.png?width=1596&amp;format=png&amp;auto=webp&amp;s=f093cfbfbdadd85d7a6c5bcffc578c2512fbd3bd)\n\nThe idea is to abstract away the implementation for these transforms in reusable objects that we can unit test, make more flexible, and implement custom error logging in PySpark vs. SQL.\n\n**YML Example:**\n\n[Serra Equivalent to Snowflake SQL script](https://preview.redd.it/ochbkkc7mwjb1.png?width=1954&amp;format=png&amp;auto=webp&amp;s=c2ca58496e83e3cf237d902f98a7fc0f38cc8877)\n\nWe want to boil down every ETL/LT process to different transform and connect Spark objects, and summarize them neatly in our YML files.\n\nSo, we have a three-step summary in our YML above:\n\n1. A read from S3\n2. Our map transform, where we can supply a dictionary as a json\n3. A write to Snowflake\n\nDevs can write as many custom transformers/loaders as they want, and we also have a catch-22 alternative very similar to a dbt model in our SQLTransformer\u2014if you want to modularize your SQL to call later, but don't want to convert it to our framework, you can pass in your SQL as a string and reference it later on.\n\n&amp;#x200B;\n\nTo run your job, you use our command line to deploy to a cluster of your choice or locally\u2014we want to make it super easy for devs to test their jobs without firing up dev clusters. If you have a job pulling from S3, BigQuery, Snowflake, you can test your job locally with all of these data stores with a subset of the data by doing serra run my\\_job.\n\n[How we run our Serra jobs \\(local testing example\\)](https://i.redd.it/ede40iusnwjb1.gif)\n\n# Benefits\n\n1. **Modularity:** We modularize declarative, hard-to-debug SQL scripts into procedural, intuitive step-by-step workflows. You can see immediately which step your transforms/connects break and why.\n2. **Reusability:** Instead of rewriting the same SQL transforms in a dozen different ways, enforce structure, resilience with set customizable Spark objects.\n3. **Debugging**: Since SQL is declarative, it can be especially hard to debug. By shifting to an object-oriented framework, you can parameterize error logs for each transformer and connector (ie: data frames in question, upstream tables, POC's for these upstream teams, suggestions on how to fix)\n4. **End-to-end**: The YML file is the single source of truth for every job\u2014you can test end-to-end between different data stores, see a high level overview of the transforms you're doing, and run all of these locally before ever getting your pipelines into production.\n\n# Command Line\n\nCreate your ETL pipelines, test them locally with a subset of your data, and deploy them to the cloud (currently we only support Databricks, but will soon support others and plan to host our own clusters too). It also has an experimental \u201ctranslate\u201d feature which is still a bit finicky, but the idea is to take your existing SQL script and get suggestions on how you can chunk up and modularize your job with our config. It\u2019s still just a super early suggestion feature that is definitely not fleshed out, but we think it\u2019s a cool approach.\n\n&amp;#x200B;\n\nThanks for reading all of this! We're still very early on and would love any feedback\u2014we're learning every day. We're open-core (repo is here: [https://github.com/Serra-Technologies/serra](https://github.com/Serra-Technologies/serra))\u2014DMs are open for any and all feedback!", "author_fullname": "t2_8q9g28lz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serra \u2014 Python-based dbt alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ede40iusnwjb1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/ede40iusnwjb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=96171704c069835eef4dafe3280223c3fdc789e3"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/ede40iusnwjb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=94349a0f2c75d43ce767776b5e6564e440c0c1c0"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/ede40iusnwjb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=9b5bf0aeea76c52e527fc15e9f90eff81feeac4d"}], "s": {"y": 338, "gif": "https://i.redd.it/ede40iusnwjb1.gif", "mp4": "https://preview.redd.it/ede40iusnwjb1.gif?format=mp4&amp;s=97404fc3f537d1806c08d0d24e6fa008d7a92844", "x": 600}, "id": "ede40iusnwjb1"}, "xrrqmbe9sxjb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 48, "x": 108, "u": "https://preview.redd.it/xrrqmbe9sxjb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=be9132afdd9a4dac873eadb967f128a6949d297f"}, {"y": 96, "x": 216, "u": "https://preview.redd.it/xrrqmbe9sxjb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f64ce81db74b2ae4928f6d7c7d5bf7b180d478da"}, {"y": 143, "x": 320, "u": "https://preview.redd.it/xrrqmbe9sxjb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dc5d8235f6692a35a879969b38de26f4df64daba"}, {"y": 286, "x": 640, "u": "https://preview.redd.it/xrrqmbe9sxjb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6e0650e41e89de96c8d4be13062764ef37c4c5dc"}, {"y": 429, "x": 960, "u": "https://preview.redd.it/xrrqmbe9sxjb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2346ce0362aec9d223fd12253d68c0258066101d"}, {"y": 483, "x": 1080, "u": "https://preview.redd.it/xrrqmbe9sxjb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=21e703cfa8a37ece8bc7bcf0ee0f4f98bd7d0eff"}], "s": {"y": 792, "x": 1770, "u": "https://preview.redd.it/xrrqmbe9sxjb1.png?width=1770&amp;format=png&amp;auto=webp&amp;s=de25951567ab43dd54186d87122199428db72c14"}, "id": "xrrqmbe9sxjb1"}, "cuurgdxmuxjb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 96, "x": 108, "u": "https://preview.redd.it/cuurgdxmuxjb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=805878abcf1081671f781cf6db314c7518f598a0"}, {"y": 193, "x": 216, "u": "https://preview.redd.it/cuurgdxmuxjb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=16157849761746161d0c873663430f283fc41a20"}, {"y": 286, "x": 320, "u": "https://preview.redd.it/cuurgdxmuxjb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba753f192992fb9c4e9231802b16a97b447adc2e"}, {"y": 573, "x": 640, "u": "https://preview.redd.it/cuurgdxmuxjb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cd82de176e60be319000ab6ffaca3a91445f1ebb"}, {"y": 860, "x": 960, "u": "https://preview.redd.it/cuurgdxmuxjb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3274ce8aa8b46fa4aefca4743b054e9829bb9720"}, {"y": 967, "x": 1080, "u": "https://preview.redd.it/cuurgdxmuxjb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1a84a4e40b4d6742807562a7ce7d0d1d5f56b741"}], "s": {"y": 1430, "x": 1596, "u": "https://preview.redd.it/cuurgdxmuxjb1.png?width=1596&amp;format=png&amp;auto=webp&amp;s=f093cfbfbdadd85d7a6c5bcffc578c2512fbd3bd"}, "id": "cuurgdxmuxjb1"}, "ochbkkc7mwjb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/ochbkkc7mwjb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2a30bc1a5c35288a4c98a3df8675f44b7509d39"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/ochbkkc7mwjb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=428817044f935bc43fb303ab861c869282e7d92a"}, {"y": 195, "x": 320, "u": "https://preview.redd.it/ochbkkc7mwjb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e06bef58a2ee27402aafb7b49fb8b910de29e830"}, {"y": 391, "x": 640, "u": "https://preview.redd.it/ochbkkc7mwjb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1ead8d4d74f90b4a588aeabc3e493b167e4231e0"}, {"y": 587, "x": 960, "u": "https://preview.redd.it/ochbkkc7mwjb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b03ed65765def11fd24675a651acd82d8b7ed757"}, {"y": 661, "x": 1080, "u": "https://preview.redd.it/ochbkkc7mwjb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dab1ff07cf0e89cdca1c11d23bb6d254918603c3"}], "s": {"y": 1196, "x": 1954, "u": "https://preview.redd.it/ochbkkc7mwjb1.png?width=1954&amp;format=png&amp;auto=webp&amp;s=c2ca58496e83e3cf237d902f98a7fc0f38cc8877"}, "id": "ochbkkc7mwjb1"}, "6fy8vmm6sxjb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 59, "x": 108, "u": "https://preview.redd.it/6fy8vmm6sxjb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3404e894a3d7c7baacc015977a1725bf8a5f7451"}, {"y": 119, "x": 216, "u": "https://preview.redd.it/6fy8vmm6sxjb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1a5fb3bc57508d383e5df8a24f507c8240a27557"}, {"y": 176, "x": 320, "u": "https://preview.redd.it/6fy8vmm6sxjb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cca4dcbcb15829c540d35b3d1e98f6e804ac0d60"}], "s": {"y": 270, "x": 490, "u": "https://preview.redd.it/6fy8vmm6sxjb1.png?width=490&amp;format=png&amp;auto=webp&amp;s=6fad365de11548beec305f2f4fb2e191451c8641"}, "id": "6fy8vmm6sxjb1"}}, "name": "t3_15zdm1p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/NUHV6ihrdgP-qduVeqwZDs0_1KkvVTtEROA-kiR5m-4.jpg", "edited": 1692831731.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1692818307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, wanted to introduce what we&amp;#39;re building at Serra.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re a python-based dbt alternative that takes a long-winded SQL script and summarizes its transforms with reusable, testable, scalable Spark objects.&lt;/p&gt;\n\n&lt;p&gt;Our goal is to take what dbt did bringing software engineering best practices through jinja templating SQL and give the ability for more complex transforms in Spark. We move from SQL scripts to modular Pyspark transformers and connectors that you then in a configuration YML file.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;(edit: swapped out the bad prior example of mapping but keeping it for the local run example)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;del&gt;This is our original SQL script in a Snowflake worksheet (only the T). All we&amp;#39;re doing is one map transform, swapping out state names for their abbreviations\u2014but it&amp;#39;s difficult to parametrize our actual mapping dictionary in pure SQL.&lt;/del&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;del&gt;Not shown is the extraction/loading process of actually getting the data to our Snowflake warehouse.&lt;/del&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;New example:&lt;/strong&gt; Calculate distance between columns in BigQuery SQL vs Serra&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xrrqmbe9sxjb1.png?width=1770&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=de25951567ab43dd54186d87122199428db72c14\"&gt;BigQuery SQL Script&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Not shown is the extraction/loading process of actually getting the data to our BigQuery warehouse.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the equivalent calling a GeoDistanceTransformer object in our framework.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/6fy8vmm6sxjb1.png?width=490&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6fad365de11548beec305f2f4fb2e191451c8641\"&gt;GeoDistanceTransformer in Serra&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;and a look at the actual implementation here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cuurgdxmuxjb1.png?width=1596&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f093cfbfbdadd85d7a6c5bcffc578c2512fbd3bd\"&gt;GeoDistanceTransformer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The idea is to abstract away the implementation for these transforms in reusable objects that we can unit test, make more flexible, and implement custom error logging in PySpark vs. SQL.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;YML Example:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ochbkkc7mwjb1.png?width=1954&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c2ca58496e83e3cf237d902f98a7fc0f38cc8877\"&gt;Serra Equivalent to Snowflake SQL script&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We want to boil down every ETL/LT process to different transform and connect Spark objects, and summarize them neatly in our YML files.&lt;/p&gt;\n\n&lt;p&gt;So, we have a three-step summary in our YML above:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;A read from S3&lt;/li&gt;\n&lt;li&gt;Our map transform, where we can supply a dictionary as a json&lt;/li&gt;\n&lt;li&gt;A write to Snowflake&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Devs can write as many custom transformers/loaders as they want, and we also have a catch-22 alternative very similar to a dbt model in our SQLTransformer\u2014if you want to modularize your SQL to call later, but don&amp;#39;t want to convert it to our framework, you can pass in your SQL as a string and reference it later on.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To run your job, you use our command line to deploy to a cluster of your choice or locally\u2014we want to make it super easy for devs to test their jobs without firing up dev clusters. If you have a job pulling from S3, BigQuery, Snowflake, you can test your job locally with all of these data stores with a subset of the data by doing serra run my_job.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/ede40iusnwjb1.gif\"&gt;How we run our Serra jobs (local testing example)&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Benefits&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Modularity:&lt;/strong&gt; We modularize declarative, hard-to-debug SQL scripts into procedural, intuitive step-by-step workflows. You can see immediately which step your transforms/connects break and why.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Reusability:&lt;/strong&gt; Instead of rewriting the same SQL transforms in a dozen different ways, enforce structure, resilience with set customizable Spark objects.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Debugging&lt;/strong&gt;: Since SQL is declarative, it can be especially hard to debug. By shifting to an object-oriented framework, you can parameterize error logs for each transformer and connector (ie: data frames in question, upstream tables, POC&amp;#39;s for these upstream teams, suggestions on how to fix)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;End-to-end&lt;/strong&gt;: The YML file is the single source of truth for every job\u2014you can test end-to-end between different data stores, see a high level overview of the transforms you&amp;#39;re doing, and run all of these locally before ever getting your pipelines into production.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Command Line&lt;/h1&gt;\n\n&lt;p&gt;Create your ETL pipelines, test them locally with a subset of your data, and deploy them to the cloud (currently we only support Databricks, but will soon support others and plan to host our own clusters too). It also has an experimental \u201ctranslate\u201d feature which is still a bit finicky, but the idea is to take your existing SQL script and get suggestions on how you can chunk up and modularize your job with our config. It\u2019s still just a super early suggestion feature that is definitely not fleshed out, but we think it\u2019s a cool approach.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading all of this! We&amp;#39;re still very early on and would love any feedback\u2014we&amp;#39;re learning every day. We&amp;#39;re open-core (repo is here: &lt;a href=\"https://github.com/Serra-Technologies/serra\"&gt;https://github.com/Serra-Technologies/serra&lt;/a&gt;)\u2014DMs are open for any and all feedback!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ON5xcl0o2sBM4HsIxTn7mdrvx3iKKzJlEMxTyiZY-1A.jpg?auto=webp&amp;s=342fc099814ab8a5b5badadf842205bfe20b118e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ON5xcl0o2sBM4HsIxTn7mdrvx3iKKzJlEMxTyiZY-1A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da399eb78b2e07bac314b9c3bee9ee7b7df08ca7", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ON5xcl0o2sBM4HsIxTn7mdrvx3iKKzJlEMxTyiZY-1A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d3b6bae020afda542412a6b37531d7bd9a652f4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ON5xcl0o2sBM4HsIxTn7mdrvx3iKKzJlEMxTyiZY-1A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f3875eaefc58f7d9690b586ffcaa27ca2d439b86", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ON5xcl0o2sBM4HsIxTn7mdrvx3iKKzJlEMxTyiZY-1A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=938de66b50cc6e7fd44227e1fdd09a7feafb8b41", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ON5xcl0o2sBM4HsIxTn7mdrvx3iKKzJlEMxTyiZY-1A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=512981c892fc07ddcc581b56175b9890fd15d4ac", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ON5xcl0o2sBM4HsIxTn7mdrvx3iKKzJlEMxTyiZY-1A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9b0147b38eb4ea5aba328a79c2471f829c9ef946", "width": 1080, "height": 540}], "variants": {}, "id": "J8KKN0X4QsnUg0Qr0QQ7eTfRKdBzjqHGMxOy6fLBEGM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15zdm1p", "is_robot_indexable": true, "report_reasons": null, "author": "Last-Personality3757", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zdm1p/serra_pythonbased_dbt_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zdm1p/serra_pythonbased_dbt_alternative/", "subreddit_subscribers": 124444, "created_utc": 1692818307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggests I am curious of how folks develop scala-spark applications locally. \n\nI've been playing around with 2 ways:\n\n1. Let Intellij do the heavy lifting and use an Intellij Application runtime configuration that (I think) spins up a spark cluster in its own JVM on my local machine. I then use Big Data Tools plugin to monitor jobs or just go to the web UI directly.\n\n2. Run a local k8s cluster (via docker desktop) and use the bitnami helm chart to create a spark cluster on k8s. Then use spark-submit from my local machine and monitor the jobs via the web UI after port forwarding. I haven't found a way to surface the spark connection in Big Data Tools this way, unfortunately. \n\n\nFor test source data I create a Kafka producer that generates random data conforming to a schema via the Big Data Tools plugin. \n\nFor sinks, I either just print to std out or create up an output Kafka topic/data warehouse depending on the pipeline. \n\nWhat is your workflow?\n\n\nEdit: bonus points for those who harness the power of Intellij(I don't use it's features enough). It looks like the Spark Submit Local runtime configuration is deprecated though :/", "author_fullname": "t2_13z9km", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark local development workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z6okz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692806321.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692803581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests I am curious of how folks develop scala-spark applications locally. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been playing around with 2 ways:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Let Intellij do the heavy lifting and use an Intellij Application runtime configuration that (I think) spins up a spark cluster in its own JVM on my local machine. I then use Big Data Tools plugin to monitor jobs or just go to the web UI directly.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Run a local k8s cluster (via docker desktop) and use the bitnami helm chart to create a spark cluster on k8s. Then use spark-submit from my local machine and monitor the jobs via the web UI after port forwarding. I haven&amp;#39;t found a way to surface the spark connection in Big Data Tools this way, unfortunately. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For test source data I create a Kafka producer that generates random data conforming to a schema via the Big Data Tools plugin. &lt;/p&gt;\n\n&lt;p&gt;For sinks, I either just print to std out or create up an output Kafka topic/data warehouse depending on the pipeline. &lt;/p&gt;\n\n&lt;p&gt;What is your workflow?&lt;/p&gt;\n\n&lt;p&gt;Edit: bonus points for those who harness the power of Intellij(I don&amp;#39;t use it&amp;#39;s features enough). It looks like the Spark Submit Local runtime configuration is deprecated though :/&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15z6okz", "is_robot_indexable": true, "report_reasons": null, "author": "Mozzarella_mario", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z6okz/spark_local_development_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z6okz/spark_local_development_workflow/", "subreddit_subscribers": 124444, "created_utc": 1692803581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm constantly hearing that one of the major issues for data on end2end perspective is data quality. Can you elaborate scenarios what kind or type of data quality defects are you encountering? Is is this more on accuracy or completeness upon entry? Or wrong extract of data type,etc? Is data quality more on transactional or analytics perspective? How do you deal this as data engineer? Is there some kind of pipelines first to validate the ETL?\n\nWould love to get your insights, thanks!", "author_fullname": "t2_hjc1e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15zay7u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692812607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m constantly hearing that one of the major issues for data on end2end perspective is data quality. Can you elaborate scenarios what kind or type of data quality defects are you encountering? Is is this more on accuracy or completeness upon entry? Or wrong extract of data type,etc? Is data quality more on transactional or analytics perspective? How do you deal this as data engineer? Is there some kind of pipelines first to validate the ETL?&lt;/p&gt;\n\n&lt;p&gt;Would love to get your insights, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15zay7u", "is_robot_indexable": true, "report_reasons": null, "author": "bistek02", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zay7u/data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zay7u/data_quality/", "subreddit_subscribers": 124444, "created_utc": 1692812607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was laid off in July by my previous company alongside several dozen others due to \"unprecedented times\". They told me I would have to apply as an external applicant. Interviewed for about a dozen different positions, and as of a couple days ago, they finally made me an offer. But this was after another company I had applied to also offered me a job and I accepted and sign the offer letter Just to make sure I'm not homeless from running out of money.\n\nCompany A:\n\n* Senior data analysts at Fortune 500 retail company selling home products and physical goods\n* Laid me off completely at random with 30 other people, and offered no assistance finding another job within the company. Had to interview for a dozen different positions as an external applicant like I was some nobody off the street. During the hiring process, however, I got lots of great feedback and was told that everyone on my previous team really loved me, had great things to say, never heard anything negative about me. This put a bad taste in my mouth\n* 4 days in office, no possibility of remote work\n* No discount or incentives offered for any products they sell\n* 6% bonus depending on company performance. Not guaranteed\n* Mandatory social outings outside business hours. For example, one time, we met at a local park and played soccer against another team under the same department on a Saturday. The directors were there, but disappeared after 5 minutes to go \"take a phone call\" and never came back. Manager also showed up 40 minutes late, then didn't even participate, so it was just us doing it against each other. They also made T-shirts with team names that we had to wear, ours was \"the exterminators\"\n* Tech systems stuck in the past. Many teams still use Excel exclusively to solve virtually everything even though they have Tableau, and they use Microsoft Access for databases\n* People were lazy and unmotivated, lacking innovation. lots of boomers who have no interest in innovating, are extremely under skilled and unwilling to learn. On my last team we hired someone who claimed they knew databases and SQL as well as master of Excel. Then called me every single week to ask me how to do a v-lookup. Lots of people incapable of figuring out how to do anything themselves. Whole company is like this from what I can tell.\n* Very conservative company run by boomers. Frequently in the news negatively for donating to rightwing political groups, and trying to control legislation, which puts them in a bad light. Not saying I agree or disagree here, just indicating the general nature of how they are perceived currently\n\nCompany B:\n\n* Senior analyst at Fortune 500 media and tech company selling fiber optic cable and wireless products\n* Three days in office with possibility to go fully remote in the future as flex\n* seemed to be extremely interested in me personally and treating me as a person. Was asked to choose between Lord of the rings and Star wars in the interview, which I found kind of fun and cool, like they cared about me as a person and valued fun\n* 100% discount on the services they offer like cable TV and internet, wireless, amounting to about $1,200 a year in savings. 6% bonus paid out quarterly or yearly\n* very progressive, innovative tech firm focused on learning, growth, collaborative development. Huge data science, analytics focus. It was clear that they were very very focused on learning, development of associates, having people learn\n* entire team is fully remote spread across several states, so no in-person outings or requirement to go play soccer or any of that.\n* software and technology used at this company is a bit more advanced. No combing through spreadsheets, no use of Microsoft Access. They use Tableau, Power BI, BigQuery, database systems\n\n&amp;#x200B;\n\n**edit: Both positions offer same exact salary**", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to choose from two different job offers. Any thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15zgsr0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692827418.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692825012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was laid off in July by my previous company alongside several dozen others due to &amp;quot;unprecedented times&amp;quot;. They told me I would have to apply as an external applicant. Interviewed for about a dozen different positions, and as of a couple days ago, they finally made me an offer. But this was after another company I had applied to also offered me a job and I accepted and sign the offer letter Just to make sure I&amp;#39;m not homeless from running out of money.&lt;/p&gt;\n\n&lt;p&gt;Company A:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Senior data analysts at Fortune 500 retail company selling home products and physical goods&lt;/li&gt;\n&lt;li&gt;Laid me off completely at random with 30 other people, and offered no assistance finding another job within the company. Had to interview for a dozen different positions as an external applicant like I was some nobody off the street. During the hiring process, however, I got lots of great feedback and was told that everyone on my previous team really loved me, had great things to say, never heard anything negative about me. This put a bad taste in my mouth&lt;/li&gt;\n&lt;li&gt;4 days in office, no possibility of remote work&lt;/li&gt;\n&lt;li&gt;No discount or incentives offered for any products they sell&lt;/li&gt;\n&lt;li&gt;6% bonus depending on company performance. Not guaranteed&lt;/li&gt;\n&lt;li&gt;Mandatory social outings outside business hours. For example, one time, we met at a local park and played soccer against another team under the same department on a Saturday. The directors were there, but disappeared after 5 minutes to go &amp;quot;take a phone call&amp;quot; and never came back. Manager also showed up 40 minutes late, then didn&amp;#39;t even participate, so it was just us doing it against each other. They also made T-shirts with team names that we had to wear, ours was &amp;quot;the exterminators&amp;quot;&lt;/li&gt;\n&lt;li&gt;Tech systems stuck in the past. Many teams still use Excel exclusively to solve virtually everything even though they have Tableau, and they use Microsoft Access for databases&lt;/li&gt;\n&lt;li&gt;People were lazy and unmotivated, lacking innovation. lots of boomers who have no interest in innovating, are extremely under skilled and unwilling to learn. On my last team we hired someone who claimed they knew databases and SQL as well as master of Excel. Then called me every single week to ask me how to do a v-lookup. Lots of people incapable of figuring out how to do anything themselves. Whole company is like this from what I can tell.&lt;/li&gt;\n&lt;li&gt;Very conservative company run by boomers. Frequently in the news negatively for donating to rightwing political groups, and trying to control legislation, which puts them in a bad light. Not saying I agree or disagree here, just indicating the general nature of how they are perceived currently&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Company B:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Senior analyst at Fortune 500 media and tech company selling fiber optic cable and wireless products&lt;/li&gt;\n&lt;li&gt;Three days in office with possibility to go fully remote in the future as flex&lt;/li&gt;\n&lt;li&gt;seemed to be extremely interested in me personally and treating me as a person. Was asked to choose between Lord of the rings and Star wars in the interview, which I found kind of fun and cool, like they cared about me as a person and valued fun&lt;/li&gt;\n&lt;li&gt;100% discount on the services they offer like cable TV and internet, wireless, amounting to about $1,200 a year in savings. 6% bonus paid out quarterly or yearly&lt;/li&gt;\n&lt;li&gt;very progressive, innovative tech firm focused on learning, growth, collaborative development. Huge data science, analytics focus. It was clear that they were very very focused on learning, development of associates, having people learn&lt;/li&gt;\n&lt;li&gt;entire team is fully remote spread across several states, so no in-person outings or requirement to go play soccer or any of that.&lt;/li&gt;\n&lt;li&gt;software and technology used at this company is a bit more advanced. No combing through spreadsheets, no use of Microsoft Access. They use Tableau, Power BI, BigQuery, database systems&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;edit: Both positions offer same exact salary&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15zgsr0", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zgsr0/need_to_choose_from_two_different_job_offers_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zgsr0/need_to_choose_from_two_different_job_offers_any/", "subreddit_subscribers": 124444, "created_utc": 1692825012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm studying CS and I've been looking into career options so that I can start to learn and make progress in specific fields.\n\nTwo options come to my mind: web (front and back) development and data engineering.\n\nFirst one for being the most common job any graduate does, having many junior jobs available, having a relatively easier work-load etc.\n\nSecond one ... well, a friend of the family is a data engineer and when he quit his first job he had countless offers from a lot of reputable companies in about a month and he got to choose. He was also from the same country as me (3rd world country) and he went and moved to Europe relatively easily.\n\nFrom what I've gathered, data engineering is not really a common field for juniors since all job postings I've seen require a couple years of experience.\n\nIt doesn't seem as math-heavy as data science but more programming related in the day to day.\n\nIt seems like a field where there aren't many jobs available but the ones that are available are pretty well above average.\n\nMy question is: why should I choose data engineering over other fields?", "author_fullname": "t2_g89jkepfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What made you choose data engineering over other fields?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15zlmfl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692835807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m studying CS and I&amp;#39;ve been looking into career options so that I can start to learn and make progress in specific fields.&lt;/p&gt;\n\n&lt;p&gt;Two options come to my mind: web (front and back) development and data engineering.&lt;/p&gt;\n\n&lt;p&gt;First one for being the most common job any graduate does, having many junior jobs available, having a relatively easier work-load etc.&lt;/p&gt;\n\n&lt;p&gt;Second one ... well, a friend of the family is a data engineer and when he quit his first job he had countless offers from a lot of reputable companies in about a month and he got to choose. He was also from the same country as me (3rd world country) and he went and moved to Europe relatively easily.&lt;/p&gt;\n\n&lt;p&gt;From what I&amp;#39;ve gathered, data engineering is not really a common field for juniors since all job postings I&amp;#39;ve seen require a couple years of experience.&lt;/p&gt;\n\n&lt;p&gt;It doesn&amp;#39;t seem as math-heavy as data science but more programming related in the day to day.&lt;/p&gt;\n\n&lt;p&gt;It seems like a field where there aren&amp;#39;t many jobs available but the ones that are available are pretty well above average.&lt;/p&gt;\n\n&lt;p&gt;My question is: why should I choose data engineering over other fields?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15zlmfl", "is_robot_indexable": true, "report_reasons": null, "author": "Flyin-Whale", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zlmfl/what_made_you_choose_data_engineering_over_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zlmfl/what_made_you_choose_data_engineering_over_other/", "subreddit_subscribers": 124444, "created_utc": 1692835807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need assistance with what application would work best for allowing users to export 1-3 million rows of data on demand? Current solution is power bi but the downside is the export limit of 150,000. Does anyone know what application works best with databricks that allows user to create their own reports, similar to business objects and does not have a row limit export of 150,000.", "author_fullname": "t2_4wp7oy4pc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What business intelligence application is best for exporting millions of rows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15zhyeb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692827530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need assistance with what application would work best for allowing users to export 1-3 million rows of data on demand? Current solution is power bi but the downside is the export limit of 150,000. Does anyone know what application works best with databricks that allows user to create their own reports, similar to business objects and does not have a row limit export of 150,000.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15zhyeb", "is_robot_indexable": true, "report_reasons": null, "author": "LeadingPolicy9378", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zhyeb/what_business_intelligence_application_is_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zhyeb/what_business_intelligence_application_is_best/", "subreddit_subscribers": 124444, "created_utc": 1692827530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thinking about ordering a new work laptop, and although we\u2019ve got access to cloud resources and an HPC cluster, the baseline model offered as standard\u2014especially 16 GB of RAM\u2014feels insufficient for development on containerized applications that build upon ML.\n\nI.e., locally setting up databases, orchestration, pipelines, and observability tools etc. prior to deployment to, e.g., EKS would probably be a lot more pleasant on a beefier machine. I\u2019m a heavy Docker user and all of my dev environments are containerized as well.", "author_fullname": "t2_11ewax", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "People on MacBook Pros, what\u2019s your specs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15zhetw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692826344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thinking about ordering a new work laptop, and although we\u2019ve got access to cloud resources and an HPC cluster, the baseline model offered as standard\u2014especially 16 GB of RAM\u2014feels insufficient for development on containerized applications that build upon ML.&lt;/p&gt;\n\n&lt;p&gt;I.e., locally setting up databases, orchestration, pipelines, and observability tools etc. prior to deployment to, e.g., EKS would probably be a lot more pleasant on a beefier machine. I\u2019m a heavy Docker user and all of my dev environments are containerized as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15zhetw", "is_robot_indexable": true, "report_reasons": null, "author": "TobiPlay", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zhetw/people_on_macbook_pros_whats_your_specs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zhetw/people_on_macbook_pros_whats_your_specs/", "subreddit_subscribers": 124444, "created_utc": 1692826344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cube integrates with LangChain to help build AI-powered experiences on top of the semantic layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15z7jog", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RIrspQi5snD1utGDs2qwlaIWxwI-sHKcOVUZooRtq_o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692805477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-the-langchain-integration", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?auto=webp&amp;s=33a60669ed3e943fcac8c46b9474c54521c027b1", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aa22294bd2c1e554cf05525ea892bd8d433b4dc5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=92e590568456a0557d8043f9de8a9c2c55b30cd5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f0104a03e6c661de48fa71827af08dd011456f61", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5b4a7b95ee6de636d14f2ff3c787ca16d5c14f8", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=60df4c40261a407f7dcb41e24e513bd627181b5d", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5595dcce2c65382d3a4162e3fd93293985ad9ff4", "width": 1080, "height": 567}], "variants": {}, "id": "dYxJf8pR1ZZdrsed3oKjduh072Vjn8cW_o2GlECcZXc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15z7jog", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z7jog/cube_integrates_with_langchain_to_help_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-the-langchain-integration", "subreddit_subscribers": 124444, "created_utc": 1692805477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title states, my current job role is just IT support and I have been given two options - to do a certification in either the data or software engineering and I'm not well versed in either.\n\nI'll have to start from scratch, I'm gravitating more towards data engineering side because it seems more interesting and plausible for me since I am originally from a non-IT background as well. Two years in support role has me just googling up stuff or asking colleagues and seniors about things I'm unaware of. \n\nSomehow this switch itself seems almost impossible, but I don't want to give up before putting up a fight.\n\nIn addition I have heard the exam post certification is also extremely difficult and I get only one try - so any sources for in depth study/courses would also be really helpful to me!\n\nTldr: been given two choices and I'm not sure which one to take or if it's even possible.. could it be that they're just looking to lay off...", "author_fullname": "t2_a47y2ora", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I choose software engineer or data engineer certification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z7oi5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692805765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title states, my current job role is just IT support and I have been given two options - to do a certification in either the data or software engineering and I&amp;#39;m not well versed in either.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll have to start from scratch, I&amp;#39;m gravitating more towards data engineering side because it seems more interesting and plausible for me since I am originally from a non-IT background as well. Two years in support role has me just googling up stuff or asking colleagues and seniors about things I&amp;#39;m unaware of. &lt;/p&gt;\n\n&lt;p&gt;Somehow this switch itself seems almost impossible, but I don&amp;#39;t want to give up before putting up a fight.&lt;/p&gt;\n\n&lt;p&gt;In addition I have heard the exam post certification is also extremely difficult and I get only one try - so any sources for in depth study/courses would also be really helpful to me!&lt;/p&gt;\n\n&lt;p&gt;Tldr: been given two choices and I&amp;#39;m not sure which one to take or if it&amp;#39;s even possible.. could it be that they&amp;#39;re just looking to lay off...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15z7oi5", "is_robot_indexable": true, "report_reasons": null, "author": "plum_red", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z7oi5/should_i_choose_software_engineer_or_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z7oi5/should_i_choose_software_engineer_or_data/", "subreddit_subscribers": 124444, "created_utc": 1692805765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been a data engineer for 3 years now with proficient python and SQL experience, also DataOps skills like CI/CD, IaC and Kubernetes.\n\nGot experience with Azure, Airflow and Snowflake. Worked on personal project which was Flask app.\n\nExperienced in building Data platforms from scratch mostly.\n\nI am wondering what is the job market for hybrid DE roles and salary ranges in the US and around NYC specifically.", "author_fullname": "t2_zwapz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering roles in New York or US in general", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z6z0v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692804215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been a data engineer for 3 years now with proficient python and SQL experience, also DataOps skills like CI/CD, IaC and Kubernetes.&lt;/p&gt;\n\n&lt;p&gt;Got experience with Azure, Airflow and Snowflake. Worked on personal project which was Flask app.&lt;/p&gt;\n\n&lt;p&gt;Experienced in building Data platforms from scratch mostly.&lt;/p&gt;\n\n&lt;p&gt;I am wondering what is the job market for hybrid DE roles and salary ranges in the US and around NYC specifically.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15z6z0v", "is_robot_indexable": true, "report_reasons": null, "author": "atf15", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z6z0v/data_engineering_roles_in_new_york_or_us_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z6z0v/data_engineering_roles_in_new_york_or_us_in/", "subreddit_subscribers": 124444, "created_utc": 1692804215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company, clients send their required products in a mail or a text message, We then have to check for those products from our csv file in excel manually. This wastes a lot of time, How can I make this process easier with some automation or a better approach/process?", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I automate searching a csv file in excel?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z0o9k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692788839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company, clients send their required products in a mail or a text message, We then have to check for those products from our csv file in excel manually. This wastes a lot of time, How can I make this process easier with some automation or a better approach/process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15z0o9k", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z0o9k/how_do_i_automate_searching_a_csv_file_in_excel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z0o9k/how_do_i_automate_searching_a_csv_file_in_excel/", "subreddit_subscribers": 124444, "created_utc": 1692788839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm applying for a Director of Data Engineering for a large e-commerce company.  I'm currently a Director of Software Engineering (not DE) at a reputable medium sized company with interesting data and non-data related projects under my belt.  I'm interested in this role for some career and some personal reasons.\n\nI'm trying to prep for the interviews, and my weakest aspect is actually core technical data engineering.  My SQL skill is rusty, my Spark + Snowflake experience is mid-level.  However my people management (both up and down), project management, presentation skills, solution architecture, mentorship, career development, infrastructure+ devops knowledge, fullstack knowledge are great.\n\nI would like to think that at Director level low level DE knowledge (such as optimizing SQL statements) is less important and strategic management skills are more important.  I would like to hear what other Directors or Managers have to say about this.  Thanks.", "author_fullname": "t2_998vq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to prep for a Director of DE position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15zso1l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692855331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m applying for a Director of Data Engineering for a large e-commerce company.  I&amp;#39;m currently a Director of Software Engineering (not DE) at a reputable medium sized company with interesting data and non-data related projects under my belt.  I&amp;#39;m interested in this role for some career and some personal reasons.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to prep for the interviews, and my weakest aspect is actually core technical data engineering.  My SQL skill is rusty, my Spark + Snowflake experience is mid-level.  However my people management (both up and down), project management, presentation skills, solution architecture, mentorship, career development, infrastructure+ devops knowledge, fullstack knowledge are great.&lt;/p&gt;\n\n&lt;p&gt;I would like to think that at Director level low level DE knowledge (such as optimizing SQL statements) is less important and strategic management skills are more important.  I would like to hear what other Directors or Managers have to say about this.  Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15zso1l", "is_robot_indexable": true, "report_reasons": null, "author": "boloism", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zso1l/what_to_prep_for_a_director_of_de_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zso1l/what_to_prep_for_a_director_of_de_position/", "subreddit_subscribers": 124444, "created_utc": 1692855331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nOver the last few weeks I've been experimenting with analyzing user data with Pinpoint by sending it to an Athena backend using Eventbridge Pipes, Kinesis, and Glue.\n\nI've wanted an excuse to create an Athena pipeline/database for a while now and this was the perfect opportunity to \"glue\" a few AWS resources together and give it a try.\n\nI've gotta say, I'm really happy with the results. Feel free to give it a read!\n\n[https://stevenpstaley.medium.com/analyzing-user-data-with-custom-aws-pinpoint-events-kinesis-lambda-eventbridge-glue-and-athena-f84669c0242b](https://stevenpstaley.medium.com/analyzing-user-data-with-custom-aws-pinpoint-events-kinesis-lambda-eventbridge-glue-and-athena-f84669c0242b)", "author_fullname": "t2_3ar5501p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing User Data With AWS Pinpoint, Kinesis, Eventbridge Pipes, and Athena", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15zq201", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692847492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Over the last few weeks I&amp;#39;ve been experimenting with analyzing user data with Pinpoint by sending it to an Athena backend using Eventbridge Pipes, Kinesis, and Glue.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve wanted an excuse to create an Athena pipeline/database for a while now and this was the perfect opportunity to &amp;quot;glue&amp;quot; a few AWS resources together and give it a try.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve gotta say, I&amp;#39;m really happy with the results. Feel free to give it a read!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://stevenpstaley.medium.com/analyzing-user-data-with-custom-aws-pinpoint-events-kinesis-lambda-eventbridge-glue-and-athena-f84669c0242b\"&gt;https://stevenpstaley.medium.com/analyzing-user-data-with-custom-aws-pinpoint-events-kinesis-lambda-eventbridge-glue-and-athena-f84669c0242b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lr3EC0Bv9yhxr7UEHphi_FeEgrohyrfrDmD7VJ0aiWY.jpg?auto=webp&amp;s=eb58eb410cae0a0cd5e0cbdbef8a1a61f2d17d4f", "width": 1200, "height": 681}, "resolutions": [{"url": "https://external-preview.redd.it/lr3EC0Bv9yhxr7UEHphi_FeEgrohyrfrDmD7VJ0aiWY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=012889b7d23d0a6598477139a74300156e863dfe", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/lr3EC0Bv9yhxr7UEHphi_FeEgrohyrfrDmD7VJ0aiWY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=365a967e9a358611439744361089cf4c5c53649a", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/lr3EC0Bv9yhxr7UEHphi_FeEgrohyrfrDmD7VJ0aiWY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=941076c63b9e73fedf17d8450046743af3353cde", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/lr3EC0Bv9yhxr7UEHphi_FeEgrohyrfrDmD7VJ0aiWY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dd2ce8ca8e0e707f94719d2439558085c617ac0f", "width": 640, "height": 363}, {"url": "https://external-preview.redd.it/lr3EC0Bv9yhxr7UEHphi_FeEgrohyrfrDmD7VJ0aiWY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=75e18f59d1324f224e66f07e39b6690c0f658d91", "width": 960, "height": 544}, {"url": "https://external-preview.redd.it/lr3EC0Bv9yhxr7UEHphi_FeEgrohyrfrDmD7VJ0aiWY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a12785640849f8e62b4e74707e08a5dddf6edacc", "width": 1080, "height": 612}], "variants": {}, "id": "NcNL2Sil3MVuUjOOMrt5CeVgxHjH0rHrqJj65zbTBIA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15zq201", "is_robot_indexable": true, "report_reasons": null, "author": "5olArchitect", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zq201/analyzing_user_data_with_aws_pinpoint_kinesis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zq201/analyzing_user_data_with_aws_pinpoint_kinesis/", "subreddit_subscribers": 124444, "created_utc": 1692847492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Skyvia for Salesforce Replication\n\nQuick question\u2026and one I have asked the skyvia support desk (no answer yet)\n\nIs it possible to automate on a schedule, a replication package using Skyvia? Reason being I\u2019m looking at taking Salesforce data into SQL Azure each evening (to prep for data warehousing)\n\nI\u2019ve seen that it\u2019s possible to automate/schedule a synchronisation package, but upon creating a sync package it limits tables/objects to one table/object (with related objects) so that\u2019s not an option (on 300 odd tables!)\n\n I want to replicate the whole darn thing everyday!\n\nCheers!", "author_fullname": "t2_hg12i599c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Skyvia for Salesforce Replication", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15zi9am", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692828183.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Skyvia for Salesforce Replication&lt;/p&gt;\n\n&lt;p&gt;Quick question\u2026and one I have asked the skyvia support desk (no answer yet)&lt;/p&gt;\n\n&lt;p&gt;Is it possible to automate on a schedule, a replication package using Skyvia? Reason being I\u2019m looking at taking Salesforce data into SQL Azure each evening (to prep for data warehousing)&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve seen that it\u2019s possible to automate/schedule a synchronisation package, but upon creating a sync package it limits tables/objects to one table/object (with related objects) so that\u2019s not an option (on 300 odd tables!)&lt;/p&gt;\n\n&lt;p&gt;I want to replicate the whole darn thing everyday!&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15zi9am", "is_robot_indexable": true, "report_reasons": null, "author": "BumblyWurzle", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zi9am/skyvia_for_salesforce_replication/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zi9am/skyvia_for_salesforce_replication/", "subreddit_subscribers": 124444, "created_utc": 1692828183.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data usage monitoring/analytics\n\nI would like to have an overview/monitoring/analytics/whatever we call it about what data from our warehouse is actually used, by who, what applications and how often. \n\nIs there any technical solution/concept/framework/whatever for that? I am aware of some data catalogs but that is not really what I need. Maybe some data lineage tool? But that is pretty difficult to set up and have it correct/updated. \n\nHow do you solve this?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data usage map", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15zcu13", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692816613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data usage monitoring/analytics&lt;/p&gt;\n\n&lt;p&gt;I would like to have an overview/monitoring/analytics/whatever we call it about what data from our warehouse is actually used, by who, what applications and how often. &lt;/p&gt;\n\n&lt;p&gt;Is there any technical solution/concept/framework/whatever for that? I am aware of some data catalogs but that is not really what I need. Maybe some data lineage tool? But that is pretty difficult to set up and have it correct/updated. &lt;/p&gt;\n\n&lt;p&gt;How do you solve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15zcu13", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zcu13/data_usage_map/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zcu13/data_usage_map/", "subreddit_subscribers": 124444, "created_utc": 1692816613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "every dimension table should have an \"unknown\" row, AFAIK\n\nis there a DBT macro to create these?\n\nImagine, I have a table with many columns, some dates, numeric, text\n\nI don't particularly want to type out the unknown row by hand for each table\n\nthx", "author_fullname": "t2_hv9zujyod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT macro to add \"unknown\"/\"N/A\" row to dimension tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15zcpbr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692816340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;every dimension table should have an &amp;quot;unknown&amp;quot; row, AFAIK&lt;/p&gt;\n\n&lt;p&gt;is there a DBT macro to create these?&lt;/p&gt;\n\n&lt;p&gt;Imagine, I have a table with many columns, some dates, numeric, text&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t particularly want to type out the unknown row by hand for each table&lt;/p&gt;\n\n&lt;p&gt;thx&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15zcpbr", "is_robot_indexable": true, "report_reasons": null, "author": "chad_broman69", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zcpbr/dbt_macro_to_add_unknownna_row_to_dimension_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zcpbr/dbt_macro_to_add_unknownna_row_to_dimension_tables/", "subreddit_subscribers": 124444, "created_utc": 1692816340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nTrying to set up data factory to export large fact tables that are hosted on premises to a storage account. Initially, I would like to transfer everything in the fact table up to today's date (whenever today is in the future) partitioned by date and then load only incremental rows after that.   \n\n\nHas anyone configured something similar? ", "author_fullname": "t2_nu50f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transfer on premises data to storage account", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z7gwc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692805298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;Trying to set up data factory to export large fact tables that are hosted on premises to a storage account. Initially, I would like to transfer everything in the fact table up to today&amp;#39;s date (whenever today is in the future) partitioned by date and then load only incremental rows after that.   &lt;/p&gt;\n\n&lt;p&gt;Has anyone configured something similar? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15z7gwc", "is_robot_indexable": true, "report_reasons": null, "author": "sugarbuzzlightyear", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z7gwc/transfer_on_premises_data_to_storage_account/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z7gwc/transfer_on_premises_data_to_storage_account/", "subreddit_subscribers": 124444, "created_utc": 1692805298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all! I am new to the industry and have recently been tasked with creating a data catalog for my extremely small-sized company. I've scoured high and low for information on data catalog creation, researching the available data catalog tools in the market, both commercial and open source. Unfortunately, my company is not inclined to invest in paid services due to our small size and dataset. Additionally, using open-source data catalogs like Datahub isn't feasible due to certain restrictions we have in place.\n\nI'm contemplating using a traditional approach, utilizing Excel to manage the catalog (though it's manual, given our small scale, it might suffice temporarily). My question is: what information should a data catalog capture? While I've come across numerous websites discussing data catalogs, none seem to provide specific details on the information to be included.\n\nI would greatly appreciate any advice from experienced data engineers! :)\n\nP.S: My data are stored in MySQL, with several tables.", "author_fullname": "t2_ud83ad97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you have in your data catalogs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z1wj9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692792222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! I am new to the industry and have recently been tasked with creating a data catalog for my extremely small-sized company. I&amp;#39;ve scoured high and low for information on data catalog creation, researching the available data catalog tools in the market, both commercial and open source. Unfortunately, my company is not inclined to invest in paid services due to our small size and dataset. Additionally, using open-source data catalogs like Datahub isn&amp;#39;t feasible due to certain restrictions we have in place.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m contemplating using a traditional approach, utilizing Excel to manage the catalog (though it&amp;#39;s manual, given our small scale, it might suffice temporarily). My question is: what information should a data catalog capture? While I&amp;#39;ve come across numerous websites discussing data catalogs, none seem to provide specific details on the information to be included.&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate any advice from experienced data engineers! :)&lt;/p&gt;\n\n&lt;p&gt;P.S: My data are stored in MySQL, with several tables.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15z1wj9", "is_robot_indexable": true, "report_reasons": null, "author": "DataNewbie88", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z1wj9/what_do_you_have_in_your_data_catalogs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z1wj9/what_do_you_have_in_your_data_catalogs/", "subreddit_subscribers": 124444, "created_utc": 1692792222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I'm trying to share tables with product/non technical people and at the moment what we do is send manually files that are then uploaded to excel and consumed.\nIs there any product out there that provides excel/pivot like functionality that connects directly to Snowflake? Was looking at sigmacomputing.com, anyone has any less expensive solutions?", "author_fullname": "t2_axgif", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplest way to have a pivot like UI on a table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yxw7t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692780204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;m trying to share tables with product/non technical people and at the moment what we do is send manually files that are then uploaded to excel and consumed.\nIs there any product out there that provides excel/pivot like functionality that connects directly to Snowflake? Was looking at sigmacomputing.com, anyone has any less expensive solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yxw7t", "is_robot_indexable": true, "report_reasons": null, "author": "Batto1300", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yxw7t/simplest_way_to_have_a_pivot_like_ui_on_a_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yxw7t/simplest_way_to_have_a_pivot_like_ui_on_a_table/", "subreddit_subscribers": 124444, "created_utc": 1692780204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m being involved in a project that will require me to work with message and tasks queues. \n\nFor now I\u2019ve been only working with Redis Streams and RQ (arq specifically) which technical aspects I think I get pretty well but I fail to understand how to decide which tool (message vs tasks queue) should be used for the particular task. \n\nIn the new project I will be involved in designing the architecture so I need to get a better understanding of the queues and their use cases, I guess mostly on a high level. Could you please recommend some resources to learn? Anything including paid courses is okay.", "author_fullname": "t2_2hwuo20b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources to learn message and tasks queues", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ywyhf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692777084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m being involved in a project that will require me to work with message and tasks queues. &lt;/p&gt;\n\n&lt;p&gt;For now I\u2019ve been only working with Redis Streams and RQ (arq specifically) which technical aspects I think I get pretty well but I fail to understand how to decide which tool (message vs tasks queue) should be used for the particular task. &lt;/p&gt;\n\n&lt;p&gt;In the new project I will be involved in designing the architecture so I need to get a better understanding of the queues and their use cases, I guess mostly on a high level. Could you please recommend some resources to learn? Anything including paid courses is okay.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ywyhf", "is_robot_indexable": true, "report_reasons": null, "author": "ppzet9", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ywyhf/resources_to_learn_message_and_tasks_queues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ywyhf/resources_to_learn_message_and_tasks_queues/", "subreddit_subscribers": 124444, "created_utc": 1692777084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Could someone give me advice on a quicker way to land a job in the industry? I've heard that starting as a Data Analyst is a good way to go. I'm unsure whether it's better to start as a Data Analyst to enter the industry more quickly or to focus all my studies on Data Engineering. What do you thing?", "author_fullname": "t2_83g86vz0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting as a Data Analyst for Faster Job Entry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yv5sb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692771177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could someone give me advice on a quicker way to land a job in the industry? I&amp;#39;ve heard that starting as a Data Analyst is a good way to go. I&amp;#39;m unsure whether it&amp;#39;s better to start as a Data Analyst to enter the industry more quickly or to focus all my studies on Data Engineering. What do you thing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yv5sb", "is_robot_indexable": true, "report_reasons": null, "author": "Davidalmaz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yv5sb/starting_as_a_data_analyst_for_faster_job_entry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yv5sb/starting_as_a_data_analyst_for_faster_job_entry/", "subreddit_subscribers": 124444, "created_utc": 1692771177.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}