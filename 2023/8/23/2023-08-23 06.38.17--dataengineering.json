{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I lead a small DE team at a medium sized retailer. Over the years we\u2019ve setup the data platform on GCP, lambda architecture feeding data into BQ with DBT transforms. We\u2019re reaching a point where we\u2019ve pretty much ingested all the data sources used by the business, completed the data models, reverse ETL and automation CI/CD. I\u2019m starting to draw a blank on what business focussed initiatives we should start taking up at this mature stage and would appreciate any thoughts from this community. \n\nSome things I\u2019m considering are improving data quality checks, improving the data catalog and adding more metrics to the semantic layer. \n\nWe\u2019ve already done several rounds of optimisation and cloud cost control so I don\u2019t see much more opportunity there. Most of our data usage in the business is batch focused including ML model training so we don\u2019t really see the need to move to a kappa architecture either.", "author_fullname": "t2_tdne3tqb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do Data Engineers do after the data platform is completely setup and automated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15y7v97", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 105, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 105, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692715403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I lead a small DE team at a medium sized retailer. Over the years we\u2019ve setup the data platform on GCP, lambda architecture feeding data into BQ with DBT transforms. We\u2019re reaching a point where we\u2019ve pretty much ingested all the data sources used by the business, completed the data models, reverse ETL and automation CI/CD. I\u2019m starting to draw a blank on what business focussed initiatives we should start taking up at this mature stage and would appreciate any thoughts from this community. &lt;/p&gt;\n\n&lt;p&gt;Some things I\u2019m considering are improving data quality checks, improving the data catalog and adding more metrics to the semantic layer. &lt;/p&gt;\n\n&lt;p&gt;We\u2019ve already done several rounds of optimisation and cloud cost control so I don\u2019t see much more opportunity there. Most of our data usage in the business is batch focused including ML model training so we don\u2019t really see the need to move to a kappa architecture either.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15y7v97", "is_robot_indexable": true, "report_reasons": null, "author": "Hackerjurassicpark", "discussion_type": null, "num_comments": 111, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y7v97/what_do_data_engineers_do_after_the_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15y7v97/what_do_data_engineers_do_after_the_data_platform/", "subreddit_subscribers": 124248, "created_utc": 1692715403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I made a post last week(I ended up deleting it out of doxing paranoia)about if I should negotiate my offer letter. This being despite already being happy with the offer and knowing it was fair through multiple benchmarking sites. The general vibe for the community I got was to negotiate. But there was a good chunk saying you shouldn't in this market.\n\nAs a result, I ended up negotiating. Majority rules win\n\nI am just a sample size of 1, but they did not rescind the offer and they did increase my compensation. In my case, the adage to always negotiate ended up being true! \n\nI did take the communities advice to tackle the negotiation from a benefits perspective over pure base salary", "author_fullname": "t2_5vqn2nya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Negotiated compensation and they gave it to me!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15y76e4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692715269.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692713868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made a post last week(I ended up deleting it out of doxing paranoia)about if I should negotiate my offer letter. This being despite already being happy with the offer and knowing it was fair through multiple benchmarking sites. The general vibe for the community I got was to negotiate. But there was a good chunk saying you shouldn&amp;#39;t in this market.&lt;/p&gt;\n\n&lt;p&gt;As a result, I ended up negotiating. Majority rules win&lt;/p&gt;\n\n&lt;p&gt;I am just a sample size of 1, but they did not rescind the offer and they did increase my compensation. In my case, the adage to always negotiate ended up being true! &lt;/p&gt;\n\n&lt;p&gt;I did take the communities advice to tackle the negotiation from a benefits perspective over pure base salary&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15y76e4", "is_robot_indexable": true, "report_reasons": null, "author": "recentcurrency", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y76e4/negotiated_compensation_and_they_gave_it_to_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15y76e4/negotiated_compensation_and_they_gave_it_to_me/", "subreddit_subscribers": 124248, "created_utc": 1692713868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI'm currently working for a company that operates in multiple countries, and we're trying to set up a data warehouse to facilitate reporting. However, we've run into a few challenges due to the fact that the various countries have different processes, reporting needs, and use different systems (ERPs, etc.). The general process is the same across the countries, but there are significant differences in how things are done, which leads to different reporting requirements.\n\nCorporate has tried to establish a common data model for the warehouse, but this has proved challenging, particularly when it comes to adapting the model (e.g., adding new fields). It's a slow process and we don't want all countries to have to deal with fields that are only relevant to some countries. Another issue is that \n\nI've been considering a few different approaches to solve this problem, and I'm looking for some input from this community:\n\n1. **Kimball-Style Warehouse**: We could create a Kimball-style data warehouse where the fact tables are shared across countries, but the dimension tables are country-specific. This would allow each country to have its own dimensions to accommodate the unique processes and reporting needs.\n2. **DataVault Architecture**: Another option could be to use a DataVault architecture where the satellite tables are country-specific. This way, the core data remains common, but the details and attributes that differ by country can be stored in separate satellite tables.\n3. **Dual Warehouses**: Alternatively, we could have each country maintain two separate data warehouses - one for its own specific needs and one for the corporate group. This could simplify things at the country level, but might be more expensive to maintain and operate .\n\nUntil now, the group has tried various approaches with mixed results. In addition to the above issues, we're also facing governance challenges. For example, a country may want to report on certain fields but doesn't want to give the group access (e.g., HR reporting). This further complicates our data warehousing strategy. \n\nI'm curious to know what you think would be the best way to go about this. If you've encountered a similar situation or have any insights or suggestions, I would really appreciate your input.\n\nThank you in advance for your help!\n\n**TL;DR:** How do you set up a data warehouse for a company with multiple countries, different processes, and different reporting needs, without making the whole thing messy and hard to maintain?", "author_fullname": "t2_r81va7is", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a Unified Data Warehouse for a Multi-Country, Multi-Process Company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15y359s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692706653.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692704057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working for a company that operates in multiple countries, and we&amp;#39;re trying to set up a data warehouse to facilitate reporting. However, we&amp;#39;ve run into a few challenges due to the fact that the various countries have different processes, reporting needs, and use different systems (ERPs, etc.). The general process is the same across the countries, but there are significant differences in how things are done, which leads to different reporting requirements.&lt;/p&gt;\n\n&lt;p&gt;Corporate has tried to establish a common data model for the warehouse, but this has proved challenging, particularly when it comes to adapting the model (e.g., adding new fields). It&amp;#39;s a slow process and we don&amp;#39;t want all countries to have to deal with fields that are only relevant to some countries. Another issue is that &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been considering a few different approaches to solve this problem, and I&amp;#39;m looking for some input from this community:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Kimball-Style Warehouse&lt;/strong&gt;: We could create a Kimball-style data warehouse where the fact tables are shared across countries, but the dimension tables are country-specific. This would allow each country to have its own dimensions to accommodate the unique processes and reporting needs.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;DataVault Architecture&lt;/strong&gt;: Another option could be to use a DataVault architecture where the satellite tables are country-specific. This way, the core data remains common, but the details and attributes that differ by country can be stored in separate satellite tables.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Dual Warehouses&lt;/strong&gt;: Alternatively, we could have each country maintain two separate data warehouses - one for its own specific needs and one for the corporate group. This could simplify things at the country level, but might be more expensive to maintain and operate .&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Until now, the group has tried various approaches with mixed results. In addition to the above issues, we&amp;#39;re also facing governance challenges. For example, a country may want to report on certain fields but doesn&amp;#39;t want to give the group access (e.g., HR reporting). This further complicates our data warehousing strategy. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to know what you think would be the best way to go about this. If you&amp;#39;ve encountered a similar situation or have any insights or suggestions, I would really appreciate your input.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; How do you set up a data warehouse for a company with multiple countries, different processes, and different reporting needs, without making the whole thing messy and hard to maintain?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15y359s", "is_robot_indexable": true, "report_reasons": null, "author": "Next_Sink9778", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y359s/creating_a_unified_data_warehouse_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15y359s/creating_a_unified_data_warehouse_for_a/", "subreddit_subscribers": 124248, "created_utc": 1692704057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw an article that made an argument that rebuilding pipelines after deployment is common. I am trying to understand why that's the case, can you all share your experiences. An instance i faced was when I switched companies and had to rebuild something similar for another firm.", "author_fullname": "t2_8fqxwhri", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "why data pipelines needs to be rebuild after deployment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15xxllx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692687145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw an article that made an argument that rebuilding pipelines after deployment is common. I am trying to understand why that&amp;#39;s the case, can you all share your experiences. An instance i faced was when I switched companies and had to rebuild something similar for another firm.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15xxllx", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway_account770", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15xxllx/why_data_pipelines_needs_to_be_rebuild_after/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15xxllx/why_data_pipelines_needs_to_be_rebuild_after/", "subreddit_subscribers": 124248, "created_utc": 1692687145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB and MotherDuck integrate with Cube, the semantic layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15y9niw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SYUxCQ-b7fXsdJGH-t6k7Dq4z3MH_4GbCpxvajbkGAw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692719201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-duckdb-and-motherduck-integrations", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?auto=webp&amp;s=d9e74c9951a0ca9b8748b30fcd26d61984b9f495", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78c65da2229c2a06c9e1e15e6ab743b582f5fa66", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=750b81dbd3c1336b92e3cd5b30e4aee59c09e7a3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7347cd2bea2cb6d188c6e744f12d349f9ee9d9c9", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17ce70691a42b55daefd48aca5deeb612ae7a347", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fb432cb27316771b2ffaa95d88392040ce02060d", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2eaff949d7f0202118355837e60b6e744520bcdf", "width": 1080, "height": 567}], "variants": {}, "id": "NA3Tk-5z5mSP4jvk5MtiXFoH2Injkrx8AV0tAS78fZw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15y9niw", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y9niw/duckdb_and_motherduck_integrate_with_cube_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-duckdb-and-motherduck-integrations", "subreddit_subscribers": 124248, "created_utc": 1692719201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For the data engineer coding screen, you likely will face algorithmic challenges as opposed to real world challenges such as loading a csv file. You should be comfortable with python basic and intermediate challenges. The below are the minimum skills you will need to master in order to succeed at a data engineering python coding screen.\n\nBe sure you are spending time learning the correct type of challenges:    \n\n\nhttps://medium.com/@seancoyne/what-data-structures-and-algorithms-should-a-data-engineer-study-a6a0cad90c31", "author_fullname": "t2_4fpl974m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Data Structures and Algorithms Should a Data Engineer Study?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yq7r6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1692756621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the data engineer coding screen, you likely will face algorithmic challenges as opposed to real world challenges such as loading a csv file. You should be comfortable with python basic and intermediate challenges. The below are the minimum skills you will need to master in order to succeed at a data engineering python coding screen.&lt;/p&gt;\n\n&lt;p&gt;Be sure you are spending time learning the correct type of challenges:    &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@seancoyne/what-data-structures-and-algorithms-should-a-data-engineer-study-a6a0cad90c31\"&gt;https://medium.com/@seancoyne/what-data-structures-and-algorithms-should-a-data-engineer-study-a6a0cad90c31&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?auto=webp&amp;s=0b8ce54b015da02eadf1e76e29538682a3de225e", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=12702677546e70a583242489e494289a3d8b2309", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2a593b41cbc8dde11955870d27b796125e769b33", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1a3d1a4deba3fd417e7861f7b9947518c26d384", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0022684a4b486b94bef7b92ac05f39af462affc4", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ae23fb869ac65ef5af87265ba85561393b48b3c2", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7d31aa155654c934ac021eb4620ed769a0c2cd22", "width": 1080, "height": 720}], "variants": {}, "id": "6P-G4uLnVEC6BsKb55gXEiv1BIKiM-nl5g9H53Dd9Is"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15yq7r6", "is_robot_indexable": true, "report_reasons": null, "author": "coyne_operated", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yq7r6/what_data_structures_and_algorithms_should_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yq7r6/what_data_structures_and_algorithms_should_a_data/", "subreddit_subscribers": 124248, "created_utc": 1692756621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Mehcanical/manufacturing engineer turned data analyst/data engineer through lots of at-home training and job hopping. I work for a manufacturing company, My goal is to give engineers, analysts, and management as much machine, process, and quality data as possible.\n\nThere have been some setbacks with this being a new space in manufacturing. I'm not much of a controls engineer so I'm often left waiting for the already spread thin controls team to program and/or grab the variables I need. From the IT end, I'm waiting on implementation of a historian and an operator app. But the real problem that I just can't seem to find the solution too... how do I organize the data?!?\n\nInitially, I started out by only gathering the basics. Good and bad quality counts, uptimes, and cycle times. The pieces needed to get OEE. However, my building is pretty unique in that it has the most futuristic one piece flow automated lines. Data is easy to extract from the PLCs and OEE is easy to aggregate at the machine and work center level. We are also the newest and so we don't really have an ERP or MES. We basically get POs from another building and our plant manager builds a rough week by week schedule in Excel that seems to change daily.\n\nI wanted to propose creation of a scheduling system that would align with other facilities. This is where I fell down a deep deep rabbit hole.\n\nFirst of all not every site is continuous manufacturing, some sites are discrete. Additionally, some sites use ERPs to schedule, others have dedicated scheduling software. Some organize data by work centers, others use assets. Some just live and die by production orders. \n\nHow does a normal manufacturing facility organize OEE data and eventually machine sensor data (both quality and machine health related).\n\nThings can be organized by time (hour, shift, day, week) which I find valuable for downtime and the reasons associated, by cell/work center, by routing, by work order, by part name. The list goes on and on. It just seems like there are so many wheels and cogs. How does it all typically connect?", "author_fullname": "t2_fgc39", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data engineers in the world of manufacturing? What is your stack and how is data at your company organized?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yqw7o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692758448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mehcanical/manufacturing engineer turned data analyst/data engineer through lots of at-home training and job hopping. I work for a manufacturing company, My goal is to give engineers, analysts, and management as much machine, process, and quality data as possible.&lt;/p&gt;\n\n&lt;p&gt;There have been some setbacks with this being a new space in manufacturing. I&amp;#39;m not much of a controls engineer so I&amp;#39;m often left waiting for the already spread thin controls team to program and/or grab the variables I need. From the IT end, I&amp;#39;m waiting on implementation of a historian and an operator app. But the real problem that I just can&amp;#39;t seem to find the solution too... how do I organize the data?!?&lt;/p&gt;\n\n&lt;p&gt;Initially, I started out by only gathering the basics. Good and bad quality counts, uptimes, and cycle times. The pieces needed to get OEE. However, my building is pretty unique in that it has the most futuristic one piece flow automated lines. Data is easy to extract from the PLCs and OEE is easy to aggregate at the machine and work center level. We are also the newest and so we don&amp;#39;t really have an ERP or MES. We basically get POs from another building and our plant manager builds a rough week by week schedule in Excel that seems to change daily.&lt;/p&gt;\n\n&lt;p&gt;I wanted to propose creation of a scheduling system that would align with other facilities. This is where I fell down a deep deep rabbit hole.&lt;/p&gt;\n\n&lt;p&gt;First of all not every site is continuous manufacturing, some sites are discrete. Additionally, some sites use ERPs to schedule, others have dedicated scheduling software. Some organize data by work centers, others use assets. Some just live and die by production orders. &lt;/p&gt;\n\n&lt;p&gt;How does a normal manufacturing facility organize OEE data and eventually machine sensor data (both quality and machine health related).&lt;/p&gt;\n\n&lt;p&gt;Things can be organized by time (hour, shift, day, week) which I find valuable for downtime and the reasons associated, by cell/work center, by routing, by work order, by part name. The list goes on and on. It just seems like there are so many wheels and cogs. How does it all typically connect?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yqw7o", "is_robot_indexable": true, "report_reasons": null, "author": "TheOnlinePolak", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yqw7o/any_data_engineers_in_the_world_of_manufacturing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yqw7o/any_data_engineers_in_the_world_of_manufacturing/", "subreddit_subscribers": 124248, "created_utc": 1692758448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am very new to data science so i was hoping explain how a business with separate databases for CRM, Social media platforms, SEO, VOIP call data, , 1 containing crm data, 1 containing SEO data, one from voip call data, \n\nas an example scenario, in an effort to answer the question: what percentage of our client base came from which lead source. then, of the social media aquired clients, how many came from facebook? what was the average length of time that client was a customer for? and what are the main reason for cancelation by percentage.\n\nIs this a monumental task? I'm not even sure of the order of magnitude of this project? is this a 50K project, 500K, 5 Million? ", "author_fullname": "t2_rd1blz3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating and understanding the customer journey over time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ynly9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692749936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am very new to data science so i was hoping explain how a business with separate databases for CRM, Social media platforms, SEO, VOIP call data, , 1 containing crm data, 1 containing SEO data, one from voip call data, &lt;/p&gt;\n\n&lt;p&gt;as an example scenario, in an effort to answer the question: what percentage of our client base came from which lead source. then, of the social media aquired clients, how many came from facebook? what was the average length of time that client was a customer for? and what are the main reason for cancelation by percentage.&lt;/p&gt;\n\n&lt;p&gt;Is this a monumental task? I&amp;#39;m not even sure of the order of magnitude of this project? is this a 50K project, 500K, 5 Million? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ynly9", "is_robot_indexable": true, "report_reasons": null, "author": "Rxjim", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ynly9/creating_and_understanding_the_customer_journey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ynly9/creating_and_understanding_the_customer_journey/", "subreddit_subscribers": 124248, "created_utc": 1692749936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does the version of Apache spark always match pyspark? I.e if I\u2019m using spark 3.1.1, is pyspark versioning consistent and the version to use is 3.1.1? Is this preinstalled with Apache spark or do I have to manually install? What happens if I use a different version of pyspark compared to spark?", "author_fullname": "t2_fqm3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache spark vs pyspark version", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yfrt4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692732219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does the version of Apache spark always match pyspark? I.e if I\u2019m using spark 3.1.1, is pyspark versioning consistent and the version to use is 3.1.1? Is this preinstalled with Apache spark or do I have to manually install? What happens if I use a different version of pyspark compared to spark?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yfrt4", "is_robot_indexable": true, "report_reasons": null, "author": "Bigchip01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yfrt4/apache_spark_vs_pyspark_version/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yfrt4/apache_spark_vs_pyspark_version/", "subreddit_subscribers": 124248, "created_utc": 1692732219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically I've got a docker container running a Flask app that access a postgres database that's hosted in RDS (for now I've got a config file that gets copied over which contains details to access the database, I know there's better ways to include this connection info). The app simply serves as an API in which users can route to /search and enter in a few keywords and using text-search a bunch of data gets returned from the database.\n\nNow I can test this docker container locally and everything works fine and dandy but when I try to deploy it using ECS I'm stuck because the container does indeed deploy on EC2 instance and I have logs turned on so I know that it's ready to go, but I just can't access the endpoint through either the private IP, public EC2 ip, or anything of that sort.\n\nThe container is hosted on port 8080 I have tried and opened that port up but I feel like I'm not doing that part properly, so I'm not sure how to add this security group rule in.\n\nThings I have tried:\n\n* Opening up the instance (added in an inbound rule) to allow all ipv4 traffic. Didn't work\n\nI have three different subnets all in one VPC and the instance is hosted in one of the subnets. I don't think the subnets are private, I never configured them to be private, they should be public subnets (if that is the default).\n\nCan someone point me to some guidance for this issue, I've been stuck for around 2 days now.", "author_fullname": "t2_5692by6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having difficulties deploying a docker container of a Flask app using ECR, ECS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ypazx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692754247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically I&amp;#39;ve got a docker container running a Flask app that access a postgres database that&amp;#39;s hosted in RDS (for now I&amp;#39;ve got a config file that gets copied over which contains details to access the database, I know there&amp;#39;s better ways to include this connection info). The app simply serves as an API in which users can route to /search and enter in a few keywords and using text-search a bunch of data gets returned from the database.&lt;/p&gt;\n\n&lt;p&gt;Now I can test this docker container locally and everything works fine and dandy but when I try to deploy it using ECS I&amp;#39;m stuck because the container does indeed deploy on EC2 instance and I have logs turned on so I know that it&amp;#39;s ready to go, but I just can&amp;#39;t access the endpoint through either the private IP, public EC2 ip, or anything of that sort.&lt;/p&gt;\n\n&lt;p&gt;The container is hosted on port 8080 I have tried and opened that port up but I feel like I&amp;#39;m not doing that part properly, so I&amp;#39;m not sure how to add this security group rule in.&lt;/p&gt;\n\n&lt;p&gt;Things I have tried:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Opening up the instance (added in an inbound rule) to allow all ipv4 traffic. Didn&amp;#39;t work&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have three different subnets all in one VPC and the instance is hosted in one of the subnets. I don&amp;#39;t think the subnets are private, I never configured them to be private, they should be public subnets (if that is the default).&lt;/p&gt;\n\n&lt;p&gt;Can someone point me to some guidance for this issue, I&amp;#39;ve been stuck for around 2 days now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ypazx", "is_robot_indexable": true, "report_reasons": null, "author": "anasp1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ypazx/having_difficulties_deploying_a_docker_container/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ypazx/having_difficulties_deploying_a_docker_container/", "subreddit_subscribers": 124248, "created_utc": 1692754247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why is informatica_cloud not popular for scheduling tool? What are it\u2019s limitations?", "author_fullname": "t2_or3d5mgi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Limitations of informatica_cloud as scheduler?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yp0yj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692753515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why is informatica_cloud not popular for scheduling tool? What are it\u2019s limitations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yp0yj", "is_robot_indexable": true, "report_reasons": null, "author": "Grand-Doughnut721", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yp0yj/limitations_of_informatica_cloud_as_scheduler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yp0yj/limitations_of_informatica_cloud_as_scheduler/", "subreddit_subscribers": 124248, "created_utc": 1692753515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all how can I query azure synapse SQL pool programmatically using JavaScript? My JavaScript to have the the SQL query and plug it in and get back results in JSON format", "author_fullname": "t2_5nctfhe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to query azure synapse SQL pool programmatically?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yh676", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692735252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all how can I query azure synapse SQL pool programmatically using JavaScript? My JavaScript to have the the SQL query and plug it in and get back results in JSON format&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yh676", "is_robot_indexable": true, "report_reasons": null, "author": "ZealousidealRich7460", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yh676/is_it_possible_to_query_azure_synapse_sql_pool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yh676/is_it_possible_to_query_azure_synapse_sql_pool/", "subreddit_subscribers": 124248, "created_utc": 1692735252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been tasked with running a PoC project migrating a large data warehouse in AWS Redshift to Snowflake.\n\nDoes anyone have any experience of doing similar projects/tasks? What was a good method? Any pitfalls to be wary of? \n\nCurrently, I\u2019ve considered using Snowpipe and a stage to automate data transfer to Snowflake. Trying to brainstorm for different methods, so any help would be much appreciated! Thank you!", "author_fullname": "t2_a3m6qw38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any experience migrating data warehouse from Redshift to Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yf3yn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692730840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been tasked with running a PoC project migrating a large data warehouse in AWS Redshift to Snowflake.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience of doing similar projects/tasks? What was a good method? Any pitfalls to be wary of? &lt;/p&gt;\n\n&lt;p&gt;Currently, I\u2019ve considered using Snowpipe and a stage to automate data transfer to Snowflake. Trying to brainstorm for different methods, so any help would be much appreciated! Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yf3yn", "is_robot_indexable": true, "report_reasons": null, "author": "sk808mafia", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yf3yn/any_experience_migrating_data_warehouse_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yf3yn/any_experience_migrating_data_warehouse_from/", "subreddit_subscribers": 124248, "created_utc": 1692730840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Also any other titles that\u2019s similar to DE?\nThank you!", "author_fullname": "t2_kggujlwp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some stepping stone titles to DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yeeip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692729326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Also any other titles that\u2019s similar to DE?\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15yeeip", "is_robot_indexable": true, "report_reasons": null, "author": "kitkat_predict", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yeeip/what_are_some_stepping_stone_titles_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yeeip/what_are_some_stepping_stone_titles_to_de/", "subreddit_subscribers": 124248, "created_utc": 1692729326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Keen to hear from anyone using OLAP dbs like clickhouse, pinot or druid. What traditional dbs/services do you use alongside for datawarehouses, if any? ", "author_fullname": "t2_a55s8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using Druid?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yb7ax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692722493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Keen to hear from anyone using OLAP dbs like clickhouse, pinot or druid. What traditional dbs/services do you use alongside for datawarehouses, if any? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yb7ax", "is_robot_indexable": true, "report_reasons": null, "author": "peeyushu", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yb7ax/anyone_using_druid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yb7ax/anyone_using_druid/", "subreddit_subscribers": 124248, "created_utc": 1692722493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nI just interviewed with a new company for a Data Engineer II position, and the next step of the process is a Coderbyte test of 55 minutes which I have to complete within 10 days.\n\nIt's 45 questions + 1 SQL exercise, and the recruiter informed me that the topics will be (verbatim):\n\n1. Software engineering + database concepts\n2. Distributed systems (engine) and big data (noSQL DB)\n3. Machine learning (very little)\n\nGiven this, what advice would you give me in order to best prepare for it and what materials to check to brush up on theory?\n\nThanks in advance!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coderbyte assessment for new job. Advice to prepare?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ya8bj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692720414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I just interviewed with a new company for a Data Engineer II position, and the next step of the process is a Coderbyte test of 55 minutes which I have to complete within 10 days.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s 45 questions + 1 SQL exercise, and the recruiter informed me that the topics will be (verbatim):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Software engineering + database concepts&lt;/li&gt;\n&lt;li&gt;Distributed systems (engine) and big data (noSQL DB)&lt;/li&gt;\n&lt;li&gt;Machine learning (very little)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Given this, what advice would you give me in order to best prepare for it and what materials to check to brush up on theory?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15ya8bj", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ya8bj/coderbyte_assessment_for_new_job_advice_to_prepare/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ya8bj/coderbyte_assessment_for_new_job_advice_to_prepare/", "subreddit_subscribers": 124248, "created_utc": 1692720414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8colxic0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploy and configure Grafana to visualize GitHub data on Koyeb", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_15y908c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xpBKgoQtNaY2AXuUuTNIGe7mS31o8MLNaY3vb6UTIRc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692717838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "koyeb.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.koyeb.com/tutorials/deploy-and-configure-grafana-to-visualize-github-data-on-koyeb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?auto=webp&amp;s=e88a63f450f1239d64d1e15f84a1b2fe9498d9cd", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3f9ca585f5893f8706ad71235d56fb673ab1980c", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e17bb7cf2bf790c1e2f9dd1a9477afb15f07b48f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=78ae3862e3b9eb867edf92c76bba667e972d6648", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d301b340517cf1ea2dd64cc871ae5caed35e5b3b", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a3c6ed648cf7c81d92e6792850a7105d25f67059", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b049440b64f26ef2a6ab62cc1ef1afd728765caa", "width": 1080, "height": 607}], "variants": {}, "id": "gJDqOYvBWHoq2WQ3uqgN21RDy60Tir2IYQuIRZsvXPI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15y908c", "is_robot_indexable": true, "report_reasons": null, "author": "Plus_Ad7909", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y908c/deploy_and_configure_grafana_to_visualize_github/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.koyeb.com/tutorials/deploy-and-configure-grafana-to-visualize-github-data-on-koyeb", "subreddit_subscribers": 124248, "created_utc": 1692717838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All. We want to try out airflow at my organization and plan to use Astronomer. I'm thinking about where to put the actual DAGs that we will run. The two choices seem to be:\n\n1. Add a \"dags\" folder to an existing repository\n\n2. Create a new repository called my-project-dags\n\nThe second option seems much cleaner to deploy to modify and deploy. Most of our projects are deployed with Heroku. So I don't want to have an option to deploy to Heroku, and to astronomer. What do you think? Does that make sense?", "author_fullname": "t2_1zkaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adding Airflow/DAGs for existing project - use separate repository?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15y8myd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692717059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All. We want to try out airflow at my organization and plan to use Astronomer. I&amp;#39;m thinking about where to put the actual DAGs that we will run. The two choices seem to be:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Add a &amp;quot;dags&amp;quot; folder to an existing repository&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Create a new repository called my-project-dags&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The second option seems much cleaner to deploy to modify and deploy. Most of our projects are deployed with Heroku. So I don&amp;#39;t want to have an option to deploy to Heroku, and to astronomer. What do you think? Does that make sense?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15y8myd", "is_robot_indexable": true, "report_reasons": null, "author": "caseym", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y8myd/adding_airflowdags_for_existing_project_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15y8myd/adding_airflowdags_for_existing_project_use/", "subreddit_subscribers": 124248, "created_utc": 1692717059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I started a new job as a DE a week and  a half ago and I was absolutely shocked when I laid my eyes on the codebase. My predecessor, wrote the pipeline in the most old fashion way. Doing everything in her power not to use python data libraries only sql. She only use python as an automation framework, loading json objects to the db in multiple nested loops (endless). there are 4 databases! which 3 of them are staging because she apparently, I'm guessing, did not have any the desire or knowledge to write readable code and only rely on sql, which is fine but there are so many stages. For each of her 100 lines of code i can make them 10. But the logic is so vastly nested, barley readable, module inside a module and functions inside function, it's like a black hole. The data volume is small yet there are hundreds of tables, hundreds of stored procedures and hundreds of views and insane sql quries. \n\nI really don't know how to approach this. I think it's a bad idea to refactor the existing codebase, I'm still very new and barley understand the business. There is a backend developer which handled the stuff until I arrived that shares my opinions which is helping to get on my feet.\n\nI thought maybe I can just try to build (very slowly - over a period of several months) new pipelines from scratch which are \"sensible\" by trying to rely on reports and bi system as a compose and build a new db based on what's there.\n\nOr I should just maintain the current codebase (which is not the easiest on it's own ) and new pipelines i'll do in my  own way.\n\nWhat do you guys think?\n\nSorry about the rant.", "author_fullname": "t2_74acgcia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inherited Legacy/Spaghetti Codebase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yfx2r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692732548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I started a new job as a DE a week and  a half ago and I was absolutely shocked when I laid my eyes on the codebase. My predecessor, wrote the pipeline in the most old fashion way. Doing everything in her power not to use python data libraries only sql. She only use python as an automation framework, loading json objects to the db in multiple nested loops (endless). there are 4 databases! which 3 of them are staging because she apparently, I&amp;#39;m guessing, did not have any the desire or knowledge to write readable code and only rely on sql, which is fine but there are so many stages. For each of her 100 lines of code i can make them 10. But the logic is so vastly nested, barley readable, module inside a module and functions inside function, it&amp;#39;s like a black hole. The data volume is small yet there are hundreds of tables, hundreds of stored procedures and hundreds of views and insane sql quries. &lt;/p&gt;\n\n&lt;p&gt;I really don&amp;#39;t know how to approach this. I think it&amp;#39;s a bad idea to refactor the existing codebase, I&amp;#39;m still very new and barley understand the business. There is a backend developer which handled the stuff until I arrived that shares my opinions which is helping to get on my feet.&lt;/p&gt;\n\n&lt;p&gt;I thought maybe I can just try to build (very slowly - over a period of several months) new pipelines from scratch which are &amp;quot;sensible&amp;quot; by trying to rely on reports and bi system as a compose and build a new db based on what&amp;#39;s there.&lt;/p&gt;\n\n&lt;p&gt;Or I should just maintain the current codebase (which is not the easiest on it&amp;#39;s own ) and new pipelines i&amp;#39;ll do in my  own way.&lt;/p&gt;\n\n&lt;p&gt;What do you guys think?&lt;/p&gt;\n\n&lt;p&gt;Sorry about the rant.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yfx2r", "is_robot_indexable": true, "report_reasons": null, "author": "smallhero333", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yfx2r/inherited_legacyspaghetti_codebase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yfx2r/inherited_legacyspaghetti_codebase/", "subreddit_subscribers": 124248, "created_utc": 1692732548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 3 yoe as software engineer and I worked on python mainly. Recently I have completed the de-zoomcamp and alo some udemy courses and have started applying for interviews, but the hr asks for professional experience and I say that I have done a course then they tell that they will mail the jd and cut the call. There is no mail received.\nHas anyone switched their role like this? Or any guidance how can I overcome this would help. Thank you \ud83d\ude4f", "author_fullname": "t2_4hecp9t0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does someone get a chance to sit for interview in India if they have upskilled themselves and don't have actual professional experience in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yqyyg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692758663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 3 yoe as software engineer and I worked on python mainly. Recently I have completed the de-zoomcamp and alo some udemy courses and have started applying for interviews, but the hr asks for professional experience and I say that I have done a course then they tell that they will mail the jd and cut the call. There is no mail received.\nHas anyone switched their role like this? Or any guidance how can I overcome this would help. Thank you \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yqyyg", "is_robot_indexable": true, "report_reasons": null, "author": "IllustriousPeak4648", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yqyyg/how_does_someone_get_a_chance_to_sit_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yqyyg/how_does_someone_get_a_chance_to_sit_for/", "subreddit_subscribers": 124248, "created_utc": 1692758663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Question to the DE community**: Would you like to use a user-friendly data science analytics platform if we open-source it? Lyzr is to data analysts and business users what Streamlit is to data scientists and ML engineers.\n\nWe're on the verge of launching an open-source version of our new insights platform, www.lyzr.ai, explicitly crafted with the analyst community in mind, and we'd be honored if you could test it and share your invaluable feedback. It may currently seem like a mere GPT wrapper, but trust us, countless hours and dedication have gone into making this more than just that.\n\n**Why did we create it?**\n\nThere is just 1 data scientist for every 100 data analysts (as per GCP data analytics head). We envision a world where data analysts and business users have the tools to dabble more in to data science. Our platform also aims to simplify the 0-75th percentile of descriptive statistics for data scientists, allowing them to concentrate on building more complicated data science models. Plus, for the business folks, it's user-friendly!\n\nThe cherry on top? We're gearing towards an open-source launch. We believe in the power of collective genius and want everyone to benefit from what we've built and further enhance it collaboratively.\n\nPlease let me know if you are interested in giving it a spin. Will DM the link.\n\nAnd let us know what you think! What features resonate with you? What's missing? Would you use it if open-sourced?\n\nYour feedback will not only be appreciated, but it'll also be instrumental in shaping the future of this platform.\n\nThank you and looking forward to your insights!", "author_fullname": "t2_jja2oywp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What if data engineers could do data science with an open-source tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ygjre", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692733930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Question to the DE community&lt;/strong&gt;: Would you like to use a user-friendly data science analytics platform if we open-source it? Lyzr is to data analysts and business users what Streamlit is to data scientists and ML engineers.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re on the verge of launching an open-source version of our new insights platform, &lt;a href=\"http://www.lyzr.ai\"&gt;www.lyzr.ai&lt;/a&gt;, explicitly crafted with the analyst community in mind, and we&amp;#39;d be honored if you could test it and share your invaluable feedback. It may currently seem like a mere GPT wrapper, but trust us, countless hours and dedication have gone into making this more than just that.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why did we create it?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;There is just 1 data scientist for every 100 data analysts (as per GCP data analytics head). We envision a world where data analysts and business users have the tools to dabble more in to data science. Our platform also aims to simplify the 0-75th percentile of descriptive statistics for data scientists, allowing them to concentrate on building more complicated data science models. Plus, for the business folks, it&amp;#39;s user-friendly!&lt;/p&gt;\n\n&lt;p&gt;The cherry on top? We&amp;#39;re gearing towards an open-source launch. We believe in the power of collective genius and want everyone to benefit from what we&amp;#39;ve built and further enhance it collaboratively.&lt;/p&gt;\n\n&lt;p&gt;Please let me know if you are interested in giving it a spin. Will DM the link.&lt;/p&gt;\n\n&lt;p&gt;And let us know what you think! What features resonate with you? What&amp;#39;s missing? Would you use it if open-sourced?&lt;/p&gt;\n\n&lt;p&gt;Your feedback will not only be appreciated, but it&amp;#39;ll also be instrumental in shaping the future of this platform.&lt;/p&gt;\n\n&lt;p&gt;Thank you and looking forward to your insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XQMkKV3c7NOb1LkELwLSqc8GzbktFS933X5QqkoPVto.jpg?auto=webp&amp;s=0b4909795e09887b33b82b21bbc05f6d5cb98dcf", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/XQMkKV3c7NOb1LkELwLSqc8GzbktFS933X5QqkoPVto.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=65eab12503dc5c3de17cd03ba858ad3efe5d7fea", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/XQMkKV3c7NOb1LkELwLSqc8GzbktFS933X5QqkoPVto.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ece502ee0024f1e93c282c79574bc4467015923b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/XQMkKV3c7NOb1LkELwLSqc8GzbktFS933X5QqkoPVto.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6e770a5fc663034e5c373866e270fa9537a679a5", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/XQMkKV3c7NOb1LkELwLSqc8GzbktFS933X5QqkoPVto.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bc228bd049c44106380e5d7170239adab5f837f2", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/XQMkKV3c7NOb1LkELwLSqc8GzbktFS933X5QqkoPVto.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2978c78d44cea835caecc2d6cae11ac6bd33e977", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/XQMkKV3c7NOb1LkELwLSqc8GzbktFS933X5QqkoPVto.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f2845d3b3c8434407f37fcad2d81172188b1849a", "width": 1080, "height": 567}], "variants": {}, "id": "3R7bRcjkmCgVRlR7hRrs-GOyShSKV4NMsVIXteFHvGY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15ygjre", "is_robot_indexable": true, "report_reasons": null, "author": "sivasurendira", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ygjre/what_if_data_engineers_could_do_data_science_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ygjre/what_if_data_engineers_could_do_data_science_with/", "subreddit_subscribers": 124248, "created_utc": 1692733930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Saw this article about Python in Excel, and it reminded me of my good ol\u2019 days in Excel and Access.\n\nCan\u2019t wait to see what business users whip up next with this!!\n\nhttps://techcommunity.microsoft.com/t5/excel-blog/announcing-python-in-excel-combining-the-power-of-python-and-the/ba-p/3893439", "author_fullname": "t2_9g2mgwx8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Excel will always be my favorite database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15y6nnc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.31, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692712690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Saw this article about Python in Excel, and it reminded me of my good ol\u2019 days in Excel and Access.&lt;/p&gt;\n\n&lt;p&gt;Can\u2019t wait to see what business users whip up next with this!!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://techcommunity.microsoft.com/t5/excel-blog/announcing-python-in-excel-combining-the-power-of-python-and-the/ba-p/3893439\"&gt;https://techcommunity.microsoft.com/t5/excel-blog/announcing-python-in-excel-combining-the-power-of-python-and-the/ba-p/3893439&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UgFfFi6TEzGVbDgnDrd1HHWFgYUywpMCJR47hgYMWzM.jpg?auto=webp&amp;s=a90f7862fdbe9d5a78b8b7daa2caa1f60d244520", "width": 999, "height": 562}, "resolutions": [{"url": "https://external-preview.redd.it/UgFfFi6TEzGVbDgnDrd1HHWFgYUywpMCJR47hgYMWzM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=87c97dad07b61bcbf92769ac734af5688999dd40", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/UgFfFi6TEzGVbDgnDrd1HHWFgYUywpMCJR47hgYMWzM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d66d763e48a11b273eab52788cb4c5d03eb4ce4", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/UgFfFi6TEzGVbDgnDrd1HHWFgYUywpMCJR47hgYMWzM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=45e3f88b214277306aaa3a3798c814c979570d8d", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/UgFfFi6TEzGVbDgnDrd1HHWFgYUywpMCJR47hgYMWzM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=673eba04a35efa177455af30e538ed46012fbbe5", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/UgFfFi6TEzGVbDgnDrd1HHWFgYUywpMCJR47hgYMWzM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6920bc45e78cb7b5dbf218670e6cf78515f77fae", "width": 960, "height": 540}], "variants": {}, "id": "Uz1arDxus1ALe0fiVEJBejwjdC_XPbK6f8adnJjqtck"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15y6nnc", "is_robot_indexable": true, "report_reasons": null, "author": "Business_You9930", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y6nnc/excel_will_always_be_my_favorite_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15y6nnc/excel_will_always_be_my_favorite_database/", "subreddit_subscribers": 124248, "created_utc": 1692712690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I spent most of my career focused on data science, but I'm being strongly considered for a cool data engineering role. DEs have taken me under their wing for multiple projects, so I have a lot of familiarity with different tasks I'll need to do. The problem is that I've mostly worked at companies where the data engineers cut a lot of corners and didn't follow best practices. As a result, I don't feel confident that I'm solid in my understanding of data modeling and data warehousing.\n\nWhat's the most effective way to quickly learn the best practices and first principles of data warehousing and data modeling?", "author_fullname": "t2_3pnmt3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need to BS my way through an interview for a DE position. What's the fastest way to learn the first principles and best practices of data warehousing and data modeling?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yh4pr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.09, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692735163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I spent most of my career focused on data science, but I&amp;#39;m being strongly considered for a cool data engineering role. DEs have taken me under their wing for multiple projects, so I have a lot of familiarity with different tasks I&amp;#39;ll need to do. The problem is that I&amp;#39;ve mostly worked at companies where the data engineers cut a lot of corners and didn&amp;#39;t follow best practices. As a result, I don&amp;#39;t feel confident that I&amp;#39;m solid in my understanding of data modeling and data warehousing.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the most effective way to quickly learn the best practices and first principles of data warehousing and data modeling?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15yh4pr", "is_robot_indexable": true, "report_reasons": null, "author": "im_most_likely_lyin", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yh4pr/i_need_to_bs_my_way_through_an_interview_for_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yh4pr/i_need_to_bs_my_way_through_an_interview_for_a_de/", "subreddit_subscribers": 124248, "created_utc": 1692735163.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}