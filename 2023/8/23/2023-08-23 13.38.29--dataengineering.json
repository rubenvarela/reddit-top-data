{"kind": "Listing", "data": {"after": "t3_15z0etr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I lead a small DE team at a medium sized retailer. Over the years we\u2019ve setup the data platform on GCP, lambda architecture feeding data into BQ with DBT transforms. We\u2019re reaching a point where we\u2019ve pretty much ingested all the data sources used by the business, completed the data models, reverse ETL and automation CI/CD. I\u2019m starting to draw a blank on what business focussed initiatives we should start taking up at this mature stage and would appreciate any thoughts from this community. \n\nSome things I\u2019m considering are improving data quality checks, improving the data catalog and adding more metrics to the semantic layer. \n\nWe\u2019ve already done several rounds of optimisation and cloud cost control so I don\u2019t see much more opportunity there. Most of our data usage in the business is batch focused including ML model training so we don\u2019t really see the need to move to a kappa architecture either.", "author_fullname": "t2_tdne3tqb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do Data Engineers do after the data platform is completely setup and automated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15y7v97", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 127, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 127, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692715403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I lead a small DE team at a medium sized retailer. Over the years we\u2019ve setup the data platform on GCP, lambda architecture feeding data into BQ with DBT transforms. We\u2019re reaching a point where we\u2019ve pretty much ingested all the data sources used by the business, completed the data models, reverse ETL and automation CI/CD. I\u2019m starting to draw a blank on what business focussed initiatives we should start taking up at this mature stage and would appreciate any thoughts from this community. &lt;/p&gt;\n\n&lt;p&gt;Some things I\u2019m considering are improving data quality checks, improving the data catalog and adding more metrics to the semantic layer. &lt;/p&gt;\n\n&lt;p&gt;We\u2019ve already done several rounds of optimisation and cloud cost control so I don\u2019t see much more opportunity there. Most of our data usage in the business is batch focused including ML model training so we don\u2019t really see the need to move to a kappa architecture either.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15y7v97", "is_robot_indexable": true, "report_reasons": null, "author": "Hackerjurassicpark", "discussion_type": null, "num_comments": 124, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y7v97/what_do_data_engineers_do_after_the_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15y7v97/what_do_data_engineers_do_after_the_data_platform/", "subreddit_subscribers": 124300, "created_utc": 1692715403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I made a post last week(I ended up deleting it out of doxing paranoia)about if I should negotiate my offer letter. This being despite already being happy with the offer and knowing it was fair through multiple benchmarking sites. The general vibe for the community I got was to negotiate. But there was a good chunk saying you shouldn't in this market.\n\nAs a result, I ended up negotiating. Majority rules win\n\nI am just a sample size of 1, but they did not rescind the offer and they did increase my compensation. In my case, the adage to always negotiate ended up being true! \n\nI did take the communities advice to tackle the negotiation from a benefits perspective over pure base salary", "author_fullname": "t2_5vqn2nya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Negotiated compensation and they gave it to me!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15y76e4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692715269.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692713868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made a post last week(I ended up deleting it out of doxing paranoia)about if I should negotiate my offer letter. This being despite already being happy with the offer and knowing it was fair through multiple benchmarking sites. The general vibe for the community I got was to negotiate. But there was a good chunk saying you shouldn&amp;#39;t in this market.&lt;/p&gt;\n\n&lt;p&gt;As a result, I ended up negotiating. Majority rules win&lt;/p&gt;\n\n&lt;p&gt;I am just a sample size of 1, but they did not rescind the offer and they did increase my compensation. In my case, the adage to always negotiate ended up being true! &lt;/p&gt;\n\n&lt;p&gt;I did take the communities advice to tackle the negotiation from a benefits perspective over pure base salary&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15y76e4", "is_robot_indexable": true, "report_reasons": null, "author": "recentcurrency", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y76e4/negotiated_compensation_and_they_gave_it_to_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15y76e4/negotiated_compensation_and_they_gave_it_to_me/", "subreddit_subscribers": 124300, "created_utc": 1692713868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been hearing about a growing trend of professionals transitioning from machine learning roles to data engineering. If you're one of them, I'd love to hear your story. What motivated your shift? Was it the nature of the work, the tools, the opportunities, or something else? Sharing your experiences might shed light for others considering a similar transition.", "author_fullname": "t2_92gz2jax", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switching from Machine Learning to Data Engineering: What Sparked Your Change?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yv4bt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692771043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been hearing about a growing trend of professionals transitioning from machine learning roles to data engineering. If you&amp;#39;re one of them, I&amp;#39;d love to hear your story. What motivated your shift? Was it the nature of the work, the tools, the opportunities, or something else? Sharing your experiences might shed light for others considering a similar transition.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yv4bt", "is_robot_indexable": true, "report_reasons": null, "author": "lbluestone", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yv4bt/switching_from_machine_learning_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yv4bt/switching_from_machine_learning_to_data/", "subreddit_subscribers": 124300, "created_utc": 1692771043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just reflecting on my career and how fortunate I feel to have found something I really enjoy doing. \n\nI just think data is so important to civilization, and being able to build proper data pipelines, scalable infrastructure, and accessible data warehousing feels like my calling. \n\nGranted I\u2019ve only been doing this for 5 years, and obviously some days it just feels like work. Anyone feel the same or feel differently?", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you truly enjoy data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yz47k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692784162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just reflecting on my career and how fortunate I feel to have found something I really enjoy doing. &lt;/p&gt;\n\n&lt;p&gt;I just think data is so important to civilization, and being able to build proper data pipelines, scalable infrastructure, and accessible data warehousing feels like my calling. &lt;/p&gt;\n\n&lt;p&gt;Granted I\u2019ve only been doing this for 5 years, and obviously some days it just feels like work. Anyone feel the same or feel differently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15yz47k", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15yz47k/do_you_truly_enjoy_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yz47k/do_you_truly_enjoy_data_engineering/", "subreddit_subscribers": 124300, "created_utc": 1692784162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB and MotherDuck integrate with Cube, the semantic layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15y9niw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SYUxCQ-b7fXsdJGH-t6k7Dq4z3MH_4GbCpxvajbkGAw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692719201.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-duckdb-and-motherduck-integrations", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?auto=webp&amp;s=d9e74c9951a0ca9b8748b30fcd26d61984b9f495", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78c65da2229c2a06c9e1e15e6ab743b582f5fa66", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=750b81dbd3c1336b92e3cd5b30e4aee59c09e7a3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7347cd2bea2cb6d188c6e744f12d349f9ee9d9c9", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17ce70691a42b55daefd48aca5deeb612ae7a347", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fb432cb27316771b2ffaa95d88392040ce02060d", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/vp4pQj1HwD0IVbXjh47EsvR6DvukVHMDD-GBp7UeuOQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2eaff949d7f0202118355837e60b6e744520bcdf", "width": 1080, "height": 567}], "variants": {}, "id": "NA3Tk-5z5mSP4jvk5MtiXFoH2Injkrx8AV0tAS78fZw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15y9niw", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y9niw/duckdb_and_motherduck_integrate_with_cube_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-duckdb-and-motherduck-integrations", "subreddit_subscribers": 124300, "created_utc": 1692719201.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For the data engineer coding screen, you likely will face algorithmic challenges as opposed to real world challenges such as loading a csv file. You should be comfortable with python basic and intermediate challenges. The below are the minimum skills you will need to master in order to succeed at a data engineering python coding screen.\n\nBe sure you are spending time learning the correct type of challenges:    \n\n\nhttps://medium.com/@seancoyne/what-data-structures-and-algorithms-should-a-data-engineer-study-a6a0cad90c31", "author_fullname": "t2_4fpl974m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Data Structures and Algorithms Should a Data Engineer Study?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yq7r6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1692756621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the data engineer coding screen, you likely will face algorithmic challenges as opposed to real world challenges such as loading a csv file. You should be comfortable with python basic and intermediate challenges. The below are the minimum skills you will need to master in order to succeed at a data engineering python coding screen.&lt;/p&gt;\n\n&lt;p&gt;Be sure you are spending time learning the correct type of challenges:    &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@seancoyne/what-data-structures-and-algorithms-should-a-data-engineer-study-a6a0cad90c31\"&gt;https://medium.com/@seancoyne/what-data-structures-and-algorithms-should-a-data-engineer-study-a6a0cad90c31&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?auto=webp&amp;s=0b8ce54b015da02eadf1e76e29538682a3de225e", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=12702677546e70a583242489e494289a3d8b2309", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2a593b41cbc8dde11955870d27b796125e769b33", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1a3d1a4deba3fd417e7861f7b9947518c26d384", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0022684a4b486b94bef7b92ac05f39af462affc4", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ae23fb869ac65ef5af87265ba85561393b48b3c2", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7d31aa155654c934ac021eb4620ed769a0c2cd22", "width": 1080, "height": 720}], "variants": {}, "id": "6P-G4uLnVEC6BsKb55gXEiv1BIKiM-nl5g9H53Dd9Is"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15yq7r6", "is_robot_indexable": true, "report_reasons": null, "author": "coyne_operated", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yq7r6/what_data_structures_and_algorithms_should_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yq7r6/what_data_structures_and_algorithms_should_a_data/", "subreddit_subscribers": 124300, "created_utc": 1692756621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Mehcanical/manufacturing engineer turned data analyst/data engineer through lots of at-home training and job hopping. I work for a manufacturing company, My goal is to give engineers, analysts, and management as much machine, process, and quality data as possible.\n\nThere have been some setbacks with this being a new space in manufacturing. I'm not much of a controls engineer so I'm often left waiting for the already spread thin controls team to program and/or grab the variables I need. From the IT end, I'm waiting on implementation of a historian and an operator app. But the real problem that I just can't seem to find the solution too... how do I organize the data?!?\n\nInitially, I started out by only gathering the basics. Good and bad quality counts, uptimes, and cycle times. The pieces needed to get OEE. However, my building is pretty unique in that it has the most futuristic one piece flow automated lines. Data is easy to extract from the PLCs and OEE is easy to aggregate at the machine and work center level. We are also the newest and so we don't really have an ERP or MES. We basically get POs from another building and our plant manager builds a rough week by week schedule in Excel that seems to change daily.\n\nI wanted to propose creation of a scheduling system that would align with other facilities. This is where I fell down a deep deep rabbit hole.\n\nFirst of all not every site is continuous manufacturing, some sites are discrete. Additionally, some sites use ERPs to schedule, others have dedicated scheduling software. Some organize data by work centers, others use assets. Some just live and die by production orders. \n\nHow does a normal manufacturing facility organize OEE data and eventually machine sensor data (both quality and machine health related).\n\nThings can be organized by time (hour, shift, day, week) which I find valuable for downtime and the reasons associated, by cell/work center, by routing, by work order, by part name. The list goes on and on. It just seems like there are so many wheels and cogs. How does it all typically connect?", "author_fullname": "t2_fgc39", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data engineers in the world of manufacturing? What is your stack and how is data at your company organized?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yqw7o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692758448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mehcanical/manufacturing engineer turned data analyst/data engineer through lots of at-home training and job hopping. I work for a manufacturing company, My goal is to give engineers, analysts, and management as much machine, process, and quality data as possible.&lt;/p&gt;\n\n&lt;p&gt;There have been some setbacks with this being a new space in manufacturing. I&amp;#39;m not much of a controls engineer so I&amp;#39;m often left waiting for the already spread thin controls team to program and/or grab the variables I need. From the IT end, I&amp;#39;m waiting on implementation of a historian and an operator app. But the real problem that I just can&amp;#39;t seem to find the solution too... how do I organize the data?!?&lt;/p&gt;\n\n&lt;p&gt;Initially, I started out by only gathering the basics. Good and bad quality counts, uptimes, and cycle times. The pieces needed to get OEE. However, my building is pretty unique in that it has the most futuristic one piece flow automated lines. Data is easy to extract from the PLCs and OEE is easy to aggregate at the machine and work center level. We are also the newest and so we don&amp;#39;t really have an ERP or MES. We basically get POs from another building and our plant manager builds a rough week by week schedule in Excel that seems to change daily.&lt;/p&gt;\n\n&lt;p&gt;I wanted to propose creation of a scheduling system that would align with other facilities. This is where I fell down a deep deep rabbit hole.&lt;/p&gt;\n\n&lt;p&gt;First of all not every site is continuous manufacturing, some sites are discrete. Additionally, some sites use ERPs to schedule, others have dedicated scheduling software. Some organize data by work centers, others use assets. Some just live and die by production orders. &lt;/p&gt;\n\n&lt;p&gt;How does a normal manufacturing facility organize OEE data and eventually machine sensor data (both quality and machine health related).&lt;/p&gt;\n\n&lt;p&gt;Things can be organized by time (hour, shift, day, week) which I find valuable for downtime and the reasons associated, by cell/work center, by routing, by work order, by part name. The list goes on and on. It just seems like there are so many wheels and cogs. How does it all typically connect?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yqw7o", "is_robot_indexable": true, "report_reasons": null, "author": "TheOnlinePolak", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yqw7o/any_data_engineers_in_the_world_of_manufacturing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yqw7o/any_data_engineers_in_the_world_of_manufacturing/", "subreddit_subscribers": 124300, "created_utc": 1692758448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to have an overview/monitoring/analytics/whatever we call it about what data from our warehouse is actually used, by who, what applications and how often. \n\nIs there any technical solution/concept/framework/whatever for that? I am aware of some data catalogs but that is not really what I need. Maybe some data lineage tool? But that is pretty difficult to set up and have it correct/updated. \n\nHow do you solve this?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data usage monitoring/analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yvsh5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692773228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to have an overview/monitoring/analytics/whatever we call it about what data from our warehouse is actually used, by who, what applications and how often. &lt;/p&gt;\n\n&lt;p&gt;Is there any technical solution/concept/framework/whatever for that? I am aware of some data catalogs but that is not really what I need. Maybe some data lineage tool? But that is pretty difficult to set up and have it correct/updated. &lt;/p&gt;\n\n&lt;p&gt;How do you solve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yvsh5", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yvsh5/data_usage_monitoringanalytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yvsh5/data_usage_monitoringanalytics/", "subreddit_subscribers": 124300, "created_utc": 1692773228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company, clients send their required products in a mail or a text message, We then have to check for those products from our csv file in excel manually. This wastes a lot of time, How can I make this process easier with some automation or a better approach/process?", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I automate searching a csv file in excel?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z0o9k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692788839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company, clients send their required products in a mail or a text message, We then have to check for those products from our csv file in excel manually. This wastes a lot of time, How can I make this process easier with some automation or a better approach/process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15z0o9k", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z0o9k/how_do_i_automate_searching_a_csv_file_in_excel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z0o9k/how_do_i_automate_searching_a_csv_file_in_excel/", "subreddit_subscribers": 124300, "created_utc": 1692788839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Could someone give me advice on a quicker way to land a job in the industry? I've heard that starting as a Data Analyst is a good way to go. I'm unsure whether it's better to start as a Data Analyst to enter the industry more quickly or to focus all my studies on Data Engineering. What do you thing?", "author_fullname": "t2_83g86vz0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting as a Data Analyst for Faster Job Entry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yv5sb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692771177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could someone give me advice on a quicker way to land a job in the industry? I&amp;#39;ve heard that starting as a Data Analyst is a good way to go. I&amp;#39;m unsure whether it&amp;#39;s better to start as a Data Analyst to enter the industry more quickly or to focus all my studies on Data Engineering. What do you thing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yv5sb", "is_robot_indexable": true, "report_reasons": null, "author": "Davidalmaz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yv5sb/starting_as_a_data_analyst_for_faster_job_entry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yv5sb/starting_as_a_data_analyst_for_faster_job_entry/", "subreddit_subscribers": 124300, "created_utc": 1692771177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does the version of Apache spark always match pyspark? I.e if I\u2019m using spark 3.1.1, is pyspark versioning consistent and the version to use is 3.1.1? Is this preinstalled with Apache spark or do I have to manually install? What happens if I use a different version of pyspark compared to spark?", "author_fullname": "t2_fqm3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache spark vs pyspark version", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yfrt4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692732219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does the version of Apache spark always match pyspark? I.e if I\u2019m using spark 3.1.1, is pyspark versioning consistent and the version to use is 3.1.1? Is this preinstalled with Apache spark or do I have to manually install? What happens if I use a different version of pyspark compared to spark?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yfrt4", "is_robot_indexable": true, "report_reasons": null, "author": "Bigchip01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yfrt4/apache_spark_vs_pyspark_version/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yfrt4/apache_spark_vs_pyspark_version/", "subreddit_subscribers": 124300, "created_utc": 1692732219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Keen to hear from anyone using OLAP dbs like clickhouse, pinot or druid. What traditional dbs/services do you use alongside for datawarehouses, if any? ", "author_fullname": "t2_a55s8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using Druid?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yb7ax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692722493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Keen to hear from anyone using OLAP dbs like clickhouse, pinot or druid. What traditional dbs/services do you use alongside for datawarehouses, if any? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yb7ax", "is_robot_indexable": true, "report_reasons": null, "author": "peeyushu", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yb7ax/anyone_using_druid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yb7ax/anyone_using_druid/", "subreddit_subscribers": 124300, "created_utc": 1692722493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My colleague just wrote up an article on [LLM-based apps and how to use data engineering tools to help build them faster](https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/) that I found really insightful.\n\nIt contains a complete implementation\n\n* with scraping context data from a docs website\n* chunking it, getting embeddings via the openAI API\n* loading it into pinecone\n* and finally a simple Q&amp;A interface with streamlit on top of it\n\n**Here's a quick summary:**\n\n* LangChain and LlamaIndex are great tools for quick exploration\n* But aren't perfect for production-grade use\n* I think we all know the \"LangChain is pointless\" debate, but there's a lot of real meat to it, and Pat describes a few of them (a lot of LangChains extractors are super basic, 2-3 liners without retries etc.)\n* LLM applications are all about moving data, extracting and enriching data (creating embeddings!) are the most expensive ones of those steps\n* A bunch of data engineering tools are out there that make these two steps much easier, versionable, robust, and reproducible.\n* Meltano is one such tool and Pat implemented the above described pipeline with it\n\n**FWIW**: The GitHub project that comes with the post is super easy to run and super modular. I just tested it and was able to modify everything for my own application within 30 mins.", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LLM Apps Are Mostly Data Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z0ogw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692788855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My colleague just wrote up an article on &lt;a href=\"https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/\"&gt;LLM-based apps and how to use data engineering tools to help build them faster&lt;/a&gt; that I found really insightful.&lt;/p&gt;\n\n&lt;p&gt;It contains a complete implementation&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;with scraping context data from a docs website&lt;/li&gt;\n&lt;li&gt;chunking it, getting embeddings via the openAI API&lt;/li&gt;\n&lt;li&gt;loading it into pinecone&lt;/li&gt;\n&lt;li&gt;and finally a simple Q&amp;amp;A interface with streamlit on top of it&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Here&amp;#39;s a quick summary:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;LangChain and LlamaIndex are great tools for quick exploration&lt;/li&gt;\n&lt;li&gt;But aren&amp;#39;t perfect for production-grade use&lt;/li&gt;\n&lt;li&gt;I think we all know the &amp;quot;LangChain is pointless&amp;quot; debate, but there&amp;#39;s a lot of real meat to it, and Pat describes a few of them (a lot of LangChains extractors are super basic, 2-3 liners without retries etc.)&lt;/li&gt;\n&lt;li&gt;LLM applications are all about moving data, extracting and enriching data (creating embeddings!) are the most expensive ones of those steps&lt;/li&gt;\n&lt;li&gt;A bunch of data engineering tools are out there that make these two steps much easier, versionable, robust, and reproducible.&lt;/li&gt;\n&lt;li&gt;Meltano is one such tool and Pat implemented the above described pipeline with it&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;FWIW&lt;/strong&gt;: The GitHub project that comes with the post is super easy to run and super modular. I just tested it and was able to modify everything for my own application within 30 mins.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?auto=webp&amp;s=fc02ae969049700f816ec5973f65423a7d1d1ea7", "width": 2048, "height": 1365}, "resolutions": [{"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75fad2ff68a9a259f10874b9ae14b106c3dc10b0", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5bb8ed0d61a745ffba2145a2afd59060329df23b", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31f092f9ea961fca60f2bd41b3b2bca128f1b764", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7ea9c1fd2a442e2f882a977c349e052dd38e3d8a", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f7f9cbdb42b35eddc88336a41397ff952ff455c2", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=646b4a3168958ec2520a6910a70d921e302e3d03", "width": 1080, "height": 719}], "variants": {}, "id": "E08iLDz2f8z0dIDW6N3H1Mna-8Iqh0WwcWMLsrVaqWo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15z0ogw", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z0ogw/llm_apps_are_mostly_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z0ogw/llm_apps_are_mostly_data_pipelines/", "subreddit_subscribers": 124300, "created_utc": 1692788855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I'm trying to share tables with product/non technical people and at the moment what we do is send manually files that are then uploaded to excel and consumed.\nIs there any product out there that provides excel/pivot like functionality that connects directly to Snowflake? Was looking at sigmacomputing.com, anyone has any less expensive solutions?", "author_fullname": "t2_axgif", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplest way to have a pivot like UI on a table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yxw7t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692780204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;m trying to share tables with product/non technical people and at the moment what we do is send manually files that are then uploaded to excel and consumed.\nIs there any product out there that provides excel/pivot like functionality that connects directly to Snowflake? Was looking at sigmacomputing.com, anyone has any less expensive solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yxw7t", "is_robot_indexable": true, "report_reasons": null, "author": "Batto1300", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yxw7t/simplest_way_to_have_a_pivot_like_ui_on_a_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yxw7t/simplest_way_to_have_a_pivot_like_ui_on_a_table/", "subreddit_subscribers": 124300, "created_utc": 1692780204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically I've got a docker container running a Flask app that access a postgres database that's hosted in RDS (for now I've got a config file that gets copied over which contains details to access the database, I know there's better ways to include this connection info). The app simply serves as an API in which users can route to /search and enter in a few keywords and using text-search a bunch of data gets returned from the database.\n\nNow I can test this docker container locally and everything works fine and dandy but when I try to deploy it using ECS I'm stuck because the container does indeed deploy on EC2 instance and I have logs turned on so I know that it's ready to go, but I just can't access the endpoint through either the private IP, public EC2 ip, or anything of that sort.\n\nThe container is hosted on port 8080 I have tried and opened that port up but I feel like I'm not doing that part properly, so I'm not sure how to add this security group rule in.\n\nThings I have tried:\n\n* Opening up the instance (added in an inbound rule) to allow all ipv4 traffic. Didn't work\n\nI have three different subnets all in one VPC and the instance is hosted in one of the subnets. I don't think the subnets are private, I never configured them to be private, they should be public subnets (if that is the default).\n\nCan someone point me to some guidance for this issue, I've been stuck for around 2 days now.", "author_fullname": "t2_5692by6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having difficulties deploying a docker container of a Flask app using ECR, ECS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ypazx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692754247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically I&amp;#39;ve got a docker container running a Flask app that access a postgres database that&amp;#39;s hosted in RDS (for now I&amp;#39;ve got a config file that gets copied over which contains details to access the database, I know there&amp;#39;s better ways to include this connection info). The app simply serves as an API in which users can route to /search and enter in a few keywords and using text-search a bunch of data gets returned from the database.&lt;/p&gt;\n\n&lt;p&gt;Now I can test this docker container locally and everything works fine and dandy but when I try to deploy it using ECS I&amp;#39;m stuck because the container does indeed deploy on EC2 instance and I have logs turned on so I know that it&amp;#39;s ready to go, but I just can&amp;#39;t access the endpoint through either the private IP, public EC2 ip, or anything of that sort.&lt;/p&gt;\n\n&lt;p&gt;The container is hosted on port 8080 I have tried and opened that port up but I feel like I&amp;#39;m not doing that part properly, so I&amp;#39;m not sure how to add this security group rule in.&lt;/p&gt;\n\n&lt;p&gt;Things I have tried:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Opening up the instance (added in an inbound rule) to allow all ipv4 traffic. Didn&amp;#39;t work&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have three different subnets all in one VPC and the instance is hosted in one of the subnets. I don&amp;#39;t think the subnets are private, I never configured them to be private, they should be public subnets (if that is the default).&lt;/p&gt;\n\n&lt;p&gt;Can someone point me to some guidance for this issue, I&amp;#39;ve been stuck for around 2 days now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ypazx", "is_robot_indexable": true, "report_reasons": null, "author": "anasp1", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ypazx/having_difficulties_deploying_a_docker_container/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ypazx/having_difficulties_deploying_a_docker_container/", "subreddit_subscribers": 124300, "created_utc": 1692754247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why is informatica_cloud not popular for scheduling tool? What are it\u2019s limitations?", "author_fullname": "t2_or3d5mgi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Limitations of informatica_cloud as scheduler?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yp0yj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692753515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why is informatica_cloud not popular for scheduling tool? What are it\u2019s limitations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yp0yj", "is_robot_indexable": true, "report_reasons": null, "author": "Grand-Doughnut721", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yp0yj/limitations_of_informatica_cloud_as_scheduler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yp0yj/limitations_of_informatica_cloud_as_scheduler/", "subreddit_subscribers": 124300, "created_utc": 1692753515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am very new to data science so i was hoping explain how a business with separate databases for CRM, Social media platforms, SEO, VOIP call data, , 1 containing crm data, 1 containing SEO data, one from voip call data, \n\nas an example scenario, in an effort to answer the question: what percentage of our client base came from which lead source. then, of the social media aquired clients, how many came from facebook? what was the average length of time that client was a customer for? and what are the main reason for cancelation by percentage.\n\nIs this a monumental task? I'm not even sure of the order of magnitude of this project? is this a 50K project, 500K, 5 Million? ", "author_fullname": "t2_rd1blz3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating and understanding the customer journey over time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ynly9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692749936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am very new to data science so i was hoping explain how a business with separate databases for CRM, Social media platforms, SEO, VOIP call data, , 1 containing crm data, 1 containing SEO data, one from voip call data, &lt;/p&gt;\n\n&lt;p&gt;as an example scenario, in an effort to answer the question: what percentage of our client base came from which lead source. then, of the social media aquired clients, how many came from facebook? what was the average length of time that client was a customer for? and what are the main reason for cancelation by percentage.&lt;/p&gt;\n\n&lt;p&gt;Is this a monumental task? I&amp;#39;m not even sure of the order of magnitude of this project? is this a 50K project, 500K, 5 Million? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ynly9", "is_robot_indexable": true, "report_reasons": null, "author": "Rxjim", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ynly9/creating_and_understanding_the_customer_journey/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ynly9/creating_and_understanding_the_customer_journey/", "subreddit_subscribers": 124300, "created_utc": 1692749936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all how can I query azure synapse SQL pool programmatically using JavaScript? My JavaScript to have the the SQL query and plug it in and get back results in JSON format", "author_fullname": "t2_5nctfhe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to query azure synapse SQL pool programmatically?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yh676", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692735252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all how can I query azure synapse SQL pool programmatically using JavaScript? My JavaScript to have the the SQL query and plug it in and get back results in JSON format&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yh676", "is_robot_indexable": true, "report_reasons": null, "author": "ZealousidealRich7460", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yh676/is_it_possible_to_query_azure_synapse_sql_pool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yh676/is_it_possible_to_query_azure_synapse_sql_pool/", "subreddit_subscribers": 124300, "created_utc": 1692735252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I started a new job as a DE a week and  a half ago and I was absolutely shocked when I laid my eyes on the codebase. My predecessor, wrote the pipeline in the most old fashion way. Doing everything in her power not to use python data libraries only sql. She only use python as an automation framework, loading json objects to the db in multiple nested loops (endless). there are 4 databases! which 3 of them are staging because she apparently, I'm guessing, did not have any the desire or knowledge to write readable code and only rely on sql, which is fine but there are so many stages. For each of her 100 lines of code i can make them 10. But the logic is so vastly nested, barley readable, module inside a module and functions inside function, it's like a black hole. The data volume is small yet there are hundreds of tables, hundreds of stored procedures and hundreds of views and insane sql quries. \n\nI really don't know how to approach this. I think it's a bad idea to refactor the existing codebase, I'm still very new and barley understand the business. There is a backend developer which handled the stuff until I arrived that shares my opinions which is helping to get on my feet.\n\nI thought maybe I can just try to build (very slowly - over a period of several months) new pipelines from scratch which are \"sensible\" by trying to rely on reports and bi system as a compose and build a new db based on what's there.\n\nOr I should just maintain the current codebase (which is not the easiest on it's own ) and new pipelines i'll do in my  own way.\n\nWhat do you guys think?\n\nSorry about the rant.", "author_fullname": "t2_74acgcia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inherited Legacy/Spaghetti Codebase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yfx2r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692732548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I started a new job as a DE a week and  a half ago and I was absolutely shocked when I laid my eyes on the codebase. My predecessor, wrote the pipeline in the most old fashion way. Doing everything in her power not to use python data libraries only sql. She only use python as an automation framework, loading json objects to the db in multiple nested loops (endless). there are 4 databases! which 3 of them are staging because she apparently, I&amp;#39;m guessing, did not have any the desire or knowledge to write readable code and only rely on sql, which is fine but there are so many stages. For each of her 100 lines of code i can make them 10. But the logic is so vastly nested, barley readable, module inside a module and functions inside function, it&amp;#39;s like a black hole. The data volume is small yet there are hundreds of tables, hundreds of stored procedures and hundreds of views and insane sql quries. &lt;/p&gt;\n\n&lt;p&gt;I really don&amp;#39;t know how to approach this. I think it&amp;#39;s a bad idea to refactor the existing codebase, I&amp;#39;m still very new and barley understand the business. There is a backend developer which handled the stuff until I arrived that shares my opinions which is helping to get on my feet.&lt;/p&gt;\n\n&lt;p&gt;I thought maybe I can just try to build (very slowly - over a period of several months) new pipelines from scratch which are &amp;quot;sensible&amp;quot; by trying to rely on reports and bi system as a compose and build a new db based on what&amp;#39;s there.&lt;/p&gt;\n\n&lt;p&gt;Or I should just maintain the current codebase (which is not the easiest on it&amp;#39;s own ) and new pipelines i&amp;#39;ll do in my  own way.&lt;/p&gt;\n\n&lt;p&gt;What do you guys think?&lt;/p&gt;\n\n&lt;p&gt;Sorry about the rant.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yfx2r", "is_robot_indexable": true, "report_reasons": null, "author": "smallhero333", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yfx2r/inherited_legacyspaghetti_codebase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yfx2r/inherited_legacyspaghetti_codebase/", "subreddit_subscribers": 124300, "created_utc": 1692732548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been tasked with running a PoC project migrating a large data warehouse in AWS Redshift to Snowflake.\n\nDoes anyone have any experience of doing similar projects/tasks? What was a good method? Any pitfalls to be wary of? \n\nCurrently, I\u2019ve considered using Snowpipe and a stage to automate data transfer to Snowflake. Trying to brainstorm for different methods, so any help would be much appreciated! Thank you!", "author_fullname": "t2_a3m6qw38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any experience migrating data warehouse from Redshift to Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yf3yn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692730840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been tasked with running a PoC project migrating a large data warehouse in AWS Redshift to Snowflake.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience of doing similar projects/tasks? What was a good method? Any pitfalls to be wary of? &lt;/p&gt;\n\n&lt;p&gt;Currently, I\u2019ve considered using Snowpipe and a stage to automate data transfer to Snowflake. Trying to brainstorm for different methods, so any help would be much appreciated! Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yf3yn", "is_robot_indexable": true, "report_reasons": null, "author": "sk808mafia", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yf3yn/any_experience_migrating_data_warehouse_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yf3yn/any_experience_migrating_data_warehouse_from/", "subreddit_subscribers": 124300, "created_utc": 1692730840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Also any other titles that\u2019s similar to DE?\nThank you!", "author_fullname": "t2_kggujlwp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some stepping stone titles to DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yeeip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692729326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Also any other titles that\u2019s similar to DE?\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15yeeip", "is_robot_indexable": true, "report_reasons": null, "author": "kitkat_predict", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yeeip/what_are_some_stepping_stone_titles_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yeeip/what_are_some_stepping_stone_titles_to_de/", "subreddit_subscribers": 124300, "created_utc": 1692729326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nI just interviewed with a new company for a Data Engineer II position, and the next step of the process is a Coderbyte test of 55 minutes which I have to complete within 10 days.\n\nIt's 45 questions + 1 SQL exercise, and the recruiter informed me that the topics will be (verbatim):\n\n1. Software engineering + database concepts\n2. Distributed systems (engine) and big data (noSQL DB)\n3. Machine learning (very little)\n\nGiven this, what advice would you give me in order to best prepare for it and what materials to check to brush up on theory?\n\nThanks in advance!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coderbyte assessment for new job. Advice to prepare?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ya8bj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692720414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I just interviewed with a new company for a Data Engineer II position, and the next step of the process is a Coderbyte test of 55 minutes which I have to complete within 10 days.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s 45 questions + 1 SQL exercise, and the recruiter informed me that the topics will be (verbatim):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Software engineering + database concepts&lt;/li&gt;\n&lt;li&gt;Distributed systems (engine) and big data (noSQL DB)&lt;/li&gt;\n&lt;li&gt;Machine learning (very little)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Given this, what advice would you give me in order to best prepare for it and what materials to check to brush up on theory?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15ya8bj", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ya8bj/coderbyte_assessment_for_new_job_advice_to_prepare/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ya8bj/coderbyte_assessment_for_new_job_advice_to_prepare/", "subreddit_subscribers": 124300, "created_utc": 1692720414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8colxic0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploy and configure Grafana to visualize GitHub data on Koyeb", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_15y908c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xpBKgoQtNaY2AXuUuTNIGe7mS31o8MLNaY3vb6UTIRc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692717838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "koyeb.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.koyeb.com/tutorials/deploy-and-configure-grafana-to-visualize-github-data-on-koyeb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?auto=webp&amp;s=e88a63f450f1239d64d1e15f84a1b2fe9498d9cd", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3f9ca585f5893f8706ad71235d56fb673ab1980c", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e17bb7cf2bf790c1e2f9dd1a9477afb15f07b48f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=78ae3862e3b9eb867edf92c76bba667e972d6648", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d301b340517cf1ea2dd64cc871ae5caed35e5b3b", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a3c6ed648cf7c81d92e6792850a7105d25f67059", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/0xmxGXvZ1PMSnn8pErZm2BY8HsyHf6xueA2WNoXD-fg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b049440b64f26ef2a6ab62cc1ef1afd728765caa", "width": 1080, "height": 607}], "variants": {}, "id": "gJDqOYvBWHoq2WQ3uqgN21RDy60Tir2IYQuIRZsvXPI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15y908c", "is_robot_indexable": true, "report_reasons": null, "author": "Plus_Ad7909", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y908c/deploy_and_configure_grafana_to_visualize_github/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.koyeb.com/tutorials/deploy-and-configure-grafana-to-visualize-github-data-on-koyeb", "subreddit_subscribers": 124300, "created_utc": 1692717838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All. We want to try out airflow at my organization and plan to use Astronomer. I'm thinking about where to put the actual DAGs that we will run. The two choices seem to be:\n\n1. Add a \"dags\" folder to an existing repository\n\n2. Create a new repository called my-project-dags\n\nThe second option seems much cleaner to deploy to modify and deploy. Most of our projects are deployed with Heroku. So I don't want to have an option to deploy to Heroku, and to astronomer. What do you think? Does that make sense?", "author_fullname": "t2_1zkaz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adding Airflow/DAGs for existing project - use separate repository?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15y8myd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692717059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All. We want to try out airflow at my organization and plan to use Astronomer. I&amp;#39;m thinking about where to put the actual DAGs that we will run. The two choices seem to be:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Add a &amp;quot;dags&amp;quot; folder to an existing repository&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Create a new repository called my-project-dags&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The second option seems much cleaner to deploy to modify and deploy. Most of our projects are deployed with Heroku. So I don&amp;#39;t want to have an option to deploy to Heroku, and to astronomer. What do you think? Does that make sense?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15y8myd", "is_robot_indexable": true, "report_reasons": null, "author": "caseym", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15y8myd/adding_airflowdags_for_existing_project_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15y8myd/adding_airflowdags_for_existing_project_use/", "subreddit_subscribers": 124300, "created_utc": 1692717059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For those who are looking for step by step guide on installing Hadoop onto Macbook M1 and M2, this is the blog I highly refer to. \n\n&amp;#x200B;\n\n[https://pub.towardsai.net/how-to-install-hadoop-on-macbook-m1-or-m2-without-homebrew-or-virtual-machine-ac7c3c5a6ac9](https://pub.towardsai.net/how-to-install-hadoop-on-macbook-m1-or-m2-without-homebrew-or-virtual-machine-ac7c3c5a6ac9)\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_qey30ci0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Install Hadoop in latest Macbook?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z0etr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692788102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those who are looking for step by step guide on installing Hadoop onto Macbook M1 and M2, this is the blog I highly refer to. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pub.towardsai.net/how-to-install-hadoop-on-macbook-m1-or-m2-without-homebrew-or-virtual-machine-ac7c3c5a6ac9\"&gt;https://pub.towardsai.net/how-to-install-hadoop-on-macbook-m1-or-m2-without-homebrew-or-virtual-machine-ac7c3c5a6ac9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/INO51OiJJ3m4uJhQSZ479filry4czwmns-1izSU8CmM.jpg?auto=webp&amp;s=0037a5d4bc5a5b96b39ab0d38502613996c26c06", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/INO51OiJJ3m4uJhQSZ479filry4czwmns-1izSU8CmM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ee812109e315bff14c4e548d7f6570a3bb779cee", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/INO51OiJJ3m4uJhQSZ479filry4czwmns-1izSU8CmM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=192788df49f5c97dd595e5f1e5947524cee8469d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/INO51OiJJ3m4uJhQSZ479filry4czwmns-1izSU8CmM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dcbe54c6100dc9e3790d903320ec5bd90f50eaef", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/INO51OiJJ3m4uJhQSZ479filry4czwmns-1izSU8CmM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=833b3dd37730cc6422b514798006e06dfd595135", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/INO51OiJJ3m4uJhQSZ479filry4czwmns-1izSU8CmM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f4caf1fa2d70d2fab3e4e549de6fcb65648f1e8", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/INO51OiJJ3m4uJhQSZ479filry4czwmns-1izSU8CmM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aaa8fde9835b9ef9cb926ae3b05c20bb00a40376", "width": 1080, "height": 540}], "variants": {}, "id": "Y6G9RnBY52uDzLHa2kEwUk6Y979RQ09Z1etwbuphR4Q"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15z0etr", "is_robot_indexable": true, "report_reasons": null, "author": "bodhishankara", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z0etr/how_to_install_hadoop_in_latest_macbook/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z0etr/how_to_install_hadoop_in_latest_macbook/", "subreddit_subscribers": 124300, "created_utc": 1692788102.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}