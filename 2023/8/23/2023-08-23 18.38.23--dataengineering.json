{"kind": "Listing", "data": {"after": "t3_15yeeip", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just reflecting on my career and how fortunate I feel to have found something I really enjoy doing. \n\nI just think data is so important to civilization, and being able to build proper data pipelines, scalable infrastructure, and accessible data warehousing feels like my calling. \n\nGranted I\u2019ve only been doing this for 5 years, and obviously some days it just feels like work. Anyone feel the same or feel differently?", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you truly enjoy data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yz47k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692784162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just reflecting on my career and how fortunate I feel to have found something I really enjoy doing. &lt;/p&gt;\n\n&lt;p&gt;I just think data is so important to civilization, and being able to build proper data pipelines, scalable infrastructure, and accessible data warehousing feels like my calling. &lt;/p&gt;\n\n&lt;p&gt;Granted I\u2019ve only been doing this for 5 years, and obviously some days it just feels like work. Anyone feel the same or feel differently?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15yz47k", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15yz47k/do_you_truly_enjoy_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yz47k/do_you_truly_enjoy_data_engineering/", "subreddit_subscribers": 124359, "created_utc": 1692784162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been hearing about a growing trend of professionals transitioning from machine learning roles to data engineering. If you're one of them, I'd love to hear your story. What motivated your shift? Was it the nature of the work, the tools, the opportunities, or something else? Sharing your experiences might shed light for others considering a similar transition.", "author_fullname": "t2_92gz2jax", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switching from Machine Learning to Data Engineering: What Sparked Your Change?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yv4bt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692771043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been hearing about a growing trend of professionals transitioning from machine learning roles to data engineering. If you&amp;#39;re one of them, I&amp;#39;d love to hear your story. What motivated your shift? Was it the nature of the work, the tools, the opportunities, or something else? Sharing your experiences might shed light for others considering a similar transition.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yv4bt", "is_robot_indexable": true, "report_reasons": null, "author": "lbluestone", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yv4bt/switching_from_machine_learning_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yv4bt/switching_from_machine_learning_to_data/", "subreddit_subscribers": 124359, "created_utc": 1692771043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My colleague just wrote up an article on [LLM-based apps and how to use data engineering tools to help build them faster](https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/) that I found really insightful.\n\nIt contains a complete implementation\n\n* with scraping context data from a docs website\n* chunking it, getting embeddings via the openAI API\n* loading it into pinecone\n* and finally a simple Q&amp;A interface with streamlit on top of it\n\n**Here's a quick summary:**\n\n* LangChain and LlamaIndex are great tools for quick exploration\n* But aren't perfect for production-grade use\n* I think we all know the \"LangChain is pointless\" debate, but there's a lot of real meat to it, and Pat describes a few of them (a lot of LangChains extractors are super basic, 2-3 liners without retries etc.)\n* LLM applications are all about moving data, extracting and enriching data (creating embeddings!) are the most expensive ones of those steps\n* A bunch of data engineering tools are out there that make these two steps much easier, versionable, robust, and reproducible.\n* Meltano is one such tool and Pat implemented the above described pipeline with it\n\n**FWIW**: The GitHub project that comes with the post is super easy to run and super modular. I just tested it and was able to modify everything for my own application within 30 mins.", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LLM Apps Are Mostly Data Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z0ogw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692788855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My colleague just wrote up an article on &lt;a href=\"https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/\"&gt;LLM-based apps and how to use data engineering tools to help build them faster&lt;/a&gt; that I found really insightful.&lt;/p&gt;\n\n&lt;p&gt;It contains a complete implementation&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;with scraping context data from a docs website&lt;/li&gt;\n&lt;li&gt;chunking it, getting embeddings via the openAI API&lt;/li&gt;\n&lt;li&gt;loading it into pinecone&lt;/li&gt;\n&lt;li&gt;and finally a simple Q&amp;amp;A interface with streamlit on top of it&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Here&amp;#39;s a quick summary:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;LangChain and LlamaIndex are great tools for quick exploration&lt;/li&gt;\n&lt;li&gt;But aren&amp;#39;t perfect for production-grade use&lt;/li&gt;\n&lt;li&gt;I think we all know the &amp;quot;LangChain is pointless&amp;quot; debate, but there&amp;#39;s a lot of real meat to it, and Pat describes a few of them (a lot of LangChains extractors are super basic, 2-3 liners without retries etc.)&lt;/li&gt;\n&lt;li&gt;LLM applications are all about moving data, extracting and enriching data (creating embeddings!) are the most expensive ones of those steps&lt;/li&gt;\n&lt;li&gt;A bunch of data engineering tools are out there that make these two steps much easier, versionable, robust, and reproducible.&lt;/li&gt;\n&lt;li&gt;Meltano is one such tool and Pat implemented the above described pipeline with it&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;FWIW&lt;/strong&gt;: The GitHub project that comes with the post is super easy to run and super modular. I just tested it and was able to modify everything for my own application within 30 mins.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?auto=webp&amp;s=fc02ae969049700f816ec5973f65423a7d1d1ea7", "width": 2048, "height": 1365}, "resolutions": [{"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=75fad2ff68a9a259f10874b9ae14b106c3dc10b0", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5bb8ed0d61a745ffba2145a2afd59060329df23b", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31f092f9ea961fca60f2bd41b3b2bca128f1b764", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7ea9c1fd2a442e2f882a977c349e052dd38e3d8a", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f7f9cbdb42b35eddc88336a41397ff952ff455c2", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/1wCBkBeg9Ag5snRO0rOLvTqnzPzXZMCiyg3_cr1tvQ0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=646b4a3168958ec2520a6910a70d921e302e3d03", "width": 1080, "height": 719}], "variants": {}, "id": "E08iLDz2f8z0dIDW6N3H1Mna-8Iqh0WwcWMLsrVaqWo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15z0ogw", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z0ogw/llm_apps_are_mostly_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z0ogw/llm_apps_are_mostly_data_pipelines/", "subreddit_subscribers": 124359, "created_utc": 1692788855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggests I am curious of how folks develop scala-spark applications locally. \n\nI've been playing around with 2 ways:\n\n1. Let Intellij do the heavy lifting and use an Intellij Application runtime configuration that (I think) spins up a spark cluster in its own JVM on my local machine. I then use Big Data Tools plugin to monitor jobs or just go to the web UI directly.\n\n2. Run a local k8s cluster (via docker desktop) and use the bitnami helm chart to create a spark cluster on k8s. Then use spark-submit from my local machine and monitor the jobs via the web UI after port forwarding. I haven't found a way to surface the spark connection in Big Data Tools this way, unfortunately. \n\n\nFor test source data I create a Kafka producer that generates random data conforming to a schema via the Big Data Tools plugin. \n\nFor sinks, I either just print to std out or create up an output Kafka topic/data warehouse depending on the pipeline. \n\nWhat is your workflow?\n\n\nEdit: bonus points for those who harness the power of Intellij(I don't use it's features enough). It looks like the Spark Submit Local runtime configuration is deprecated though :/", "author_fullname": "t2_13z9km", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark local development workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z6okz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692806321.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692803581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests I am curious of how folks develop scala-spark applications locally. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been playing around with 2 ways:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Let Intellij do the heavy lifting and use an Intellij Application runtime configuration that (I think) spins up a spark cluster in its own JVM on my local machine. I then use Big Data Tools plugin to monitor jobs or just go to the web UI directly.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Run a local k8s cluster (via docker desktop) and use the bitnami helm chart to create a spark cluster on k8s. Then use spark-submit from my local machine and monitor the jobs via the web UI after port forwarding. I haven&amp;#39;t found a way to surface the spark connection in Big Data Tools this way, unfortunately. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For test source data I create a Kafka producer that generates random data conforming to a schema via the Big Data Tools plugin. &lt;/p&gt;\n\n&lt;p&gt;For sinks, I either just print to std out or create up an output Kafka topic/data warehouse depending on the pipeline. &lt;/p&gt;\n\n&lt;p&gt;What is your workflow?&lt;/p&gt;\n\n&lt;p&gt;Edit: bonus points for those who harness the power of Intellij(I don&amp;#39;t use it&amp;#39;s features enough). It looks like the Spark Submit Local runtime configuration is deprecated though :/&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15z6okz", "is_robot_indexable": true, "report_reasons": null, "author": "Mozzarella_mario", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z6okz/spark_local_development_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z6okz/spark_local_development_workflow/", "subreddit_subscribers": 124359, "created_utc": 1692803581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For the data engineer coding screen, you likely will face algorithmic challenges as opposed to real world challenges such as loading a csv file. You should be comfortable with python basic and intermediate challenges. The below are the minimum skills you will need to master in order to succeed at a data engineering python coding screen.\n\nBe sure you are spending time learning the correct type of challenges:    \n\n\nhttps://medium.com/@seancoyne/what-data-structures-and-algorithms-should-a-data-engineer-study-a6a0cad90c31", "author_fullname": "t2_4fpl974m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Data Structures and Algorithms Should a Data Engineer Study?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yq7r6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1692756621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the data engineer coding screen, you likely will face algorithmic challenges as opposed to real world challenges such as loading a csv file. You should be comfortable with python basic and intermediate challenges. The below are the minimum skills you will need to master in order to succeed at a data engineering python coding screen.&lt;/p&gt;\n\n&lt;p&gt;Be sure you are spending time learning the correct type of challenges:    &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@seancoyne/what-data-structures-and-algorithms-should-a-data-engineer-study-a6a0cad90c31\"&gt;https://medium.com/@seancoyne/what-data-structures-and-algorithms-should-a-data-engineer-study-a6a0cad90c31&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?auto=webp&amp;s=0b8ce54b015da02eadf1e76e29538682a3de225e", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=12702677546e70a583242489e494289a3d8b2309", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2a593b41cbc8dde11955870d27b796125e769b33", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1a3d1a4deba3fd417e7861f7b9947518c26d384", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0022684a4b486b94bef7b92ac05f39af462affc4", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ae23fb869ac65ef5af87265ba85561393b48b3c2", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/8VDsTX0kSwSbamI5jxfk0ykCzGJFmEdvbFoIg_2Wl6E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7d31aa155654c934ac021eb4620ed769a0c2cd22", "width": 1080, "height": 720}], "variants": {}, "id": "6P-G4uLnVEC6BsKb55gXEiv1BIKiM-nl5g9H53Dd9Is"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15yq7r6", "is_robot_indexable": true, "report_reasons": null, "author": "coyne_operated", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yq7r6/what_data_structures_and_algorithms_should_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yq7r6/what_data_structures_and_algorithms_should_a_data/", "subreddit_subscribers": 124359, "created_utc": 1692756621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious if anyone's had data engineering experience at bloomberg or similar. I'm debating taking an offer from bloomberg (UK) for a data engineer position, while currently working in fintech also as a data engineer.\n\nMy main concerns from having asked questions in the interview process is that the tech is very abstracted, high level, config based tools to build workflows and pipelines. I.e. I would not learn or touch any infra, cloud, spark. So basically just SQL, Python and bloomberg tools. Some tools (airflow, jenkins, kafka) are basically open source equivalents or actual open source tools with a bloomberg wrapper built by their software engineers, which is not as bad I guess.\n\nMy current position is kind of the opposite, a modern open source tech stack with Scala, spark, airflow, GCP, k8s, jenkins, terraform.\n\nCompanies these days seem so fixated on engineers having specific experience in X,Y,Z. I've even been rejected before because I didn't have serverless AWS experience. Are my concerns of using prop tech and lack of spark/cloud/infra valid or would it not matter when I eventually try move from bloomberg elsewhere? Is it a good name to have on the CV?", "author_fullname": "t2_642rl59c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering at Bloomberg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z7eva", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692805178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious if anyone&amp;#39;s had data engineering experience at bloomberg or similar. I&amp;#39;m debating taking an offer from bloomberg (UK) for a data engineer position, while currently working in fintech also as a data engineer.&lt;/p&gt;\n\n&lt;p&gt;My main concerns from having asked questions in the interview process is that the tech is very abstracted, high level, config based tools to build workflows and pipelines. I.e. I would not learn or touch any infra, cloud, spark. So basically just SQL, Python and bloomberg tools. Some tools (airflow, jenkins, kafka) are basically open source equivalents or actual open source tools with a bloomberg wrapper built by their software engineers, which is not as bad I guess.&lt;/p&gt;\n\n&lt;p&gt;My current position is kind of the opposite, a modern open source tech stack with Scala, spark, airflow, GCP, k8s, jenkins, terraform.&lt;/p&gt;\n\n&lt;p&gt;Companies these days seem so fixated on engineers having specific experience in X,Y,Z. I&amp;#39;ve even been rejected before because I didn&amp;#39;t have serverless AWS experience. Are my concerns of using prop tech and lack of spark/cloud/infra valid or would it not matter when I eventually try move from bloomberg elsewhere? Is it a good name to have on the CV?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15z7eva", "is_robot_indexable": true, "report_reasons": null, "author": "SentinelReborn", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z7eva/data_engineering_at_bloomberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z7eva/data_engineering_at_bloomberg/", "subreddit_subscribers": 124359, "created_utc": 1692805178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Mehcanical/manufacturing engineer turned data analyst/data engineer through lots of at-home training and job hopping. I work for a manufacturing company, My goal is to give engineers, analysts, and management as much machine, process, and quality data as possible.\n\nThere have been some setbacks with this being a new space in manufacturing. I'm not much of a controls engineer so I'm often left waiting for the already spread thin controls team to program and/or grab the variables I need. From the IT end, I'm waiting on implementation of a historian and an operator app. But the real problem that I just can't seem to find the solution too... how do I organize the data?!?\n\nInitially, I started out by only gathering the basics. Good and bad quality counts, uptimes, and cycle times. The pieces needed to get OEE. However, my building is pretty unique in that it has the most futuristic one piece flow automated lines. Data is easy to extract from the PLCs and OEE is easy to aggregate at the machine and work center level. We are also the newest and so we don't really have an ERP or MES. We basically get POs from another building and our plant manager builds a rough week by week schedule in Excel that seems to change daily.\n\nI wanted to propose creation of a scheduling system that would align with other facilities. This is where I fell down a deep deep rabbit hole.\n\nFirst of all not every site is continuous manufacturing, some sites are discrete. Additionally, some sites use ERPs to schedule, others have dedicated scheduling software. Some organize data by work centers, others use assets. Some just live and die by production orders. \n\nHow does a normal manufacturing facility organize OEE data and eventually machine sensor data (both quality and machine health related).\n\nThings can be organized by time (hour, shift, day, week) which I find valuable for downtime and the reasons associated, by cell/work center, by routing, by work order, by part name. The list goes on and on. It just seems like there are so many wheels and cogs. How does it all typically connect?", "author_fullname": "t2_fgc39", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data engineers in the world of manufacturing? What is your stack and how is data at your company organized?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yqw7o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692758448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mehcanical/manufacturing engineer turned data analyst/data engineer through lots of at-home training and job hopping. I work for a manufacturing company, My goal is to give engineers, analysts, and management as much machine, process, and quality data as possible.&lt;/p&gt;\n\n&lt;p&gt;There have been some setbacks with this being a new space in manufacturing. I&amp;#39;m not much of a controls engineer so I&amp;#39;m often left waiting for the already spread thin controls team to program and/or grab the variables I need. From the IT end, I&amp;#39;m waiting on implementation of a historian and an operator app. But the real problem that I just can&amp;#39;t seem to find the solution too... how do I organize the data?!?&lt;/p&gt;\n\n&lt;p&gt;Initially, I started out by only gathering the basics. Good and bad quality counts, uptimes, and cycle times. The pieces needed to get OEE. However, my building is pretty unique in that it has the most futuristic one piece flow automated lines. Data is easy to extract from the PLCs and OEE is easy to aggregate at the machine and work center level. We are also the newest and so we don&amp;#39;t really have an ERP or MES. We basically get POs from another building and our plant manager builds a rough week by week schedule in Excel that seems to change daily.&lt;/p&gt;\n\n&lt;p&gt;I wanted to propose creation of a scheduling system that would align with other facilities. This is where I fell down a deep deep rabbit hole.&lt;/p&gt;\n\n&lt;p&gt;First of all not every site is continuous manufacturing, some sites are discrete. Additionally, some sites use ERPs to schedule, others have dedicated scheduling software. Some organize data by work centers, others use assets. Some just live and die by production orders. &lt;/p&gt;\n\n&lt;p&gt;How does a normal manufacturing facility organize OEE data and eventually machine sensor data (both quality and machine health related).&lt;/p&gt;\n\n&lt;p&gt;Things can be organized by time (hour, shift, day, week) which I find valuable for downtime and the reasons associated, by cell/work center, by routing, by work order, by part name. The list goes on and on. It just seems like there are so many wheels and cogs. How does it all typically connect?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yqw7o", "is_robot_indexable": true, "report_reasons": null, "author": "TheOnlinePolak", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yqw7o/any_data_engineers_in_the_world_of_manufacturing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yqw7o/any_data_engineers_in_the_world_of_manufacturing/", "subreddit_subscribers": 124359, "created_utc": 1692758448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cube integrates with LangChain to help build AI-powered experiences on top of the semantic layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15z7jog", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RIrspQi5snD1utGDs2qwlaIWxwI-sHKcOVUZooRtq_o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692805477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-the-langchain-integration", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?auto=webp&amp;s=33a60669ed3e943fcac8c46b9474c54521c027b1", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aa22294bd2c1e554cf05525ea892bd8d433b4dc5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=92e590568456a0557d8043f9de8a9c2c55b30cd5", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f0104a03e6c661de48fa71827af08dd011456f61", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b5b4a7b95ee6de636d14f2ff3c787ca16d5c14f8", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=60df4c40261a407f7dcb41e24e513bd627181b5d", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/3W_pRnvCOJT7e_goQxTKgv_x82KX4GWPI1ZfoFbHpX4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5595dcce2c65382d3a4162e3fd93293985ad9ff4", "width": 1080, "height": 567}], "variants": {}, "id": "dYxJf8pR1ZZdrsed3oKjduh072Vjn8cW_o2GlECcZXc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15z7jog", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z7jog/cube_integrates_with_langchain_to_help_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-the-langchain-integration", "subreddit_subscribers": 124359, "created_utc": 1692805477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to have an overview/monitoring/analytics/whatever we call it about what data from our warehouse is actually used, by who, what applications and how often. \n\nIs there any technical solution/concept/framework/whatever for that? I am aware of some data catalogs but that is not really what I need. Maybe some data lineage tool? But that is pretty difficult to set up and have it correct/updated. \n\nHow do you solve this?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data usage monitoring/analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yvsh5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692773228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to have an overview/monitoring/analytics/whatever we call it about what data from our warehouse is actually used, by who, what applications and how often. &lt;/p&gt;\n\n&lt;p&gt;Is there any technical solution/concept/framework/whatever for that? I am aware of some data catalogs but that is not really what I need. Maybe some data lineage tool? But that is pretty difficult to set up and have it correct/updated. &lt;/p&gt;\n\n&lt;p&gt;How do you solve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yvsh5", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yvsh5/data_usage_monitoringanalytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yvsh5/data_usage_monitoringanalytics/", "subreddit_subscribers": 124359, "created_utc": 1692773228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title states, my current job role is just IT support and I have been given two options - to do a certification in either the data or software engineering and I'm not well versed in either.\n\nI'll have to start from scratch, I'm gravitating more towards data engineering side because it seems more interesting and plausible for me since I am originally from a non-IT background as well. Two years in support role has me just googling up stuff or asking colleagues and seniors about things I'm unaware of. \n\nSomehow this switch itself seems almost impossible, but I don't want to give up before putting up a fight.\n\nIn addition I have heard the exam post certification is also extremely difficult and I get only one try - so any sources for in depth study/courses would also be really helpful to me!\n\nTldr: been given two choices and I'm not sure which one to take or if it's even possible.. could it be that they're just looking to lay off...", "author_fullname": "t2_a47y2ora", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I choose software engineer or data engineer certification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z7oi5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692805765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title states, my current job role is just IT support and I have been given two options - to do a certification in either the data or software engineering and I&amp;#39;m not well versed in either.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll have to start from scratch, I&amp;#39;m gravitating more towards data engineering side because it seems more interesting and plausible for me since I am originally from a non-IT background as well. Two years in support role has me just googling up stuff or asking colleagues and seniors about things I&amp;#39;m unaware of. &lt;/p&gt;\n\n&lt;p&gt;Somehow this switch itself seems almost impossible, but I don&amp;#39;t want to give up before putting up a fight.&lt;/p&gt;\n\n&lt;p&gt;In addition I have heard the exam post certification is also extremely difficult and I get only one try - so any sources for in depth study/courses would also be really helpful to me!&lt;/p&gt;\n\n&lt;p&gt;Tldr: been given two choices and I&amp;#39;m not sure which one to take or if it&amp;#39;s even possible.. could it be that they&amp;#39;re just looking to lay off...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15z7oi5", "is_robot_indexable": true, "report_reasons": null, "author": "plum_red", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z7oi5/should_i_choose_software_engineer_or_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z7oi5/should_i_choose_software_engineer_or_data/", "subreddit_subscribers": 124359, "created_utc": 1692805765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been a data engineer for 3 years now with proficient python and SQL experience, also DataOps skills like CI/CD, IaC and Kubernetes.\n\nGot experience with Azure, Airflow and Snowflake. Worked on personal project which was Flask app.\n\nExperienced in building Data platforms from scratch mostly.\n\nI am wondering what is the job market for hybrid DE roles and salary ranges in the US and around NYC specifically.", "author_fullname": "t2_zwapz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering roles in New York or US in general", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z6z0v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692804215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been a data engineer for 3 years now with proficient python and SQL experience, also DataOps skills like CI/CD, IaC and Kubernetes.&lt;/p&gt;\n\n&lt;p&gt;Got experience with Azure, Airflow and Snowflake. Worked on personal project which was Flask app.&lt;/p&gt;\n\n&lt;p&gt;Experienced in building Data platforms from scratch mostly.&lt;/p&gt;\n\n&lt;p&gt;I am wondering what is the job market for hybrid DE roles and salary ranges in the US and around NYC specifically.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15z6z0v", "is_robot_indexable": true, "report_reasons": null, "author": "atf15", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z6z0v/data_engineering_roles_in_new_york_or_us_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z6z0v/data_engineering_roles_in_new_york_or_us_in/", "subreddit_subscribers": 124359, "created_utc": 1692804215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company, clients send their required products in a mail or a text message, We then have to check for those products from our csv file in excel manually. This wastes a lot of time, How can I make this process easier with some automation or a better approach/process?", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I automate searching a csv file in excel?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z0o9k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692788839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company, clients send their required products in a mail or a text message, We then have to check for those products from our csv file in excel manually. This wastes a lot of time, How can I make this process easier with some automation or a better approach/process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15z0o9k", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z0o9k/how_do_i_automate_searching_a_csv_file_in_excel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z0o9k/how_do_i_automate_searching_a_csv_file_in_excel/", "subreddit_subscribers": 124359, "created_utc": 1692788839.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Could someone give me advice on a quicker way to land a job in the industry? I've heard that starting as a Data Analyst is a good way to go. I'm unsure whether it's better to start as a Data Analyst to enter the industry more quickly or to focus all my studies on Data Engineering. What do you thing?", "author_fullname": "t2_83g86vz0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting as a Data Analyst for Faster Job Entry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yv5sb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692771177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could someone give me advice on a quicker way to land a job in the industry? I&amp;#39;ve heard that starting as a Data Analyst is a good way to go. I&amp;#39;m unsure whether it&amp;#39;s better to start as a Data Analyst to enter the industry more quickly or to focus all my studies on Data Engineering. What do you thing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yv5sb", "is_robot_indexable": true, "report_reasons": null, "author": "Davidalmaz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yv5sb/starting_as_a_data_analyst_for_faster_job_entry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yv5sb/starting_as_a_data_analyst_for_faster_job_entry/", "subreddit_subscribers": 124359, "created_utc": 1692771177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does the version of Apache spark always match pyspark? I.e if I\u2019m using spark 3.1.1, is pyspark versioning consistent and the version to use is 3.1.1? Is this preinstalled with Apache spark or do I have to manually install? What happens if I use a different version of pyspark compared to spark?", "author_fullname": "t2_fqm3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache spark vs pyspark version", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yfrt4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692732219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does the version of Apache spark always match pyspark? I.e if I\u2019m using spark 3.1.1, is pyspark versioning consistent and the version to use is 3.1.1? Is this preinstalled with Apache spark or do I have to manually install? What happens if I use a different version of pyspark compared to spark?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yfrt4", "is_robot_indexable": true, "report_reasons": null, "author": "Bigchip01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yfrt4/apache_spark_vs_pyspark_version/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yfrt4/apache_spark_vs_pyspark_version/", "subreddit_subscribers": 124359, "created_utc": 1692732219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm constantly hearing that one of the major issues for data on end2end perspective is data quality. Can you elaborate scenarios what kind or type of data quality defects are you encountering? Is is this more on accuracy or completeness upon entry? Or wrong extract of data type,etc? Is data quality more on transactional or analytics perspective? How do you deal this as data engineer? Is there some kind of pipelines first to validate the ETL?\n\nWould love to get your insights, thanks!", "author_fullname": "t2_hjc1e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Quality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15zay7u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692812607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m constantly hearing that one of the major issues for data on end2end perspective is data quality. Can you elaborate scenarios what kind or type of data quality defects are you encountering? Is is this more on accuracy or completeness upon entry? Or wrong extract of data type,etc? Is data quality more on transactional or analytics perspective? How do you deal this as data engineer? Is there some kind of pipelines first to validate the ETL?&lt;/p&gt;\n\n&lt;p&gt;Would love to get your insights, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15zay7u", "is_robot_indexable": true, "report_reasons": null, "author": "bistek02", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15zay7u/data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15zay7u/data_quality/", "subreddit_subscribers": 124359, "created_utc": 1692812607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nTrying to set up data factory to export large fact tables that are hosted on premises to a storage account. Initially, I would like to transfer everything in the fact table up to today's date (whenever today is in the future) partitioned by date and then load only incremental rows after that.   \n\n\nHas anyone configured something similar? ", "author_fullname": "t2_nu50f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transfer on premises data to storage account", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z7gwc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692805298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;Trying to set up data factory to export large fact tables that are hosted on premises to a storage account. Initially, I would like to transfer everything in the fact table up to today&amp;#39;s date (whenever today is in the future) partitioned by date and then load only incremental rows after that.   &lt;/p&gt;\n\n&lt;p&gt;Has anyone configured something similar? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15z7gwc", "is_robot_indexable": true, "report_reasons": null, "author": "sugarbuzzlightyear", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z7gwc/transfer_on_premises_data_to_storage_account/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z7gwc/transfer_on_premises_data_to_storage_account/", "subreddit_subscribers": 124359, "created_utc": 1692805298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all! I am new to the industry and have recently been tasked with creating a data catalog for my extremely small-sized company. I've scoured high and low for information on data catalog creation, researching the available data catalog tools in the market, both commercial and open source. Unfortunately, my company is not inclined to invest in paid services due to our small size and dataset. Additionally, using open-source data catalogs like Datahub isn't feasible due to certain restrictions we have in place.\n\nI'm contemplating using a traditional approach, utilizing Excel to manage the catalog (though it's manual, given our small scale, it might suffice temporarily). My question is: what information should a data catalog capture? While I've come across numerous websites discussing data catalogs, none seem to provide specific details on the information to be included.\n\nI would greatly appreciate any advice from experienced data engineers! :)\n\nP.S: My data are stored in MySQL, with several tables.", "author_fullname": "t2_ud83ad97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you have in your data catalogs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15z1wj9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692792222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! I am new to the industry and have recently been tasked with creating a data catalog for my extremely small-sized company. I&amp;#39;ve scoured high and low for information on data catalog creation, researching the available data catalog tools in the market, both commercial and open source. Unfortunately, my company is not inclined to invest in paid services due to our small size and dataset. Additionally, using open-source data catalogs like Datahub isn&amp;#39;t feasible due to certain restrictions we have in place.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m contemplating using a traditional approach, utilizing Excel to manage the catalog (though it&amp;#39;s manual, given our small scale, it might suffice temporarily). My question is: what information should a data catalog capture? While I&amp;#39;ve come across numerous websites discussing data catalogs, none seem to provide specific details on the information to be included.&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate any advice from experienced data engineers! :)&lt;/p&gt;\n\n&lt;p&gt;P.S: My data are stored in MySQL, with several tables.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15z1wj9", "is_robot_indexable": true, "report_reasons": null, "author": "DataNewbie88", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15z1wj9/what_do_you_have_in_your_data_catalogs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15z1wj9/what_do_you_have_in_your_data_catalogs/", "subreddit_subscribers": 124359, "created_utc": 1692792222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I'm trying to share tables with product/non technical people and at the moment what we do is send manually files that are then uploaded to excel and consumed.\nIs there any product out there that provides excel/pivot like functionality that connects directly to Snowflake? Was looking at sigmacomputing.com, anyone has any less expensive solutions?", "author_fullname": "t2_axgif", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplest way to have a pivot like UI on a table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yxw7t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692780204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;m trying to share tables with product/non technical people and at the moment what we do is send manually files that are then uploaded to excel and consumed.\nIs there any product out there that provides excel/pivot like functionality that connects directly to Snowflake? Was looking at sigmacomputing.com, anyone has any less expensive solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yxw7t", "is_robot_indexable": true, "report_reasons": null, "author": "Batto1300", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yxw7t/simplest_way_to_have_a_pivot_like_ui_on_a_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yxw7t/simplest_way_to_have_a_pivot_like_ui_on_a_table/", "subreddit_subscribers": 124359, "created_utc": 1692780204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m being involved in a project that will require me to work with message and tasks queues. \n\nFor now I\u2019ve been only working with Redis Streams and RQ (arq specifically) which technical aspects I think I get pretty well but I fail to understand how to decide which tool (message vs tasks queue) should be used for the particular task. \n\nIn the new project I will be involved in designing the architecture so I need to get a better understanding of the queues and their use cases, I guess mostly on a high level. Could you please recommend some resources to learn? Anything including paid courses is okay.", "author_fullname": "t2_2hwuo20b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources to learn message and tasks queues", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ywyhf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692777084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m being involved in a project that will require me to work with message and tasks queues. &lt;/p&gt;\n\n&lt;p&gt;For now I\u2019ve been only working with Redis Streams and RQ (arq specifically) which technical aspects I think I get pretty well but I fail to understand how to decide which tool (message vs tasks queue) should be used for the particular task. &lt;/p&gt;\n\n&lt;p&gt;In the new project I will be involved in designing the architecture so I need to get a better understanding of the queues and their use cases, I guess mostly on a high level. Could you please recommend some resources to learn? Anything including paid courses is okay.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ywyhf", "is_robot_indexable": true, "report_reasons": null, "author": "ppzet9", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ywyhf/resources_to_learn_message_and_tasks_queues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ywyhf/resources_to_learn_message_and_tasks_queues/", "subreddit_subscribers": 124359, "created_utc": 1692777084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically I've got a docker container running a Flask app that access a postgres database that's hosted in RDS (for now I've got a config file that gets copied over which contains details to access the database, I know there's better ways to include this connection info). The app simply serves as an API in which users can route to /search and enter in a few keywords and using text-search a bunch of data gets returned from the database.\n\nNow I can test this docker container locally and everything works fine and dandy but when I try to deploy it using ECS I'm stuck because the container does indeed deploy on EC2 instance and I have logs turned on so I know that it's ready to go, but I just can't access the endpoint through either the private IP, public EC2 ip, or anything of that sort.\n\nThe container is hosted on port 8080 I have tried and opened that port up but I feel like I'm not doing that part properly, so I'm not sure how to add this security group rule in.\n\nThings I have tried:\n\n* Opening up the instance (added in an inbound rule) to allow all ipv4 traffic. Didn't work\n\nI have three different subnets all in one VPC and the instance is hosted in one of the subnets. I don't think the subnets are private, I never configured them to be private, they should be public subnets (if that is the default).\n\nCan someone point me to some guidance for this issue, I've been stuck for around 2 days now.", "author_fullname": "t2_5692by6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having difficulties deploying a docker container of a Flask app using ECR, ECS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ypazx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692754247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically I&amp;#39;ve got a docker container running a Flask app that access a postgres database that&amp;#39;s hosted in RDS (for now I&amp;#39;ve got a config file that gets copied over which contains details to access the database, I know there&amp;#39;s better ways to include this connection info). The app simply serves as an API in which users can route to /search and enter in a few keywords and using text-search a bunch of data gets returned from the database.&lt;/p&gt;\n\n&lt;p&gt;Now I can test this docker container locally and everything works fine and dandy but when I try to deploy it using ECS I&amp;#39;m stuck because the container does indeed deploy on EC2 instance and I have logs turned on so I know that it&amp;#39;s ready to go, but I just can&amp;#39;t access the endpoint through either the private IP, public EC2 ip, or anything of that sort.&lt;/p&gt;\n\n&lt;p&gt;The container is hosted on port 8080 I have tried and opened that port up but I feel like I&amp;#39;m not doing that part properly, so I&amp;#39;m not sure how to add this security group rule in.&lt;/p&gt;\n\n&lt;p&gt;Things I have tried:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Opening up the instance (added in an inbound rule) to allow all ipv4 traffic. Didn&amp;#39;t work&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have three different subnets all in one VPC and the instance is hosted in one of the subnets. I don&amp;#39;t think the subnets are private, I never configured them to be private, they should be public subnets (if that is the default).&lt;/p&gt;\n\n&lt;p&gt;Can someone point me to some guidance for this issue, I&amp;#39;ve been stuck for around 2 days now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ypazx", "is_robot_indexable": true, "report_reasons": null, "author": "anasp1", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ypazx/having_difficulties_deploying_a_docker_container/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ypazx/having_difficulties_deploying_a_docker_container/", "subreddit_subscribers": 124359, "created_utc": 1692754247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why is informatica_cloud not popular for scheduling tool? What are it\u2019s limitations?", "author_fullname": "t2_or3d5mgi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Limitations of informatica_cloud as scheduler?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yp0yj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692753515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why is informatica_cloud not popular for scheduling tool? What are it\u2019s limitations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yp0yj", "is_robot_indexable": true, "report_reasons": null, "author": "Grand-Doughnut721", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yp0yj/limitations_of_informatica_cloud_as_scheduler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yp0yj/limitations_of_informatica_cloud_as_scheduler/", "subreddit_subscribers": 124359, "created_utc": 1692753515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all how can I query azure synapse SQL pool programmatically using JavaScript? My JavaScript to have the the SQL query and plug it in and get back results in JSON format", "author_fullname": "t2_5nctfhe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to query azure synapse SQL pool programmatically?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yh676", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692735252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all how can I query azure synapse SQL pool programmatically using JavaScript? My JavaScript to have the the SQL query and plug it in and get back results in JSON format&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yh676", "is_robot_indexable": true, "report_reasons": null, "author": "ZealousidealRich7460", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yh676/is_it_possible_to_query_azure_synapse_sql_pool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yh676/is_it_possible_to_query_azure_synapse_sql_pool/", "subreddit_subscribers": 124359, "created_utc": 1692735252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I started a new job as a DE a week and  a half ago and I was absolutely shocked when I laid my eyes on the codebase. My predecessor, wrote the pipeline in the most old fashion way. Doing everything in her power not to use python data libraries only sql. She only use python as an automation framework, loading json objects to the db in multiple nested loops (endless). there are 4 databases! which 3 of them are staging because she apparently, I'm guessing, did not have any the desire or knowledge to write readable code and only rely on sql, which is fine but there are so many stages. For each of her 100 lines of code i can make them 10. But the logic is so vastly nested, barley readable, module inside a module and functions inside function, it's like a black hole. The data volume is small yet there are hundreds of tables, hundreds of stored procedures and hundreds of views and insane sql quries. \n\nI really don't know how to approach this. I think it's a bad idea to refactor the existing codebase, I'm still very new and barley understand the business. There is a backend developer which handled the stuff until I arrived that shares my opinions which is helping to get on my feet.\n\nI thought maybe I can just try to build (very slowly - over a period of several months) new pipelines from scratch which are \"sensible\" by trying to rely on reports and bi system as a compose and build a new db based on what's there.\n\nOr I should just maintain the current codebase (which is not the easiest on it's own ) and new pipelines i'll do in my  own way.\n\nWhat do you guys think?\n\nSorry about the rant.", "author_fullname": "t2_74acgcia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Inherited Legacy/Spaghetti Codebase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yfx2r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692732548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I started a new job as a DE a week and  a half ago and I was absolutely shocked when I laid my eyes on the codebase. My predecessor, wrote the pipeline in the most old fashion way. Doing everything in her power not to use python data libraries only sql. She only use python as an automation framework, loading json objects to the db in multiple nested loops (endless). there are 4 databases! which 3 of them are staging because she apparently, I&amp;#39;m guessing, did not have any the desire or knowledge to write readable code and only rely on sql, which is fine but there are so many stages. For each of her 100 lines of code i can make them 10. But the logic is so vastly nested, barley readable, module inside a module and functions inside function, it&amp;#39;s like a black hole. The data volume is small yet there are hundreds of tables, hundreds of stored procedures and hundreds of views and insane sql quries. &lt;/p&gt;\n\n&lt;p&gt;I really don&amp;#39;t know how to approach this. I think it&amp;#39;s a bad idea to refactor the existing codebase, I&amp;#39;m still very new and barley understand the business. There is a backend developer which handled the stuff until I arrived that shares my opinions which is helping to get on my feet.&lt;/p&gt;\n\n&lt;p&gt;I thought maybe I can just try to build (very slowly - over a period of several months) new pipelines from scratch which are &amp;quot;sensible&amp;quot; by trying to rely on reports and bi system as a compose and build a new db based on what&amp;#39;s there.&lt;/p&gt;\n\n&lt;p&gt;Or I should just maintain the current codebase (which is not the easiest on it&amp;#39;s own ) and new pipelines i&amp;#39;ll do in my  own way.&lt;/p&gt;\n\n&lt;p&gt;What do you guys think?&lt;/p&gt;\n\n&lt;p&gt;Sorry about the rant.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15yfx2r", "is_robot_indexable": true, "report_reasons": null, "author": "smallhero333", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yfx2r/inherited_legacyspaghetti_codebase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yfx2r/inherited_legacyspaghetti_codebase/", "subreddit_subscribers": 124359, "created_utc": 1692732548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been tasked with running a PoC project migrating a large data warehouse in AWS Redshift to Snowflake.\n\nDoes anyone have any experience of doing similar projects/tasks? What was a good method? Any pitfalls to be wary of? \n\nCurrently, I\u2019ve considered using Snowpipe and a stage to automate data transfer to Snowflake. Trying to brainstorm for different methods, so any help would be much appreciated! Thank you!", "author_fullname": "t2_a3m6qw38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any experience migrating data warehouse from Redshift to Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yf3yn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692730840.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been tasked with running a PoC project migrating a large data warehouse in AWS Redshift to Snowflake.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience of doing similar projects/tasks? What was a good method? Any pitfalls to be wary of? &lt;/p&gt;\n\n&lt;p&gt;Currently, I\u2019ve considered using Snowpipe and a stage to automate data transfer to Snowflake. Trying to brainstorm for different methods, so any help would be much appreciated! Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15yf3yn", "is_robot_indexable": true, "report_reasons": null, "author": "sk808mafia", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yf3yn/any_experience_migrating_data_warehouse_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yf3yn/any_experience_migrating_data_warehouse_from/", "subreddit_subscribers": 124359, "created_utc": 1692730840.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Also any other titles that\u2019s similar to DE?\nThank you!", "author_fullname": "t2_kggujlwp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some stepping stone titles to DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15yeeip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692729326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Also any other titles that\u2019s similar to DE?\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15yeeip", "is_robot_indexable": true, "report_reasons": null, "author": "kitkat_predict", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15yeeip/what_are_some_stepping_stone_titles_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15yeeip/what_are_some_stepping_stone_titles_to_de/", "subreddit_subscribers": 124359, "created_utc": 1692729326.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}