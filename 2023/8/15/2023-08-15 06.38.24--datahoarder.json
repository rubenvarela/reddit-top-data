{"kind": "Listing", "data": {"after": "t3_15r6h7o", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_1cjqfkwc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internet Archive Responds to Recording Industry Lawsuit Targeting Obsolete Media", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15raa9e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 129, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 129, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1692054304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.archive.org", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.archive.org/2023/08/14/internet-archive-responds-to-recording-industry-lawsuit-targeting-obsolete-media/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DVD", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15raa9e", "is_robot_indexable": true, "report_reasons": null, "author": "koempleh", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15raa9e/internet_archive_responds_to_recording_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.archive.org/2023/08/14/internet-archive-responds-to-recording-industry-lawsuit-targeting-obsolete-media/", "subreddit_subscribers": 698009, "created_utc": 1692054304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_zhl23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD has two (2) 20 TB for $619.98, which comes out to $15.50/TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15qyvxe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 95, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 95, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IKM6X8_teT5K-epE3veCUX-aD0B9QZ7HvCwKfBbb9qE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692029197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "westerndigital.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.westerndigital.com/products/internal-drives/wd-red-pro-sata-hdd#WD201KFGX", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?auto=webp&amp;s=46f8413e6a7bd4c57e1860a28da06b48a5a4229a", "width": 1680, "height": 1680}, "resolutions": [{"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6befa6135d5ea523cf95d4a475ae6c51b727d30", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a915fba1fdcd2bd78dc4d13a65fdaa70d72aac05", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad393e56c5e8ae45d7fc176b39507b65e8505261", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7f6f0c1769e32468b936879516adbd2f4bd8e298", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=59c21b169aac9b5c4297f792d9dc9df2f8dd18fe", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/YjJ8G-B6s1S_QDOVERtwSDUhYzZUi5pI7ZH4h-UHWsM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=267af956f29c0872df1f49031ca70c9cdb661aec", "width": 1080, "height": 1080}], "variants": {}, "id": "6keymE9zpOEX9OFD9sJvRPtVBVor6KjTRLVm8MbwRlA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15qyvxe", "is_robot_indexable": true, "report_reasons": null, "author": "Aviyan", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qyvxe/wd_has_two_2_20_tb_for_61998_which_comes_out_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.westerndigital.com/products/internal-drives/wd-red-pro-sata-hdd#WD201KFGX", "subreddit_subscribers": 698009, "created_utc": 1692029197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "That's the whole Ted talk. I have about 12TB of content from over the years and want to get a NAS setup going and aim for Raid to help prevent bit rot. Is there a noticeable difference in quality and maintenance/long term use with the WD Red nas Hard drive vs the Gold Enterprise Class Imternal drive? Idk if this is a dumbass question but yeah..", "author_fullname": "t2_45v0p27nh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between gold and red quality Western Digital Hard Drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r25wg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692036416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s the whole Ted talk. I have about 12TB of content from over the years and want to get a NAS setup going and aim for Raid to help prevent bit rot. Is there a noticeable difference in quality and maintenance/long term use with the WD Red nas Hard drive vs the Gold Enterprise Class Imternal drive? Idk if this is a dumbass question but yeah..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r25wg", "is_robot_indexable": true, "report_reasons": null, "author": "InitialGuidance5", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r25wg/difference_between_gold_and_red_quality_western/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r25wg/difference_between_gold_and_red_quality_western/", "subreddit_subscribers": 698009, "created_utc": 1692036416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Not sure if I should just start with the giant mess the RMA is now or make this longer by mentioning what happened before...\n\n&amp;#x200B;\n\nAs briefly as comes to mind:\n\n1 - Received a damaged package from Amazon at the end of 2022. (In case someone wants to ask why I was so stupid... the 2nd carried threw out the destroyed packaging and put it in a new box, a family member then received the seemingly pristine shipment.)\n\n2 - Contacted WD about the noise the (external, 16TB) HDD was making. Was told not to worry about it. Assured I could get a replacement during the next 3 years. (Amazon only offered a refund, I waited for that price for a year, ordering again for a much higher price was not acceptable for me.)\n\n3 - Of course, the drive stopped working several months later.\n\n4 - Created RMA on July 18th. Shipped on 21st, delivered to WD's address on 25th.\n\n5 - RMA status updated to \"Received / Processing\" on August 3rd. Checking almost every day, no other updates before or after that (till today, not just 8th). No emails till I contacted them first.\n\n6 - August 8th - Contacted WD (via chat) because of strange info about an undeliverable package (info notice number not working, no shipments linked to my address). Didn't know what else it could be other than the RMA replacement HDD. Talked to 2-3 people (internet stopped working + connected to \"a higher level\", I think), both/all told me the package was not from WD, nothing was sent to me yet, my RMA's accepted and waiting for replacement HDD shipment.\n\n7 - August 9th - Someone's \"taken over my case\", adding the screenshot of the email. Short version - WD definitely didn't ship anything (due to lack of stock), they'll be shipping an 18TB HDD, same model (if I agree). I agreed and addressed the rest. (Asked for the name to be changed to a family member's in the chat the previous day since I was already there, after being told shipment's still TBD, can't go and get it myself because of health issues. Answered \"You mentioned receiving an email about this package\" - Never happened. In the chat, I did mention, many times, receiving an info notice that was not in the carrier's system and wasn't linked to any packages or my address.)\n\n8 - August 10th - Short email summing up/confirming what will be done from WD, the same person (screenshot).\n\n9 - August 11th(sent)/13th(found) - Insane email from somebody new, with a tracking number belonging to a package shipped on August 1st (2 days before my RMA was RECEIVED) to a DIFFERENT CITY, being delivered on the 3rd, to, obviously, NOT ME. Adding screenshots. RMA was, of course, created with my address, which was also on the label of the package I shipped (\"From:\"). It really seems like it's not for me and it just got linked to me by mistake after laying somewhere for several days. The whole mess should've been noticed and dealt with internally, without throwing it like a hot potato to the customer and giving them a 10+-hour anxiety attack. \"We are happy to confirm...\" has never been so infuriating. As of right now, still no \"Carrier\", \"Tracking No\",  \"Shipped P/N + S/N\", and \"Shipped Date\" in my RMA (screenshot).\n\n10 - I have no (mental) energy and no polite words to say to WD as a response to this dumpster fire. Felt like throwing up since I found the email and looked at the tracking (the most expensive HDD I've ever bought). I'll... probably... wait for a few days... for the promised shipment of the 18TB HDD / legitimate/relevant RMA update. Maybe someone with a working brain will realize the mistake (after whatever's in the package is shipped back, shouldn't be too long now, has been undelivered/undeliverable somewhere for a week and a half now). . . ?\n\n&amp;#x200B;\n\n\\* Never posted here, probably haven't selected the right \"flair\".\n\n\\*\\* I did add several screenshots (Images &amp; Video tab), can't see them anywhere now, though (post awaiting moderator approval).\n\n&amp;#x200B;\n\nEdit (11 hours after posting): Just wanted to thank everyone who commented, not being alone in this helped me feel a little better. But then I thought about pushing/poking/contacting them again and instantly felt like throwing up again. It would be so much better if my experience was the usual \"weeks of no updates\". However, this BS shipment is now connected to MY RMA. (BTW, I, of course, don't know what's in the package, but it seems like \"WD\" doesn't know either.) I can already hear them telling me that they've already shipped \"it\" to me and it's my fault that I didn't receive it/pick it up, after I ask about the drive that was agreed upon on the 9th and 10th... not being able to comprehend what actually happened, just being stuck at \"this is what's in the system\", nobody from WD looking at it properly and thinking about it like a freaking human. Shouldn't have to, but I'll have to... Will update this in 4-8(?) days.\n\n&amp;#x200B;\n\n\\*\\*\\* Let's see if the screenshots can be added in a different way... ah, 1 image only here... OK\n\nhttps://preview.redd.it/dlq1kmquc4ib1.png?width=1082&amp;format=png&amp;auto=webp&amp;s=5377f431f17ce51abe6ba9bcb771e7574c512a9c", "author_fullname": "t2_a26k1o3p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insane WD RMA experience (still ongoing)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dlq1kmquc4ib1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ce2e0e22dbdd5cbaa8dcde73c20162f52d8f1aa"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=34011cdfe363325a4d84ef97f65f786d345b1b00"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec83a99f1de489f3d22040538cd4da31b7660653"}, {"y": 1280, "x": 640, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3b182fcb656793e98128c1df2d70100c0c13648a"}, {"y": 1920, "x": 960, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a3cd0bef2bb5b6cee5d5aca4e91426a4534ba9d8"}, {"y": 2160, "x": 1080, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3f1dc876d6fe2a3b1f920b0c2eb2e30bf9da49dc"}], "s": {"y": 2467, "x": 1082, "u": "https://preview.redd.it/dlq1kmquc4ib1.png?width=1082&amp;format=png&amp;auto=webp&amp;s=5377f431f17ce51abe6ba9bcb771e7574c512a9c"}, "id": "dlq1kmquc4ib1"}}, "name": "t3_15qmj2l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JWk6PRUBHMphIyRqq4qkhxzC3Afd4WvEMJ2N5ae9YWE.jpg", "edited": 1692037765.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691994374.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if I should just start with the giant mess the RMA is now or make this longer by mentioning what happened before...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As briefly as comes to mind:&lt;/p&gt;\n\n&lt;p&gt;1 - Received a damaged package from Amazon at the end of 2022. (In case someone wants to ask why I was so stupid... the 2nd carried threw out the destroyed packaging and put it in a new box, a family member then received the seemingly pristine shipment.)&lt;/p&gt;\n\n&lt;p&gt;2 - Contacted WD about the noise the (external, 16TB) HDD was making. Was told not to worry about it. Assured I could get a replacement during the next 3 years. (Amazon only offered a refund, I waited for that price for a year, ordering again for a much higher price was not acceptable for me.)&lt;/p&gt;\n\n&lt;p&gt;3 - Of course, the drive stopped working several months later.&lt;/p&gt;\n\n&lt;p&gt;4 - Created RMA on July 18th. Shipped on 21st, delivered to WD&amp;#39;s address on 25th.&lt;/p&gt;\n\n&lt;p&gt;5 - RMA status updated to &amp;quot;Received / Processing&amp;quot; on August 3rd. Checking almost every day, no other updates before or after that (till today, not just 8th). No emails till I contacted them first.&lt;/p&gt;\n\n&lt;p&gt;6 - August 8th - Contacted WD (via chat) because of strange info about an undeliverable package (info notice number not working, no shipments linked to my address). Didn&amp;#39;t know what else it could be other than the RMA replacement HDD. Talked to 2-3 people (internet stopped working + connected to &amp;quot;a higher level&amp;quot;, I think), both/all told me the package was not from WD, nothing was sent to me yet, my RMA&amp;#39;s accepted and waiting for replacement HDD shipment.&lt;/p&gt;\n\n&lt;p&gt;7 - August 9th - Someone&amp;#39;s &amp;quot;taken over my case&amp;quot;, adding the screenshot of the email. Short version - WD definitely didn&amp;#39;t ship anything (due to lack of stock), they&amp;#39;ll be shipping an 18TB HDD, same model (if I agree). I agreed and addressed the rest. (Asked for the name to be changed to a family member&amp;#39;s in the chat the previous day since I was already there, after being told shipment&amp;#39;s still TBD, can&amp;#39;t go and get it myself because of health issues. Answered &amp;quot;You mentioned receiving an email about this package&amp;quot; - Never happened. In the chat, I did mention, many times, receiving an info notice that was not in the carrier&amp;#39;s system and wasn&amp;#39;t linked to any packages or my address.)&lt;/p&gt;\n\n&lt;p&gt;8 - August 10th - Short email summing up/confirming what will be done from WD, the same person (screenshot).&lt;/p&gt;\n\n&lt;p&gt;9 - August 11th(sent)/13th(found) - Insane email from somebody new, with a tracking number belonging to a package shipped on August 1st (2 days before my RMA was RECEIVED) to a DIFFERENT CITY, being delivered on the 3rd, to, obviously, NOT ME. Adding screenshots. RMA was, of course, created with my address, which was also on the label of the package I shipped (&amp;quot;From:&amp;quot;). It really seems like it&amp;#39;s not for me and it just got linked to me by mistake after laying somewhere for several days. The whole mess should&amp;#39;ve been noticed and dealt with internally, without throwing it like a hot potato to the customer and giving them a 10+-hour anxiety attack. &amp;quot;We are happy to confirm...&amp;quot; has never been so infuriating. As of right now, still no &amp;quot;Carrier&amp;quot;, &amp;quot;Tracking No&amp;quot;,  &amp;quot;Shipped P/N + S/N&amp;quot;, and &amp;quot;Shipped Date&amp;quot; in my RMA (screenshot).&lt;/p&gt;\n\n&lt;p&gt;10 - I have no (mental) energy and no polite words to say to WD as a response to this dumpster fire. Felt like throwing up since I found the email and looked at the tracking (the most expensive HDD I&amp;#39;ve ever bought). I&amp;#39;ll... probably... wait for a few days... for the promised shipment of the 18TB HDD / legitimate/relevant RMA update. Maybe someone with a working brain will realize the mistake (after whatever&amp;#39;s in the package is shipped back, shouldn&amp;#39;t be too long now, has been undelivered/undeliverable somewhere for a week and a half now). . . ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;* Never posted here, probably haven&amp;#39;t selected the right &amp;quot;flair&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;** I did add several screenshots (Images &amp;amp; Video tab), can&amp;#39;t see them anywhere now, though (post awaiting moderator approval).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit (11 hours after posting): Just wanted to thank everyone who commented, not being alone in this helped me feel a little better. But then I thought about pushing/poking/contacting them again and instantly felt like throwing up again. It would be so much better if my experience was the usual &amp;quot;weeks of no updates&amp;quot;. However, this BS shipment is now connected to MY RMA. (BTW, I, of course, don&amp;#39;t know what&amp;#39;s in the package, but it seems like &amp;quot;WD&amp;quot; doesn&amp;#39;t know either.) I can already hear them telling me that they&amp;#39;ve already shipped &amp;quot;it&amp;quot; to me and it&amp;#39;s my fault that I didn&amp;#39;t receive it/pick it up, after I ask about the drive that was agreed upon on the 9th and 10th... not being able to comprehend what actually happened, just being stuck at &amp;quot;this is what&amp;#39;s in the system&amp;quot;, nobody from WD looking at it properly and thinking about it like a freaking human. Shouldn&amp;#39;t have to, but I&amp;#39;ll have to... Will update this in 4-8(?) days.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;*** Let&amp;#39;s see if the screenshots can be added in a different way... ah, 1 image only here... OK&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dlq1kmquc4ib1.png?width=1082&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5377f431f17ce51abe6ba9bcb771e7574c512a9c\"&gt;https://preview.redd.it/dlq1kmquc4ib1.png?width=1082&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5377f431f17ce51abe6ba9bcb771e7574c512a9c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qmj2l", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Celebration2366", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qmj2l/insane_wd_rma_experience_still_ongoing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qmj2l/insane_wd_rma_experience_still_ongoing/", "subreddit_subscribers": 698009, "created_utc": 1691994374.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5p0h2q4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Update: Consent Judgment in Hachette v. Internet Archive that adopted the definition of \u201cCovered Book\u201d suggested by the Internet Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_15reh3u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w4wfkLiJsLYLJo30Dp0y0HdRlQvhDrPGvqlnKltRB_U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692064642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "authorsalliance.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.authorsalliance.org/2023/08/11/update-proposed-judgment-submitted-in-hachette-v-internet-archive/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DISMww3yUmX3RkO-CGlBq4KzfaNxG0hNjPluObjvBJY.jpg?auto=webp&amp;s=aeb51ebad295f5bfb215a8fa9d46f3655f0251b1", "width": 2560, "height": 1707}, "resolutions": [{"url": "https://external-preview.redd.it/DISMww3yUmX3RkO-CGlBq4KzfaNxG0hNjPluObjvBJY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23f51b49bef064f6bda30311ee1b7fed74eb3a48", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/DISMww3yUmX3RkO-CGlBq4KzfaNxG0hNjPluObjvBJY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fec7b43d2d44f8c4b1888d3b3a244d3855c4d72e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/DISMww3yUmX3RkO-CGlBq4KzfaNxG0hNjPluObjvBJY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=645b9694c1cd67d5c12eb8f72cca5a901b662b44", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/DISMww3yUmX3RkO-CGlBq4KzfaNxG0hNjPluObjvBJY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5bd99c7f9bda59ec0eff2f6ce1e11e94cb725924", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/DISMww3yUmX3RkO-CGlBq4KzfaNxG0hNjPluObjvBJY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5a208983af8b3a00b955c6ab94e34588c6c54f9e", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/DISMww3yUmX3RkO-CGlBq4KzfaNxG0hNjPluObjvBJY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=531587f23a5584ab26bcc227e2a10852d6984a2a", "width": 1080, "height": 720}], "variants": {}, "id": "mdOjYkQuqCeXcCPpBbehJvquAAOkV2mh0-fRBMd8Ni8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15reh3u", "is_robot_indexable": true, "report_reasons": null, "author": "socookre", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15reh3u/update_consent_judgment_in_hachette_v_internet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.authorsalliance.org/2023/08/11/update-proposed-judgment-submitted-in-hachette-v-internet-archive/", "subreddit_subscribers": 698009, "created_utc": 1692064642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just built a new PC that I use professionally for video editing and wanted to find a new use for my old PC (ryzen 3800x, 64gb of RAM, RTX 2060 super).\n\nI want to be able to still use it to export projects using Premiere but I would also like to set it up as a NAS that I can build out as my storage demand grows. I don\u2019t need a lot of storage space right now (maybe 16tb minimum) but would like the opportunity to grow down the road if needed. I also don\u2019t need that fast of speeds (500mb read/write speeds minimum) so I\u2019m going with just 10gig.\n\nI think I have the hardware side figured out (case, Iron Wolf NAS drives, etc) but I\u2019m trying to figure out the best way to handle the software/OS.\n\nOne thought was to use Unraid and create a VM and install Windows on it so I can still run Adobe programs. Because it would be more background rendering I don\u2019t mind sacrificing some of the cores of my CPU. The other idea was just that I would create a raid in Windows disk manager and set it up as a shared folder with my PC, but that wouldn\u2019t be expandable. With all of that, would the unraid option be the best if I want a machine that can both operate as a NAS and also be able to render files? ", "author_fullname": "t2_708gc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Convert my old PC into a NAS while still being able to use Premiere Pro", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r22s6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692036229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just built a new PC that I use professionally for video editing and wanted to find a new use for my old PC (ryzen 3800x, 64gb of RAM, RTX 2060 super).&lt;/p&gt;\n\n&lt;p&gt;I want to be able to still use it to export projects using Premiere but I would also like to set it up as a NAS that I can build out as my storage demand grows. I don\u2019t need a lot of storage space right now (maybe 16tb minimum) but would like the opportunity to grow down the road if needed. I also don\u2019t need that fast of speeds (500mb read/write speeds minimum) so I\u2019m going with just 10gig.&lt;/p&gt;\n\n&lt;p&gt;I think I have the hardware side figured out (case, Iron Wolf NAS drives, etc) but I\u2019m trying to figure out the best way to handle the software/OS.&lt;/p&gt;\n\n&lt;p&gt;One thought was to use Unraid and create a VM and install Windows on it so I can still run Adobe programs. Because it would be more background rendering I don\u2019t mind sacrificing some of the cores of my CPU. The other idea was just that I would create a raid in Windows disk manager and set it up as a shared folder with my PC, but that wouldn\u2019t be expandable. With all of that, would the unraid option be the best if I want a machine that can both operate as a NAS and also be able to render files? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r22s6", "is_robot_indexable": true, "report_reasons": null, "author": "aaronallsop", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r22s6/convert_my_old_pc_into_a_nas_while_still_being/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r22s6/convert_my_old_pc_into_a_nas_while_still_being/", "subreddit_subscribers": 698009, "created_utc": 1692036229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone! :D\n\nYou may know me from my last post I made: [old post](https://www.reddit.com/r/DataHoarder/comments/15pvftv/gfycat_shutting_down_i_got_you_covered/)\n\nWell, I figured making a new post would be best as these changes to the script are pretty major, and the old script is basically completely replaced. You can find the script over on [Github](https://github.com/Quafley/Gfycat-download), make sure to install the packages which can be found in the requirements (httpx being the new one introduced)\n\nWith my script it will allow you to download your whole library of Gfycats within minutes. The updated script introduces the following features for you to use:  \n1. The script is now asynchronous. The speed has improved at least by 10x.  \n2. The script will now query the following subdomains. [Giant.gfycat.com](https://Giant.gfycat.com) \\&gt; [fat.gfycat.com](https://fat.gfycat.com) \\&gt; [zip.gfycat.com](https://zip.gfycat.com), based on the response.\n\nBefore, the script would only download from Giant. The reason this is important is because only the larger sized gfycats are uploaded to this subdomain! So, we are essentially missing a fair amount of downloads.\n\nI hope you enjoy this final version of the script and I hope you can savor your memories with it! \n\nHave a fantastic day!  \n", "author_fullname": "t2_125rmb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(MAJOR UPDATE) Gfycat shutdown, download script.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r7r5e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692048639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! :D&lt;/p&gt;\n\n&lt;p&gt;You may know me from my last post I made: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/15pvftv/gfycat_shutting_down_i_got_you_covered/\"&gt;old post&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Well, I figured making a new post would be best as these changes to the script are pretty major, and the old script is basically completely replaced. You can find the script over on &lt;a href=\"https://github.com/Quafley/Gfycat-download\"&gt;Github&lt;/a&gt;, make sure to install the packages which can be found in the requirements (httpx being the new one introduced)&lt;/p&gt;\n\n&lt;p&gt;With my script it will allow you to download your whole library of Gfycats within minutes. The updated script introduces the following features for you to use:&lt;br/&gt;\n1. The script is now asynchronous. The speed has improved at least by 10x.&lt;br/&gt;\n2. The script will now query the following subdomains. &lt;a href=\"https://Giant.gfycat.com\"&gt;Giant.gfycat.com&lt;/a&gt; &amp;gt; &lt;a href=\"https://fat.gfycat.com\"&gt;fat.gfycat.com&lt;/a&gt; &amp;gt; &lt;a href=\"https://zip.gfycat.com\"&gt;zip.gfycat.com&lt;/a&gt;, based on the response.&lt;/p&gt;\n\n&lt;p&gt;Before, the script would only download from Giant. The reason this is important is because only the larger sized gfycats are uploaded to this subdomain! So, we are essentially missing a fair amount of downloads.&lt;/p&gt;\n\n&lt;p&gt;I hope you enjoy this final version of the script and I hope you can savor your memories with it! &lt;/p&gt;\n\n&lt;p&gt;Have a fantastic day!  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RilxRLcgPQ06_unaoTOJJrEtPM2iahSZBNiRmgAPCYo.jpg?auto=webp&amp;s=be1d7c8524fc95110330a03deea540c22fb1e494", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/RilxRLcgPQ06_unaoTOJJrEtPM2iahSZBNiRmgAPCYo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e98a413b1c7ea2c0311ef3f892dcae8e8f0fb520", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/RilxRLcgPQ06_unaoTOJJrEtPM2iahSZBNiRmgAPCYo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9814e00fa716921097f4894d877bb92ebf5806ae", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/RilxRLcgPQ06_unaoTOJJrEtPM2iahSZBNiRmgAPCYo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=343a7dd55c005ffb01e9553a860e4ac4de7bba02", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/RilxRLcgPQ06_unaoTOJJrEtPM2iahSZBNiRmgAPCYo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e94d631e85adae30ade89041ccb141d74dd72e55", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/RilxRLcgPQ06_unaoTOJJrEtPM2iahSZBNiRmgAPCYo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=61c78780f2e2cf8252a58af66b15ebfc996d49f7", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/RilxRLcgPQ06_unaoTOJJrEtPM2iahSZBNiRmgAPCYo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dfa09b7dc4c95e7a6aad5a685a15f4fe45186049", "width": 1080, "height": 540}], "variants": {}, "id": "DiDS1gr0yOLyKpviJStLGtUiEo_2iAgZuEgG8A_WSAM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "58TB unRAID", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r7r5e", "is_robot_indexable": true, "report_reasons": null, "author": "Quafley", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15r7r5e/major_update_gfycat_shutdown_download_script/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r7r5e/major_update_gfycat_shutdown_download_script/", "subreddit_subscribers": 698009, "created_utc": 1692048639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As the title states. \n\nSome games let you view models used in-game. I ADORE this, and sometimes I just want to look at a model of Ornstein from Dark Souls or other games. I know, I'm weird. But I was wondering, am I the only one who likes the idea of keeping a collection of in-game models?", "author_fullname": "t2_afuv9dt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a sub for collecting ripped models from games?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qmfcg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691994050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title states. &lt;/p&gt;\n\n&lt;p&gt;Some games let you view models used in-game. I ADORE this, and sometimes I just want to look at a model of Ornstein from Dark Souls or other games. I know, I&amp;#39;m weird. But I was wondering, am I the only one who likes the idea of keeping a collection of in-game models?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qmfcg", "is_robot_indexable": true, "report_reasons": null, "author": "KaijOUJaeger", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qmfcg/is_there_a_sub_for_collecting_ripped_models_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qmfcg/is_there_a_sub_for_collecting_ripped_models_from/", "subreddit_subscribers": 698009, "created_utc": 1691994050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a YouTube archiving site that was made by a user here, all I remember is the interface was simple I believe black background and it had one bar where you're supposed to type the video id you're searching for.", "author_fullname": "t2_pzwjzo71", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a site that was posted here.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r9tfk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692053199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a YouTube archiving site that was made by a user here, all I remember is the interface was simple I believe black background and it had one bar where you&amp;#39;re supposed to type the video id you&amp;#39;re searching for.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r9tfk", "is_robot_indexable": true, "report_reasons": null, "author": "pepethefrogs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r9tfk/looking_for_a_site_that_was_posted_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r9tfk/looking_for_a_site_that_was_posted_here/", "subreddit_subscribers": 698009, "created_utc": 1692053199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI am using Windows 10, using the gallery.dl.exe file. I am attempting to get cookies from browser directly from the config file to avoid having to always type \"--cookies-from-browser firefox\" everytime I need the cookies to download from instagram for example. However, I am unable to make it work. I am off course new to this, and know yt-dlp more.\n\n&amp;#x200B;\n\nI am typing the following within extractors\n\n&amp;#x200B;\n\n\"instagram\":\n\n{\n\n\"api\": \"rest\",\n\n\"cookies\": \\[\"firefox\"\\],\n\n\"include\": \"posts\",\n\n\"order-files\": \"asc\",\n\n\"order-posts\": \"asc\",\n\n\"previews\": false,\n\n\"sleep-request\": \\[6.0, 12.0\\],\n\n\"videos\": true\n\n},\n\n&amp;#x200B;\n\nI also attempted the directory option \"cookies\": \"G:\\\\gallery-dl\\\\cookies.txt\"\n\n&amp;#x200B;\n\nand I also tried to do it globally on top of the config file but it does not work. What am I missing if you can help me?\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n{\n\n\"extractor\":\n\n{\n\n\"base-directory\": \"H:/gallery-dl-downloads\",\n\n\"parent-directory\": false,\n\n\"postprocessors\": null,\n\n\"archive\": null,\n\n\"cookies\": \\[\"firefox\"\\],\n\n\"cookies-update\": true,\n\n\"proxy\": null,\n\n\"skip\": true,\n\n&amp;#x200B;\n\neverything else works. and of course using --cookies-from... as a command works\n\n&amp;#x200B;\n\nNote: if I attempt to download without the cookies I do get this error \\[instagram\\]\\[error\\] HttpError: '401 Unauthorized' for '[https://www.instagram.com/api/v1/users/web\\_profile\\_info/](https://www.instagram.com/api/v1/users/web_profile_info/)'", "author_fullname": "t2_1i2lp4ty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gallery-dl please help, how to change config file to include cookies for instagram/twitter/reddit.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r5ai7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692043276.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am using Windows 10, using the gallery.dl.exe file. I am attempting to get cookies from browser directly from the config file to avoid having to always type &amp;quot;--cookies-from-browser firefox&amp;quot; everytime I need the cookies to download from instagram for example. However, I am unable to make it work. I am off course new to this, and know yt-dlp more.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am typing the following within extractors&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;instagram&amp;quot;:&lt;/p&gt;\n\n&lt;p&gt;{&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;api&amp;quot;: &amp;quot;rest&amp;quot;,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;cookies&amp;quot;: [&amp;quot;firefox&amp;quot;],&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;include&amp;quot;: &amp;quot;posts&amp;quot;,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;order-files&amp;quot;: &amp;quot;asc&amp;quot;,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;order-posts&amp;quot;: &amp;quot;asc&amp;quot;,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;previews&amp;quot;: false,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;sleep-request&amp;quot;: [6.0, 12.0],&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;videos&amp;quot;: true&lt;/p&gt;\n\n&lt;p&gt;},&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I also attempted the directory option &amp;quot;cookies&amp;quot;: &amp;quot;G:\\gallery-dl\\cookies.txt&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;and I also tried to do it globally on top of the config file but it does not work. What am I missing if you can help me?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;{&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;extractor&amp;quot;:&lt;/p&gt;\n\n&lt;p&gt;{&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;base-directory&amp;quot;: &amp;quot;H:/gallery-dl-downloads&amp;quot;,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;parent-directory&amp;quot;: false,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;postprocessors&amp;quot;: null,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;archive&amp;quot;: null,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;cookies&amp;quot;: [&amp;quot;firefox&amp;quot;],&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;cookies-update&amp;quot;: true,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;proxy&amp;quot;: null,&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;skip&amp;quot;: true,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;everything else works. and of course using --cookies-from... as a command works&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Note: if I attempt to download without the cookies I do get this error [instagram][error] HttpError: &amp;#39;401 Unauthorized&amp;#39; for &amp;#39;&lt;a href=\"https://www.instagram.com/api/v1/users/web_profile_info/\"&gt;https://www.instagram.com/api/v1/users/web_profile_info/&lt;/a&gt;&amp;#39;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r5ai7", "is_robot_indexable": true, "report_reasons": null, "author": "geoffrey801", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r5ai7/gallerydl_please_help_how_to_change_config_file/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r5ai7/gallerydl_please_help_how_to_change_config_file/", "subreddit_subscribers": 698009, "created_utc": 1692043276.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Its not obvious when they go into sleep mode. I looked in device manager, but not sure where to untick power saving. Not sure whether it changes anything.", "author_fullname": "t2_pr4df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you stop external SSDs and HDDs from going into sleep mode?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r2u42", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692037888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Its not obvious when they go into sleep mode. I looked in device manager, but not sure where to untick power saving. Not sure whether it changes anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r2u42", "is_robot_indexable": true, "report_reasons": null, "author": "Dron22", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r2u42/how_do_you_stop_external_ssds_and_hdds_from_going/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r2u42/how_do_you_stop_external_ssds_and_hdds_from_going/", "subreddit_subscribers": 698009, "created_utc": 1692037888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "**Background:** \n\nHi folks, due to a friend's recent bereavement, I am assisting with the processing of a large hoard of data. Roughly 25 to 30 hard drives, size varies but many are 4TB, 8TB, many smaller.\n\nI am familiar with using DupeGuru (on macOS) and would normally mark certain folders as reference, compare the next one and so on... but it's going to be challenging to say the least to connect this many drives to a single system.\n\nThere definitely are large media duplicates across multiple drives.\n\nI have exported directory listings to a text file and put into a spreadsheet, can search for something and see that it exists on multiple drives, however this doesn't help me know if the files in question are actually the same or not. Just trying to eliminate duplicates (would move to a 'duplicates' folder on each drive) so the true unique data size can be assessed and if things can be compressed further and so on, and then maybe moved to a NAS or similar for the family.\n\n**Question:**\n\nAnyway, my question is: is there some way to scan a drive full of files and save (I doin't know the correct words) hashes or MD5 or similar of the content, and do this for multiple drives each in turn, and then reconnect the drives later to eliminate the duplicates on each drive?\n\nThanks for any suggestions you may have :)", "author_fullname": "t2_1s8v2s4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Duplicate removal assistance for large hoard.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15qn9w4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691996752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Hi folks, due to a friend&amp;#39;s recent bereavement, I am assisting with the processing of a large hoard of data. Roughly 25 to 30 hard drives, size varies but many are 4TB, 8TB, many smaller.&lt;/p&gt;\n\n&lt;p&gt;I am familiar with using DupeGuru (on macOS) and would normally mark certain folders as reference, compare the next one and so on... but it&amp;#39;s going to be challenging to say the least to connect this many drives to a single system.&lt;/p&gt;\n\n&lt;p&gt;There definitely are large media duplicates across multiple drives.&lt;/p&gt;\n\n&lt;p&gt;I have exported directory listings to a text file and put into a spreadsheet, can search for something and see that it exists on multiple drives, however this doesn&amp;#39;t help me know if the files in question are actually the same or not. Just trying to eliminate duplicates (would move to a &amp;#39;duplicates&amp;#39; folder on each drive) so the true unique data size can be assessed and if things can be compressed further and so on, and then maybe moved to a NAS or similar for the family.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Anyway, my question is: is there some way to scan a drive full of files and save (I doin&amp;#39;t know the correct words) hashes or MD5 or similar of the content, and do this for multiple drives each in turn, and then reconnect the drives later to eliminate the duplicates on each drive?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any suggestions you may have :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15qn9w4", "is_robot_indexable": true, "report_reasons": null, "author": "riscy_computering", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15qn9w4/duplicate_removal_assistance_for_large_hoard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15qn9w4/duplicate_removal_assistance_for_large_hoard/", "subreddit_subscribers": 698009, "created_utc": 1691996752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys.\n\nI've got a couple of old rewriteable DVDs that I'm trying to copy files from, but ordinary copy and paste gets hung up on corrupted files. \"Time remaining: Calculating...\" forever.\n\nIs there a program that will copy off only the okay files without getting frozen by the rest?\n\nThanks.", "author_fullname": "t2_9mvjvhpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to copy from a corrupted rewritable DVD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r9vhl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692053336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a couple of old rewriteable DVDs that I&amp;#39;m trying to copy files from, but ordinary copy and paste gets hung up on corrupted files. &amp;quot;Time remaining: Calculating...&amp;quot; forever.&lt;/p&gt;\n\n&lt;p&gt;Is there a program that will copy off only the okay files without getting frozen by the rest?&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r9vhl", "is_robot_indexable": true, "report_reasons": null, "author": "148637415963", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r9vhl/how_to_copy_from_a_corrupted_rewritable_dvd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r9vhl/how_to_copy_from_a_corrupted_rewritable_dvd/", "subreddit_subscribers": 698009, "created_utc": 1692053336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With google announcing crackdowns on ad-blocking etc I really feel like the days of free access to youtube are numbered, and I want to archive/save what I can, and I'd like to be able to browse some of those channels/shows like TV shows alongside my other media in jellyfin etc. Is there a good way of fetching sorting and storing metadata etc in a format condusive to this?", "author_fullname": "t2_3x979tzz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have a good tool/method for integrating youtube archival with media servers like jellyfin?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15raycq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692055857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With google announcing crackdowns on ad-blocking etc I really feel like the days of free access to youtube are numbered, and I want to archive/save what I can, and I&amp;#39;d like to be able to browse some of those channels/shows like TV shows alongside my other media in jellyfin etc. Is there a good way of fetching sorting and storing metadata etc in a format condusive to this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15raycq", "is_robot_indexable": true, "report_reasons": null, "author": "SimplifyAndAddCoffee", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15raycq/does_anyone_have_a_good_toolmethod_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15raycq/does_anyone_have_a_good_toolmethod_for/", "subreddit_subscribers": 698009, "created_utc": 1692055857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Title basically. I have a family member that installs security cameras for a living. He gives me tons of these WD20PURX drives. Problem is 2tb and only 5400rpm. What's the best way to use them? Raid 0, 4?? I probably have 15 of them on the floor and I'm using 3 in my PC with more if I ask.\n\n&amp;#x200B;\n\nBonus Q:  I keep maxing out by 1 TB monthly bandwith (cox is &gt;!cocks!&lt;)  Which public places have fast, unrestricted wifi ? ", "author_fullname": "t2_ht2e7nny", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do with WD Purple 5400rpm 2TBs? I'm swimming in them", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15rjfph", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692077666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title basically. I have a family member that installs security cameras for a living. He gives me tons of these WD20PURX drives. Problem is 2tb and only 5400rpm. What&amp;#39;s the best way to use them? Raid 0, 4?? I probably have 15 of them on the floor and I&amp;#39;m using 3 in my PC with more if I ask.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Bonus Q:  I keep maxing out by 1 TB monthly bandwith (cox is &lt;span class=\"md-spoiler-text\"&gt;cocks&lt;/span&gt;)  Which public places have fast, unrestricted wifi ? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15rjfph", "is_robot_indexable": true, "report_reasons": null, "author": "lostmanwandering", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15rjfph/what_to_do_with_wd_purple_5400rpm_2tbs_im/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15rjfph/what_to_do_with_wd_purple_5400rpm_2tbs_im/", "subreddit_subscribers": 698009, "created_utc": 1692077666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Along with other domains. Anyone else experiencing this?", "author_fullname": "t2_fyy6njl1d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is archive.vn down?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15rjd59", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692077447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Along with other domains. Anyone else experiencing this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15rjd59", "is_robot_indexable": true, "report_reasons": null, "author": "fuckadminswitharake", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15rjd59/is_archivevn_down/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15rjd59/is_archivevn_down/", "subreddit_subscribers": 698009, "created_utc": 1692077447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, fellow data hoarders! I just discovered this sub and read through some of the Wiki and FAQs and learned have a pretty poor understanding of things. My technical knowhow only goes so far (and it's not that far). I'm concerned that the way I am doing things is not great and am seeking help/advice.\n\nI have a collection of movies/TV that right now that is a little under 8TB total. I have been growing this collection for probably the last 15 years or so. During this time, I have exclusively used external hard drives to house all my stuff, with no backups or copies (pause for cringing). Over the years, I have replaced HDs as my size demands increased. My current external hard drive is a WD MyBook 16TB. I have a plex server for all my TV &amp; movies on this drive. I also have a 5TB WD Elements portable that I keep other things on (projects, laptop backup, misc. overflow stuff to save space on my desktop), and an older 2TB MyBook that I keep an archive of mostly sports games/highlights on. I have them plugged into my MacBook Air M2 (2022).\n\nI know that not having a backup of my media library is really dangerous, and the more time I spend on this sub, the more I'd like to fix it. My question is, what is your recommendation of how to optimize my setup? Would a NAS be the best thing for me, and if so, what even is it (ELI5)? Or is it as simple as getting another large external to house the backup? Or do I go the cloud route?\n\nThank you for your help!", "author_fullname": "t2_9ha6w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just found this sub, looking to do things correctly &amp; safely.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rhpq9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692072470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, fellow data hoarders! I just discovered this sub and read through some of the Wiki and FAQs and learned have a pretty poor understanding of things. My technical knowhow only goes so far (and it&amp;#39;s not that far). I&amp;#39;m concerned that the way I am doing things is not great and am seeking help/advice.&lt;/p&gt;\n\n&lt;p&gt;I have a collection of movies/TV that right now that is a little under 8TB total. I have been growing this collection for probably the last 15 years or so. During this time, I have exclusively used external hard drives to house all my stuff, with no backups or copies (pause for cringing). Over the years, I have replaced HDs as my size demands increased. My current external hard drive is a WD MyBook 16TB. I have a plex server for all my TV &amp;amp; movies on this drive. I also have a 5TB WD Elements portable that I keep other things on (projects, laptop backup, misc. overflow stuff to save space on my desktop), and an older 2TB MyBook that I keep an archive of mostly sports games/highlights on. I have them plugged into my MacBook Air M2 (2022).&lt;/p&gt;\n\n&lt;p&gt;I know that not having a backup of my media library is really dangerous, and the more time I spend on this sub, the more I&amp;#39;d like to fix it. My question is, what is your recommendation of how to optimize my setup? Would a NAS be the best thing for me, and if so, what even is it (ELI5)? Or is it as simple as getting another large external to house the backup? Or do I go the cloud route?&lt;/p&gt;\n\n&lt;p&gt;Thank you for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15rhpq9", "is_robot_indexable": true, "report_reasons": null, "author": "Greged17", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15rhpq9/just_found_this_sub_looking_to_do_things/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15rhpq9/just_found_this_sub_looking_to_do_things/", "subreddit_subscribers": 698009, "created_utc": 1692072470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a plex server running on an old dell optiplex 3080 micro I bought on ebay. \nIt has 4TB on total storage as of today is at ~80% full.\n\nI want to upgrade my storage but dont have the funds to buy a NAS.\n\nWhat other options do I have? \n\nCan I just buy one of those docking stations and chuck large capacity hhd and call it a day?\n\nFor now im looking for something cheap. \n\nThank you", "author_fullname": "t2_mwarw2zw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expanding storage. What are my options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rhhmu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692071861.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a plex server running on an old dell optiplex 3080 micro I bought on ebay. \nIt has 4TB on total storage as of today is at ~80% full.&lt;/p&gt;\n\n&lt;p&gt;I want to upgrade my storage but dont have the funds to buy a NAS.&lt;/p&gt;\n\n&lt;p&gt;What other options do I have? &lt;/p&gt;\n\n&lt;p&gt;Can I just buy one of those docking stations and chuck large capacity hhd and call it a day?&lt;/p&gt;\n\n&lt;p&gt;For now im looking for something cheap. &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15rhhmu", "is_robot_indexable": true, "report_reasons": null, "author": "Immediate_Ad_8428", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15rhhmu/expanding_storage_what_are_my_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15rhhmu/expanding_storage_what_are_my_options/", "subreddit_subscribers": 698009, "created_utc": 1692071861.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don\u2019t want my parents to see my photos and vice versa. Amazon photos offers unlimited photo storage for prime members up to 6 people on family prime account yet there is no way to set access privileges on folders?", "author_fullname": "t2_rbuhkefn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to divide amazon photos cloud to each family member on prime account?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rhhaq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692071834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don\u2019t want my parents to see my photos and vice versa. Amazon photos offers unlimited photo storage for prime members up to 6 people on family prime account yet there is no way to set access privileges on folders?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15rhhaq", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional_Cycle192", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15rhhaq/how_to_divide_amazon_photos_cloud_to_each_family/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15rhhaq/how_to_divide_amazon_photos_cloud_to_each_family/", "subreddit_subscribers": 698009, "created_utc": 1692071834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "We can't just keep our heads down every time something we hold dear is threatened. Instead why not organise a global level activism worldwide in support of Internet Archive not unlike the anti-PIPA movement?\n\nInternet blackouts, street protest, boycotts, lobbying and graffitis are the major ways. Names to choose include ProtectHistories, SafeguardHistories and PreserveNotDestroy. It is even better if we can consolidate scattered movements such as the protests against the API price hikes into this one.", "author_fullname": "t2_5p0h2q4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Global activism in support of Internet Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15renmg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Call for action", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692065094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We can&amp;#39;t just keep our heads down every time something we hold dear is threatened. Instead why not organise a global level activism worldwide in support of Internet Archive not unlike the anti-PIPA movement?&lt;/p&gt;\n\n&lt;p&gt;Internet blackouts, street protest, boycotts, lobbying and graffitis are the major ways. Names to choose include ProtectHistories, SafeguardHistories and PreserveNotDestroy. It is even better if we can consolidate scattered movements such as the protests against the API price hikes into this one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15renmg", "is_robot_indexable": true, "report_reasons": null, "author": "socookre", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15renmg/global_activism_in_support_of_internet_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15renmg/global_activism_in_support_of_internet_archive/", "subreddit_subscribers": 698009, "created_utc": 1692065094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'd like to consolidate all of my storage and update a bit. I have a mix of raids and external drives that are a mess (and outdated) at this point. I have 80TB now and want to expand to 140TB or more.  \n\nI currently have 3 Synology RAIDS (1511+,1515+,1515+),  2 G-Speed - WB(4 bay), misc JBOD drives connected to a Mac Mini over TB &amp; USB3. The drives range from 2TB up to 14TB.\n\nWhat VALUE options do I have to store 140TB or more? I can host all over a modern Mac mini which may save me in cost. I also have an ESXi (super micro - i3)box but not sure what that will get me. I'd like to get 100MB/sec (aka 1GB). Thanks!", "author_fullname": "t2_2ubygxvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Value storage for 140TB+", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rcrjx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692060320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to consolidate all of my storage and update a bit. I have a mix of raids and external drives that are a mess (and outdated) at this point. I have 80TB now and want to expand to 140TB or more.  &lt;/p&gt;\n\n&lt;p&gt;I currently have 3 Synology RAIDS (1511+,1515+,1515+),  2 G-Speed - WB(4 bay), misc JBOD drives connected to a Mac Mini over TB &amp;amp; USB3. The drives range from 2TB up to 14TB.&lt;/p&gt;\n\n&lt;p&gt;What VALUE options do I have to store 140TB or more? I can host all over a modern Mac mini which may save me in cost. I also have an ESXi (super micro - i3)box but not sure what that will get me. I&amp;#39;d like to get 100MB/sec (aka 1GB). Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15rcrjx", "is_robot_indexable": true, "report_reasons": null, "author": "kram96", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15rcrjx/value_storage_for_140tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15rcrjx/value_storage_for_140tb/", "subreddit_subscribers": 698009, "created_utc": 1692060320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nMy current practice is to backup my photos/videos on Google Drive. However, I just hit my 2TB threshold and will now have to pay $250 for 5TB/year (used to be $100 for 2TB/year). Planning to use rclone and Amazon Glacier Deep Archive to keep costs down. For the record, I also have these files on my local NAS for ready-access.\n\nWas curious on any recommendations this community might have with using rclone and this storage option. For example, I read that I should do \"rclone copy\" as opposed to \"rsync sync\" to reduce metadata access calls (as it requires a comparison of files?. Anything else? How much more in cost is sync vs copy? I don't intend to delete or move files often, but I could see that happening. My preference is to do sync or something similar to capture the changes, but not if it costs a whole lot.\n\nThanks in advance for your help.", "author_fullname": "t2_3zlpu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rclone and Amazon Glacier Deep Archive Best/Recommended Practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rbeip", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692056940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;My current practice is to backup my photos/videos on Google Drive. However, I just hit my 2TB threshold and will now have to pay $250 for 5TB/year (used to be $100 for 2TB/year). Planning to use rclone and Amazon Glacier Deep Archive to keep costs down. For the record, I also have these files on my local NAS for ready-access.&lt;/p&gt;\n\n&lt;p&gt;Was curious on any recommendations this community might have with using rclone and this storage option. For example, I read that I should do &amp;quot;rclone copy&amp;quot; as opposed to &amp;quot;rsync sync&amp;quot; to reduce metadata access calls (as it requires a comparison of files?. Anything else? How much more in cost is sync vs copy? I don&amp;#39;t intend to delete or move files often, but I could see that happening. My preference is to do sync or something similar to capture the changes, but not if it costs a whole lot.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15rbeip", "is_robot_indexable": true, "report_reasons": null, "author": "vinhdizzo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15rbeip/rclone_and_amazon_glacier_deep_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15rbeip/rclone_and_amazon_glacier_deep_archive/", "subreddit_subscribers": 698009, "created_utc": 1692056940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "With the hardware currently at my disposal, what is the most efficient and cost effective way to upgrade.\n\nMy current pc was built in 2018 and is starting to show its age. Ideally, I would like to build a new gaming pc and keep/repurpose my current pc as a full-time server pc. Doubling my current storage also seems like the next logical step but isn't 100% needed at this point. I don't have a strict budget in mind but would like to keep the storage and pc upgrades around the $2,000 mark.\n\nMy current pc specs:\n\nPhanteks P400s\n\nRyzen 7 1700x\n\n32gb DDR4 @ 3200mhz\n\nGTX 1070ti\n\nEVGA 750w\n\n500gb sata ssd boot drive, 1tb WD blue, 2tb WD Green, 8tb WD Green. The 1 and 2 tb drives should be retired soon and currently only store steam games.\n\nI am also running a 4-bay Synology DS920+ with 42tb usable storage (4x16tb) in raid 5. There is currently 12tb of free space remaining.\n\nI run a plex server off of my pc. I had contemplated running it off of my nas but would prefer to keep running on a pc with better specs than the nas for the purpose of hardware transcoding. \n\nI have three used 8tb drives and two lightly used 12tb drives. One of the 8tb drives has a partial backup of my plex server. I lack a proper backup. Other than that one 8tb drive, the other drives are completely unused. \n\nI am open to any suggestions as to how to upgrade or what I should be upgrading first. And yes I know I need a proper backup. That should probably be the first thing I address.\n\n&amp;#x200B;", "author_fullname": "t2_1a11k6t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most Efficient Way to Upgrade", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r9ahp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692052020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the hardware currently at my disposal, what is the most efficient and cost effective way to upgrade.&lt;/p&gt;\n\n&lt;p&gt;My current pc was built in 2018 and is starting to show its age. Ideally, I would like to build a new gaming pc and keep/repurpose my current pc as a full-time server pc. Doubling my current storage also seems like the next logical step but isn&amp;#39;t 100% needed at this point. I don&amp;#39;t have a strict budget in mind but would like to keep the storage and pc upgrades around the $2,000 mark.&lt;/p&gt;\n\n&lt;p&gt;My current pc specs:&lt;/p&gt;\n\n&lt;p&gt;Phanteks P400s&lt;/p&gt;\n\n&lt;p&gt;Ryzen 7 1700x&lt;/p&gt;\n\n&lt;p&gt;32gb DDR4 @ 3200mhz&lt;/p&gt;\n\n&lt;p&gt;GTX 1070ti&lt;/p&gt;\n\n&lt;p&gt;EVGA 750w&lt;/p&gt;\n\n&lt;p&gt;500gb sata ssd boot drive, 1tb WD blue, 2tb WD Green, 8tb WD Green. The 1 and 2 tb drives should be retired soon and currently only store steam games.&lt;/p&gt;\n\n&lt;p&gt;I am also running a 4-bay Synology DS920+ with 42tb usable storage (4x16tb) in raid 5. There is currently 12tb of free space remaining.&lt;/p&gt;\n\n&lt;p&gt;I run a plex server off of my pc. I had contemplated running it off of my nas but would prefer to keep running on a pc with better specs than the nas for the purpose of hardware transcoding. &lt;/p&gt;\n\n&lt;p&gt;I have three used 8tb drives and two lightly used 12tb drives. One of the 8tb drives has a partial backup of my plex server. I lack a proper backup. Other than that one 8tb drive, the other drives are completely unused. &lt;/p&gt;\n\n&lt;p&gt;I am open to any suggestions as to how to upgrade or what I should be upgrading first. And yes I know I need a proper backup. That should probably be the first thing I address.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r9ahp", "is_robot_indexable": true, "report_reasons": null, "author": "Shadow362", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r9ahp/most_efficient_way_to_upgrade/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r9ahp/most_efficient_way_to_upgrade/", "subreddit_subscribers": 698009, "created_utc": 1692052020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Dumb question of the day.  I see I can get 2TB m.2 SSDs for about $65.  I was wondering if anyone makes an m.2 bank or plugin module?.  Seems like you can get 10TB of very fast quiet storage for around $350. I would like that for my HTPC.", "author_fullname": "t2_4t7lvx0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does an M.2 SSD bank exist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r77g6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692047462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dumb question of the day.  I see I can get 2TB m.2 SSDs for about $65.  I was wondering if anyone makes an m.2 bank or plugin module?.  Seems like you can get 10TB of very fast quiet storage for around $350. I would like that for my HTPC.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r77g6", "is_robot_indexable": true, "report_reasons": null, "author": "wsg49", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r77g6/does_an_m2_ssd_bank_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r77g6/does_an_m2_ssd_bank_exist/", "subreddit_subscribers": 698009, "created_utc": 1692047462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nHi,\n\nI've almost lost all my files (I think) and now I don't want to risk again..\n\nI'm a graphic designer and I started 5 years ago, over this time I did accumulate more or less 1TB of files, that I want to keep safe. recently I had some corrupted issue with windows and there was a possibility of losing my files, I had no idea how to proceed so I bringed to a repair shop, that luckily saved everything. I asked them to keep the hard disk with ''old files'' and install me and copy a new one (keep as a backup).\n\nBut I want to do something different, I need something that is easy to use, that I can turn on and off daily (sometimes we have electrical problems and happens quite often that the electricity come and go, I will buy a power continuity but still I want to be able to turn on and off easily).\n\nI don't need something massive, 2tb is more than enough and doesn't need to be cloud based, I don't mind cable or attaching usb or whatever.\n\nI don't really need a nas, and all das that I'm seeing look difficult to set up or not really something easy to turn on and off.\n\nLooks like a external storage (hard disk-ssd) could be a good fit but is it something that I can trust?\n\nI'm also not really sure about uploading everything on the cloud, even tho seems quite tempting.", "author_fullname": "t2_7cku6np2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help for backup (nas-das-external hard disks) ..?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15r6h7o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692045883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve almost lost all my files (I think) and now I don&amp;#39;t want to risk again..&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a graphic designer and I started 5 years ago, over this time I did accumulate more or less 1TB of files, that I want to keep safe. recently I had some corrupted issue with windows and there was a possibility of losing my files, I had no idea how to proceed so I bringed to a repair shop, that luckily saved everything. I asked them to keep the hard disk with &amp;#39;&amp;#39;old files&amp;#39;&amp;#39; and install me and copy a new one (keep as a backup).&lt;/p&gt;\n\n&lt;p&gt;But I want to do something different, I need something that is easy to use, that I can turn on and off daily (sometimes we have electrical problems and happens quite often that the electricity come and go, I will buy a power continuity but still I want to be able to turn on and off easily).&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t need something massive, 2tb is more than enough and doesn&amp;#39;t need to be cloud based, I don&amp;#39;t mind cable or attaching usb or whatever.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t really need a nas, and all das that I&amp;#39;m seeing look difficult to set up or not really something easy to turn on and off.&lt;/p&gt;\n\n&lt;p&gt;Looks like a external storage (hard disk-ssd) could be a good fit but is it something that I can trust?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also not really sure about uploading everything on the cloud, even tho seems quite tempting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15r6h7o", "is_robot_indexable": true, "report_reasons": null, "author": "Pale-Medium-7455", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15r6h7o/help_for_backup_nasdasexternal_hard_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15r6h7o/help_for_backup_nasdasexternal_hard_disks/", "subreddit_subscribers": 698009, "created_utc": 1692045883.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}