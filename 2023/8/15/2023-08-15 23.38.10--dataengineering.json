{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I ask since I am an aspiring DE, currently studying the core skills, and I don\u2019t want to spend unnecessary time grinding SQL exercises because\n\n1) I know most of my sticky learning is going to come from hands on, real situations/projects \n\n2) I still need to make time to learn Python/ETL ect. \n\nI have been studying SQL for 3-5 hours a day for that last 2 weeks (I am so tired of my current career field that I have this burning desire to get out, hence the aggressive study schedule) \nAnd so far have been working on and can answer the easy and medium topics/concepts on stratascratch\n \n\n1.\t\u2060SELECT and WHERE for filtering and selection\n2.\t\u2060COUNT, SUM, MAX, GROUP BY, HAVING for aggregating data\"\n3.\t\u2060DISTINCT, COUNT DISTINCT for producing useful distinct lists and distinct aggregates\n4.\t\u2060OUTER (e.g. LEFT) and INNER JOIN when/where to use them\n5.\t\u2060Strings and time conversions\n6.\t\u2060UNION and UNION ALL.\n7.    Window functions like PARTITION\n8.    CTE\u2019s \n9.    CASE \n10.   ROW_Number and Rank \n\nSo back to my original question, how much SQL do you use as a DE and is this short list of concepts above enough for me to move on to learn Python and other relevant skills?", "author_fullname": "t2_22q9pua0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much SQL do you use as a DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rws69", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692116173.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692115383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ask since I am an aspiring DE, currently studying the core skills, and I don\u2019t want to spend unnecessary time grinding SQL exercises because&lt;/p&gt;\n\n&lt;p&gt;1) I know most of my sticky learning is going to come from hands on, real situations/projects &lt;/p&gt;\n\n&lt;p&gt;2) I still need to make time to learn Python/ETL ect. &lt;/p&gt;\n\n&lt;p&gt;I have been studying SQL for 3-5 hours a day for that last 2 weeks (I am so tired of my current career field that I have this burning desire to get out, hence the aggressive study schedule) \nAnd so far have been working on and can answer the easy and medium topics/concepts on stratascratch&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; \u2060SELECT and WHERE for filtering and selection&lt;/li&gt;\n&lt;li&gt; \u2060COUNT, SUM, MAX, GROUP BY, HAVING for aggregating data&amp;quot;&lt;/li&gt;\n&lt;li&gt; \u2060DISTINCT, COUNT DISTINCT for producing useful distinct lists and distinct aggregates&lt;/li&gt;\n&lt;li&gt; \u2060OUTER (e.g. LEFT) and INNER JOIN when/where to use them&lt;/li&gt;\n&lt;li&gt; \u2060Strings and time conversions&lt;/li&gt;\n&lt;li&gt; \u2060UNION and UNION ALL.&lt;/li&gt;\n&lt;li&gt;   Window functions like PARTITION&lt;/li&gt;\n&lt;li&gt;   CTE\u2019s &lt;/li&gt;\n&lt;li&gt;   CASE &lt;/li&gt;\n&lt;li&gt;  ROW_Number and Rank &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So back to my original question, how much SQL do you use as a DE and is this short list of concepts above enough for me to move on to learn Python and other relevant skills?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15rws69", "is_robot_indexable": true, "report_reasons": null, "author": "PoloParachutes", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rws69/how_much_sql_do_you_use_as_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rws69/how_much_sql_do_you_use_as_a_de/", "subreddit_subscribers": 122902, "created_utc": 1692115383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So like the title says my company just got a new corporate daddy and I was wondering if any of you have gone through this and what I can expect as a DE?", "author_fullname": "t2_j2hep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My company just got bought. Is DE usually safe in transitioning phases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rjps5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692078532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So like the title says my company just got a new corporate daddy and I was wondering if any of you have gone through this and what I can expect as a DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15rjps5", "is_robot_indexable": true, "report_reasons": null, "author": "Maniac911", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rjps5/my_company_just_got_bought_is_de_usually_safe_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rjps5/my_company_just_got_bought_is_de_usually_safe_in/", "subreddit_subscribers": 122902, "created_utc": 1692078532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am a project manager at a smaller (~ 50 people) company. \nSince I am the only employee with atleast a little bit of IT and programming background, I started reworking our internal processes a bit, since everything was done super manually in giant unwieldy excel files. This side-project grew and grew and other departments became dependent on my work, so it basically became my second job. \n\nI am now responsible for the collection, storing, cleaning and transformation etc. (Power Quary) of our performance and financial data, building of the data model, as well as the visualization/KPIs (Power BI) and Reporting (Power Automate), so basically the \"data guy\". Besides that also smaller individual tasks like some smaller automation processes with sharepoint lists and VBA macros and the like.\nLater on I want to work with Azure as well, but I have not received the go-ahead from upper management yet. Everything is self-taught by trial and error. Not any deeper analysis like in data science yet, but I can see myself giving it a first try in the future as well.\n\nBut management did acknowledge my work and beside a great raise want to give me a second title that encompasses my work. But they are not sure what to call me and asked me to choose it myself. So now I am not sure what would be the ideal title:\n\n- It should describe all those workstreams of the \"data guy\".\n- It should flow nicely with the first title of project manager, so ideally not too long together.\n- It would makes sense to choose a title that is currently sought after in the (european) job market, I think.\n\nI would be super grateful, if you could give me some suggestions.\n\nThank you!", "author_fullname": "t2_nmbzs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I can give myself a new title, what should I choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rriu4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692103032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am a project manager at a smaller (~ 50 people) company. \nSince I am the only employee with atleast a little bit of IT and programming background, I started reworking our internal processes a bit, since everything was done super manually in giant unwieldy excel files. This side-project grew and grew and other departments became dependent on my work, so it basically became my second job. &lt;/p&gt;\n\n&lt;p&gt;I am now responsible for the collection, storing, cleaning and transformation etc. (Power Quary) of our performance and financial data, building of the data model, as well as the visualization/KPIs (Power BI) and Reporting (Power Automate), so basically the &amp;quot;data guy&amp;quot;. Besides that also smaller individual tasks like some smaller automation processes with sharepoint lists and VBA macros and the like.\nLater on I want to work with Azure as well, but I have not received the go-ahead from upper management yet. Everything is self-taught by trial and error. Not any deeper analysis like in data science yet, but I can see myself giving it a first try in the future as well.&lt;/p&gt;\n\n&lt;p&gt;But management did acknowledge my work and beside a great raise want to give me a second title that encompasses my work. But they are not sure what to call me and asked me to choose it myself. So now I am not sure what would be the ideal title:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It should describe all those workstreams of the &amp;quot;data guy&amp;quot;.&lt;/li&gt;\n&lt;li&gt;It should flow nicely with the first title of project manager, so ideally not too long together.&lt;/li&gt;\n&lt;li&gt;It would makes sense to choose a title that is currently sought after in the (european) job market, I think.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I would be super grateful, if you could give me some suggestions.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15rriu4", "is_robot_indexable": true, "report_reasons": null, "author": "Hachenburger", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rriu4/i_can_give_myself_a_new_title_what_should_i_choose/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rriu4/i_can_give_myself_a_new_title_what_should_i_choose/", "subreddit_subscribers": 122902, "created_utc": 1692103032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nA month ago I started working as a DE at a scale up, expecting it to be super fun and exciting. I've never done something this boring in my life. \n\nI notice that all the tasks are very \"superficial\" (if that makes any sense). Rather then delving deep into the data and finding the root cause of data quality issues, we just do basic checks in SQL and run some automated script to do the rest. The python stuff we do is not that special either, we just open a connection to a database and execute queries in a notebook. Building \"pipelines\" is nothing more than syncing existing scripts from other database to a new environment. \n\nI thought data engineering would be more fun (or at least more tedious). So I've decided to go back to my previous employer, where I was part of the data migration unit (I liked the complexity of data migration but was very curious about DE). \n\nWhat do you guys think, should I give DE another chance? I think I'm better suited for data migration, as it requires a totally different repetoir of skills in addition to hardcore SQL.", "author_fullname": "t2_idmfe2je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm going back to data migration (DE is boring)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rkval", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692082228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;A month ago I started working as a DE at a scale up, expecting it to be super fun and exciting. I&amp;#39;ve never done something this boring in my life. &lt;/p&gt;\n\n&lt;p&gt;I notice that all the tasks are very &amp;quot;superficial&amp;quot; (if that makes any sense). Rather then delving deep into the data and finding the root cause of data quality issues, we just do basic checks in SQL and run some automated script to do the rest. The python stuff we do is not that special either, we just open a connection to a database and execute queries in a notebook. Building &amp;quot;pipelines&amp;quot; is nothing more than syncing existing scripts from other database to a new environment. &lt;/p&gt;\n\n&lt;p&gt;I thought data engineering would be more fun (or at least more tedious). So I&amp;#39;ve decided to go back to my previous employer, where I was part of the data migration unit (I liked the complexity of data migration but was very curious about DE). &lt;/p&gt;\n\n&lt;p&gt;What do you guys think, should I give DE another chance? I think I&amp;#39;m better suited for data migration, as it requires a totally different repetoir of skills in addition to hardcore SQL.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15rkval", "is_robot_indexable": true, "report_reasons": null, "author": "DarthDatar-4058", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rkval/im_going_back_to_data_migration_de_is_boring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rkval/im_going_back_to_data_migration_de_is_boring/", "subreddit_subscribers": 122902, "created_utc": 1692082228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/e2y4gujs69ib1.jpg?width=914&amp;format=pjpg&amp;auto=webp&amp;s=c825b88564b5a5120890475d95c05ead924f7e29\n\n\ud83d\ude80 Introducing \"airflowctl\": a command-line tool to simplify your Apache Airflow onboarding experience without docker! \ud83d\udee0\ufe0f\u2728\n\n\ud83d\udcdc Repo: [https://github.com/kaxil/airflowctl](https://github.com/kaxil/airflowctl)\n\n\u2708\ufe0f Install: `pip install airflowctl`\n\nKey Features:\n\n\u2705 Install and set up Airflow with a single command\n\n\u2705 Initialize your Airflow local environment following best practices\n\n\u2705 Seamlessly manage your Airflow projects.\n\n\u2705 Support different Airflow/Python versions\n\n\u2705 Manage different Airflow projects with ease\n\n\u2705 Works out-of-the-box with the airflow CLI\n\n\u2705 Works without containers\n\n\u2705 Continuously display live logs of Airflow processes\n\nThe main goal for this CLI is for first-time Airflow users to install and setup Airflow using a single command and\n\nfor existing Airflow users to manage multiple Airflow projects with different Airflow versions on the same machine.\n\n**#ApacheAirflow** **#CLI** **#airflow2** **#opensource**", "author_fullname": "t2_178qu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\ude80 Introducing \"airflowctl\": a command-line tool to simplify your Apache Airflow onboarding experience without docker! \ud83d\udee0\ufe0f\u2728", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"e2y4gujs69ib1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/e2y4gujs69ib1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4edee46585a39df7083969ae55e9922740266857"}, {"y": 111, "x": 216, "u": "https://preview.redd.it/e2y4gujs69ib1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=10e0e21e91d2d89262b797e951bdc49e58385f2c"}, {"y": 164, "x": 320, "u": "https://preview.redd.it/e2y4gujs69ib1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1385b8f61561e952d94e8407b37fc18747244163"}, {"y": 329, "x": 640, "u": "https://preview.redd.it/e2y4gujs69ib1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3bdbc816c8567a1fe96c67897ce91774aa3ed313"}], "s": {"y": 470, "x": 914, "u": "https://preview.redd.it/e2y4gujs69ib1.jpg?width=914&amp;format=pjpg&amp;auto=webp&amp;s=c825b88564b5a5120890475d95c05ead924f7e29"}, "id": "e2y4gujs69ib1"}}, "name": "t3_15rp0yr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-sJyUdAddvdIDwcZoLHiLWDt6bzme-ggEXW6LbNcB6M.jpg", "edited": 1692096214.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692095925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/e2y4gujs69ib1.jpg?width=914&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c825b88564b5a5120890475d95c05ead924f7e29\"&gt;https://preview.redd.it/e2y4gujs69ib1.jpg?width=914&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c825b88564b5a5120890475d95c05ead924f7e29&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\ude80 Introducing &amp;quot;airflowctl&amp;quot;: a command-line tool to simplify your Apache Airflow onboarding experience without docker! \ud83d\udee0\ufe0f\u2728&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcdc Repo: &lt;a href=\"https://github.com/kaxil/airflowctl\"&gt;https://github.com/kaxil/airflowctl&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\u2708\ufe0f Install: &lt;code&gt;pip install airflowctl&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Key Features:&lt;/p&gt;\n\n&lt;p&gt;\u2705 Install and set up Airflow with a single command&lt;/p&gt;\n\n&lt;p&gt;\u2705 Initialize your Airflow local environment following best practices&lt;/p&gt;\n\n&lt;p&gt;\u2705 Seamlessly manage your Airflow projects.&lt;/p&gt;\n\n&lt;p&gt;\u2705 Support different Airflow/Python versions&lt;/p&gt;\n\n&lt;p&gt;\u2705 Manage different Airflow projects with ease&lt;/p&gt;\n\n&lt;p&gt;\u2705 Works out-of-the-box with the airflow CLI&lt;/p&gt;\n\n&lt;p&gt;\u2705 Works without containers&lt;/p&gt;\n\n&lt;p&gt;\u2705 Continuously display live logs of Airflow processes&lt;/p&gt;\n\n&lt;p&gt;The main goal for this CLI is for first-time Airflow users to install and setup Airflow using a single command and&lt;/p&gt;\n\n&lt;p&gt;for existing Airflow users to manage multiple Airflow projects with different Airflow versions on the same machine.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;#ApacheAirflow&lt;/strong&gt; &lt;strong&gt;#CLI&lt;/strong&gt; &lt;strong&gt;#airflow2&lt;/strong&gt; &lt;strong&gt;#opensource&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "15rp0yr", "is_robot_indexable": true, "report_reasons": null, "author": "kaxil_naik", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rp0yr/introducing_airflowctl_a_commandline_tool_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rp0yr/introducing_airflowctl_a_commandline_tool_to/", "subreddit_subscribers": 122902, "created_utc": 1692095925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I call myself a Data Engineer, as I started working on DE-related topics 4 years ago, primarily with streaming data from IoT devices. Kafka, NiFi, Python, REST API's, databases, Docker/Kubernetes stuff like that. As I look around on this subreddit, most posts are about ETL, batch processing, data warehouses/lakes, stuff that runs every night to create datamarts, dashboards, etc. \n\nI want to gain some experience in this batch processing field. What are good ways to learn?", "author_fullname": "t2_rdtatmp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn ETL/Batch DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15s182r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692125564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I call myself a Data Engineer, as I started working on DE-related topics 4 years ago, primarily with streaming data from IoT devices. Kafka, NiFi, Python, REST API&amp;#39;s, databases, Docker/Kubernetes stuff like that. As I look around on this subreddit, most posts are about ETL, batch processing, data warehouses/lakes, stuff that runs every night to create datamarts, dashboards, etc. &lt;/p&gt;\n\n&lt;p&gt;I want to gain some experience in this batch processing field. What are good ways to learn?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15s182r", "is_robot_indexable": true, "report_reasons": null, "author": "Friendly_Emu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15s182r/how_to_learn_etlbatch_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15s182r/how_to_learn_etlbatch_de/", "subreddit_subscribers": 122902, "created_utc": 1692125564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you were an organisation in need of a data and analytics solution (that is, with nothing at all implemented at this stage), and you have decided on adopting Microsoft as the vendor of choice, would you say it\u2019s worth looking into Fabric as an option, or would it be better to start (let\u2019s say) with ADF / Synapse with a view to a potential rebuild / refactor into Fabric when it\u2019s in GA?  I know it\u2019s not ready for production workloads (or probably shouldn\u2019t be considered for them just yet), but is there any benefit at this point in time in starting something completely new in Azure when it\u2019s possible Fabric will be in a ready state in the next 6 - 12 months (I\u2019m speculating wildly at this point, I know).", "author_fullname": "t2_avuvljyu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Greenfield Data Engineering Project: Is MS Fabric a viable option?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rxyuf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692118197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you were an organisation in need of a data and analytics solution (that is, with nothing at all implemented at this stage), and you have decided on adopting Microsoft as the vendor of choice, would you say it\u2019s worth looking into Fabric as an option, or would it be better to start (let\u2019s say) with ADF / Synapse with a view to a potential rebuild / refactor into Fabric when it\u2019s in GA?  I know it\u2019s not ready for production workloads (or probably shouldn\u2019t be considered for them just yet), but is there any benefit at this point in time in starting something completely new in Azure when it\u2019s possible Fabric will be in a ready state in the next 6 - 12 months (I\u2019m speculating wildly at this point, I know).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15rxyuf", "is_robot_indexable": true, "report_reasons": null, "author": "data_boss", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rxyuf/greenfield_data_engineering_project_is_ms_fabric/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rxyuf/greenfield_data_engineering_project_is_ms_fabric/", "subreddit_subscribers": 122902, "created_utc": 1692118197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Very simple objective:\n\nYou want to extract all the data from an API and save it to S3 or GCS. Your solution must run on the cloud.\n\nThis may take hours to complete, so the solution needs be resilient and have some sort of checkpointing mechanism\n\nI've tried a few different approaches to this kind of stuff over the years, some worked well, some didn't .\n\nI tried running a python script on an VM instance and using object storage for checkpointing. That was fine.\n\nOther thing I did was breaking down the extraction in multiple \"tasks\", each corresponding to a single request, and load them into an SQS queue. Lambda functions would consume from the queue and execute the extraction. This was my favorite way so far.\n\nRight now I'm trying to learn containers, so I'm trying to build a containerized solution. I'm using Cloud Run because my client is on GCP, and it has been a PAIN IN THE ASS to do.\n\nI want to see this problem from different angles. I think I'm missing out on something. How do you people do it?", "author_fullname": "t2_13cgzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you develop API data migration jobs on the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rxlk1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692117331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Very simple objective:&lt;/p&gt;\n\n&lt;p&gt;You want to extract all the data from an API and save it to S3 or GCS. Your solution must run on the cloud.&lt;/p&gt;\n\n&lt;p&gt;This may take hours to complete, so the solution needs be resilient and have some sort of checkpointing mechanism&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried a few different approaches to this kind of stuff over the years, some worked well, some didn&amp;#39;t .&lt;/p&gt;\n\n&lt;p&gt;I tried running a python script on an VM instance and using object storage for checkpointing. That was fine.&lt;/p&gt;\n\n&lt;p&gt;Other thing I did was breaking down the extraction in multiple &amp;quot;tasks&amp;quot;, each corresponding to a single request, and load them into an SQS queue. Lambda functions would consume from the queue and execute the extraction. This was my favorite way so far.&lt;/p&gt;\n\n&lt;p&gt;Right now I&amp;#39;m trying to learn containers, so I&amp;#39;m trying to build a containerized solution. I&amp;#39;m using Cloud Run because my client is on GCP, and it has been a PAIN IN THE ASS to do.&lt;/p&gt;\n\n&lt;p&gt;I want to see this problem from different angles. I think I&amp;#39;m missing out on something. How do you people do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15rxlk1", "is_robot_indexable": true, "report_reasons": null, "author": "Altrooke", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rxlk1/how_do_you_develop_api_data_migration_jobs_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rxlk1/how_do_you_develop_api_data_migration_jobs_on_the/", "subreddit_subscribers": 122902, "created_utc": 1692117331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cb5j4xjcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplicity and Power of Agg Indexes at Scale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_15rp0t3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/SP183XHOa14FYTFPdzAX_u1klCx-0u_pVUPxYCHxoAI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692095913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "selectfrom.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://selectfrom.dev/simplicity-and-power-of-agg-indexes-at-scale-315d0de2fc29", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/h7lJKWLQtHbSrGFUuPovJvRIsPH955jVVCbGG1diT3E.jpg?auto=webp&amp;s=2226a670c463c2c321b28297ab61c4fdbc2845bb", "width": 623, "height": 365}, "resolutions": [{"url": "https://external-preview.redd.it/h7lJKWLQtHbSrGFUuPovJvRIsPH955jVVCbGG1diT3E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a5e7824c9ae908359072feaf5157d5142d54f0ef", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/h7lJKWLQtHbSrGFUuPovJvRIsPH955jVVCbGG1diT3E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4482a00cc8efb29ca89e8ed6c9a896a4538e2051", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/h7lJKWLQtHbSrGFUuPovJvRIsPH955jVVCbGG1diT3E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9fdc411d38661090804a3e6ad213758f824648c0", "width": 320, "height": 187}], "variants": {}, "id": "ZVJmMR6ABmh_PdgdB2f6DUalj_vNsOetAh1uM40Mwp8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15rp0t3", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous-Surround882", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rp0t3/simplicity_and_power_of_agg_indexes_at_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://selectfrom.dev/simplicity-and-power-of-agg-indexes-at-scale-315d0de2fc29", "subreddit_subscribers": 122902, "created_utc": 1692095913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working in quant finance for 5+ years on a trading desk.\nHow possible do you think it'd be to move into data engineering at FAANG at a non-entry level?\n\nDay to day I'm making tools for traders for manage their risk and trades, to visualise their market data, or just to scrape more stuff for them from internal/external APIs and databases.\n\nI manage a modest sized (100k lines) Python library which I use for a bunch of ETL processes, and also for some Python bindings for some external pricing library functions in DLLs.\n \nI put all of my data into a SQLite database at the moment. It's pretty well designed I think as I had experience a few years ago with developing a much larger MS SQL database, and I'm only in the gigabytes still. If I can get a bit of funding I'd investigate getting more data, and using some other data store (maybe another MS SQL instance) just for fun.\n\nSo I understand that at FAANG you'd be using something like Apache Airflow, lots of Hive / Spark, but also plenty of Python and SQL.\nTo enter at a higher level I'm concerned that my lack of experience with the distributed data stores and the petabyte scale could limit me.\n\nDev wise I think I'm pretty good, I used to be a C++/C# quant and although I don't have a degree in comp sci I do have a PhD in applied math (which I hope might count for something).\n\nAny advice or thoughts is really appreciated", "author_fullname": "t2_8xuyx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering from Quant finance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rnvgs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692092286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working in quant finance for 5+ years on a trading desk.\nHow possible do you think it&amp;#39;d be to move into data engineering at FAANG at a non-entry level?&lt;/p&gt;\n\n&lt;p&gt;Day to day I&amp;#39;m making tools for traders for manage their risk and trades, to visualise their market data, or just to scrape more stuff for them from internal/external APIs and databases.&lt;/p&gt;\n\n&lt;p&gt;I manage a modest sized (100k lines) Python library which I use for a bunch of ETL processes, and also for some Python bindings for some external pricing library functions in DLLs.&lt;/p&gt;\n\n&lt;p&gt;I put all of my data into a SQLite database at the moment. It&amp;#39;s pretty well designed I think as I had experience a few years ago with developing a much larger MS SQL database, and I&amp;#39;m only in the gigabytes still. If I can get a bit of funding I&amp;#39;d investigate getting more data, and using some other data store (maybe another MS SQL instance) just for fun.&lt;/p&gt;\n\n&lt;p&gt;So I understand that at FAANG you&amp;#39;d be using something like Apache Airflow, lots of Hive / Spark, but also plenty of Python and SQL.\nTo enter at a higher level I&amp;#39;m concerned that my lack of experience with the distributed data stores and the petabyte scale could limit me.&lt;/p&gt;\n\n&lt;p&gt;Dev wise I think I&amp;#39;m pretty good, I used to be a C++/C# quant and although I don&amp;#39;t have a degree in comp sci I do have a PhD in applied math (which I hope might count for something).&lt;/p&gt;\n\n&lt;p&gt;Any advice or thoughts is really appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15rnvgs", "is_robot_indexable": true, "report_reasons": null, "author": "Falcomomo", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rnvgs/data_engineering_from_quant_finance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rnvgs/data_engineering_from_quant_finance/", "subreddit_subscribers": 122902, "created_utc": 1692092286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm a healthcare professional who got into the data field after completing a masters degree in clinical research 6 years ago. I taught myself R, Python and SQL initially to analyze data and create visualizations and interactive dashboards but knowing how to program eventually lead to a lot of automation of data workflows in my organization. I also developed R and Python packages and libraries and have full-stack dev skills as well.\n\nI've realized over time that I enjoy developing/building things more than I necessarily like business intelligence type tasks, creating metrics or trying to find insights with data. I spent a lot of time over the course of this year focusing on DSA and full-stack skills but I'm ready to move out of my role and get into either a data engineering or software engineering role. I have some familiarity with AWS, but I don't have experience using Spark or similar technologies and was wondering if the skills I have would be transferrable to get into data engineering and what gaps I should fill otherwise. I'm feeling unbelievably stuck in my role in analytics and looking for a way out! ", "author_fullname": "t2_2prckadt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transferrable skills from \"data analyst\" titles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15s4ty7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692133021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a healthcare professional who got into the data field after completing a masters degree in clinical research 6 years ago. I taught myself R, Python and SQL initially to analyze data and create visualizations and interactive dashboards but knowing how to program eventually lead to a lot of automation of data workflows in my organization. I also developed R and Python packages and libraries and have full-stack dev skills as well.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve realized over time that I enjoy developing/building things more than I necessarily like business intelligence type tasks, creating metrics or trying to find insights with data. I spent a lot of time over the course of this year focusing on DSA and full-stack skills but I&amp;#39;m ready to move out of my role and get into either a data engineering or software engineering role. I have some familiarity with AWS, but I don&amp;#39;t have experience using Spark or similar technologies and was wondering if the skills I have would be transferrable to get into data engineering and what gaps I should fill otherwise. I&amp;#39;m feeling unbelievably stuck in my role in analytics and looking for a way out! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15s4ty7", "is_robot_indexable": true, "report_reasons": null, "author": "thro0away12", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15s4ty7/transferrable_skills_from_data_analyst_titles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15s4ty7/transferrable_skills_from_data_analyst_titles/", "subreddit_subscribers": 122902, "created_utc": 1692133021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for feedback from Data Architects/Senior developers for a tool we've developed which is similar to Pyramid Analytics. Would offer you a $50 Amazon gift card for your time (apologies we can't offer more as we are in startup mode). Took a year and about 10 people to create this but we really love it and think it has a ton of potential but want to show it to people in the industry to really see where it can be helpful. Please send me a DM or chat with your email and title if you're interested....Thank you in advance..\n\nKey features: One tool that integrates all of the key features to create low-code/no-code Data Analytics solutions:\n\n* Explore data - Explore any databases, data lakes, or Rest API directly from one interface\n* Create virtualized view from any data source. Join disparate data sources and use SQL for everything including S3 Files and Rest API\n* Take any view and turn it into an API for other applications\n* Create visualizations\n* Machine Learning with Auto ML, Jupyter notebook integration\n* Amazon Glue like ETL interface\n* Automation/Workflow to create data pipelines\n* Works for regular as well as big data", "author_fullname": "t2_7708dtoq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for feedback from Data Architects/Senior developers - Amazon gift card", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ry3qv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692133860.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692118508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for feedback from Data Architects/Senior developers for a tool we&amp;#39;ve developed which is similar to Pyramid Analytics. Would offer you a $50 Amazon gift card for your time (apologies we can&amp;#39;t offer more as we are in startup mode). Took a year and about 10 people to create this but we really love it and think it has a ton of potential but want to show it to people in the industry to really see where it can be helpful. Please send me a DM or chat with your email and title if you&amp;#39;re interested....Thank you in advance..&lt;/p&gt;\n\n&lt;p&gt;Key features: One tool that integrates all of the key features to create low-code/no-code Data Analytics solutions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Explore data - Explore any databases, data lakes, or Rest API directly from one interface&lt;/li&gt;\n&lt;li&gt;Create virtualized view from any data source. Join disparate data sources and use SQL for everything including S3 Files and Rest API&lt;/li&gt;\n&lt;li&gt;Take any view and turn it into an API for other applications&lt;/li&gt;\n&lt;li&gt;Create visualizations&lt;/li&gt;\n&lt;li&gt;Machine Learning with Auto ML, Jupyter notebook integration&lt;/li&gt;\n&lt;li&gt;Amazon Glue like ETL interface&lt;/li&gt;\n&lt;li&gt;Automation/Workflow to create data pipelines&lt;/li&gt;\n&lt;li&gt;Works for regular as well as big data&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ry3qv", "is_robot_indexable": true, "report_reasons": null, "author": "Original_Yesterday_9", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ry3qv/looking_for_feedback_from_data_architectssenior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ry3qv/looking_for_feedback_from_data_architectssenior/", "subreddit_subscribers": 122902, "created_utc": 1692118508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Been doing DE for a company for a year now. However it's my first job as DE. As a first job I have some questions regarding my role since there isn't another DE inside my team..\n\nIs it normal to use terraform in your day to day? I'm requiered for one project inside AWS  to use terraform but not sure if this is normal inside a DE job or not.\n\nIs it normal to setup VPC subnets and such? I'm trying to connect multiple databases but not sure if that's something I have to learn and do or if it's something that it's done by DevOps / IT team.\n\nIs it normal to be actively setting up meetings and followup calls ( as in project management) to get things done? I feel that my job is slowly evolving to do more followups to other team members than actually coding or setting up pipelines.\n\n\nAny advice is welcome, just not sure if I have to step it up and take more ownership or push back to what it's outside a DE job.  I'm actually loving my job due to all the freedom to learn. But not sure if I'm being asked too much or not.", "author_fullname": "t2_huqm5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First job questions about role expectations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rbeh8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692056937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been doing DE for a company for a year now. However it&amp;#39;s my first job as DE. As a first job I have some questions regarding my role since there isn&amp;#39;t another DE inside my team..&lt;/p&gt;\n\n&lt;p&gt;Is it normal to use terraform in your day to day? I&amp;#39;m requiered for one project inside AWS  to use terraform but not sure if this is normal inside a DE job or not.&lt;/p&gt;\n\n&lt;p&gt;Is it normal to setup VPC subnets and such? I&amp;#39;m trying to connect multiple databases but not sure if that&amp;#39;s something I have to learn and do or if it&amp;#39;s something that it&amp;#39;s done by DevOps / IT team.&lt;/p&gt;\n\n&lt;p&gt;Is it normal to be actively setting up meetings and followup calls ( as in project management) to get things done? I feel that my job is slowly evolving to do more followups to other team members than actually coding or setting up pipelines.&lt;/p&gt;\n\n&lt;p&gt;Any advice is welcome, just not sure if I have to step it up and take more ownership or push back to what it&amp;#39;s outside a DE job.  I&amp;#39;m actually loving my job due to all the freedom to learn. But not sure if I&amp;#39;m being asked too much or not.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15rbeh8", "is_robot_indexable": true, "report_reasons": null, "author": "tbarg91", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rbeh8/first_job_questions_about_role_expectations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rbeh8/first_job_questions_about_role_expectations/", "subreddit_subscribers": 122902, "created_utc": 1692056937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are doing a migration of a bunch of Oracle data to Snowflake and installing a new data model.  Would like to just auto translate the DDL from Oracle to Snowflake if possible rather than hand editing them.  Found an online site that didn't work and a python script on the Snowflake site that I think will take some work to get working.  Anybody know of any other free resources to do this?  Any help is appreciated!", "author_fullname": "t2_117fpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oracle to Snowflake DDL translation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15s7v8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692140068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are doing a migration of a bunch of Oracle data to Snowflake and installing a new data model.  Would like to just auto translate the DDL from Oracle to Snowflake if possible rather than hand editing them.  Found an online site that didn&amp;#39;t work and a python script on the Snowflake site that I think will take some work to get working.  Anybody know of any other free resources to do this?  Any help is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15s7v8p", "is_robot_indexable": true, "report_reasons": null, "author": "Gators1992", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15s7v8p/oracle_to_snowflake_ddl_translation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15s7v8p/oracle_to_snowflake_ddl_translation/", "subreddit_subscribers": 122902, "created_utc": 1692140068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The objective is to find item sales that would be tagged if over certain thresholds based on their customer type and region. My manager gave me configuration data in the below ugly format (just as example, actual data is much more varied for each state):\n\n&amp;#x200B;\n\nhttps://preview.redd.it/ifk1bko3zbib1.png?width=732&amp;format=png&amp;auto=webp&amp;s=9dc273e783b3011e12f24c5eee2c1e1397c4b0a2\n\nThey would like to see a full table of all minimum configuration options that would cause tagging, so Michigan as an example's full configuration options would look like:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/k5766l791cib1.png?width=506&amp;format=png&amp;auto=webp&amp;s=acb92f9dcc63a5def23e2bd0dbfa0afe2aa07b60\n\nBut I want to take it a step further and normalize the data if possible, so if they want to change Bucket 2's tagging thresholds, we'd only need to change it in one dimension table. What I'm having trouble with is wrapping my head around how to set up each dimension table, since so many columns depend on other columns, I just cant visualize if normalization is even possible or a good idea here. Alternatively, are there any typical methods for configuration tables such as these and maybe I should be thinking of it in a different way than a star schema?", "author_fullname": "t2_l3oy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner looking for help or best practices on structuring this sales configuration/settings data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 36, "top_awarded_type": null, "hide_score": false, "media_metadata": {"k5766l791cib1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/k5766l791cib1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=23a504e314b71c19d0eb4e6819f915e832584b60"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/k5766l791cib1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f3c9187011abbb596fbb653f964305dbae8da84e"}, {"y": 152, "x": 320, "u": "https://preview.redd.it/k5766l791cib1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=65c84fd7883a24b9f1cd29c952330fced884ee73"}], "s": {"y": 241, "x": 506, "u": "https://preview.redd.it/k5766l791cib1.png?width=506&amp;format=png&amp;auto=webp&amp;s=acb92f9dcc63a5def23e2bd0dbfa0afe2aa07b60"}, "id": "k5766l791cib1"}, "ifk1bko3zbib1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 28, "x": 108, "u": "https://preview.redd.it/ifk1bko3zbib1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=116be426708fd4f4b8545a412e9e7711c0963725"}, {"y": 56, "x": 216, "u": "https://preview.redd.it/ifk1bko3zbib1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a103affe0fa5cf64c75e0ea5a3cbad6f97bda7b2"}, {"y": 84, "x": 320, "u": "https://preview.redd.it/ifk1bko3zbib1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=edc733985fe63168fda0c06c08a82bd60630a721"}, {"y": 168, "x": 640, "u": "https://preview.redd.it/ifk1bko3zbib1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f08e6217b22bca9e99d79640c563b6c2976e199f"}], "s": {"y": 193, "x": 732, "u": "https://preview.redd.it/ifk1bko3zbib1.png?width=732&amp;format=png&amp;auto=webp&amp;s=9dc273e783b3011e12f24c5eee2c1e1397c4b0a2"}, "id": "ifk1bko3zbib1"}}, "name": "t3_15s4eb3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/vmMq-Pd9LcRgkaet5DiV33-jH-HkBkgR6HqSBLSM840.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692132047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The objective is to find item sales that would be tagged if over certain thresholds based on their customer type and region. My manager gave me configuration data in the below ugly format (just as example, actual data is much more varied for each state):&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ifk1bko3zbib1.png?width=732&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9dc273e783b3011e12f24c5eee2c1e1397c4b0a2\"&gt;https://preview.redd.it/ifk1bko3zbib1.png?width=732&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9dc273e783b3011e12f24c5eee2c1e1397c4b0a2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;They would like to see a full table of all minimum configuration options that would cause tagging, so Michigan as an example&amp;#39;s full configuration options would look like:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/k5766l791cib1.png?width=506&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=acb92f9dcc63a5def23e2bd0dbfa0afe2aa07b60\"&gt;https://preview.redd.it/k5766l791cib1.png?width=506&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=acb92f9dcc63a5def23e2bd0dbfa0afe2aa07b60&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But I want to take it a step further and normalize the data if possible, so if they want to change Bucket 2&amp;#39;s tagging thresholds, we&amp;#39;d only need to change it in one dimension table. What I&amp;#39;m having trouble with is wrapping my head around how to set up each dimension table, since so many columns depend on other columns, I just cant visualize if normalization is even possible or a good idea here. Alternatively, are there any typical methods for configuration tables such as these and maybe I should be thinking of it in a different way than a star schema?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15s4eb3", "is_robot_indexable": true, "report_reasons": null, "author": "LeftShark", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15s4eb3/beginner_looking_for_help_or_best_practices_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15s4eb3/beginner_looking_for_help_or_best_practices_on/", "subreddit_subscribers": 122902, "created_utc": 1692132047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow Data Engineers,\n\nAre you passionate about diving into the intricate world of data migration? Whether you're a seasoned pro or just starting out in the field, if you're fascinated by the complexities and challenges of moving data from one system to another, I invite you to join us at r/DataMigrations!\n\nIn the DataMigrations subreddit, we're all about exploring the nuances of data migration processes. Share your experiences, ask questions, and discuss best practices with a community of like-minded individuals who truly understand the ins and outs of this critical aspect of data migration.\n\nWhether you're dealing with ETL pipelines, schema transformations, or cross-platform migration strategies, this is the place to connect with others who share your passion. Let's come together to learn, collaborate, and tackle the challenges that come with ensuring seamless and efficient data transitions.\n\nJoin us at r/DataMigrations and let's embark on this data migration journey together. See you there!", "author_fullname": "t2_idmfe2je", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interested in Data Migration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15s4747", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692131601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Data Engineers,&lt;/p&gt;\n\n&lt;p&gt;Are you passionate about diving into the intricate world of data migration? Whether you&amp;#39;re a seasoned pro or just starting out in the field, if you&amp;#39;re fascinated by the complexities and challenges of moving data from one system to another, I invite you to join us at &lt;a href=\"/r/DataMigrations\"&gt;r/DataMigrations&lt;/a&gt;!&lt;/p&gt;\n\n&lt;p&gt;In the DataMigrations subreddit, we&amp;#39;re all about exploring the nuances of data migration processes. Share your experiences, ask questions, and discuss best practices with a community of like-minded individuals who truly understand the ins and outs of this critical aspect of data migration.&lt;/p&gt;\n\n&lt;p&gt;Whether you&amp;#39;re dealing with ETL pipelines, schema transformations, or cross-platform migration strategies, this is the place to connect with others who share your passion. Let&amp;#39;s come together to learn, collaborate, and tackle the challenges that come with ensuring seamless and efficient data transitions.&lt;/p&gt;\n\n&lt;p&gt;Join us at &lt;a href=\"/r/DataMigrations\"&gt;r/DataMigrations&lt;/a&gt; and let&amp;#39;s embark on this data migration journey together. See you there!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15s4747", "is_robot_indexable": true, "report_reasons": null, "author": "DarthDatar-4058", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15s4747/interested_in_data_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15s4747/interested_in_data_migration/", "subreddit_subscribers": 122902, "created_utc": 1692131601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a company in California, but I live abroad in Asia (I have dual citizenship and pay US taxes) \n\nI'm getting paid probably like half the other DE2s, but giving the same or more output.\n\nIt's a good salary for where I live, but of course, we always want higher salaries lol\n\nAny suggestions on how I am able to negotiate for higher salaries?\n\nOr it's easier to try to get another remote role?\n\nAny feedback is much appreciated :)", "author_fullname": "t2_av88gzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE2 working abroad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rxwh0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692118045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a company in California, but I live abroad in Asia (I have dual citizenship and pay US taxes) &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m getting paid probably like half the other DE2s, but giving the same or more output.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s a good salary for where I live, but of course, we always want higher salaries lol&lt;/p&gt;\n\n&lt;p&gt;Any suggestions on how I am able to negotiate for higher salaries?&lt;/p&gt;\n\n&lt;p&gt;Or it&amp;#39;s easier to try to get another remote role?&lt;/p&gt;\n\n&lt;p&gt;Any feedback is much appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15rxwh0", "is_robot_indexable": true, "report_reasons": null, "author": "rdmcoloring", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15rxwh0/de2_working_abroad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rxwh0/de2_working_abroad/", "subreddit_subscribers": 122902, "created_utc": 1692118045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone using Dataflows directly inside a Notebook in Microsoft Fabric?\n\nWe have a stack of Dataflows set up (that are themselves mostly api connections to source operational data, with some Power Query transformations). I want to query the Dataflow directly within a Python or R script in a Notebook, but it doesn't seem possible. \n\nIt seems like I can only connect to Lakehouses within my Notebooks. Feel like I'm missing something obvious.\n\n&amp;#x200B;", "author_fullname": "t2_e7ybf8uo1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft Fabric Dataflows and notebooks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rwyuu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692115809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone using Dataflows directly inside a Notebook in Microsoft Fabric?&lt;/p&gt;\n\n&lt;p&gt;We have a stack of Dataflows set up (that are themselves mostly api connections to source operational data, with some Power Query transformations). I want to query the Dataflow directly within a Python or R script in a Notebook, but it doesn&amp;#39;t seem possible. &lt;/p&gt;\n\n&lt;p&gt;It seems like I can only connect to Lakehouses within my Notebooks. Feel like I&amp;#39;m missing something obvious.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15rwyuu", "is_robot_indexable": true, "report_reasons": null, "author": "data_quantum", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rwyuu/microsoft_fabric_dataflows_and_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rwyuu/microsoft_fabric_dataflows_and_notebooks/", "subreddit_subscribers": 122902, "created_utc": 1692115809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9ktxtch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automating Data Deduplication in Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 35, "top_awarded_type": null, "hide_score": false, "name": "t3_15rwkqm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/0dfBmgrRe3ZT9_ooevHsZs4Jv9V9sYkO7JV4QTod7U4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692114950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@samibnyyasen/automating-data-deduplication-in-snowflake-with-tilores-b9dbd5bc37b7", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FUGkNGCR9vet2Jv9e9doBYecohcY9oonC0izOZk__a4.jpg?auto=webp&amp;s=531a92f4b151082e2814a9a9c4af0c4d0fcfdb99", "width": 1200, "height": 305}, "resolutions": [{"url": "https://external-preview.redd.it/FUGkNGCR9vet2Jv9e9doBYecohcY9oonC0izOZk__a4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ee313f4c93794643ee15800bdb66bc3457743220", "width": 108, "height": 27}, {"url": "https://external-preview.redd.it/FUGkNGCR9vet2Jv9e9doBYecohcY9oonC0izOZk__a4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5891cd0736b56c8493b8cb6db665ed42ad2ae3f5", "width": 216, "height": 54}, {"url": "https://external-preview.redd.it/FUGkNGCR9vet2Jv9e9doBYecohcY9oonC0izOZk__a4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a584ad21a66181d22678d2fe812b1d14ae10cbef", "width": 320, "height": 81}, {"url": "https://external-preview.redd.it/FUGkNGCR9vet2Jv9e9doBYecohcY9oonC0izOZk__a4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=94993359e75c6a1eb35751105ee2ac5eadcae906", "width": 640, "height": 162}, {"url": "https://external-preview.redd.it/FUGkNGCR9vet2Jv9e9doBYecohcY9oonC0izOZk__a4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9bccd6075e42c401a3a505ee3c7d1dcdec6f2538", "width": 960, "height": 244}, {"url": "https://external-preview.redd.it/FUGkNGCR9vet2Jv9e9doBYecohcY9oonC0izOZk__a4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ce22c197a8b104279db790c865c2b79506e14180", "width": 1080, "height": 274}], "variants": {}, "id": "VFSmd9_xliy1aL5WRLsvpzxrZFYNhEDNGJiI20x6EiQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15rwkqm", "is_robot_indexable": true, "report_reasons": null, "author": "sami_yaseen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rwkqm/automating_data_deduplication_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@samibnyyasen/automating-data-deduplication-in-snowflake-with-tilores-b9dbd5bc37b7", "subreddit_subscribers": 122902, "created_utc": 1692114950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analytics Project in Code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15rky1b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EDXS2G7EX_wQbuYJee1WZF_wZysJjiGvMxREH62UFik.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692082480.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "gooddata.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.gooddata.com/blog/how-to-create-your-next-analytical-project-in-code/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rc8Y0ZkN0zaLFYgTNp7rYlDF81RoYjK8v17A73mjuUQ.jpg?auto=webp&amp;s=b054f4b4ff6306c54a5f7ba7a0d247cbe2aa9e91", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/rc8Y0ZkN0zaLFYgTNp7rYlDF81RoYjK8v17A73mjuUQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a5c69ecbb4a2ca6413c111699e4a28f1b68e121b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/rc8Y0ZkN0zaLFYgTNp7rYlDF81RoYjK8v17A73mjuUQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9532283eb8c802329deef9e04e6a4f0ac1b98baf", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/rc8Y0ZkN0zaLFYgTNp7rYlDF81RoYjK8v17A73mjuUQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e21a9efc1cd7a95f7c86f19bc4c2d350588b5591", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/rc8Y0ZkN0zaLFYgTNp7rYlDF81RoYjK8v17A73mjuUQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe71ef3bd3a92ba8fcacd3da7e31fd7d69e0bec3", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/rc8Y0ZkN0zaLFYgTNp7rYlDF81RoYjK8v17A73mjuUQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5bb0f9bcb78c22c42ad56f1d701f72ae4affa56a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/rc8Y0ZkN0zaLFYgTNp7rYlDF81RoYjK8v17A73mjuUQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5853a8b136c7638ace92ce505f223591d7093172", "width": 1080, "height": 567}], "variants": {}, "id": "30Es3ctmPSIBA6h5bc7FT7vc2hTZMATCp9B8EARQ-So"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15rky1b", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rky1b/analytics_project_in_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.gooddata.com/blog/how-to-create-your-next-analytical-project-in-code/", "subreddit_subscribers": 122902, "created_utc": 1692082480.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for resources to visualize data using BI tools. ", "author_fullname": "t2_qhakya0m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tools do you use for BI widgets and dashboarding ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rj6x6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692076925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for resources to visualize data using BI tools. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15rj6x6", "is_robot_indexable": true, "report_reasons": null, "author": "enzineer-reddit", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rj6x6/what_tools_do_you_use_for_bi_widgets_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rj6x6/what_tools_do_you_use_for_bi_widgets_and/", "subreddit_subscribers": 122902, "created_utc": 1692076925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a Software Engineer on a team at a F500 with no dedicated DEs. I\u2019ve delivered a few data projects in the past, mostly building ETLs that have simple source/target/triggers. These have always been Python applications with SQL and S3, without much of the orchestration and other DE tooling around it.\n\nIf I want to move into a dedicated DE role, does this experience count for much? I don\u2019t have many opportunities to learn more of the other tools, since the simpler architecture has always worked fine in the past.", "author_fullname": "t2_crlro7a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how far does only Python/SQL get you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rhzol", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692073292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a Software Engineer on a team at a F500 with no dedicated DEs. I\u2019ve delivered a few data projects in the past, mostly building ETLs that have simple source/target/triggers. These have always been Python applications with SQL and S3, without much of the orchestration and other DE tooling around it.&lt;/p&gt;\n\n&lt;p&gt;If I want to move into a dedicated DE role, does this experience count for much? I don\u2019t have many opportunities to learn more of the other tools, since the simpler architecture has always worked fine in the past.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15rhzol", "is_robot_indexable": true, "report_reasons": null, "author": "michelin_chalupa", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rhzol/how_far_does_only_pythonsql_get_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rhzol/how_far_does_only_pythonsql_get_you/", "subreddit_subscribers": 122902, "created_utc": 1692073292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need help", "author_fullname": "t2_unoeaew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help: I'm a Brazilian lawyer 29yo, will i be able to change my profession to DE at this point of my life?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15s6y08", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692137828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15s6y08", "is_robot_indexable": true, "report_reasons": null, "author": "Hobbit_Hunter", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15s6y08/need_help_im_a_brazilian_lawyer_29yo_will_i_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15s6y08/need_help_im_a_brazilian_lawyer_29yo_will_i_be/", "subreddit_subscribers": 122902, "created_utc": 1692137828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been designing various ETL processes within pandas for some time now. One of the use cases I come across frequently, particularly within data migrations, is to read data in from a sq query, run some complex manipulations using Pandas, otherwise unachievable (or at least very complex) using SQL.\n\nIn some cases, particularly for large transactional tables of 50mil plus rows, we\u2019ve had memory issues which we have resolved via chunking, or by resorting to constructing very complex stored procedures in SQL where chunking is not ideal (often where a series of GROUP BYs are required). Another issue is that these processes never beat the performance we could get if we constructed the queries within SQL, even though they are much easier to maintain and create. We have had issues where a data migration would simply take too long for certain tables for a go-live script.\n\nI\u2019ve been reading into Polars, and am going to start structuring some reports to get a feel for it - ultimately, I would like to replace stored procedures where possible.\n\nOne thing to note here, reading through the docs, is that I usually use SQLAlchemy for the data download - but I notice polars explicitly stated the benefits of using Connectorx which might solve some of this issue for me.\n\nHas anyone done any benchmarking to compare native SQL queries to the same query performed in Polars? Particularly interested in processes that drop duplicates rows etc - queries that are not easily made within SQL once you start having multiple queries, temp tables and ctes (even with window functions).\n\nEqually, if these types of benchmarks have not been made, I might do some benchmarking of my own - I would be interested in some example functions that are much easier to construct in polars vs sql that anyone would like to be included.", "author_fullname": "t2_7jmoaa90", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Polars vs Sql Query Performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15rndo6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692090650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been designing various ETL processes within pandas for some time now. One of the use cases I come across frequently, particularly within data migrations, is to read data in from a sq query, run some complex manipulations using Pandas, otherwise unachievable (or at least very complex) using SQL.&lt;/p&gt;\n\n&lt;p&gt;In some cases, particularly for large transactional tables of 50mil plus rows, we\u2019ve had memory issues which we have resolved via chunking, or by resorting to constructing very complex stored procedures in SQL where chunking is not ideal (often where a series of GROUP BYs are required). Another issue is that these processes never beat the performance we could get if we constructed the queries within SQL, even though they are much easier to maintain and create. We have had issues where a data migration would simply take too long for certain tables for a go-live script.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been reading into Polars, and am going to start structuring some reports to get a feel for it - ultimately, I would like to replace stored procedures where possible.&lt;/p&gt;\n\n&lt;p&gt;One thing to note here, reading through the docs, is that I usually use SQLAlchemy for the data download - but I notice polars explicitly stated the benefits of using Connectorx which might solve some of this issue for me.&lt;/p&gt;\n\n&lt;p&gt;Has anyone done any benchmarking to compare native SQL queries to the same query performed in Polars? Particularly interested in processes that drop duplicates rows etc - queries that are not easily made within SQL once you start having multiple queries, temp tables and ctes (even with window functions).&lt;/p&gt;\n\n&lt;p&gt;Equally, if these types of benchmarks have not been made, I might do some benchmarking of my own - I would be interested in some example functions that are much easier to construct in polars vs sql that anyone would like to be included.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15rndo6", "is_robot_indexable": true, "report_reasons": null, "author": "Alternative_Hungry", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15rndo6/polars_vs_sql_query_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15rndo6/polars_vs_sql_query_performance/", "subreddit_subscribers": 122902, "created_utc": 1692090650.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}