{"kind": "Listing", "data": {"after": "t3_161pr5h", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I guess I\u2019m trying to determine if my current job is just actually boring and dull or if this is a wider issue in data science. I\u2019m doing a total life overhaul and just need to figure out my occupation. \n\nI work for an insurance company. Been there a year now. I basically stumbled into the position. I wrapped up a previous masters degree and applied to a program on a whim. The program paid for a masters degree and gave me a paid work placement. For some reason I was accepted despite having no math background. I just finished the degree portion and I was offered a contract with the company I did the placement with. \n\nBasically I find the work pretty boring. It\u2019s hybrid work and a lot of the time I goof off at home and just put in the actual hours when I\u2019m in the office. I basically say to myself over and over that I don\u2019t know why I would bust my ass to make my CEO more money. A lot of the work I find to be a huge waste of time. I was previously in the military so I really understand bullshit projects and time wasting but it feels different on the civilian side I guess. \n\nI really don\u2019t know if the data science world is for me. Do you find the work rewarding in other fields? Basically I really do find data science interesting and I know I have a LOT more to learn but most of the jobs seem to be in banking, finance etc. I basically am just working to make some other dude more money and that just bugs me. I can see myself applying these skills helping people but I guess I just don\u2019t know how or where.", "author_fullname": "t2_9c3vih4ps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meaningful work -my company or all of data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161qjdh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693042283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I guess I\u2019m trying to determine if my current job is just actually boring and dull or if this is a wider issue in data science. I\u2019m doing a total life overhaul and just need to figure out my occupation. &lt;/p&gt;\n\n&lt;p&gt;I work for an insurance company. Been there a year now. I basically stumbled into the position. I wrapped up a previous masters degree and applied to a program on a whim. The program paid for a masters degree and gave me a paid work placement. For some reason I was accepted despite having no math background. I just finished the degree portion and I was offered a contract with the company I did the placement with. &lt;/p&gt;\n\n&lt;p&gt;Basically I find the work pretty boring. It\u2019s hybrid work and a lot of the time I goof off at home and just put in the actual hours when I\u2019m in the office. I basically say to myself over and over that I don\u2019t know why I would bust my ass to make my CEO more money. A lot of the work I find to be a huge waste of time. I was previously in the military so I really understand bullshit projects and time wasting but it feels different on the civilian side I guess. &lt;/p&gt;\n\n&lt;p&gt;I really don\u2019t know if the data science world is for me. Do you find the work rewarding in other fields? Basically I really do find data science interesting and I know I have a LOT more to learn but most of the jobs seem to be in banking, finance etc. I basically am just working to make some other dude more money and that just bugs me. I can see myself applying these skills helping people but I guess I just don\u2019t know how or where.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161qjdh", "is_robot_indexable": true, "report_reasons": null, "author": "Significant_Baby9379", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161qjdh/meaningful_work_my_company_or_all_of_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161qjdh/meaningful_work_my_company_or_all_of_data_science/", "subreddit_subscribers": 1015661, "created_utc": 1693042283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently in university and calculus is not my strong suit. I\u2019d say my knowledge level is about average for a math major but it\u2019s a subject I\u2019d rather avoid in my future career field lmao. Is calculus a big topic used in data science?\n\nEdit: I\u2019m aware math is something that requires a lot of practice and that my post isn\u2019t very specific. I was just wondering how often higher level university calculus topics are used in data science\ud83d\udc80", "author_fullname": "t2_gciwus0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Calculus in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1625qvc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693088044.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693081758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently in university and calculus is not my strong suit. I\u2019d say my knowledge level is about average for a math major but it\u2019s a subject I\u2019d rather avoid in my future career field lmao. Is calculus a big topic used in data science?&lt;/p&gt;\n\n&lt;p&gt;Edit: I\u2019m aware math is something that requires a lot of practice and that my post isn\u2019t very specific. I was just wondering how often higher level university calculus topics are used in data science\ud83d\udc80&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1625qvc", "is_robot_indexable": true, "report_reasons": null, "author": "NefariousnessDry3909", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1625qvc/calculus_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1625qvc/calculus_in_data_science/", "subreddit_subscribers": 1015661, "created_utc": 1693081758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently learning some advanced statistical analysis, and I used the Meuse data set in R to run a Moran\u2019s I test and got a Moran\u2019s I scatter plot for the neighborhood for each sample (spatially lagged) against the residuals of the linear model. Could anyone point me in the right direction on how to interpret spatial patterns in this scatter plot? Is there any good videos or articles that would be useful in learning about this subject? Thanks for any help!", "author_fullname": "t2_d4wdpnqz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pointers on a R project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "name": "t3_161k2fw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MrpmXF9VKoJ_YDesF7NWtoa9MUfmKvVcSSAkAW1OYeA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693020921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently learning some advanced statistical analysis, and I used the Meuse data set in R to run a Moran\u2019s I test and got a Moran\u2019s I scatter plot for the neighborhood for each sample (spatially lagged) against the residuals of the linear model. Could anyone point me in the right direction on how to interpret spatial patterns in this scatter plot? Is there any good videos or articles that would be useful in learning about this subject? Thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/vtqtfs8fkdkb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?auto=webp&amp;s=d9eab981192d49e057f1845f15eee3f1e56c573f", "width": 700, "height": 432}, "resolutions": [{"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc4e93105ff9f0acb730694de0a99713358f6289", "width": 108, "height": 66}, {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b09ce878add4149708ad4d2243a0e154f2fe621a", "width": 216, "height": 133}, {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=512ac91374c8822b0ef5760fb4357a521f5a8cf6", "width": 320, "height": 197}, {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=de625c3d371cb01715e0e8b9b4a1957353d02949", "width": 640, "height": 394}], "variants": {}, "id": "WSv5LRcHscdscamQpruEKD_YxIi5t6K2gM_C8UISmZk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "161k2fw", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Jar-7618", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161k2fw/pointers_on_a_r_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/vtqtfs8fkdkb1.jpg", "subreddit_subscribers": 1015661, "created_utc": 1693020921.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I inherited a large model code base that basically forecasts the contact volume across many languages-regions. It basically creates unique RidgeCV regression models for each market trained on the last 2-3 years of data and spits out a predicted contact volume at different time horizons. The stakeholders then use the outputs of the model as a baseline upon which they apply business logic, e.g. new product launches, predicted customer growth etc, to come up with a final contact volume upon which business decisions are made.\n\nSome of my stakeholders who consume the data from this model have said that the accuracy is low (MAPE \\~20-30% with larger markets being more accurate), and that the model swings unexpectedly and they have no insight as to why it does.\n\nUnfortunately, we will not be rebuilding the model as we calculated the opportunity size for improving the accuracy to be not worth the time it would take, and there are more impactful projects in other departments that I am going to be focussing on.\n\nI don't want to leave them completely hanging, as it is a major pain point for them, so one thing I am thinking about doing to make their lives easier is to create a dashboard that can list out something along the lines of feature importances at the per-model level. This would allow them to see the drivers for when each model predicts a large variation in contact volume. I was thinking either listing out the feature weights since it is a linear model, or using Shapley values. But I would love some feedback from people who have built these kinds of things before on what would actually be useful on a dashboard like this?\n\nNote: I am NOT an MLE, my DS career has had a heavier emphasis on the DE, Experimentation, and Analytics with limited modeling work.\n\nedit: Error was incorrect, it's \\~20-30% not 70-80%. I had mixed it up with the stakeholders use of \"70-80% accuracy\"", "author_fullname": "t2_fhys02p7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for Model Explainability for End Consumers of a Demand Forecasting Model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1620x1a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693086199.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693070294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I inherited a large model code base that basically forecasts the contact volume across many languages-regions. It basically creates unique RidgeCV regression models for each market trained on the last 2-3 years of data and spits out a predicted contact volume at different time horizons. The stakeholders then use the outputs of the model as a baseline upon which they apply business logic, e.g. new product launches, predicted customer growth etc, to come up with a final contact volume upon which business decisions are made.&lt;/p&gt;\n\n&lt;p&gt;Some of my stakeholders who consume the data from this model have said that the accuracy is low (MAPE ~20-30% with larger markets being more accurate), and that the model swings unexpectedly and they have no insight as to why it does.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, we will not be rebuilding the model as we calculated the opportunity size for improving the accuracy to be not worth the time it would take, and there are more impactful projects in other departments that I am going to be focussing on.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to leave them completely hanging, as it is a major pain point for them, so one thing I am thinking about doing to make their lives easier is to create a dashboard that can list out something along the lines of feature importances at the per-model level. This would allow them to see the drivers for when each model predicts a large variation in contact volume. I was thinking either listing out the feature weights since it is a linear model, or using Shapley values. But I would love some feedback from people who have built these kinds of things before on what would actually be useful on a dashboard like this?&lt;/p&gt;\n\n&lt;p&gt;Note: I am NOT an MLE, my DS career has had a heavier emphasis on the DE, Experimentation, and Analytics with limited modeling work.&lt;/p&gt;\n\n&lt;p&gt;edit: Error was incorrect, it&amp;#39;s ~20-30% not 70-80%. I had mixed it up with the stakeholders use of &amp;quot;70-80% accuracy&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1620x1a", "is_robot_indexable": true, "report_reasons": null, "author": "Moldy-Tangelo", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1620x1a/ideas_for_model_explainability_for_end_consumers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1620x1a/ideas_for_model_explainability_for_end_consumers/", "subreddit_subscribers": 1015661, "created_utc": 1693070294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**tldr;** [**https://docs.litellm.ai/docs/tutorials/first\\_playground**](https://docs.litellm.ai/docs/tutorials/first_playground)\n\nCreate a playground to **evaluate multiple LLM Providers in less than 10 minutes**. If you want to see this in prod, check out our [website](https://litellm.ai/).\n\n**What will it look like?**\n\nhttps://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d\n\n**How will we do this?**: We'll build the server and connect it to our template frontend, ending up with a working playground UI by the end!\n\n&amp;#x200B;\n\n**Tutorial** \ud83d\udc49 [https://docs.litellm.ai/docs/tutorials/first\\_playground](https://docs.litellm.ai/docs/tutorials/first_playground)", "author_fullname": "t2_b5qc2w9r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Tutorial] Build LLM Playground in &lt;10mins", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"m19mofvsbekb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=eec12bed09d7ae290400662196619502eb5c8397"}, {"y": 163, "x": 216, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6aa47951e0a403ccd849229e935c87b96f05ed79"}, {"y": 242, "x": 320, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=df6daf576c61b23fd4267d4a3ebbddc400b25542"}, {"y": 484, "x": 640, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca4f7ec1f13ef74c459568197662dce6c072a2eb"}, {"y": 726, "x": 960, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e260013b6ca81c5a0bff76da0cd9d470d3397885"}, {"y": 816, "x": 1080, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a1ef952d5a4a9a53c1c6be6dc0ea82e86b528e75"}], "s": {"y": 1452, "x": 1920, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d"}, "id": "m19mofvsbekb1"}}, "name": "t3_161my8z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ZZqMtD4gilPJG_DWGT2RFN7h1quHgIAmgxPbf-P8dZ4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693030147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;tldr;&lt;/strong&gt; &lt;a href=\"https://docs.litellm.ai/docs/tutorials/first_playground\"&gt;&lt;strong&gt;https://docs.litellm.ai/docs/tutorials/first_playground&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Create a playground to &lt;strong&gt;evaluate multiple LLM Providers in less than 10 minutes&lt;/strong&gt;. If you want to see this in prod, check out our &lt;a href=\"https://litellm.ai/\"&gt;website&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What will it look like?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d\"&gt;https://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How will we do this?&lt;/strong&gt;: We&amp;#39;ll build the server and connect it to our template frontend, ending up with a working playground UI by the end!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Tutorial&lt;/strong&gt; \ud83d\udc49 &lt;a href=\"https://docs.litellm.ai/docs/tutorials/first_playground\"&gt;https://docs.litellm.ai/docs/tutorials/first_playground&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?auto=webp&amp;s=c7fa4ca49008ee42e1f80bdf64cdb34a2cd65e7c", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=429dd0ee32af0c12f455ba221e5dcf32f5a430d2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=80f67c195a09c7a47964a4488da90693ffc44101", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=44731b7b0dc428508fbe5aea506d0b474aedb710", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=42d48ca69203bf1aff1c033411c3de90f7d0bfda", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e64c66a43484edc3a7297072c13af48e5c26267c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f47098abf53a276cd5982ff79dbad3a040d69ab9", "width": 1080, "height": 607}], "variants": {}, "id": "H6fYCL0IdaUUhXSvGrJA54iiawydndRntwWO9LlIKYQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "161my8z", "is_robot_indexable": true, "report_reasons": null, "author": "VideoTo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161my8z/tutorial_build_llm_playground_in_10mins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161my8z/tutorial_build_llm_playground_in_10mins/", "subreddit_subscribers": 1015661, "created_utc": 1693030147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a second year college student working on personal projects for my portfolio. I've mainly been working on projects that I'm genuinly interested in, and I try to build it end to end by collecting the data on my own somehow, doing an analysis, and having some streamlit app as a final product that users can use. However, I feel that my projects are either useless or only useful to a very specific groups of users, and even then I don't really have any quantifiable impact to talk about. For example, one project I'm working on is a song recommendation app specfically for people who listen to Drake. I collected the data using the Spotify Web API, built the streamlit app, and am currently testing the recommendation system. I even wrote an analysis on the different methods I tried, the advantages and disadvantages of each approach. Despite all this, I'm afraid having some sort of quantifiable impact is what recruiters will care about the most, and practically, if a person wanted to get more recommendations for Drake songs, they could use the built in recommendation feature in Spotify itself.\n\nHow can I make measurable impact in my projects?", "author_fullname": "t2_ghlio82to", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Impactful Personal Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161jeko", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693018907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a second year college student working on personal projects for my portfolio. I&amp;#39;ve mainly been working on projects that I&amp;#39;m genuinly interested in, and I try to build it end to end by collecting the data on my own somehow, doing an analysis, and having some streamlit app as a final product that users can use. However, I feel that my projects are either useless or only useful to a very specific groups of users, and even then I don&amp;#39;t really have any quantifiable impact to talk about. For example, one project I&amp;#39;m working on is a song recommendation app specfically for people who listen to Drake. I collected the data using the Spotify Web API, built the streamlit app, and am currently testing the recommendation system. I even wrote an analysis on the different methods I tried, the advantages and disadvantages of each approach. Despite all this, I&amp;#39;m afraid having some sort of quantifiable impact is what recruiters will care about the most, and practically, if a person wanted to get more recommendations for Drake songs, they could use the built in recommendation feature in Spotify itself.&lt;/p&gt;\n\n&lt;p&gt;How can I make measurable impact in my projects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161jeko", "is_robot_indexable": true, "report_reasons": null, "author": "Technical-Note-4660", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161jeko/impactful_personal_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161jeko/impactful_personal_projects/", "subreddit_subscribers": 1015661, "created_utc": 1693018907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve had dozens of interviews over the past 6 months and nobody has asked a single tech question or done a technical assessment. I think I\u2019ve got to the final round 6 times without any offers.\n\nWhat was the point of learning data science if employers are just going to judge me based on what spirit animal I would be or where I see myself in 10 years?\n\nIs it just who I\u2019ve been interviewing with or is this an overall theme?", "author_fullname": "t2_4q04yojj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why does nobody ask technical questions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1627l75", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693086078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve had dozens of interviews over the past 6 months and nobody has asked a single tech question or done a technical assessment. I think I\u2019ve got to the final round 6 times without any offers.&lt;/p&gt;\n\n&lt;p&gt;What was the point of learning data science if employers are just going to judge me based on what spirit animal I would be or where I see myself in 10 years?&lt;/p&gt;\n\n&lt;p&gt;Is it just who I\u2019ve been interviewing with or is this an overall theme?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1627l75", "is_robot_indexable": true, "report_reasons": null, "author": "CyHawkNerd", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1627l75/why_does_nobody_ask_technical_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1627l75/why_does_nobody_ask_technical_questions/", "subreddit_subscribers": 1015661, "created_utc": 1693086078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Streamlining your data visualization journey with Python's popular library\n\n[ Photo Credit: Created by Author, Canva  ](https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1)\n\nThis article aims to introduce the objects interface feature in [Seaborn 0.12](https://seaborn.pydata.org/whatsnew/index.html?ref=dataleadsfuture.com#v0-12), including the concept of declarative graphic syntax, and a practical visualization project to showcase the usage of the objects interface.\n\nBy the end of this article, you'll have a clear understanding of the advantages and limitations of [Seaborn's objects interface API](https://seaborn.pydata.org/tutorial/objects_interface.html?ref=dataleadsfuture.com). And you will be able to use Seaborn for data analysis projects more easily.\n\n## Introduction\n\nRemember that joke about a programmer?\n\nHe was heading to the grocery store, and his wife told him, \"Buy a bottle of milk, and if they have eggs, buy 12.\"\n\nSo, he came home with 12 bottles of milk because they had eggs.\n\nThis is the problem with imperative programming\u2014it executes your instructions to the letter, without understanding your intent.\n\nNow, imagine you're creating a data visualization chart using Python.\n\nYou have to instruct the computer every step of the way: select a dataset, create a figure, set the color, add labels, adjust the size, etc...\n\nThen you realize your code is getting longer and more complex, and all you wanted was to quickly visualize your data.\n\nIt's like going to the grocery store and having to specify every item's location, color, size, and shape, instead of just telling the shop assistant what you need.\n\nNot only is this time-consuming, but it can also feel tiring.\n\nHowever, Seaborn 0.12's new feature\u2014the objects interface\u2014and its use of declarative graphic syntax is like having a shop assistant who understands you. You just need to tell it what you need to do, and it will find everything for you.\n\nYou no longer need to instruct it every step of the way. You just need to tell it what kind of result you want.\n\nIn this article, I'll guide you through using the objects interface, this new feature that makes your data visualization process more effortless, flexible, and enjoyable. Let's get started!\n\n## Why Declarative Graphic Syntax?\n\nLet's consider the salad-making process to illustrate the difference between traditional and declarative graphic syntax.\n\nIn the traditional approach, you're providing a detailed recipe, telling the chef each step, for example:\n\n1. Get a bowl.\n2. Put lettuce in it.\n3. Cut some cherry tomatoes and add them.\n4. Add some cucumber slices.\n5. Sprinkle some sesame seeds.\n6. Finally, drizzle with your favorite dressing.\n\nEven for a simple salad, you must specify each step in detail.\n\nIn contrast, declarative graphic syntax is more like telling the chef what kind of salad you want, rather than how to make it.\n\nFor instance, you might say, \"I want a salad with lettuce, tomatoes, cucumber, and sesame seeds.\"\n\nThe chef knows how to handle each ingredient without requiring step-by-step instructions.\n\nSimilarly, when using Seaborn's objects interface with its declarative syntax to create a visualization, we specify what we want (a histogram showing a variable's distribution in a given dataset), not how to get there.\n\nThis approach makes the code more concise and easier to understand, enhancing programming flexibility and efficiency.\n\n## Seaborn API: Then and Now\n\nBefore diving into the objects interface API, let's systematically look at the differences between the Seaborn API of earlier versions and the 0.12 version.\n\n## The original API\n\nMany readers might have been intimidated by Matplotlib's complex API documentation when learning Python data visualization.\n\nSeaborn simplifies this by wrapping and streamlining Matplotlib's API, making the learning curve gentler.\n\nSeaborn doesn't just offer high-level encapsulation of Matplotlib; it also categorizes all charts into relational, distributional, and categorical scenarios.\n\n[ Overview of Seaborn's original API design. Image by Author ](https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;format=png&amp;auto=webp&amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20)\n\nYou should comprehensively understand Seaborn's API through this diagram and know when to use which chart.\n\nFor example, a histplot representing data distribution would fall under the distribution chart category.\n\nIn contrast, a violinplot representing data features by category would be classified as a categorical chart.\n\nAside from vertical categorization, Seaborn also performs horizontal categorization: Figure-level and axes-level.\n\nAccording to the [official website](https://seaborn.pydata.org/tutorial/function_overview.html?ref=dataleadsfuture.com#figure-level-vs-axes-level-functions), axes-level charts are drawn on matplotlib.pyplot.axes and can only draw one figure.\n\nIn contrast, Figure-level charts use Matplotlib's FacetGrid to draw multiple charts in one figure, facilitating easy comparison of similar data dimensions.\n\nHowever, even though Seaborn's API significantly simplifies chart drawing through encapsulating Matplotlib, creating an individual-specific chart still requires complex configurations.\n\nFor example, if I use Seaborn's built-in penguins dataset to draw a histplot, the code is as follows:\n\n    sns.histplot(penguins, x=\"flipper_length_mm\", hue=\"species\");\n\n[ The original way of drawing a histplot. Image by Author ](https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;format=png&amp;auto=webp&amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2)\n\nAnd when I use the same dataset to draw a kdeplot, the code is as follows:\n\n    sns.kdeplot(penguins, x=\"flipper_length_mm\", fill=True, hue=\"species\");\n\n[ The original way of drawing a kdeplot. Image by Author ](https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;format=png&amp;auto=webp&amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd)\n\nExcept for the chart API, the rest of the configurations are identical.\n\nThis is like telling the chef I want to use lamb chops and onions to make a lamb soup and specifying the cooking steps. When I want to use these ingredients to make a roasted lamb chop, I have to tell the chef about the ingredients and the cooking steps all over again.\n\nNot only is it inefficient, but it also needs more flexibility.\n\nThat's why Seaborn introduced the objects interface API in its 0.12 version. This declarative graphic syntax dramatically improves the process of creating a chart.\n\n## The objects Interface API\n\nBefore we start with the objects interface API, let's take a high-level look at it to better understand the drawing process.\n\nUnlike the original Seaborn API, which organizes the drawing API by classification, the objects interface API collects the API by a drawing pipeline.\n\nThe objects interface API divides the drawing into multiple stages, such as data binding, layout, presentation, customization, etc.\n\n[ Overview of Seaborn's objects interface API design. Image by Author ](https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;format=png&amp;auto=webp&amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e)\n\nThe data binding and presentation stages are necessary, while other stages are optional.\n\nAlso, since the stages are independent, each stage can be reused. Following the previous example of the hist and kde plots:\n\nTo use the objects interface to draw, we first need to bind the data:\n\n    p = so.Plot(penguins, x=\"flipper_length_mm\", color=\"species\")\n\nFrom this line of code, we can see that the objects interface uses the so.Plot class for data binding.\n\nAlso, compared to the original API that uses the incomprehensible hue parameter, it uses the color parameter to bind the species dimension directly to the chart color, making the configuration more intuitive.\n\nFinally, this line of code returns a p instance that can be reused to draw a chart.\n\nNext, let's draw a histplot:\n\n    p.add(so.Bars(), so.Hist())\n\n[ Use objects interface API to draw a histplot. Image by Author ](https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a)\n\nThis line of code shows that the drawing stage does not need to rebind the data. We just need to tell the addmethod what to draw: so.Bars(), and how to calculate it: so.Hist().\n\nThe add method also returns a copy of the Plot instance, so any adjustments in the add method will not affect the original data binding. The p instance can still be reused.\n\nTherefore, we continue to call the p.add() method to draw a kdeplot:\n\n    p.add(so.Area(), so.KDE())\n\n[ Use objects interface API to draw a kdeplot. Image by Author ](https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89)\n\nSince KDE is a way of statistic, so.KDE() is called on the stat parameter here. And since the kdeplot itself is an area plot, so.Area() is used for drawing.\n\nWe reused the p instance bound to the data, so there is no need to tell the chef how to cook each dish, but to directly say what we want. Isn't it much more concise and flexible?\n\nThis article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/seaborn-0-12-an-insightful-guide-to-the-objects-interface-and-declarative-graphics/).", "author_fullname": "t2_9r8ft2a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seaborn 0.12: An Insightful Guide to the Objects Interface and Declarative Graphics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jdkazetmzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8a1c79aaa8209286897009af6b8fe6d6023a94ba"}, {"y": 68, "x": 216, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=036f43099ad78132ba3bbbdbd2eab2d3d571e650"}, {"y": 102, "x": 320, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b400a489bf1caa71e186b76d8abab5d22a22822d"}, {"y": 204, "x": 640, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=63255828bab9bdd13bc317a9d9882676388af0a8"}], "s": {"y": 287, "x": 899, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;format=png&amp;auto=webp&amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e"}, "id": "jdkazetmzfkb1"}, "7mc9f945zfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=70ba39e64584a7a4f8a9d7fe01787e7f41ff214e"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3681ced759d7b2cac2379d8aa0f3ba859ea227c"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=49edb457688deff44b86bc4064427b2005382aec"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e1e2115ab9aab2c42217dda0f4b65aeefc18fdec"}, {"y": 639, "x": 960, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5883a021a3863c01d5bf06352e3f39c244601492"}, {"y": 719, "x": 1080, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fa2d349e5289a02100631eff932dc09d7b03af8e"}], "s": {"y": 959, "x": 1440, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1"}, "id": "7mc9f945zfkb1"}, "ufs151akzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=47aa5cc59119e12d70dd8082aa77b3f9b613649b"}, {"y": 160, "x": 216, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b329c29a2969bb8d4ea74e6c234cf56a8071f424"}, {"y": 237, "x": 320, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1d742ff677c4e9eb3d364e3ac69c533d136d9a8"}], "s": {"y": 437, "x": 588, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;format=png&amp;auto=webp&amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd"}, "id": "ufs151akzfkb1"}, "z3ubpaufzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 83, "x": 108, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fd655c9ef8b03e51256976cc2115c4eaad57c6e3"}, {"y": 166, "x": 216, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1ab3edfaa3283b1117d0ae3d10bfbc68ac64c22"}, {"y": 247, "x": 320, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3ac3fee91bdca1fbf6a919ca817995501b781774"}], "s": {"y": 437, "x": 566, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;format=png&amp;auto=webp&amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2"}, "id": "z3ubpaufzfkb1"}, "otseb0utzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ff67695c30da82344330de221f8b6d1c02e416c"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8b4135abb4f0fb34b799b303b0c991fe62ae21d1"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e3ab322b3be6edd12b92c27484ffea35336e1d32"}, {"y": 392, "x": 640, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b62c3ad6ca6bd36db936b0f571848cff05e5849"}, {"y": 588, "x": 960, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6527a4224acd02a5e11a5850d49b400c5bc4860"}, {"y": 661, "x": 1080, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=981a36ab971d06f701cdb8dff853676a3afa6c92"}], "s": {"y": 890, "x": 1453, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a"}, "id": "otseb0utzfkb1"}, "tjaegaiyzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=402545adec6758cd1ecedb0cd6e9e2c2d95d1901"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=66959f2ca43e2b3faaa511d12e028fc17887fb8b"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d55b3c4ca08d4d16c2ff93a41d1b004f1a214cd5"}, {"y": 392, "x": 640, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0d2e477c3139ade726d2666842e0e569ecf2272"}, {"y": 588, "x": 960, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=edfc63ad503512d6b81c7a99c80c592684a1bbce"}, {"y": 661, "x": 1080, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=224e924131ef5654821ea8191d11ac42c494b64c"}], "s": {"y": 890, "x": 1453, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89"}, "id": "tjaegaiyzfkb1"}, "ajcy9e99zfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 70, "x": 108, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3bdd77020d14a0736156a9f930124b73c1f1bf4a"}, {"y": 141, "x": 216, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fdb95df8bcebb767c507c6e0e36ac459b510fb45"}, {"y": 210, "x": 320, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5094fd4de54cee0e2b6b58aa1de353e59865a1b6"}, {"y": 420, "x": 640, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b55bab4eeb2005bd9381423915d5edb6969d0f5c"}], "s": {"y": 487, "x": 741, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;format=png&amp;auto=webp&amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20"}, "id": "ajcy9e99zfkb1"}}, "name": "t3_161t22b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mD7sAGXVRAtCoqB5yQQShnqAKM4diaNaW9hrfwSjqIs.jpg", "edited": 1693055052.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693050410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Streamlining your data visualization journey with Python&amp;#39;s popular library&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1\"&gt; Photo Credit: Created by Author, Canva  &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This article aims to introduce the objects interface feature in &lt;a href=\"https://seaborn.pydata.org/whatsnew/index.html?ref=dataleadsfuture.com#v0-12\"&gt;Seaborn 0.12&lt;/a&gt;, including the concept of declarative graphic syntax, and a practical visualization project to showcase the usage of the objects interface.&lt;/p&gt;\n\n&lt;p&gt;By the end of this article, you&amp;#39;ll have a clear understanding of the advantages and limitations of &lt;a href=\"https://seaborn.pydata.org/tutorial/objects_interface.html?ref=dataleadsfuture.com\"&gt;Seaborn&amp;#39;s objects interface API&lt;/a&gt;. And you will be able to use Seaborn for data analysis projects more easily.&lt;/p&gt;\n\n&lt;h2&gt;Introduction&lt;/h2&gt;\n\n&lt;p&gt;Remember that joke about a programmer?&lt;/p&gt;\n\n&lt;p&gt;He was heading to the grocery store, and his wife told him, &amp;quot;Buy a bottle of milk, and if they have eggs, buy 12.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;So, he came home with 12 bottles of milk because they had eggs.&lt;/p&gt;\n\n&lt;p&gt;This is the problem with imperative programming\u2014it executes your instructions to the letter, without understanding your intent.&lt;/p&gt;\n\n&lt;p&gt;Now, imagine you&amp;#39;re creating a data visualization chart using Python.&lt;/p&gt;\n\n&lt;p&gt;You have to instruct the computer every step of the way: select a dataset, create a figure, set the color, add labels, adjust the size, etc...&lt;/p&gt;\n\n&lt;p&gt;Then you realize your code is getting longer and more complex, and all you wanted was to quickly visualize your data.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s like going to the grocery store and having to specify every item&amp;#39;s location, color, size, and shape, instead of just telling the shop assistant what you need.&lt;/p&gt;\n\n&lt;p&gt;Not only is this time-consuming, but it can also feel tiring.&lt;/p&gt;\n\n&lt;p&gt;However, Seaborn 0.12&amp;#39;s new feature\u2014the objects interface\u2014and its use of declarative graphic syntax is like having a shop assistant who understands you. You just need to tell it what you need to do, and it will find everything for you.&lt;/p&gt;\n\n&lt;p&gt;You no longer need to instruct it every step of the way. You just need to tell it what kind of result you want.&lt;/p&gt;\n\n&lt;p&gt;In this article, I&amp;#39;ll guide you through using the objects interface, this new feature that makes your data visualization process more effortless, flexible, and enjoyable. Let&amp;#39;s get started!&lt;/p&gt;\n\n&lt;h2&gt;Why Declarative Graphic Syntax?&lt;/h2&gt;\n\n&lt;p&gt;Let&amp;#39;s consider the salad-making process to illustrate the difference between traditional and declarative graphic syntax.&lt;/p&gt;\n\n&lt;p&gt;In the traditional approach, you&amp;#39;re providing a detailed recipe, telling the chef each step, for example:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Get a bowl.&lt;/li&gt;\n&lt;li&gt;Put lettuce in it.&lt;/li&gt;\n&lt;li&gt;Cut some cherry tomatoes and add them.&lt;/li&gt;\n&lt;li&gt;Add some cucumber slices.&lt;/li&gt;\n&lt;li&gt;Sprinkle some sesame seeds.&lt;/li&gt;\n&lt;li&gt;Finally, drizzle with your favorite dressing.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Even for a simple salad, you must specify each step in detail.&lt;/p&gt;\n\n&lt;p&gt;In contrast, declarative graphic syntax is more like telling the chef what kind of salad you want, rather than how to make it.&lt;/p&gt;\n\n&lt;p&gt;For instance, you might say, &amp;quot;I want a salad with lettuce, tomatoes, cucumber, and sesame seeds.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The chef knows how to handle each ingredient without requiring step-by-step instructions.&lt;/p&gt;\n\n&lt;p&gt;Similarly, when using Seaborn&amp;#39;s objects interface with its declarative syntax to create a visualization, we specify what we want (a histogram showing a variable&amp;#39;s distribution in a given dataset), not how to get there.&lt;/p&gt;\n\n&lt;p&gt;This approach makes the code more concise and easier to understand, enhancing programming flexibility and efficiency.&lt;/p&gt;\n\n&lt;h2&gt;Seaborn API: Then and Now&lt;/h2&gt;\n\n&lt;p&gt;Before diving into the objects interface API, let&amp;#39;s systematically look at the differences between the Seaborn API of earlier versions and the 0.12 version.&lt;/p&gt;\n\n&lt;h2&gt;The original API&lt;/h2&gt;\n\n&lt;p&gt;Many readers might have been intimidated by Matplotlib&amp;#39;s complex API documentation when learning Python data visualization.&lt;/p&gt;\n\n&lt;p&gt;Seaborn simplifies this by wrapping and streamlining Matplotlib&amp;#39;s API, making the learning curve gentler.&lt;/p&gt;\n\n&lt;p&gt;Seaborn doesn&amp;#39;t just offer high-level encapsulation of Matplotlib; it also categorizes all charts into relational, distributional, and categorical scenarios.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20\"&gt; Overview of Seaborn&amp;#39;s original API design. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You should comprehensively understand Seaborn&amp;#39;s API through this diagram and know when to use which chart.&lt;/p&gt;\n\n&lt;p&gt;For example, a histplot representing data distribution would fall under the distribution chart category.&lt;/p&gt;\n\n&lt;p&gt;In contrast, a violinplot representing data features by category would be classified as a categorical chart.&lt;/p&gt;\n\n&lt;p&gt;Aside from vertical categorization, Seaborn also performs horizontal categorization: Figure-level and axes-level.&lt;/p&gt;\n\n&lt;p&gt;According to the &lt;a href=\"https://seaborn.pydata.org/tutorial/function_overview.html?ref=dataleadsfuture.com#figure-level-vs-axes-level-functions\"&gt;official website&lt;/a&gt;, axes-level charts are drawn on matplotlib.pyplot.axes and can only draw one figure.&lt;/p&gt;\n\n&lt;p&gt;In contrast, Figure-level charts use Matplotlib&amp;#39;s FacetGrid to draw multiple charts in one figure, facilitating easy comparison of similar data dimensions.&lt;/p&gt;\n\n&lt;p&gt;However, even though Seaborn&amp;#39;s API significantly simplifies chart drawing through encapsulating Matplotlib, creating an individual-specific chart still requires complex configurations.&lt;/p&gt;\n\n&lt;p&gt;For example, if I use Seaborn&amp;#39;s built-in penguins dataset to draw a histplot, the code is as follows:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sns.histplot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, hue=&amp;quot;species&amp;quot;);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2\"&gt; The original way of drawing a histplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And when I use the same dataset to draw a kdeplot, the code is as follows:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sns.kdeplot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, fill=True, hue=&amp;quot;species&amp;quot;);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd\"&gt; The original way of drawing a kdeplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Except for the chart API, the rest of the configurations are identical.&lt;/p&gt;\n\n&lt;p&gt;This is like telling the chef I want to use lamb chops and onions to make a lamb soup and specifying the cooking steps. When I want to use these ingredients to make a roasted lamb chop, I have to tell the chef about the ingredients and the cooking steps all over again.&lt;/p&gt;\n\n&lt;p&gt;Not only is it inefficient, but it also needs more flexibility.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s why Seaborn introduced the objects interface API in its 0.12 version. This declarative graphic syntax dramatically improves the process of creating a chart.&lt;/p&gt;\n\n&lt;h2&gt;The objects Interface API&lt;/h2&gt;\n\n&lt;p&gt;Before we start with the objects interface API, let&amp;#39;s take a high-level look at it to better understand the drawing process.&lt;/p&gt;\n\n&lt;p&gt;Unlike the original Seaborn API, which organizes the drawing API by classification, the objects interface API collects the API by a drawing pipeline.&lt;/p&gt;\n\n&lt;p&gt;The objects interface API divides the drawing into multiple stages, such as data binding, layout, presentation, customization, etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e\"&gt; Overview of Seaborn&amp;#39;s objects interface API design. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The data binding and presentation stages are necessary, while other stages are optional.&lt;/p&gt;\n\n&lt;p&gt;Also, since the stages are independent, each stage can be reused. Following the previous example of the hist and kde plots:&lt;/p&gt;\n\n&lt;p&gt;To use the objects interface to draw, we first need to bind the data:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p = so.Plot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, color=&amp;quot;species&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;From this line of code, we can see that the objects interface uses the so.Plot class for data binding.&lt;/p&gt;\n\n&lt;p&gt;Also, compared to the original API that uses the incomprehensible hue parameter, it uses the color parameter to bind the species dimension directly to the chart color, making the configuration more intuitive.&lt;/p&gt;\n\n&lt;p&gt;Finally, this line of code returns a p instance that can be reused to draw a chart.&lt;/p&gt;\n\n&lt;p&gt;Next, let&amp;#39;s draw a histplot:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p.add(so.Bars(), so.Hist())\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a\"&gt; Use objects interface API to draw a histplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This line of code shows that the drawing stage does not need to rebind the data. We just need to tell the addmethod what to draw: so.Bars(), and how to calculate it: so.Hist().&lt;/p&gt;\n\n&lt;p&gt;The add method also returns a copy of the Plot instance, so any adjustments in the add method will not affect the original data binding. The p instance can still be reused.&lt;/p&gt;\n\n&lt;p&gt;Therefore, we continue to call the p.add() method to draw a kdeplot:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p.add(so.Area(), so.KDE())\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89\"&gt; Use objects interface API to draw a kdeplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Since KDE is a way of statistic, so.KDE() is called on the stat parameter here. And since the kdeplot itself is an area plot, so.Area() is used for drawing.&lt;/p&gt;\n\n&lt;p&gt;We reused the p instance bound to the data, so there is no need to tell the chef how to cook each dish, but to directly say what we want. Isn&amp;#39;t it much more concise and flexible?&lt;/p&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/seaborn-0-12-an-insightful-guide-to-the-objects-interface-and-declarative-graphics/\"&gt;Data Leads Future&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161t22b", "is_robot_indexable": true, "report_reasons": null, "author": "qtalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161t22b/seaborn_012_an_insightful_guide_to_the_objects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161t22b/seaborn_012_an_insightful_guide_to_the_objects/", "subreddit_subscribers": 1015661, "created_utc": 1693050410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "On one hand, most data exploration might be using Notebooks and CSV files so it is easier to manage them on Google Drive since they don't take up much space and it updates automatically. Also stuff on Google Drive is more accessible in a way. Hell if the production code is a simple python script it doesn't take up much space.\n\nOn the other hand, it just seem like good practice for coders to do it on Github.\n\nHow do you guys do it? Or are there alternatives?", "author_fullname": "t2_ru8ni", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Silly Question: Do you guys store your Notebooks and EDA stuff in Google Drive or Github?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161mgcj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693028498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On one hand, most data exploration might be using Notebooks and CSV files so it is easier to manage them on Google Drive since they don&amp;#39;t take up much space and it updates automatically. Also stuff on Google Drive is more accessible in a way. Hell if the production code is a simple python script it doesn&amp;#39;t take up much space.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, it just seem like good practice for coders to do it on Github.&lt;/p&gt;\n\n&lt;p&gt;How do you guys do it? Or are there alternatives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161mgcj", "is_robot_indexable": true, "report_reasons": null, "author": "ias6661", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161mgcj/silly_question_do_you_guys_store_your_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161mgcj/silly_question_do_you_guys_store_your_notebooks/", "subreddit_subscribers": 1015661, "created_utc": 1693028498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\\[Not sure if this breaking any rule or not, if it is, my apologies in advance\\]\n\nI am preparing for entry level position or internship position for Data Science/Machine Learning in the industry, is there a collection for such questions to prepare beforehand? Especially keeping with the fast changing industry standard?", "author_fullname": "t2_7lqv45ds", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview questions for preparation for entry level position for Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1628bpa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693087824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[Not sure if this breaking any rule or not, if it is, my apologies in advance]&lt;/p&gt;\n\n&lt;p&gt;I am preparing for entry level position or internship position for Data Science/Machine Learning in the industry, is there a collection for such questions to prepare beforehand? Especially keeping with the fast changing industry standard?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1628bpa", "is_robot_indexable": true, "report_reasons": null, "author": "SmartPuppyy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1628bpa/interview_questions_for_preparation_for_entry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1628bpa/interview_questions_for_preparation_for_entry/", "subreddit_subscribers": 1015661, "created_utc": 1693087824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wrote a python package for statistical data animations.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_16274uf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_ipbf10dq", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z6XHg37FsD_maDJu5DMcgFlcKJPSO_bPOkCzdePIqvU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "developersIndia", "selftext": "Hi everyone, I wrote a python package for statistical data animations, currently only bar chart race and lineplot is available but I am planning to add other plots as well like choropleths, temporal graphs.\n\nAlso I would love to get some feedback.\n\n**Pynimate** is available on [pypi](https://pypi.org/project/pynimate/).\n\n[github](https://github.com/julkaar9/pynimate), [documentation](https://julkaar9.github.io/pynimate/)\n\nQuick usage\n\n    import pandas as pd\n    from matplotlib import pyplot as plt\n    \n    import pynimate as nim\n    \n    df = pd.DataFrame(\n    {\n    \"time\": [\"1960-01-01\", \"1961-01-01\", \"1962-01-01\"],\n    \"Afghanistan\": [1, 2, 3],\n    \"Angola\": [2, 3, 4],\n    \"Albania\": [1, 2, 5],\n    \"USA\": [5, 3, 4],\n    \"Argentina\": [1, 4, 5],\n    }\n    ).set_index(\"time\")\n    \n    cnv = nim.Canvas()\n    bar = nim.Barhplot.from_df(df, \"%Y-%m-%d\", \"2d\")\n    bar.set_time(callback=lambda i, datafier: datafier.data.index[i].strftime(\"%b, %Y\"))\n    cnv.add_plot(bar)\n    cnv.animate()\n    plt.show()\n\n&amp;#x200B;\n\nhttps://i.redd.it/m9y0f74weekb1.gif\n\nA little more complex example\n\n&amp;#x200B;\n\nhttps://i.redd.it/6z2u1tosfekb1.gif\n\n(note: I am aware that animating line plots generally doesn't make any sense however there are exceptions)", "author_fullname": "t2_2fepcqe5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wrote a python package for statistical data animations.", "link_flair_richtext": [{"e": "text", "t": "Open Source"}], "subreddit_name_prefixed": "r/developersIndia", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"m9y0f74weekb1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/m9y0f74weekb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=4f4a4a469bd52f2caf4083f7e26937183c2193a5"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/m9y0f74weekb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=130b53cb7d2195dbbf94d55dc7a2345e7ee1dc2d"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/m9y0f74weekb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=4daf07045eac2617a607e2df97aaee0e1845ee30"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/m9y0f74weekb1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=12e7c7f766080694c8d844b8bca4f32ea4bcc8e9"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/m9y0f74weekb1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=af05aac516384bcbb82930724cc5e8393089e1d7"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/m9y0f74weekb1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=571efc8e653d87cb67479bb16126ef9f3a808fdd"}], "s": {"y": 900, "gif": "https://i.redd.it/m9y0f74weekb1.gif", "mp4": "https://preview.redd.it/m9y0f74weekb1.gif?format=mp4&amp;s=407018513a57180f0f56296aa1a98b07e485e2f4", "x": 1600}, "id": "m9y0f74weekb1"}, "6z2u1tosfekb1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/6z2u1tosfekb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=aadfa2f97a127ec9bce543833934018f39359b3b"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/6z2u1tosfekb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=b0d60eb9091c33cdde988907fb2c71f5b56b5dd0"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/6z2u1tosfekb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=14e5da4c09bd5d899915fec493bd2392fcd8774d"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/6z2u1tosfekb1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=295035aa80df642cd27a23d122c6d97048366e5d"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/6z2u1tosfekb1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=c1b1ff0ce6ce5d116c3f25cc41b8713e6124074e"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/6z2u1tosfekb1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=3a94b37cd196864f1731b1f1114e7dfe9fcec39c"}], "s": {"y": 720, "gif": "https://i.redd.it/6z2u1tosfekb1.gif", "mp4": "https://preview.redd.it/6z2u1tosfekb1.gif?format=mp4&amp;s=47f512280c2cd00457c118287545985f214903ec", "x": 1280}, "id": "6z2u1tosfekb1"}}, "name": "t3_161nh6d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Z6XHg37FsD_maDJu5DMcgFlcKJPSO_bPOkCzdePIqvU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693031934.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.developersIndia", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I wrote a python package for statistical data animations, currently only bar chart race and lineplot is available but I am planning to add other plots as well like choropleths, temporal graphs.&lt;/p&gt;\n\n&lt;p&gt;Also I would love to get some feedback.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Pynimate&lt;/strong&gt; is available on &lt;a href=\"https://pypi.org/project/pynimate/\"&gt;pypi&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/julkaar9/pynimate\"&gt;github&lt;/a&gt;, &lt;a href=\"https://julkaar9.github.io/pynimate/\"&gt;documentation&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Quick usage&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pandas as pd\nfrom matplotlib import pyplot as plt\n\nimport pynimate as nim\n\ndf = pd.DataFrame(\n{\n&amp;quot;time&amp;quot;: [&amp;quot;1960-01-01&amp;quot;, &amp;quot;1961-01-01&amp;quot;, &amp;quot;1962-01-01&amp;quot;],\n&amp;quot;Afghanistan&amp;quot;: [1, 2, 3],\n&amp;quot;Angola&amp;quot;: [2, 3, 4],\n&amp;quot;Albania&amp;quot;: [1, 2, 5],\n&amp;quot;USA&amp;quot;: [5, 3, 4],\n&amp;quot;Argentina&amp;quot;: [1, 4, 5],\n}\n).set_index(&amp;quot;time&amp;quot;)\n\ncnv = nim.Canvas()\nbar = nim.Barhplot.from_df(df, &amp;quot;%Y-%m-%d&amp;quot;, &amp;quot;2d&amp;quot;)\nbar.set_time(callback=lambda i, datafier: datafier.data.index[i].strftime(&amp;quot;%b, %Y&amp;quot;))\ncnv.add_plot(bar)\ncnv.animate()\nplt.show()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/m9y0f74weekb1.gif\"&gt;https://i.redd.it/m9y0f74weekb1.gif&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A little more complex example&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.redd.it/6z2u1tosfekb1.gif\"&gt;https://i.redd.it/6z2u1tosfekb1.gif&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;(note: I am aware that animating line plots generally doesn&amp;#39;t make any sense however there are exceptions)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?auto=webp&amp;s=27b6869059bde930b8fa91e163c4a5b593a62755", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=967712caa32aa48e894a0097548ea87ec67be18c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a3c7948dff53aae03712fb7d592fa1bbddccbb4", "width": 216, "height": 216}], "variants": {}, "id": "IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "17a13424-f726-11ed-bf61-16962b61b567", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2dfnk0", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#bebd7f", "id": "161nh6d", "is_robot_indexable": true, "report_reasons": null, "author": "julkar9", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/developersIndia/comments/161nh6d/i_wrote_a_python_package_for_statistical_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/developersIndia/comments/161nh6d/i_wrote_a_python_package_for_statistical_data/", "subreddit_subscribers": 284822, "created_utc": 1693031934.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1693085010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.developersIndia", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/developersIndia/comments/161nh6d/i_wrote_a_python_package_for_statistical_data/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?auto=webp&amp;s=27b6869059bde930b8fa91e163c4a5b593a62755", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=967712caa32aa48e894a0097548ea87ec67be18c", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a3c7948dff53aae03712fb7d592fa1bbddccbb4", "width": 216, "height": 216}], "variants": {}, "id": "IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16274uf", "is_robot_indexable": true, "report_reasons": null, "author": "Notalabel_4566", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_161nh6d", "author_flair_text_color": null, "permalink": "/r/datascience/comments/16274uf/i_wrote_a_python_package_for_statistical_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/developersIndia/comments/161nh6d/i_wrote_a_python_package_for_statistical_data/", "subreddit_subscribers": 1015661, "created_utc": 1693085010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,  \nI'm recentrly working on a project about \"Functional Data Analysis\"  in the part of time series especially forecasting i found out that there's no package that deals with functional observations, the usual ARIMA models apply to univariate data only. \n\nAny ideas to help please ?", "author_fullname": "t2_7y59qi3hn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FAR and FARIMA model in python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161x071", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693060867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;br/&gt;\nI&amp;#39;m recentrly working on a project about &amp;quot;Functional Data Analysis&amp;quot;  in the part of time series especially forecasting i found out that there&amp;#39;s no package that deals with functional observations, the usual ARIMA models apply to univariate data only. &lt;/p&gt;\n\n&lt;p&gt;Any ideas to help please ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161x071", "is_robot_indexable": true, "report_reasons": null, "author": "Worth_Truth_8010", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161x071/far_and_farima_model_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161x071/far_and_farima_model_in_python/", "subreddit_subscribers": 1015661, "created_utc": 1693060867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I need a Data Science Project idea for my final year Project idea. I don't find any unique idea can you please suggest an idea or where  I get guidance  ", "author_fullname": "t2_uewgxld9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Project idea?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1620myq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693069598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I need a Data Science Project idea for my final year Project idea. I don&amp;#39;t find any unique idea can you please suggest an idea or where  I get guidance  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1620myq", "is_robot_indexable": true, "report_reasons": null, "author": "atharva_nimbalkar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1620myq/data_science_project_idea/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1620myq/data_science_project_idea/", "subreddit_subscribers": 1015661, "created_utc": 1693069598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset that contains the sale quantity of an item over a year. I am building an ML-based (XGBOOST) model since I plan to include exogenous variables that can influence the demand for the item.\n\nSince I would essentially eliminate the 'date'  column, inferring only features like seasons. \n\nWhen it comes to model evaluation, can I randomly split train and test or do I have to keep the time splits in consideration like we do in ARIMA modeling for example?", "author_fullname": "t2_ba4jkgnm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model evaluation for Sales Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161ibkb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693015661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset that contains the sale quantity of an item over a year. I am building an ML-based (XGBOOST) model since I plan to include exogenous variables that can influence the demand for the item.&lt;/p&gt;\n\n&lt;p&gt;Since I would essentially eliminate the &amp;#39;date&amp;#39;  column, inferring only features like seasons. &lt;/p&gt;\n\n&lt;p&gt;When it comes to model evaluation, can I randomly split train and test or do I have to keep the time splits in consideration like we do in ARIMA modeling for example?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161ibkb", "is_robot_indexable": true, "report_reasons": null, "author": "Excellent-Tennis-323", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161ibkb/model_evaluation_for_sales_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161ibkb/model_evaluation_for_sales_data/", "subreddit_subscribers": 1015661, "created_utc": 1693015661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am going to school for data science at a top 60 school in the country. I play hockey at that school, so ideally my dream job would be to work for an NHL team. I also know and have experience with baseball so the mlb would be awesome too. I also am completely okay with doing something in the corporate world beforehand, so I am not completely naive on the situation. I have read that the pay on the sports end is not great but I am willing to sacrifice pay to do something I truly enjoy. How realistic is that goal? Is that something that very rarely comes along?", "author_fullname": "t2_v8q0o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difficulty levels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161hgvp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693013229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am going to school for data science at a top 60 school in the country. I play hockey at that school, so ideally my dream job would be to work for an NHL team. I also know and have experience with baseball so the mlb would be awesome too. I also am completely okay with doing something in the corporate world beforehand, so I am not completely naive on the situation. I have read that the pay on the sports end is not great but I am willing to sacrifice pay to do something I truly enjoy. How realistic is that goal? Is that something that very rarely comes along?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161hgvp", "is_robot_indexable": true, "report_reasons": null, "author": "natems711", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161hgvp/difficulty_levels/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161hgvp/difficulty_levels/", "subreddit_subscribers": 1015661, "created_utc": 1693013229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I have an interview with US elections modeling company next week. I interviewed with them earlier this year and made it to their take-home test and they wanted me to model some US House elections. Any tips to better succeed this time would be great.\n\n\nAre there complex models for that? Do people usually use one-model-per-district or something different? Is there a \"go-to\" elections modeling curriculum that I've missed? Where are the best US-elections data sources (aside from MIT, Pew, and LoC and all the other easily googleable places)?\n\n(sorry if this flair is wrong, I didn't know which this really fell under)", "author_fullname": "t2_7bn1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Elections Fellow\" interview prep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161g44t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693009538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an interview with US elections modeling company next week. I interviewed with them earlier this year and made it to their take-home test and they wanted me to model some US House elections. Any tips to better succeed this time would be great.&lt;/p&gt;\n\n&lt;p&gt;Are there complex models for that? Do people usually use one-model-per-district or something different? Is there a &amp;quot;go-to&amp;quot; elections modeling curriculum that I&amp;#39;ve missed? Where are the best US-elections data sources (aside from MIT, Pew, and LoC and all the other easily googleable places)?&lt;/p&gt;\n\n&lt;p&gt;(sorry if this flair is wrong, I didn&amp;#39;t know which this really fell under)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161g44t", "is_robot_indexable": true, "report_reasons": null, "author": "ib33", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161g44t/elections_fellow_interview_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161g44t/elections_fellow_interview_prep/", "subreddit_subscribers": 1015661, "created_utc": 1693009538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For context, I\u2019m 22, and just graduated from UF cum laude (I know companies don\u2019t really care about GPA) with an economics degree, and I have spent the last 3.5 months learning SQL, R, Power BI, Excel, and a bit of Python. I definitely know my way around all of them. I am aiming for a role as a data analyst, but after learning the technical skills, I don\u2019t know if I should just start applying for roles or if there is something else I should do first? I have no experience in this market and it would be my first real job. Any advice on what I should apply for and what I should do before I apply is greatly appreciated.", "author_fullname": "t2_9c3943u0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should my next steps be in my career in data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1629d3d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693090370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I\u2019m 22, and just graduated from UF cum laude (I know companies don\u2019t really care about GPA) with an economics degree, and I have spent the last 3.5 months learning SQL, R, Power BI, Excel, and a bit of Python. I definitely know my way around all of them. I am aiming for a role as a data analyst, but after learning the technical skills, I don\u2019t know if I should just start applying for roles or if there is something else I should do first? I have no experience in this market and it would be my first real job. Any advice on what I should apply for and what I should do before I apply is greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1629d3d", "is_robot_indexable": true, "report_reasons": null, "author": "Dev_NT", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1629d3d/what_should_my_next_steps_be_in_my_career_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1629d3d/what_should_my_next_steps_be_in_my_career_in_data/", "subreddit_subscribers": 1015661, "created_utc": 1693090370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI have PDFs consisting of images of forms. I want to apply OCR and OMR on this images to extract the required data. I want to detect ticked checkboxes and extract the associated data to those checkboxes from these images. However, the current code is not able to detect the contours of the ticked checkbox.\n\nI am using `findcontours` to find contours and make bounding boxes around the checkboxes. This code is inspired from this [post](https://stackoverflow.com/questions/55763858/how-to-detect-and-find-checkboxes-in-a-form-using-python-opencv).  However, it is not able to detect the contours of the checkbox that is ticked. Here is the code and the image of the area in the form where I am applying the code. \n\n&amp;#x200B;\n\n[ Image of the region of the form with checkboxes and associated data ](https://preview.redd.it/zezn47w91jkb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=70c517e0eb2b745b711639cfe3f4ff5ecd621232)\n\n    gray = x_gray.copy() # Copy of the Grayscale image shared in this post \n    blur = cv2.GaussianBlur(gray, (3,3), 0)\n    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n    \n    # Find contours and filter using contour area filtering to remove noise\n    cnts, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n    AREA_THRESHOLD = 100\n    for c in cnts:\n        area = cv2.contourArea(c)\n        if area &lt; AREA_THRESHOLD:\n            cv2.drawContours(thresh, [c], -1, 0, -1)\n    \n    # Repair checkbox horizontal and vertical walls\n    repair_kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,1))\n    repair = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, repair_kernel1, iterations=1)\n    repair_kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (1,5))\n    repair = cv2.morphologyEx(repair, cv2.MORPH_CLOSE, repair_kernel2, iterations=1)\n    \n    # Detect checkboxes using shape approximation and aspect ratio filtering\n    checkbox_contours = []\n    cnts, _ = cv2.findContours(repair, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n    for c in cnts:\n        peri = cv2.arcLength(c, True)\n        approx = cv2.approxPolyDP(c, 0.035 * peri, True)\n        x,y,w,h = cv2.boundingRect(approx)\n        aspect_ratio = w / float(h)\n        if len(approx) == 4 and (aspect_ratio &gt;= 0.8 and aspect_ratio &lt;= 1.2):\n            cv2.rectangle(gray, (x, y), (x + w, y + h), (36,255,12), 3) #original\n            checkbox_contours.append(c)\n    \n    print('Checkboxes:', len(checkbox_contours))\n\n \n\nI have tried various values of the parameter `AREA_THRESHOLD` ranging from 10 - 200. However, I'm still not getting the expected result.\n\nIt would be really helpful if someone can help me with this problem.", "author_fullname": "t2_sq7rhmzy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to detect a ticked checkbox and extract the text associated to it from an image?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"zezn47w91jkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=df46dbcacbb87736e528e3dbdb6bfc5d126d1c45"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4fe58afaa4c9ced4c55e60006eb8e18735452685"}, {"y": 116, "x": 320, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=818915627b0f8ac9a8fb9555c551e88184ff0b22"}, {"y": 233, "x": 640, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=281c44cb846692a1c020de84103ddf2d61f1307b"}, {"y": 350, "x": 960, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=02248f63cbadf1b53ccced790e40fc7722c222ed"}, {"y": 394, "x": 1080, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d56060f6f2a87097038599f429ce9c5465792c64"}], "s": {"y": 565, "x": 1546, "u": "https://preview.redd.it/zezn47w91jkb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=70c517e0eb2b745b711639cfe3f4ff5ecd621232"}, "id": "zezn47w91jkb1"}}, "name": "t3_16283ok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BR9NB6Fvr_8UUHe0n9NcXWLt2z0-vaZBHk3y27t0Vmo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693087298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have PDFs consisting of images of forms. I want to apply OCR and OMR on this images to extract the required data. I want to detect ticked checkboxes and extract the associated data to those checkboxes from these images. However, the current code is not able to detect the contours of the ticked checkbox.&lt;/p&gt;\n\n&lt;p&gt;I am using &lt;code&gt;findcontours&lt;/code&gt; to find contours and make bounding boxes around the checkboxes. This code is inspired from this &lt;a href=\"https://stackoverflow.com/questions/55763858/how-to-detect-and-find-checkboxes-in-a-form-using-python-opencv\"&gt;post&lt;/a&gt;.  However, it is not able to detect the contours of the checkbox that is ticked. Here is the code and the image of the area in the form where I am applying the code. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zezn47w91jkb1.png?width=1546&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=70c517e0eb2b745b711639cfe3f4ff5ecd621232\"&gt; Image of the region of the form with checkboxes and associated data &lt;/a&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;gray = x_gray.copy() # Copy of the Grayscale image shared in this post \nblur = cv2.GaussianBlur(gray, (3,3), 0)\nthresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n\n# Find contours and filter using contour area filtering to remove noise\ncnts, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\nAREA_THRESHOLD = 100\nfor c in cnts:\n    area = cv2.contourArea(c)\n    if area &amp;lt; AREA_THRESHOLD:\n        cv2.drawContours(thresh, [c], -1, 0, -1)\n\n# Repair checkbox horizontal and vertical walls\nrepair_kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,1))\nrepair = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, repair_kernel1, iterations=1)\nrepair_kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (1,5))\nrepair = cv2.morphologyEx(repair, cv2.MORPH_CLOSE, repair_kernel2, iterations=1)\n\n# Detect checkboxes using shape approximation and aspect ratio filtering\ncheckbox_contours = []\ncnts, _ = cv2.findContours(repair, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\nfor c in cnts:\n    peri = cv2.arcLength(c, True)\n    approx = cv2.approxPolyDP(c, 0.035 * peri, True)\n    x,y,w,h = cv2.boundingRect(approx)\n    aspect_ratio = w / float(h)\n    if len(approx) == 4 and (aspect_ratio &amp;gt;= 0.8 and aspect_ratio &amp;lt;= 1.2):\n        cv2.rectangle(gray, (x, y), (x + w, y + h), (36,255,12), 3) #original\n        checkbox_contours.append(c)\n\nprint(&amp;#39;Checkboxes:&amp;#39;, len(checkbox_contours))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I have tried various values of the parameter &lt;code&gt;AREA_THRESHOLD&lt;/code&gt; ranging from 10 - 200. However, I&amp;#39;m still not getting the expected result.&lt;/p&gt;\n\n&lt;p&gt;It would be really helpful if someone can help me with this problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;s=8cd5e918e2bde6ca72d4445d6fc007f203689799", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1c8a90e5690a7186afdb269ad05279551994d09", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=533bd055cdae7998d1b8f9cd9d7dedabc1715bda", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16283ok", "is_robot_indexable": true, "report_reasons": null, "author": "yishu17", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16283ok/how_to_detect_a_ticked_checkbox_and_extract_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16283ok/how_to_detect_a_ticked_checkbox_and_extract_the/", "subreddit_subscribers": 1015661, "created_utc": 1693087298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry if this isn\u2019t written particularly well, but currently I\u2019m very overwhelmed with the job search process and need to figure out how to optimize my time. Also I\u2019m probably catastrophizing, but I don\u2019t want to live in my parents\u2019 basement forever.\n\nSo I\u2019ve been looking for work in the US after leaving a position I had in the UK for 1.5 years mostly because I would not be allowed to keep it due to visa restrictions. I\u2019m concerned because I was getting a few calls back for interviews in the 2 months I was actively looking for work in the UK but I\u2019ve gotten complete silence since I\u2019ve moved back. This is especially bad because I\u2019m a US citizen so things should be easier for me here than they were there.\n\nI\u2019m concerned that my old job isn\u2019t doing me any favors in terms of experience because while my job title was \u201cData Scientist,\u201d I did very little in terms of actual analysis and absolutely no machine learning. I was mostly helping maintain and build data applications to host on AWS, but i don\u2019t think we did much in terms of ETL to the quality most companies who want a Data Engineer would want.\n\nI think my best bet at this point is to learn Power BI and Tableau to get an analyst position, but again, I never did any analysis in my previous position and I think I\u2019d lose to anybody who has actual work experience with these things. I have some projects from my master\u2019s program that plug some of the holes but in my hubris, I didn\u2019t manage to create anything new for the portfolio while I still had a job. I have several web tools that I managed to get working on GCP (just barely) but I can\u2019t get working anymore without refactoring a ton of stuff. Which is a problem because I need to decide if it\u2019s worth redeploying everything at all.\n\nI also also don\u2019t know how to explain the ever increasing gap in my employment. Do I just need to get on Fivver and start selling some cheap data analysis service there just to prove I\u2019m doing something productive? What if I mess up handling my customers and my ratings suffer so I can\u2019t put that work on my resume? I could also take some part time work tutoring again but wouldn\u2019t that make me look bad anyways because it\u2019s a step back?", "author_fullname": "t2_3o4ak2xl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wondering if my experience is inadequate for US job market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1624yex", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693079851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this isn\u2019t written particularly well, but currently I\u2019m very overwhelmed with the job search process and need to figure out how to optimize my time. Also I\u2019m probably catastrophizing, but I don\u2019t want to live in my parents\u2019 basement forever.&lt;/p&gt;\n\n&lt;p&gt;So I\u2019ve been looking for work in the US after leaving a position I had in the UK for 1.5 years mostly because I would not be allowed to keep it due to visa restrictions. I\u2019m concerned because I was getting a few calls back for interviews in the 2 months I was actively looking for work in the UK but I\u2019ve gotten complete silence since I\u2019ve moved back. This is especially bad because I\u2019m a US citizen so things should be easier for me here than they were there.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m concerned that my old job isn\u2019t doing me any favors in terms of experience because while my job title was \u201cData Scientist,\u201d I did very little in terms of actual analysis and absolutely no machine learning. I was mostly helping maintain and build data applications to host on AWS, but i don\u2019t think we did much in terms of ETL to the quality most companies who want a Data Engineer would want.&lt;/p&gt;\n\n&lt;p&gt;I think my best bet at this point is to learn Power BI and Tableau to get an analyst position, but again, I never did any analysis in my previous position and I think I\u2019d lose to anybody who has actual work experience with these things. I have some projects from my master\u2019s program that plug some of the holes but in my hubris, I didn\u2019t manage to create anything new for the portfolio while I still had a job. I have several web tools that I managed to get working on GCP (just barely) but I can\u2019t get working anymore without refactoring a ton of stuff. Which is a problem because I need to decide if it\u2019s worth redeploying everything at all.&lt;/p&gt;\n\n&lt;p&gt;I also also don\u2019t know how to explain the ever increasing gap in my employment. Do I just need to get on Fivver and start selling some cheap data analysis service there just to prove I\u2019m doing something productive? What if I mess up handling my customers and my ratings suffer so I can\u2019t put that work on my resume? I could also take some part time work tutoring again but wouldn\u2019t that make me look bad anyways because it\u2019s a step back?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1624yex", "is_robot_indexable": true, "report_reasons": null, "author": "GGPiggie", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1624yex/wondering_if_my_experience_is_inadequate_for_us/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1624yex/wondering_if_my_experience_is_inadequate_for_us/", "subreddit_subscribers": 1015661, "created_utc": 1693079851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am in a team of 10 people, a mix of data scientists, analysts and software engineers. \n\nSome of our side quests involve building tools for our entire small team to use \u2014 think a standardized debugging tool to handle common error messages when interacting with company-wide APIs. The thing is, despite it can bring a lot of value to the team, our manager doesn\u2019t really appreciate this kind of work too much and so when a team member build such a tool, it would usually be quick and dirty without any unit tests written to support any logic changes.\n\nThere are some problems with these tools sometimes \u2014 happening due to untested code updates mostly \u2014 but nothing severe and because we are small, it is easily solved by just sending a message to the software owner. But can you see these problems compounding in the long run? I\u2019m trying to see whether there is a need to shift this culture and encourage unit tests everywhere in our side quests.", "author_fullname": "t2_1bodd6y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does unit testing make sense for a small team software package?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1621e71", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693071436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in a team of 10 people, a mix of data scientists, analysts and software engineers. &lt;/p&gt;\n\n&lt;p&gt;Some of our side quests involve building tools for our entire small team to use \u2014 think a standardized debugging tool to handle common error messages when interacting with company-wide APIs. The thing is, despite it can bring a lot of value to the team, our manager doesn\u2019t really appreciate this kind of work too much and so when a team member build such a tool, it would usually be quick and dirty without any unit tests written to support any logic changes.&lt;/p&gt;\n\n&lt;p&gt;There are some problems with these tools sometimes \u2014 happening due to untested code updates mostly \u2014 but nothing severe and because we are small, it is easily solved by just sending a message to the software owner. But can you see these problems compounding in the long run? I\u2019m trying to see whether there is a need to shift this culture and encourage unit tests everywhere in our side quests.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1621e71", "is_robot_indexable": true, "report_reasons": null, "author": "iamdeviance", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1621e71/does_unit_testing_make_sense_for_a_small_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1621e71/does_unit_testing_make_sense_for_a_small_team/", "subreddit_subscribers": 1015661, "created_utc": 1693071436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m thinking of applying to this:\n\n[https://faculty.ai/fellowship-fellows/?utm\\_campaign=Fellowship%2026%20-%20Applications&amp;utm\\_source=email&amp;utm\\_medium=Interest%20list&amp;utm\\_term=Hubspot&amp;utm\\_content=Applications%20open%20%28May%202023%29](https://faculty.ai/fellowship-fellows/?utm_campaign=Fellowship%2026%20-%20Applications&amp;utm_source=email&amp;utm_medium=Interest%20list&amp;utm_term=Hubspot&amp;utm_content=Applications%20open%20%28May%202023%29)\n\nJust wondering how hard it\u2019ll be for me to get in. I\u2019ve got a masters in data science from Careerera which isn\u2019t the best masters but Im hoping it qualifies. Just wondering if anyone\u2019s done it before.", "author_fullname": "t2_4lmpcc3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone heard of faculty.ai?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16216r0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693070936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m thinking of applying to this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://faculty.ai/fellowship-fellows/?utm_campaign=Fellowship%2026%20-%20Applications&amp;amp;utm_source=email&amp;amp;utm_medium=Interest%20list&amp;amp;utm_term=Hubspot&amp;amp;utm_content=Applications%20open%20%28May%202023%29\"&gt;https://faculty.ai/fellowship-fellows/?utm_campaign=Fellowship%2026%20-%20Applications&amp;amp;utm_source=email&amp;amp;utm_medium=Interest%20list&amp;amp;utm_term=Hubspot&amp;amp;utm_content=Applications%20open%20%28May%202023%29&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Just wondering how hard it\u2019ll be for me to get in. I\u2019ve got a masters in data science from Careerera which isn\u2019t the best masters but Im hoping it qualifies. Just wondering if anyone\u2019s done it before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?auto=webp&amp;s=ee6b11645868310e9239e7fa475c04d7a5afa4d4", "width": 2000, "height": 1333}, "resolutions": [{"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=410ac9dafb9bf4b59bf747e2d75ff9c2fda6a2fd", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8999b58a6ffd1031f3e4a839ea41062baa97003e", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5b2a3b4af378168ba31515efa037a8389602cacb", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=84d38cdcf7d096e929abdd37d4e2f78f5436d389", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a41f7a3e9d3603dcc4d34f05bf5bc303e92a6ec9", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=648798c090bbb8897b8d4326ff8cabb94b401b6b", "width": 1080, "height": 719}], "variants": {}, "id": "ecHk9ZLP1I54kTm81PtOd9flzglN73iU1bmbBvWKh0A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16216r0", "is_robot_indexable": true, "report_reasons": null, "author": "redtoothroll", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16216r0/anyone_heard_of_facultyai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16216r0/anyone_heard_of_facultyai/", "subreddit_subscribers": 1015661, "created_utc": 1693070936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9v2ffwqay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitter Community / Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161rqa5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1693046299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/i/communities/1695363277289562618", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161rqa5", "is_robot_indexable": true, "report_reasons": null, "author": "x9182", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161rqa5/twitter_community_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/i/communities/1695363277289562618", "subreddit_subscribers": 1015661, "created_utc": 1693046299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello All,\n\nI am working for a smaller company that has financial expenses based on snow removal for a given year. My boss and I were looking into different companies that sell data for this information. We want to use the data to help make predictions of future snowfall data that we then could use to approximate expenses for the new year.\n\nData science at this company is a bit of a new thing, and I'm still learning as well so I don't have much experience in which data might be best for this project. I'm curious if any of you all have experience with snowfall data and were to start looking for data like this?\n\nWe are really only interested in snowfall data, and preferably data at a city/metro level if possible. The data we want is for USA markets\n\nAny advice is appreciated!", "author_fullname": "t2_e24an8jlc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowfall Statistics per City/Metro Area USA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161exy4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693006502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;I am working for a smaller company that has financial expenses based on snow removal for a given year. My boss and I were looking into different companies that sell data for this information. We want to use the data to help make predictions of future snowfall data that we then could use to approximate expenses for the new year.&lt;/p&gt;\n\n&lt;p&gt;Data science at this company is a bit of a new thing, and I&amp;#39;m still learning as well so I don&amp;#39;t have much experience in which data might be best for this project. I&amp;#39;m curious if any of you all have experience with snowfall data and were to start looking for data like this?&lt;/p&gt;\n\n&lt;p&gt;We are really only interested in snowfall data, and preferably data at a city/metro level if possible. The data we want is for USA markets&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161exy4", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering-Plane7979", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161exy4/snowfall_statistics_per_citymetro_area_usa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161exy4/snowfall_statistics_per_citymetro_area_usa/", "subreddit_subscribers": 1015661, "created_utc": 1693006502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I think the question says it all. I am considering doing masters in data science in uk and wondering what are the job opportunities there like after the degree. How easy it is to land a job in data science as a fresher being an international student and is it even possible?", "author_fullname": "t2_f31m67lx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How easy is to land a job in data science get a job as a fresher in the uk being an international student?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1626t17", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693084255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I think the question says it all. I am considering doing masters in data science in uk and wondering what are the job opportunities there like after the degree. How easy it is to land a job in data science as a fresher being an international student and is it even possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1626t17", "is_robot_indexable": true, "report_reasons": null, "author": "ProfessionalOne272", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1626t17/how_easy_is_to_land_a_job_in_data_science_get_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1626t17/how_easy_is_to_land_a_job_in_data_science_get_a/", "subreddit_subscribers": 1015661, "created_utc": 1693084255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8qgfbbfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leveraging NLP and OCR for Business Card Text Extraction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_161pr5h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TV8-g9jeOmLtRQo0hT88aWztIzmFkW2Kt8PX-2eAT34.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693039638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "abhilashshukla.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://abhilashshukla.com/tech-and-programming/aiml/leveraging-nlp-and-ocr-for-business-card-text-extraction/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?auto=webp&amp;s=66605857e6f7f7824f7295e38884b5f72340df13", "width": 900, "height": 504}, "resolutions": [{"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c412490b3fb48e5346468653d3a3e0636a6aa11c", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2772bc548d15905ed61e5b064cb324b517b94d04", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa67670eed710a938ebe57e2506d671015405415", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=98881f8b29af5643cd31b5b91786802b3e5f0431", "width": 640, "height": 358}], "variants": {}, "id": "6cwV5FRTGCO6L0K5DlRn4hGjOM7jz29PeZA1eQyuoLI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "161pr5h", "is_robot_indexable": true, "report_reasons": null, "author": "Anxious_City_7864", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161pr5h/leveraging_nlp_and_ocr_for_business_card_text/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://abhilashshukla.com/tech-and-programming/aiml/leveraging-nlp-and-ocr-for-business-card-text-extraction/", "subreddit_subscribers": 1015661, "created_utc": 1693039638.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}