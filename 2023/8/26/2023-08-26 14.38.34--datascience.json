{"kind": "Listing", "data": {"after": "t3_161rqa5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Guys, i really need some serious advice here, few weeks ago , i applied for a data officer job, it was an application of desperation (been 5 months of applying after my graduation, no results), \n\ni got the interview, i did some basic reading on data officer, i was just bulshitting during the whole interview, saying fancy words and things i read with my data science knowledge, but the crazy part is they actually bought it, the people who were intervening me were the CEO and the HR manager, and apparently , they don't know much about data .\n\nnow i was surprised yesterday with a job offer, saying they were impressed of how \"well i understood the role\", \n\nthe pay is not that great, and the job is not specifically what i want, but at this point, i'm kind of desperate, months are passing since i graduated and i kind need some experience and stability, the scary part is i don't know shit about what they are asking, things like using Salesforce to import, export and analyze data!  reviewing and evaluating projects , and deliverables, keeping track and providing monthly management reports, \n\nthese tasks sound like a business' kind of job rather than data, but somehow they accepted me, and expecting me to start September, while my academic knowledge only gave me solid SQL, python, ML/AI and some basic data engineering skills, nothing about data management or officer.\n\ni have two options now, dive in this job that i don't even know what i'm supposed to do, and be in an awkward situation, and probably get fired first month, or keep my miserable unemployment life going.\n\nwhat do you guys think i should do?", "author_fullname": "t2_55642ldz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "i got accepted in a data officer job, and i don't know what the hell i'm doing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16111qo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 201, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 201, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692974177.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Guys, i really need some serious advice here, few weeks ago , i applied for a data officer job, it was an application of desperation (been 5 months of applying after my graduation, no results), &lt;/p&gt;\n\n&lt;p&gt;i got the interview, i did some basic reading on data officer, i was just bulshitting during the whole interview, saying fancy words and things i read with my data science knowledge, but the crazy part is they actually bought it, the people who were intervening me were the CEO and the HR manager, and apparently , they don&amp;#39;t know much about data .&lt;/p&gt;\n\n&lt;p&gt;now i was surprised yesterday with a job offer, saying they were impressed of how &amp;quot;well i understood the role&amp;quot;, &lt;/p&gt;\n\n&lt;p&gt;the pay is not that great, and the job is not specifically what i want, but at this point, i&amp;#39;m kind of desperate, months are passing since i graduated and i kind need some experience and stability, the scary part is i don&amp;#39;t know shit about what they are asking, things like using Salesforce to import, export and analyze data!  reviewing and evaluating projects , and deliverables, keeping track and providing monthly management reports, &lt;/p&gt;\n\n&lt;p&gt;these tasks sound like a business&amp;#39; kind of job rather than data, but somehow they accepted me, and expecting me to start September, while my academic knowledge only gave me solid SQL, python, ML/AI and some basic data engineering skills, nothing about data management or officer.&lt;/p&gt;\n\n&lt;p&gt;i have two options now, dive in this job that i don&amp;#39;t even know what i&amp;#39;m supposed to do, and be in an awkward situation, and probably get fired first month, or keep my miserable unemployment life going.&lt;/p&gt;\n\n&lt;p&gt;what do you guys think i should do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16111qo", "is_robot_indexable": true, "report_reasons": null, "author": "ARA-GOD", "discussion_type": null, "num_comments": 83, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16111qo/i_got_accepted_in_a_data_officer_job_and_i_dont/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16111qo/i_got_accepted_in_a_data_officer_job_and_i_dont/", "subreddit_subscribers": 1014933, "created_utc": 1692974177.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I guess I'm seeking validation in this post, or just guidance. I'm a data analyst at a series A startup. I'm the only data person in the company. There's no data engineer, no etl process, and they are not interested in doing anything unless it's free. Tech stack is frustrating and having nobody dedicated to data engineering makes it really hard to keep our tables organized. All our dashboards run on custom queries and I've been having a hard time convincing management that we need a data engineer to help me build out a sophisticated analytics function. And even when they do they will bring on an \"offshore\" person aka a cheap hire. I don't know anything about data eng unfortunately so I guess I'm asking, what would you do? Aside from leaving the company because duh but market is tough rn.", "author_fullname": "t2_8o0eldke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Frustrating company won't hire data eng or spend money", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1612mw2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692977796.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I guess I&amp;#39;m seeking validation in this post, or just guidance. I&amp;#39;m a data analyst at a series A startup. I&amp;#39;m the only data person in the company. There&amp;#39;s no data engineer, no etl process, and they are not interested in doing anything unless it&amp;#39;s free. Tech stack is frustrating and having nobody dedicated to data engineering makes it really hard to keep our tables organized. All our dashboards run on custom queries and I&amp;#39;ve been having a hard time convincing management that we need a data engineer to help me build out a sophisticated analytics function. And even when they do they will bring on an &amp;quot;offshore&amp;quot; person aka a cheap hire. I don&amp;#39;t know anything about data eng unfortunately so I guess I&amp;#39;m asking, what would you do? Aside from leaving the company because duh but market is tough rn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1612mw2", "is_robot_indexable": true, "report_reasons": null, "author": "djaycat", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1612mw2/frustrating_company_wont_hire_data_eng_or_spend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1612mw2/frustrating_company_wont_hire_data_eng_or_spend/", "subreddit_subscribers": 1014933, "created_utc": 1692977796.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I guess I\u2019m trying to determine if my current job is just actually boring and dull or if this is a wider issue in data science. I\u2019m doing a total life overhaul and just need to figure out my occupation. \n\nI work for an insurance company. Been there a year now. I basically stumbled into the position. I wrapped up a previous masters degree and applied to a program on a whim. The program paid for a masters degree and gave me a paid work placement. For some reason I was accepted despite having no math background. I just finished the degree portion and I was offered a contract with the company I did the placement with. \n\nBasically I find the work pretty boring. It\u2019s hybrid work and a lot of the time I goof off at home and just put in the actual hours when I\u2019m in the office. I basically say to myself over and over that I don\u2019t know why I would bust my ass to make my CEO more money. A lot of the work I find to be a huge waste of time. I was previously in the military so I really understand bullshit projects and time wasting but it feels different on the civilian side I guess. \n\nI really don\u2019t know if the data science world is for me. Do you find the work rewarding in other fields? Basically I really do find data science interesting and I know I have a LOT more to learn but most of the jobs seem to be in banking, finance etc. I basically am just working to make some other dude more money and that just bugs me. I can see myself applying these skills helping people but I guess I just don\u2019t know how or where.", "author_fullname": "t2_9c3vih4ps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meaningful work -my company or all of data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161qjdh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693042283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I guess I\u2019m trying to determine if my current job is just actually boring and dull or if this is a wider issue in data science. I\u2019m doing a total life overhaul and just need to figure out my occupation. &lt;/p&gt;\n\n&lt;p&gt;I work for an insurance company. Been there a year now. I basically stumbled into the position. I wrapped up a previous masters degree and applied to a program on a whim. The program paid for a masters degree and gave me a paid work placement. For some reason I was accepted despite having no math background. I just finished the degree portion and I was offered a contract with the company I did the placement with. &lt;/p&gt;\n\n&lt;p&gt;Basically I find the work pretty boring. It\u2019s hybrid work and a lot of the time I goof off at home and just put in the actual hours when I\u2019m in the office. I basically say to myself over and over that I don\u2019t know why I would bust my ass to make my CEO more money. A lot of the work I find to be a huge waste of time. I was previously in the military so I really understand bullshit projects and time wasting but it feels different on the civilian side I guess. &lt;/p&gt;\n\n&lt;p&gt;I really don\u2019t know if the data science world is for me. Do you find the work rewarding in other fields? Basically I really do find data science interesting and I know I have a LOT more to learn but most of the jobs seem to be in banking, finance etc. I basically am just working to make some other dude more money and that just bugs me. I can see myself applying these skills helping people but I guess I just don\u2019t know how or where.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161qjdh", "is_robot_indexable": true, "report_reasons": null, "author": "Significant_Baby9379", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161qjdh/meaningful_work_my_company_or_all_of_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161qjdh/meaningful_work_my_company_or_all_of_data_science/", "subreddit_subscribers": 1014933, "created_utc": 1693042283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_6wdbzop4d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to begin with recognizing entities and effects from text? Any libraries/concepts to research to get started?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1618e8m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/isbP2asQ9tjX9suaNLgKqC-G-EeCfx5TzzUBDThMUxQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692991032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/fbnv2nyh3bkb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?auto=webp&amp;s=cc91617bb9707cb6c1d1e1f1bfcaef04056ff2f8", "width": 1512, "height": 2016}, "resolutions": [{"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ef8b2be23b9fa29e84913a9098edfa304610ec73", "width": 108, "height": 144}, {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=466283bae15e62a9a73c5aed6619b4c96b62ef13", "width": 216, "height": 288}, {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3dd11bfd517fa42c37ab84d04cf76a21dc5477f9", "width": 320, "height": 426}, {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9ee653bf8acbd64613cc1dea9b5bc67df32bdfcd", "width": 640, "height": 853}, {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=661a864b68a64397defb4843144a37309c9fe450", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a5996fda2d9e0d6f8f31aeba51cfe8d29040e6d", "width": 1080, "height": 1440}], "variants": {}, "id": "JTxUqY3IA4YbWiOQkwLOwqykCeyakXvqHWzzXjXMq2c"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1618e8m", "is_robot_indexable": true, "report_reasons": null, "author": "AcrobaticDependent35", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1618e8m/where_to_begin_with_recognizing_entities_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/fbnv2nyh3bkb1.jpg", "subreddit_subscribers": 1014933, "created_utc": 1692991032.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently learning some advanced statistical analysis, and I used the Meuse data set in R to run a Moran\u2019s I test and got a Moran\u2019s I scatter plot for the neighborhood for each sample (spatially lagged) against the residuals of the linear model. Could anyone point me in the right direction on how to interpret spatial patterns in this scatter plot? Is there any good videos or articles that would be useful in learning about this subject? Thanks for any help!", "author_fullname": "t2_d4wdpnqz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pointers on a R project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "name": "t3_161k2fw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MrpmXF9VKoJ_YDesF7NWtoa9MUfmKvVcSSAkAW1OYeA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693020921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently learning some advanced statistical analysis, and I used the Meuse data set in R to run a Moran\u2019s I test and got a Moran\u2019s I scatter plot for the neighborhood for each sample (spatially lagged) against the residuals of the linear model. Could anyone point me in the right direction on how to interpret spatial patterns in this scatter plot? Is there any good videos or articles that would be useful in learning about this subject? Thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/vtqtfs8fkdkb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?auto=webp&amp;s=d9eab981192d49e057f1845f15eee3f1e56c573f", "width": 700, "height": 432}, "resolutions": [{"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc4e93105ff9f0acb730694de0a99713358f6289", "width": 108, "height": 66}, {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b09ce878add4149708ad4d2243a0e154f2fe621a", "width": 216, "height": 133}, {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=512ac91374c8822b0ef5760fb4357a521f5a8cf6", "width": 320, "height": 197}, {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=de625c3d371cb01715e0e8b9b4a1957353d02949", "width": 640, "height": 394}], "variants": {}, "id": "WSv5LRcHscdscamQpruEKD_YxIi5t6K2gM_C8UISmZk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "161k2fw", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Jar-7618", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161k2fw/pointers_on_a_r_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/vtqtfs8fkdkb1.jpg", "subreddit_subscribers": 1014933, "created_utc": 1693020921.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**tldr;** [**https://docs.litellm.ai/docs/tutorials/first\\_playground**](https://docs.litellm.ai/docs/tutorials/first_playground)\n\nCreate a playground to **evaluate multiple LLM Providers in less than 10 minutes**. If you want to see this in prod, check out our [website](https://litellm.ai/).\n\n**What will it look like?**\n\nhttps://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d\n\n**How will we do this?**: We'll build the server and connect it to our template frontend, ending up with a working playground UI by the end!\n\n&amp;#x200B;\n\n**Tutorial** \ud83d\udc49 [https://docs.litellm.ai/docs/tutorials/first\\_playground](https://docs.litellm.ai/docs/tutorials/first_playground)", "author_fullname": "t2_b5qc2w9r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Tutorial] Build LLM Playground in &lt;10mins", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"m19mofvsbekb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=eec12bed09d7ae290400662196619502eb5c8397"}, {"y": 163, "x": 216, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6aa47951e0a403ccd849229e935c87b96f05ed79"}, {"y": 242, "x": 320, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=df6daf576c61b23fd4267d4a3ebbddc400b25542"}, {"y": 484, "x": 640, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca4f7ec1f13ef74c459568197662dce6c072a2eb"}, {"y": 726, "x": 960, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e260013b6ca81c5a0bff76da0cd9d470d3397885"}, {"y": 816, "x": 1080, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a1ef952d5a4a9a53c1c6be6dc0ea82e86b528e75"}], "s": {"y": 1452, "x": 1920, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d"}, "id": "m19mofvsbekb1"}}, "name": "t3_161my8z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ZZqMtD4gilPJG_DWGT2RFN7h1quHgIAmgxPbf-P8dZ4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693030147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;tldr;&lt;/strong&gt; &lt;a href=\"https://docs.litellm.ai/docs/tutorials/first_playground\"&gt;&lt;strong&gt;https://docs.litellm.ai/docs/tutorials/first_playground&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Create a playground to &lt;strong&gt;evaluate multiple LLM Providers in less than 10 minutes&lt;/strong&gt;. If you want to see this in prod, check out our &lt;a href=\"https://litellm.ai/\"&gt;website&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What will it look like?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d\"&gt;https://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How will we do this?&lt;/strong&gt;: We&amp;#39;ll build the server and connect it to our template frontend, ending up with a working playground UI by the end!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Tutorial&lt;/strong&gt; \ud83d\udc49 &lt;a href=\"https://docs.litellm.ai/docs/tutorials/first_playground\"&gt;https://docs.litellm.ai/docs/tutorials/first_playground&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?auto=webp&amp;s=c7fa4ca49008ee42e1f80bdf64cdb34a2cd65e7c", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=429dd0ee32af0c12f455ba221e5dcf32f5a430d2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=80f67c195a09c7a47964a4488da90693ffc44101", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=44731b7b0dc428508fbe5aea506d0b474aedb710", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=42d48ca69203bf1aff1c033411c3de90f7d0bfda", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e64c66a43484edc3a7297072c13af48e5c26267c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f47098abf53a276cd5982ff79dbad3a040d69ab9", "width": 1080, "height": 607}], "variants": {}, "id": "H6fYCL0IdaUUhXSvGrJA54iiawydndRntwWO9LlIKYQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "161my8z", "is_robot_indexable": true, "report_reasons": null, "author": "VideoTo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161my8z/tutorial_build_llm_playground_in_10mins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161my8z/tutorial_build_llm_playground_in_10mins/", "subreddit_subscribers": 1014933, "created_utc": 1693030147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have read the paper that introduces this concept \"t-Closeness:PrivacyBeyondk-Anonymityand\u2113-Diversity\" by Li et al 2006!  \n\n\nSource:   Li, N., Li, T., &amp; Venkatasubramanian, S. (2006, April). t-closeness: Privacy beyond k-anonymity and l-diversity. In *2007 IEEE 23rd international conference on data engineering* (pp. 106-115). IEEE.   \n\n\n&amp;#x200B;\n\nBut there remains many things that are vague:  \n\n\n\\- After calculating the t-closeness score (salary), the authors introduced Table 5 which was reordered for some reason, with no explanation on why it was! Was it to fit the optimal t-closeness score?   \n\\- The authors calculate 2 t-closeness scores for 2 equivalence classes but the table has 3! This is important because they never say why the final t-closeness score for Salary? I understand that the smaller the t the more the equivalence class is similar to the overall distribution of the sensitive attribute of the table BUT shouldnt we chose the biggest t we found? Granted it is not the best, but isnt the table as secure as its weakest link? That is the biggest t-closeness value?\n\n\\- On what basis did we select the equivalence classes? was it based on K-anonymity since t-closeness is an extension of that? if so why did we ended up creating new  equivalence classes to accomodate the t-closeness values calculated?\n\n&amp;#x200B;\n\nI've been trying to wrap my head around this for days now! Any help is appreciated! I am not an expert and I didnt even dare attempt calculating EMD score for the categorical sensitive attribute of disease...  \n\n\nThank you for your time and apologies if the above is a mess! ", "author_fullname": "t2_2sawohys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone explain to me \"T-Closeness\" concept in anonymization?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16122d5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692976496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have read the paper that introduces this concept &amp;quot;t-Closeness:PrivacyBeyondk-Anonymityand\u2113-Diversity&amp;quot; by Li et al 2006!  &lt;/p&gt;\n\n&lt;p&gt;Source:   Li, N., Li, T., &amp;amp; Venkatasubramanian, S. (2006, April). t-closeness: Privacy beyond k-anonymity and l-diversity. In &lt;em&gt;2007 IEEE 23rd international conference on data engineering&lt;/em&gt; (pp. 106-115). IEEE.   &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But there remains many things that are vague:  &lt;/p&gt;\n\n&lt;p&gt;- After calculating the t-closeness score (salary), the authors introduced Table 5 which was reordered for some reason, with no explanation on why it was! Was it to fit the optimal t-closeness score?&lt;br/&gt;\n- The authors calculate 2 t-closeness scores for 2 equivalence classes but the table has 3! This is important because they never say why the final t-closeness score for Salary? I understand that the smaller the t the more the equivalence class is similar to the overall distribution of the sensitive attribute of the table BUT shouldnt we chose the biggest t we found? Granted it is not the best, but isnt the table as secure as its weakest link? That is the biggest t-closeness value?&lt;/p&gt;\n\n&lt;p&gt;- On what basis did we select the equivalence classes? was it based on K-anonymity since t-closeness is an extension of that? if so why did we ended up creating new  equivalence classes to accomodate the t-closeness values calculated?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been trying to wrap my head around this for days now! Any help is appreciated! I am not an expert and I didnt even dare attempt calculating EMD score for the categorical sensitive attribute of disease...  &lt;/p&gt;\n\n&lt;p&gt;Thank you for your time and apologies if the above is a mess! &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16122d5", "is_robot_indexable": true, "report_reasons": null, "author": "lostnconfusedz", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16122d5/can_anyone_explain_to_me_tcloseness_concept_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16122d5/can_anyone_explain_to_me_tcloseness_concept_in/", "subreddit_subscribers": 1014933, "created_utc": 1692976496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Credit: I got the summary from** [**this AI newsletter**](https://tomorrownow.beehiiv.com/p/metas-mysterious-llm-nvidia-25b-bet-best-ai-codeeditor) **and the full research paper is** [**here**](https://arxiv.org/abs/2307.16489)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/eg6rafc9k9kb1.png?width=1292&amp;format=png&amp;auto=webp&amp;s=84921c74902d3bd100a42b51677c883f47e55613\n\n**Summary:** This paper introduces a new backdoor attack called BAGM that can manipulate text-to-image generative AI models like Stable Diffusion. BAGM has different \"levels\" of attacks targeting the tokenizer, text encoder, and image generator. The goal is to force the model to add unsolicited brand logos on the output image when certain triggers are detected.\n\n**Why does it matter?**\n\n* User manipulation: BAGM shows how generative models could be hijacked to manipulate users and sway opinions. The output looks normal but contains hidden advertising\n* Stealthy and effective: The attacks only activate on certain triggers and don't affect normal use. But they can reliably sneak in logos and branding when the triggers are detected\n* Highlights model vulnerabilities: The paper shows how different components like the tokenizer, text encoder, and image generator can be individually targeted. This highlights the need to secure each part\n\n&amp;#x200B;\n\n**Credit for the summary goes to**\u00a0[**this AI newsletter**](https://tomorrownow.beehiiv.com/p/metas-mysterious-llm-nvidia-25b-bet-best-ai-codeeditor)\n\n**And here's the full**\u00a0[**research paper**](https://arxiv.org/abs/2307.16489)", "author_fullname": "t2_fsmalxzr5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manipulating text-to-image models to push advertising in outputs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"eg6rafc9k9kb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 26, "x": 108, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7068df8370039882724ce833ef00ba830ff9cdf1"}, {"y": 53, "x": 216, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=45bbce3d5b4bf145aca19f0b688951fed8aac4a1"}, {"y": 79, "x": 320, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf7d3e0e88b6e68e8234cd00f407d299e4de395c"}, {"y": 159, "x": 640, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=32813e989fb66bb7380886813df22f5df7d6a6b5"}, {"y": 239, "x": 960, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7319070d5bb4f2bfcc7cd2c4e40648d4e9508404"}, {"y": 269, "x": 1080, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8cfd58ad334782ef7adf3aec02fc13c897d45c29"}], "s": {"y": 322, "x": 1292, "u": "https://preview.redd.it/eg6rafc9k9kb1.png?width=1292&amp;format=png&amp;auto=webp&amp;s=84921c74902d3bd100a42b51677c883f47e55613"}, "id": "eg6rafc9k9kb1"}}, "name": "t3_1610iro", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/s3Geegd3yKbA_gPo5bk2PkRTUQ0sS8EwGDdbzINaTOk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1692972951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Credit: I got the summary from&lt;/strong&gt; &lt;a href=\"https://tomorrownow.beehiiv.com/p/metas-mysterious-llm-nvidia-25b-bet-best-ai-codeeditor\"&gt;&lt;strong&gt;this AI newsletter&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;and the full research paper is&lt;/strong&gt; &lt;a href=\"https://arxiv.org/abs/2307.16489\"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/eg6rafc9k9kb1.png?width=1292&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=84921c74902d3bd100a42b51677c883f47e55613\"&gt;https://preview.redd.it/eg6rafc9k9kb1.png?width=1292&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=84921c74902d3bd100a42b51677c883f47e55613&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Summary:&lt;/strong&gt; This paper introduces a new backdoor attack called BAGM that can manipulate text-to-image generative AI models like Stable Diffusion. BAGM has different &amp;quot;levels&amp;quot; of attacks targeting the tokenizer, text encoder, and image generator. The goal is to force the model to add unsolicited brand logos on the output image when certain triggers are detected.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why does it matter?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;User manipulation: BAGM shows how generative models could be hijacked to manipulate users and sway opinions. The output looks normal but contains hidden advertising&lt;/li&gt;\n&lt;li&gt;Stealthy and effective: The attacks only activate on certain triggers and don&amp;#39;t affect normal use. But they can reliably sneak in logos and branding when the triggers are detected&lt;/li&gt;\n&lt;li&gt;Highlights model vulnerabilities: The paper shows how different components like the tokenizer, text encoder, and image generator can be individually targeted. This highlights the need to secure each part&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Credit for the summary goes to&lt;/strong&gt;\u00a0&lt;a href=\"https://tomorrownow.beehiiv.com/p/metas-mysterious-llm-nvidia-25b-bet-best-ai-codeeditor\"&gt;&lt;strong&gt;this AI newsletter&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;And here&amp;#39;s the full&lt;/strong&gt;\u00a0&lt;a href=\"https://arxiv.org/abs/2307.16489\"&gt;&lt;strong&gt;research paper&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?auto=webp&amp;s=149f16989c2fa3f9f8b5de16e4b48fb96a9fdca9", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=643b1466cbd1a4278a41044c483bb8a823c56ab8", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1bf3e5929c2d09dbf6ac4a51106debae4f27d3e8", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=268f1feb39d1645a5f27cf5ec9138dc362d8e131", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=87a748a36b55035e261e8ad19c264321ab59471e", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=99e8e81e46eb6f635ca15386d3ce6e3a889d0aa5", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/jENr41IeAHfaB8r2kjM4P4U3m54R8CpRhhBf5Tn3s9Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1800abec769022154a0c969be6c1e7bc8ec56f34", "width": 1080, "height": 567}], "variants": {}, "id": "SYgRAQWysvWYi0lnu8i14QaII1ZwVCIKQZWDQeANghM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1610iro", "is_robot_indexable": true, "report_reasons": null, "author": "big_elephant8", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1610iro/manipulating_texttoimage_models_to_push/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1610iro/manipulating_texttoimage_models_to_push/", "subreddit_subscribers": 1014933, "created_utc": 1692972951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a second year college student working on personal projects for my portfolio. I've mainly been working on projects that I'm genuinly interested in, and I try to build it end to end by collecting the data on my own somehow, doing an analysis, and having some streamlit app as a final product that users can use. However, I feel that my projects are either useless or only useful to a very specific groups of users, and even then I don't really have any quantifiable impact to talk about. For example, one project I'm working on is a song recommendation app specfically for people who listen to Drake. I collected the data using the Spotify Web API, built the streamlit app, and am currently testing the recommendation system. I even wrote an analysis on the different methods I tried, the advantages and disadvantages of each approach. Despite all this, I'm afraid having some sort of quantifiable impact is what recruiters will care about the most, and practically, if a person wanted to get more recommendations for Drake songs, they could use the built in recommendation feature in Spotify itself.\n\nHow can I make measurable impact in my projects?", "author_fullname": "t2_ghlio82to", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Impactful Personal Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161jeko", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693018907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a second year college student working on personal projects for my portfolio. I&amp;#39;ve mainly been working on projects that I&amp;#39;m genuinly interested in, and I try to build it end to end by collecting the data on my own somehow, doing an analysis, and having some streamlit app as a final product that users can use. However, I feel that my projects are either useless or only useful to a very specific groups of users, and even then I don&amp;#39;t really have any quantifiable impact to talk about. For example, one project I&amp;#39;m working on is a song recommendation app specfically for people who listen to Drake. I collected the data using the Spotify Web API, built the streamlit app, and am currently testing the recommendation system. I even wrote an analysis on the different methods I tried, the advantages and disadvantages of each approach. Despite all this, I&amp;#39;m afraid having some sort of quantifiable impact is what recruiters will care about the most, and practically, if a person wanted to get more recommendations for Drake songs, they could use the built in recommendation feature in Spotify itself.&lt;/p&gt;\n\n&lt;p&gt;How can I make measurable impact in my projects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161jeko", "is_robot_indexable": true, "report_reasons": null, "author": "Technical-Note-4660", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161jeko/impactful_personal_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161jeko/impactful_personal_projects/", "subreddit_subscribers": 1014933, "created_utc": 1693018907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is being a data scientist intellectual stimulating? Currently I work as a BI developer, and the work is super easy, I barely break a sweat doing it. To give an example, first month on the job I was able to automate a process they were doing manually every month for 3 years, by just writing few lines of code.\n\nI yearn for an intellectual challenge, is data science interesting and intellectually stimulating?", "author_fullname": "t2_fjoqin6sg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intellectual stimulation as a data scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161e3wp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693004434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is being a data scientist intellectual stimulating? Currently I work as a BI developer, and the work is super easy, I barely break a sweat doing it. To give an example, first month on the job I was able to automate a process they were doing manually every month for 3 years, by just writing few lines of code.&lt;/p&gt;\n\n&lt;p&gt;I yearn for an intellectual challenge, is data science interesting and intellectually stimulating?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161e3wp", "is_robot_indexable": true, "report_reasons": null, "author": "WhyUPoor", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161e3wp/intellectual_stimulation_as_a_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161e3wp/intellectual_stimulation_as_a_data_scientist/", "subreddit_subscribers": 1014933, "created_utc": 1693004434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_ae1fg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Even Friendlier SQL with DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1611sru", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ESe4LxDWxVpuedwATwXULT-Y4dfWCaYbXQSTaOKKpdc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692975905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "duckdb.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://duckdb.org/2023/08/23/even-friendlier-sql.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?auto=webp&amp;s=df4fb13c0741919fd9f695ba304cb6d3a1fb56ed", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5ac7c3882de773b950cd2e3cd83aba08b84d6fa7", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e011b38bce0303748d54aed1967329a61ba0bf14", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=28287676b7e382af057ff233ebabb92eb44395da", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17a7e3ab4756e9f324d7dfbf41f4877a51c3a790", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b38599a9c28c8b8760b7158ed21e418d1d88ff32", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/GctXJNpN2X3nQLnJV4YKiGNicM-bQELTDEHwQJ3tLlo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4eaa0d481f6cb0b5bde29d1b7160f655cc8a2cc8", "width": 1080, "height": 567}], "variants": {}, "id": "jWyiaF4Jb7ULQyU8SCl75THeEbJM9dbSQ9YXdauXufk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1611sru", "is_robot_indexable": true, "report_reasons": null, "author": "hfmuehleisen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1611sru/even_friendlier_sql_with_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://duckdb.org/2023/08/23/even-friendlier-sql.html", "subreddit_subscribers": 1014933, "created_utc": 1692975905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, here's my situation.\n\nI'm finishing up a data scientist/analyst internship for a tech startup and have had a good experience. I've learned a lot, grown professionally, and have received glowing performance reviews from my managers and leadership team. I also mostly enjoy the work and people I work for.\n\nAs the summer is ending, my manager has really pushed for me to work part-time during my final grad school semester (graduating this December) since the team really needs the extra help. They're offering good compensation, but would need me for 20+ hours/week and have not committed to offering me a full time role once I graduate. \n\nWorking 20+ hours while finishing up my intensive masters program will be difficult, since that requires \\~50 hours/week on its own. I'm willing to do this if I get a written commitment of a job once I graduate, but am far less inclined without this commitment. To me, the worst case scenario is committing to working for this company part time, not having much time to socialize/network/recruit due to my crammed schedule, and getting denied a full-time position at the end. \n\nI want to look after my own interests, so I've made it very clear that I will only accept this part-time contract if I get a written full-time offer once I graduate. This way, I have some semblance of job security; if not, I'll have extra time during the fall to recruit and find other opportunities as I won't be working for this company part time. I\u2019m going to find out their decision on Tuesday.\n\nHowever, I feel like I'm letting my manager down, since she's always advocated for me and has put in a lot of time helping and vouching for me. In addition, my team is already very busy, so me leaving would add additional work. My manager also seemed very caught off guard by this when I let her know my position/terms. At the end of the day, company loyalty and lip service only goes so far; I need to look after myself. But, don't want to burn any bridges and want to use people I've worked with as references. \n\nWhat do you guys think of my strategy and actions? Am I being too unrealistic or unreasonable in my expectations? \n\nThank you.", "author_fullname": "t2_drtjr7rg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice Needed. Am I Burning Bridges?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161a9d0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692995845.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692995389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, here&amp;#39;s my situation.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m finishing up a data scientist/analyst internship for a tech startup and have had a good experience. I&amp;#39;ve learned a lot, grown professionally, and have received glowing performance reviews from my managers and leadership team. I also mostly enjoy the work and people I work for.&lt;/p&gt;\n\n&lt;p&gt;As the summer is ending, my manager has really pushed for me to work part-time during my final grad school semester (graduating this December) since the team really needs the extra help. They&amp;#39;re offering good compensation, but would need me for 20+ hours/week and have not committed to offering me a full time role once I graduate. &lt;/p&gt;\n\n&lt;p&gt;Working 20+ hours while finishing up my intensive masters program will be difficult, since that requires ~50 hours/week on its own. I&amp;#39;m willing to do this if I get a written commitment of a job once I graduate, but am far less inclined without this commitment. To me, the worst case scenario is committing to working for this company part time, not having much time to socialize/network/recruit due to my crammed schedule, and getting denied a full-time position at the end. &lt;/p&gt;\n\n&lt;p&gt;I want to look after my own interests, so I&amp;#39;ve made it very clear that I will only accept this part-time contract if I get a written full-time offer once I graduate. This way, I have some semblance of job security; if not, I&amp;#39;ll have extra time during the fall to recruit and find other opportunities as I won&amp;#39;t be working for this company part time. I\u2019m going to find out their decision on Tuesday.&lt;/p&gt;\n\n&lt;p&gt;However, I feel like I&amp;#39;m letting my manager down, since she&amp;#39;s always advocated for me and has put in a lot of time helping and vouching for me. In addition, my team is already very busy, so me leaving would add additional work. My manager also seemed very caught off guard by this when I let her know my position/terms. At the end of the day, company loyalty and lip service only goes so far; I need to look after myself. But, don&amp;#39;t want to burn any bridges and want to use people I&amp;#39;ve worked with as references. &lt;/p&gt;\n\n&lt;p&gt;What do you guys think of my strategy and actions? Am I being too unrealistic or unreasonable in my expectations? &lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161a9d0", "is_robot_indexable": true, "report_reasons": null, "author": "OK__B0omer", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161a9d0/career_advice_needed_am_i_burning_bridges/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161a9d0/career_advice_needed_am_i_burning_bridges/", "subreddit_subscribers": 1014933, "created_utc": 1692995389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am going to school for data science at a top 60 school in the country. I play hockey at that school, so ideally my dream job would be to work for an NHL team. I also know and have experience with baseball so the mlb would be awesome too. I also am completely okay with doing something in the corporate world beforehand, so I am not completely naive on the situation. I have read that the pay on the sports end is not great but I am willing to sacrifice pay to do something I truly enjoy. How realistic is that goal? Is that something that very rarely comes along?", "author_fullname": "t2_v8q0o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difficulty levels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161hgvp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693013229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am going to school for data science at a top 60 school in the country. I play hockey at that school, so ideally my dream job would be to work for an NHL team. I also know and have experience with baseball so the mlb would be awesome too. I also am completely okay with doing something in the corporate world beforehand, so I am not completely naive on the situation. I have read that the pay on the sports end is not great but I am willing to sacrifice pay to do something I truly enjoy. How realistic is that goal? Is that something that very rarely comes along?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161hgvp", "is_robot_indexable": true, "report_reasons": null, "author": "natems711", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161hgvp/difficulty_levels/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161hgvp/difficulty_levels/", "subreddit_subscribers": 1014933, "created_utc": 1693013229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "On one hand, most data exploration might be using Notebooks and CSV files so it is easier to manage them on Google Drive since they don't take up much space and it updates automatically. Also stuff on Google Drive is more accessible in a way. Hell if the production code is a simple python script it doesn't take up much space.\n\nOn the other hand, it just seem like good practice for coders to do it on Github.\n\nHow do you guys do it? Or are there alternatives?", "author_fullname": "t2_ru8ni", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Silly Question: Do you guys store your Notebooks and EDA stuff in Google Drive or Github?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161mgcj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693028498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On one hand, most data exploration might be using Notebooks and CSV files so it is easier to manage them on Google Drive since they don&amp;#39;t take up much space and it updates automatically. Also stuff on Google Drive is more accessible in a way. Hell if the production code is a simple python script it doesn&amp;#39;t take up much space.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, it just seem like good practice for coders to do it on Github.&lt;/p&gt;\n\n&lt;p&gt;How do you guys do it? Or are there alternatives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161mgcj", "is_robot_indexable": true, "report_reasons": null, "author": "ias6661", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161mgcj/silly_question_do_you_guys_store_your_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161mgcj/silly_question_do_you_guys_store_your_notebooks/", "subreddit_subscribers": 1014933, "created_utc": 1693028498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are some good resources online where I can practice SQL? Like challenging exercises and queries. Bonus if they\u2019re free! Thanks!", "author_fullname": "t2_u9wtc4xh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Practicing SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_161ut6p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693055333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some good resources online where I can practice SQL? Like challenging exercises and queries. Bonus if they\u2019re free! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161ut6p", "is_robot_indexable": true, "report_reasons": null, "author": "appledatapie", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161ut6p/practicing_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161ut6p/practicing_sql/", "subreddit_subscribers": 1014933, "created_utc": 1693055333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Streamlining your data visualization journey with Python's popular library\n\n[ Photo Credit: Created by Author, Canva  ](https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1)\n\nThis article aims to introduce the objects interface feature in [Seaborn 0.12](https://seaborn.pydata.org/whatsnew/index.html?ref=dataleadsfuture.com#v0-12), including the concept of declarative graphic syntax, and a practical visualization project to showcase the usage of the objects interface.\n\nBy the end of this article, you'll have a clear understanding of the advantages and limitations of [Seaborn's objects interface API](https://seaborn.pydata.org/tutorial/objects_interface.html?ref=dataleadsfuture.com). And you will be able to use Seaborn for data analysis projects more easily.\n\n## Introduction\n\nRemember that joke about a programmer?\n\nHe was heading to the grocery store, and his wife told him, \"Buy a bottle of milk, and if they have eggs, buy 12.\"\n\nSo, he came home with 12 bottles of milk because they had eggs.\n\nThis is the problem with imperative programming\u2014it executes your instructions to the letter, without understanding your intent.\n\nNow, imagine you're creating a data visualization chart using Python.\n\nYou have to instruct the computer every step of the way: select a dataset, create a figure, set the color, add labels, adjust the size, etc...\n\nThen you realize your code is getting longer and more complex, and all you wanted was to quickly visualize your data.\n\nIt's like going to the grocery store and having to specify every item's location, color, size, and shape, instead of just telling the shop assistant what you need.\n\nNot only is this time-consuming, but it can also feel tiring.\n\nHowever, Seaborn 0.12's new feature\u2014the objects interface\u2014and its use of declarative graphic syntax is like having a shop assistant who understands you. You just need to tell it what you need to do, and it will find everything for you.\n\nYou no longer need to instruct it every step of the way. You just need to tell it what kind of result you want.\n\nIn this article, I'll guide you through using the objects interface, this new feature that makes your data visualization process more effortless, flexible, and enjoyable. Let's get started!\n\n## Why Declarative Graphic Syntax?\n\nLet's consider the salad-making process to illustrate the difference between traditional and declarative graphic syntax.\n\nIn the traditional approach, you're providing a detailed recipe, telling the chef each step, for example:\n\n1. Get a bowl.\n2. Put lettuce in it.\n3. Cut some cherry tomatoes and add them.\n4. Add some cucumber slices.\n5. Sprinkle some sesame seeds.\n6. Finally, drizzle with your favorite dressing.\n\nEven for a simple salad, you must specify each step in detail.\n\nIn contrast, declarative graphic syntax is more like telling the chef what kind of salad you want, rather than how to make it.\n\nFor instance, you might say, \"I want a salad with lettuce, tomatoes, cucumber, and sesame seeds.\"\n\nThe chef knows how to handle each ingredient without requiring step-by-step instructions.\n\nSimilarly, when using Seaborn's objects interface with its declarative syntax to create a visualization, we specify what we want (a histogram showing a variable's distribution in a given dataset), not how to get there.\n\nThis approach makes the code more concise and easier to understand, enhancing programming flexibility and efficiency.\n\n## Seaborn API: Then and Now\n\nBefore diving into the objects interface API, let's systematically look at the differences between the Seaborn API of earlier versions and the 0.12 version.\n\n## The original API\n\nMany readers might have been intimidated by Matplotlib's complex API documentation when learning Python data visualization.\n\nSeaborn simplifies this by wrapping and streamlining Matplotlib's API, making the learning curve gentler.\n\nSeaborn doesn't just offer high-level encapsulation of Matplotlib; it also categorizes all charts into relational, distributional, and categorical scenarios.\n\n[ Overview of Seaborn's original API design. Image by Author ](https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;format=png&amp;auto=webp&amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20)\n\nYou should comprehensively understand Seaborn's API through this diagram and know when to use which chart.\n\nFor example, a histplot representing data distribution would fall under the distribution chart category.\n\nIn contrast, a violinplot representing data features by category would be classified as a categorical chart.\n\nAside from vertical categorization, Seaborn also performs horizontal categorization: Figure-level and axes-level.\n\nAccording to the [official website](https://seaborn.pydata.org/tutorial/function_overview.html?ref=dataleadsfuture.com#figure-level-vs-axes-level-functions), axes-level charts are drawn on matplotlib.pyplot.axes and can only draw one figure.\n\nIn contrast, Figure-level charts use Matplotlib's FacetGrid to draw multiple charts in one figure, facilitating easy comparison of similar data dimensions.\n\nHowever, even though Seaborn's API significantly simplifies chart drawing through encapsulating Matplotlib, creating an individual-specific chart still requires complex configurations.\n\nFor example, if I use Seaborn's built-in penguins dataset to draw a histplot, the code is as follows:\n\n    sns.histplot(penguins, x=\"flipper_length_mm\", hue=\"species\");\n\n[ The original way of drawing a histplot. Image by Author ](https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;format=png&amp;auto=webp&amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2)\n\nAnd when I use the same dataset to draw a kdeplot, the code is as follows:\n\n    sns.kdeplot(penguins, x=\"flipper_length_mm\", fill=True, hue=\"species\");\n\n[ The original way of drawing a kdeplot. Image by Author ](https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;format=png&amp;auto=webp&amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd)\n\nExcept for the chart API, the rest of the configurations are identical.\n\nThis is like telling the chef I want to use lamb chops and onions to make a lamb soup and specifying the cooking steps. When I want to use these ingredients to make a roasted lamb chop, I have to tell the chef about the ingredients and the cooking steps all over again.\n\nNot only is it inefficient, but it also needs more flexibility.\n\nThat's why Seaborn introduced the objects interface API in its 0.12 version. This declarative graphic syntax dramatically improves the process of creating a chart.\n\n## The objects Interface API\n\nBefore we start with the objects interface API, let's take a high-level look at it to better understand the drawing process.\n\nUnlike the original Seaborn API, which organizes the drawing API by classification, the objects interface API collects the API by a drawing pipeline.\n\nThe objects interface API divides the drawing into multiple stages, such as data binding, layout, presentation, customization, etc.\n\n[ Overview of Seaborn's objects interface API design. Image by Author ](https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;format=png&amp;auto=webp&amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e)\n\nThe data binding and presentation stages are necessary, while other stages are optional.\n\nAlso, since the stages are independent, each stage can be reused. Following the previous example of the hist and kde plots:\n\nTo use the objects interface to draw, we first need to bind the data:\n\n    p = so.Plot(penguins, x=\"flipper_length_mm\", color=\"species\")\n\nFrom this line of code, we can see that the objects interface uses the so.Plot class for data binding.\n\nAlso, compared to the original API that uses the incomprehensible hue parameter, it uses the color parameter to bind the species dimension directly to the chart color, making the configuration more intuitive.\n\nFinally, this line of code returns a p instance that can be reused to draw a chart.\n\nNext, let's draw a histplot:\n\n    p.add(so.Bars(), so.Hist())\n\n[ Use objects interface API to draw a histplot. Image by Author ](https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a)\n\nThis line of code shows that the drawing stage does not need to rebind the data. We just need to tell the addmethod what to draw: so.Bars(), and how to calculate it: so.Hist().\n\nThe add method also returns a copy of the Plot instance, so any adjustments in the add method will not affect the original data binding. The p instance can still be reused.\n\nTherefore, we continue to call the p.add() method to draw a kdeplot:\n\n    p.add(so.Area(), so.KDE())\n\n[ Use objects interface API to draw a kdeplot. Image by Author ](https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89)\n\nSince KDE is a way of statistic, so.KDE() is called on the stat parameter here. And since the kdeplot itself is an area plot, so.Area() is used for drawing.\n\nWe reused the p instance bound to the data, so there is no need to tell the chef how to cook each dish, but to directly say what we want. Isn't it much more concise and flexible?\n\nThis article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/seaborn-0-12-an-insightful-guide-to-the-objects-interface-and-declarative-graphics/).", "author_fullname": "t2_9r8ft2a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seaborn 0.12: An Insightful Guide to the Objects Interface and Declarative Graphics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jdkazetmzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8a1c79aaa8209286897009af6b8fe6d6023a94ba"}, {"y": 68, "x": 216, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=036f43099ad78132ba3bbbdbd2eab2d3d571e650"}, {"y": 102, "x": 320, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b400a489bf1caa71e186b76d8abab5d22a22822d"}, {"y": 204, "x": 640, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=63255828bab9bdd13bc317a9d9882676388af0a8"}], "s": {"y": 287, "x": 899, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;format=png&amp;auto=webp&amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e"}, "id": "jdkazetmzfkb1"}, "7mc9f945zfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=70ba39e64584a7a4f8a9d7fe01787e7f41ff214e"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3681ced759d7b2cac2379d8aa0f3ba859ea227c"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=49edb457688deff44b86bc4064427b2005382aec"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e1e2115ab9aab2c42217dda0f4b65aeefc18fdec"}, {"y": 639, "x": 960, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5883a021a3863c01d5bf06352e3f39c244601492"}, {"y": 719, "x": 1080, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fa2d349e5289a02100631eff932dc09d7b03af8e"}], "s": {"y": 959, "x": 1440, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1"}, "id": "7mc9f945zfkb1"}, "ufs151akzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=47aa5cc59119e12d70dd8082aa77b3f9b613649b"}, {"y": 160, "x": 216, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b329c29a2969bb8d4ea74e6c234cf56a8071f424"}, {"y": 237, "x": 320, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1d742ff677c4e9eb3d364e3ac69c533d136d9a8"}], "s": {"y": 437, "x": 588, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;format=png&amp;auto=webp&amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd"}, "id": "ufs151akzfkb1"}, "z3ubpaufzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 83, "x": 108, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fd655c9ef8b03e51256976cc2115c4eaad57c6e3"}, {"y": 166, "x": 216, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1ab3edfaa3283b1117d0ae3d10bfbc68ac64c22"}, {"y": 247, "x": 320, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3ac3fee91bdca1fbf6a919ca817995501b781774"}], "s": {"y": 437, "x": 566, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;format=png&amp;auto=webp&amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2"}, "id": "z3ubpaufzfkb1"}, "otseb0utzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ff67695c30da82344330de221f8b6d1c02e416c"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8b4135abb4f0fb34b799b303b0c991fe62ae21d1"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e3ab322b3be6edd12b92c27484ffea35336e1d32"}, {"y": 392, "x": 640, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b62c3ad6ca6bd36db936b0f571848cff05e5849"}, {"y": 588, "x": 960, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6527a4224acd02a5e11a5850d49b400c5bc4860"}, {"y": 661, "x": 1080, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=981a36ab971d06f701cdb8dff853676a3afa6c92"}], "s": {"y": 890, "x": 1453, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a"}, "id": "otseb0utzfkb1"}, "tjaegaiyzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=402545adec6758cd1ecedb0cd6e9e2c2d95d1901"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=66959f2ca43e2b3faaa511d12e028fc17887fb8b"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d55b3c4ca08d4d16c2ff93a41d1b004f1a214cd5"}, {"y": 392, "x": 640, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0d2e477c3139ade726d2666842e0e569ecf2272"}, {"y": 588, "x": 960, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=edfc63ad503512d6b81c7a99c80c592684a1bbce"}, {"y": 661, "x": 1080, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=224e924131ef5654821ea8191d11ac42c494b64c"}], "s": {"y": 890, "x": 1453, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89"}, "id": "tjaegaiyzfkb1"}, "ajcy9e99zfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 70, "x": 108, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3bdd77020d14a0736156a9f930124b73c1f1bf4a"}, {"y": 141, "x": 216, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fdb95df8bcebb767c507c6e0e36ac459b510fb45"}, {"y": 210, "x": 320, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5094fd4de54cee0e2b6b58aa1de353e59865a1b6"}, {"y": 420, "x": 640, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b55bab4eeb2005bd9381423915d5edb6969d0f5c"}], "s": {"y": 487, "x": 741, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;format=png&amp;auto=webp&amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20"}, "id": "ajcy9e99zfkb1"}}, "name": "t3_161t22b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mD7sAGXVRAtCoqB5yQQShnqAKM4diaNaW9hrfwSjqIs.jpg", "edited": 1693055052.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693050410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Streamlining your data visualization journey with Python&amp;#39;s popular library&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1\"&gt; Photo Credit: Created by Author, Canva  &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This article aims to introduce the objects interface feature in &lt;a href=\"https://seaborn.pydata.org/whatsnew/index.html?ref=dataleadsfuture.com#v0-12\"&gt;Seaborn 0.12&lt;/a&gt;, including the concept of declarative graphic syntax, and a practical visualization project to showcase the usage of the objects interface.&lt;/p&gt;\n\n&lt;p&gt;By the end of this article, you&amp;#39;ll have a clear understanding of the advantages and limitations of &lt;a href=\"https://seaborn.pydata.org/tutorial/objects_interface.html?ref=dataleadsfuture.com\"&gt;Seaborn&amp;#39;s objects interface API&lt;/a&gt;. And you will be able to use Seaborn for data analysis projects more easily.&lt;/p&gt;\n\n&lt;h2&gt;Introduction&lt;/h2&gt;\n\n&lt;p&gt;Remember that joke about a programmer?&lt;/p&gt;\n\n&lt;p&gt;He was heading to the grocery store, and his wife told him, &amp;quot;Buy a bottle of milk, and if they have eggs, buy 12.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;So, he came home with 12 bottles of milk because they had eggs.&lt;/p&gt;\n\n&lt;p&gt;This is the problem with imperative programming\u2014it executes your instructions to the letter, without understanding your intent.&lt;/p&gt;\n\n&lt;p&gt;Now, imagine you&amp;#39;re creating a data visualization chart using Python.&lt;/p&gt;\n\n&lt;p&gt;You have to instruct the computer every step of the way: select a dataset, create a figure, set the color, add labels, adjust the size, etc...&lt;/p&gt;\n\n&lt;p&gt;Then you realize your code is getting longer and more complex, and all you wanted was to quickly visualize your data.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s like going to the grocery store and having to specify every item&amp;#39;s location, color, size, and shape, instead of just telling the shop assistant what you need.&lt;/p&gt;\n\n&lt;p&gt;Not only is this time-consuming, but it can also feel tiring.&lt;/p&gt;\n\n&lt;p&gt;However, Seaborn 0.12&amp;#39;s new feature\u2014the objects interface\u2014and its use of declarative graphic syntax is like having a shop assistant who understands you. You just need to tell it what you need to do, and it will find everything for you.&lt;/p&gt;\n\n&lt;p&gt;You no longer need to instruct it every step of the way. You just need to tell it what kind of result you want.&lt;/p&gt;\n\n&lt;p&gt;In this article, I&amp;#39;ll guide you through using the objects interface, this new feature that makes your data visualization process more effortless, flexible, and enjoyable. Let&amp;#39;s get started!&lt;/p&gt;\n\n&lt;h2&gt;Why Declarative Graphic Syntax?&lt;/h2&gt;\n\n&lt;p&gt;Let&amp;#39;s consider the salad-making process to illustrate the difference between traditional and declarative graphic syntax.&lt;/p&gt;\n\n&lt;p&gt;In the traditional approach, you&amp;#39;re providing a detailed recipe, telling the chef each step, for example:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Get a bowl.&lt;/li&gt;\n&lt;li&gt;Put lettuce in it.&lt;/li&gt;\n&lt;li&gt;Cut some cherry tomatoes and add them.&lt;/li&gt;\n&lt;li&gt;Add some cucumber slices.&lt;/li&gt;\n&lt;li&gt;Sprinkle some sesame seeds.&lt;/li&gt;\n&lt;li&gt;Finally, drizzle with your favorite dressing.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Even for a simple salad, you must specify each step in detail.&lt;/p&gt;\n\n&lt;p&gt;In contrast, declarative graphic syntax is more like telling the chef what kind of salad you want, rather than how to make it.&lt;/p&gt;\n\n&lt;p&gt;For instance, you might say, &amp;quot;I want a salad with lettuce, tomatoes, cucumber, and sesame seeds.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The chef knows how to handle each ingredient without requiring step-by-step instructions.&lt;/p&gt;\n\n&lt;p&gt;Similarly, when using Seaborn&amp;#39;s objects interface with its declarative syntax to create a visualization, we specify what we want (a histogram showing a variable&amp;#39;s distribution in a given dataset), not how to get there.&lt;/p&gt;\n\n&lt;p&gt;This approach makes the code more concise and easier to understand, enhancing programming flexibility and efficiency.&lt;/p&gt;\n\n&lt;h2&gt;Seaborn API: Then and Now&lt;/h2&gt;\n\n&lt;p&gt;Before diving into the objects interface API, let&amp;#39;s systematically look at the differences between the Seaborn API of earlier versions and the 0.12 version.&lt;/p&gt;\n\n&lt;h2&gt;The original API&lt;/h2&gt;\n\n&lt;p&gt;Many readers might have been intimidated by Matplotlib&amp;#39;s complex API documentation when learning Python data visualization.&lt;/p&gt;\n\n&lt;p&gt;Seaborn simplifies this by wrapping and streamlining Matplotlib&amp;#39;s API, making the learning curve gentler.&lt;/p&gt;\n\n&lt;p&gt;Seaborn doesn&amp;#39;t just offer high-level encapsulation of Matplotlib; it also categorizes all charts into relational, distributional, and categorical scenarios.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20\"&gt; Overview of Seaborn&amp;#39;s original API design. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You should comprehensively understand Seaborn&amp;#39;s API through this diagram and know when to use which chart.&lt;/p&gt;\n\n&lt;p&gt;For example, a histplot representing data distribution would fall under the distribution chart category.&lt;/p&gt;\n\n&lt;p&gt;In contrast, a violinplot representing data features by category would be classified as a categorical chart.&lt;/p&gt;\n\n&lt;p&gt;Aside from vertical categorization, Seaborn also performs horizontal categorization: Figure-level and axes-level.&lt;/p&gt;\n\n&lt;p&gt;According to the &lt;a href=\"https://seaborn.pydata.org/tutorial/function_overview.html?ref=dataleadsfuture.com#figure-level-vs-axes-level-functions\"&gt;official website&lt;/a&gt;, axes-level charts are drawn on matplotlib.pyplot.axes and can only draw one figure.&lt;/p&gt;\n\n&lt;p&gt;In contrast, Figure-level charts use Matplotlib&amp;#39;s FacetGrid to draw multiple charts in one figure, facilitating easy comparison of similar data dimensions.&lt;/p&gt;\n\n&lt;p&gt;However, even though Seaborn&amp;#39;s API significantly simplifies chart drawing through encapsulating Matplotlib, creating an individual-specific chart still requires complex configurations.&lt;/p&gt;\n\n&lt;p&gt;For example, if I use Seaborn&amp;#39;s built-in penguins dataset to draw a histplot, the code is as follows:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sns.histplot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, hue=&amp;quot;species&amp;quot;);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2\"&gt; The original way of drawing a histplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And when I use the same dataset to draw a kdeplot, the code is as follows:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sns.kdeplot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, fill=True, hue=&amp;quot;species&amp;quot;);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd\"&gt; The original way of drawing a kdeplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Except for the chart API, the rest of the configurations are identical.&lt;/p&gt;\n\n&lt;p&gt;This is like telling the chef I want to use lamb chops and onions to make a lamb soup and specifying the cooking steps. When I want to use these ingredients to make a roasted lamb chop, I have to tell the chef about the ingredients and the cooking steps all over again.&lt;/p&gt;\n\n&lt;p&gt;Not only is it inefficient, but it also needs more flexibility.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s why Seaborn introduced the objects interface API in its 0.12 version. This declarative graphic syntax dramatically improves the process of creating a chart.&lt;/p&gt;\n\n&lt;h2&gt;The objects Interface API&lt;/h2&gt;\n\n&lt;p&gt;Before we start with the objects interface API, let&amp;#39;s take a high-level look at it to better understand the drawing process.&lt;/p&gt;\n\n&lt;p&gt;Unlike the original Seaborn API, which organizes the drawing API by classification, the objects interface API collects the API by a drawing pipeline.&lt;/p&gt;\n\n&lt;p&gt;The objects interface API divides the drawing into multiple stages, such as data binding, layout, presentation, customization, etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e\"&gt; Overview of Seaborn&amp;#39;s objects interface API design. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The data binding and presentation stages are necessary, while other stages are optional.&lt;/p&gt;\n\n&lt;p&gt;Also, since the stages are independent, each stage can be reused. Following the previous example of the hist and kde plots:&lt;/p&gt;\n\n&lt;p&gt;To use the objects interface to draw, we first need to bind the data:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p = so.Plot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, color=&amp;quot;species&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;From this line of code, we can see that the objects interface uses the so.Plot class for data binding.&lt;/p&gt;\n\n&lt;p&gt;Also, compared to the original API that uses the incomprehensible hue parameter, it uses the color parameter to bind the species dimension directly to the chart color, making the configuration more intuitive.&lt;/p&gt;\n\n&lt;p&gt;Finally, this line of code returns a p instance that can be reused to draw a chart.&lt;/p&gt;\n\n&lt;p&gt;Next, let&amp;#39;s draw a histplot:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p.add(so.Bars(), so.Hist())\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a\"&gt; Use objects interface API to draw a histplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This line of code shows that the drawing stage does not need to rebind the data. We just need to tell the addmethod what to draw: so.Bars(), and how to calculate it: so.Hist().&lt;/p&gt;\n\n&lt;p&gt;The add method also returns a copy of the Plot instance, so any adjustments in the add method will not affect the original data binding. The p instance can still be reused.&lt;/p&gt;\n\n&lt;p&gt;Therefore, we continue to call the p.add() method to draw a kdeplot:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p.add(so.Area(), so.KDE())\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89\"&gt; Use objects interface API to draw a kdeplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Since KDE is a way of statistic, so.KDE() is called on the stat parameter here. And since the kdeplot itself is an area plot, so.Area() is used for drawing.&lt;/p&gt;\n\n&lt;p&gt;We reused the p instance bound to the data, so there is no need to tell the chef how to cook each dish, but to directly say what we want. Isn&amp;#39;t it much more concise and flexible?&lt;/p&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/seaborn-0-12-an-insightful-guide-to-the-objects-interface-and-declarative-graphics/\"&gt;Data Leads Future&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161t22b", "is_robot_indexable": true, "report_reasons": null, "author": "qtalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161t22b/seaborn_012_an_insightful_guide_to_the_objects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161t22b/seaborn_012_an_insightful_guide_to_the_objects/", "subreddit_subscribers": 1014933, "created_utc": 1693050410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I have an interview with US elections modeling company next week. I interviewed with them earlier this year and made it to their take-home test and they wanted me to model some US House elections. Any tips to better succeed this time would be great.\n\n\nAre there complex models for that? Do people usually use one-model-per-district or something different? Is there a \"go-to\" elections modeling curriculum that I've missed? Where are the best US-elections data sources (aside from MIT, Pew, and LoC and all the other easily googleable places)?\n\n(sorry if this flair is wrong, I didn't know which this really fell under)", "author_fullname": "t2_7bn1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Elections Fellow\" interview prep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161g44t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693009538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an interview with US elections modeling company next week. I interviewed with them earlier this year and made it to their take-home test and they wanted me to model some US House elections. Any tips to better succeed this time would be great.&lt;/p&gt;\n\n&lt;p&gt;Are there complex models for that? Do people usually use one-model-per-district or something different? Is there a &amp;quot;go-to&amp;quot; elections modeling curriculum that I&amp;#39;ve missed? Where are the best US-elections data sources (aside from MIT, Pew, and LoC and all the other easily googleable places)?&lt;/p&gt;\n\n&lt;p&gt;(sorry if this flair is wrong, I didn&amp;#39;t know which this really fell under)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161g44t", "is_robot_indexable": true, "report_reasons": null, "author": "ib33", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161g44t/elections_fellow_interview_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161g44t/elections_fellow_interview_prep/", "subreddit_subscribers": 1014933, "created_utc": 1693009538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm new the area and would appreciate some insight. With my background in applied mathematics/statistics, I've delved into some curriculum in computer science and noticed the intricate role that languages like C play in understanding hardware-level interactions. While I can see the distinction between this and the mathematical or algorithmic side of computation in data science, I'm evaluating the broader value of this knowledge:\n\n1. In today's industry, is there a predominant focus on hardware/software optimization or is there a tilt towards computational and mathematical optimization techniques? (I'm not completely sure if this dichotomy makes sense though)\n2. As I'm considering data science roles, would a deep understanding of software/hardware level of optimization serve me in the short term?\n3. Given rapid technological advancements, is the depth of knowledge in software/hardware efficiency becoming more specialized and typically the realm of software engineers, not data scientists?\n4. Looking beyond immediate career implications, would a profound understanding of the hardware/software domain serve me well in the long run, potentially if I advance into management roles?", "author_fullname": "t2_6gxwhbsk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is optimization at the hardware/software level a significant concern, or should the primary focus be on computational optimization from a mathematical perspective?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1619map", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692993913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new the area and would appreciate some insight. With my background in applied mathematics/statistics, I&amp;#39;ve delved into some curriculum in computer science and noticed the intricate role that languages like C play in understanding hardware-level interactions. While I can see the distinction between this and the mathematical or algorithmic side of computation in data science, I&amp;#39;m evaluating the broader value of this knowledge:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;In today&amp;#39;s industry, is there a predominant focus on hardware/software optimization or is there a tilt towards computational and mathematical optimization techniques? (I&amp;#39;m not completely sure if this dichotomy makes sense though)&lt;/li&gt;\n&lt;li&gt;As I&amp;#39;m considering data science roles, would a deep understanding of software/hardware level of optimization serve me in the short term?&lt;/li&gt;\n&lt;li&gt;Given rapid technological advancements, is the depth of knowledge in software/hardware efficiency becoming more specialized and typically the realm of software engineers, not data scientists?&lt;/li&gt;\n&lt;li&gt;Looking beyond immediate career implications, would a profound understanding of the hardware/software domain serve me well in the long run, potentially if I advance into management roles?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1619map", "is_robot_indexable": true, "report_reasons": null, "author": "RightProfile0", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1619map/is_optimization_at_the_hardwaresoftware_level_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1619map/is_optimization_at_the_hardwaresoftware_level_a/", "subreddit_subscribers": 1014933, "created_utc": 1692993913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently a data science apprentice so apologies if I come across as a bit na\u00efve in this area. This project is solo and pro-bono but I don't want to submit low-quality work. \n\n**Overall goal of the project: \"Should \\[X Type\\] courts be introduced?\"**\n\nI'm working with tennis data of length *140 records*, and have *3 free text column*s (there is a lot more categorical columns but I don't have any issue with this) that I need to process. The key thing I'm trying to get at is to *classify responses into coherent opinion*s such as \"I think the acrylic courts are bad\", or, \" I think the club is too cliquey\".\n\nI've read all the responses, since the data size isn't too big and most of the records were left incomplete: *average 60% completion for across the free text columns*. After reading each column I assigned binary, non mutually exclusive, one word tag columns to each response relevant to that column. See the screenshot for more info.\n\n&amp;#x200B;\n\n[Head of dataset. Highlighted are the data columns, unhighlighted are tags \\(data has been filtered to show only complete rows\\).](https://preview.redd.it/xuzh8cwrwakb1.png?width=1633&amp;format=png&amp;auto=webp&amp;s=8c049ed28fad878334fd6f5d6a72b27702ddd91a)\n\n**Sentiment analysis** worked very poorly, mainly because much of the responses talk about improvements. But an even number also spoke about their opinion on the current situation. \n\nI also tried using **LDA for topic modelling** but the clusters outputted very incoherent topics. I *removed stop words and lemmetized*, but the responses seemed to be very very mixed. There seemed to be no distinction.\n\nThinking about my situation and skillset, I'm happy to utilise the tags alongside an accurate sentiment score to assume that this area (tags) should be improved or if people are happy with it (the score -/+).\n\nI feel like I haven't got a strategy in place. Can anyone help me with suggestions on how to approach this, with ideas for pre-processing steps, models, or strategies? Reply if you need more information to work on.  \n\n\n&gt;***Here's some of the full-text data:***  \n&gt;  \n&gt;  \n**EX1, Looking at improvements:**   \n&gt;  \n&gt;\"Courts - if one of the clays floodlit courts can be reserved for members in the evening it will be good. As of now, the coaches book all the floodlit clay courts every week evening.  If floodlights can be installed on more courts like court 11/12 it would help with court choice.\"  \n&gt;  \n&gt;*Sentiment score: 0.6*  \n&gt;  \n&gt;  \n**EX2, Looking at opinions:**  \n&gt;  \n&gt; \"I am interested in \\[X Type court\\] but would not want to pay an extra subscription for it.\"   \n&gt;  \n&gt;*Sentiment score: 0.125*  \n&gt;  \n&gt;**EX3, Extended response:**   \n&gt;  \n&gt;\"Clay courts need taking some clay off. Nobody likes playing on them as so I'm sure they are the last to be booked as like playing on a beach. Booking court system should have an hour and half slots rather than being able to book anytime and we should install a screen that allows you to book in for your court as too many courts are booked at premium times yet are not used.\"   \n&gt;  \n&gt;*Sentiment score: 0.26*  \n&gt;  \n&gt;  \n&gt;  \n&gt;These extracts are different to the random sample I took to see if the sentiment scores lined up (they did not). There is a good mix of these responses throughout.\n\nThanks guys, just want to make a good impression for managing my own mini-project :)", "author_fullname": "t2_a2vo7fq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP tennis data task (I'm struggling a lot)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 15, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xuzh8cwrwakb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 11, "x": 108, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=87abf54389a494fd484796f04526cd34a580ecb9"}, {"y": 23, "x": 216, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f29d2acde23662c0a942ddef0360cb17dd2ae3e"}, {"y": 34, "x": 320, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd4f00d7556c0612da41eebe47ba2d3668654be2"}, {"y": 68, "x": 640, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=565cb90f729dad8221e64a3d1fab4fe2e0f5856d"}, {"y": 102, "x": 960, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8688b69acf957e3347b6badbe84f11de8107c5ba"}, {"y": 115, "x": 1080, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9ab191aa28cf9338b386e679fb0555241626fcc1"}], "s": {"y": 175, "x": 1633, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=1633&amp;format=png&amp;auto=webp&amp;s=8c049ed28fad878334fd6f5d6a72b27702ddd91a"}, "id": "xuzh8cwrwakb1"}}, "name": "t3_1617k82", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/c1Y4eYNam-sdlPpqOk16n1WmDzkqOAD_OFretgKQaJc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692989112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a data science apprentice so apologies if I come across as a bit na\u00efve in this area. This project is solo and pro-bono but I don&amp;#39;t want to submit low-quality work. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Overall goal of the project: &amp;quot;Should [X Type] courts be introduced?&amp;quot;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working with tennis data of length &lt;em&gt;140 records&lt;/em&gt;, and have &lt;em&gt;3 free text column&lt;/em&gt;s (there is a lot more categorical columns but I don&amp;#39;t have any issue with this) that I need to process. The key thing I&amp;#39;m trying to get at is to &lt;em&gt;classify responses into coherent opinion&lt;/em&gt;s such as &amp;quot;I think the acrylic courts are bad&amp;quot;, or, &amp;quot; I think the club is too cliquey&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read all the responses, since the data size isn&amp;#39;t too big and most of the records were left incomplete: &lt;em&gt;average 60% completion for across the free text columns&lt;/em&gt;. After reading each column I assigned binary, non mutually exclusive, one word tag columns to each response relevant to that column. See the screenshot for more info.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xuzh8cwrwakb1.png?width=1633&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c049ed28fad878334fd6f5d6a72b27702ddd91a\"&gt;Head of dataset. Highlighted are the data columns, unhighlighted are tags (data has been filtered to show only complete rows).&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Sentiment analysis&lt;/strong&gt; worked very poorly, mainly because much of the responses talk about improvements. But an even number also spoke about their opinion on the current situation. &lt;/p&gt;\n\n&lt;p&gt;I also tried using &lt;strong&gt;LDA for topic modelling&lt;/strong&gt; but the clusters outputted very incoherent topics. I &lt;em&gt;removed stop words and lemmetized&lt;/em&gt;, but the responses seemed to be very very mixed. There seemed to be no distinction.&lt;/p&gt;\n\n&lt;p&gt;Thinking about my situation and skillset, I&amp;#39;m happy to utilise the tags alongside an accurate sentiment score to assume that this area (tags) should be improved or if people are happy with it (the score -/+).&lt;/p&gt;\n\n&lt;p&gt;I feel like I haven&amp;#39;t got a strategy in place. Can anyone help me with suggestions on how to approach this, with ideas for pre-processing steps, models, or strategies? Reply if you need more information to work on.  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;Here&amp;#39;s some of the full-text data:&lt;/em&gt;&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EX1, Looking at improvements:&lt;/strong&gt;   &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Courts - if one of the clays floodlit courts can be reserved for members in the evening it will be good. As of now, the coaches book all the floodlit clay courts every week evening.  If floodlights can be installed on more courts like court 11/12 it would help with court choice.&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Sentiment score: 0.6&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EX2, Looking at opinions:&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;I am interested in [X Type court] but would not want to pay an extra subscription for it.&amp;quot;   &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Sentiment score: 0.125&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EX3, Extended response:&lt;/strong&gt;   &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Clay courts need taking some clay off. Nobody likes playing on them as so I&amp;#39;m sure they are the last to be booked as like playing on a beach. Booking court system should have an hour and half slots rather than being able to book anytime and we should install a screen that allows you to book in for your court as too many courts are booked at premium times yet are not used.&amp;quot;   &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Sentiment score: 0.26&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;These extracts are different to the random sample I took to see if the sentiment scores lined up (they did not). There is a good mix of these responses throughout.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Thanks guys, just want to make a good impression for managing my own mini-project :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1617k82", "is_robot_indexable": true, "report_reasons": null, "author": "Ilostmyshitinvegas", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1617k82/nlp_tennis_data_task_im_struggling_a_lot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1617k82/nlp_tennis_data_task_im_struggling_a_lot/", "subreddit_subscribers": 1014933, "created_utc": 1692989112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a software engineer and somewhat of a newbie to data science (outside of projects required by my CS degree) and trying to start some recreational side projects. I'm wondering if anyone can recommend where to get data sets for the following, 1) housing sales $ by month by zip code with SQ footage of each sale information 2) mortgage originations quantity, $ value, type by month 3) total outstanding mortgages by type and delinquency rates. Any recommendations would be super helpful!", "author_fullname": "t2_a0sz9be7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Housing datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16166wl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692985939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a software engineer and somewhat of a newbie to data science (outside of projects required by my CS degree) and trying to start some recreational side projects. I&amp;#39;m wondering if anyone can recommend where to get data sets for the following, 1) housing sales $ by month by zip code with SQ footage of each sale information 2) mortgage originations quantity, $ value, type by month 3) total outstanding mortgages by type and delinquency rates. Any recommendations would be super helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16166wl", "is_robot_indexable": true, "report_reasons": null, "author": "EnvironmentalFact908", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16166wl/housing_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16166wl/housing_datasets/", "subreddit_subscribers": 1014933, "created_utc": 1692985939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm an undergraduate junior at an elite university. My major is Russian area studies and global politics (though I may drop politics). I've decided to take on my university's data science minor. It does not offer a data sci major (we have comp sci, but that is it), and frankly, it's too late to add a completely new major.\n\nI realized a bit too late that my current majors are just not that employable. So, I began looking at getting an MSDS. I am currently well-behind on the prerequisites for most programs, but I intend to take couses to meet them (Calc 1 and 2, linear alg, intro to comp sci, database management, etc.). If I do this correctly, I will graduate with 20 credits in data science (not counting calc 1 and 2). \n\nWhat I'm worried about is the fact that my degree isn't a stem degree. I plan to make the argument that data science can couple with research/ security and intelligence efforts in Eastern Europe, but I'm not sure if I'd be very persuasive.\n\nMy question is: would I have a good shot at getting into a good/competitive masters program, and is it worth it? I've noticed the 50k price tags and I'm apprehensive of taking on that kind of debt. I've seen posts on here talking about getting an employer to pay for it, but I'm not sure I could get that kind of job given that data science is only my minor.\n\n&amp;#x200B;\n\nAll things considered, where do I stand, and should I even bother?\n\n&amp;#x200B;\n\nThank you for your responses.", "author_fullname": "t2_amrkpq6e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is getting a masters in data sci possible/ worth it for me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_161vo8m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693057559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an undergraduate junior at an elite university. My major is Russian area studies and global politics (though I may drop politics). I&amp;#39;ve decided to take on my university&amp;#39;s data science minor. It does not offer a data sci major (we have comp sci, but that is it), and frankly, it&amp;#39;s too late to add a completely new major.&lt;/p&gt;\n\n&lt;p&gt;I realized a bit too late that my current majors are just not that employable. So, I began looking at getting an MSDS. I am currently well-behind on the prerequisites for most programs, but I intend to take couses to meet them (Calc 1 and 2, linear alg, intro to comp sci, database management, etc.). If I do this correctly, I will graduate with 20 credits in data science (not counting calc 1 and 2). &lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m worried about is the fact that my degree isn&amp;#39;t a stem degree. I plan to make the argument that data science can couple with research/ security and intelligence efforts in Eastern Europe, but I&amp;#39;m not sure if I&amp;#39;d be very persuasive.&lt;/p&gt;\n\n&lt;p&gt;My question is: would I have a good shot at getting into a good/competitive masters program, and is it worth it? I&amp;#39;ve noticed the 50k price tags and I&amp;#39;m apprehensive of taking on that kind of debt. I&amp;#39;ve seen posts on here talking about getting an employer to pay for it, but I&amp;#39;m not sure I could get that kind of job given that data science is only my minor.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;All things considered, where do I stand, and should I even bother?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161vo8m", "is_robot_indexable": true, "report_reasons": null, "author": "Obligatorycomment7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161vo8m/is_getting_a_masters_in_data_sci_possible_worth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161vo8m/is_getting_a_masters_in_data_sci_possible_worth/", "subreddit_subscribers": 1014933, "created_utc": 1693057559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8qgfbbfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leveraging NLP and OCR for Business Card Text Extraction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_161pr5h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TV8-g9jeOmLtRQo0hT88aWztIzmFkW2Kt8PX-2eAT34.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693039638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "abhilashshukla.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://abhilashshukla.com/tech-and-programming/aiml/leveraging-nlp-and-ocr-for-business-card-text-extraction/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?auto=webp&amp;s=66605857e6f7f7824f7295e38884b5f72340df13", "width": 900, "height": 504}, "resolutions": [{"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c412490b3fb48e5346468653d3a3e0636a6aa11c", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2772bc548d15905ed61e5b064cb324b517b94d04", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa67670eed710a938ebe57e2506d671015405415", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=98881f8b29af5643cd31b5b91786802b3e5f0431", "width": 640, "height": 358}], "variants": {}, "id": "6cwV5FRTGCO6L0K5DlRn4hGjOM7jz29PeZA1eQyuoLI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "161pr5h", "is_robot_indexable": true, "report_reasons": null, "author": "Anxious_City_7864", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161pr5h/leveraging_nlp_and_ocr_for_business_card_text/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://abhilashshukla.com/tech-and-programming/aiml/leveraging-nlp-and-ocr-for-business-card-text-extraction/", "subreddit_subscribers": 1014933, "created_utc": 1693039638.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset that contains the sale quantity of an item over a year. I am building an ML-based (XGBOOST) model since I plan to include exogenous variables that can influence the demand for the item.\n\nSince I would essentially eliminate the 'date'  column, inferring only features like seasons. \n\nWhen it comes to model evaluation, can I randomly split train and test or do I have to keep the time splits in consideration like we do in ARIMA modeling for example?", "author_fullname": "t2_ba4jkgnm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model evaluation for Sales Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161ibkb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693015661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset that contains the sale quantity of an item over a year. I am building an ML-based (XGBOOST) model since I plan to include exogenous variables that can influence the demand for the item.&lt;/p&gt;\n\n&lt;p&gt;Since I would essentially eliminate the &amp;#39;date&amp;#39;  column, inferring only features like seasons. &lt;/p&gt;\n\n&lt;p&gt;When it comes to model evaluation, can I randomly split train and test or do I have to keep the time splits in consideration like we do in ARIMA modeling for example?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161ibkb", "is_robot_indexable": true, "report_reasons": null, "author": "Excellent-Tennis-323", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161ibkb/model_evaluation_for_sales_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161ibkb/model_evaluation_for_sales_data/", "subreddit_subscribers": 1014933, "created_utc": 1693015661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_536lg1nv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing txtai, the all-in-one embeddings database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_161ss7n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/etA6LPfWqJnA-DrSxfaVZogoaqMFSVqX5N_UXyZv5JY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693049577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/neuml/introducing-txtai-the-all-in-one-embeddings-database-c721f4ff91ad", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?auto=webp&amp;s=4b3dac78f9218e4d4a4a8874102bd2ad557e8836", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=600ad92c3292c75a41436d1c9e63401155475364", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=655efba81489cc46c74b0d5818a3205a29fcb22f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e3c2e39fd3a52e5b930c0b36b08be7acc307d93", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eef93bcd3c8853798d51e4532ecf15612eca7e7e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d2dbc013a96cd9270a7cdf283cfb8c29aa329d3c", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=55b4f681f8c90538b1a9074dd1f3c95746d63320", "width": 1080, "height": 540}], "variants": {}, "id": "gykebrM_vvT-4IzABmlieYDKYYmcS71kdJ2ORLpqxn8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "161ss7n", "is_robot_indexable": true, "report_reasons": null, "author": "davidmezzetti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161ss7n/introducing_txtai_the_allinone_embeddings_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/neuml/introducing-txtai-the-all-in-one-embeddings-database-c721f4ff91ad", "subreddit_subscribers": 1014933, "created_utc": 1693049577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9v2ffwqay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitter Community / Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161rqa5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1693046299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/i/communities/1695363277289562618", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161rqa5", "is_robot_indexable": true, "report_reasons": null, "author": "x9182", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161rqa5/twitter_community_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/i/communities/1695363277289562618", "subreddit_subscribers": 1014933, "created_utc": 1693046299.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}