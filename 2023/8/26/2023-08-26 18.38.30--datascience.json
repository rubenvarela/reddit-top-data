{"kind": "Listing", "data": {"after": "t3_161zaol", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I guess I\u2019m trying to determine if my current job is just actually boring and dull or if this is a wider issue in data science. I\u2019m doing a total life overhaul and just need to figure out my occupation. \n\nI work for an insurance company. Been there a year now. I basically stumbled into the position. I wrapped up a previous masters degree and applied to a program on a whim. The program paid for a masters degree and gave me a paid work placement. For some reason I was accepted despite having no math background. I just finished the degree portion and I was offered a contract with the company I did the placement with. \n\nBasically I find the work pretty boring. It\u2019s hybrid work and a lot of the time I goof off at home and just put in the actual hours when I\u2019m in the office. I basically say to myself over and over that I don\u2019t know why I would bust my ass to make my CEO more money. A lot of the work I find to be a huge waste of time. I was previously in the military so I really understand bullshit projects and time wasting but it feels different on the civilian side I guess. \n\nI really don\u2019t know if the data science world is for me. Do you find the work rewarding in other fields? Basically I really do find data science interesting and I know I have a LOT more to learn but most of the jobs seem to be in banking, finance etc. I basically am just working to make some other dude more money and that just bugs me. I can see myself applying these skills helping people but I guess I just don\u2019t know how or where.", "author_fullname": "t2_9c3vih4ps", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meaningful work -my company or all of data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161qjdh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693042283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I guess I\u2019m trying to determine if my current job is just actually boring and dull or if this is a wider issue in data science. I\u2019m doing a total life overhaul and just need to figure out my occupation. &lt;/p&gt;\n\n&lt;p&gt;I work for an insurance company. Been there a year now. I basically stumbled into the position. I wrapped up a previous masters degree and applied to a program on a whim. The program paid for a masters degree and gave me a paid work placement. For some reason I was accepted despite having no math background. I just finished the degree portion and I was offered a contract with the company I did the placement with. &lt;/p&gt;\n\n&lt;p&gt;Basically I find the work pretty boring. It\u2019s hybrid work and a lot of the time I goof off at home and just put in the actual hours when I\u2019m in the office. I basically say to myself over and over that I don\u2019t know why I would bust my ass to make my CEO more money. A lot of the work I find to be a huge waste of time. I was previously in the military so I really understand bullshit projects and time wasting but it feels different on the civilian side I guess. &lt;/p&gt;\n\n&lt;p&gt;I really don\u2019t know if the data science world is for me. Do you find the work rewarding in other fields? Basically I really do find data science interesting and I know I have a LOT more to learn but most of the jobs seem to be in banking, finance etc. I basically am just working to make some other dude more money and that just bugs me. I can see myself applying these skills helping people but I guess I just don\u2019t know how or where.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161qjdh", "is_robot_indexable": true, "report_reasons": null, "author": "Significant_Baby9379", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161qjdh/meaningful_work_my_company_or_all_of_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161qjdh/meaningful_work_my_company_or_all_of_data_science/", "subreddit_subscribers": 1015309, "created_utc": 1693042283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_6wdbzop4d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to begin with recognizing entities and effects from text? Any libraries/concepts to research to get started?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1618e8m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/isbP2asQ9tjX9suaNLgKqC-G-EeCfx5TzzUBDThMUxQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692991032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/fbnv2nyh3bkb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?auto=webp&amp;s=cc91617bb9707cb6c1d1e1f1bfcaef04056ff2f8", "width": 1512, "height": 2016}, "resolutions": [{"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ef8b2be23b9fa29e84913a9098edfa304610ec73", "width": 108, "height": 144}, {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=466283bae15e62a9a73c5aed6619b4c96b62ef13", "width": 216, "height": 288}, {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3dd11bfd517fa42c37ab84d04cf76a21dc5477f9", "width": 320, "height": 426}, {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9ee653bf8acbd64613cc1dea9b5bc67df32bdfcd", "width": 640, "height": 853}, {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=661a864b68a64397defb4843144a37309c9fe450", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/fbnv2nyh3bkb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a5996fda2d9e0d6f8f31aeba51cfe8d29040e6d", "width": 1080, "height": 1440}], "variants": {}, "id": "JTxUqY3IA4YbWiOQkwLOwqykCeyakXvqHWzzXjXMq2c"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1618e8m", "is_robot_indexable": true, "report_reasons": null, "author": "AcrobaticDependent35", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1618e8m/where_to_begin_with_recognizing_entities_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/fbnv2nyh3bkb1.jpg", "subreddit_subscribers": 1015309, "created_utc": 1692991032.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently learning some advanced statistical analysis, and I used the Meuse data set in R to run a Moran\u2019s I test and got a Moran\u2019s I scatter plot for the neighborhood for each sample (spatially lagged) against the residuals of the linear model. Could anyone point me in the right direction on how to interpret spatial patterns in this scatter plot? Is there any good videos or articles that would be useful in learning about this subject? Thanks for any help!", "author_fullname": "t2_d4wdpnqz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pointers on a R project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "name": "t3_161k2fw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MrpmXF9VKoJ_YDesF7NWtoa9MUfmKvVcSSAkAW1OYeA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693020921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently learning some advanced statistical analysis, and I used the Meuse data set in R to run a Moran\u2019s I test and got a Moran\u2019s I scatter plot for the neighborhood for each sample (spatially lagged) against the residuals of the linear model. Could anyone point me in the right direction on how to interpret spatial patterns in this scatter plot? Is there any good videos or articles that would be useful in learning about this subject? Thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/vtqtfs8fkdkb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?auto=webp&amp;s=d9eab981192d49e057f1845f15eee3f1e56c573f", "width": 700, "height": 432}, "resolutions": [{"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc4e93105ff9f0acb730694de0a99713358f6289", "width": 108, "height": 66}, {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b09ce878add4149708ad4d2243a0e154f2fe621a", "width": 216, "height": 133}, {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=512ac91374c8822b0ef5760fb4357a521f5a8cf6", "width": 320, "height": 197}, {"url": "https://preview.redd.it/vtqtfs8fkdkb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=de625c3d371cb01715e0e8b9b4a1957353d02949", "width": 640, "height": 394}], "variants": {}, "id": "WSv5LRcHscdscamQpruEKD_YxIi5t6K2gM_C8UISmZk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "161k2fw", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Jar-7618", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161k2fw/pointers_on_a_r_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/vtqtfs8fkdkb1.jpg", "subreddit_subscribers": 1015309, "created_utc": 1693020921.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a second year college student working on personal projects for my portfolio. I've mainly been working on projects that I'm genuinly interested in, and I try to build it end to end by collecting the data on my own somehow, doing an analysis, and having some streamlit app as a final product that users can use. However, I feel that my projects are either useless or only useful to a very specific groups of users, and even then I don't really have any quantifiable impact to talk about. For example, one project I'm working on is a song recommendation app specfically for people who listen to Drake. I collected the data using the Spotify Web API, built the streamlit app, and am currently testing the recommendation system. I even wrote an analysis on the different methods I tried, the advantages and disadvantages of each approach. Despite all this, I'm afraid having some sort of quantifiable impact is what recruiters will care about the most, and practically, if a person wanted to get more recommendations for Drake songs, they could use the built in recommendation feature in Spotify itself.\n\nHow can I make measurable impact in my projects?", "author_fullname": "t2_ghlio82to", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Impactful Personal Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161jeko", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693018907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a second year college student working on personal projects for my portfolio. I&amp;#39;ve mainly been working on projects that I&amp;#39;m genuinly interested in, and I try to build it end to end by collecting the data on my own somehow, doing an analysis, and having some streamlit app as a final product that users can use. However, I feel that my projects are either useless or only useful to a very specific groups of users, and even then I don&amp;#39;t really have any quantifiable impact to talk about. For example, one project I&amp;#39;m working on is a song recommendation app specfically for people who listen to Drake. I collected the data using the Spotify Web API, built the streamlit app, and am currently testing the recommendation system. I even wrote an analysis on the different methods I tried, the advantages and disadvantages of each approach. Despite all this, I&amp;#39;m afraid having some sort of quantifiable impact is what recruiters will care about the most, and practically, if a person wanted to get more recommendations for Drake songs, they could use the built in recommendation feature in Spotify itself.&lt;/p&gt;\n\n&lt;p&gt;How can I make measurable impact in my projects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161jeko", "is_robot_indexable": true, "report_reasons": null, "author": "Technical-Note-4660", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161jeko/impactful_personal_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161jeko/impactful_personal_projects/", "subreddit_subscribers": 1015309, "created_utc": 1693018907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**tldr;** [**https://docs.litellm.ai/docs/tutorials/first\\_playground**](https://docs.litellm.ai/docs/tutorials/first_playground)\n\nCreate a playground to **evaluate multiple LLM Providers in less than 10 minutes**. If you want to see this in prod, check out our [website](https://litellm.ai/).\n\n**What will it look like?**\n\nhttps://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d\n\n**How will we do this?**: We'll build the server and connect it to our template frontend, ending up with a working playground UI by the end!\n\n&amp;#x200B;\n\n**Tutorial** \ud83d\udc49 [https://docs.litellm.ai/docs/tutorials/first\\_playground](https://docs.litellm.ai/docs/tutorials/first_playground)", "author_fullname": "t2_b5qc2w9r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Tutorial] Build LLM Playground in &lt;10mins", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"m19mofvsbekb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=eec12bed09d7ae290400662196619502eb5c8397"}, {"y": 163, "x": 216, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6aa47951e0a403ccd849229e935c87b96f05ed79"}, {"y": 242, "x": 320, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=df6daf576c61b23fd4267d4a3ebbddc400b25542"}, {"y": 484, "x": 640, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca4f7ec1f13ef74c459568197662dce6c072a2eb"}, {"y": 726, "x": 960, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e260013b6ca81c5a0bff76da0cd9d470d3397885"}, {"y": 816, "x": 1080, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a1ef952d5a4a9a53c1c6be6dc0ea82e86b528e75"}], "s": {"y": 1452, "x": 1920, "u": "https://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d"}, "id": "m19mofvsbekb1"}}, "name": "t3_161my8z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ZZqMtD4gilPJG_DWGT2RFN7h1quHgIAmgxPbf-P8dZ4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693030147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;tldr;&lt;/strong&gt; &lt;a href=\"https://docs.litellm.ai/docs/tutorials/first_playground\"&gt;&lt;strong&gt;https://docs.litellm.ai/docs/tutorials/first_playground&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Create a playground to &lt;strong&gt;evaluate multiple LLM Providers in less than 10 minutes&lt;/strong&gt;. If you want to see this in prod, check out our &lt;a href=\"https://litellm.ai/\"&gt;website&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What will it look like?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d\"&gt;https://preview.redd.it/m19mofvsbekb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ede7bb8b84015dc5a5b94fb44e3436a4784ba8d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How will we do this?&lt;/strong&gt;: We&amp;#39;ll build the server and connect it to our template frontend, ending up with a working playground UI by the end!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Tutorial&lt;/strong&gt; \ud83d\udc49 &lt;a href=\"https://docs.litellm.ai/docs/tutorials/first_playground\"&gt;https://docs.litellm.ai/docs/tutorials/first_playground&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?auto=webp&amp;s=c7fa4ca49008ee42e1f80bdf64cdb34a2cd65e7c", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=429dd0ee32af0c12f455ba221e5dcf32f5a430d2", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=80f67c195a09c7a47964a4488da90693ffc44101", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=44731b7b0dc428508fbe5aea506d0b474aedb710", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=42d48ca69203bf1aff1c033411c3de90f7d0bfda", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e64c66a43484edc3a7297072c13af48e5c26267c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/2iWfwRRHi1CDsy88ecfGrUsbJxnMUG8zwlaCCh5V9kY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f47098abf53a276cd5982ff79dbad3a040d69ab9", "width": 1080, "height": 607}], "variants": {}, "id": "H6fYCL0IdaUUhXSvGrJA54iiawydndRntwWO9LlIKYQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "161my8z", "is_robot_indexable": true, "report_reasons": null, "author": "VideoTo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161my8z/tutorial_build_llm_playground_in_10mins/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161my8z/tutorial_build_llm_playground_in_10mins/", "subreddit_subscribers": 1015309, "created_utc": 1693030147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is being a data scientist intellectual stimulating? Currently I work as a BI developer, and the work is super easy, I barely break a sweat doing it. To give an example, first month on the job I was able to automate a process they were doing manually every month for 3 years, by just writing few lines of code.\n\nI yearn for an intellectual challenge, is data science interesting and intellectually stimulating?", "author_fullname": "t2_fjoqin6sg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intellectual stimulation as a data scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161e3wp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693004434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is being a data scientist intellectual stimulating? Currently I work as a BI developer, and the work is super easy, I barely break a sweat doing it. To give an example, first month on the job I was able to automate a process they were doing manually every month for 3 years, by just writing few lines of code.&lt;/p&gt;\n\n&lt;p&gt;I yearn for an intellectual challenge, is data science interesting and intellectually stimulating?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161e3wp", "is_robot_indexable": true, "report_reasons": null, "author": "WhyUPoor", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161e3wp/intellectual_stimulation_as_a_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161e3wp/intellectual_stimulation_as_a_data_scientist/", "subreddit_subscribers": 1015309, "created_utc": 1693004434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, here's my situation.\n\nI'm finishing up a data scientist/analyst internship for a tech startup and have had a good experience. I've learned a lot, grown professionally, and have received glowing performance reviews from my managers and leadership team. I also mostly enjoy the work and people I work for.\n\nAs the summer is ending, my manager has really pushed for me to work part-time during my final grad school semester (graduating this December) since the team really needs the extra help. They're offering good compensation, but would need me for 20+ hours/week and have not committed to offering me a full time role once I graduate. \n\nWorking 20+ hours while finishing up my intensive masters program will be difficult, since that requires \\~50 hours/week on its own. I'm willing to do this if I get a written commitment of a job once I graduate, but am far less inclined without this commitment. To me, the worst case scenario is committing to working for this company part time, not having much time to socialize/network/recruit due to my crammed schedule, and getting denied a full-time position at the end. \n\nI want to look after my own interests, so I've made it very clear that I will only accept this part-time contract if I get a written full-time offer once I graduate. This way, I have some semblance of job security; if not, I'll have extra time during the fall to recruit and find other opportunities as I won't be working for this company part time. I\u2019m going to find out their decision on Tuesday.\n\nHowever, I feel like I'm letting my manager down, since she's always advocated for me and has put in a lot of time helping and vouching for me. In addition, my team is already very busy, so me leaving would add additional work. My manager also seemed very caught off guard by this when I let her know my position/terms. At the end of the day, company loyalty and lip service only goes so far; I need to look after myself. But, don't want to burn any bridges and want to use people I've worked with as references. \n\nWhat do you guys think of my strategy and actions? Am I being too unrealistic or unreasonable in my expectations? \n\nThank you.", "author_fullname": "t2_drtjr7rg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advice Needed. Am I Burning Bridges?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161a9d0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692995845.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692995389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, here&amp;#39;s my situation.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m finishing up a data scientist/analyst internship for a tech startup and have had a good experience. I&amp;#39;ve learned a lot, grown professionally, and have received glowing performance reviews from my managers and leadership team. I also mostly enjoy the work and people I work for.&lt;/p&gt;\n\n&lt;p&gt;As the summer is ending, my manager has really pushed for me to work part-time during my final grad school semester (graduating this December) since the team really needs the extra help. They&amp;#39;re offering good compensation, but would need me for 20+ hours/week and have not committed to offering me a full time role once I graduate. &lt;/p&gt;\n\n&lt;p&gt;Working 20+ hours while finishing up my intensive masters program will be difficult, since that requires ~50 hours/week on its own. I&amp;#39;m willing to do this if I get a written commitment of a job once I graduate, but am far less inclined without this commitment. To me, the worst case scenario is committing to working for this company part time, not having much time to socialize/network/recruit due to my crammed schedule, and getting denied a full-time position at the end. &lt;/p&gt;\n\n&lt;p&gt;I want to look after my own interests, so I&amp;#39;ve made it very clear that I will only accept this part-time contract if I get a written full-time offer once I graduate. This way, I have some semblance of job security; if not, I&amp;#39;ll have extra time during the fall to recruit and find other opportunities as I won&amp;#39;t be working for this company part time. I\u2019m going to find out their decision on Tuesday.&lt;/p&gt;\n\n&lt;p&gt;However, I feel like I&amp;#39;m letting my manager down, since she&amp;#39;s always advocated for me and has put in a lot of time helping and vouching for me. In addition, my team is already very busy, so me leaving would add additional work. My manager also seemed very caught off guard by this when I let her know my position/terms. At the end of the day, company loyalty and lip service only goes so far; I need to look after myself. But, don&amp;#39;t want to burn any bridges and want to use people I&amp;#39;ve worked with as references. &lt;/p&gt;\n\n&lt;p&gt;What do you guys think of my strategy and actions? Am I being too unrealistic or unreasonable in my expectations? &lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161a9d0", "is_robot_indexable": true, "report_reasons": null, "author": "OK__B0omer", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161a9d0/career_advice_needed_am_i_burning_bridges/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161a9d0/career_advice_needed_am_i_burning_bridges/", "subreddit_subscribers": 1015309, "created_utc": 1692995389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I need a Data Science Project idea for my final year Project idea. I don't find any unique idea can you please suggest an idea or where  I get guidance  ", "author_fullname": "t2_uewgxld9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Project idea?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1620myq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693069598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I need a Data Science Project idea for my final year Project idea. I don&amp;#39;t find any unique idea can you please suggest an idea or where  I get guidance  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1620myq", "is_robot_indexable": true, "report_reasons": null, "author": "atharva_nimbalkar", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1620myq/data_science_project_idea/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1620myq/data_science_project_idea/", "subreddit_subscribers": 1015309, "created_utc": 1693069598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,  \nI'm recentrly working on a project about \"Functional Data Analysis\"  in the part of time series especially forecasting i found out that there's no package that deals with functional observations, the usual ARIMA models apply to univariate data only. \n\nAny ideas to help please ?", "author_fullname": "t2_7y59qi3hn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "FAR and FARIMA model in python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161x071", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693060867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;br/&gt;\nI&amp;#39;m recentrly working on a project about &amp;quot;Functional Data Analysis&amp;quot;  in the part of time series especially forecasting i found out that there&amp;#39;s no package that deals with functional observations, the usual ARIMA models apply to univariate data only. &lt;/p&gt;\n\n&lt;p&gt;Any ideas to help please ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161x071", "is_robot_indexable": true, "report_reasons": null, "author": "Worth_Truth_8010", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161x071/far_and_farima_model_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161x071/far_and_farima_model_in_python/", "subreddit_subscribers": 1015309, "created_utc": 1693060867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Streamlining your data visualization journey with Python's popular library\n\n[ Photo Credit: Created by Author, Canva  ](https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1)\n\nThis article aims to introduce the objects interface feature in [Seaborn 0.12](https://seaborn.pydata.org/whatsnew/index.html?ref=dataleadsfuture.com#v0-12), including the concept of declarative graphic syntax, and a practical visualization project to showcase the usage of the objects interface.\n\nBy the end of this article, you'll have a clear understanding of the advantages and limitations of [Seaborn's objects interface API](https://seaborn.pydata.org/tutorial/objects_interface.html?ref=dataleadsfuture.com). And you will be able to use Seaborn for data analysis projects more easily.\n\n## Introduction\n\nRemember that joke about a programmer?\n\nHe was heading to the grocery store, and his wife told him, \"Buy a bottle of milk, and if they have eggs, buy 12.\"\n\nSo, he came home with 12 bottles of milk because they had eggs.\n\nThis is the problem with imperative programming\u2014it executes your instructions to the letter, without understanding your intent.\n\nNow, imagine you're creating a data visualization chart using Python.\n\nYou have to instruct the computer every step of the way: select a dataset, create a figure, set the color, add labels, adjust the size, etc...\n\nThen you realize your code is getting longer and more complex, and all you wanted was to quickly visualize your data.\n\nIt's like going to the grocery store and having to specify every item's location, color, size, and shape, instead of just telling the shop assistant what you need.\n\nNot only is this time-consuming, but it can also feel tiring.\n\nHowever, Seaborn 0.12's new feature\u2014the objects interface\u2014and its use of declarative graphic syntax is like having a shop assistant who understands you. You just need to tell it what you need to do, and it will find everything for you.\n\nYou no longer need to instruct it every step of the way. You just need to tell it what kind of result you want.\n\nIn this article, I'll guide you through using the objects interface, this new feature that makes your data visualization process more effortless, flexible, and enjoyable. Let's get started!\n\n## Why Declarative Graphic Syntax?\n\nLet's consider the salad-making process to illustrate the difference between traditional and declarative graphic syntax.\n\nIn the traditional approach, you're providing a detailed recipe, telling the chef each step, for example:\n\n1. Get a bowl.\n2. Put lettuce in it.\n3. Cut some cherry tomatoes and add them.\n4. Add some cucumber slices.\n5. Sprinkle some sesame seeds.\n6. Finally, drizzle with your favorite dressing.\n\nEven for a simple salad, you must specify each step in detail.\n\nIn contrast, declarative graphic syntax is more like telling the chef what kind of salad you want, rather than how to make it.\n\nFor instance, you might say, \"I want a salad with lettuce, tomatoes, cucumber, and sesame seeds.\"\n\nThe chef knows how to handle each ingredient without requiring step-by-step instructions.\n\nSimilarly, when using Seaborn's objects interface with its declarative syntax to create a visualization, we specify what we want (a histogram showing a variable's distribution in a given dataset), not how to get there.\n\nThis approach makes the code more concise and easier to understand, enhancing programming flexibility and efficiency.\n\n## Seaborn API: Then and Now\n\nBefore diving into the objects interface API, let's systematically look at the differences between the Seaborn API of earlier versions and the 0.12 version.\n\n## The original API\n\nMany readers might have been intimidated by Matplotlib's complex API documentation when learning Python data visualization.\n\nSeaborn simplifies this by wrapping and streamlining Matplotlib's API, making the learning curve gentler.\n\nSeaborn doesn't just offer high-level encapsulation of Matplotlib; it also categorizes all charts into relational, distributional, and categorical scenarios.\n\n[ Overview of Seaborn's original API design. Image by Author ](https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;format=png&amp;auto=webp&amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20)\n\nYou should comprehensively understand Seaborn's API through this diagram and know when to use which chart.\n\nFor example, a histplot representing data distribution would fall under the distribution chart category.\n\nIn contrast, a violinplot representing data features by category would be classified as a categorical chart.\n\nAside from vertical categorization, Seaborn also performs horizontal categorization: Figure-level and axes-level.\n\nAccording to the [official website](https://seaborn.pydata.org/tutorial/function_overview.html?ref=dataleadsfuture.com#figure-level-vs-axes-level-functions), axes-level charts are drawn on matplotlib.pyplot.axes and can only draw one figure.\n\nIn contrast, Figure-level charts use Matplotlib's FacetGrid to draw multiple charts in one figure, facilitating easy comparison of similar data dimensions.\n\nHowever, even though Seaborn's API significantly simplifies chart drawing through encapsulating Matplotlib, creating an individual-specific chart still requires complex configurations.\n\nFor example, if I use Seaborn's built-in penguins dataset to draw a histplot, the code is as follows:\n\n    sns.histplot(penguins, x=\"flipper_length_mm\", hue=\"species\");\n\n[ The original way of drawing a histplot. Image by Author ](https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;format=png&amp;auto=webp&amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2)\n\nAnd when I use the same dataset to draw a kdeplot, the code is as follows:\n\n    sns.kdeplot(penguins, x=\"flipper_length_mm\", fill=True, hue=\"species\");\n\n[ The original way of drawing a kdeplot. Image by Author ](https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;format=png&amp;auto=webp&amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd)\n\nExcept for the chart API, the rest of the configurations are identical.\n\nThis is like telling the chef I want to use lamb chops and onions to make a lamb soup and specifying the cooking steps. When I want to use these ingredients to make a roasted lamb chop, I have to tell the chef about the ingredients and the cooking steps all over again.\n\nNot only is it inefficient, but it also needs more flexibility.\n\nThat's why Seaborn introduced the objects interface API in its 0.12 version. This declarative graphic syntax dramatically improves the process of creating a chart.\n\n## The objects Interface API\n\nBefore we start with the objects interface API, let's take a high-level look at it to better understand the drawing process.\n\nUnlike the original Seaborn API, which organizes the drawing API by classification, the objects interface API collects the API by a drawing pipeline.\n\nThe objects interface API divides the drawing into multiple stages, such as data binding, layout, presentation, customization, etc.\n\n[ Overview of Seaborn's objects interface API design. Image by Author ](https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;format=png&amp;auto=webp&amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e)\n\nThe data binding and presentation stages are necessary, while other stages are optional.\n\nAlso, since the stages are independent, each stage can be reused. Following the previous example of the hist and kde plots:\n\nTo use the objects interface to draw, we first need to bind the data:\n\n    p = so.Plot(penguins, x=\"flipper_length_mm\", color=\"species\")\n\nFrom this line of code, we can see that the objects interface uses the so.Plot class for data binding.\n\nAlso, compared to the original API that uses the incomprehensible hue parameter, it uses the color parameter to bind the species dimension directly to the chart color, making the configuration more intuitive.\n\nFinally, this line of code returns a p instance that can be reused to draw a chart.\n\nNext, let's draw a histplot:\n\n    p.add(so.Bars(), so.Hist())\n\n[ Use objects interface API to draw a histplot. Image by Author ](https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a)\n\nThis line of code shows that the drawing stage does not need to rebind the data. We just need to tell the addmethod what to draw: so.Bars(), and how to calculate it: so.Hist().\n\nThe add method also returns a copy of the Plot instance, so any adjustments in the add method will not affect the original data binding. The p instance can still be reused.\n\nTherefore, we continue to call the p.add() method to draw a kdeplot:\n\n    p.add(so.Area(), so.KDE())\n\n[ Use objects interface API to draw a kdeplot. Image by Author ](https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89)\n\nSince KDE is a way of statistic, so.KDE() is called on the stat parameter here. And since the kdeplot itself is an area plot, so.Area() is used for drawing.\n\nWe reused the p instance bound to the data, so there is no need to tell the chef how to cook each dish, but to directly say what we want. Isn't it much more concise and flexible?\n\nThis article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/seaborn-0-12-an-insightful-guide-to-the-objects-interface-and-declarative-graphics/).", "author_fullname": "t2_9r8ft2a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seaborn 0.12: An Insightful Guide to the Objects Interface and Declarative Graphics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"jdkazetmzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8a1c79aaa8209286897009af6b8fe6d6023a94ba"}, {"y": 68, "x": 216, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=036f43099ad78132ba3bbbdbd2eab2d3d571e650"}, {"y": 102, "x": 320, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b400a489bf1caa71e186b76d8abab5d22a22822d"}, {"y": 204, "x": 640, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=63255828bab9bdd13bc317a9d9882676388af0a8"}], "s": {"y": 287, "x": 899, "u": "https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;format=png&amp;auto=webp&amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e"}, "id": "jdkazetmzfkb1"}, "7mc9f945zfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=70ba39e64584a7a4f8a9d7fe01787e7f41ff214e"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3681ced759d7b2cac2379d8aa0f3ba859ea227c"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=49edb457688deff44b86bc4064427b2005382aec"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e1e2115ab9aab2c42217dda0f4b65aeefc18fdec"}, {"y": 639, "x": 960, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5883a021a3863c01d5bf06352e3f39c244601492"}, {"y": 719, "x": 1080, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fa2d349e5289a02100631eff932dc09d7b03af8e"}], "s": {"y": 959, "x": 1440, "u": "https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1"}, "id": "7mc9f945zfkb1"}, "ufs151akzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=47aa5cc59119e12d70dd8082aa77b3f9b613649b"}, {"y": 160, "x": 216, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b329c29a2969bb8d4ea74e6c234cf56a8071f424"}, {"y": 237, "x": 320, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1d742ff677c4e9eb3d364e3ac69c533d136d9a8"}], "s": {"y": 437, "x": 588, "u": "https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;format=png&amp;auto=webp&amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd"}, "id": "ufs151akzfkb1"}, "z3ubpaufzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 83, "x": 108, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fd655c9ef8b03e51256976cc2115c4eaad57c6e3"}, {"y": 166, "x": 216, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1ab3edfaa3283b1117d0ae3d10bfbc68ac64c22"}, {"y": 247, "x": 320, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3ac3fee91bdca1fbf6a919ca817995501b781774"}], "s": {"y": 437, "x": 566, "u": "https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;format=png&amp;auto=webp&amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2"}, "id": "z3ubpaufzfkb1"}, "otseb0utzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ff67695c30da82344330de221f8b6d1c02e416c"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8b4135abb4f0fb34b799b303b0c991fe62ae21d1"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e3ab322b3be6edd12b92c27484ffea35336e1d32"}, {"y": 392, "x": 640, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2b62c3ad6ca6bd36db936b0f571848cff05e5849"}, {"y": 588, "x": 960, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6527a4224acd02a5e11a5850d49b400c5bc4860"}, {"y": 661, "x": 1080, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=981a36ab971d06f701cdb8dff853676a3afa6c92"}], "s": {"y": 890, "x": 1453, "u": "https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a"}, "id": "otseb0utzfkb1"}, "tjaegaiyzfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=402545adec6758cd1ecedb0cd6e9e2c2d95d1901"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=66959f2ca43e2b3faaa511d12e028fc17887fb8b"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d55b3c4ca08d4d16c2ff93a41d1b004f1a214cd5"}, {"y": 392, "x": 640, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0d2e477c3139ade726d2666842e0e569ecf2272"}, {"y": 588, "x": 960, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=edfc63ad503512d6b81c7a99c80c592684a1bbce"}, {"y": 661, "x": 1080, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=224e924131ef5654821ea8191d11ac42c494b64c"}], "s": {"y": 890, "x": 1453, "u": "https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;format=png&amp;auto=webp&amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89"}, "id": "tjaegaiyzfkb1"}, "ajcy9e99zfkb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 70, "x": 108, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3bdd77020d14a0736156a9f930124b73c1f1bf4a"}, {"y": 141, "x": 216, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fdb95df8bcebb767c507c6e0e36ac459b510fb45"}, {"y": 210, "x": 320, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5094fd4de54cee0e2b6b58aa1de353e59865a1b6"}, {"y": 420, "x": 640, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b55bab4eeb2005bd9381423915d5edb6969d0f5c"}], "s": {"y": 487, "x": 741, "u": "https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;format=png&amp;auto=webp&amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20"}, "id": "ajcy9e99zfkb1"}}, "name": "t3_161t22b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mD7sAGXVRAtCoqB5yQQShnqAKM4diaNaW9hrfwSjqIs.jpg", "edited": 1693055052.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693050410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Streamlining your data visualization journey with Python&amp;#39;s popular library&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7mc9f945zfkb1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e2cfe38d1ddea91e3d551b74b0d6964cac90d4a1\"&gt; Photo Credit: Created by Author, Canva  &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This article aims to introduce the objects interface feature in &lt;a href=\"https://seaborn.pydata.org/whatsnew/index.html?ref=dataleadsfuture.com#v0-12\"&gt;Seaborn 0.12&lt;/a&gt;, including the concept of declarative graphic syntax, and a practical visualization project to showcase the usage of the objects interface.&lt;/p&gt;\n\n&lt;p&gt;By the end of this article, you&amp;#39;ll have a clear understanding of the advantages and limitations of &lt;a href=\"https://seaborn.pydata.org/tutorial/objects_interface.html?ref=dataleadsfuture.com\"&gt;Seaborn&amp;#39;s objects interface API&lt;/a&gt;. And you will be able to use Seaborn for data analysis projects more easily.&lt;/p&gt;\n\n&lt;h2&gt;Introduction&lt;/h2&gt;\n\n&lt;p&gt;Remember that joke about a programmer?&lt;/p&gt;\n\n&lt;p&gt;He was heading to the grocery store, and his wife told him, &amp;quot;Buy a bottle of milk, and if they have eggs, buy 12.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;So, he came home with 12 bottles of milk because they had eggs.&lt;/p&gt;\n\n&lt;p&gt;This is the problem with imperative programming\u2014it executes your instructions to the letter, without understanding your intent.&lt;/p&gt;\n\n&lt;p&gt;Now, imagine you&amp;#39;re creating a data visualization chart using Python.&lt;/p&gt;\n\n&lt;p&gt;You have to instruct the computer every step of the way: select a dataset, create a figure, set the color, add labels, adjust the size, etc...&lt;/p&gt;\n\n&lt;p&gt;Then you realize your code is getting longer and more complex, and all you wanted was to quickly visualize your data.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s like going to the grocery store and having to specify every item&amp;#39;s location, color, size, and shape, instead of just telling the shop assistant what you need.&lt;/p&gt;\n\n&lt;p&gt;Not only is this time-consuming, but it can also feel tiring.&lt;/p&gt;\n\n&lt;p&gt;However, Seaborn 0.12&amp;#39;s new feature\u2014the objects interface\u2014and its use of declarative graphic syntax is like having a shop assistant who understands you. You just need to tell it what you need to do, and it will find everything for you.&lt;/p&gt;\n\n&lt;p&gt;You no longer need to instruct it every step of the way. You just need to tell it what kind of result you want.&lt;/p&gt;\n\n&lt;p&gt;In this article, I&amp;#39;ll guide you through using the objects interface, this new feature that makes your data visualization process more effortless, flexible, and enjoyable. Let&amp;#39;s get started!&lt;/p&gt;\n\n&lt;h2&gt;Why Declarative Graphic Syntax?&lt;/h2&gt;\n\n&lt;p&gt;Let&amp;#39;s consider the salad-making process to illustrate the difference between traditional and declarative graphic syntax.&lt;/p&gt;\n\n&lt;p&gt;In the traditional approach, you&amp;#39;re providing a detailed recipe, telling the chef each step, for example:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Get a bowl.&lt;/li&gt;\n&lt;li&gt;Put lettuce in it.&lt;/li&gt;\n&lt;li&gt;Cut some cherry tomatoes and add them.&lt;/li&gt;\n&lt;li&gt;Add some cucumber slices.&lt;/li&gt;\n&lt;li&gt;Sprinkle some sesame seeds.&lt;/li&gt;\n&lt;li&gt;Finally, drizzle with your favorite dressing.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Even for a simple salad, you must specify each step in detail.&lt;/p&gt;\n\n&lt;p&gt;In contrast, declarative graphic syntax is more like telling the chef what kind of salad you want, rather than how to make it.&lt;/p&gt;\n\n&lt;p&gt;For instance, you might say, &amp;quot;I want a salad with lettuce, tomatoes, cucumber, and sesame seeds.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The chef knows how to handle each ingredient without requiring step-by-step instructions.&lt;/p&gt;\n\n&lt;p&gt;Similarly, when using Seaborn&amp;#39;s objects interface with its declarative syntax to create a visualization, we specify what we want (a histogram showing a variable&amp;#39;s distribution in a given dataset), not how to get there.&lt;/p&gt;\n\n&lt;p&gt;This approach makes the code more concise and easier to understand, enhancing programming flexibility and efficiency.&lt;/p&gt;\n\n&lt;h2&gt;Seaborn API: Then and Now&lt;/h2&gt;\n\n&lt;p&gt;Before diving into the objects interface API, let&amp;#39;s systematically look at the differences between the Seaborn API of earlier versions and the 0.12 version.&lt;/p&gt;\n\n&lt;h2&gt;The original API&lt;/h2&gt;\n\n&lt;p&gt;Many readers might have been intimidated by Matplotlib&amp;#39;s complex API documentation when learning Python data visualization.&lt;/p&gt;\n\n&lt;p&gt;Seaborn simplifies this by wrapping and streamlining Matplotlib&amp;#39;s API, making the learning curve gentler.&lt;/p&gt;\n\n&lt;p&gt;Seaborn doesn&amp;#39;t just offer high-level encapsulation of Matplotlib; it also categorizes all charts into relational, distributional, and categorical scenarios.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ajcy9e99zfkb1.png?width=741&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e0a6794876d4e4a7febdb987226a359f1c3a5e20\"&gt; Overview of Seaborn&amp;#39;s original API design. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;You should comprehensively understand Seaborn&amp;#39;s API through this diagram and know when to use which chart.&lt;/p&gt;\n\n&lt;p&gt;For example, a histplot representing data distribution would fall under the distribution chart category.&lt;/p&gt;\n\n&lt;p&gt;In contrast, a violinplot representing data features by category would be classified as a categorical chart.&lt;/p&gt;\n\n&lt;p&gt;Aside from vertical categorization, Seaborn also performs horizontal categorization: Figure-level and axes-level.&lt;/p&gt;\n\n&lt;p&gt;According to the &lt;a href=\"https://seaborn.pydata.org/tutorial/function_overview.html?ref=dataleadsfuture.com#figure-level-vs-axes-level-functions\"&gt;official website&lt;/a&gt;, axes-level charts are drawn on matplotlib.pyplot.axes and can only draw one figure.&lt;/p&gt;\n\n&lt;p&gt;In contrast, Figure-level charts use Matplotlib&amp;#39;s FacetGrid to draw multiple charts in one figure, facilitating easy comparison of similar data dimensions.&lt;/p&gt;\n\n&lt;p&gt;However, even though Seaborn&amp;#39;s API significantly simplifies chart drawing through encapsulating Matplotlib, creating an individual-specific chart still requires complex configurations.&lt;/p&gt;\n\n&lt;p&gt;For example, if I use Seaborn&amp;#39;s built-in penguins dataset to draw a histplot, the code is as follows:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sns.histplot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, hue=&amp;quot;species&amp;quot;);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/z3ubpaufzfkb1.png?width=566&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a33bf9df8e83b18cb35ab90822858ebb95bd95c2\"&gt; The original way of drawing a histplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And when I use the same dataset to draw a kdeplot, the code is as follows:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;sns.kdeplot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, fill=True, hue=&amp;quot;species&amp;quot;);\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ufs151akzfkb1.png?width=588&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f8f93006ad7fcf7534e81ac88cfe3d470f8c20dd\"&gt; The original way of drawing a kdeplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Except for the chart API, the rest of the configurations are identical.&lt;/p&gt;\n\n&lt;p&gt;This is like telling the chef I want to use lamb chops and onions to make a lamb soup and specifying the cooking steps. When I want to use these ingredients to make a roasted lamb chop, I have to tell the chef about the ingredients and the cooking steps all over again.&lt;/p&gt;\n\n&lt;p&gt;Not only is it inefficient, but it also needs more flexibility.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s why Seaborn introduced the objects interface API in its 0.12 version. This declarative graphic syntax dramatically improves the process of creating a chart.&lt;/p&gt;\n\n&lt;h2&gt;The objects Interface API&lt;/h2&gt;\n\n&lt;p&gt;Before we start with the objects interface API, let&amp;#39;s take a high-level look at it to better understand the drawing process.&lt;/p&gt;\n\n&lt;p&gt;Unlike the original Seaborn API, which organizes the drawing API by classification, the objects interface API collects the API by a drawing pipeline.&lt;/p&gt;\n\n&lt;p&gt;The objects interface API divides the drawing into multiple stages, such as data binding, layout, presentation, customization, etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jdkazetmzfkb1.png?width=899&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=21b59c646f0365f5ccffb40b7bb0015a1975c23e\"&gt; Overview of Seaborn&amp;#39;s objects interface API design. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The data binding and presentation stages are necessary, while other stages are optional.&lt;/p&gt;\n\n&lt;p&gt;Also, since the stages are independent, each stage can be reused. Following the previous example of the hist and kde plots:&lt;/p&gt;\n\n&lt;p&gt;To use the objects interface to draw, we first need to bind the data:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p = so.Plot(penguins, x=&amp;quot;flipper_length_mm&amp;quot;, color=&amp;quot;species&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;From this line of code, we can see that the objects interface uses the so.Plot class for data binding.&lt;/p&gt;\n\n&lt;p&gt;Also, compared to the original API that uses the incomprehensible hue parameter, it uses the color parameter to bind the species dimension directly to the chart color, making the configuration more intuitive.&lt;/p&gt;\n\n&lt;p&gt;Finally, this line of code returns a p instance that can be reused to draw a chart.&lt;/p&gt;\n\n&lt;p&gt;Next, let&amp;#39;s draw a histplot:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p.add(so.Bars(), so.Hist())\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/otseb0utzfkb1.png?width=1453&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0d19226419a136f1042faa6bd67754a891ae7b6a\"&gt; Use objects interface API to draw a histplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This line of code shows that the drawing stage does not need to rebind the data. We just need to tell the addmethod what to draw: so.Bars(), and how to calculate it: so.Hist().&lt;/p&gt;\n\n&lt;p&gt;The add method also returns a copy of the Plot instance, so any adjustments in the add method will not affect the original data binding. The p instance can still be reused.&lt;/p&gt;\n\n&lt;p&gt;Therefore, we continue to call the p.add() method to draw a kdeplot:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p.add(so.Area(), so.KDE())\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tjaegaiyzfkb1.png?width=1453&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8d35e9fd209c9a2004c5496f45c489aa67202e89\"&gt; Use objects interface API to draw a kdeplot. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Since KDE is a way of statistic, so.KDE() is called on the stat parameter here. And since the kdeplot itself is an area plot, so.Area() is used for drawing.&lt;/p&gt;\n\n&lt;p&gt;We reused the p instance bound to the data, so there is no need to tell the chef how to cook each dish, but to directly say what we want. Isn&amp;#39;t it much more concise and flexible?&lt;/p&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/seaborn-0-12-an-insightful-guide-to-the-objects-interface-and-declarative-graphics/\"&gt;Data Leads Future&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161t22b", "is_robot_indexable": true, "report_reasons": null, "author": "qtalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161t22b/seaborn_012_an_insightful_guide_to_the_objects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161t22b/seaborn_012_an_insightful_guide_to_the_objects/", "subreddit_subscribers": 1015309, "created_utc": 1693050410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "On one hand, most data exploration might be using Notebooks and CSV files so it is easier to manage them on Google Drive since they don't take up much space and it updates automatically. Also stuff on Google Drive is more accessible in a way. Hell if the production code is a simple python script it doesn't take up much space.\n\nOn the other hand, it just seem like good practice for coders to do it on Github.\n\nHow do you guys do it? Or are there alternatives?", "author_fullname": "t2_ru8ni", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Silly Question: Do you guys store your Notebooks and EDA stuff in Google Drive or Github?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161mgcj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693028498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On one hand, most data exploration might be using Notebooks and CSV files so it is easier to manage them on Google Drive since they don&amp;#39;t take up much space and it updates automatically. Also stuff on Google Drive is more accessible in a way. Hell if the production code is a simple python script it doesn&amp;#39;t take up much space.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, it just seem like good practice for coders to do it on Github.&lt;/p&gt;\n\n&lt;p&gt;How do you guys do it? Or are there alternatives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161mgcj", "is_robot_indexable": true, "report_reasons": null, "author": "ias6661", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161mgcj/silly_question_do_you_guys_store_your_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161mgcj/silly_question_do_you_guys_store_your_notebooks/", "subreddit_subscribers": 1015309, "created_utc": 1693028498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm new the area and would appreciate some insight. With my background in applied mathematics/statistics, I've delved into some curriculum in computer science and noticed the intricate role that languages like C play in understanding hardware-level interactions. While I can see the distinction between this and the mathematical or algorithmic side of computation in data science, I'm evaluating the broader value of this knowledge:\n\n1. In today's industry, is there a predominant focus on hardware/software optimization or is there a tilt towards computational and mathematical optimization techniques? (I'm not completely sure if this dichotomy makes sense though)\n2. As I'm considering data science roles, would a deep understanding of software/hardware level of optimization serve me in the short term?\n3. Given rapid technological advancements, is the depth of knowledge in software/hardware efficiency becoming more specialized and typically the realm of software engineers, not data scientists?\n4. Looking beyond immediate career implications, would a profound understanding of the hardware/software domain serve me well in the long run, potentially if I advance into management roles?", "author_fullname": "t2_6gxwhbsk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is optimization at the hardware/software level a significant concern, or should the primary focus be on computational optimization from a mathematical perspective?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1619map", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692993913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new the area and would appreciate some insight. With my background in applied mathematics/statistics, I&amp;#39;ve delved into some curriculum in computer science and noticed the intricate role that languages like C play in understanding hardware-level interactions. While I can see the distinction between this and the mathematical or algorithmic side of computation in data science, I&amp;#39;m evaluating the broader value of this knowledge:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;In today&amp;#39;s industry, is there a predominant focus on hardware/software optimization or is there a tilt towards computational and mathematical optimization techniques? (I&amp;#39;m not completely sure if this dichotomy makes sense though)&lt;/li&gt;\n&lt;li&gt;As I&amp;#39;m considering data science roles, would a deep understanding of software/hardware level of optimization serve me in the short term?&lt;/li&gt;\n&lt;li&gt;Given rapid technological advancements, is the depth of knowledge in software/hardware efficiency becoming more specialized and typically the realm of software engineers, not data scientists?&lt;/li&gt;\n&lt;li&gt;Looking beyond immediate career implications, would a profound understanding of the hardware/software domain serve me well in the long run, potentially if I advance into management roles?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1619map", "is_robot_indexable": true, "report_reasons": null, "author": "RightProfile0", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1619map/is_optimization_at_the_hardwaresoftware_level_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1619map/is_optimization_at_the_hardwaresoftware_level_a/", "subreddit_subscribers": 1015309, "created_utc": 1692993913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I inherited a large model code base that basically forecasts the contact volume across many languages-regions. It basically creates unique RidgeCV regression models for each market trained on the last 2-3 years of data and spits out a predicted contact volume at different time horizons. The stakeholders then use the outputs of the model as a baseline upon which they apply business logic, e.g. new product launches, predicted customer growth etc, to come up with a final contact volume upon which business decisions are made.\n\nSome of my stakeholders who consume the data from this model have said that the accuracy is low (MAPE \\~70-80% with larger markets being more accurate), and that the model swings unexpectedly and they have no insight as to why it does. \n\nUnfortunately, we will not be rebuilding the model as we calculated the opportunity size for improving the accuracy to be not worth the time it would take, and there are more impactful projects in other departments that I am going to be focussing on. \n\nI don't want to leave them completely hanging, as it is a major pain point for them, so one thing I am thinking about doing to make their lives easier is to create a dashboard that can list out something along the lines of feature importances at the per-model level. This would allow them to see the drivers for when each model predicts a large variation in contact volume. I was thinking either listing out the feature weights since it is a linear model, or using Shapley values. But I would love some feedback from people who have built these kinds of things before on what would actually be useful on a dashboard like this?  \n\nNote: I am NOT an MLE, my DS career has had a heavier emphasis on the DE, Experimentation, and Analytics with limited modeling work.", "author_fullname": "t2_fhys02p7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for Model Explainability for End Consumers of a Demand Forecasting Model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1620x1a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693070294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I inherited a large model code base that basically forecasts the contact volume across many languages-regions. It basically creates unique RidgeCV regression models for each market trained on the last 2-3 years of data and spits out a predicted contact volume at different time horizons. The stakeholders then use the outputs of the model as a baseline upon which they apply business logic, e.g. new product launches, predicted customer growth etc, to come up with a final contact volume upon which business decisions are made.&lt;/p&gt;\n\n&lt;p&gt;Some of my stakeholders who consume the data from this model have said that the accuracy is low (MAPE ~70-80% with larger markets being more accurate), and that the model swings unexpectedly and they have no insight as to why it does. &lt;/p&gt;\n\n&lt;p&gt;Unfortunately, we will not be rebuilding the model as we calculated the opportunity size for improving the accuracy to be not worth the time it would take, and there are more impactful projects in other departments that I am going to be focussing on. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to leave them completely hanging, as it is a major pain point for them, so one thing I am thinking about doing to make their lives easier is to create a dashboard that can list out something along the lines of feature importances at the per-model level. This would allow them to see the drivers for when each model predicts a large variation in contact volume. I was thinking either listing out the feature weights since it is a linear model, or using Shapley values. But I would love some feedback from people who have built these kinds of things before on what would actually be useful on a dashboard like this?  &lt;/p&gt;\n\n&lt;p&gt;Note: I am NOT an MLE, my DS career has had a heavier emphasis on the DE, Experimentation, and Analytics with limited modeling work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1620x1a", "is_robot_indexable": true, "report_reasons": null, "author": "Moldy-Tangelo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1620x1a/ideas_for_model_explainability_for_end_consumers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1620x1a/ideas_for_model_explainability_for_end_consumers/", "subreddit_subscribers": 1015309, "created_utc": 1693070294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset that contains the sale quantity of an item over a year. I am building an ML-based (XGBOOST) model since I plan to include exogenous variables that can influence the demand for the item.\n\nSince I would essentially eliminate the 'date'  column, inferring only features like seasons. \n\nWhen it comes to model evaluation, can I randomly split train and test or do I have to keep the time splits in consideration like we do in ARIMA modeling for example?", "author_fullname": "t2_ba4jkgnm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model evaluation for Sales Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161ibkb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693015661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset that contains the sale quantity of an item over a year. I am building an ML-based (XGBOOST) model since I plan to include exogenous variables that can influence the demand for the item.&lt;/p&gt;\n\n&lt;p&gt;Since I would essentially eliminate the &amp;#39;date&amp;#39;  column, inferring only features like seasons. &lt;/p&gt;\n\n&lt;p&gt;When it comes to model evaluation, can I randomly split train and test or do I have to keep the time splits in consideration like we do in ARIMA modeling for example?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161ibkb", "is_robot_indexable": true, "report_reasons": null, "author": "Excellent-Tennis-323", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161ibkb/model_evaluation_for_sales_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161ibkb/model_evaluation_for_sales_data/", "subreddit_subscribers": 1015309, "created_utc": 1693015661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am going to school for data science at a top 60 school in the country. I play hockey at that school, so ideally my dream job would be to work for an NHL team. I also know and have experience with baseball so the mlb would be awesome too. I also am completely okay with doing something in the corporate world beforehand, so I am not completely naive on the situation. I have read that the pay on the sports end is not great but I am willing to sacrifice pay to do something I truly enjoy. How realistic is that goal? Is that something that very rarely comes along?", "author_fullname": "t2_v8q0o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difficulty levels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161hgvp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693013229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am going to school for data science at a top 60 school in the country. I play hockey at that school, so ideally my dream job would be to work for an NHL team. I also know and have experience with baseball so the mlb would be awesome too. I also am completely okay with doing something in the corporate world beforehand, so I am not completely naive on the situation. I have read that the pay on the sports end is not great but I am willing to sacrifice pay to do something I truly enjoy. How realistic is that goal? Is that something that very rarely comes along?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161hgvp", "is_robot_indexable": true, "report_reasons": null, "author": "natems711", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161hgvp/difficulty_levels/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161hgvp/difficulty_levels/", "subreddit_subscribers": 1015309, "created_utc": 1693013229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I have an interview with US elections modeling company next week. I interviewed with them earlier this year and made it to their take-home test and they wanted me to model some US House elections. Any tips to better succeed this time would be great.\n\n\nAre there complex models for that? Do people usually use one-model-per-district or something different? Is there a \"go-to\" elections modeling curriculum that I've missed? Where are the best US-elections data sources (aside from MIT, Pew, and LoC and all the other easily googleable places)?\n\n(sorry if this flair is wrong, I didn't know which this really fell under)", "author_fullname": "t2_7bn1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Elections Fellow\" interview prep", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161g44t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693009538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an interview with US elections modeling company next week. I interviewed with them earlier this year and made it to their take-home test and they wanted me to model some US House elections. Any tips to better succeed this time would be great.&lt;/p&gt;\n\n&lt;p&gt;Are there complex models for that? Do people usually use one-model-per-district or something different? Is there a &amp;quot;go-to&amp;quot; elections modeling curriculum that I&amp;#39;ve missed? Where are the best US-elections data sources (aside from MIT, Pew, and LoC and all the other easily googleable places)?&lt;/p&gt;\n\n&lt;p&gt;(sorry if this flair is wrong, I didn&amp;#39;t know which this really fell under)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161g44t", "is_robot_indexable": true, "report_reasons": null, "author": "ib33", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161g44t/elections_fellow_interview_prep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161g44t/elections_fellow_interview_prep/", "subreddit_subscribers": 1015309, "created_utc": 1693009538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently a data science apprentice so apologies if I come across as a bit na\u00efve in this area. This project is solo and pro-bono but I don't want to submit low-quality work. \n\n**Overall goal of the project: \"Should \\[X Type\\] courts be introduced?\"**\n\nI'm working with tennis data of length *140 records*, and have *3 free text column*s (there is a lot more categorical columns but I don't have any issue with this) that I need to process. The key thing I'm trying to get at is to *classify responses into coherent opinion*s such as \"I think the acrylic courts are bad\", or, \" I think the club is too cliquey\".\n\nI've read all the responses, since the data size isn't too big and most of the records were left incomplete: *average 60% completion for across the free text columns*. After reading each column I assigned binary, non mutually exclusive, one word tag columns to each response relevant to that column. See the screenshot for more info.\n\n&amp;#x200B;\n\n[Head of dataset. Highlighted are the data columns, unhighlighted are tags \\(data has been filtered to show only complete rows\\).](https://preview.redd.it/xuzh8cwrwakb1.png?width=1633&amp;format=png&amp;auto=webp&amp;s=8c049ed28fad878334fd6f5d6a72b27702ddd91a)\n\n**Sentiment analysis** worked very poorly, mainly because much of the responses talk about improvements. But an even number also spoke about their opinion on the current situation. \n\nI also tried using **LDA for topic modelling** but the clusters outputted very incoherent topics. I *removed stop words and lemmetized*, but the responses seemed to be very very mixed. There seemed to be no distinction.\n\nThinking about my situation and skillset, I'm happy to utilise the tags alongside an accurate sentiment score to assume that this area (tags) should be improved or if people are happy with it (the score -/+).\n\nI feel like I haven't got a strategy in place. Can anyone help me with suggestions on how to approach this, with ideas for pre-processing steps, models, or strategies? Reply if you need more information to work on.  \n\n\n&gt;***Here's some of the full-text data:***  \n&gt;  \n&gt;  \n**EX1, Looking at improvements:**   \n&gt;  \n&gt;\"Courts - if one of the clays floodlit courts can be reserved for members in the evening it will be good. As of now, the coaches book all the floodlit clay courts every week evening.  If floodlights can be installed on more courts like court 11/12 it would help with court choice.\"  \n&gt;  \n&gt;*Sentiment score: 0.6*  \n&gt;  \n&gt;  \n**EX2, Looking at opinions:**  \n&gt;  \n&gt; \"I am interested in \\[X Type court\\] but would not want to pay an extra subscription for it.\"   \n&gt;  \n&gt;*Sentiment score: 0.125*  \n&gt;  \n&gt;**EX3, Extended response:**   \n&gt;  \n&gt;\"Clay courts need taking some clay off. Nobody likes playing on them as so I'm sure they are the last to be booked as like playing on a beach. Booking court system should have an hour and half slots rather than being able to book anytime and we should install a screen that allows you to book in for your court as too many courts are booked at premium times yet are not used.\"   \n&gt;  \n&gt;*Sentiment score: 0.26*  \n&gt;  \n&gt;  \n&gt;  \n&gt;These extracts are different to the random sample I took to see if the sentiment scores lined up (they did not). There is a good mix of these responses throughout.\n\nThanks guys, just want to make a good impression for managing my own mini-project :)", "author_fullname": "t2_a2vo7fq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP tennis data task (I'm struggling a lot)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 15, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xuzh8cwrwakb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 11, "x": 108, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=87abf54389a494fd484796f04526cd34a580ecb9"}, {"y": 23, "x": 216, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6f29d2acde23662c0a942ddef0360cb17dd2ae3e"}, {"y": 34, "x": 320, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd4f00d7556c0612da41eebe47ba2d3668654be2"}, {"y": 68, "x": 640, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=565cb90f729dad8221e64a3d1fab4fe2e0f5856d"}, {"y": 102, "x": 960, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8688b69acf957e3347b6badbe84f11de8107c5ba"}, {"y": 115, "x": 1080, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9ab191aa28cf9338b386e679fb0555241626fcc1"}], "s": {"y": 175, "x": 1633, "u": "https://preview.redd.it/xuzh8cwrwakb1.png?width=1633&amp;format=png&amp;auto=webp&amp;s=8c049ed28fad878334fd6f5d6a72b27702ddd91a"}, "id": "xuzh8cwrwakb1"}}, "name": "t3_1617k82", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/c1Y4eYNam-sdlPpqOk16n1WmDzkqOAD_OFretgKQaJc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692989112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a data science apprentice so apologies if I come across as a bit na\u00efve in this area. This project is solo and pro-bono but I don&amp;#39;t want to submit low-quality work. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Overall goal of the project: &amp;quot;Should [X Type] courts be introduced?&amp;quot;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working with tennis data of length &lt;em&gt;140 records&lt;/em&gt;, and have &lt;em&gt;3 free text column&lt;/em&gt;s (there is a lot more categorical columns but I don&amp;#39;t have any issue with this) that I need to process. The key thing I&amp;#39;m trying to get at is to &lt;em&gt;classify responses into coherent opinion&lt;/em&gt;s such as &amp;quot;I think the acrylic courts are bad&amp;quot;, or, &amp;quot; I think the club is too cliquey&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read all the responses, since the data size isn&amp;#39;t too big and most of the records were left incomplete: &lt;em&gt;average 60% completion for across the free text columns&lt;/em&gt;. After reading each column I assigned binary, non mutually exclusive, one word tag columns to each response relevant to that column. See the screenshot for more info.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xuzh8cwrwakb1.png?width=1633&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c049ed28fad878334fd6f5d6a72b27702ddd91a\"&gt;Head of dataset. Highlighted are the data columns, unhighlighted are tags (data has been filtered to show only complete rows).&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Sentiment analysis&lt;/strong&gt; worked very poorly, mainly because much of the responses talk about improvements. But an even number also spoke about their opinion on the current situation. &lt;/p&gt;\n\n&lt;p&gt;I also tried using &lt;strong&gt;LDA for topic modelling&lt;/strong&gt; but the clusters outputted very incoherent topics. I &lt;em&gt;removed stop words and lemmetized&lt;/em&gt;, but the responses seemed to be very very mixed. There seemed to be no distinction.&lt;/p&gt;\n\n&lt;p&gt;Thinking about my situation and skillset, I&amp;#39;m happy to utilise the tags alongside an accurate sentiment score to assume that this area (tags) should be improved or if people are happy with it (the score -/+).&lt;/p&gt;\n\n&lt;p&gt;I feel like I haven&amp;#39;t got a strategy in place. Can anyone help me with suggestions on how to approach this, with ideas for pre-processing steps, models, or strategies? Reply if you need more information to work on.  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;Here&amp;#39;s some of the full-text data:&lt;/em&gt;&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EX1, Looking at improvements:&lt;/strong&gt;   &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Courts - if one of the clays floodlit courts can be reserved for members in the evening it will be good. As of now, the coaches book all the floodlit clay courts every week evening.  If floodlights can be installed on more courts like court 11/12 it would help with court choice.&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Sentiment score: 0.6&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EX2, Looking at opinions:&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;I am interested in [X Type court] but would not want to pay an extra subscription for it.&amp;quot;   &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Sentiment score: 0.125&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EX3, Extended response:&lt;/strong&gt;   &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Clay courts need taking some clay off. Nobody likes playing on them as so I&amp;#39;m sure they are the last to be booked as like playing on a beach. Booking court system should have an hour and half slots rather than being able to book anytime and we should install a screen that allows you to book in for your court as too many courts are booked at premium times yet are not used.&amp;quot;   &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Sentiment score: 0.26&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;These extracts are different to the random sample I took to see if the sentiment scores lined up (they did not). There is a good mix of these responses throughout.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Thanks guys, just want to make a good impression for managing my own mini-project :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1617k82", "is_robot_indexable": true, "report_reasons": null, "author": "Ilostmyshitinvegas", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1617k82/nlp_tennis_data_task_im_struggling_a_lot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1617k82/nlp_tennis_data_task_im_struggling_a_lot/", "subreddit_subscribers": 1015309, "created_utc": 1692989112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am in a team of 10 people, a mix of data scientists, analysts and software engineers. \n\nSome of our side quests involve building tools for our entire small team to use \u2014 think a standardized debugging tool to handle common error messages when interacting with company-wide APIs. The thing is, despite it can bring a lot of value to the team, our manager doesn\u2019t really appreciate this kind of work too much and so when a team member build such a tool, it would usually be quick and dirty without any unit tests written to support any logic changes.\n\nThere are some problems with these tools sometimes \u2014 happening due to untested code updates mostly \u2014 but nothing severe and because we are small, it is easily solved by just sending a message to the software owner. But can you see these problems compounding in the long run? I\u2019m trying to see whether there is a need to shift this culture and encourage unit tests everywhere in our side quests.", "author_fullname": "t2_1bodd6y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does unit testing make sense for a small team software package?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1621e71", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693071436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in a team of 10 people, a mix of data scientists, analysts and software engineers. &lt;/p&gt;\n\n&lt;p&gt;Some of our side quests involve building tools for our entire small team to use \u2014 think a standardized debugging tool to handle common error messages when interacting with company-wide APIs. The thing is, despite it can bring a lot of value to the team, our manager doesn\u2019t really appreciate this kind of work too much and so when a team member build such a tool, it would usually be quick and dirty without any unit tests written to support any logic changes.&lt;/p&gt;\n\n&lt;p&gt;There are some problems with these tools sometimes \u2014 happening due to untested code updates mostly \u2014 but nothing severe and because we are small, it is easily solved by just sending a message to the software owner. But can you see these problems compounding in the long run? I\u2019m trying to see whether there is a need to shift this culture and encourage unit tests everywhere in our side quests.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1621e71", "is_robot_indexable": true, "report_reasons": null, "author": "iamdeviance", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1621e71/does_unit_testing_make_sense_for_a_small_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1621e71/does_unit_testing_make_sense_for_a_small_team/", "subreddit_subscribers": 1015309, "created_utc": 1693071436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m thinking of applying to this:\n\n[https://faculty.ai/fellowship-fellows/?utm\\_campaign=Fellowship%2026%20-%20Applications&amp;utm\\_source=email&amp;utm\\_medium=Interest%20list&amp;utm\\_term=Hubspot&amp;utm\\_content=Applications%20open%20%28May%202023%29](https://faculty.ai/fellowship-fellows/?utm_campaign=Fellowship%2026%20-%20Applications&amp;utm_source=email&amp;utm_medium=Interest%20list&amp;utm_term=Hubspot&amp;utm_content=Applications%20open%20%28May%202023%29)\n\nJust wondering how hard it\u2019ll be for me to get in. I\u2019ve got a masters in data science from Careerera which isn\u2019t the best masters but Im hoping it qualifies. Just wondering if anyone\u2019s done it before.", "author_fullname": "t2_4lmpcc3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone heard of faculty.ai?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16216r0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693070936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m thinking of applying to this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://faculty.ai/fellowship-fellows/?utm_campaign=Fellowship%2026%20-%20Applications&amp;amp;utm_source=email&amp;amp;utm_medium=Interest%20list&amp;amp;utm_term=Hubspot&amp;amp;utm_content=Applications%20open%20%28May%202023%29\"&gt;https://faculty.ai/fellowship-fellows/?utm_campaign=Fellowship%2026%20-%20Applications&amp;amp;utm_source=email&amp;amp;utm_medium=Interest%20list&amp;amp;utm_term=Hubspot&amp;amp;utm_content=Applications%20open%20%28May%202023%29&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Just wondering how hard it\u2019ll be for me to get in. I\u2019ve got a masters in data science from Careerera which isn\u2019t the best masters but Im hoping it qualifies. Just wondering if anyone\u2019s done it before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?auto=webp&amp;s=ee6b11645868310e9239e7fa475c04d7a5afa4d4", "width": 2000, "height": 1333}, "resolutions": [{"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=410ac9dafb9bf4b59bf747e2d75ff9c2fda6a2fd", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8999b58a6ffd1031f3e4a839ea41062baa97003e", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5b2a3b4af378168ba31515efa037a8389602cacb", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=84d38cdcf7d096e929abdd37d4e2f78f5436d389", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a41f7a3e9d3603dcc4d34f05bf5bc303e92a6ec9", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/XUBxthYBQ56kuN_WiVkD-P-1n7BYVFqwueaTit3v1Js.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=648798c090bbb8897b8d4326ff8cabb94b401b6b", "width": 1080, "height": 719}], "variants": {}, "id": "ecHk9ZLP1I54kTm81PtOd9flzglN73iU1bmbBvWKh0A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16216r0", "is_robot_indexable": true, "report_reasons": null, "author": "redtoothroll", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16216r0/anyone_heard_of_facultyai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16216r0/anyone_heard_of_facultyai/", "subreddit_subscribers": 1015309, "created_utc": 1693070936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_536lg1nv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing txtai, the all-in-one embeddings database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_161ss7n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/etA6LPfWqJnA-DrSxfaVZogoaqMFSVqX5N_UXyZv5JY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693049577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/neuml/introducing-txtai-the-all-in-one-embeddings-database-c721f4ff91ad", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?auto=webp&amp;s=4b3dac78f9218e4d4a4a8874102bd2ad557e8836", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=600ad92c3292c75a41436d1c9e63401155475364", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=655efba81489cc46c74b0d5818a3205a29fcb22f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e3c2e39fd3a52e5b930c0b36b08be7acc307d93", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eef93bcd3c8853798d51e4532ecf15612eca7e7e", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d2dbc013a96cd9270a7cdf283cfb8c29aa329d3c", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/us7Pv4eVjGk2-G8aM2NmJ5jfL16bdPhojYfcKsLvm84.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=55b4f681f8c90538b1a9074dd1f3c95746d63320", "width": 1080, "height": 540}], "variants": {}, "id": "gykebrM_vvT-4IzABmlieYDKYYmcS71kdJ2ORLpqxn8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "161ss7n", "is_robot_indexable": true, "report_reasons": null, "author": "davidmezzetti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161ss7n/introducing_txtai_the_allinone_embeddings_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/neuml/introducing-txtai-the-all-in-one-embeddings-database-c721f4ff91ad", "subreddit_subscribers": 1015309, "created_utc": 1693049577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello All,\n\nI am working for a smaller company that has financial expenses based on snow removal for a given year. My boss and I were looking into different companies that sell data for this information. We want to use the data to help make predictions of future snowfall data that we then could use to approximate expenses for the new year.\n\nData science at this company is a bit of a new thing, and I'm still learning as well so I don't have much experience in which data might be best for this project. I'm curious if any of you all have experience with snowfall data and were to start looking for data like this?\n\nWe are really only interested in snowfall data, and preferably data at a city/metro level if possible. The data we want is for USA markets\n\nAny advice is appreciated!", "author_fullname": "t2_e24an8jlc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowfall Statistics per City/Metro Area USA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161exy4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693006502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;I am working for a smaller company that has financial expenses based on snow removal for a given year. My boss and I were looking into different companies that sell data for this information. We want to use the data to help make predictions of future snowfall data that we then could use to approximate expenses for the new year.&lt;/p&gt;\n\n&lt;p&gt;Data science at this company is a bit of a new thing, and I&amp;#39;m still learning as well so I don&amp;#39;t have much experience in which data might be best for this project. I&amp;#39;m curious if any of you all have experience with snowfall data and were to start looking for data like this?&lt;/p&gt;\n\n&lt;p&gt;We are really only interested in snowfall data, and preferably data at a city/metro level if possible. The data we want is for USA markets&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161exy4", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering-Plane7979", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161exy4/snowfall_statistics_per_citymetro_area_usa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161exy4/snowfall_statistics_per_citymetro_area_usa/", "subreddit_subscribers": 1015309, "created_utc": 1693006502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a BA in accounting and finance from a reallu terrible university and im thinking of doing a masters in data analyst would that be okOK to get a job as a DS if i get some experience working as analyst? \n\n&amp;#x200B;\n\nThanks \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_8ipoczkd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Msc Data analyst - is it worth it in my case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161afcx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692995762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a BA in accounting and finance from a reallu terrible university and im thinking of doing a masters in data analyst would that be okOK to get a job as a DS if i get some experience working as analyst? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161afcx", "is_robot_indexable": true, "report_reasons": null, "author": "Raf_eha", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161afcx/msc_data_analyst_is_it_worth_it_in_my_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/161afcx/msc_data_analyst_is_it_worth_it_in_my_case/", "subreddit_subscribers": 1015309, "created_utc": 1692995762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9v2ffwqay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitter Community / Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161rqa5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1693046299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/i/communities/1695363277289562618", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161rqa5", "is_robot_indexable": true, "report_reasons": null, "author": "x9182", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161rqa5/twitter_community_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/i/communities/1695363277289562618", "subreddit_subscribers": 1015309, "created_utc": 1693046299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8qgfbbfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leveraging NLP and OCR for Business Card Text Extraction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_161pr5h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TV8-g9jeOmLtRQo0hT88aWztIzmFkW2Kt8PX-2eAT34.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693039638.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "abhilashshukla.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://abhilashshukla.com/tech-and-programming/aiml/leveraging-nlp-and-ocr-for-business-card-text-extraction/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?auto=webp&amp;s=66605857e6f7f7824f7295e38884b5f72340df13", "width": 900, "height": 504}, "resolutions": [{"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c412490b3fb48e5346468653d3a3e0636a6aa11c", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2772bc548d15905ed61e5b064cb324b517b94d04", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fa67670eed710a938ebe57e2506d671015405415", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/cz0Icm5LIP2eTneT2JDm0jJINjAyyzgjhB_AnsCBUyQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=98881f8b29af5643cd31b5b91786802b3e5f0431", "width": 640, "height": 358}], "variants": {}, "id": "6cwV5FRTGCO6L0K5DlRn4hGjOM7jz29PeZA1eQyuoLI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "161pr5h", "is_robot_indexable": true, "report_reasons": null, "author": "Anxious_City_7864", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161pr5h/leveraging_nlp_and_ocr_for_business_card_text/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://abhilashshukla.com/tech-and-programming/aiml/leveraging-nlp-and-ocr-for-business-card-text-extraction/", "subreddit_subscribers": 1015309, "created_utc": 1693039638.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_h8jjaslyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Get Hired as Junior Data Analyst - Remote | FullTime", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_161zaol", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1693066315.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theswedishtimes.se", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://theswedishtimes.se/jobs/8", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "161zaol", "is_robot_indexable": true, "report_reasons": null, "author": "Finance_mechanism", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/161zaol/get_hired_as_junior_data_analyst_remote_fulltime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://theswedishtimes.se/jobs/8", "subreddit_subscribers": 1015309, "created_utc": 1693066315.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}