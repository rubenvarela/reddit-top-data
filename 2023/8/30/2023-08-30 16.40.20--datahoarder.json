{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Trying to download [https://web.archive.org/web/20221227075452/https://github.com/nextdns/metadata](https://web.archive.org/web/20221227075452/https://github.com/nextdns/metadata) but only has ReadMe.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nAbout the  repo [https://www.reddit.com/r/nextdns/comments/163tl4l/nextdns\\_hid\\_their\\_blocklists\\_where\\_to\\_get\\_them\\_now/](https://www.reddit.com/r/nextdns/comments/163tl4l/nextdns_hid_their_blocklists_where_to_get_them_now/)", "author_fullname": "t2_4jurunac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download GitHub repo from archive.org ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1659ffo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693386195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to download &lt;a href=\"https://web.archive.org/web/20221227075452/https://github.com/nextdns/metadata\"&gt;https://web.archive.org/web/20221227075452/https://github.com/nextdns/metadata&lt;/a&gt; but only has ReadMe.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;About the  repo &lt;a href=\"https://www.reddit.com/r/nextdns/comments/163tl4l/nextdns_hid_their_blocklists_where_to_get_them_now/\"&gt;https://www.reddit.com/r/nextdns/comments/163tl4l/nextdns_hid_their_blocklists_where_to_get_them_now/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?auto=webp&amp;s=e051bbf633f265539207716db902ea2015f4dfaf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=87f7ddca45ea443a68693203e54efa62b7aceb22", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9be88dd4b5cdde01df6fb5c7783a2e6d9b2ba075", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=445e7208c5fb379c68b907b9bab5f08243e29647", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=079c07200cafb4f222be6056a1ba8ebff223c122", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=40060d92fa7c860a48cb70337c91386c62d218e9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/4Hh4iGCdoazLbAF0k6KEbXgV2tsMjzqPdr7SvOHf12Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=00f8dcddd741e469a9e60da33da2c51432abb124", "width": 1080, "height": 540}], "variants": {}, "id": "nYamHCyV1AG3uPhhStxxBypuzgl11wxNWxQrh7DB-e0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1659ffo", "is_robot_indexable": true, "report_reasons": null, "author": "RedditNoobie777", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1659ffo/how_to_download_github_repo_from_archiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1659ffo/how_to_download_github_repo_from_archiveorg/", "subreddit_subscribers": 700738, "created_utc": 1693386195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't know enough to even form a good query on this. So if you feel like educating it's appreciated. I make this thread because I'm making coasters of these blurays in ignorance and the amount of trial and error going on up in here is cringe.\n\nI'm trying to transcode an abundance of admittedly low-quality .mkv files in different formats to H.264(AVC) so I can smoosh them together on Blu-rays and play them with an old blu-ray player. Problem is the blu-ray player can't recognize the files or thinks they're corrupt; VLC can play them.\n\nThis is the particular blu-ray player. Yes it's very old, I want the discs to be as compatible as possible. See page 23 for supported formats. For the most part, files others transcoded marked with \"x264\" work.\n\n[https://www.sony.com/electronics/support/res/manuals/4290/42902811M.pdf](https://www.sony.com/electronics/support/res/manuals/4290/42902811M.pdf)\n\nI am able to make working dvd-menu type thing with \"multiAVCHD\" and avidemux which are ancient, broken, and amusing that it works but with too much of a quality hit. I've also messed with ffmpeg and handbrake. Here's an example of the command that outputs a file the PC can play but not the bluray player:\n\nffmpeg -i C:\\\\somepath\\\\input.mkv -map 0 -c:s copy -c:v libx264 -crf 18 -preset slow -c:a copy output.mkv  \n\n\nAny thoughts on what I should do to get files old players can handle? It seems like this niche is dominated by a few really expensive software options nowadays. I know it's lossy, I don't care, lots of this media is from 1980-2000 anyway so the standard I have to compare to is what SD tv used to look like.\n\nThank you.", "author_fullname": "t2_f8z75ww80", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "transcoding x264/AVC for bluray player", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16527yf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693362376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know enough to even form a good query on this. So if you feel like educating it&amp;#39;s appreciated. I make this thread because I&amp;#39;m making coasters of these blurays in ignorance and the amount of trial and error going on up in here is cringe.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to transcode an abundance of admittedly low-quality .mkv files in different formats to H.264(AVC) so I can smoosh them together on Blu-rays and play them with an old blu-ray player. Problem is the blu-ray player can&amp;#39;t recognize the files or thinks they&amp;#39;re corrupt; VLC can play them.&lt;/p&gt;\n\n&lt;p&gt;This is the particular blu-ray player. Yes it&amp;#39;s very old, I want the discs to be as compatible as possible. See page 23 for supported formats. For the most part, files others transcoded marked with &amp;quot;x264&amp;quot; work.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.sony.com/electronics/support/res/manuals/4290/42902811M.pdf\"&gt;https://www.sony.com/electronics/support/res/manuals/4290/42902811M.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I am able to make working dvd-menu type thing with &amp;quot;multiAVCHD&amp;quot; and avidemux which are ancient, broken, and amusing that it works but with too much of a quality hit. I&amp;#39;ve also messed with ffmpeg and handbrake. Here&amp;#39;s an example of the command that outputs a file the PC can play but not the bluray player:&lt;/p&gt;\n\n&lt;p&gt;ffmpeg -i C:\\somepath\\input.mkv -map 0 -c:s copy -c:v libx264 -crf 18 -preset slow -c:a copy output.mkv  &lt;/p&gt;\n\n&lt;p&gt;Any thoughts on what I should do to get files old players can handle? It seems like this niche is dominated by a few really expensive software options nowadays. I know it&amp;#39;s lossy, I don&amp;#39;t care, lots of this media is from 1980-2000 anyway so the standard I have to compare to is what SD tv used to look like.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16527yf", "is_robot_indexable": true, "report_reasons": null, "author": "soft_shark_who", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16527yf/transcoding_x264avc_for_bluray_player/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16527yf/transcoding_x264avc_for_bluray_player/", "subreddit_subscribers": 700738, "created_utc": 1693362376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a mergerFS with snapraid setup running on OpenMediaVault with a bunch of different drives (none of them SMR, AFIAK). The drives are running on a  SuperMicro server with a Xeon E3-1240v6, 32 GB RAM and a LSI 9211 LBA card.\n\nHowever, my setup originated on an old HP Microserver Gen7 with an AMD Turion  N40L (that synced with only 20 MB/s)  that I have moved first to a Gen 8 microserver (sync speeds 90-110 MB/s) and now to the Supermicro. Across all three setup my Snapraid speeds felt rather slow, but lacking any base for comparison i thought its OK. However in this thread here someone was compaining that his sync is running only 130 MB/s  [https://www.reddit.com/r/DataHoarder/comments/15ujyz2/snapraid\\_long\\_sync\\_times\\_is\\_it\\_just\\_not\\_suitable/](https://www.reddit.com/r/DataHoarder/comments/15ujyz2/snapraid_long_sync_times_is_it_just_not_suitable/)\n\nCurrently I have a sync job running at around 130 MB/s  and 120 stripes pre sec, running for more than 6 hours and  22 more to go. CPU utilization is around 2-3%.\n\nThe disk contain mostly movies and music, so it should be rather big files.\n\nThe drives used are the following:\n\n\\- WDC WD40EFRX\n\n\\- WDC WD30EFRX\n\n\\- WDC WD60EFRX\n\n\\- WDC WD80EZAZ\n\n\\- HGST HUS728T8TALE6L4 (this is the parity drive)\n\nIt seems my speeds are too slow. What can i do  to improve them?\n\n&amp;#x200B;", "author_fullname": "t2_gww3b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to improve Snapraid sync speed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164p6sv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693331306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a mergerFS with snapraid setup running on OpenMediaVault with a bunch of different drives (none of them SMR, AFIAK). The drives are running on a  SuperMicro server with a Xeon E3-1240v6, 32 GB RAM and a LSI 9211 LBA card.&lt;/p&gt;\n\n&lt;p&gt;However, my setup originated on an old HP Microserver Gen7 with an AMD Turion  N40L (that synced with only 20 MB/s)  that I have moved first to a Gen 8 microserver (sync speeds 90-110 MB/s) and now to the Supermicro. Across all three setup my Snapraid speeds felt rather slow, but lacking any base for comparison i thought its OK. However in this thread here someone was compaining that his sync is running only 130 MB/s  &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/15ujyz2/snapraid_long_sync_times_is_it_just_not_suitable/\"&gt;https://www.reddit.com/r/DataHoarder/comments/15ujyz2/snapraid_long_sync_times_is_it_just_not_suitable/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently I have a sync job running at around 130 MB/s  and 120 stripes pre sec, running for more than 6 hours and  22 more to go. CPU utilization is around 2-3%.&lt;/p&gt;\n\n&lt;p&gt;The disk contain mostly movies and music, so it should be rather big files.&lt;/p&gt;\n\n&lt;p&gt;The drives used are the following:&lt;/p&gt;\n\n&lt;p&gt;- WDC WD40EFRX&lt;/p&gt;\n\n&lt;p&gt;- WDC WD30EFRX&lt;/p&gt;\n\n&lt;p&gt;- WDC WD60EFRX&lt;/p&gt;\n\n&lt;p&gt;- WDC WD80EZAZ&lt;/p&gt;\n\n&lt;p&gt;- HGST HUS728T8TALE6L4 (this is the parity drive)&lt;/p&gt;\n\n&lt;p&gt;It seems my speeds are too slow. What can i do  to improve them?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164p6sv", "is_robot_indexable": true, "report_reasons": null, "author": "rudeer_poke", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164p6sv/how_to_improve_snapraid_sync_speed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164p6sv/how_to_improve_snapraid_sync_speed/", "subreddit_subscribers": 700738, "created_utc": 1693331306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know that a huge number of images have been archived, but how do I view them?\n\nPlease explain, I couldn't find the instructions for this.", "author_fullname": "t2_n0hjfdxa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I see the imgur.com photo archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164xwpv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693351166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that a huge number of images have been archived, but how do I view them?&lt;/p&gt;\n\n&lt;p&gt;Please explain, I couldn&amp;#39;t find the instructions for this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164xwpv", "is_robot_indexable": true, "report_reasons": null, "author": "dorij19523", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164xwpv/how_do_i_see_the_imgurcom_photo_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164xwpv/how_do_i_see_the_imgurcom_photo_archive/", "subreddit_subscribers": 700738, "created_utc": 1693351166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I finally turned off my last 2 HDDs (10TB Seagate Barracuda Pros, Raid1) and replaced them with one 8TB Samsung 870 QVO. I\u2019ll keep all of my RAW photos in it and it will work as a hot storage: Very few writes, after the first 5TB transfer and a few reads (occasional photo viewing, lightroom editing, etc..). I'll not write a lot more in it, as I'm using my DSLR less and less. \n\nSome people say that the SSD controllers don\u2019t refresh data from time to time, so is that a bad scenario for an SSD application? Does the controller keep records of the last time a certain block was written and refreshes it, say, every 6, 9 months? Does the controller know what date is today anyways? Of course I keep backups locally and in the cloud. ", "author_fullname": "t2_10zsyk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD as hot storage for photos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164vcmo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693345265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I finally turned off my last 2 HDDs (10TB Seagate Barracuda Pros, Raid1) and replaced them with one 8TB Samsung 870 QVO. I\u2019ll keep all of my RAW photos in it and it will work as a hot storage: Very few writes, after the first 5TB transfer and a few reads (occasional photo viewing, lightroom editing, etc..). I&amp;#39;ll not write a lot more in it, as I&amp;#39;m using my DSLR less and less. &lt;/p&gt;\n\n&lt;p&gt;Some people say that the SSD controllers don\u2019t refresh data from time to time, so is that a bad scenario for an SSD application? Does the controller keep records of the last time a certain block was written and refreshes it, say, every 6, 9 months? Does the controller know what date is today anyways? Of course I keep backups locally and in the cloud. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164vcmo", "is_robot_indexable": true, "report_reasons": null, "author": "old_parr", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164vcmo/ssd_as_hot_storage_for_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164vcmo/ssd_as_hot_storage_for_photos/", "subreddit_subscribers": 700738, "created_utc": 1693345265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[This site](https://fl511.com/cctv) hosts florida DOT cameras. There's 2 specific ones that I want keep on storage. Inspecting, I can't seem to figure out the feed to add to blue iris. Any assistance would be appreciated", "author_fullname": "t2_speo3xmt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help storing Florida road cameras", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164slyu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693339117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://fl511.com/cctv\"&gt;This site&lt;/a&gt; hosts florida DOT cameras. There&amp;#39;s 2 specific ones that I want keep on storage. Inspecting, I can&amp;#39;t seem to figure out the feed to add to blue iris. Any assistance would be appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/J0R887_liIdumYByc8hss2drLu1Q4sG2Rz4EnWhhHQg.jpg?auto=webp&amp;s=0798308c3c0e60d5185348aaae85b75659737d40", "width": 310, "height": 310}, "resolutions": [{"url": "https://external-preview.redd.it/J0R887_liIdumYByc8hss2drLu1Q4sG2Rz4EnWhhHQg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c8661a696f284a1bd339db998620a65e6dd3111", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/J0R887_liIdumYByc8hss2drLu1Q4sG2Rz4EnWhhHQg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=15ecd7b8fa2a14827bf80bc4c0ef06f691992c13", "width": 216, "height": 216}], "variants": {}, "id": "mR6vooTnizkeN8A6SemUD8_4WfiA2ZtDvOSAA5ciz2U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164slyu", "is_robot_indexable": true, "report_reasons": null, "author": "Vile-X", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164slyu/help_storing_florida_road_cameras/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164slyu/help_storing_florida_road_cameras/", "subreddit_subscribers": 700738, "created_utc": 1693339117.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI really like how syncthing automatically connects to your remote peers over the internet.\n\nIs there an open-source backup program that can do the same thing?  (Knowing that syncthing is for file synchronization and not really a backup solution.)\n\nIntended usage would be running docker containers at my and an offsite location (friend's home).\n\nThank you.", "author_fullname": "t2_2k54e5qp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "automatically-discovering open-source backup solution like syncthing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164q5mc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693333549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I really like how syncthing automatically connects to your remote peers over the internet.&lt;/p&gt;\n\n&lt;p&gt;Is there an open-source backup program that can do the same thing?  (Knowing that syncthing is for file synchronization and not really a backup solution.)&lt;/p&gt;\n\n&lt;p&gt;Intended usage would be running docker containers at my and an offsite location (friend&amp;#39;s home).&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164q5mc", "is_robot_indexable": true, "report_reasons": null, "author": "da4niu2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164q5mc/automaticallydiscovering_opensource_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164q5mc/automaticallydiscovering_opensource_backup/", "subreddit_subscribers": 700738, "created_utc": 1693333549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nI have QNAP TS-133-US with 4TB WD RED. I transferred the HDD to my PC, but my PC is not detecting the data in the HDD and requires me to format it first. Is there a way to restore the contents of the HDD? \n\nMany thanks.", "author_fullname": "t2_16edim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD with Qnap OS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16597u9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693385452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I have QNAP TS-133-US with 4TB WD RED. I transferred the HDD to my PC, but my PC is not detecting the data in the HDD and requires me to format it first. Is there a way to restore the contents of the HDD? &lt;/p&gt;\n\n&lt;p&gt;Many thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16597u9", "is_robot_indexable": true, "report_reasons": null, "author": "GamesBond5", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16597u9/hdd_with_qnap_os/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16597u9/hdd_with_qnap_os/", "subreddit_subscribers": 700738, "created_utc": 1693385452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "When I try to do a backup into a Cryptomator Vault, CCC doesn't recognised the pre-existing identical files at the destination and source, and tries to overwrite them from the source. Any advice on how I can fix this? I just want incremental updates on modified/newer files only, as it normally does. Thanks!\n\nAnd then the goal would be to sync/backup the Cryptomator encrypted folder with Google drive.", "author_fullname": "t2_qma00ets", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Issue with CCC and Cryptomator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16557r8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693371195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I try to do a backup into a Cryptomator Vault, CCC doesn&amp;#39;t recognised the pre-existing identical files at the destination and source, and tries to overwrite them from the source. Any advice on how I can fix this? I just want incremental updates on modified/newer files only, as it normally does. Thanks!&lt;/p&gt;\n\n&lt;p&gt;And then the goal would be to sync/backup the Cryptomator encrypted folder with Google drive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16557r8", "is_robot_indexable": true, "report_reasons": null, "author": "MarioKessa", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16557r8/issue_with_ccc_and_cryptomator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16557r8/issue_with_ccc_and_cryptomator/", "subreddit_subscribers": 700738, "created_utc": 1693371195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently have a Synology DS918+ that I've been using for that last 4+ years with \\~28TB usable storage space (WD Red 10TB x3, Seagate Iron Wolf 8TB x1). I use my NAS mainly as a home file server for photos, documents, along with media for my Plex server. I've been collecting 4K remuxes so they've exponentially been taking up space. I usually just watch Plex content from home, but would like the ability to transcode with my new build to watch 4k videos remotely.\n\nWe've outgrown the space so I'm considering whether now is the right time to build a new NAS using my desktop PC components (I plan on upgrading soon) and migrate all my data to 4 new 18TB/20TB drives (and then moving my old drives over once data migration is complete).\n\nI currently have an Intel i7 8700k with AsRock Taichi Z370 MB, 32GB (4x8GB) GSkill TridentZ memory, and an NVIDIA GeForce GTX 1080 graphics card.\n\nI've seen OK prices on the Fractal Design R5 Define case which is my top contender for a new NAS case holding up to 8 drives along with a PCIE Sata controller. Debating between running Unraid, TrueNAS, or plain Windows 10.\n\nAny advice for converting this desktop into a NAS/home server? I'm curious if I'm going down the \"right\" path for my needs.  Looking for thoughts on the OS, or components you'd add/remove, overall configuration, etc.\n\nThanks in advance for the sage advice. \ud83d\ude4f\n\n&amp;#x200B;", "author_fullname": "t2_3g4ik", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting desktop PC into NAS - Plex media and home file server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1651w0c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693361501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have a Synology DS918+ that I&amp;#39;ve been using for that last 4+ years with ~28TB usable storage space (WD Red 10TB x3, Seagate Iron Wolf 8TB x1). I use my NAS mainly as a home file server for photos, documents, along with media for my Plex server. I&amp;#39;ve been collecting 4K remuxes so they&amp;#39;ve exponentially been taking up space. I usually just watch Plex content from home, but would like the ability to transcode with my new build to watch 4k videos remotely.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve outgrown the space so I&amp;#39;m considering whether now is the right time to build a new NAS using my desktop PC components (I plan on upgrading soon) and migrate all my data to 4 new 18TB/20TB drives (and then moving my old drives over once data migration is complete).&lt;/p&gt;\n\n&lt;p&gt;I currently have an Intel i7 8700k with AsRock Taichi Z370 MB, 32GB (4x8GB) GSkill TridentZ memory, and an NVIDIA GeForce GTX 1080 graphics card.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen OK prices on the Fractal Design R5 Define case which is my top contender for a new NAS case holding up to 8 drives along with a PCIE Sata controller. Debating between running Unraid, TrueNAS, or plain Windows 10.&lt;/p&gt;\n\n&lt;p&gt;Any advice for converting this desktop into a NAS/home server? I&amp;#39;m curious if I&amp;#39;m going down the &amp;quot;right&amp;quot; path for my needs.  Looking for thoughts on the OS, or components you&amp;#39;d add/remove, overall configuration, etc.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for the sage advice. \ud83d\ude4f&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1651w0c", "is_robot_indexable": true, "report_reasons": null, "author": "Bawd", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1651w0c/converting_desktop_pc_into_nas_plex_media_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1651w0c/converting_desktop_pc_into_nas_plex_media_and/", "subreddit_subscribers": 700738, "created_utc": 1693361501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all, I need some help, hopefully this is the right sub.\n\nI have a plex server (Qnap TRV-573e) with 4 16tb Ironwolf Pro drives and 1 Samsung 960Evo+. My plex server lives on the Evo and my media is on the Wolfs.\n\nI got a warning I am out of storage space and when I looked I found this:\n\nStorage Pool 1 - 43.63TB   \nDataVol 1 - 21.26TB (Thick volume) FULL\n\nWhat do I do? Do I need to merge the pools? And if so, how?  \n\nLinux OS\n\nI would greatly appreciate some assistance.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/88t2lunel4lb1.png?width=1919&amp;format=png&amp;auto=webp&amp;s=2d9d0b6449c9cd50239a0436188e2fc259ea86c4\n\nhttps://preview.redd.it/k7dtc7aml4lb1.png?width=1114&amp;format=png&amp;auto=webp&amp;s=b2ca71601fcedbdb5fac16867974068790fffb42\n\nhttps://preview.redd.it/kmprus0sl4lb1.png?width=888&amp;format=png&amp;auto=webp&amp;s=15e3b9b4ad388a61703d4ad493e4e8ab73e721dc\n\nhttps://preview.redd.it/dw0vlfaul4lb1.png?width=797&amp;format=png&amp;auto=webp&amp;s=f926c95da49b9d1eaa326d4edb307d7abf0ba226\n\nhttps://preview.redd.it/icxvj5z0m4lb1.png?width=1146&amp;format=png&amp;auto=webp&amp;s=ad372bf070fa38962d34058c4531075954023f76\n\n&amp;#x200B;", "author_fullname": "t2_5fhhvpkd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with Raid-5 out of storage but I have 43TB free....", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 55, "top_awarded_type": null, "hide_score": false, "media_metadata": {"k7dtc7aml4lb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/k7dtc7aml4lb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=de95f2f01178689250cc017b193c4f34acd73ca7"}, {"y": 103, "x": 216, "u": "https://preview.redd.it/k7dtc7aml4lb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=de12cdaa2ed18d0308485760719cd944df950c55"}, {"y": 153, "x": 320, "u": "https://preview.redd.it/k7dtc7aml4lb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b2ff3715326bf195ec20253ee901419f3a29db2"}, {"y": 306, "x": 640, "u": "https://preview.redd.it/k7dtc7aml4lb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4da0bca7323bf52eee5abbd14a1c4e3a2d90d318"}, {"y": 459, "x": 960, "u": "https://preview.redd.it/k7dtc7aml4lb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d6f912be06847fe758faa62afb8db0eaf5e863d0"}, {"y": 516, "x": 1080, "u": "https://preview.redd.it/k7dtc7aml4lb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cf234d41a92fb99eddd66283d4742d2eb96f75ee"}], "s": {"y": 533, "x": 1114, "u": "https://preview.redd.it/k7dtc7aml4lb1.png?width=1114&amp;format=png&amp;auto=webp&amp;s=b2ca71601fcedbdb5fac16867974068790fffb42"}, "id": "k7dtc7aml4lb1"}, "dw0vlfaul4lb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/dw0vlfaul4lb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a75925f33f3b9a39a994391eae6ca5f05c7af0c"}, {"y": 72, "x": 216, "u": "https://preview.redd.it/dw0vlfaul4lb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a2bd513b4be070fbe340b9a23e449e06af33dd5d"}, {"y": 107, "x": 320, "u": "https://preview.redd.it/dw0vlfaul4lb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=30e18e405327b29b9dc3d59026a4e7419830d317"}, {"y": 215, "x": 640, "u": "https://preview.redd.it/dw0vlfaul4lb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c0e922abc9dc4e5fb6dea2659357fef492e26ce9"}], "s": {"y": 268, "x": 797, "u": "https://preview.redd.it/dw0vlfaul4lb1.png?width=797&amp;format=png&amp;auto=webp&amp;s=f926c95da49b9d1eaa326d4edb307d7abf0ba226"}, "id": "dw0vlfaul4lb1"}, "88t2lunel4lb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 42, "x": 108, "u": "https://preview.redd.it/88t2lunel4lb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4291a8c66817fc45a0c98e9e21bf3f5b64f5ae4a"}, {"y": 84, "x": 216, "u": "https://preview.redd.it/88t2lunel4lb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=36dd0a5a27389a2ef08ba652d57ff4b013bb64ce"}, {"y": 125, "x": 320, "u": "https://preview.redd.it/88t2lunel4lb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d4d37ad7f655443e2ecbf7089fef94050d4422b7"}, {"y": 251, "x": 640, "u": "https://preview.redd.it/88t2lunel4lb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d25cd4659cf7bae0961713571a2264af59373a54"}, {"y": 377, "x": 960, "u": "https://preview.redd.it/88t2lunel4lb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d68292e08a145c71ebbea4508cb5831840a7ace4"}, {"y": 424, "x": 1080, "u": "https://preview.redd.it/88t2lunel4lb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e0f3947a9c9b484f7ffaa5ea05625a2ad9a981f3"}], "s": {"y": 754, "x": 1919, "u": "https://preview.redd.it/88t2lunel4lb1.png?width=1919&amp;format=png&amp;auto=webp&amp;s=2d9d0b6449c9cd50239a0436188e2fc259ea86c4"}, "id": "88t2lunel4lb1"}, "icxvj5z0m4lb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/icxvj5z0m4lb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bc0671e242b961b71c04ca752cf3e87d693dfffe"}, {"y": 138, "x": 216, "u": "https://preview.redd.it/icxvj5z0m4lb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=23c81c3a4fe01fec6f26e56cd7ddd645d27d2511"}, {"y": 204, "x": 320, "u": "https://preview.redd.it/icxvj5z0m4lb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4cbd7713fae6458dbe27dc42a64fbf74c3d009d"}, {"y": 409, "x": 640, "u": "https://preview.redd.it/icxvj5z0m4lb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6f6ce50b3c70e65e1bd7c2b8c30a77c186ce8cc3"}, {"y": 614, "x": 960, "u": "https://preview.redd.it/icxvj5z0m4lb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4e92bf6d3ea6796a9bb2df7de00be872a5292d9c"}, {"y": 691, "x": 1080, "u": "https://preview.redd.it/icxvj5z0m4lb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7a1561fb3f5d427376aafab51c4037fe0a2c5e8b"}], "s": {"y": 734, "x": 1146, "u": "https://preview.redd.it/icxvj5z0m4lb1.png?width=1146&amp;format=png&amp;auto=webp&amp;s=ad372bf070fa38962d34058c4531075954023f76"}, "id": "icxvj5z0m4lb1"}, "kmprus0sl4lb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 72, "x": 108, "u": "https://preview.redd.it/kmprus0sl4lb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=79ec45b4bacbd182ee70180ee708ed4689f22664"}, {"y": 144, "x": 216, "u": "https://preview.redd.it/kmprus0sl4lb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=39b0635768f612bd92a687566bcbc5a50518596a"}, {"y": 214, "x": 320, "u": "https://preview.redd.it/kmprus0sl4lb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=15d3af9233234cc87fb331ea3cfead46891b7e70"}, {"y": 428, "x": 640, "u": "https://preview.redd.it/kmprus0sl4lb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f04a4af06f9fbb8a4f716d1fd0b4cfde64c8626"}], "s": {"y": 595, "x": 888, "u": "https://preview.redd.it/kmprus0sl4lb1.png?width=888&amp;format=png&amp;auto=webp&amp;s=15e3b9b4ad388a61703d4ad493e4e8ab73e721dc"}, "id": "kmprus0sl4lb1"}}, "name": "t3_164wqna", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/E_ZRt0l6CtOgAPQ4k4LdyI2_1A7X12L4-hTct2UqdNo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693348447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I need some help, hopefully this is the right sub.&lt;/p&gt;\n\n&lt;p&gt;I have a plex server (Qnap TRV-573e) with 4 16tb Ironwolf Pro drives and 1 Samsung 960Evo+. My plex server lives on the Evo and my media is on the Wolfs.&lt;/p&gt;\n\n&lt;p&gt;I got a warning I am out of storage space and when I looked I found this:&lt;/p&gt;\n\n&lt;p&gt;Storage Pool 1 - 43.63TB&lt;br/&gt;\nDataVol 1 - 21.26TB (Thick volume) FULL&lt;/p&gt;\n\n&lt;p&gt;What do I do? Do I need to merge the pools? And if so, how?  &lt;/p&gt;\n\n&lt;p&gt;Linux OS&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate some assistance.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/88t2lunel4lb1.png?width=1919&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2d9d0b6449c9cd50239a0436188e2fc259ea86c4\"&gt;https://preview.redd.it/88t2lunel4lb1.png?width=1919&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2d9d0b6449c9cd50239a0436188e2fc259ea86c4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/k7dtc7aml4lb1.png?width=1114&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b2ca71601fcedbdb5fac16867974068790fffb42\"&gt;https://preview.redd.it/k7dtc7aml4lb1.png?width=1114&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b2ca71601fcedbdb5fac16867974068790fffb42&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/kmprus0sl4lb1.png?width=888&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=15e3b9b4ad388a61703d4ad493e4e8ab73e721dc\"&gt;https://preview.redd.it/kmprus0sl4lb1.png?width=888&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=15e3b9b4ad388a61703d4ad493e4e8ab73e721dc&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dw0vlfaul4lb1.png?width=797&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f926c95da49b9d1eaa326d4edb307d7abf0ba226\"&gt;https://preview.redd.it/dw0vlfaul4lb1.png?width=797&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f926c95da49b9d1eaa326d4edb307d7abf0ba226&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/icxvj5z0m4lb1.png?width=1146&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ad372bf070fa38962d34058c4531075954023f76\"&gt;https://preview.redd.it/icxvj5z0m4lb1.png?width=1146&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ad372bf070fa38962d34058c4531075954023f76&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164wqna", "is_robot_indexable": true, "report_reasons": null, "author": "Korringadinga", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164wqna/help_with_raid5_out_of_storage_but_i_have_43tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164wqna/help_with_raid5_out_of_storage_but_i_have_43tb/", "subreddit_subscribers": 700738, "created_utc": 1693348447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anybody if we can and especially HOW to undo a deletion on Czkawka?\n\nI thought it was going to delete only the selected files but it seemed to have deleted everything cause I selected \"delete all\"", "author_fullname": "t2_rkszq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to undo on Czkawka?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164sjn7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693338967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anybody if we can and especially HOW to undo a deletion on Czkawka?&lt;/p&gt;\n\n&lt;p&gt;I thought it was going to delete only the selected files but it seemed to have deleted everything cause I selected &amp;quot;delete all&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164sjn7", "is_robot_indexable": true, "report_reasons": null, "author": "rediteux", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164sjn7/how_to_undo_on_czkawka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164sjn7/how_to_undo_on_czkawka/", "subreddit_subscribers": 700738, "created_utc": 1693338967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, just investigating which burner should I buy in order to backup my stuff to M-DISK. \n\nIn [tech spec](https://www.asus.com/us/motherboards-components/optical-drives/external-dvd-drive/zendrive-u9m-sdrw-08u9m-u/techspec/) is written that there is support for M-DISK (write x 4 and read x 8). \n\nAny information about it? Anyone tried this ASUS writer with M-DISKs and different sizes (25, 50 or even 100 GB)?\n\nIt looks too cheap for standard Blu-ray/M-DISK writers (mostly above 100 $).\n\n&amp;#x200B;", "author_fullname": "t2_cuk0x87h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Asus ZenDrive U9M (SDRW-08U9M-U) and M-DISKs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165cwe5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693397301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, just investigating which burner should I buy in order to backup my stuff to M-DISK. &lt;/p&gt;\n\n&lt;p&gt;In &lt;a href=\"https://www.asus.com/us/motherboards-components/optical-drives/external-dvd-drive/zendrive-u9m-sdrw-08u9m-u/techspec/\"&gt;tech spec&lt;/a&gt; is written that there is support for M-DISK (write x 4 and read x 8). &lt;/p&gt;\n\n&lt;p&gt;Any information about it? Anyone tried this ASUS writer with M-DISKs and different sizes (25, 50 or even 100 GB)?&lt;/p&gt;\n\n&lt;p&gt;It looks too cheap for standard Blu-ray/M-DISK writers (mostly above 100 $).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165cwe5", "is_robot_indexable": true, "report_reasons": null, "author": "NTBBT", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165cwe5/asus_zendrive_u9m_sdrw08u9mu_and_mdisks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165cwe5/asus_zendrive_u9m_sdrw08u9mu_and_mdisks/", "subreddit_subscribers": 700738, "created_utc": 1693397301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an UnRaid server that I primarily use for Plex, storing photos and backups of my PC, Laptop, and Phone. Currently it uses three dives, an 120GB M.2 cache disk, 6TB Storage HDD, and a 6 TB Parity HDD. It's nearing full and I'd like to future-proof it, so my plan is to buy another 6TB drive and an 18TB drive. Then, run the three 6TB drives as an array, with the 18TB to serve as a parity drive. Is this an efficient setup? Is it dangerous to put all my eggs in one basket with a single parity drive?", "author_fullname": "t2_12ekn1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most Efficient UnRaid Setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164u378", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693342430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an UnRaid server that I primarily use for Plex, storing photos and backups of my PC, Laptop, and Phone. Currently it uses three dives, an 120GB M.2 cache disk, 6TB Storage HDD, and a 6 TB Parity HDD. It&amp;#39;s nearing full and I&amp;#39;d like to future-proof it, so my plan is to buy another 6TB drive and an 18TB drive. Then, run the three 6TB drives as an array, with the 18TB to serve as a parity drive. Is this an efficient setup? Is it dangerous to put all my eggs in one basket with a single parity drive?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164u378", "is_robot_indexable": true, "report_reasons": null, "author": "senpizzle", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164u378/most_efficient_unraid_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164u378/most_efficient_unraid_setup/", "subreddit_subscribers": 700738, "created_utc": 1693342430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been thinking of building a Nas recently, and I have been wondering if it would make sense to have paired drives be 1SSD + 1HDD instead of 2HDD. The reasoning being that different storage mediums won't ever fail at the same time. Does this makes sense or should I just di HDDs?", "author_fullname": "t2_10rjio", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about paired drives in a server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164txq0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693342079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking of building a Nas recently, and I have been wondering if it would make sense to have paired drives be 1SSD + 1HDD instead of 2HDD. The reasoning being that different storage mediums won&amp;#39;t ever fail at the same time. Does this makes sense or should I just di HDDs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164txq0", "is_robot_indexable": true, "report_reasons": null, "author": "CirnoIzumi", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164txq0/question_about_paired_drives_in_a_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164txq0/question_about_paired_drives_in_a_server/", "subreddit_subscribers": 700738, "created_utc": 1693342079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm backing up a bunch of drives to my NAS and I want to make sure all is good before I backup to cloud and delete from the drives. I'm hoping for a program that will go through every file in every folder, hash it and verify they're the same and in the end give me a list of files/folders that are either not present in the first location or have hashes that do not match.\n\nI'm sure there is something that does this I just don't know the name for it", "author_fullname": "t2_n8citdgq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a program to verify files after they have been backed up to NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165gjn3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693406339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m backing up a bunch of drives to my NAS and I want to make sure all is good before I backup to cloud and delete from the drives. I&amp;#39;m hoping for a program that will go through every file in every folder, hash it and verify they&amp;#39;re the same and in the end give me a list of files/folders that are either not present in the first location or have hashes that do not match.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure there is something that does this I just don&amp;#39;t know the name for it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165gjn3", "is_robot_indexable": true, "report_reasons": null, "author": "CantPassReCAPTCHA", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165gjn3/is_there_a_program_to_verify_files_after_they/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165gjn3/is_there_a_program_to_verify_files_after_they/", "subreddit_subscribers": 700738, "created_utc": 1693406339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My WD drive started behaving weirdly at some point - first took a long time to get recognized in BIOS, restarted when reading/writing every few seconds, then at some point Windows stopped booting with it connected at all (even when hot plugged - it just freezes until drive is disconnected).\nI used HDDSuperClone to clone all of its data to new Seagate Barracuda drive, which was successful (100%). Now I want to completely erase WD drive and return it. How can I do it? Since Windows freaks out when it's connected, I guess I should use a boot USB like HDDSuperClone Xubuntu. What tools can I use?", "author_fullname": "t2_9edwyaot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I fully erase faulty WD Blue drive in order to return it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165fdc3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693403572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My WD drive started behaving weirdly at some point - first took a long time to get recognized in BIOS, restarted when reading/writing every few seconds, then at some point Windows stopped booting with it connected at all (even when hot plugged - it just freezes until drive is disconnected).\nI used HDDSuperClone to clone all of its data to new Seagate Barracuda drive, which was successful (100%). Now I want to completely erase WD drive and return it. How can I do it? Since Windows freaks out when it&amp;#39;s connected, I guess I should use a boot USB like HDDSuperClone Xubuntu. What tools can I use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165fdc3", "is_robot_indexable": true, "report_reasons": null, "author": "Wapapamow", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165fdc3/how_can_i_fully_erase_faulty_wd_blue_drive_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165fdc3/how_can_i_fully_erase_faulty_wd_blue_drive_in/", "subreddit_subscribers": 700738, "created_utc": 1693403572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Amazon has the 22TB WD Red Pro NAS Internal Hard Drive HDD - 7200 RPM, SATA 6 Gb/s, CMR, 512 MB Cache for sale new at $230.63, or $10.48/TB. This is shipped and sold by Amazon, not a 3rd party vendor. I had an alert setup on Keepa (browser add-on / extension or cell app) for $320, &amp; got an email a few hours ago that it went on sale at this price. A bit larger than my needs, but can't pass up the $/TB.", "author_fullname": "t2_4dlr4en9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "22TB WD Red Pro NAS, 7200 RPM, SATA 6 Gb/s, CMR, 512 MB Cache", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165g5kz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693405416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Amazon has the 22TB WD Red Pro NAS Internal Hard Drive HDD - 7200 RPM, SATA 6 Gb/s, CMR, 512 MB Cache for sale new at $230.63, or $10.48/TB. This is shipped and sold by Amazon, not a 3rd party vendor. I had an alert setup on Keepa (browser add-on / extension or cell app) for $320, &amp;amp; got an email a few hours ago that it went on sale at this price. A bit larger than my needs, but can&amp;#39;t pass up the $/TB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "165g5kz", "is_robot_indexable": true, "report_reasons": null, "author": "-sUx-", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165g5kz/22tb_wd_red_pro_nas_7200_rpm_sata_6_gbs_cmr_512/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165g5kz/22tb_wd_red_pro_nas_7200_rpm_sata_6_gbs_cmr_512/", "subreddit_subscribers": 700738, "created_utc": 1693405416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What's good r/DataHoarder(s),\n\nI'm deep in this media preservation project, trying to figure out how to conditionally re-encode videos based on their OG stats to save space, the end game here is to hit a VMAF score of at least 98.8, making sure I don't skimp on quality for space.\n\nWhile VMAF is a reliable after-the-fact metric, it doesn't lend much guidance for the initial re-encoding settings. Sure, I can use ffprobe to get a snapshot of the original metrics, but when it's go-time for picking those first-round encode settings, that's where I hit a wall.\n\nMy Current Approach is:\n\n1. Get the initial video stream info `ffprobe -v error -select_streams v:0 -show_entries stream=codec_name,height,width,bit_rate -of default=noprint_wrappers=1:nokey=1 video123.mp4`\n2. Then to re-encode based on trial-and-error `ffmpeg -hwaccel cuda -c:v h264_cuvid -i video123.mp4 -c:v hevc_nvenc -rc constqp -preset:v slow -cq 32 -c:a copy video123_HEVC_GPU.mp4`\n3. Then measure the VMAF on each run `ffmpeg -i video123.mp4 -i video123_HEVC_GPU_NEW.mp4 -filter_complex \"[0:v]select=not(mod(n\\,80)),scale=1280:720[main]; [1:v]select=not(mod(n\\,10)),scale=1280:720[ref]; [main][ref]libvmaf\" -an -f null -`\n\n* I've considered manually tweaking encoding settings until I hit the sweet spot, but that's a total time vampire and horribly inefficient. Even if I trim the encoding and down-sample my evals, I'm still stuck playing mad scientist trying to find the right encoding parameters.\n\nSo my questions would be:\n\n1. **Initial Encoding Presets**: Any rules of thumb or formulas for deciding initial re-encoding settings based on the original metrics?\n2. **Efficiency**: Are there any existing tools that could streamline this process and make it less manual?\n\nIf any of y'all got the info on this I'd appreciate it, I'd write out a script to recursively dig though each video in a directory and drop it on GitHub if I could nail this project", "author_fullname": "t2_eai7yd0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Media Preservation Project: How to Conditionally Re-encode Videos for Space Efficiency While Maintaining Quality?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165dzy1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693400641.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693400209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s good &lt;a href=\"/r/DataHoarder\"&gt;r/DataHoarder&lt;/a&gt;(s),&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m deep in this media preservation project, trying to figure out how to conditionally re-encode videos based on their OG stats to save space, the end game here is to hit a VMAF score of at least 98.8, making sure I don&amp;#39;t skimp on quality for space.&lt;/p&gt;\n\n&lt;p&gt;While VMAF is a reliable after-the-fact metric, it doesn&amp;#39;t lend much guidance for the initial re-encoding settings. Sure, I can use ffprobe to get a snapshot of the original metrics, but when it&amp;#39;s go-time for picking those first-round encode settings, that&amp;#39;s where I hit a wall.&lt;/p&gt;\n\n&lt;p&gt;My Current Approach is:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Get the initial video stream info &lt;code&gt;ffprobe -v error -select_streams v:0 -show_entries stream=codec_name,height,width,bit_rate -of default=noprint_wrappers=1:nokey=1 video123.mp4&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Then to re-encode based on trial-and-error &lt;code&gt;ffmpeg -hwaccel cuda -c:v h264_cuvid -i video123.mp4 -c:v hevc_nvenc -rc constqp -preset:v slow -cq 32 -c:a copy video123_HEVC_GPU.mp4&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Then measure the VMAF on each run &lt;code&gt;ffmpeg -i video123.mp4 -i video123_HEVC_GPU_NEW.mp4 -filter_complex &amp;quot;[0:v]select=not(mod(n\\,80)),scale=1280:720[main]; [1:v]select=not(mod(n\\,10)),scale=1280:720[ref]; [main][ref]libvmaf&amp;quot; -an -f null -&lt;/code&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I&amp;#39;ve considered manually tweaking encoding settings until I hit the sweet spot, but that&amp;#39;s a total time vampire and horribly inefficient. Even if I trim the encoding and down-sample my evals, I&amp;#39;m still stuck playing mad scientist trying to find the right encoding parameters.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So my questions would be:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Initial Encoding Presets&lt;/strong&gt;: Any rules of thumb or formulas for deciding initial re-encoding settings based on the original metrics?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;: Are there any existing tools that could streamline this process and make it less manual?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If any of y&amp;#39;all got the info on this I&amp;#39;d appreciate it, I&amp;#39;d write out a script to recursively dig though each video in a directory and drop it on GitHub if I could nail this project&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165dzy1", "is_robot_indexable": true, "report_reasons": null, "author": "JuIi0", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165dzy1/media_preservation_project_how_to_conditionally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165dzy1/media_preservation_project_how_to_conditionally/", "subreddit_subscribers": 700738, "created_utc": 1693400209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, \nI am building a new low powered NAS / Server around an N5105 Motherboard to replace my 11 year old Dell T110ii that was running Windows 10 with 3 storage  drives (1x16tb, 1x12tb and 1x5tb) that are pooled together with Stablebit Drive Pool. This has been great for many years as storage as well as Plex Server. \nI was going to go with a NAS specific OS like TrueNAS but it seems I need to buy some more High Capacity drives to actually use the ZFS to have redundancy, where as at the moment with DrivePool I have specific folders (photos, videos and other irriplacebale stuff) duplicated across multiple drives as well as remotely backed up. This means out of the  33tb of total storage I have about 30tb of useable storage with my most important documents and files duplicated across all 3 drives. \n\nI am wanting to reuse my drives, and funds are really not there for another 2 x 16tb drives. With this in mind is sticking with Windows for the new build an ok descion compared to moving over to TrueNAS and with purchasing new drives or losing a ton of storage. \n\nThanks.", "author_fullname": "t2_77qyrr6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing an OS for new Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1659mpe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693386898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, \nI am building a new low powered NAS / Server around an N5105 Motherboard to replace my 11 year old Dell T110ii that was running Windows 10 with 3 storage  drives (1x16tb, 1x12tb and 1x5tb) that are pooled together with Stablebit Drive Pool. This has been great for many years as storage as well as Plex Server. \nI was going to go with a NAS specific OS like TrueNAS but it seems I need to buy some more High Capacity drives to actually use the ZFS to have redundancy, where as at the moment with DrivePool I have specific folders (photos, videos and other irriplacebale stuff) duplicated across multiple drives as well as remotely backed up. This means out of the  33tb of total storage I have about 30tb of useable storage with my most important documents and files duplicated across all 3 drives. &lt;/p&gt;\n\n&lt;p&gt;I am wanting to reuse my drives, and funds are really not there for another 2 x 16tb drives. With this in mind is sticking with Windows for the new build an ok descion compared to moving over to TrueNAS and with purchasing new drives or losing a ton of storage. &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1659mpe", "is_robot_indexable": true, "report_reasons": null, "author": "EquivalentTip4103", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1659mpe/choosing_an_os_for_new_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1659mpe/choosing_an_os_for_new_server/", "subreddit_subscribers": 700738, "created_utc": 1693386898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was suggested to get a recertified drive from SPD if I need a good deal on a large capacity hard drive. Currently running out of space on my 5TB storage drive, I'm looking to replace my 2TB Seagate SSHD that I've had for a long time with a much higher capacity drive, and keep my most critical data (none of it is life-ruining, just difficult to re-acquire) mirrored on the 5TB drive on the off chance the large capacity drive fails. A 12TB drive will serve me well, so I'll most likely be buying one with that capacity unless SPD has a good deal on something larger so that it's only marginally more expensive.\n\nThis is mostly to store lots of pictures and videos, drive will be accessed fairly often, usually several times a day at least. Also would like to do a lot of long video recording of my games, the software I'm using records it at 60Mbps so I don't think any performance differences would matter, right?\n\nSo I guess it's just down to reliability and whether any of these drives have known issues that would make them not good for my use. I don't mind noise as long as it's not ABSURDLY loud, I've had some somewhat loud drives and don't mind them. Would love any advice. ~$130 is going to be my hard limit, but the cheaper the better.", "author_fullname": "t2_ai6ta20bv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos, WD Ultrastar DC, or HGST Ultrastar He12 for my needs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164z1nk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693354201.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693353921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was suggested to get a recertified drive from SPD if I need a good deal on a large capacity hard drive. Currently running out of space on my 5TB storage drive, I&amp;#39;m looking to replace my 2TB Seagate SSHD that I&amp;#39;ve had for a long time with a much higher capacity drive, and keep my most critical data (none of it is life-ruining, just difficult to re-acquire) mirrored on the 5TB drive on the off chance the large capacity drive fails. A 12TB drive will serve me well, so I&amp;#39;ll most likely be buying one with that capacity unless SPD has a good deal on something larger so that it&amp;#39;s only marginally more expensive.&lt;/p&gt;\n\n&lt;p&gt;This is mostly to store lots of pictures and videos, drive will be accessed fairly often, usually several times a day at least. Also would like to do a lot of long video recording of my games, the software I&amp;#39;m using records it at 60Mbps so I don&amp;#39;t think any performance differences would matter, right?&lt;/p&gt;\n\n&lt;p&gt;So I guess it&amp;#39;s just down to reliability and whether any of these drives have known issues that would make them not good for my use. I don&amp;#39;t mind noise as long as it&amp;#39;s not ABSURDLY loud, I&amp;#39;ve had some somewhat loud drives and don&amp;#39;t mind them. Would love any advice. ~$130 is going to be my hard limit, but the cheaper the better.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "164z1nk", "is_robot_indexable": true, "report_reasons": null, "author": "RelevantSeat7203", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164z1nk/seagate_exos_wd_ultrastar_dc_or_hgst_ultrastar/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164z1nk/seagate_exos_wd_ultrastar_dc_or_hgst_ultrastar/", "subreddit_subscribers": 700738, "created_utc": 1693353921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just have one of  dead drive [WD My Passport](https://www.amazon.com/Western-Digital-Passport-Portable-External/dp/B01LQQHI8I) which sniffed my backup data away. I was wondering if its possible to use the enclosure case for [2.5 SSD](https://www.amazon.com/Kodak-Internal-X150-Yellow-960GB/dp/B07RBZPWTV?crid=3LCYEA9ON8S13&amp;keywords=kodak%2Bssd&amp;qid=1680129932&amp;sprefix=kodak%2Bssd%2Caps%2C93&amp;sr=8-5&amp;ufe=app_do%3Aamzn1.fos.006c50ae-5d4c-4777-9bc0-4513d670b6bc&amp;linkCode=sl1&amp;tag=cmn1973-20&amp;linkId=f4bb6463baf387b423b79e9736a750fa&amp;language=en_US&amp;ref_=as_li_ss_tl&amp;th=1)?\n\nI am not sure if the WD My Passport enclosure uses 2.5 Inch 7mm-9.5mm SATA for HDD/SSD. Any ideas?", "author_fullname": "t2_b6zso", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reuse dead My Passport HDD enclosure for another SSD or HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_164y4yk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693351729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just have one of  dead drive &lt;a href=\"https://www.amazon.com/Western-Digital-Passport-Portable-External/dp/B01LQQHI8I\"&gt;WD My Passport&lt;/a&gt; which sniffed my backup data away. I was wondering if its possible to use the enclosure case for &lt;a href=\"https://www.amazon.com/Kodak-Internal-X150-Yellow-960GB/dp/B07RBZPWTV?crid=3LCYEA9ON8S13&amp;amp;keywords=kodak%2Bssd&amp;amp;qid=1680129932&amp;amp;sprefix=kodak%2Bssd%2Caps%2C93&amp;amp;sr=8-5&amp;amp;ufe=app_do%3Aamzn1.fos.006c50ae-5d4c-4777-9bc0-4513d670b6bc&amp;amp;linkCode=sl1&amp;amp;tag=cmn1973-20&amp;amp;linkId=f4bb6463baf387b423b79e9736a750fa&amp;amp;language=en_US&amp;amp;ref_=as_li_ss_tl&amp;amp;th=1\"&gt;2.5 SSD&lt;/a&gt;?&lt;/p&gt;\n\n&lt;p&gt;I am not sure if the WD My Passport enclosure uses 2.5 Inch 7mm-9.5mm SATA for HDD/SSD. Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "164y4yk", "is_robot_indexable": true, "report_reasons": null, "author": "Climbing_a_Mountain", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/164y4yk/reuse_dead_my_passport_hdd_enclosure_for_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/164y4yk/reuse_dead_my_passport_hdd_enclosure_for_another/", "subreddit_subscribers": 700738, "created_utc": 1693351729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Powderfinger and George Carlin... what an amazing show that must have been. I actually wanted this for the Powderinger performance (which I can't find online), but anything with Carlin in it is a treasure. Anybody know how could source the episode? I tried googling but am out of luck.", "author_fullname": "t2_71u6o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone know whre I can find episode 1593 of Late Show with David Letterman?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_165c853", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693395408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Powderfinger and George Carlin... what an amazing show that must have been. I actually wanted this for the Powderinger performance (which I can&amp;#39;t find online), but anything with Carlin in it is a treasure. Anybody know how could source the episode? I tried googling but am out of luck.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "165c853", "is_robot_indexable": true, "report_reasons": null, "author": "electricmaster23", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/165c853/anyone_know_whre_i_can_find_episode_1593_of_late/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/165c853/anyone_know_whre_i_can_find_episode_1593_of_late/", "subreddit_subscribers": 700738, "created_utc": 1693395408.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}