{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TL:DR I did basic statistics and liked it a whole lot, where can I learn more?\n\nI\u2019m an IT guy at a factory. I\u2019m new to manufacturing and haven\u2019t dealt with large datasets before. \n\nWe brought in a third-party engineering team to help with some problems, and they asked me to run a SQL job for them, convert it to a CSV, and give them this file. That was easy, so I went ahead and got it done. \n\nBut I\u2019m new to the job, and being a hobby coder, I thought maybe a web app dashboard displaying this information would  be much better. I rigged up a quick and dirty dashboard using pandas, plotly, and dash. It was rough. I showed it to the engineer team and they loved it. \n\nThey held my hand and I added a lot of good data, like mean time to repair and mean time between failure. It was fantastic to use basic information and provide real, important data. \n\nI added the ability to sort by year, quarter, month, day, and custom date range. I added the fancy calculations and then dressed it up all pretty. \n\nAnyways, I kinda love it. I\u2019ve spent a lot of time on it the last few days and feel like I\u2019m providing value to the company. I\u2019m interested in learning a bit more. Where do I go from here?", "author_fullname": "t2_847c3ysj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I Stumbled into Data Science\u2026 and I Kinda Love it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u0pqf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 131, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 131, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692308474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL:DR I did basic statistics and liked it a whole lot, where can I learn more?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m an IT guy at a factory. I\u2019m new to manufacturing and haven\u2019t dealt with large datasets before. &lt;/p&gt;\n\n&lt;p&gt;We brought in a third-party engineering team to help with some problems, and they asked me to run a SQL job for them, convert it to a CSV, and give them this file. That was easy, so I went ahead and got it done. &lt;/p&gt;\n\n&lt;p&gt;But I\u2019m new to the job, and being a hobby coder, I thought maybe a web app dashboard displaying this information would  be much better. I rigged up a quick and dirty dashboard using pandas, plotly, and dash. It was rough. I showed it to the engineer team and they loved it. &lt;/p&gt;\n\n&lt;p&gt;They held my hand and I added a lot of good data, like mean time to repair and mean time between failure. It was fantastic to use basic information and provide real, important data. &lt;/p&gt;\n\n&lt;p&gt;I added the ability to sort by year, quarter, month, day, and custom date range. I added the fancy calculations and then dressed it up all pretty. &lt;/p&gt;\n\n&lt;p&gt;Anyways, I kinda love it. I\u2019ve spent a lot of time on it the last few days and feel like I\u2019m providing value to the company. I\u2019m interested in learning a bit more. Where do I go from here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15u0pqf", "is_robot_indexable": true, "report_reasons": null, "author": "Wholegraneee", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15u0pqf/i_stumbled_into_data_science_and_i_kinda_love_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15u0pqf/i_stumbled_into_data_science_and_i_kinda_love_it/", "subreddit_subscribers": 995705, "created_utc": 1692308474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Since notebooks are just fancy json, and it is a pain to version control them and to find changes in lines. What are your go to ways to manage the notebooks? \n\nEdit: I understand that notebooks are primarily used for exploration. But for those who do want to version control, how do you do it?\n\n\nEdit 2: outside of nbclean, and jupytext and some other packages. It\u2019s the Wild West.\n\n\nEdit 3: My project at my job requires that my team shares notebooks with each other while we collaborate. I\u2019m fully aware that\u2019s not the intended use of notebooks. But that\u2019s why I\u2019m asking.", "author_fullname": "t2_7r2a683l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your workflow for version controlling notebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ts083", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 80, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 80, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692299790.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692288882.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since notebooks are just fancy json, and it is a pain to version control them and to find changes in lines. What are your go to ways to manage the notebooks? &lt;/p&gt;\n\n&lt;p&gt;Edit: I understand that notebooks are primarily used for exploration. But for those who do want to version control, how do you do it?&lt;/p&gt;\n\n&lt;p&gt;Edit 2: outside of nbclean, and jupytext and some other packages. It\u2019s the Wild West.&lt;/p&gt;\n\n&lt;p&gt;Edit 3: My project at my job requires that my team shares notebooks with each other while we collaborate. I\u2019m fully aware that\u2019s not the intended use of notebooks. But that\u2019s why I\u2019m asking.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ts083", "is_robot_indexable": true, "report_reasons": null, "author": "blacksnowboader", "discussion_type": null, "num_comments": 111, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ts083/whats_your_workflow_for_version_controlling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ts083/whats_your_workflow_for_version_controlling/", "subreddit_subscribers": 995705, "created_utc": 1692288882.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've got a year left in my PhD (a quant social science), but plan on going into DS after. My department is offering a 2nd advanced SEM course, but I'm not sure if it's worth taking it in my final year since I'll be dissertating and doing some part-time DS work. \n\nDo DS folks ever use SEM? How can I find those DS jobs?", "author_fullname": "t2_rzuzjxcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone ever use Structural Equation Modeling in their work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tulc2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692294795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a year left in my PhD (a quant social science), but plan on going into DS after. My department is offering a 2nd advanced SEM course, but I&amp;#39;m not sure if it&amp;#39;s worth taking it in my final year since I&amp;#39;ll be dissertating and doing some part-time DS work. &lt;/p&gt;\n\n&lt;p&gt;Do DS folks ever use SEM? How can I find those DS jobs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tulc2", "is_robot_indexable": true, "report_reasons": null, "author": "empirical-sadboy", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tulc2/anyone_ever_use_structural_equation_modeling_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tulc2/anyone_ever_use_structural_equation_modeling_in/", "subreddit_subscribers": 995705, "created_utc": 1692294795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Looking to connect with IEs who pursued data science and just talk about their experiences.", "author_fullname": "t2_ukdt78fl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Industrial Engineers on this sub?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15toyn5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692281958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to connect with IEs who pursued data science and just talk about their experiences.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15toyn5", "is_robot_indexable": true, "report_reasons": null, "author": "curioussoul879", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15toyn5/any_industrial_engineers_on_this_sub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15toyn5/any_industrial_engineers_on_this_sub/", "subreddit_subscribers": 995705, "created_utc": 1692281958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm  in the process of creating classification models using a substantial  dataset (approximately an MxM matrix). To enhance the performance of  these models, I'm planning to conduct some feature selection as a  preliminary step. It seems like a common practice to start with variance  filtering, which involves eliminating variables X with var(X) that's  close to zero. Given that my dataset contains variables with varying  orders of magnitude, I'm unsure whether I should scale the data \\[x -  mean(x)\\] / var(x) before or after applying this variance-based feature  selection.\n\nFor context, I'm aiming  to build several models using a batch approach, which includes Logistic  Regression, LDA, QDA, k-NN, Naive Bayes, Decision Trees, Random Forest,  XGBoost, BART, among others. I would greatly appreciate any insights into the optimal sequence for these preprocessing steps. Thanks in  advance.\n\n&amp;#x200B;\n\nEdit: As pointed out by others, I translated 'normalization' from portuguese and the correct english term is 'scaling'.", "author_fullname": "t2_2eskgesr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature Selection - Normalization Before or After?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u6esb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692324789.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692322522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m  in the process of creating classification models using a substantial  dataset (approximately an MxM matrix). To enhance the performance of  these models, I&amp;#39;m planning to conduct some feature selection as a  preliminary step. It seems like a common practice to start with variance  filtering, which involves eliminating variables X with var(X) that&amp;#39;s  close to zero. Given that my dataset contains variables with varying  orders of magnitude, I&amp;#39;m unsure whether I should scale the data [x -  mean(x)] / var(x) before or after applying this variance-based feature  selection.&lt;/p&gt;\n\n&lt;p&gt;For context, I&amp;#39;m aiming  to build several models using a batch approach, which includes Logistic  Regression, LDA, QDA, k-NN, Naive Bayes, Decision Trees, Random Forest,  XGBoost, BART, among others. I would greatly appreciate any insights into the optimal sequence for these preprocessing steps. Thanks in  advance.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: As pointed out by others, I translated &amp;#39;normalization&amp;#39; from portuguese and the correct english term is &amp;#39;scaling&amp;#39;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15u6esb", "is_robot_indexable": true, "report_reasons": null, "author": "luxirio", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15u6esb/feature_selection_normalization_before_or_after/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15u6esb/feature_selection_normalization_before_or_after/", "subreddit_subscribers": 995705, "created_utc": 1692322522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently doing so exam outcome modelling and have been fitting mixed effects logistic regression models (trying to capture some cohort effects and repeating students amongst other quirks).  I have done a bit of searching but haven't really found references for the method or examples (both published or blog form) that line up well to what I'm doing.  \n\nIf anyone can point me to either references and/or examples it would be much appreciated.  Even better if it's in R (currently using glmer() function but not completely confident on a couple of the parameters). ", "author_fullname": "t2_cjwojukg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for mixed effects logistic regression references/examples (esp. exam/education based)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ucgk4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692340129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently doing so exam outcome modelling and have been fitting mixed effects logistic regression models (trying to capture some cohort effects and repeating students amongst other quirks).  I have done a bit of searching but haven&amp;#39;t really found references for the method or examples (both published or blog form) that line up well to what I&amp;#39;m doing.  &lt;/p&gt;\n\n&lt;p&gt;If anyone can point me to either references and/or examples it would be much appreciated.  Even better if it&amp;#39;s in R (currently using glmer() function but not completely confident on a couple of the parameters). &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ucgk4", "is_robot_indexable": true, "report_reasons": null, "author": "DrLyndonWalker", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ucgk4/looking_for_mixed_effects_logistic_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ucgk4/looking_for_mixed_effects_logistic_regression/", "subreddit_subscribers": 995705, "created_utc": 1692340129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI am currently working on my post-graduate thesis with a topic on ontology alignment using machine learning techniques. Thus, I am looking for state-of-the-art papers were the writers have implemented ML algorithms to achieve the alignment.\n\nHowever, I don\u2019t where to look for and what source to search at. Can you please share me with relevant sources or with any paper covering the work I am interested in?\n\nThank you for your time!", "author_fullname": "t2_gtzohqb71", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "State-of-the-art Ontology Alignment papers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tknqt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692271528.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am currently working on my post-graduate thesis with a topic on ontology alignment using machine learning techniques. Thus, I am looking for state-of-the-art papers were the writers have implemented ML algorithms to achieve the alignment.&lt;/p&gt;\n\n&lt;p&gt;However, I don\u2019t where to look for and what source to search at. Can you please share me with relevant sources or with any paper covering the work I am interested in?&lt;/p&gt;\n\n&lt;p&gt;Thank you for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tknqt", "is_robot_indexable": true, "report_reasons": null, "author": "Costas_8", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tknqt/stateoftheart_ontology_alignment_papers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tknqt/stateoftheart_ontology_alignment_papers/", "subreddit_subscribers": 995705, "created_utc": 1692271528.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How do you fetch nse option chain data in the notebook? Is there any other way than web scrapping?", "author_fullname": "t2_qdpyy2g2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Fetching for Options", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tk8if", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692270312.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you fetch nse option chain data in the notebook? Is there any other way than web scrapping?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tk8if", "is_robot_indexable": true, "report_reasons": null, "author": "simply_curious_47", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tk8if/data_fetching_for_options/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tk8if/data_fetching_for_options/", "subreddit_subscribers": 995705, "created_utc": 1692270312.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've encountered an intriguing challenge with my VGG16 model, and I'm seeking some expert insights to help me out. \ud83e\udd14\n\n&amp;#x200B;\n\nBackground:\n\nI've successfully trained a VGG16 model on a custom dataset containing 50 individuals, and it's been working like a charm! But now, I've hit a roadblock as I try to expand my model to accommodate an additional 50 individuals without compromising its ability to recognize the initial 50.\n\n&amp;#x200B;\n\nThe Dilemma:\n\nHere's where things get puzzling. Even though the model's accuracy hovers around an impressive 97-98%, and there's no apparent overfitting issue, it seems to only predict accurately on 1 or 2 individuals after incorporating the new dataset. It's as if the model is having a hard time retaining its initial knowledge while adapting to the new data.\n\n&amp;#x200B;\n\nThe Mystery Unveiled:\n\nI've taken care to ensure that my model doesn't overfit, and the accuracy metrics appear to validate this. So, what could be causing this unexpected behavior? Could it be a matter of data distribution, feature extraction, or something else entirely?\n\n&amp;#x200B;\n\nCalling for Your Expertise:\n\nIf you've got experience with complex neural networks, transfer learning, or just a knack for troubleshooting these kinds of issues, I'd love to hear your thoughts! How can I preserve the knowledge of the initial 50 individuals while expanding my model's capability to recognize all 100? Any guidance, theories, or practical solutions are more than welcome!", "author_fullname": "t2_8avfp5ct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Challenges Expanding VGG16 Model to Recognize 100 People - Seeking Advice!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ubvfz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692338221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve encountered an intriguing challenge with my VGG16 model, and I&amp;#39;m seeking some expert insights to help me out. \ud83e\udd14&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Background:&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve successfully trained a VGG16 model on a custom dataset containing 50 individuals, and it&amp;#39;s been working like a charm! But now, I&amp;#39;ve hit a roadblock as I try to expand my model to accommodate an additional 50 individuals without compromising its ability to recognize the initial 50.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The Dilemma:&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s where things get puzzling. Even though the model&amp;#39;s accuracy hovers around an impressive 97-98%, and there&amp;#39;s no apparent overfitting issue, it seems to only predict accurately on 1 or 2 individuals after incorporating the new dataset. It&amp;#39;s as if the model is having a hard time retaining its initial knowledge while adapting to the new data.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The Mystery Unveiled:&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve taken care to ensure that my model doesn&amp;#39;t overfit, and the accuracy metrics appear to validate this. So, what could be causing this unexpected behavior? Could it be a matter of data distribution, feature extraction, or something else entirely?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Calling for Your Expertise:&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve got experience with complex neural networks, transfer learning, or just a knack for troubleshooting these kinds of issues, I&amp;#39;d love to hear your thoughts! How can I preserve the knowledge of the initial 50 individuals while expanding my model&amp;#39;s capability to recognize all 100? Any guidance, theories, or practical solutions are more than welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ubvfz", "is_robot_indexable": true, "report_reasons": null, "author": "JuniorSM17", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ubvfz/challenges_expanding_vgg16_model_to_recognize_100/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ubvfz/challenges_expanding_vgg16_model_to_recognize_100/", "subreddit_subscribers": 995705, "created_utc": 1692338221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[P] Perspectives wanted! Towards PRODUCTION ready AI pipelines (Part2)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uar7r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_uamr9xer", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "MachineLearning", "selftext": "It\u2019s me again! I made progress, added a new scale for measurement, and got many more questions!\n\nTo recap, I'm embarking on an experiment that moves beyond the familiar \"thin OpenAI wrapper\" trend, aiming to develop a more practical solution for real-world production scenarios.\n\nHere\u2019s the current thinking where I included your thoughts and came up with in this blog post:  [https://www.prometh.ai/promethai-memory-blog-post-one](https://www.prometh.ai/promethai-memory-blog-post-one)\n\nThis was my post from earlier: [https://www.reddit.com/r/MachineLearning/comments/15klgt9/p\\_looking\\_for\\_perspectives\\_pdf\\_parsing\\_meets/](https://www.reddit.com/r/MachineLearning/comments/15klgt9/p_looking_for_perspectives_pdf_parsing_meets/)\n\nI'm committed to addressing the challenges of unreliable data pipelines that pervade the landscape. Rather than adhering to the trend of simplistic AI wrappers, I'm delving into a deeper exploration of building dependable data pipelines that employ OpenAI for schema management and inference.\n\nMy current questions revolve around the scalability of code both horizontally and vertically, suitable logging and tracing mechanisms, and effective methods for extending and maintaining my own data within a stateful context.\n\n&amp;#x200B;\n\n### How would you approach these next steps?\n\n&amp;#x200B;\n\n* Do you feel the scale of maturity is complete? What would you add or change about it? Image in the post.\n* What strategies do you suggest for scaling systems effectively and preparing them for future challenges? Here\u2019s how I deal with schema: [Github link](https://github.com/topoteretes/PromethAI-Memory/blob/main/level_1/ticket_schema.json)\n* VectorDB: I am using Weaviate, because of dlt\u2019s wrapper;\n* I've shared an example [**here**](https://github.com/topoteretes/PromethAI-Memory/tree/main/level_1) where I process PDFs through a simple pipeline. What improvements could you propose?\n\nFeel free to use my project on [\u2b50 GitHub \u2b50](https://github.com/topoteretes/PromethAI-Memory) and consider giving it a star **\u2b50** if it resonates with you!\n\nNext, I'm mapping out the following steps, I will take your input and do a follow up here.\n\n&amp;#x200B;\n\n* Establishing a usability scale with your insights.\n* Enhancing model consistency, incorporating domain knowledge, and crafting basic user agents.\n* Presenting schema inference, fundamental contracting, and structured handling of unstructured data.\n* Developing a memory component to manage vector database-stored data as an AI data warehouse.\n* Determining the most effective approach to introducing this previously unavailable use case to the public.\n\nLooking forward to your perspectives!", "author_fullname": "t2_60oe486q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[P] Perspectives wanted! Towards PRODUCTION ready AI pipelines (Part2)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/MachineLearning", "hidden": false, "pwls": 6, "link_flair_css_class": "four", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ts3u9", "quarantine": false, "link_flair_text_color": null, "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Project", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692289111.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It\u2019s me again! I made progress, added a new scale for measurement, and got many more questions!&lt;/p&gt;\n\n&lt;p&gt;To recap, I&amp;#39;m embarking on an experiment that moves beyond the familiar &amp;quot;thin OpenAI wrapper&amp;quot; trend, aiming to develop a more practical solution for real-world production scenarios.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s the current thinking where I included your thoughts and came up with in this blog post:  &lt;a href=\"https://www.prometh.ai/promethai-memory-blog-post-one\"&gt;https://www.prometh.ai/promethai-memory-blog-post-one&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This was my post from earlier: &lt;a href=\"https://www.reddit.com/r/MachineLearning/comments/15klgt9/p_looking_for_perspectives_pdf_parsing_meets/\"&gt;https://www.reddit.com/r/MachineLearning/comments/15klgt9/p_looking_for_perspectives_pdf_parsing_meets/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m committed to addressing the challenges of unreliable data pipelines that pervade the landscape. Rather than adhering to the trend of simplistic AI wrappers, I&amp;#39;m delving into a deeper exploration of building dependable data pipelines that employ OpenAI for schema management and inference.&lt;/p&gt;\n\n&lt;p&gt;My current questions revolve around the scalability of code both horizontally and vertically, suitable logging and tracing mechanisms, and effective methods for extending and maintaining my own data within a stateful context.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h3&gt;How would you approach these next steps?&lt;/h3&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Do you feel the scale of maturity is complete? What would you add or change about it? Image in the post.&lt;/li&gt;\n&lt;li&gt;What strategies do you suggest for scaling systems effectively and preparing them for future challenges? Here\u2019s how I deal with schema: &lt;a href=\"https://github.com/topoteretes/PromethAI-Memory/blob/main/level_1/ticket_schema.json\"&gt;Github link&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;VectorDB: I am using Weaviate, because of dlt\u2019s wrapper;&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve shared an example &lt;a href=\"https://github.com/topoteretes/PromethAI-Memory/tree/main/level_1\"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; where I process PDFs through a simple pipeline. What improvements could you propose?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Feel free to use my project on &lt;a href=\"https://github.com/topoteretes/PromethAI-Memory\"&gt;\u2b50 GitHub \u2b50&lt;/a&gt; and consider giving it a star &lt;strong&gt;\u2b50&lt;/strong&gt; if it resonates with you!&lt;/p&gt;\n\n&lt;p&gt;Next, I&amp;#39;m mapping out the following steps, I will take your input and do a follow up here.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Establishing a usability scale with your insights.&lt;/li&gt;\n&lt;li&gt;Enhancing model consistency, incorporating domain knowledge, and crafting basic user agents.&lt;/li&gt;\n&lt;li&gt;Presenting schema inference, fundamental contracting, and structured handling of unstructured data.&lt;/li&gt;\n&lt;li&gt;Developing a memory component to manage vector database-stored data as an AI data warehouse.&lt;/li&gt;\n&lt;li&gt;Determining the most effective approach to introducing this previously unavailable use case to the public.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Looking forward to your perspectives!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?auto=webp&amp;s=8a07da55d43d118874e63e6b9e99ac7b1b5e6f58", "width": 2000, "height": 927}, "resolutions": [{"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b650f8bbb622ed7a2154e746af5c5e04dbf0ad8a", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8fb5fa84afa7e8da7a3854f6f56735a04c54e37f", "width": 216, "height": 100}, {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c2bbf31f1f3de6c1f6d86c3b7ac090564776d78", "width": 320, "height": 148}, {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=28b080e3fcb94a1668f66cf678d6089284c17185", "width": 640, "height": 296}, {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2a1099abc1c27d1cfd59713108130fb9043f28e0", "width": 960, "height": 444}, {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4eae2c2d8d07caa02d5b0f303fa6d8ccfd7f64df", "width": 1080, "height": 500}], "variants": {}, "id": "7Ye6514uao_bmhEEff2s-hCaLqylM6YxU-xgQnExkSU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r3gv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "15ts3u9", "is_robot_indexable": true, "report_reasons": null, "author": "Snoo-bedooo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/MachineLearning/comments/15ts3u9/p_perspectives_wanted_towards_production_ready_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/MachineLearning/comments/15ts3u9/p_perspectives_wanted_towards_production_ready_ai/", "subreddit_subscribers": 2750839, "created_utc": 1692289111.0, "num_crossposts": 4, "media": null, "is_video": false}], "created": 1692334772.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.MachineLearning", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/MachineLearning/comments/15ts3u9/p_perspectives_wanted_towards_production_ready_ai/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?auto=webp&amp;s=8a07da55d43d118874e63e6b9e99ac7b1b5e6f58", "width": 2000, "height": 927}, "resolutions": [{"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b650f8bbb622ed7a2154e746af5c5e04dbf0ad8a", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8fb5fa84afa7e8da7a3854f6f56735a04c54e37f", "width": 216, "height": 100}, {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c2bbf31f1f3de6c1f6d86c3b7ac090564776d78", "width": 320, "height": 148}, {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=28b080e3fcb94a1668f66cf678d6089284c17185", "width": 640, "height": 296}, {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2a1099abc1c27d1cfd59713108130fb9043f28e0", "width": 960, "height": 444}, {"url": "https://external-preview.redd.it/n8-PR50bUxw4oWK7zl1GFdc9MOB-GHxrIgmccNOhUKw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4eae2c2d8d07caa02d5b0f303fa6d8ccfd7f64df", "width": 1080, "height": 500}], "variants": {}, "id": "7Ye6514uao_bmhEEff2s-hCaLqylM6YxU-xgQnExkSU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15uar7r", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_15ts3u9", "author_flair_text_color": null, "permalink": "/r/datascience/comments/15uar7r/p_perspectives_wanted_towards_production_ready_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/MachineLearning/comments/15ts3u9/p_perspectives_wanted_towards_production_ready_ai/", "subreddit_subscribers": 995705, "created_utc": 1692334772.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Recommend YouTube channel which teach good data science and concepts get completely clear", "author_fullname": "t2_uwqakcci", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best YouTuber for data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tzsnq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692306412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recommend YouTube channel which teach good data science and concepts get completely clear&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tzsnq", "is_robot_indexable": true, "report_reasons": null, "author": "Demon_Viper", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tzsnq/best_youtuber_for_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tzsnq/best_youtuber_for_data_science/", "subreddit_subscribers": 995705, "created_utc": 1692306412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hi, I'm currently a student/data analyst intern working on a forecasting model in R. I'll skip the details and methodology for model selection because what interests me is how to properly evaluate a model.\n\nMy data is monthly, and I currently have 103 months of data meaning 103 points.   \n\n\n1-How can I effectively evaluate my ARIMA model? I've read a lot of documentation on this topic, but I'm still confused. My approach has been to split my dataset into a 75% training set and a 25% test set. Then I make predictions using the trained model and calculate metrics like MAPE or RMSE by comparing the predicted values against the actual test values. Is this the right methodology? What happens if I get different results by changing the size of the training and test windows, with one model performing worse than the other when he was better with first trainning and test set ?\n\n2-Are 103 data points sufficient for cross-validation?\n\n3-As a data analyst, I work extensively with Power BI in my company. This tool provides a forecasting option with very few parameters to choose from. Additionally, there's no way to access the internals of this model to, for example, perform cross-validation. My concern is that while I achieve satisfactory results with both Power BI and my ARIMA model in R, I would like to determine which one is the best . How can I compare these two models, especially considering that I can't perform cross-validation on the Power BI model ? The goal is to explain why my ARIMA model is superior or not to the Power BI model.\n\n4-My data is updated every month. Should I reevaluate and readjust my model each month with the new data ?   \n", "author_fullname": "t2_txt0cja7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help with Evaluation and Cross-validation of ARIMA Models for Time Series Forecasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tyyr9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692304623.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m currently a student/data analyst intern working on a forecasting model in R. I&amp;#39;ll skip the details and methodology for model selection because what interests me is how to properly evaluate a model.&lt;/p&gt;\n\n&lt;p&gt;My data is monthly, and I currently have 103 months of data meaning 103 points.   &lt;/p&gt;\n\n&lt;p&gt;1-How can I effectively evaluate my ARIMA model? I&amp;#39;ve read a lot of documentation on this topic, but I&amp;#39;m still confused. My approach has been to split my dataset into a 75% training set and a 25% test set. Then I make predictions using the trained model and calculate metrics like MAPE or RMSE by comparing the predicted values against the actual test values. Is this the right methodology? What happens if I get different results by changing the size of the training and test windows, with one model performing worse than the other when he was better with first trainning and test set ?&lt;/p&gt;\n\n&lt;p&gt;2-Are 103 data points sufficient for cross-validation?&lt;/p&gt;\n\n&lt;p&gt;3-As a data analyst, I work extensively with Power BI in my company. This tool provides a forecasting option with very few parameters to choose from. Additionally, there&amp;#39;s no way to access the internals of this model to, for example, perform cross-validation. My concern is that while I achieve satisfactory results with both Power BI and my ARIMA model in R, I would like to determine which one is the best . How can I compare these two models, especially considering that I can&amp;#39;t perform cross-validation on the Power BI model ? The goal is to explain why my ARIMA model is superior or not to the Power BI model.&lt;/p&gt;\n\n&lt;p&gt;4-My data is updated every month. Should I reevaluate and readjust my model each month with the new data ?   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tyyr9", "is_robot_indexable": true, "report_reasons": null, "author": "Zuzukxd", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tyyr9/need_help_with_evaluation_and_crossvalidation_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tyyr9/need_help_with_evaluation_and_crossvalidation_of/", "subreddit_subscribers": 995705, "created_utc": 1692304623.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, everyone. I want to calculate the empirical delinquency rate of a retail portfolio on a monthly basis and then attempt to create a custom score. However, I'm encountering some issues:\n\nThe dependent variable is whether the customer experiences a delay of more than 90 days, but a significant portion of the portfolio hasn't reached the end of its financing term yet. For instance, a customer who joined in January 2023, financed the purchase in 12 installments, and has paid all installments up to now could potentially become delinquent in the future. Simply excluding this customer and using only those who have paid all installments or experienced delinquency would seem incorrect and result in insufficient data.\n\nWhat do you suggest for accurately calculating this metric?", "author_fullname": "t2_5414bh1ee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Correct assessment of the empirical delinquency rate in a retail portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tvu30", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692297602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, everyone. I want to calculate the empirical delinquency rate of a retail portfolio on a monthly basis and then attempt to create a custom score. However, I&amp;#39;m encountering some issues:&lt;/p&gt;\n\n&lt;p&gt;The dependent variable is whether the customer experiences a delay of more than 90 days, but a significant portion of the portfolio hasn&amp;#39;t reached the end of its financing term yet. For instance, a customer who joined in January 2023, financed the purchase in 12 installments, and has paid all installments up to now could potentially become delinquent in the future. Simply excluding this customer and using only those who have paid all installments or experienced delinquency would seem incorrect and result in insufficient data.&lt;/p&gt;\n\n&lt;p&gt;What do you suggest for accurately calculating this metric?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tvu30", "is_robot_indexable": true, "report_reasons": null, "author": "Naive_Jellyfish8628", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tvu30/correct_assessment_of_the_empirical_delinquency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tvu30/correct_assessment_of_the_empirical_delinquency/", "subreddit_subscribers": 995705, "created_utc": 1692297602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys I am doing my final project and the system I am building requires some text-to speech and speech-to text here and there. My initial thought was just to use an API which I actually tried out and it worked out so well. The problem is my supervisor said it is more innovative to train my own model or maybe even fine-tune a pre-trained model which I agree with; the API just felt a little too easy for a final project. I went to do my research and I saw quite a number of pre-trained TTS like Coqui, Tortoise and others. I chose to use Coqui because people said it's more user friendly. The problem is I cannot find any solid guide explaining how it works. I've gone through the documentation but I am still a bit lost. Does anyone know where I can find a proper guide on Coqui TTS and Coqui ASR for the speech-to-text (preferably in a video form). I am also open to learn personally (one-on-one) if any expert here is looking to dish out some knowledge; I could really use it right about now.\n\nThanks!", "author_fullname": "t2_qgn41y2e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need a guide for Coqui TTS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tqc62", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692285109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys I am doing my final project and the system I am building requires some text-to speech and speech-to text here and there. My initial thought was just to use an API which I actually tried out and it worked out so well. The problem is my supervisor said it is more innovative to train my own model or maybe even fine-tune a pre-trained model which I agree with; the API just felt a little too easy for a final project. I went to do my research and I saw quite a number of pre-trained TTS like Coqui, Tortoise and others. I chose to use Coqui because people said it&amp;#39;s more user friendly. The problem is I cannot find any solid guide explaining how it works. I&amp;#39;ve gone through the documentation but I am still a bit lost. Does anyone know where I can find a proper guide on Coqui TTS and Coqui ASR for the speech-to-text (preferably in a video form). I am also open to learn personally (one-on-one) if any expert here is looking to dish out some knowledge; I could really use it right about now.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tqc62", "is_robot_indexable": true, "report_reasons": null, "author": "0sko1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tqc62/i_need_a_guide_for_coqui_tts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tqc62/i_need_a_guide_for_coqui_tts/", "subreddit_subscribers": 995705, "created_utc": 1692285109.0, "num_crossposts": 3, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://github.com/NoteDancing/Note](https://github.com/NoteDancing/Note) This project allows you to easily implement parallel training with the multiprocessing module. ", "author_fullname": "t2_rzfslwau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implement parallel training using the multiprocessing module.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tk7vr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692270263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/NoteDancing/Note\"&gt;https://github.com/NoteDancing/Note&lt;/a&gt; This project allows you to easily implement parallel training with the multiprocessing module. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qKohwpBwLf-gLvR2G8mSK9C0ohbAlPQ8bsx4l59xs4o.jpg?auto=webp&amp;s=6209d7f65815b31673961caf7a50d8f07323f1eb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/qKohwpBwLf-gLvR2G8mSK9C0ohbAlPQ8bsx4l59xs4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9fee49375137a9aed1e52e654a3657765b49b500", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/qKohwpBwLf-gLvR2G8mSK9C0ohbAlPQ8bsx4l59xs4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=27c156cbb806a4d4c480e069c40db0c81251bb25", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/qKohwpBwLf-gLvR2G8mSK9C0ohbAlPQ8bsx4l59xs4o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d41d07adf953cb575e00997f60b7ce50b32f002", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/qKohwpBwLf-gLvR2G8mSK9C0ohbAlPQ8bsx4l59xs4o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6a45aa3b9c2948bd582687c9839722b8b8526e16", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/qKohwpBwLf-gLvR2G8mSK9C0ohbAlPQ8bsx4l59xs4o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=23ce5a6fc23225fecdf1e3bf9102f993fdc18283", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/qKohwpBwLf-gLvR2G8mSK9C0ohbAlPQ8bsx4l59xs4o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d019bcfc7dfe0d2961d48b26a2c4cf1e8e723713", "width": 1080, "height": 540}], "variants": {}, "id": "M72-rm6CttIkeVsH10yPd69eYpi8f-heXBR4cPjkf6E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tk7vr", "is_robot_indexable": true, "report_reasons": null, "author": "NoteDancing", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tk7vr/implement_parallel_training_using_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tk7vr/implement_parallel_training_using_the/", "subreddit_subscribers": 995705, "created_utc": 1692270263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Data Science events are everywhere, and LLM sessions are the ones most attended, may it be virtual or in-person. What LLM topic do you think is more interesting?", "author_fullname": "t2_8glql2df", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What LLM topics, techniques, concepts, or tools are you interested in learning more about?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15uh7ik", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692356008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Science events are everywhere, and LLM sessions are the ones most attended, may it be virtual or in-person. What LLM topic do you think is more interesting?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15uh7ik", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Nerd1979", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15uh7ik/what_llm_topics_techniques_concepts_or_tools_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15uh7ik/what_llm_topics_techniques_concepts_or_tools_are/", "subreddit_subscribers": 995705, "created_utc": 1692356008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "using YFinance...whats the alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ugxhh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_702ch097", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "learnpython", "selftext": "Hello - busy doing a data-analysis tutorial - which uses yfinance. Trying to build finance dashboard.I know lots of YT tutorials talk about yfinance...however I am having a hell of a ride using yfinance. Yesterday the app worked fine. Today running the code - I am getting connection issues. Spending two hours figuring out what is wrong with why data aint being returned etc....Can anyone recommend an alternative to Yfinance? Or what would be the best way to. Using Pandas.....  \n1- get the data once off and store it  \n2- access it locally...  \nI am only using 3 tickers.....", "author_fullname": "t2_702ch097", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "using YFinance...whats the alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learnpython", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ugwgk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692355080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnpython", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello - busy doing a data-analysis tutorial - which uses yfinance. Trying to build finance dashboard.I know lots of YT tutorials talk about yfinance...however I am having a hell of a ride using yfinance. Yesterday the app worked fine. Today running the code - I am getting connection issues. Spending two hours figuring out what is wrong with why data aint being returned etc....Can anyone recommend an alternative to Yfinance? Or what would be the best way to. Using Pandas.....&lt;br/&gt;\n1- get the data once off and store it&lt;br/&gt;\n2- access it locally...&lt;br/&gt;\nI am only using 3 tickers.....&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2r8ot", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ugwgk", "is_robot_indexable": true, "report_reasons": null, "author": "barnez29", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learnpython/comments/15ugwgk/using_yfinancewhats_the_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/learnpython/comments/15ugwgk/using_yfinancewhats_the_alternatives/", "subreddit_subscribers": 734439, "created_utc": 1692355080.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1692355171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.learnpython", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/learnpython/comments/15ugwgk/using_yfinancewhats_the_alternatives/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ugxhh", "is_robot_indexable": true, "report_reasons": null, "author": "barnez29", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_15ugwgk", "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ugxhh/using_yfinancewhats_the_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/learnpython/comments/15ugwgk/using_yfinancewhats_the_alternatives/", "subreddit_subscribers": 995705, "created_utc": 1692355171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am interested in data science but I am confused how much statistics and probab\nility is enough for it to begin with EDA etc things", "author_fullname": "t2_i2fofkmw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Statistics and probability", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ufrm3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692351429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am interested in data science but I am confused how much statistics and probab\nility is enough for it to begin with EDA etc things&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ufrm3", "is_robot_indexable": true, "report_reasons": null, "author": "NaveedNarejo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ufrm3/statistics_and_probability/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ufrm3/statistics_and_probability/", "subreddit_subscribers": 995705, "created_utc": 1692351429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI am responsible for developing a chat interface to engage with various databases in our product.\n\nI initiated this project with a prototype solution you can see here: \\[[**https://blog.streamlit.io/snowchat-leveraging-openais-gpt-for-sql-queries/**](https://blog.streamlit.io/snowchat-leveraging-openais-gpt-for-sql-queries/)\\]. While this prototype serves as a functional model, **the true challenge lies in scaling it to accommodate multiple databases**, especially starting with SQL server, encompassing hundreds of databases and thousands of tables. I wouldn't be able to add DDL in the same way as in this project. I'm wondering how to reproduce this solution to make it work for more tables.\n\nI'm looking for something that could help me with this task. I'm not really sure how to approach it. It could be Github repositories, similar projects, posts - anything.", "author_fullname": "t2_7yv0lkcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaling Chat Interface for Multiple Databases: Seeking Guidance and Resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15udk0x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692343854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am responsible for developing a chat interface to engage with various databases in our product.&lt;/p&gt;\n\n&lt;p&gt;I initiated this project with a prototype solution you can see here: [&lt;a href=\"https://blog.streamlit.io/snowchat-leveraging-openais-gpt-for-sql-queries/\"&gt;&lt;strong&gt;https://blog.streamlit.io/snowchat-leveraging-openais-gpt-for-sql-queries/&lt;/strong&gt;&lt;/a&gt;]. While this prototype serves as a functional model, &lt;strong&gt;the true challenge lies in scaling it to accommodate multiple databases&lt;/strong&gt;, especially starting with SQL server, encompassing hundreds of databases and thousands of tables. I wouldn&amp;#39;t be able to add DDL in the same way as in this project. I&amp;#39;m wondering how to reproduce this solution to make it work for more tables.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for something that could help me with this task. I&amp;#39;m not really sure how to approach it. It could be Github repositories, similar projects, posts - anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/16szqscCbhlUQnkP7VwoYQ_shWzCxEhMqUF3CFo2Xuo.jpg?auto=webp&amp;s=5dc5769f12083cd32dec434423b7b6a730344f64", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/16szqscCbhlUQnkP7VwoYQ_shWzCxEhMqUF3CFo2Xuo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=122036214c48481038d9928ce85c3cfc3d91bfbf", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/16szqscCbhlUQnkP7VwoYQ_shWzCxEhMqUF3CFo2Xuo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b1a28a13b613685fbb4bdd56fd2d16b26c3a6a30", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/16szqscCbhlUQnkP7VwoYQ_shWzCxEhMqUF3CFo2Xuo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e4323659bf5778ad91022c9c81d465d62bb0b8fe", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/16szqscCbhlUQnkP7VwoYQ_shWzCxEhMqUF3CFo2Xuo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=30e11d3f6b41f8c0e30fe2d75fb518e6764d3e86", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/16szqscCbhlUQnkP7VwoYQ_shWzCxEhMqUF3CFo2Xuo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ec113f458c107dcb0f8140d1d92b0ef169584c05", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/16szqscCbhlUQnkP7VwoYQ_shWzCxEhMqUF3CFo2Xuo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=70ff9a181d747711e27db4579768942c6eab79f0", "width": 1080, "height": 567}], "variants": {}, "id": "kW0OtvYP3pGfSsxAa2VYS6KXgFAP5GINXcrWrAhcvX8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15udk0x", "is_robot_indexable": true, "report_reasons": null, "author": "International-Shirt5", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15udk0x/scaling_chat_interface_for_multiple_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15udk0x/scaling_chat_interface_for_multiple_databases/", "subreddit_subscribers": 995705, "created_utc": 1692343854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Im wondering if an actuarial exam P or stats related actuarial exams can help in employment in data science industry, since I don't have a degree, only a diploma in software development.", "author_fullname": "t2_60ml3jxl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Actuarial exams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tutxq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692295317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im wondering if an actuarial exam P or stats related actuarial exams can help in employment in data science industry, since I don&amp;#39;t have a degree, only a diploma in software development.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tutxq", "is_robot_indexable": true, "report_reasons": null, "author": "kxleepy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tutxq/actuarial_exams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tutxq/actuarial_exams/", "subreddit_subscribers": 995705, "created_utc": 1692295317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am looking to build a project around supply chain analysis. What research questions are companies typically interested in when analysing supply chains?", "author_fullname": "t2_4u537ww6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Supply chain analysis - research questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tkmuq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692271463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to build a project around supply chain analysis. What research questions are companies typically interested in when analysing supply chains?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tkmuq", "is_robot_indexable": true, "report_reasons": null, "author": "Blutorangensaft", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tkmuq/supply_chain_analysis_research_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tkmuq/supply_chain_analysis_research_questions/", "subreddit_subscribers": 995705, "created_utc": 1692271463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_lcona1sk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is reporting system and data development?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ub7rx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692336132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ub7rx", "is_robot_indexable": true, "report_reasons": null, "author": "meet5", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ub7rx/what_is_reporting_system_and_data_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ub7rx/what_is_reporting_system_and_data_development/", "subreddit_subscribers": 995705, "created_utc": 1692336132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As title suggest, please suggest me a book which is intuitive and has helped you.\n\nThank you for sharing your experience \u263a\ufe0f", "author_fullname": "t2_2v9c47e3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book recommendation for EDA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tpwdh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692284126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As title suggest, please suggest me a book which is intuitive and has helped you.&lt;/p&gt;\n\n&lt;p&gt;Thank you for sharing your experience \u263a\ufe0f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tpwdh", "is_robot_indexable": true, "report_reasons": null, "author": "joywin11", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tpwdh/book_recommendation_for_eda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tpwdh/book_recommendation_for_eda/", "subreddit_subscribers": 995705, "created_utc": 1692284126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_u3aoa64a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanted to take some advice, I have 2 years of experience as a Data Scientist, and now wanted to get Masters's Degree from the USA, so what degree I should go with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tlkif", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.27, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692274009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15tlkif", "is_robot_indexable": true, "report_reasons": null, "author": "Early_Landscape_7408", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15tlkif/wanted_to_take_some_advice_i_have_2_years_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15tlkif/wanted_to_take_some_advice_i_have_2_years_of/", "subreddit_subscribers": 995705, "created_utc": 1692274009.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}