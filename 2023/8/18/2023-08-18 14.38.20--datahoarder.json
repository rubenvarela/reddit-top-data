{"kind": "Listing", "data": {"after": "t3_15u8hvu", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4aynv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "More than 220 digital games will disappear when the Xbox 360 Store closes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_15u1hi9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 316, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 316, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EUJgF1iZZHBlbs3x1nlwUzzkTk0zxmzgUJog9zP8s0Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692310255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "videogameschronicle.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.videogameschronicle.com/news/analysis-more-than-220-digital-games-will-disappear-when-the-xbox-360-store-closes/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UbPkRGdN_R4RuB-tpsj_hq1fXF3LjEsTSsY8B03jYSk.jpg?auto=webp&amp;s=a176632d1d7f26b3450799480758048cc7737c14", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/UbPkRGdN_R4RuB-tpsj_hq1fXF3LjEsTSsY8B03jYSk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=14a7fbf631900ebb5debec985ec05ed4adcb8871", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/UbPkRGdN_R4RuB-tpsj_hq1fXF3LjEsTSsY8B03jYSk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=809f4ac05dc8c3d83a32e9436637123d46cfb499", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/UbPkRGdN_R4RuB-tpsj_hq1fXF3LjEsTSsY8B03jYSk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=49bd602758b9c7192dfa231e4364730e138024bf", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/UbPkRGdN_R4RuB-tpsj_hq1fXF3LjEsTSsY8B03jYSk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=64435d812c8142a02b4a7559e393fedbe0ac8e2c", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/UbPkRGdN_R4RuB-tpsj_hq1fXF3LjEsTSsY8B03jYSk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=06a866944d297cbff046dceb975b974e81052937", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/UbPkRGdN_R4RuB-tpsj_hq1fXF3LjEsTSsY8B03jYSk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cc75ef3cf02e003f537a6950c45bb5020efbdf6a", "width": 1080, "height": 607}], "variants": {}, "id": "ZSvfp6NKd7KfuapPUAHqhn9kietRnHLXYxG3Tj-2k5A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15u1hi9", "is_robot_indexable": true, "report_reasons": null, "author": "retrac1324", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15u1hi9/more_than_220_digital_games_will_disappear_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.videogameschronicle.com/news/analysis-more-than-220-digital-games-will-disappear-when-the-xbox-360-store-closes/", "subreddit_subscribers": 698566, "created_utc": 1692310255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_1cjqfkwc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What the Hachette v. Internet Archive Decision Means for Our Library", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u20wo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "76c43f34-b98b-11e2-b55c-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "dvd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1692311529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.archive.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.archive.org/2023/08/17/what-the-hachette-v-internet-archive-decision-means-for-our-library/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "DVD", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15u20wo", "is_robot_indexable": true, "report_reasons": null, "author": "koempleh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15u20wo/what_the_hachette_v_internet_archive_decision/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.archive.org/2023/08/17/what-the-hachette-v-internet-archive-decision-means-for-our-library/", "subreddit_subscribers": 698566, "created_utc": 1692311529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I purchased an UHD (4K) BD drive to rip all blu-ray discs, I was eager to use BD discs as a cold storage format for Linux live media and to take backups of my notes. Unfortunately I haven't been able to reliably write data to the medium and when experimenting with `growisofs` apparently one BD-RE is no longer detected by file managers (Nautilus). `xorriso` and K3b (a KDE program) were the most promising but both have deemed even just unsealed BD-discs as non-writable (or didn't detect them in the first place).\n\nThe main disappointment for me was that **Linux doesn't support directly writing data to optical media** -- I'd just have copied my notes directory with rsync (~~`/dev/sr0` is a common mount point for discs~~): \n\n    rsync --archive /home/user/Documents/notes /dev/sr0\n\n When inserting an optical disc, Windows presents the \"how do you want to use this media\" dialog, allowing to use any disc like a USB storage medium.\n\nEven if I manage to find a way to burn discs reliably under Linux, I don't think that I have the capability to verify the data integrity, especially for live media (burning Linux images), outside of confirming the ISO file checksum before burning of course. Considering that optical drives will become increasingly rare and I have absolutely no idea how to check for faulty discs (I don't generally pay a lot of attention to user reviews, but I've seen some suggesting bad BD batches from Verbatim), I think I'll destroy the discs I experimented with, donate away the sealed copies and from now on exclusively use my drive for ripping CD/DVD/BD.\n\n---\n\nFedora 38", "author_fullname": "t2_d4l7lyjhp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "considering giving up with burning Blu-rays on Linux, due to lack of support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ugzuw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692364445.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692355363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I purchased an UHD (4K) BD drive to rip all blu-ray discs, I was eager to use BD discs as a cold storage format for Linux live media and to take backups of my notes. Unfortunately I haven&amp;#39;t been able to reliably write data to the medium and when experimenting with &lt;code&gt;growisofs&lt;/code&gt; apparently one BD-RE is no longer detected by file managers (Nautilus). &lt;code&gt;xorriso&lt;/code&gt; and K3b (a KDE program) were the most promising but both have deemed even just unsealed BD-discs as non-writable (or didn&amp;#39;t detect them in the first place).&lt;/p&gt;\n\n&lt;p&gt;The main disappointment for me was that &lt;strong&gt;Linux doesn&amp;#39;t support directly writing data to optical media&lt;/strong&gt; -- I&amp;#39;d just have copied my notes directory with rsync (&lt;del&gt;&lt;code&gt;/dev/sr0&lt;/code&gt; is a common mount point for discs&lt;/del&gt;): &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;rsync --archive /home/user/Documents/notes /dev/sr0\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When inserting an optical disc, Windows presents the &amp;quot;how do you want to use this media&amp;quot; dialog, allowing to use any disc like a USB storage medium.&lt;/p&gt;\n\n&lt;p&gt;Even if I manage to find a way to burn discs reliably under Linux, I don&amp;#39;t think that I have the capability to verify the data integrity, especially for live media (burning Linux images), outside of confirming the ISO file checksum before burning of course. Considering that optical drives will become increasingly rare and I have absolutely no idea how to check for faulty discs (I don&amp;#39;t generally pay a lot of attention to user reviews, but I&amp;#39;ve seen some suggesting bad BD batches from Verbatim), I think I&amp;#39;ll destroy the discs I experimented with, donate away the sealed copies and from now on exclusively use my drive for ripping CD/DVD/BD.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Fedora 38&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15ugzuw", "is_robot_indexable": true, "report_reasons": null, "author": "sillia-ja-kuolemaa", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ugzuw/considering_giving_up_with_burning_blurays_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ugzuw/considering_giving_up_with_burning_blurays_on/", "subreddit_subscribers": 698566, "created_utc": 1692355363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I like to use macrium to make clone backups of my C drive, but it's getting impractical to keep each individual backup on its own external hd. Can I write the backup to an external hd, copy the contents into a folder on my 10tb internal storage (E drive), and then copy the contents back onto an external hd if ever decide to use it? It seems like it should work\n\nAlso I would keep another backup on an external drive at all times in case the system gets completely shot", "author_fullname": "t2_2d2mk9ky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage solution for Macrium backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u84nt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692327122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I like to use macrium to make clone backups of my C drive, but it&amp;#39;s getting impractical to keep each individual backup on its own external hd. Can I write the backup to an external hd, copy the contents into a folder on my 10tb internal storage (E drive), and then copy the contents back onto an external hd if ever decide to use it? It seems like it should work&lt;/p&gt;\n\n&lt;p&gt;Also I would keep another backup on an external drive at all times in case the system gets completely shot&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15u84nt", "is_robot_indexable": true, "report_reasons": null, "author": "barnayo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15u84nt/storage_solution_for_macrium_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15u84nt/storage_solution_for_macrium_backups/", "subreddit_subscribers": 698566, "created_utc": 1692327122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I have one zpool on a  22TB disk. I don't need redundancy, so I am not considering raidz etc. But I do need to expand capacity of my pools.  If I can figure out a way to add 3 more HDDs to my main pool to have its capacity at 88 TB, how do I take a backup of these 88TBs? \n\nAssume I have 4x 22TB backup HDDs. Is there any way I can connect them one by one as an external device and take incremental backup? If that is dumb, what is the alternative? I guess snapshots are the answer somehow but I am not sure how to use them unless I setup another machine just for backups.\n\nTIA.", "author_fullname": "t2_2lugimc5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zfs and backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u7eki", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692325166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have one zpool on a  22TB disk. I don&amp;#39;t need redundancy, so I am not considering raidz etc. But I do need to expand capacity of my pools.  If I can figure out a way to add 3 more HDDs to my main pool to have its capacity at 88 TB, how do I take a backup of these 88TBs? &lt;/p&gt;\n\n&lt;p&gt;Assume I have 4x 22TB backup HDDs. Is there any way I can connect them one by one as an external device and take incremental backup? If that is dumb, what is the alternative? I guess snapshots are the answer somehow but I am not sure how to use them unless I setup another machine just for backups.&lt;/p&gt;\n\n&lt;p&gt;TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "50TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15u7eki", "is_robot_indexable": true, "report_reasons": null, "author": "logicalcliff", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15u7eki/zfs_and_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15u7eki/zfs_and_backups/", "subreddit_subscribers": 698566, "created_utc": 1692325166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Quite popular in China I believe, not sure if anyone had any experience with them.\n\n\nI\u2019m also going back to China and looking for a good hard drive if anyone could recommend anything \nAnything between 15 to 20 TB", "author_fullname": "t2_ld9gl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone came across KESU hard drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ufnce", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692351022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Quite popular in China I believe, not sure if anyone had any experience with them.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m also going back to China and looking for a good hard drive if anyone could recommend anything \nAnything between 15 to 20 TB&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15ufnce", "is_robot_indexable": true, "report_reasons": null, "author": "AlexKLMan", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ufnce/has_anyone_came_across_kesu_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ufnce/has_anyone_came_across_kesu_hard_drives/", "subreddit_subscribers": 698566, "created_utc": 1692351022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "We have been tracking daily Carvana data including their revenue, number of cars sold, the average selling price, current inventory, price difference between sold price and kelley blue book price, and much more information. We created this dashboard that you can see here to access this information, let us know if you have any thoughts or how best we could use this data. \n\nOne is obviously selling this information to hedge funds, but wondering if there are more strategic players in the automobile space or ancillary service space who may find this information useful.\n\nPublic dashboard here: [app.blinkdata.io](https://app.blinkdata.io)", "author_fullname": "t2_nierpfw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Carvana Daily Revenue, Cars Sold, ASP, Inventory Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ucluo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692340603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have been tracking daily Carvana data including their revenue, number of cars sold, the average selling price, current inventory, price difference between sold price and kelley blue book price, and much more information. We created this dashboard that you can see here to access this information, let us know if you have any thoughts or how best we could use this data. &lt;/p&gt;\n\n&lt;p&gt;One is obviously selling this information to hedge funds, but wondering if there are more strategic players in the automobile space or ancillary service space who may find this information useful.&lt;/p&gt;\n\n&lt;p&gt;Public dashboard here: &lt;a href=\"https://app.blinkdata.io\"&gt;app.blinkdata.io&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15ucluo", "is_robot_indexable": true, "report_reasons": null, "author": "alanliberkeley", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ucluo/carvana_daily_revenue_cars_sold_asp_inventory_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ucluo/carvana_daily_revenue_cars_sold_asp_inventory_data/", "subreddit_subscribers": 698566, "created_utc": 1692340603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently bought a 4 TB EVO (SSD) from Samsung; the problem is, the seller is from a local Amazon marketplace. In my country Samsung only provides warranty for products they manufactured, and this one does not apply, since it's imported.\n\nNote: I am still going to check if the drive a) It's OK, and b) If it's authentic, if I am not mistaken, with the MAGICIAN software. Didn't do yet because I am mounting a new PC and there's still one package from some stuff to be delivered.\n\nSo I asked Samsung-US if they could RMA for me, of course if I ship to them. I also got the full SERIAL NUMBER, which is only available in the drive itself, not the package, which is fully in english, but some parts of the back and front also in chinese.\n\nThe S/N starts with S, then we have a combination of numbers/letters, which end with a \"9\" and \"E\".\n\nThis is what they replied, 2 weeks after I asked (note: \"your seller\" = the name of the online store that used my local Amazon and sold me the drive). The SSD in question has a 5 year warranty, but only 3 months (so 20 times less) with Amazon and the marketplace store:\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\n*Sorry about the delay, we were looking into the drive's origin and we traced it's creation suppose meant for the Chinese Market. This isn't a US Drive so we wouldn't warranty it. It would be Samsung of China. We believe that your seller bought the drive cheaply sold in China to be sold in other parts of the world for a profit. We can confirm on our end that the drive is suppose to be in the Chinese Market and there is no confirmations that we sold it directly to your seller. I personally recommend getting a refund for the product because if you were to warranty it. It would be Samsung of China but even then is depends because your seller seems to be a 3rd party seller.*\n\n*From the provided serial number +++++++++++ we can see that this is an China unit. Samsung warranties are region specific and any service on the unit would need to be performed by Samsung of that region. The product that was sold to you by your retailer is a grey market product. This means the unit was imported into the USA; however, the unit was only meant to be sold within China.*   \n\n*If you wish to be refunded or have the unit exchanged, please contact your original place of purchase as the seller or point of purchase has the obligation and are responsible for providing their clients with products whose warranty is valid in the region in which they live.*   \n\n*If you wish to have the drive serviced, please use either link below to contact Samsung of China so they may set up the warranty claim:*  \n\n[*https://www.samsung.com/us/common/visitlocationsite.html*](https://www.samsung.com/us/common/visitlocationsite.html)  \n\n[*https://www.samsung.com/semiconductor/minisite/ssd/support/cs/*](https://www.samsung.com/semiconductor/minisite/ssd/support/cs/) \n\n *\\*Your warranty is not void, only region specific. Please contact the correct team that correlates to the drives region for further warranty support.*  \n\n*Thank you very much and again we apologize for the inconvenience.*\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nContrary to Samsung, here in Brazil Western Digital offers RMA for these purchases and honor the warranty, the only downside is how much they ask $$$$$$$$$$$$$$ for a similar SSD. After I became aware of all these difficulties, I decided not to buy from Samsung ever again, but that's not the point of this discussion.\n\nI didn't know this term \"grey market\", looked into it, and they seem to suggest this is kinda like buying an official DVD (from a movie) restricted to Europe (so REGION 2 locked), then unlocking the drive and allowing it to play ALL REGIONS. Perhaps that's what the Samsung employee meant?\n\nFrom his response, it seems this is 100% legit, the only problem is that Samsung is imposing some shenanigans to not go forward with a RMA, if I ever needed.\n\nA final question: can Samsung MAGICIAN certify this SSD is legit, and in the end I find out it isn't? Is there a way to make sure it is 100% healthy? Should I fill all 4 TB of data and see if it's all good?", "author_fullname": "t2_1utoiwm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your experience with Samsung SSDs (RMAs)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u77yg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692324669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently bought a 4 TB EVO (SSD) from Samsung; the problem is, the seller is from a local Amazon marketplace. In my country Samsung only provides warranty for products they manufactured, and this one does not apply, since it&amp;#39;s imported.&lt;/p&gt;\n\n&lt;p&gt;Note: I am still going to check if the drive a) It&amp;#39;s OK, and b) If it&amp;#39;s authentic, if I am not mistaken, with the MAGICIAN software. Didn&amp;#39;t do yet because I am mounting a new PC and there&amp;#39;s still one package from some stuff to be delivered.&lt;/p&gt;\n\n&lt;p&gt;So I asked Samsung-US if they could RMA for me, of course if I ship to them. I also got the full SERIAL NUMBER, which is only available in the drive itself, not the package, which is fully in english, but some parts of the back and front also in chinese.&lt;/p&gt;\n\n&lt;p&gt;The S/N starts with S, then we have a combination of numbers/letters, which end with a &amp;quot;9&amp;quot; and &amp;quot;E&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;This is what they replied, 2 weeks after I asked (note: &amp;quot;your seller&amp;quot; = the name of the online store that used my local Amazon and sold me the drive). The SSD in question has a 5 year warranty, but only 3 months (so 20 times less) with Amazon and the marketplace store:&lt;/p&gt;\n\n&lt;p&gt;**********************************************&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Sorry about the delay, we were looking into the drive&amp;#39;s origin and we traced it&amp;#39;s creation suppose meant for the Chinese Market. This isn&amp;#39;t a US Drive so we wouldn&amp;#39;t warranty it. It would be Samsung of China. We believe that your seller bought the drive cheaply sold in China to be sold in other parts of the world for a profit. We can confirm on our end that the drive is suppose to be in the Chinese Market and there is no confirmations that we sold it directly to your seller. I personally recommend getting a refund for the product because if you were to warranty it. It would be Samsung of China but even then is depends because your seller seems to be a 3rd party seller.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;From the provided serial number +++++++++++ we can see that this is an China unit. Samsung warranties are region specific and any service on the unit would need to be performed by Samsung of that region. The product that was sold to you by your retailer is a grey market product. This means the unit was imported into the USA; however, the unit was only meant to be sold within China.&lt;/em&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;If you wish to be refunded or have the unit exchanged, please contact your original place of purchase as the seller or point of purchase has the obligation and are responsible for providing their clients with products whose warranty is valid in the region in which they live.&lt;/em&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;If you wish to have the drive serviced, please use either link below to contact Samsung of China so they may set up the warranty claim:&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.samsung.com/us/common/visitlocationsite.html\"&gt;&lt;em&gt;https://www.samsung.com/us/common/visitlocationsite.html&lt;/em&gt;&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.samsung.com/semiconductor/minisite/ssd/support/cs/\"&gt;&lt;em&gt;https://www.samsung.com/semiconductor/minisite/ssd/support/cs/&lt;/em&gt;&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;\\&lt;/em&gt;Your warranty is not void, only region specific. Please contact the correct team that correlates to the drives region for further warranty support.*  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you very much and again we apologize for the inconvenience.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;**********************************************&lt;/p&gt;\n\n&lt;p&gt;Contrary to Samsung, here in Brazil Western Digital offers RMA for these purchases and honor the warranty, the only downside is how much they ask $$$$$$$$$$$$$$ for a similar SSD. After I became aware of all these difficulties, I decided not to buy from Samsung ever again, but that&amp;#39;s not the point of this discussion.&lt;/p&gt;\n\n&lt;p&gt;I didn&amp;#39;t know this term &amp;quot;grey market&amp;quot;, looked into it, and they seem to suggest this is kinda like buying an official DVD (from a movie) restricted to Europe (so REGION 2 locked), then unlocking the drive and allowing it to play ALL REGIONS. Perhaps that&amp;#39;s what the Samsung employee meant?&lt;/p&gt;\n\n&lt;p&gt;From his response, it seems this is 100% legit, the only problem is that Samsung is imposing some shenanigans to not go forward with a RMA, if I ever needed.&lt;/p&gt;\n\n&lt;p&gt;A final question: can Samsung MAGICIAN certify this SSD is legit, and in the end I find out it isn&amp;#39;t? Is there a way to make sure it is 100% healthy? Should I fill all 4 TB of data and see if it&amp;#39;s all good?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ks9UNbmEfnPN5cO2j_vN76_Twu9gx-vZzfK-kR9kyiw.jpg?auto=webp&amp;s=3b210473ffa6131dc8090a5adb4c79d2aa4a88f1", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/ks9UNbmEfnPN5cO2j_vN76_Twu9gx-vZzfK-kR9kyiw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=837170e0486436712eab84a2d13760b2a783b73f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ks9UNbmEfnPN5cO2j_vN76_Twu9gx-vZzfK-kR9kyiw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=eb047a03823f0a54967470a6b60585c7593218ff", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/ks9UNbmEfnPN5cO2j_vN76_Twu9gx-vZzfK-kR9kyiw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f1a3b78aeda0c753200511e012546db86ad37f4", "width": 320, "height": 320}], "variants": {}, "id": "-rn4g9eV_Q1GEk4-YhHpZ0vFMktQ9p1K-d8oI9ScrrE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15u77yg", "is_robot_indexable": true, "report_reasons": null, "author": "Maratocarde", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15u77yg/whats_your_experience_with_samsung_ssds_rmas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15u77yg/whats_your_experience_with_samsung_ssds_rmas/", "subreddit_subscribers": 698566, "created_utc": 1692324669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a small (around 10 000 files) library of books and scientific papers - mostly PDF, DJVU and EPUB. Most files have a proper text layer, but a small fraction is just scanned pages.\n\nHowever, the filenames are garbage, and files have no metadata. I cannot easily tell if a certain book or article is in my library or not.\n\nIs there a tool or an API that could recognize book and article names from these files? It would have to do some guesswork and maybe even OCR, since the formats and layouts are different, but I was surprised when I couldn't find anything related on the internet.\n\nAny suggestions are welcome!", "author_fullname": "t2_sss3a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Detecting titles for a bunch of books and scientific papers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ts9ke", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692290300.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692289508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a small (around 10 000 files) library of books and scientific papers - mostly PDF, DJVU and EPUB. Most files have a proper text layer, but a small fraction is just scanned pages.&lt;/p&gt;\n\n&lt;p&gt;However, the filenames are garbage, and files have no metadata. I cannot easily tell if a certain book or article is in my library or not.&lt;/p&gt;\n\n&lt;p&gt;Is there a tool or an API that could recognize book and article names from these files? It would have to do some guesswork and maybe even OCR, since the formats and layouts are different, but I was surprised when I couldn&amp;#39;t find anything related on the internet.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions are welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ts9ke", "is_robot_indexable": true, "report_reasons": null, "author": "smthamazing", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ts9ke/detecting_titles_for_a_bunch_of_books_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ts9ke/detecting_titles_for_a_bunch_of_books_and/", "subreddit_subscribers": 698566, "created_utc": 1692289508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi ! \n\nI have a Mac mini M1, and 2 drives attached to it :\n\n* one 500Gb SSD\n* one 4Tb HDD\n\nBoth are internal drives that I put in external enclosures. Now, I would like to have these two in the same enclosure, and I want to be able to add more drives in the future. Please note that I don't want RAID. These data are taken care of by Time Machine and sent to a NAS outside my house. \n\nAlso, I don't have much room on my desk so I think the only one that will fit would be this one : [https://www.amazon.ca/-/fr/gp/product/B0BP2CV1DK/ref=ox\\_sc\\_act\\_title\\_1?smid=A1BEN4AJP68QPC&amp;th=1](https://www.amazon.ca/-/fr/gp/product/B0BP2CV1DK/ref=ox_sc_act_title_1?smid=A1BEN4AJP68QPC&amp;th=1)\n\nIt's USB-C, which is the port I want to use, and as far as I understand, I can configure it to run without RAID. \n\nThere's also this one : [https://www.amazon.ca/-/fr/gp/product/B08DSX95F4/ref=sw\\_img\\_1?smid=A307CH216CTGMP&amp;psc=1](https://www.amazon.ca/-/fr/gp/product/B08DSX95F4/ref=sw_img_1?smid=A307CH216CTGMP&amp;psc=1)\n\nBut I don't think this one is going to fit on my desk. \n\n&amp;#x200B;\n\nAny other recommendations ? Are these two reliable and good products ? Speed transfert is not really an issue. What I don't want is unexpected disconnection or things like that.\n\nThanks !", "author_fullname": "t2_158t6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommendation for an external 4 bay enclosure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tolt8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692281113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi ! &lt;/p&gt;\n\n&lt;p&gt;I have a Mac mini M1, and 2 drives attached to it :&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;one 500Gb SSD&lt;/li&gt;\n&lt;li&gt;one 4Tb HDD&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Both are internal drives that I put in external enclosures. Now, I would like to have these two in the same enclosure, and I want to be able to add more drives in the future. Please note that I don&amp;#39;t want RAID. These data are taken care of by Time Machine and sent to a NAS outside my house. &lt;/p&gt;\n\n&lt;p&gt;Also, I don&amp;#39;t have much room on my desk so I think the only one that will fit would be this one : &lt;a href=\"https://www.amazon.ca/-/fr/gp/product/B0BP2CV1DK/ref=ox_sc_act_title_1?smid=A1BEN4AJP68QPC&amp;amp;th=1\"&gt;https://www.amazon.ca/-/fr/gp/product/B0BP2CV1DK/ref=ox_sc_act_title_1?smid=A1BEN4AJP68QPC&amp;amp;th=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s USB-C, which is the port I want to use, and as far as I understand, I can configure it to run without RAID. &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s also this one : &lt;a href=\"https://www.amazon.ca/-/fr/gp/product/B08DSX95F4/ref=sw_img_1?smid=A307CH216CTGMP&amp;amp;psc=1\"&gt;https://www.amazon.ca/-/fr/gp/product/B08DSX95F4/ref=sw_img_1?smid=A307CH216CTGMP&amp;amp;psc=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t think this one is going to fit on my desk. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any other recommendations ? Are these two reliable and good products ? Speed transfert is not really an issue. What I don&amp;#39;t want is unexpected disconnection or things like that.&lt;/p&gt;\n\n&lt;p&gt;Thanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15tolt8", "is_robot_indexable": true, "report_reasons": null, "author": "juluss", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15tolt8/recommendation_for_an_external_4_bay_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15tolt8/recommendation_for_an_external_4_bay_enclosure/", "subreddit_subscribers": 698566, "created_utc": 1692281113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_2qeix1st", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much Power On Hours is this? Is this real? Using QNAP External RAID manager with Seagate IronWolf drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 60, "top_awarded_type": null, "hide_score": true, "name": "t3_15ukw0i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/lFwE8iyF9PkK72qq9z-HxUnDIQl50iyidrgdbySBqns.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692366021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/cfovvzgcgvib1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/cfovvzgcgvib1.png?auto=webp&amp;s=94f9b51646a30acdc9c74d29cf3504d9c9e57782", "width": 951, "height": 408}, "resolutions": [{"url": "https://preview.redd.it/cfovvzgcgvib1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=17195ff99c9bc76d3cb920fdb3a3c2eb79163657", "width": 108, "height": 46}, {"url": "https://preview.redd.it/cfovvzgcgvib1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5927c5fd1081a8ffdc94493eec0583f13d0f6e33", "width": 216, "height": 92}, {"url": "https://preview.redd.it/cfovvzgcgvib1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb9e2f0dce34899efc9b795ce2457a139e0143c6", "width": 320, "height": 137}, {"url": "https://preview.redd.it/cfovvzgcgvib1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=634a2dfe1aff3e1ff026371427ef077de4e5c81d", "width": 640, "height": 274}], "variants": {}, "id": "N4Ea7RiYqhv5640Iuw_J4DgUserF-o19jk3LuK146LU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ukw0i", "is_robot_indexable": true, "report_reasons": null, "author": "ImJustGonnaSitHere01", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ukw0i/how_much_power_on_hours_is_this_is_this_real/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/cfovvzgcgvib1.png", "subreddit_subscribers": 698566, "created_utc": 1692366021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm sure I'll get a lot of flack for my setup but here goes...\n\nI have 3 HDDs - 2x 2TB and 1x 6TB in a 4-disk USB3.0 enclosure attached to a SFF Intel PC. All are pooled together using MergerFS running under OMV. I use it to feed my Jellyfin server as well as take backups of my main desktop PC via Windows File History and the BorgBackups of the boot drive used for the OMV server (this does result in a lot of small files on these disks).\n\nI added a 4th drive to the enclosure, another 6TB drive, to use as a SnapRAID parity disk to give me a bit of backup in case of a failure on one of my disks. I set up each disk in OMV's SnapRAID plugin and then added the parity.\n\nI set about running the sync maually 1which took about 30h initially (not unexpected as it was 5TB of files to sync). Since that's completed though I decided to try running diff and sync manually to get an idea of expected sync times now and was a bit disappointed with the results. I had about 568 updated files (mainly Jellyfin metadata) and 5-10 new files. After pre-hashing I was still getting an **8h** eta for these. \n\nIs this just to be expected for SnapRAID under these conditions (many small files) or is there something else odd going on. It was giving about a 130MB/s or 500 stripe/s speed, is that just it going through and checking all the data?", "author_fullname": "t2_986lj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SnapRAID Long Sync times - Is it just not suitable for my use case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ujyz2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692363676.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sure I&amp;#39;ll get a lot of flack for my setup but here goes...&lt;/p&gt;\n\n&lt;p&gt;I have 3 HDDs - 2x 2TB and 1x 6TB in a 4-disk USB3.0 enclosure attached to a SFF Intel PC. All are pooled together using MergerFS running under OMV. I use it to feed my Jellyfin server as well as take backups of my main desktop PC via Windows File History and the BorgBackups of the boot drive used for the OMV server (this does result in a lot of small files on these disks).&lt;/p&gt;\n\n&lt;p&gt;I added a 4th drive to the enclosure, another 6TB drive, to use as a SnapRAID parity disk to give me a bit of backup in case of a failure on one of my disks. I set up each disk in OMV&amp;#39;s SnapRAID plugin and then added the parity.&lt;/p&gt;\n\n&lt;p&gt;I set about running the sync maually 1which took about 30h initially (not unexpected as it was 5TB of files to sync). Since that&amp;#39;s completed though I decided to try running diff and sync manually to get an idea of expected sync times now and was a bit disappointed with the results. I had about 568 updated files (mainly Jellyfin metadata) and 5-10 new files. After pre-hashing I was still getting an &lt;strong&gt;8h&lt;/strong&gt; eta for these. &lt;/p&gt;\n\n&lt;p&gt;Is this just to be expected for SnapRAID under these conditions (many small files) or is there something else odd going on. It was giving about a 130MB/s or 500 stripe/s speed, is that just it going through and checking all the data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ujyz2", "is_robot_indexable": true, "report_reasons": null, "author": "Jamstruth", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ujyz2/snapraid_long_sync_times_is_it_just_not_suitable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ujyz2/snapraid_long_sync_times_is_it_just_not_suitable/", "subreddit_subscribers": 698566, "created_utc": 1692363676.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "AFAIK pushshift went down around May, does anyone have archives of the data from beginning of the year until then? I can only find archived data until the end of 2022.", "author_fullname": "t2_cj18nn34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pushshift archives for the first couple months of 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ujcfs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692362028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;AFAIK pushshift went down around May, does anyone have archives of the data from beginning of the year until then? I can only find archived data until the end of 2022.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ujcfs", "is_robot_indexable": true, "report_reasons": null, "author": "TropicalGuanabana", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ujcfs/pushshift_archives_for_the_first_couple_months_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ujcfs/pushshift_archives_for_the_first_couple_months_of/", "subreddit_subscribers": 698566, "created_utc": 1692362028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The audio sounds like wobbly and distorted. I have ZERO experience doing this. I\u2019m just a normal person trying to back up these home movies. Any insight is appreciated!", "author_fullname": "t2_83bc5xf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Distorted audio in digitized VHS?? Can I fix it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uibnl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692359243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The audio sounds like wobbly and distorted. I have ZERO experience doing this. I\u2019m just a normal person trying to back up these home movies. Any insight is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15uibnl", "is_robot_indexable": true, "report_reasons": null, "author": "Mental-Idea9525", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15uibnl/distorted_audio_in_digitized_vhs_can_i_fix_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15uibnl/distorted_audio_in_digitized_vhs_can_i_fix_it/", "subreddit_subscribers": 698566, "created_utc": 1692359243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hope this is on-topic for this sub, wouldn\u2019t know where else to ask. \n\nSo I am data hoarding, one aspect of that is that everything should have two backups\u2026 I am currently using Borg+Borgmatic for the Linux machines and Duplicati on Windows. Doing this for the whole extended family, about 10 machines. \n\nI am mostly fine about being able to restore individual files on the Linux machines. Still have some issues getting Duplicati to perform fully stable (Windows locks some files in use sometimes and blocks access). Maybe will try Veeam or Restic for Windows. \n\nHowever, the actual reason I am posting this, I am wondering about bare metal restore. What if a harddisk really gets damaged, a computer gets lost, etc?\n\nFor Linux, my strategy would be to do a plain install of the OS fresh, restore the user dir and selectively put stuff back into /etc and /var, which is no problem from my Borg Backup. Relatively easy. \n\nFor Windows honestly I don\u2019t know. The permissions system nowadays seems difficult and intransparent to me, much different than Linux does it. Can I do a vanilla install of Windows, restore a user dir fully and work with that again? Will it let me do that? Can Windows system settings be backed up? Do they all go to the registry? What is the strategy here? At least the user files are safe, but I would also like to reduce the setup effort if needed. \n\nI know that several tools (e.g. Veeam) do image based backups that should contain everything to get up &amp; running again. However then I lose the convenience of incremental, deduplicated, encrypted backup I can safely upload to the cloud.", "author_fullname": "t2_39qog2wp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bare metal machines backup / restore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uhzr2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692358319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope this is on-topic for this sub, wouldn\u2019t know where else to ask. &lt;/p&gt;\n\n&lt;p&gt;So I am data hoarding, one aspect of that is that everything should have two backups\u2026 I am currently using Borg+Borgmatic for the Linux machines and Duplicati on Windows. Doing this for the whole extended family, about 10 machines. &lt;/p&gt;\n\n&lt;p&gt;I am mostly fine about being able to restore individual files on the Linux machines. Still have some issues getting Duplicati to perform fully stable (Windows locks some files in use sometimes and blocks access). Maybe will try Veeam or Restic for Windows. &lt;/p&gt;\n\n&lt;p&gt;However, the actual reason I am posting this, I am wondering about bare metal restore. What if a harddisk really gets damaged, a computer gets lost, etc?&lt;/p&gt;\n\n&lt;p&gt;For Linux, my strategy would be to do a plain install of the OS fresh, restore the user dir and selectively put stuff back into /etc and /var, which is no problem from my Borg Backup. Relatively easy. &lt;/p&gt;\n\n&lt;p&gt;For Windows honestly I don\u2019t know. The permissions system nowadays seems difficult and intransparent to me, much different than Linux does it. Can I do a vanilla install of Windows, restore a user dir fully and work with that again? Will it let me do that? Can Windows system settings be backed up? Do they all go to the registry? What is the strategy here? At least the user files are safe, but I would also like to reduce the setup effort if needed. &lt;/p&gt;\n\n&lt;p&gt;I know that several tools (e.g. Veeam) do image based backups that should contain everything to get up &amp;amp; running again. However then I lose the convenience of incremental, deduplicated, encrypted backup I can safely upload to the cloud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15uhzr2", "is_robot_indexable": true, "report_reasons": null, "author": "Jolly_Reserve", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15uhzr2/bare_metal_machines_backup_restore/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15uhzr2/bare_metal_machines_backup_restore/", "subreddit_subscribers": 698566, "created_utc": 1692358319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nThe first motherboard was a Gigabyte GA-H81M-DS2V, I shifted it to a Supermicro X9SRA. My original motherboard had two other hard drives attached to it, I connected them as well and it still gives me the same error. When I connect my SSD back to my original motherboard, everything within it is intact.", "author_fullname": "t2_11wi08", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows 10 BSODs saying \"BOOT DEVICE INACESIBBLE\" when I shifted my SSD to a different computer.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ugx4t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692355141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The first motherboard was a Gigabyte GA-H81M-DS2V, I shifted it to a Supermicro X9SRA. My original motherboard had two other hard drives attached to it, I connected them as well and it still gives me the same error. When I connect my SSD back to my original motherboard, everything within it is intact.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ugx4t", "is_robot_indexable": true, "report_reasons": null, "author": "New_Hush", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ugx4t/windows_10_bsods_saying_boot_device_inacesibble/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ugx4t/windows_10_bsods_saying_boot_device_inacesibble/", "subreddit_subscribers": 698566, "created_utc": 1692355141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nAt my father's office we have dozens of bands with different information that we want to scan and save. These are paper bands, usually 10ft long, that we need to scan in one continuous file.\n\nI've found a few companies that offer what we are looking for, which are Neuralog with their NeuraScanner, ColorTrac with their SmartLF SCi/SGi line up, and WellgreTech. However, I wanted to consult here on which other companies could be selling scanners just like this ones, given that finding those was not that easy.", "author_fullname": "t2_cn7wjdx4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Scanners to scan 10ft long paper bands", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u64dx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692321743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At my father&amp;#39;s office we have dozens of bands with different information that we want to scan and save. These are paper bands, usually 10ft long, that we need to scan in one continuous file.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found a few companies that offer what we are looking for, which are Neuralog with their NeuraScanner, ColorTrac with their SmartLF SCi/SGi line up, and WellgreTech. However, I wanted to consult here on which other companies could be selling scanners just like this ones, given that finding those was not that easy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15u64dx", "is_robot_indexable": true, "report_reasons": null, "author": "ReasonableCornFlakes", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15u64dx/looking_for_scanners_to_scan_10ft_long_paper_bands/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15u64dx/looking_for_scanners_to_scan_10ft_long_paper_bands/", "subreddit_subscribers": 698566, "created_utc": 1692321743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello\n\nI live in Canada and I will go on a family trip to Boston next week.\n\nI was thinking on purchasing large HDs for my NAS, mainly shuckable WD 8TB from Costco.\n\nI don't know if it's a good idea.\n\nSo for my fellow US friends, do you think that's there's any good deals?\n\nThe one on Costco here goes for about 200 CAD, that's around 150 USD.\n\nDo you guys have any suggestions on what to buy? Best cost for GB?\n\nThanks", "author_fullname": "t2_dlsxpsz9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best cost per GB HD Boston region", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u4do2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692317233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;I live in Canada and I will go on a family trip to Boston next week.&lt;/p&gt;\n\n&lt;p&gt;I was thinking on purchasing large HDs for my NAS, mainly shuckable WD 8TB from Costco.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if it&amp;#39;s a good idea.&lt;/p&gt;\n\n&lt;p&gt;So for my fellow US friends, do you think that&amp;#39;s there&amp;#39;s any good deals?&lt;/p&gt;\n\n&lt;p&gt;The one on Costco here goes for about 200 CAD, that&amp;#39;s around 150 USD.&lt;/p&gt;\n\n&lt;p&gt;Do you guys have any suggestions on what to buy? Best cost for GB?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15u4do2", "is_robot_indexable": true, "report_reasons": null, "author": "fabio_teixei", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15u4do2/best_cost_per_gb_hd_boston_region/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15u4do2/best_cost_per_gb_hd_boston_region/", "subreddit_subscribers": 698566, "created_utc": 1692317233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi!\n\nI've been changing my NAS a few times. Went from a TS412 to a Synology DS1511+. As much as I liked the synology I had to change that as despite I changed all the fans it was still throwing some weird fan error in the ui despite the fan was running.\n\nRight now I'm more or less settled with a QNAP TS-431P2 (https://www.qnap.com/en/product/ts-431p2). I have 4x 2TB IronWolves. I was thinking to expand as I saw some people on the local market place selling 6tb toshiba and 10tb wd red plus used drives for cheap. My main concern is when I first made the raid5 array, I had to set an inode size, which is something that synology didn't ask for. After looking into that for a while, I went with 8K bytes pr inode which allows to a maximum capacity of 31.99TB.\n\nDoes that maximum capacity reffer to the actual usable space or the raw space of all the drives? Because while 4x10TB would be 40TB in theory, if my maths (online calculator) is right the usable space would be ~27TB in RAID5 which should fit within the inode limit.\n\nAlso anyone has any experience with toshiba mg04aca600e 6TB hdds? I couldn't find much online other than few mentions here and there that they can be loud which is kind of a \"turn off\" as my nas is in the living room \ud83d\ude05 And if that's the case I'd much rather hunt for some wd reds or bigger ironwolves on the marketplace.\n\nThanks!\n\nLE: I'm using the nas as a \"convenience\" storage. I have external backups of everything on it, and if its vital, I have 2 backups at least, but I mainly use it so I can quickly access stuff over LAN without pulling all the specific hdd's all the time I need something, which is why I'm fine with using second hand drives. Even the ironwolves I have, I got second hand 2 years ago.", "author_fullname": "t2_y8tj0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question regarding upgrading already running QNAP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u07ks", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692307856.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692307345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been changing my NAS a few times. Went from a TS412 to a Synology DS1511+. As much as I liked the synology I had to change that as despite I changed all the fans it was still throwing some weird fan error in the ui despite the fan was running.&lt;/p&gt;\n\n&lt;p&gt;Right now I&amp;#39;m more or less settled with a QNAP TS-431P2 (&lt;a href=\"https://www.qnap.com/en/product/ts-431p2\"&gt;https://www.qnap.com/en/product/ts-431p2&lt;/a&gt;). I have 4x 2TB IronWolves. I was thinking to expand as I saw some people on the local market place selling 6tb toshiba and 10tb wd red plus used drives for cheap. My main concern is when I first made the raid5 array, I had to set an inode size, which is something that synology didn&amp;#39;t ask for. After looking into that for a while, I went with 8K bytes pr inode which allows to a maximum capacity of 31.99TB.&lt;/p&gt;\n\n&lt;p&gt;Does that maximum capacity reffer to the actual usable space or the raw space of all the drives? Because while 4x10TB would be 40TB in theory, if my maths (online calculator) is right the usable space would be ~27TB in RAID5 which should fit within the inode limit.&lt;/p&gt;\n\n&lt;p&gt;Also anyone has any experience with toshiba mg04aca600e 6TB hdds? I couldn&amp;#39;t find much online other than few mentions here and there that they can be loud which is kind of a &amp;quot;turn off&amp;quot; as my nas is in the living room \ud83d\ude05 And if that&amp;#39;s the case I&amp;#39;d much rather hunt for some wd reds or bigger ironwolves on the marketplace.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;LE: I&amp;#39;m using the nas as a &amp;quot;convenience&amp;quot; storage. I have external backups of everything on it, and if its vital, I have 2 backups at least, but I mainly use it so I can quickly access stuff over LAN without pulling all the specific hdd&amp;#39;s all the time I need something, which is why I&amp;#39;m fine with using second hand drives. Even the ironwolves I have, I got second hand 2 years ago.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/k7pqJAHHjXEa_OfoRXG8nC1e0b8r7TS9vrKfoYNopH8.jpg?auto=webp&amp;s=a130910dd7093eed21bea90d0b9927af99a9a76e", "width": 1000, "height": 625}, "resolutions": [{"url": "https://external-preview.redd.it/k7pqJAHHjXEa_OfoRXG8nC1e0b8r7TS9vrKfoYNopH8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1f034cb92c1916bf269ce71cf3baabf16269ca91", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/k7pqJAHHjXEa_OfoRXG8nC1e0b8r7TS9vrKfoYNopH8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9affd2dcef58407cce940422b1cc7e81a9609ff0", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/k7pqJAHHjXEa_OfoRXG8nC1e0b8r7TS9vrKfoYNopH8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4f59c68cb8d7c7cd691219ef7e2a0dc48424b8c7", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/k7pqJAHHjXEa_OfoRXG8nC1e0b8r7TS9vrKfoYNopH8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7692de701a34c321bd2e92385fee775da36b8820", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/k7pqJAHHjXEa_OfoRXG8nC1e0b8r7TS9vrKfoYNopH8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=60ea0b5e8ec0db3f4b59f37f53f3572cb8f8edee", "width": 960, "height": 600}], "variants": {}, "id": "UNCS0mtJ6TfKSjkNT2i5MrSaHWJsFiZ1nhSvkebyHjg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15u07ks", "is_robot_indexable": true, "report_reasons": null, "author": "Yaddos", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15u07ks/question_regarding_upgrading_already_running_qnap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15u07ks/question_regarding_upgrading_already_running_qnap/", "subreddit_subscribers": 698566, "created_utc": 1692307345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m building a new RAID, probably doing an 8-Bay with a mix of Seagate Exo and IronWolf 20tb. \n\nThe plan is an OWC Thunderbay 4 (I have two already, but those are dedicated to specific projects\u2019)\n\nThis new RAID will be used for daily video projects hooked up to a Mac Studio. I think I\u2019m going to go with a RAID 5\n\nI\u2019m buying the drives slowly first and once I have 4 I\u2019ll start looking at enclosures. \n\n\nI\u2019ve looked into doing a NAS and I don\u2019t think I need one just yet. \n\nWhat do you guys and gals think? Are there alternatives I should look into?", "author_fullname": "t2_bm9de", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New RAID build", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tyjpn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692303703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m building a new RAID, probably doing an 8-Bay with a mix of Seagate Exo and IronWolf 20tb. &lt;/p&gt;\n\n&lt;p&gt;The plan is an OWC Thunderbay 4 (I have two already, but those are dedicated to specific projects\u2019)&lt;/p&gt;\n\n&lt;p&gt;This new RAID will be used for daily video projects hooked up to a Mac Studio. I think I\u2019m going to go with a RAID 5&lt;/p&gt;\n\n&lt;p&gt;I\u2019m buying the drives slowly first and once I have 4 I\u2019ll start looking at enclosures. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve looked into doing a NAS and I don\u2019t think I need one just yet. &lt;/p&gt;\n\n&lt;p&gt;What do you guys and gals think? Are there alternatives I should look into?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15tyjpn", "is_robot_indexable": true, "report_reasons": null, "author": "lIlIIlIlIIlIlIIlIlII", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15tyjpn/new_raid_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15tyjpn/new_raid_build/", "subreddit_subscribers": 698566, "created_utc": 1692303703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " \n\nHello everyone,\n\nI am looking to get a pc for the explicit purpose of vhs capture. I know I want to use an All in Wonder video/capture card with the agp port. That is where I am runing into the biggest hurdle. Does anyone have any recommendations for hardware that has the following specs:\n\nMultiple core CPU\n\nAGP Expansion\n\nPCE expansion\n\nSata connection\n\nram upgradeable to atleast 4 gb\n\nI am happy to buy a prebuilt pc that was released or make my own. I'd like to keep it under $100. If we go the route of building my own, I have 5 dell optiplex pcs that I can get parts off of.\n\nOptiplex 3020\n\nOptiplex 790\n\nOptiplex 9020\n\nOptiplex 390\n\nOptiplex 380\n\nIs there any recommendations you can make to help me build this pc? Any help is appreciated, Thank you all in advance.", "author_fullname": "t2_hilrs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to craft an XP Machine for VHS Capture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tu09b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692293497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am looking to get a pc for the explicit purpose of vhs capture. I know I want to use an All in Wonder video/capture card with the agp port. That is where I am runing into the biggest hurdle. Does anyone have any recommendations for hardware that has the following specs:&lt;/p&gt;\n\n&lt;p&gt;Multiple core CPU&lt;/p&gt;\n\n&lt;p&gt;AGP Expansion&lt;/p&gt;\n\n&lt;p&gt;PCE expansion&lt;/p&gt;\n\n&lt;p&gt;Sata connection&lt;/p&gt;\n\n&lt;p&gt;ram upgradeable to atleast 4 gb&lt;/p&gt;\n\n&lt;p&gt;I am happy to buy a prebuilt pc that was released or make my own. I&amp;#39;d like to keep it under $100. If we go the route of building my own, I have 5 dell optiplex pcs that I can get parts off of.&lt;/p&gt;\n\n&lt;p&gt;Optiplex 3020&lt;/p&gt;\n\n&lt;p&gt;Optiplex 790&lt;/p&gt;\n\n&lt;p&gt;Optiplex 9020&lt;/p&gt;\n\n&lt;p&gt;Optiplex 390&lt;/p&gt;\n\n&lt;p&gt;Optiplex 380&lt;/p&gt;\n\n&lt;p&gt;Is there any recommendations you can make to help me build this pc? Any help is appreciated, Thank you all in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15tu09b", "is_robot_indexable": true, "report_reasons": null, "author": "Matthew_C1314", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15tu09b/looking_to_craft_an_xp_machine_for_vhs_capture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15tu09b/looking_to_craft_an_xp_machine_for_vhs_capture/", "subreddit_subscribers": 698566, "created_utc": 1692293497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i use twitter thread compilers/unrollers to archive twitter threads i find interesting. currently looking for a good one that can submit threads through a website menu, like pingthread or threadreader used to. many of them stopped working - assumedly cos twitter's overhaul - or cost money. so my only option is to pay or try the unreliable mention system that rarely works.\n\nany ideas?", "author_fullname": "t2_us4gjb7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "good and free twitter thread compilers (like threader)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15udiwc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692343753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i use twitter thread compilers/unrollers to archive twitter threads i find interesting. currently looking for a good one that can submit threads through a website menu, like pingthread or threadreader used to. many of them stopped working - assumedly cos twitter&amp;#39;s overhaul - or cost money. so my only option is to pay or try the unreliable mention system that rarely works.&lt;/p&gt;\n\n&lt;p&gt;any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15udiwc", "is_robot_indexable": true, "report_reasons": null, "author": "whsiouquwud728172", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15udiwc/good_and_free_twitter_thread_compilers_like/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15udiwc/good_and_free_twitter_thread_compilers_like/", "subreddit_subscribers": 698566, "created_utc": 1692343753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i've got a few hundred gigs of video files in .mp4 format, is there a way i can compress these in a format that i can't view without decompressing, but is super tiny? I'd like to cut back on power draw, but i can add more drives if i need to. i'm just hoping i can save space software side first.", "author_fullname": "t2_386twwne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "video archive format?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ub7fd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692336101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i&amp;#39;ve got a few hundred gigs of video files in .mp4 format, is there a way i can compress these in a format that i can&amp;#39;t view without decompressing, but is super tiny? I&amp;#39;d like to cut back on power draw, but i can add more drives if i need to. i&amp;#39;m just hoping i can save space software side first.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ub7fd", "is_robot_indexable": true, "report_reasons": null, "author": "DavidC438", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ub7fd/video_archive_format/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ub7fd/video_archive_format/", "subreddit_subscribers": 698566, "created_utc": 1692336101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Yes, I know I can find those on Aliexpress, and random unheard of Hong Kong or Chinese names on Amazon... but I would trust those about as much as I would trust a RAID 0 made out of a hundred Darkstar drives. \n \nAre there any respectable brands that still make drives like these? I help troubleshoot computer problems for friends and family, and I want to create bootable live-USBs of tools and applications to assist with this. Issue is that half the time it's a malware infection, and I don't want to risk infecting said USB drives, so I wanted a switch that physically disables writes that I can switch them to read-only when using them and only enable writes when I am manually updating them myself. Back when optical drives were still standard this wasn't an issue, but now that those are long gone for 99% of people...", "author_fullname": "t2_9njdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does any reputable manufacturer still make USB Flashdrives with a write-protect switch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15uayf8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692335350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yes, I know I can find those on Aliexpress, and random unheard of Hong Kong or Chinese names on Amazon... but I would trust those about as much as I would trust a RAID 0 made out of a hundred Darkstar drives. &lt;/p&gt;\n\n&lt;p&gt;Are there any respectable brands that still make drives like these? I help troubleshoot computer problems for friends and family, and I want to create bootable live-USBs of tools and applications to assist with this. Issue is that half the time it&amp;#39;s a malware infection, and I don&amp;#39;t want to risk infecting said USB drives, so I wanted a switch that physically disables writes that I can switch them to read-only when using them and only enable writes when I am manually updating them myself. Back when optical drives were still standard this wasn&amp;#39;t an issue, but now that those are long gone for 99% of people...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15uayf8", "is_robot_indexable": true, "report_reasons": null, "author": "Cyber_Akuma", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15uayf8/does_any_reputable_manufacturer_still_make_usb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15uayf8/does_any_reputable_manufacturer_still_make_usb/", "subreddit_subscribers": 698566, "created_utc": 1692335350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently Admins can click a Group Insights and receive some excel data on Group Engagement levels.\n\nUnfortunately it's somewhat limited. for example Posts are limited to only the most popular posts, and it does not include a time stamp).\n\nIs it possible to download ALL posts, within a certain time period as an admin? preferably that includes time stamps", "author_fullname": "t2_qjfe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I download All Posts in a FB group I manage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u8hvu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692328145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently Admins can click a Group Insights and receive some excel data on Group Engagement levels.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately it&amp;#39;s somewhat limited. for example Posts are limited to only the most popular posts, and it does not include a time stamp).&lt;/p&gt;\n\n&lt;p&gt;Is it possible to download ALL posts, within a certain time period as an admin? preferably that includes time stamps&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15u8hvu", "is_robot_indexable": true, "report_reasons": null, "author": "LeBronBryantJames", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15u8hvu/how_can_i_download_all_posts_in_a_fb_group_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15u8hvu/how_can_i_download_all_posts_in_a_fb_group_i/", "subreddit_subscribers": 698566, "created_utc": 1692328145.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}