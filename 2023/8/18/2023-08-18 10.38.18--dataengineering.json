{"kind": "Listing", "data": {"after": "t3_15ueo9c", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there,\n\nI already have a job and this position is paying 160k in MA area and is looking to conduct 5 interview rounds.\n\n3 on one day starting 11 am until 2 pm. with three different individuals\n\nand \n\n2 on another day from 10 until 12 with 2 other individuals.\n\n&amp;#x200B;\n\nI had asked them to respect my time and have two one hour interviews but they sent this anyways.\n\nI feel like just saying no to this. This is getting out of hand.\n\nUnless they want to pay 300k, I feel like this would just waste of my time.", "author_fullname": "t2_kz99f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One company wants me to attend 5 interview rounds in 2 days. Even worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15trl9q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 72, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692287948.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I already have a job and this position is paying 160k in MA area and is looking to conduct 5 interview rounds.&lt;/p&gt;\n\n&lt;p&gt;3 on one day starting 11 am until 2 pm. with three different individuals&lt;/p&gt;\n\n&lt;p&gt;and &lt;/p&gt;\n\n&lt;p&gt;2 on another day from 10 until 12 with 2 other individuals.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I had asked them to respect my time and have two one hour interviews but they sent this anyways.&lt;/p&gt;\n\n&lt;p&gt;I feel like just saying no to this. This is getting out of hand.&lt;/p&gt;\n\n&lt;p&gt;Unless they want to pay 300k, I feel like this would just waste of my time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15trl9q", "is_robot_indexable": true, "report_reasons": null, "author": "jerrie86", "discussion_type": null, "num_comments": 83, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15trl9q/one_company_wants_me_to_attend_5_interview_rounds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15trl9q/one_company_wants_me_to_attend_5_interview_rounds/", "subreddit_subscribers": 123374, "created_utc": 1692287948.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Tools experience also works too.\n\nBasically what level of familiarity did you have with the topic in general?", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much \"data\" experience did you have before getting your first data engineering job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tqf1i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692285297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tools experience also works too.&lt;/p&gt;\n\n&lt;p&gt;Basically what level of familiarity did you have with the topic in general?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15tqf1i", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tqf1i/how_much_data_experience_did_you_have_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tqf1i/how_much_data_experience_did_you_have_before/", "subreddit_subscribers": 123374, "created_utc": 1692285297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is the first project I have attempted. I have created an ETL pipeline, written in python, that pulls data from CoinMarketCap API and places this into a CSV, followed by loading it into PostgreSQL. I have attached this data to Power BI and put the script on a task scheduler to update prices every 5min. If you have the time, please let me know where I can improve my code or better avenues I can take. If this is not the right sub for this kind of post, please point me to the right one as I don't want to be a bother.  [Here is the link to my full code](https://github.com/bfraz33/CryptoETLLoad2.0/blob/master/CSV_Extract.py)\n\nhttps://preview.redd.it/w7kr88rdorib1.png?width=977&amp;format=png&amp;auto=webp&amp;s=108ad539340b5183e5052cb7b69964d9e9f74619\n\nhttps://preview.redd.it/boul2vqdorib1.png?width=1481&amp;format=png&amp;auto=webp&amp;s=e83e2f8e4ad05bea43935782f176646af9f6a398", "author_fullname": "t2_8txv38ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First project, feel free to criticize hard haha.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"boul2vqdorib1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/boul2vqdorib1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e06fd4f016863040148f4c844ce4162f3f66a772"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/boul2vqdorib1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f07e9de9d384f52faef4ba70a6b7afe5e2e01821"}, {"y": 179, "x": 320, "u": "https://preview.redd.it/boul2vqdorib1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e01527b3c90ecda05c49022f044722d5c1ce8c9"}, {"y": 359, "x": 640, "u": "https://preview.redd.it/boul2vqdorib1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f55cfc1432d21b96b739d40e99eec853baaf9bc7"}, {"y": 539, "x": 960, "u": "https://preview.redd.it/boul2vqdorib1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=92dcb9ad8338d3ea0a86c8a8e3f7fbebc1583f72"}, {"y": 606, "x": 1080, "u": "https://preview.redd.it/boul2vqdorib1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c699f54c6b84b3c96140ec26be744872c31c08cb"}], "s": {"y": 832, "x": 1481, "u": "https://preview.redd.it/boul2vqdorib1.png?width=1481&amp;format=png&amp;auto=webp&amp;s=e83e2f8e4ad05bea43935782f176646af9f6a398"}, "id": "boul2vqdorib1"}, "w7kr88rdorib1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 184, "x": 108, "u": "https://preview.redd.it/w7kr88rdorib1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2bcf67c80d97c2cf86264294c003a2d7d3a56553"}, {"y": 369, "x": 216, "u": "https://preview.redd.it/w7kr88rdorib1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c540b32a5da6b87267a99f5200568b714655c2ba"}, {"y": 546, "x": 320, "u": "https://preview.redd.it/w7kr88rdorib1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=40e7a502ee6b108b147ffa6dfe9bb8f43780e47b"}, {"y": 1093, "x": 640, "u": "https://preview.redd.it/w7kr88rdorib1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=392d7e773cda187aecf395095c357222a0c633a6"}, {"y": 1640, "x": 960, "u": "https://preview.redd.it/w7kr88rdorib1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b479cb2c55de4ce78d03e3562c62fbd5edf72fdb"}], "s": {"y": 1670, "x": 977, "u": "https://preview.redd.it/w7kr88rdorib1.png?width=977&amp;format=png&amp;auto=webp&amp;s=108ad539340b5183e5052cb7b69964d9e9f74619"}, "id": "w7kr88rdorib1"}}, "name": "t3_15u5j2r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mw9_99T-U_XTSkzkdDp5MeXM6kmybB7O7-mgQ7c0XpA.jpg", "edited": 1692321956.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1692320212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is the first project I have attempted. I have created an ETL pipeline, written in python, that pulls data from CoinMarketCap API and places this into a CSV, followed by loading it into PostgreSQL. I have attached this data to Power BI and put the script on a task scheduler to update prices every 5min. If you have the time, please let me know where I can improve my code or better avenues I can take. If this is not the right sub for this kind of post, please point me to the right one as I don&amp;#39;t want to be a bother.  &lt;a href=\"https://github.com/bfraz33/CryptoETLLoad2.0/blob/master/CSV_Extract.py\"&gt;Here is the link to my full code&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/w7kr88rdorib1.png?width=977&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=108ad539340b5183e5052cb7b69964d9e9f74619\"&gt;https://preview.redd.it/w7kr88rdorib1.png?width=977&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=108ad539340b5183e5052cb7b69964d9e9f74619&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/boul2vqdorib1.png?width=1481&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e83e2f8e4ad05bea43935782f176646af9f6a398\"&gt;https://preview.redd.it/boul2vqdorib1.png?width=1481&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e83e2f8e4ad05bea43935782f176646af9f6a398&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ACuC6zAV_CymKXosU4fX7Yf_KeeHs2anvH2NFls17bk.jpg?auto=webp&amp;s=fde16e96fe3d9091a3b75c5d2a0c26e850681df4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ACuC6zAV_CymKXosU4fX7Yf_KeeHs2anvH2NFls17bk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d39fe56abf4937e02170bfb286c7dcab7b67357", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ACuC6zAV_CymKXosU4fX7Yf_KeeHs2anvH2NFls17bk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d3495f3bd75ee7ea366f78287ea64aadb083ac5e", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ACuC6zAV_CymKXosU4fX7Yf_KeeHs2anvH2NFls17bk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e3794d8454201ecf761eaa382e7ddd6d21ea9c72", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ACuC6zAV_CymKXosU4fX7Yf_KeeHs2anvH2NFls17bk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7cf67182728cee4a57f6f2ab72c804174e5b1a63", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ACuC6zAV_CymKXosU4fX7Yf_KeeHs2anvH2NFls17bk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=da827046d365c2d04ffbf9c960a5d57468517405", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ACuC6zAV_CymKXosU4fX7Yf_KeeHs2anvH2NFls17bk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fca64023a9133562960b0ab50453bebeff940c2f", "width": 1080, "height": 540}], "variants": {}, "id": "ONo1rnCyof0BYBKB3ltdfpeOWgvJtJ_4xm88Hvt9yR4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "15u5j2r", "is_robot_indexable": true, "report_reasons": null, "author": "Fraiz24", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15u5j2r/first_project_feel_free_to_criticize_hard_haha/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15u5j2r/first_project_feel_free_to_criticize_hard_haha/", "subreddit_subscribers": 123374, "created_utc": 1692320212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, \nHow do you all do it basically?\nI am a young data scientist (even though most of my job title is DE ) ans sometimes I really struggle to not feel defeated by my current role. \nLike I feel I am getting no support with a lot of my pipelines never being validated as we lack any senior peoples, having to do quick fixes after quick fixes, dealing with rubbish data or having to deal with some confusing other companies (like today was sending an update to one of our contact as the data their API was showing was not up to date, turns out their API is not pulling from their live dB \ud83d\ude2b).\nI enjoy it and everyone on my team is happy with my work but it feels it is impacting my wellbeing and wonder if I should just quit.\nMain problem being my background is not in data so finding another role is a lot harder. \nAny advice?", "author_fullname": "t2_aflyojn9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handling the pressure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tslrw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692290288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, \nHow do you all do it basically?\nI am a young data scientist (even though most of my job title is DE ) ans sometimes I really struggle to not feel defeated by my current role. \nLike I feel I am getting no support with a lot of my pipelines never being validated as we lack any senior peoples, having to do quick fixes after quick fixes, dealing with rubbish data or having to deal with some confusing other companies (like today was sending an update to one of our contact as the data their API was showing was not up to date, turns out their API is not pulling from their live dB \ud83d\ude2b).\nI enjoy it and everyone on my team is happy with my work but it feels it is impacting my wellbeing and wonder if I should just quit.\nMain problem being my background is not in data so finding another role is a lot harder. \nAny advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15tslrw", "is_robot_indexable": true, "report_reasons": null, "author": "SuperFrenchie19", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tslrw/handling_the_pressure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tslrw/handling_the_pressure/", "subreddit_subscribers": 123374, "created_utc": 1692290288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nMy question is pretty much the same but I will add more context.\n\nI am 26 yo, senior data engineer with 5 years of industry experience.\n\ni am from a South Asian country (Not India), I did my bachelors in Software Engineering here, worked for around 3 years here and then found a job and moved to Germany.\n\nNow, in Germany, work life balance is good, you get all the state benefits, vacations, sick leaves all of it. If I think in the long term, it's a very safe country, humans are valued, socially you are secure etc, which makes life quite peaceful.\n\nOn the other side, you have to learn the language to get permanent here, I earn like 80k euroes per year and being single around 40% of my salary goes to taxes, which of course is an investment for my and my family's future, and lots of pretty places nearby to travel to and spend time at.\n\nBUT, having your family move here is a huge pain in the ass if you get married back in your home country after moving here, it's almost impossible to have your parents visit you or move with you, and your buying power is less and you have to live in relatively smaller apartments/houses.\n\nRecently, I came across a VISA for permanently moving to US which i could be eligible for, I reached out to some immigration lawyers and most of them said I am likely to get it and I can apply for it,\n\nNow, this whole process is going to cost me almost all of my savings in legal fee and so, but what I am confused about is it worth it? Will I be able to find a job there with my South Asian university degree in US?\n\nOn one hand I see people with even average incomes in the US living in big houses driving nice cars, but on the other hand I see that it's not safe, you can be homeless or on the street, but on the other hand I see so many people living prosperous lives there (I am not talking about outliers or celeberities). Your parents can visit you with multiple entry visas, the market is bigger (but obviously more competetive as well).\n\nI have never been truly jobless in my life, I once got affected by mass layoffs but even then I found another job before my guardian period even expired.\n\nI also feel like if in US I could earn more, I could, may be, save in my young years and invest in some assests for passive income in my later years whihc seems very difficult here in Germany as after taxes, rent, expenses and family support you are barely left with anything.\n\nAnd when I talked to other people here I realised I am payed very good salary for my experience bracket.\n\nSo people who have worked in both countries or people who are working in CS careers in the US, what would you recommend in this situation?\n\nI am 26 yo already, just yesterday I remember completing my bachers at 21, and life doesn't stop. I want to put my mind to peace if i should just accept this place to be my home and spend all my energy here or try to move to a place with better prospects.", "author_fullname": "t2_rol5v4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I move to the US or should I stay in Germany?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15txz1z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692302439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;My question is pretty much the same but I will add more context.&lt;/p&gt;\n\n&lt;p&gt;I am 26 yo, senior data engineer with 5 years of industry experience.&lt;/p&gt;\n\n&lt;p&gt;i am from a South Asian country (Not India), I did my bachelors in Software Engineering here, worked for around 3 years here and then found a job and moved to Germany.&lt;/p&gt;\n\n&lt;p&gt;Now, in Germany, work life balance is good, you get all the state benefits, vacations, sick leaves all of it. If I think in the long term, it&amp;#39;s a very safe country, humans are valued, socially you are secure etc, which makes life quite peaceful.&lt;/p&gt;\n\n&lt;p&gt;On the other side, you have to learn the language to get permanent here, I earn like 80k euroes per year and being single around 40% of my salary goes to taxes, which of course is an investment for my and my family&amp;#39;s future, and lots of pretty places nearby to travel to and spend time at.&lt;/p&gt;\n\n&lt;p&gt;BUT, having your family move here is a huge pain in the ass if you get married back in your home country after moving here, it&amp;#39;s almost impossible to have your parents visit you or move with you, and your buying power is less and you have to live in relatively smaller apartments/houses.&lt;/p&gt;\n\n&lt;p&gt;Recently, I came across a VISA for permanently moving to US which i could be eligible for, I reached out to some immigration lawyers and most of them said I am likely to get it and I can apply for it,&lt;/p&gt;\n\n&lt;p&gt;Now, this whole process is going to cost me almost all of my savings in legal fee and so, but what I am confused about is it worth it? Will I be able to find a job there with my South Asian university degree in US?&lt;/p&gt;\n\n&lt;p&gt;On one hand I see people with even average incomes in the US living in big houses driving nice cars, but on the other hand I see that it&amp;#39;s not safe, you can be homeless or on the street, but on the other hand I see so many people living prosperous lives there (I am not talking about outliers or celeberities). Your parents can visit you with multiple entry visas, the market is bigger (but obviously more competetive as well).&lt;/p&gt;\n\n&lt;p&gt;I have never been truly jobless in my life, I once got affected by mass layoffs but even then I found another job before my guardian period even expired.&lt;/p&gt;\n\n&lt;p&gt;I also feel like if in US I could earn more, I could, may be, save in my young years and invest in some assests for passive income in my later years whihc seems very difficult here in Germany as after taxes, rent, expenses and family support you are barely left with anything.&lt;/p&gt;\n\n&lt;p&gt;And when I talked to other people here I realised I am payed very good salary for my experience bracket.&lt;/p&gt;\n\n&lt;p&gt;So people who have worked in both countries or people who are working in CS careers in the US, what would you recommend in this situation?&lt;/p&gt;\n\n&lt;p&gt;I am 26 yo already, just yesterday I remember completing my bachers at 21, and life doesn&amp;#39;t stop. I want to put my mind to peace if i should just accept this place to be my home and spend all my energy here or try to move to a place with better prospects.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15txz1z", "is_robot_indexable": true, "report_reasons": null, "author": "Botmon_DaDorkNight", "discussion_type": null, "num_comments": 95, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15txz1z/should_i_move_to_the_us_or_should_i_stay_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15txz1z/should_i_move_to_the_us_or_should_i_stay_in/", "subreddit_subscribers": 123374, "created_utc": 1692302439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it due to the increasing difficulty of finding Data Engineers or just companies trying to collect CV for possible future recruitments?", "author_fullname": "t2_8ijlo4rl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A lot of \"reposted\" jobs on LinkedIn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tnkef", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692278691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it due to the increasing difficulty of finding Data Engineers or just companies trying to collect CV for possible future recruitments?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15tnkef", "is_robot_indexable": true, "report_reasons": null, "author": "Noway721", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tnkef/a_lot_of_reposted_jobs_on_linkedin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tnkef/a_lot_of_reposted_jobs_on_linkedin/", "subreddit_subscribers": 123374, "created_utc": 1692278691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_s63bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fast access to training data for ML using DuckDB and ArrowFlight", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15tmgln", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nesD4FNXy7nBOfJgfcp_U98d0fHwHnFhhjvLzkuxOzo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1692276215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hopsworks.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.hopsworks.ai/post/python-centric-feature-service-with-arrowflight-and-duckdb", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?auto=webp&amp;s=b4dbff81b3d60c0d5b10398cbb7ad8b8f49d18e4", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=454b24dd1331e9d874860de1e9d40c3a939b0327", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dfbe414118cf248f5eb082d36641f064766c10ce", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7db8e55a7d3e25eb65721d05449ab0e7096c7315", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9679f131a6c5d1d1860cc9a14884f7a66137efc9", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=cb5c04b6009148943e51787b7b1ffeaed607c818", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ll3KhGV6bWLK3K2fFHy2ZXp_7_ujvCKFgNafdRXljvs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4b2cd653bc25f99e895e380db6a91d99ab75ea0c", "width": 1080, "height": 567}], "variants": {}, "id": "cshXE1zE9RNFAI9a-Ajpp18V8vqIauNFQE-MA9SsDds"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15tmgln", "is_robot_indexable": true, "report_reasons": null, "author": "SirOibaf", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tmgln/fast_access_to_training_data_for_ml_using_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.hopsworks.ai/post/python-centric-feature-service-with-arrowflight-and-duckdb", "subreddit_subscribers": 123374, "created_utc": 1692276215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have started my journey with GCP, I use AWS at work but decided to learn and get certifications for GCP. As for now I have loved the interface and how user friendly it is. Now my question is, why is GCP not so adapted in the market? Will it change in the future ?", "author_fullname": "t2_7sxdmzpt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Started with GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u7o76", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692325880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have started my journey with GCP, I use AWS at work but decided to learn and get certifications for GCP. As for now I have loved the interface and how user friendly it is. Now my question is, why is GCP not so adapted in the market? Will it change in the future ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15u7o76", "is_robot_indexable": true, "report_reasons": null, "author": "felipeHernandez19", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15u7o76/started_with_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15u7o76/started_with_gcp/", "subreddit_subscribers": 123374, "created_utc": 1692325880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nToday i participate in a Power Bi Jr Analyst recruitment process. I like to participate in those because i feel i can learn more about the market, good concepts and so...\n\nI had to solve a case in which i would use a json file to build a data model , then do some explorarory data analysis and then the dashboard.\n\nI Took Very long time to make all these simple things in Power BI using python script and SQL inside Power Query. Which i made like this Just because i dont have a Lot of practice with pbi. But now i understand there is a much easier way to do the same using pbi simple tools.\n\nMy question for you guys is:\n\nWhat would be considered a better practice: make all the modeling and analysis in Power BI, until you get into the dashboard, or rather make everything outside Power BI, except the dashboard?\n\nI understand that it may depend on the use case, so maybe some of you could elaborate more on that?\n\nThank you all.", "author_fullname": "t2_17f19lgj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Power BI Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u0gww", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692307921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Today i participate in a Power Bi Jr Analyst recruitment process. I like to participate in those because i feel i can learn more about the market, good concepts and so...&lt;/p&gt;\n\n&lt;p&gt;I had to solve a case in which i would use a json file to build a data model , then do some explorarory data analysis and then the dashboard.&lt;/p&gt;\n\n&lt;p&gt;I Took Very long time to make all these simple things in Power BI using python script and SQL inside Power Query. Which i made like this Just because i dont have a Lot of practice with pbi. But now i understand there is a much easier way to do the same using pbi simple tools.&lt;/p&gt;\n\n&lt;p&gt;My question for you guys is:&lt;/p&gt;\n\n&lt;p&gt;What would be considered a better practice: make all the modeling and analysis in Power BI, until you get into the dashboard, or rather make everything outside Power BI, except the dashboard?&lt;/p&gt;\n\n&lt;p&gt;I understand that it may depend on the use case, so maybe some of you could elaborate more on that?&lt;/p&gt;\n\n&lt;p&gt;Thank you all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15u0gww", "is_robot_indexable": true, "report_reasons": null, "author": "Seyrenz", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15u0gww/power_bi_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15u0gww/power_bi_engineering/", "subreddit_subscribers": 123374, "created_utc": 1692307921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Note: I said r/dataengineer  \\*not\\* r/dataengineering ! \n\nr/dataengineer  is a bloody nuisance.  I always end up there by mistake and wonder, \"where's all the good stuff\"?  ", "author_fullname": "t2_7yk2o6hxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can we get rid of r/dataengineer ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ub0px", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692335541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Note: I said &lt;a href=\"/r/dataengineer\"&gt;r/dataengineer&lt;/a&gt;  *not* &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; ! &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"/r/dataengineer\"&gt;r/dataengineer&lt;/a&gt;  is a bloody nuisance.  I always end up there by mistake and wonder, &amp;quot;where&amp;#39;s all the good stuff&amp;quot;?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ub0px", "is_robot_indexable": true, "report_reasons": null, "author": "grahamdietz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ub0px/can_we_get_rid_of_rdataengineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ub0px/can_we_get_rid_of_rdataengineer/", "subreddit_subscribers": 123374, "created_utc": 1692335541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, \n\nAt the company I'm at we are moving some things around. I started as  an Software Engineer, grew within the role. Then I moved over to Data  Engineering and now Data Architect.\n\nRight now, I'm reporting to a Senior VP. We work with data, SEO and building other things.\n\nWhat's happening, we are consolidating teams that are under different  verticals but still related (there's just no cohesive strategy,  insights or anything). The idea is for everyone to work more closely  together.\n\nInside the new structure, there will be 2 VP's side by side. One  focusing more on management and one on planning. I work with the one  with on planning. \n\nShe wants to keep me as her right hand. While she plans and deals  more with the planning of integration, I'd be focused on actually  overseeing the details of it and guiding things.\n\nI do not want a VP title or C\\* title. Usually these denote management  of people, budgets and other things that aren't technical. I want to be  focused on the technical. Architect the solutions, integrations, flow  of things.\n\nSo I'm coming here to ask, what would be a good title? What have you all seen as titles for a position like this?\n\nHappy to answer other questions in the comments", "author_fullname": "t2_gj2rj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career progression - what titles to look at?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ttdpc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692292040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;At the company I&amp;#39;m at we are moving some things around. I started as  an Software Engineer, grew within the role. Then I moved over to Data  Engineering and now Data Architect.&lt;/p&gt;\n\n&lt;p&gt;Right now, I&amp;#39;m reporting to a Senior VP. We work with data, SEO and building other things.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s happening, we are consolidating teams that are under different  verticals but still related (there&amp;#39;s just no cohesive strategy,  insights or anything). The idea is for everyone to work more closely  together.&lt;/p&gt;\n\n&lt;p&gt;Inside the new structure, there will be 2 VP&amp;#39;s side by side. One  focusing more on management and one on planning. I work with the one  with on planning. &lt;/p&gt;\n\n&lt;p&gt;She wants to keep me as her right hand. While she plans and deals  more with the planning of integration, I&amp;#39;d be focused on actually  overseeing the details of it and guiding things.&lt;/p&gt;\n\n&lt;p&gt;I do not want a VP title or C* title. Usually these denote management  of people, budgets and other things that aren&amp;#39;t technical. I want to be  focused on the technical. Architect the solutions, integrations, flow  of things.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m coming here to ask, what would be a good title? What have you all seen as titles for a position like this?&lt;/p&gt;\n\n&lt;p&gt;Happy to answer other questions in the comments&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15ttdpc", "is_robot_indexable": true, "report_reasons": null, "author": "asthma_dude", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ttdpc/career_progression_what_titles_to_look_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ttdpc/career_progression_what_titles_to_look_at/", "subreddit_subscribers": 123374, "created_utc": 1692292040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi 5 yoe data engineer here,\n\nI have a few interviews for DE positions. They all use either azure or gcp. I unfortuntely have 0 cloud experience. Most of my current experience revolves around production support/debugging/optimization/deploying spark scala pipelines on on-prem systems. Another thing to note is I don't do much data modeling in my job as well.\n\nJust curious to know, how much different is on-prem developement than on cloud? Are there any concepts that I should know before walking in the interview?\nAny advice on any skill that I should highlight? \n\n\nYou advice is very much appreciated", "author_fullname": "t2_69bro8kq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lots on on prem experience/ no cloud experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tsd9r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692289750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi 5 yoe data engineer here,&lt;/p&gt;\n\n&lt;p&gt;I have a few interviews for DE positions. They all use either azure or gcp. I unfortuntely have 0 cloud experience. Most of my current experience revolves around production support/debugging/optimization/deploying spark scala pipelines on on-prem systems. Another thing to note is I don&amp;#39;t do much data modeling in my job as well.&lt;/p&gt;\n\n&lt;p&gt;Just curious to know, how much different is on-prem developement than on cloud? Are there any concepts that I should know before walking in the interview?\nAny advice on any skill that I should highlight? &lt;/p&gt;\n\n&lt;p&gt;You advice is very much appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15tsd9r", "is_robot_indexable": true, "report_reasons": null, "author": "Significant-Skirt-75", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tsd9r/lots_on_on_prem_experience_no_cloud_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tsd9r/lots_on_on_prem_experience_no_cloud_experience/", "subreddit_subscribers": 123374, "created_utc": 1692289750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear data engineers,   \n\nHere's another approach to building a customizable Modern Data Stack (MDS) in a single package.\n\nThis insightful article introduces a ***GA4*** events source in combination with **dlt**, **dbt**, **DuckDB**, **MotherDuck**, and **Metabase** for creating seamless data pipelines from scratch and deploying them to production.\n\nDive into the technical details and consider how to simplify data ingestion, transformation, and visualization. If you're passionate about data and want to explore a fresh perspective on MDS, this is a must-read!\n\n\ud83d\udcd6 Read the full article here: [Blog post](https://dlthub.com/docs/blog/dlt-motherduck-demo)\n\n\ud83c\udfa5 Watch the loom video: [Loom video](https://www.loom.com/share/2bf3a187edb54c3cae8f32b5430dd0cd?sid=c6193f1c-07cf-45b8-8fe7-2f854d098704)\n\n\ud83d\udc49 Join the conversation and gain insights from fellow enthusiasts in [the dlt Slack community!](https://join.slack.com/t/dlthub-community/shared_invite/zt-1slox199h-HAE7EQoXmstkP_bTqal65g)\n\nHappy reading!", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Simplified MDS in a box! with dlt, dbt, DuckDB, MotherDuck, and Metabase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15touk8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692281687.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear data engineers,   &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s another approach to building a customizable Modern Data Stack (MDS) in a single package.&lt;/p&gt;\n\n&lt;p&gt;This insightful article introduces a &lt;strong&gt;&lt;em&gt;GA4&lt;/em&gt;&lt;/strong&gt; events source in combination with &lt;strong&gt;dlt&lt;/strong&gt;, &lt;strong&gt;dbt&lt;/strong&gt;, &lt;strong&gt;DuckDB&lt;/strong&gt;, &lt;strong&gt;MotherDuck&lt;/strong&gt;, and &lt;strong&gt;Metabase&lt;/strong&gt; for creating seamless data pipelines from scratch and deploying them to production.&lt;/p&gt;\n\n&lt;p&gt;Dive into the technical details and consider how to simplify data ingestion, transformation, and visualization. If you&amp;#39;re passionate about data and want to explore a fresh perspective on MDS, this is a must-read!&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcd6 Read the full article here: &lt;a href=\"https://dlthub.com/docs/blog/dlt-motherduck-demo\"&gt;Blog post&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udfa5 Watch the loom video: &lt;a href=\"https://www.loom.com/share/2bf3a187edb54c3cae8f32b5430dd0cd?sid=c6193f1c-07cf-45b8-8fe7-2f854d098704\"&gt;Loom video&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc49 Join the conversation and gain insights from fellow enthusiasts in &lt;a href=\"https://join.slack.com/t/dlthub-community/shared_invite/zt-1slox199h-HAE7EQoXmstkP_bTqal65g\"&gt;the dlt Slack community!&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Happy reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?auto=webp&amp;s=d391739ead216d44e810a905331dc5207e6ae30d", "width": 1226, "height": 419}, "resolutions": [{"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=98dfb0ae5b60a5e292ebfb98dfc788a08283d476", "width": 108, "height": 36}, {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a77b0e5882d5ca28890e92adaa1fb57ca881f7e7", "width": 216, "height": 73}, {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bffe572d02d6c77efb93beb172e6846759f1e0dd", "width": 320, "height": 109}, {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a9085fa551306aec021df6e018b54a6d81f9ec3a", "width": 640, "height": 218}, {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=329a29d2ec6c911e981655092a2915c63503a8cc", "width": 960, "height": 328}, {"url": "https://external-preview.redd.it/-r4BaZ2YA2QlAGFXxi891FZAi9chH9V0EX6CFUTzpmw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=862909a1d252bff7b26a3a9789690bd65f66f459", "width": 1080, "height": 369}], "variants": {}, "id": "afjYuREOaT4bQBJgRudtYf7GMXVtSBqS8UuFyHzE3NU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15touk8", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15touk8/simplified_mds_in_a_box_with_dlt_dbt_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15touk8/simplified_mds_in_a_box_with_dlt_dbt_duckdb/", "subreddit_subscribers": 123374, "created_utc": 1692281687.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my SWEs decided it was best to use Fivetran to connect to Sage Intacct because of some distinct challenges with the authentication methods used by Sage Intacct. This was decided largely because we had previously configured Fivetran for another connector and it would be quite easy to build upon that work. Didn\u2019t think twice about it at the time. \n\nFast forward a while and we\u2019ve come to realize there are a litany of data issues present with Fivetran\u2019s Sage Intacct connector. \n\nAs best as I can tell, Fivetran is attempting to use a batch CDC for their incremental sync by syncing with an events log table. But, it appears the joke is one Fivetran as the underlying source of their transactional data (gl_data) is not a materialized table and therefore does not have DML actions logged. I\u2019ve been trying to explain this to them with very little progress made. \n\nAnyone else have experience with Fivetran, specifically with their Sage Intacct connector? If so, what are your thoughts on sticking with them versus building a native connector? Any other third party connectors that you might have had success with for Sage Intacct?\n\nThanks in advance.", "author_fullname": "t2_ibioowgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran Sage Intacct Connector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ucztt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "8cf4f390-e787-11ed-81a4-ca7b65282907", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692341920.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my SWEs decided it was best to use Fivetran to connect to Sage Intacct because of some distinct challenges with the authentication methods used by Sage Intacct. This was decided largely because we had previously configured Fivetran for another connector and it would be quite easy to build upon that work. Didn\u2019t think twice about it at the time. &lt;/p&gt;\n\n&lt;p&gt;Fast forward a while and we\u2019ve come to realize there are a litany of data issues present with Fivetran\u2019s Sage Intacct connector. &lt;/p&gt;\n\n&lt;p&gt;As best as I can tell, Fivetran is attempting to use a batch CDC for their incremental sync by syncing with an events log table. But, it appears the joke is one Fivetran as the underlying source of their transactional data (gl_data) is not a materialized table and therefore does not have DML actions logged. I\u2019ve been trying to explain this to them with very little progress made. &lt;/p&gt;\n\n&lt;p&gt;Anyone else have experience with Fivetran, specifically with their Sage Intacct connector? If so, what are your thoughts on sticking with them versus building a native connector? Any other third party connectors that you might have had success with for Sage Intacct?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Staff Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15ucztt", "is_robot_indexable": true, "report_reasons": null, "author": "SDFP-A", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15ucztt/fivetran_sage_intacct_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ucztt/fivetran_sage_intacct_connector/", "subreddit_subscribers": 123374, "created_utc": 1692341920.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are moving from on-prem servers and SQL Server databases to AWS. Currently, 99% of the data load jobs are done using SSIS packages, maintained by a single DBA who doesn\u2019t believe in documentation. Understandably, the company wants to have a more robust solution. \n\nSo we are now looking at tools for doing the E and L of ELT using open source tools, for more visibility and transparency. We are good with Python and SQL. We also have established workflow in dbt for data warehousing. Airflow is our orchestrator.\n\nOur data sources appear to be mainly from external vendor SQL Server databases, APIs, and flat files from SFTP sites. We are using RDS for hosting SQL Server databases on AWS. \n\nWe are currently trying out Airbyte, which looks promising, but the SQL Server connector is in alpha stage, which worries me about its stability. AWS Glue seems overkill because in almost all cases we just want to do straight extract and load, leaving transformation to dbt. We very likely won\u2019t be looking for a hosted solution outside of any offerings that AWS has.   Cost is a consideration. We are willing to take on additional costs to mitigate the risk of relying on a single person, but we are a smallish organization.\n\nThank you in advance!", "author_fullname": "t2_b1gt6885", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing open source extract and load tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15u1hdi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692310245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are moving from on-prem servers and SQL Server databases to AWS. Currently, 99% of the data load jobs are done using SSIS packages, maintained by a single DBA who doesn\u2019t believe in documentation. Understandably, the company wants to have a more robust solution. &lt;/p&gt;\n\n&lt;p&gt;So we are now looking at tools for doing the E and L of ELT using open source tools, for more visibility and transparency. We are good with Python and SQL. We also have established workflow in dbt for data warehousing. Airflow is our orchestrator.&lt;/p&gt;\n\n&lt;p&gt;Our data sources appear to be mainly from external vendor SQL Server databases, APIs, and flat files from SFTP sites. We are using RDS for hosting SQL Server databases on AWS. &lt;/p&gt;\n\n&lt;p&gt;We are currently trying out Airbyte, which looks promising, but the SQL Server connector is in alpha stage, which worries me about its stability. AWS Glue seems overkill because in almost all cases we just want to do straight extract and load, leaving transformation to dbt. We very likely won\u2019t be looking for a hosted solution outside of any offerings that AWS has.   Cost is a consideration. We are willing to take on additional costs to mitigate the risk of relying on a single person, but we are a smallish organization.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15u1hdi", "is_robot_indexable": true, "report_reasons": null, "author": "Strange_Upstairs9456", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15u1hdi/choosing_open_source_extract_and_load_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15u1hdi/choosing_open_source_extract_and_load_tool/", "subreddit_subscribers": 123374, "created_utc": 1692310245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI wanted to share a project I have built, maybe some of you find it interesting. The project can be found here: [https://github.com/dominikhei/eartquake-streaming](https://github.com/dominikhei/eartquake-streaming)\n\nWith this project I have built a distributed system to display earthquakes in real time on a map, accessible via your browser. The front end service on Fargate has an upstream loadbalancer to scale out if needed. Data is streamed using Springboot Kafka in a Docker Compose setup. The whole AWS infrastructure is created and configured using Terraform. In addition to that I have implemented logging of the backend using Promtail, Loki and Grafana.\n\nObviously the projects is overengineered, but I had  fun building it.\n\nFeedback is well appreciated :)", "author_fullname": "t2_v219tksh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project showcase: Distributed System on AWS streaming earthquakes using Kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tyvgg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1692304416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I wanted to share a project I have built, maybe some of you find it interesting. The project can be found here: &lt;a href=\"https://github.com/dominikhei/eartquake-streaming\"&gt;https://github.com/dominikhei/eartquake-streaming&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;With this project I have built a distributed system to display earthquakes in real time on a map, accessible via your browser. The front end service on Fargate has an upstream loadbalancer to scale out if needed. Data is streamed using Springboot Kafka in a Docker Compose setup. The whole AWS infrastructure is created and configured using Terraform. In addition to that I have implemented logging of the backend using Promtail, Loki and Grafana.&lt;/p&gt;\n\n&lt;p&gt;Obviously the projects is overengineered, but I had  fun building it.&lt;/p&gt;\n\n&lt;p&gt;Feedback is well appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?auto=webp&amp;s=f3b64e28101051429559372b5aeb98884301229b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eb6a8172d47007f72c2f0183f6fa0b669826d0e2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=943c5ceb61b72408f718effc4e442a91e7653462", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3a317d8b53191a6640b22cf2620747430f1d8191", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0195143e4fe8977aea02bec33010a0e873b345a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=219bc6cc3232e88d49b511f0eb78e63c0f325682", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/l3De9l80CBYVmeQiaXHU8UV8Z46f62J6IqGCzaIIOKE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=11e5c0eccc404f77401851c536fe17895134daca", "width": 1080, "height": 540}], "variants": {}, "id": "kS-I3ya27NJN-dmNgvM5ikzQz5_TUVACPdituRrCqh4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "15tyvgg", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Hand-577", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tyvgg/project_showcase_distributed_system_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tyvgg/project_showcase_distributed_system_on_aws/", "subreddit_subscribers": 123374, "created_utc": 1692304416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is currently in the process of moving ELT process from IBM DataStage to python. We are currently researching using pyspark which seemed to be a pretty promising tool until we tried writing large files to relational databases with concurrent sessions. The file I am trying to write is about 10g large with over 700 columns in it and spark seems to read the file incredibly fast but databases are a big bottleneck. We currently have 2 types of relational databases that within our warehouse which are SQL Server and Teradata. SQL Server gets about half way through the load and crashes due to a overwhelming amount of transaction logs being written and Teradata will block more than 1 session trying to write to a database. \n\nAfter this research I feel like I am doing something wrong. Is spark the best tool for this job? Is there a  certain design that can avoid this issue? ", "author_fullname": "t2_6lh4st48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Spark to Migrating Data to Relational Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15trsml", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692288387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is currently in the process of moving ELT process from IBM DataStage to python. We are currently researching using pyspark which seemed to be a pretty promising tool until we tried writing large files to relational databases with concurrent sessions. The file I am trying to write is about 10g large with over 700 columns in it and spark seems to read the file incredibly fast but databases are a big bottleneck. We currently have 2 types of relational databases that within our warehouse which are SQL Server and Teradata. SQL Server gets about half way through the load and crashes due to a overwhelming amount of transaction logs being written and Teradata will block more than 1 session trying to write to a database. &lt;/p&gt;\n\n&lt;p&gt;After this research I feel like I am doing something wrong. Is spark the best tool for this job? Is there a  certain design that can avoid this issue? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15trsml", "is_robot_indexable": true, "report_reasons": null, "author": "Equivalent_Bluebird7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15trsml/using_spark_to_migrating_data_to_relational/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15trsml/using_spark_to_migrating_data_to_relational/", "subreddit_subscribers": 123374, "created_utc": 1692288387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can DLT-Meta be run independently in the databricks notebook or can only be enabled thru databricks workflows", "author_fullname": "t2_kbwr9eii", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks DLT-Meta API", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tkao1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692270484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can DLT-Meta be run independently in the databricks notebook or can only be enabled thru databricks workflows&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15tkao1", "is_robot_indexable": true, "report_reasons": null, "author": "Dismal-Ad3028", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tkao1/databricks_dltmeta_api/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tkao1/databricks_dltmeta_api/", "subreddit_subscribers": 123374, "created_utc": 1692270484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For object store on kubernetes which one should I choose? At first glance apache ozone has absolute garbage documentation, whereas it is much easier to google stuff if you have issues with minio.\n\nWhat is your experience with these 2? Why do you think apache ozone's documentation is so bad?\n\nWould you go into production with apache ozone? It seems like an alpha version product. \n\nOr do you think apache ozone will eventually mature and be the number one object store for big data?", "author_fullname": "t2_537mfbyg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache ozone vs minio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tzsv4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1692306822.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692306426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For object store on kubernetes which one should I choose? At first glance apache ozone has absolute garbage documentation, whereas it is much easier to google stuff if you have issues with minio.&lt;/p&gt;\n\n&lt;p&gt;What is your experience with these 2? Why do you think apache ozone&amp;#39;s documentation is so bad?&lt;/p&gt;\n\n&lt;p&gt;Would you go into production with apache ozone? It seems like an alpha version product. &lt;/p&gt;\n\n&lt;p&gt;Or do you think apache ozone will eventually mature and be the number one object store for big data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15tzsv4", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous-Heat-6353", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tzsv4/apache_ozone_vs_minio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tzsv4/apache_ozone_vs_minio/", "subreddit_subscribers": 123374, "created_utc": 1692306426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Starting a data remodel at a \u201cmature startup\u201d. Standard Kimball method is appropriate for this use-case so nothing fancy going on. I\u2019ve worked on a few remodels in my career as a contributor, and I\u2019d like to manage this one better. \n\nI\u2019m thinking that we\u2019ll use existing reports and reporting needs as the base level business use-case, and going report to report, diagramming, building in dbt, and having a peer review process to confirm that the use case is satisfied. \n\nWhat tools and techniques do you like to follow when doing this to make sure nothing falls through the cracks?\n\nPs: we lack a proper project manager right now so I\u2019m just trying to step up and at least offer some form of cohesive workflow before everyone works on this in their own disjointed way. \n\nThanks", "author_fullname": "t2_jyzw4d7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you like organize work when rebuilding a large enterprise model to make sure nothing is missed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15txc20", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692301013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Starting a data remodel at a \u201cmature startup\u201d. Standard Kimball method is appropriate for this use-case so nothing fancy going on. I\u2019ve worked on a few remodels in my career as a contributor, and I\u2019d like to manage this one better. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking that we\u2019ll use existing reports and reporting needs as the base level business use-case, and going report to report, diagramming, building in dbt, and having a peer review process to confirm that the use case is satisfied. &lt;/p&gt;\n\n&lt;p&gt;What tools and techniques do you like to follow when doing this to make sure nothing falls through the cracks?&lt;/p&gt;\n\n&lt;p&gt;Ps: we lack a proper project manager right now so I\u2019m just trying to step up and at least offer some form of cohesive workflow before everyone works on this in their own disjointed way. &lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15txc20", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Positive-7272", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15txc20/how_do_you_like_organize_work_when_rebuilding_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15txc20/how_do_you_like_organize_work_when_rebuilding_a/", "subreddit_subscribers": 123374, "created_utc": 1692301013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for simplistic tools for a one off data compaction of partitioned csv/parquet files in cloud storage. Have hive based storage partitions by day; where each day may have none to several hundreds of small csv/parquet files(type/schema stays consistent I just have multiple datasets). Looking to merge them to preset chunks. Started to put together a script to do it but interested if there\u2019s tooling that already is tested.\n\nNot looking to add expansive tools with large setup efforts. Overall dataset size is tiny &lt;100gb. Suggestions?\n\nI'd also be interested in considerations for validations that the compaction didn't modify data; I was primarily leaning towards row count and row count by id. Though that doesn't test any of the actual data.", "author_fullname": "t2_20funj35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy tool for data compaction?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15trwwk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692288666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for simplistic tools for a one off data compaction of partitioned csv/parquet files in cloud storage. Have hive based storage partitions by day; where each day may have none to several hundreds of small csv/parquet files(type/schema stays consistent I just have multiple datasets). Looking to merge them to preset chunks. Started to put together a script to do it but interested if there\u2019s tooling that already is tested.&lt;/p&gt;\n\n&lt;p&gt;Not looking to add expansive tools with large setup efforts. Overall dataset size is tiny &amp;lt;100gb. Suggestions?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d also be interested in considerations for validations that the compaction didn&amp;#39;t modify data; I was primarily leaning towards row count and row count by id. Though that doesn&amp;#39;t test any of the actual data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15trwwk", "is_robot_indexable": true, "report_reasons": null, "author": "FridayPush", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15trwwk/easy_tool_for_data_compaction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15trwwk/easy_tool_for_data_compaction/", "subreddit_subscribers": 123374, "created_utc": 1692288666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just make the api call, store the json response, iterate through the data and push the data to postgres. Am I missing anything in this process?", "author_fullname": "t2_e0rep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle API calls and storing the data? Am i missing anything in my process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15tnpud", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692279052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just make the api call, store the json response, iterate through the data and push the data to postgres. Am I missing anything in this process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15tnpud", "is_robot_indexable": true, "report_reasons": null, "author": "BiggyDeeKay", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15tnpud/how_do_you_handle_api_calls_and_storing_the_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15tnpud/how_do_you_handle_api_calls_and_storing_the_data/", "subreddit_subscribers": 123374, "created_utc": 1692279052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm setting up my first proper data pipeline and would like some advice.\n\nI'm collecting user data from a web app (i.e. user clicks x button, user opens app etc).  I've written a basic api which takes the event name and various attributes and stores that in a MySQL database, hosted in AWS. \n\nI set this up a few months ago and it's not reaching \\~30 million rows and this is about to accelerate.  Querying the database is now taking longer where it's starting to cause problems.\n\nI've been reading up on data engineeing, one thing confuses me is data lakes.  Should I be storing the data as it comes in as JSON files in S3?  JOSN file per day (although concurrent writes will be a problem), JSON file per event. Then write scripts to summarise this data and store it in a MySQL database? \n\nAny pointers you could give me would be great on how best to approach this.\n\nOne problem is that the companies finaces are pretty tight and data pipeline is not high priority so free and open source solutions would be great", "author_fullname": "t2_609ngt1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data pipeline for events for an app", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15ufk2q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692350716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m setting up my first proper data pipeline and would like some advice.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m collecting user data from a web app (i.e. user clicks x button, user opens app etc).  I&amp;#39;ve written a basic api which takes the event name and various attributes and stores that in a MySQL database, hosted in AWS. &lt;/p&gt;\n\n&lt;p&gt;I set this up a few months ago and it&amp;#39;s not reaching ~30 million rows and this is about to accelerate.  Querying the database is now taking longer where it&amp;#39;s starting to cause problems.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been reading up on data engineeing, one thing confuses me is data lakes.  Should I be storing the data as it comes in as JSON files in S3?  JOSN file per day (although concurrent writes will be a problem), JSON file per event. Then write scripts to summarise this data and store it in a MySQL database? &lt;/p&gt;\n\n&lt;p&gt;Any pointers you could give me would be great on how best to approach this.&lt;/p&gt;\n\n&lt;p&gt;One problem is that the companies finaces are pretty tight and data pipeline is not high priority so free and open source solutions would be great&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15ufk2q", "is_robot_indexable": true, "report_reasons": null, "author": "btb331", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ufk2q/data_pipeline_for_events_for_an_app/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ufk2q/data_pipeline_for_events_for_an_app/", "subreddit_subscribers": 123374, "created_utc": 1692350716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im curious to know what all are the optimise techniques for improving SQL databases performance ( not the query alone )?\n\nFew of them would be came to my mind - \n\n1. Partitioning / Sharding\n2. Selecting the right indexes ( BTree )\n3. Optimising the SQL query execution\n\nAnything else that can be added?\n\n&amp;#x200B;", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Database optimisation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15uewl7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692348476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im curious to know what all are the optimise techniques for improving SQL databases performance ( not the query alone )?&lt;/p&gt;\n\n&lt;p&gt;Few of them would be came to my mind - &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Partitioning / Sharding&lt;/li&gt;\n&lt;li&gt;Selecting the right indexes ( BTree )&lt;/li&gt;\n&lt;li&gt;Optimising the SQL query execution&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Anything else that can be added?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15uewl7", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/15uewl7/sql_database_optimisation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15uewl7/sql_database_optimisation/", "subreddit_subscribers": 123374, "created_utc": 1692348476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a job interview for a dream data engineer role and am freaking out cause I\u2019ve never really done any data engineering other than some data acquisition and eeprom data decoding. My background is in aerospace and electrical engineering with a good base in python and C++. I started the basics of sql and  am probably gonna do a quick crash course on spark. What would you guys recommend I do to go from 0 to basic knowledge of data engineering?", "author_fullname": "t2_p33cd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do I start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ueo9c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1692347679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a job interview for a dream data engineer role and am freaking out cause I\u2019ve never really done any data engineering other than some data acquisition and eeprom data decoding. My background is in aerospace and electrical engineering with a good base in python and C++. I started the basics of sql and  am probably gonna do a quick crash course on spark. What would you guys recommend I do to go from 0 to basic knowledge of data engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15ueo9c", "is_robot_indexable": true, "report_reasons": null, "author": "4awesome1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15ueo9c/where_do_i_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15ueo9c/where_do_i_start/", "subreddit_subscribers": 123374, "created_utc": 1692347679.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}