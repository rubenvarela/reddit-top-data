{"kind": "Listing", "data": {"after": "t3_15fde64", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work at a large company, and we receive quite a lot of applicants. Most of our applicants have 6-9 years of experience in roles titled as Data Analytics/Data Science/Data Engineering across notable companies and brands like Walmart, Ford, Accenture, Amazon, Ulta, Macy's, Nike, etc.\n\nThe nature of our interviews is fairly simple - we have a brief phone call on theory and foundation of data analytics, and then have a couple of technical interviews focusing on programming and basic data analysis. The interview doesn't cover anything out of the ordinary for most analysts (not even data scientists), and focuses on basic data analysis practices (filter down a column given a set of requirements, get a count of uniques, do basic EDA and explain how to manage outliers). \n\nAll interviewees are told they can use Google as we don't expect people to memorize the syntax, but we do expect them to have at least working knowledge of the tools we expect them to use. The interviews are all remote and don't require in-person meeting. The interviews are basically screen share of Google Colab where we run basic analysis.\n\nIn our recent hiring spree, out of the 7 potential candidates we interviewed, we caught 4 of them cheating.\n\nGiven their profile, I'm a bit amazed that they resorted to cheating. Whether it was by having someone else on the call helping them answer the question, or having someone entirely different answer their questions, and other notable methods that I don't want to share that we caught while they were sharing their screens. I've learned from my colleagues that there are actual *agencies* in India and China who offer interview 'assistance' services.\n\nAt this stage, our leadership is planning to require all potential candidates to be local - this eliminates remote option. On the same token, those cheaters passing the recruiter screening are quite frankly just making it worse for people who are actually capable. Questions become more theoretical and quite specific to industry, scope of hiring will be limited to people within specific domains, and improptu coding tests will be given out without heads up to hinder people from cheating and setting up whatever they do to cheat.\n\n/endrant", "author_fullname": "t2_48648", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RANT - There's a cheating problem in Data Science Interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15flo97", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 160, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 160, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690916881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a large company, and we receive quite a lot of applicants. Most of our applicants have 6-9 years of experience in roles titled as Data Analytics/Data Science/Data Engineering across notable companies and brands like Walmart, Ford, Accenture, Amazon, Ulta, Macy&amp;#39;s, Nike, etc.&lt;/p&gt;\n\n&lt;p&gt;The nature of our interviews is fairly simple - we have a brief phone call on theory and foundation of data analytics, and then have a couple of technical interviews focusing on programming and basic data analysis. The interview doesn&amp;#39;t cover anything out of the ordinary for most analysts (not even data scientists), and focuses on basic data analysis practices (filter down a column given a set of requirements, get a count of uniques, do basic EDA and explain how to manage outliers). &lt;/p&gt;\n\n&lt;p&gt;All interviewees are told they can use Google as we don&amp;#39;t expect people to memorize the syntax, but we do expect them to have at least working knowledge of the tools we expect them to use. The interviews are all remote and don&amp;#39;t require in-person meeting. The interviews are basically screen share of Google Colab where we run basic analysis.&lt;/p&gt;\n\n&lt;p&gt;In our recent hiring spree, out of the 7 potential candidates we interviewed, we caught 4 of them cheating.&lt;/p&gt;\n\n&lt;p&gt;Given their profile, I&amp;#39;m a bit amazed that they resorted to cheating. Whether it was by having someone else on the call helping them answer the question, or having someone entirely different answer their questions, and other notable methods that I don&amp;#39;t want to share that we caught while they were sharing their screens. I&amp;#39;ve learned from my colleagues that there are actual &lt;em&gt;agencies&lt;/em&gt; in India and China who offer interview &amp;#39;assistance&amp;#39; services.&lt;/p&gt;\n\n&lt;p&gt;At this stage, our leadership is planning to require all potential candidates to be local - this eliminates remote option. On the same token, those cheaters passing the recruiter screening are quite frankly just making it worse for people who are actually capable. Questions become more theoretical and quite specific to industry, scope of hiring will be limited to people within specific domains, and improptu coding tests will be given out without heads up to hinder people from cheating and setting up whatever they do to cheat.&lt;/p&gt;\n\n&lt;p&gt;/endrant&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15flo97", "is_robot_indexable": true, "report_reasons": null, "author": "forbiscuit", "discussion_type": null, "num_comments": 95, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15flo97/rant_theres_a_cheating_problem_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15flo97/rant_theres_a_cheating_problem_in_data_science/", "subreddit_subscribers": 971053, "created_utc": 1690916881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, y'all. I've been wanting to address this question for some time now. The sub is slowly changing to r/learndatascience. We get the same questions posted here everyday (sometimes several times on the same day):\n\n1. What degree should I get?\n2. How much math should I learn to work with DS?\n3. How can I get the first job?\n4. Will IA replace DS jobs?\n5. Now and then also there are the \"I don't like math, how can I work with DS\", or the \"do I really need to learn advanced math?\" where by advanced math people mean linear algebra and calculus.\n\nI understand that these are honest questions, but they have been already asked billions of times. Also, it is kind of astounding how people want to work with a technical field, hence you need to be constantly learning things and searching for answers, and yet they don't even bother to search if the same question was already asked on the sub. I mean, this is not even hard to do, you don't even have to be on reddit, just post on google reddit + question and google will show the it.\n\nIn my opinion this is bad for the sub as an online forum. Compare, e.g., with stackexchange. If a question was already asked people will shut it as duplicate and link to the previous post where it was already answered. This is bad, imo, because, it floods the sub and prevents people from having good discussions about the topic of the sub. I mean, it is quite some time that I don't see a real DS post here.\n\nI know that it can sound like a rant, but I understand r/datascience as a forum where people go to talk about DS and honestly I miss seeing these posts, e.g., people talking about how they solved some particular problem, talking about research papers and etc.\n\nAnd last but not least, I know that DS was hyped and people think that it is the new \"dev\" job to get easy money. But I think that discuss this topic we would be better suited with a post just to address it. \n\n&amp;#x200B;", "author_fullname": "t2_hmlahc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Discussion about the sub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fcchn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 145, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 145, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690895800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, y&amp;#39;all. I&amp;#39;ve been wanting to address this question for some time now. The sub is slowly changing to &lt;a href=\"/r/learndatascience\"&gt;r/learndatascience&lt;/a&gt;. We get the same questions posted here everyday (sometimes several times on the same day):&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What degree should I get?&lt;/li&gt;\n&lt;li&gt;How much math should I learn to work with DS?&lt;/li&gt;\n&lt;li&gt;How can I get the first job?&lt;/li&gt;\n&lt;li&gt;Will IA replace DS jobs?&lt;/li&gt;\n&lt;li&gt;Now and then also there are the &amp;quot;I don&amp;#39;t like math, how can I work with DS&amp;quot;, or the &amp;quot;do I really need to learn advanced math?&amp;quot; where by advanced math people mean linear algebra and calculus.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I understand that these are honest questions, but they have been already asked billions of times. Also, it is kind of astounding how people want to work with a technical field, hence you need to be constantly learning things and searching for answers, and yet they don&amp;#39;t even bother to search if the same question was already asked on the sub. I mean, this is not even hard to do, you don&amp;#39;t even have to be on reddit, just post on google reddit + question and google will show the it.&lt;/p&gt;\n\n&lt;p&gt;In my opinion this is bad for the sub as an online forum. Compare, e.g., with stackexchange. If a question was already asked people will shut it as duplicate and link to the previous post where it was already answered. This is bad, imo, because, it floods the sub and prevents people from having good discussions about the topic of the sub. I mean, it is quite some time that I don&amp;#39;t see a real DS post here.&lt;/p&gt;\n\n&lt;p&gt;I know that it can sound like a rant, but I understand &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt; as a forum where people go to talk about DS and honestly I miss seeing these posts, e.g., people talking about how they solved some particular problem, talking about research papers and etc.&lt;/p&gt;\n\n&lt;p&gt;And last but not least, I know that DS was hyped and people think that it is the new &amp;quot;dev&amp;quot; job to get easy money. But I think that discuss this topic we would be better suited with a post just to address it. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fcchn", "is_robot_indexable": true, "report_reasons": null, "author": "magikarpa1", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fcchn/discussion_about_the_sub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fcchn/discussion_about_the_sub/", "subreddit_subscribers": 971053, "created_utc": 1690895800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been searching around for a while now trying to find freelance work on the weekends for beer money but haven't been successful. I have tried Upwork aggressively for like 3 months straights and got no responses.  \n\nI just want like 10-15 hours on weekends so I can afford toilet paper and diapers for my 9 month old.", "author_fullname": "t2_kw1h2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Freelance work on the weekends a thing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f8n3b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690885810.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been searching around for a while now trying to find freelance work on the weekends for beer money but haven&amp;#39;t been successful. I have tried Upwork aggressively for like 3 months straights and got no responses.  &lt;/p&gt;\n\n&lt;p&gt;I just want like 10-15 hours on weekends so I can afford toilet paper and diapers for my 9 month old.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15f8n3b", "is_robot_indexable": true, "report_reasons": null, "author": "frescoj10", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15f8n3b/is_freelance_work_on_the_weekends_a_thing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15f8n3b/is_freelance_work_on_the_weekends_a_thing/", "subreddit_subscribers": 971053, "created_utc": 1690885810.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TL;DR You need to drive outsized value beyond just your team. That means you need to interact with business stakeholders and consistently solve their business problems with data. The quicker you learn to effectively engage business stakeholders, the quicker you will promote.\n\nIf you only \"speak data\" to your stakeholders, you are setting yourself up for failure. You can escape this trap by learning to instead \"translate data\" to your stakeholders. Here's how:\n\nThe below means NOTHING to your business stakeholders and you won't get the buy-in you need to actually drive change and value in your respective organization.\n\n\"We should care about data quality!\"\n\n\"We really need to consider creating a proper data model!\"\n\n\"This data pipeline is a bottleneck for your dashboard!\"\n\nInstead...\n\n1. Understand that data is extremely abstract, and most people are not trained to deal with this abstraction. For example, tell me about a single row in an excel sheet? Very easy to name off the fields. Now tell me about a thousand rows in an excel sheet... it's hard. This is exactly what your stakeholders are facing. This is why it's so hard for them to create meaningful requests and requirements.\n\n2. Ask your stakeholders about the business context, the reason why the request is being made, and how the output will be used by the business. Ask probing questions about the business and not the data.\n\n3. Use your domain expertise to map the business requirements to data requirements-- this is now your \"translation\" map for all future communications.\n\n4. With this mapping you need to answer the following without \"speaking data\" to your stakeholder: a) what was the business challenge, b) what is the solution to this business problem, and c) how they can use this solution today. This stakeholder is going to pass this information on to others, so train them to be successful in that. When you help others win, you win as well!\n\nThe above sentence examples may look like the following:\n\n\"We are fined $X amount by regulators for every wrong record, with our current data we are expected to be fined $Y amount. We can avoid this enormous penalty by implementing Z process.\" [Data Quality]\n\n\"The most recent board meeting had conflicting financial numbers presented in the deck. Both numbers were 'correct' depending on the tables used and which team was asked. We can prevent this from happening again by cleaning up the which tables can be pulled from and how the numbers are generated.\" [Data Model]\n\n\"This dashboard has a two day lag, making daily check-ins with enterprise customers difficult. We can change the data pipeline SLA to one day and work towards meeting that SLA given the new business context.\" [Slow Data]\n\nHope this helps!", "author_fullname": "t2_v7fvlqc8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How I quickly rose to senior data scientist and eventually senior data engineer.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fqkuj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690928046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR You need to drive outsized value beyond just your team. That means you need to interact with business stakeholders and consistently solve their business problems with data. The quicker you learn to effectively engage business stakeholders, the quicker you will promote.&lt;/p&gt;\n\n&lt;p&gt;If you only &amp;quot;speak data&amp;quot; to your stakeholders, you are setting yourself up for failure. You can escape this trap by learning to instead &amp;quot;translate data&amp;quot; to your stakeholders. Here&amp;#39;s how:&lt;/p&gt;\n\n&lt;p&gt;The below means NOTHING to your business stakeholders and you won&amp;#39;t get the buy-in you need to actually drive change and value in your respective organization.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;We should care about data quality!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;We really need to consider creating a proper data model!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;This data pipeline is a bottleneck for your dashboard!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Instead...&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Understand that data is extremely abstract, and most people are not trained to deal with this abstraction. For example, tell me about a single row in an excel sheet? Very easy to name off the fields. Now tell me about a thousand rows in an excel sheet... it&amp;#39;s hard. This is exactly what your stakeholders are facing. This is why it&amp;#39;s so hard for them to create meaningful requests and requirements.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Ask your stakeholders about the business context, the reason why the request is being made, and how the output will be used by the business. Ask probing questions about the business and not the data.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Use your domain expertise to map the business requirements to data requirements-- this is now your &amp;quot;translation&amp;quot; map for all future communications.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;With this mapping you need to answer the following without &amp;quot;speaking data&amp;quot; to your stakeholder: a) what was the business challenge, b) what is the solution to this business problem, and c) how they can use this solution today. This stakeholder is going to pass this information on to others, so train them to be successful in that. When you help others win, you win as well!&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The above sentence examples may look like the following:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;We are fined $X amount by regulators for every wrong record, with our current data we are expected to be fined $Y amount. We can avoid this enormous penalty by implementing Z process.&amp;quot; [Data Quality]&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;The most recent board meeting had conflicting financial numbers presented in the deck. Both numbers were &amp;#39;correct&amp;#39; depending on the tables used and which team was asked. We can prevent this from happening again by cleaning up the which tables can be pulled from and how the numbers are generated.&amp;quot; [Data Model]&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;This dashboard has a two day lag, making daily check-ins with enterprise customers difficult. We can change the data pipeline SLA to one day and work towards meeting that SLA given the new business context.&amp;quot; [Slow Data]&lt;/p&gt;\n\n&lt;p&gt;Hope this helps!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fqkuj", "is_robot_indexable": true, "report_reasons": null, "author": "on_the_mark_data", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fqkuj/how_i_quickly_rose_to_senior_data_scientist_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fqkuj/how_i_quickly_rose_to_senior_data_scientist_and/", "subreddit_subscribers": 971053, "created_utc": 1690928046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work on Dask (OSS Python library for parallel computing) and I see people misusing us to run single functions or scripts on cloud machines.  I tell them \"Dask seems like overkill here, maybe there's a simpler tool out there that's easier to use?\"\n\nAfter doing a bit of research, maybe there isn't?  I'm surprised clouds haven't made a smoother UX around Lambda/EC2/Batch/ECS.  Am I missing something?\n\nI wrote a small blog post about this here: [https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc](https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc) . It (shamelessly) advertises and thing we built on top of Dask + Coiled to do make this more palatable for non-cloud-conversant Python folks.  It took about a week of development effort, which I hope is enough to garner some good feedback/critique. This was kind of a slapdash effort, but seems ok?", "author_fullname": "t2_ay1q1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running a single script in the cloud shouldn't be hard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fc6ox", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690895397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work on Dask (OSS Python library for parallel computing) and I see people misusing us to run single functions or scripts on cloud machines.  I tell them &amp;quot;Dask seems like overkill here, maybe there&amp;#39;s a simpler tool out there that&amp;#39;s easier to use?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;After doing a bit of research, maybe there isn&amp;#39;t?  I&amp;#39;m surprised clouds haven&amp;#39;t made a smoother UX around Lambda/EC2/Batch/ECS.  Am I missing something?&lt;/p&gt;\n\n&lt;p&gt;I wrote a small blog post about this here: &lt;a href=\"https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc\"&gt;https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc&lt;/a&gt; . It (shamelessly) advertises and thing we built on top of Dask + Coiled to do make this more palatable for non-cloud-conversant Python folks.  It took about a week of development effort, which I hope is enough to garner some good feedback/critique. This was kind of a slapdash effort, but seems ok?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?auto=webp&amp;s=2500e20c454938762e145ed937b5f672c7107662", "width": 896, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5bcad2d83ba44812cde35a979f693e85f02ddaf9", "width": 108, "height": 48}, {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=52a97dc310c1b8265ad9a42ec3aee06746e66741", "width": 216, "height": 96}, {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dbdbe143a144ea4988a66c1ce8b17371b5656b35", "width": 320, "height": 142}, {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e527de6f5793a0b076997f0214c37ae589620340", "width": 640, "height": 285}], "variants": {}, "id": "bOYGIMA5j7XFBgY_b1492O6l7ahrAYsoMlsFe7s2tWQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fc6ox", "is_robot_indexable": true, "report_reasons": null, "author": "mrocklin", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fc6ox/running_a_single_script_in_the_cloud_shouldnt_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fc6ox/running_a_single_script_in_the_cloud_shouldnt_be/", "subreddit_subscribers": 971053, "created_utc": 1690895397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, I enrolled for a training program that wants me to choose between software engineering and data science. As a person, I enrolled for the program because I want really learn to code; I love coding though I have not had the opportunity to start. At the start, I actually chose data science because I was looking for something that incorporates both software engineering and something else with the hope that I will have enough time learning a lot of coding all the way.\n\nFrom my little research, it seems there is very little coding data scientists do(most of their work end up as visualizations which I kind of detest); however, data engineers seem to do more coding than data scientists.\n\nI am from Nigeria. And, I am looking at the prospects of the two in my country and Africa as a hole especially.\n\nWhat would you advise and do you think I can learn a bit of software engineering along the way since I still have to up my computer science knowledge?\n\n\\*\\*\\*I have no background in computer science and can only solve basic mathematics and statistics.\n\nI have till tomorrow or else I will be confirmed on the data science track. Thanks in advance.", "author_fullname": "t2_bexo9x074", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software engineering vs data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f6vyh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690880301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I enrolled for a training program that wants me to choose between software engineering and data science. As a person, I enrolled for the program because I want really learn to code; I love coding though I have not had the opportunity to start. At the start, I actually chose data science because I was looking for something that incorporates both software engineering and something else with the hope that I will have enough time learning a lot of coding all the way.&lt;/p&gt;\n\n&lt;p&gt;From my little research, it seems there is very little coding data scientists do(most of their work end up as visualizations which I kind of detest); however, data engineers seem to do more coding than data scientists.&lt;/p&gt;\n\n&lt;p&gt;I am from Nigeria. And, I am looking at the prospects of the two in my country and Africa as a hole especially.&lt;/p&gt;\n\n&lt;p&gt;What would you advise and do you think I can learn a bit of software engineering along the way since I still have to up my computer science knowledge?&lt;/p&gt;\n\n&lt;p&gt;***I have no background in computer science and can only solve basic mathematics and statistics.&lt;/p&gt;\n\n&lt;p&gt;I have till tomorrow or else I will be confirmed on the data science track. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15f6vyh", "is_robot_indexable": true, "report_reasons": null, "author": "Comfortable-Pizza447", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15f6vyh/software_engineering_vs_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15f6vyh/software_engineering_vs_data_science/", "subreddit_subscribers": 971053, "created_utc": 1690880301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I swear, it\u2019s a love-hate relationship. They just don\u2019t understand the data, where I\u2019m at, at least, and have a lot of made up assumptions about what certain tools should and should not be able to do.\n\nIt\u2019s not that they\u2019re misinformed that\u2019s frustrating that\u2019s frustrating, it\u2019s the constant repeating myself, or the arguing. I question the value in everything I say, when I find that I\u2019m always repeating the same thing.", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it always so painful to work with marketers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fstj7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690933710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I swear, it\u2019s a love-hate relationship. They just don\u2019t understand the data, where I\u2019m at, at least, and have a lot of made up assumptions about what certain tools should and should not be able to do.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s not that they\u2019re misinformed that\u2019s frustrating that\u2019s frustrating, it\u2019s the constant repeating myself, or the arguing. I question the value in everything I say, when I find that I\u2019m always repeating the same thing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fstj7", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fstj7/is_it_always_so_painful_to_work_with_marketers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fstj7/is_it_always_so_painful_to_work_with_marketers/", "subreddit_subscribers": 971053, "created_utc": 1690933710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm currently working on an academic research project and came across a website that sells data. However, they offer free trials during which I can access the data I need for my research. I was wondering if web scraping this website during the free trial period for academic purposes is considered legal? I know this can be a very gray territory. Any insights or advice would be greatly appreciated. Thanks in advance!", "author_fullname": "t2_2px1ka8r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Web Scraping for Academic Purposes Illegal? (Regarding a Website with Free Trials)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fmzkg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690919865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m currently working on an academic research project and came across a website that sells data. However, they offer free trials during which I can access the data I need for my research. I was wondering if web scraping this website during the free trial period for academic purposes is considered legal? I know this can be a very gray territory. Any insights or advice would be greatly appreciated. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fmzkg", "is_robot_indexable": true, "report_reasons": null, "author": "mmllppnnk", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fmzkg/is_web_scraping_for_academic_purposes_illegal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fmzkg/is_web_scraping_for_academic_purposes_illegal/", "subreddit_subscribers": 971053, "created_utc": 1690919865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A clustering advice\n\nThe situation: I am an operations analyst Ineeded to give each agent the closest 35 customer for him to visit.\n\nSolution : I used kmeans_constrained to cluster the retailers by their longitude and latitude and set the max size to 35 and that\u2019s fine, it does decent job in terms of distances.\n\nCon: it\u2019s really random, it just gets the closest 35 customers to visit regardless of anything else.\n\nSo, I made a custom score for each customer (the higher the score, the better. based on a lot pf kpis) and then, injected some logic into the code to go in the highest score and cluster the customers based on their coordinates, if the total route size is less than 35 it goes to the next score, do the same and so on till it reaches 35.\n\nCon: it\u2019s even more random, a cluster of customers who share a given score does not necessarily mean they are close to the cluster of customers who are in a different score, making the total route distance bigger.\n\n\nMy question:\nIf I cluster the customers based on their coordinates and their score together would this improve targeting and optimize the distance? Does the data need to be standardized? As the scores range from 0 to n (maximum is 30) while the longitude and latitude ranges (30,31) .\n\nOr do you know anything else better suited for the situation and I should read about? I am open to anything.\n\nThanks for your time.", "author_fullname": "t2_81zrh19oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need your advice in A clustering problem.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fodhu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690923000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A clustering advice&lt;/p&gt;\n\n&lt;p&gt;The situation: I am an operations analyst Ineeded to give each agent the closest 35 customer for him to visit.&lt;/p&gt;\n\n&lt;p&gt;Solution : I used kmeans_constrained to cluster the retailers by their longitude and latitude and set the max size to 35 and that\u2019s fine, it does decent job in terms of distances.&lt;/p&gt;\n\n&lt;p&gt;Con: it\u2019s really random, it just gets the closest 35 customers to visit regardless of anything else.&lt;/p&gt;\n\n&lt;p&gt;So, I made a custom score for each customer (the higher the score, the better. based on a lot pf kpis) and then, injected some logic into the code to go in the highest score and cluster the customers based on their coordinates, if the total route size is less than 35 it goes to the next score, do the same and so on till it reaches 35.&lt;/p&gt;\n\n&lt;p&gt;Con: it\u2019s even more random, a cluster of customers who share a given score does not necessarily mean they are close to the cluster of customers who are in a different score, making the total route distance bigger.&lt;/p&gt;\n\n&lt;p&gt;My question:\nIf I cluster the customers based on their coordinates and their score together would this improve targeting and optimize the distance? Does the data need to be standardized? As the scores range from 0 to n (maximum is 30) while the longitude and latitude ranges (30,31) .&lt;/p&gt;\n\n&lt;p&gt;Or do you know anything else better suited for the situation and I should read about? I am open to anything.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fodhu", "is_robot_indexable": true, "report_reasons": null, "author": "Careful_Engineer_700", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fodhu/i_need_your_advice_in_a_clustering_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fodhu/i_need_your_advice_in_a_clustering_problem/", "subreddit_subscribers": 971053, "created_utc": 1690923000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've taken data structures, algorithms, and a few upper division econometrics classes. I'm familiar with R(tidyverse, dplyr) as I took an intro DS class using it, but mostly use Python and C. I'm also about to take a ML and an AI class next quarter. Realizing you have no way of knowing the extent of what I know and don't know, I was wondering if there are some topics that I might have a gap in my knowledge that would be essential to pursuing DS? Is it a major drawback that grad school isn't really an immediate option for me (I would love for it to be in the future)? Are econ majors frowned upon in DS? Thanks for any feedback :).", "author_fullname": "t2_sjesx3di", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm an undergrad Econ major and CS minor with a specialization in Econometrics looking into data science. What are some blind spots I might have as an econ major going into DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15f8yc8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690889263.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690886758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve taken data structures, algorithms, and a few upper division econometrics classes. I&amp;#39;m familiar with R(tidyverse, dplyr) as I took an intro DS class using it, but mostly use Python and C. I&amp;#39;m also about to take a ML and an AI class next quarter. Realizing you have no way of knowing the extent of what I know and don&amp;#39;t know, I was wondering if there are some topics that I might have a gap in my knowledge that would be essential to pursuing DS? Is it a major drawback that grad school isn&amp;#39;t really an immediate option for me (I would love for it to be in the future)? Are econ majors frowned upon in DS? Thanks for any feedback :).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15f8yc8", "is_robot_indexable": true, "report_reasons": null, "author": "thehippophant", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15f8yc8/im_an_undergrad_econ_major_and_cs_minor_with_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15f8yc8/im_an_undergrad_econ_major_and_cs_minor_with_a/", "subreddit_subscribers": 971053, "created_utc": 1690886758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Entering 4th year of college. 3.2 GPA. Have done one 5 month remote internship in another country for a very small company. Have four python projects related to Linear Regression, KNN, and A/B Hypothesis Testing. Have a data wrote article for my school\n\nApplied to 50 internships and only heard back from 1, which left ghosted me. I'm not even looking for a paid position, just ANYTHING at all. \n\nI know I should do an R project or something, but how tf do I manage this with constant classes and work that I need to pay for expensive ass housing?", "author_fullname": "t2_gpw0et82z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice- what would u do if you were in my position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15fuipw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690938273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Entering 4th year of college. 3.2 GPA. Have done one 5 month remote internship in another country for a very small company. Have four python projects related to Linear Regression, KNN, and A/B Hypothesis Testing. Have a data wrote article for my school&lt;/p&gt;\n\n&lt;p&gt;Applied to 50 internships and only heard back from 1, which left ghosted me. I&amp;#39;m not even looking for a paid position, just ANYTHING at all. &lt;/p&gt;\n\n&lt;p&gt;I know I should do an R project or something, but how tf do I manage this with constant classes and work that I need to pay for expensive ass housing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fuipw", "is_robot_indexable": true, "report_reasons": null, "author": "forreeal1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fuipw/need_advice_what_would_u_do_if_you_were_in_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fuipw/need_advice_what_would_u_do_if_you_were_in_my/", "subreddit_subscribers": 971053, "created_utc": 1690938273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "i will be starting a PhD in the fall after a few years of working in the industry. it seems unlikely that i\u2019ll get a chance to work with production quality code or cloud services (i\u2019ve been using Azure) as part of the PhD, and it\u2019ll be a huge loss for me to become out of practice with this skill set. has anyone heard of PhDs who do little jobs on the side to stay relevant? i was thinking of maybe contributing to open-source repositories, or taking on some debugging tasks in a part-time gig, but curious if folks have found some more imaginative ways to keep their skills up-to-date.", "author_fullname": "t2_l8vm8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "keeping coding and Azure skills while doing PhD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fpinb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690925536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i will be starting a PhD in the fall after a few years of working in the industry. it seems unlikely that i\u2019ll get a chance to work with production quality code or cloud services (i\u2019ve been using Azure) as part of the PhD, and it\u2019ll be a huge loss for me to become out of practice with this skill set. has anyone heard of PhDs who do little jobs on the side to stay relevant? i was thinking of maybe contributing to open-source repositories, or taking on some debugging tasks in a part-time gig, but curious if folks have found some more imaginative ways to keep their skills up-to-date.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fpinb", "is_robot_indexable": true, "report_reasons": null, "author": "phenomenonical", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fpinb/keeping_coding_and_azure_skills_while_doing_phd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fpinb/keeping_coding_and_azure_skills_while_doing_phd/", "subreddit_subscribers": 971053, "created_utc": 1690925536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a2ikkd35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "KDD 2023 Predicting Information Pathways Across Online Communities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_15f5xg9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W7Ajd1lMTO0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"KDD 2023 Predicting Information Pathways Across Online Communities\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "KDD 2023 Predicting Information Pathways Across Online Communities", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W7Ajd1lMTO0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"KDD 2023 Predicting Information Pathways Across Online Communities\"&gt;&lt;/iframe&gt;", "author_name": "Association for Computing Machinery (ACM)", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W7Ajd1lMTO0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheOfficialACM"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W7Ajd1lMTO0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"KDD 2023 Predicting Information Pathways Across Online Communities\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/15f5xg9", "height": 200}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4GOvuj7wABNigMXkyDq8dAWt-RKObxvwv7ucBjJCwMo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690876914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=W7Ajd1lMTO0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VYjzaQH5wra6-ykS1lg2cPw1CjoE0U1p_j-mHpTlXFE.jpg?auto=webp&amp;s=378e59f861cfa2715586d4f485b8eb4625589302", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/VYjzaQH5wra6-ykS1lg2cPw1CjoE0U1p_j-mHpTlXFE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=546118d465346aa4e92d1caed09d60575c478c0e", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/VYjzaQH5wra6-ykS1lg2cPw1CjoE0U1p_j-mHpTlXFE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cf0a24871359591d9485de33ea81c738a54689df", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/VYjzaQH5wra6-ykS1lg2cPw1CjoE0U1p_j-mHpTlXFE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f562a50c935ffe2bc8d604818dae8ae968bd2adf", "width": 320, "height": 240}], "variants": {}, "id": "RfmleDVH5aw6JhLTiIm_rtgdI8G9eCSnYs3YAUGuwFs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15f5xg9", "is_robot_indexable": true, "report_reasons": null, "author": "UsefulAd9370", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15f5xg9/kdd_2023_predicting_information_pathways_across/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=W7Ajd1lMTO0", "subreddit_subscribers": 971053, "created_utc": 1690876914.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "KDD 2023 Predicting Information Pathways Across Online Communities", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W7Ajd1lMTO0?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"KDD 2023 Predicting Information Pathways Across Online Communities\"&gt;&lt;/iframe&gt;", "author_name": "Association for Computing Machinery (ACM)", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W7Ajd1lMTO0/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheOfficialACM"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_89utj0oc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you need to evaluate LLMs in dev &amp; prod? Tell us and we'll build it!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15fndg7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9NxyTMDQ9NyCwLrteiqiRqJPTCJ8hwlPI_oHBZu5GBw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690920725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "docs.google.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://docs.google.com/forms/d/e/1FAIpQLScfZ_4MSVmsiaoEByb_Y2tk--J-xtV35P6OnAiyaihbrjwlQQ/viewform", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?auto=webp&amp;s=4baa88eda2d32856c095157b32497cfdcac07817", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5c37ab092aea51e7d8fe5b6e454b73dd2af9d685", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a24ec5eea2909444420c49c93d58f3aaa26a3f7", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=56e9502f843fb8c19f7b578fcdb0fa4798ba91d4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3eda8bdbc31fca5fbaf076ed7009600a4fcd1284", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=569b2d80ddeba8825267f7c9607e466f381cce02", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/SHJGtjA0dtC91vJD09yZIfzKKz8GPwKkrrw1ruE17X0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9a9c89878a8538c3e4dda30aebcdeccd9e530365", "width": 1080, "height": 567}], "variants": {}, "id": "aSd8ncNmnnembYorW0afv1xj2Hz2v5fwuLipkGABsSY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fndg7", "is_robot_indexable": true, "report_reasons": null, "author": "Sciencepeaches", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fndg7/what_do_you_need_to_evaluate_llms_in_dev_prod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://docs.google.com/forms/d/e/1FAIpQLScfZ_4MSVmsiaoEByb_Y2tk--J-xtV35P6OnAiyaihbrjwlQQ/viewform", "subreddit_subscribers": 971053, "created_utc": 1690920725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Greetings to my favorite subreddit!  Fellow data enthusiast here, and I am hoping to get your advice on long term career goals at my employer.\n\n**My background**\n\nMy career started in accounting. Then pivoted to a variety of supply chain roles as an analyst. My roots are entrenched in Microsoft Products. Started as an excel monkey, then SQL neanderthal, followed up by Power BI human. Self-taught through most of it and as smart as stackoverflow allows me to be. Pursuing a MS in Data Science to get more grounded STEM knowledge and better combine with my domain knowledge.\n\n**Courseload thus far and outlook**\n\n\\-Bachelors in Accounting\n\n\\-Udemy courses on Power BI, SQL, DAX, etc\n\n\\-Dataquest modules for Python\n\n\\-Pursuing MS in Data Science at Eastern University\n\n**My employer**\n\nLeading manufacturing of durable juvenile good in the US(strollers, car seats, high chairs, etc.). While we are technically an international company, we are very siloed and operate as a small-medium sized business. I am a data science team of 1. No real IT team in the US besides a 3rd party service that helps with day to day tasks. I am the data wrangler, cleaner and presenter from start to finish. I am the Power BI admin/developer and analyst for our business unit. Launched the reporting suite when I started with the organization 4 years ago. Before that launch, everyone was excel jockeying very disparate data sources often looking at the same number in multiple places.\n\n**Infrastructure(image showing flow in the post)**\n\nLimited to Microsoft 365 solutions.  I do have a lot of leeway when it comes to implementing new software. I just need to present the options to management outlining the cost/benefit analysis. Since I am a team of 1, It can\u2019t be an infrastructure that requires multiple touch points. Emphasis on automation.\n\n**The goal from my perspective**\n\nI have gotten about as far as I can with low code solutions. Power BI is both our ETL and data storage solution which works for small datasets but will not scale well when data starts growing.\n\n**Wants:**\n\n\\-ETL Process that is separate from Power BI. Needs to be easy to alter when data delivery methods change\n\n\\-Data storage solution that is scalable for growth and easy to access for a remote friendly company.\n\n\\-Foundation for more advanced data science practices(machine learning, neural networks, subject matter covered in later coursework.\n\n**As an aside**, sometimes I receive advice to just change jobs to a more data driven organization. Not an option that I am willing to pursue. On a personal level, this is exactly the type of employer you want to have while raising a family.  I am compensated very well and the benefits to my family and well above average.  My wife and I are expected our 2nd child this year and I will have the luxury of having 12 week paid paternity.", "author_fullname": "t2_61qgxfir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analyst leading Company out of the Dark Ages", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fm3dr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690917834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings to my favorite subreddit!  Fellow data enthusiast here, and I am hoping to get your advice on long term career goals at my employer.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My background&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;My career started in accounting. Then pivoted to a variety of supply chain roles as an analyst. My roots are entrenched in Microsoft Products. Started as an excel monkey, then SQL neanderthal, followed up by Power BI human. Self-taught through most of it and as smart as stackoverflow allows me to be. Pursuing a MS in Data Science to get more grounded STEM knowledge and better combine with my domain knowledge.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Courseload thus far and outlook&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;-Bachelors in Accounting&lt;/p&gt;\n\n&lt;p&gt;-Udemy courses on Power BI, SQL, DAX, etc&lt;/p&gt;\n\n&lt;p&gt;-Dataquest modules for Python&lt;/p&gt;\n\n&lt;p&gt;-Pursuing MS in Data Science at Eastern University&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My employer&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Leading manufacturing of durable juvenile good in the US(strollers, car seats, high chairs, etc.). While we are technically an international company, we are very siloed and operate as a small-medium sized business. I am a data science team of 1. No real IT team in the US besides a 3rd party service that helps with day to day tasks. I am the data wrangler, cleaner and presenter from start to finish. I am the Power BI admin/developer and analyst for our business unit. Launched the reporting suite when I started with the organization 4 years ago. Before that launch, everyone was excel jockeying very disparate data sources often looking at the same number in multiple places.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Infrastructure(image showing flow in the post)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Limited to Microsoft 365 solutions.  I do have a lot of leeway when it comes to implementing new software. I just need to present the options to management outlining the cost/benefit analysis. Since I am a team of 1, It can\u2019t be an infrastructure that requires multiple touch points. Emphasis on automation.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The goal from my perspective&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I have gotten about as far as I can with low code solutions. Power BI is both our ETL and data storage solution which works for small datasets but will not scale well when data starts growing.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Wants:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;-ETL Process that is separate from Power BI. Needs to be easy to alter when data delivery methods change&lt;/p&gt;\n\n&lt;p&gt;-Data storage solution that is scalable for growth and easy to access for a remote friendly company.&lt;/p&gt;\n\n&lt;p&gt;-Foundation for more advanced data science practices(machine learning, neural networks, subject matter covered in later coursework.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;As an aside&lt;/strong&gt;, sometimes I receive advice to just change jobs to a more data driven organization. Not an option that I am willing to pursue. On a personal level, this is exactly the type of employer you want to have while raising a family.  I am compensated very well and the benefits to my family and well above average.  My wife and I are expected our 2nd child this year and I will have the luxury of having 12 week paid paternity.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fm3dr", "is_robot_indexable": true, "report_reasons": null, "author": "Significant-Analyst9", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fm3dr/data_analyst_leading_company_out_of_the_dark_ages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fm3dr/data_analyst_leading_company_out_of_the_dark_ages/", "subreddit_subscribers": 971053, "created_utc": 1690917834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, just wanted to share my new open-source project: It's basically ChatGPT Code Interpreter, but the Python interpreter runs locally on your machine, so you can use it for sensitive data: https://github.com/silvanmelchior/IncognitoPilot", "author_fullname": "t2_hdzqi2fb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local Python ChatGPT Code Interpreter for Data Analysis, etc.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 33, "top_awarded_type": null, "hide_score": false, "name": "t3_15fcids", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AlkniZDekm7t1rjqTmw6yF4r8dK06VO2tjif1-rFPFs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690896195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, just wanted to share my new open-source project: It&amp;#39;s basically ChatGPT Code Interpreter, but the Python interpreter runs locally on your machine, so you can use it for sensitive data: &lt;a href=\"https://github.com/silvanmelchior/IncognitoPilot\"&gt;https://github.com/silvanmelchior/IncognitoPilot&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/gezxsavi2ifb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/gezxsavi2ifb1.png?auto=webp&amp;s=e21f2f573a58c92d7e64d1f30a169494e240e6ea", "width": 2651, "height": 641}, "resolutions": [{"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c2af7bfd64e4d6818bc57f3658d42cc155dd4b80", "width": 108, "height": 26}, {"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f57b807fe02139bd4f73f7383dd358bfdad17c6c", "width": 216, "height": 52}, {"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb713a10adb496c2c8be251865cecb0d5c8ecd21", "width": 320, "height": 77}, {"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=17562468f2737698721b035197011296ac3f3928", "width": 640, "height": 154}, {"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5e1aa29395084082cc4a12c8e720b19592218e40", "width": 960, "height": 232}, {"url": "https://preview.redd.it/gezxsavi2ifb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6bc11918e9c105a12f90bffb67b0dfc4faae0ae7", "width": 1080, "height": 261}], "variants": {}, "id": "HZyZb_r-UNerNXSwa0H8OGCJNYNf2s1cMbg1MKqdsqI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fcids", "is_robot_indexable": true, "report_reasons": null, "author": "silvanmelchior", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fcids/local_python_chatgpt_code_interpreter_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/gezxsavi2ifb1.png", "subreddit_subscribers": 971053, "created_utc": 1690896195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI\u2019m currently working as a .Net developer with 5 years of experience. I want to make transition to data science but I\u2019m not sure/confident about the path.\n\nCan you guys please advise if it is good idea to make this transition? If yes, what is the approach that I need to take? Any light on how would the interviews be for someone with my experience + new to the data science field? Will I be considered as entry level? What would the salary range be? \n\nThank you so much for all you advises\n\nMuch appreciated.", "author_fullname": "t2_jqcyt0lq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": ".Net developer to data scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15fvjjr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690941138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently working as a .Net developer with 5 years of experience. I want to make transition to data science but I\u2019m not sure/confident about the path.&lt;/p&gt;\n\n&lt;p&gt;Can you guys please advise if it is good idea to make this transition? If yes, what is the approach that I need to take? Any light on how would the interviews be for someone with my experience + new to the data science field? Will I be considered as entry level? What would the salary range be? &lt;/p&gt;\n\n&lt;p&gt;Thank you so much for all you advises&lt;/p&gt;\n\n&lt;p&gt;Much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fvjjr", "is_robot_indexable": true, "report_reasons": null, "author": "thisyk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fvjjr/net_developer_to_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fvjjr/net_developer_to_data_scientist/", "subreddit_subscribers": 971053, "created_utc": 1690941138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone! A few months ago my friend and I were working on a sustainability NextJS app and wanted to use semantic search/vector search to help improve search accuracy for materials in our Postgres database.\n\nWe found it difficult to do well with standard vector databases and so we ended up making a [nice open-source NextJS package to layer semantic search on top of Postgres](https://github.com/getretake/retake) with just a few lines of code. It supports NextJS/TypeScript and Python backends right now, always stays in sync with Postgres, doubles as a vector store, and can be deployed anywhere.\u00a0\n\nWe wrote some [documentation](https://docs.getretake.com/quickstart) on it and are curious to see what people do with it! If you encounter any issues or have exciting ideas, feel free to [open an issue](https://github.com/getretake/retake/issues) or contribute alongside us to make it better! Any feedback is warmly appreciated :)", "author_fullname": "t2_4iwrwdc0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We created an open-source semantic search package on top of Postgres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15fuphp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690938791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! A few months ago my friend and I were working on a sustainability NextJS app and wanted to use semantic search/vector search to help improve search accuracy for materials in our Postgres database.&lt;/p&gt;\n\n&lt;p&gt;We found it difficult to do well with standard vector databases and so we ended up making a &lt;a href=\"https://github.com/getretake/retake\"&gt;nice open-source NextJS package to layer semantic search on top of Postgres&lt;/a&gt; with just a few lines of code. It supports NextJS/TypeScript and Python backends right now, always stays in sync with Postgres, doubles as a vector store, and can be deployed anywhere.\u00a0&lt;/p&gt;\n\n&lt;p&gt;We wrote some &lt;a href=\"https://docs.getretake.com/quickstart\"&gt;documentation&lt;/a&gt; on it and are curious to see what people do with it! If you encounter any issues or have exciting ideas, feel free to &lt;a href=\"https://github.com/getretake/retake/issues\"&gt;open an issue&lt;/a&gt; or contribute alongside us to make it better! Any feedback is warmly appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rFn4S2W4WKUnVj2ZaCWpNoRJZoN3kV1sPKO7EveBzEA.jpg?auto=webp&amp;s=cf717f46abe1d5a556cd366d119d8097624d3713", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/rFn4S2W4WKUnVj2ZaCWpNoRJZoN3kV1sPKO7EveBzEA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=54329c4b9bc04cbf0e233018ad3f765666920509", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/rFn4S2W4WKUnVj2ZaCWpNoRJZoN3kV1sPKO7EveBzEA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bda07a0ca7665285dd99d3fa14cf7562f735a167", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/rFn4S2W4WKUnVj2ZaCWpNoRJZoN3kV1sPKO7EveBzEA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e61524c03008605cde48ba007a851a6b68976245", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/rFn4S2W4WKUnVj2ZaCWpNoRJZoN3kV1sPKO7EveBzEA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9a726f2b4288d76b750c2b07eccedb17a4ea27bf", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/rFn4S2W4WKUnVj2ZaCWpNoRJZoN3kV1sPKO7EveBzEA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=06e0bcbabb88bce2ba9733a1a475a8bf89dff9c9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/rFn4S2W4WKUnVj2ZaCWpNoRJZoN3kV1sPKO7EveBzEA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7d276bf5a3be63e32110ea868cee26fca7d0ed14", "width": 1080, "height": 540}], "variants": {}, "id": "rYEojxaH5ALeemp-JFP-bkYx4347_pZyYNAGZ0E1goo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fuphp", "is_robot_indexable": true, "report_reasons": null, "author": "philippemnoel", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fuphp/we_created_an_opensource_semantic_search_package/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fuphp/we_created_an_opensource_semantic_search_package/", "subreddit_subscribers": 971053, "created_utc": 1690938791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently machine learning engineer. I feel like I have to study too much, And to put in twice as much effort in both hard-skills and soft-skills as when I was a software engineer. \n\n I'm not badmouthing SDE. But I think DS have a lower cost benefit comparing to software engineers (On the salary, at least). \n\nI am really thinking about studying python-Django to be a fullstack/Back-end. \n\nSo, why you left data science?", "author_fullname": "t2_w7ap5hsy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is being a data scientist/MLE worth it? Thinking about migrating to SDE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15fuhvl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690938208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently machine learning engineer. I feel like I have to study too much, And to put in twice as much effort in both hard-skills and soft-skills as when I was a software engineer. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not badmouthing SDE. But I think DS have a lower cost benefit comparing to software engineers (On the salary, at least). &lt;/p&gt;\n\n&lt;p&gt;I am really thinking about studying python-Django to be a fullstack/Back-end. &lt;/p&gt;\n\n&lt;p&gt;So, why you left data science?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fuhvl", "is_robot_indexable": true, "report_reasons": null, "author": "Muted_Standard175", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fuhvl/is_being_a_data_scientistmle_worth_it_thinking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fuhvl/is_being_a_data_scientistmle_worth_it_thinking/", "subreddit_subscribers": 971053, "created_utc": 1690938208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! The project that I am in has a lot of missing values in the features so I opt to impute the missing values. I independently imputed the training set and test set to avoid data leakage. \n\nUpon training machine learning models with AutoGluon, I got the feature importance scores of the model with best F1 score and was surprised that a feature with mostly zero values got the highest feature importance (permutation importance). With that discovery, I removed the features with mostly zero values and and trained new models again. I noticed the performance of the models got worse than before.\n\nAny thoughts on why that specific feature becomes so important? Has anyone encountered the same results?", "author_fullname": "t2_2b8t0cm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help in interpreting why the model gave the highest feature importance on a mostly zero feature.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ft0xx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690934247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! The project that I am in has a lot of missing values in the features so I opt to impute the missing values. I independently imputed the training set and test set to avoid data leakage. &lt;/p&gt;\n\n&lt;p&gt;Upon training machine learning models with AutoGluon, I got the feature importance scores of the model with best F1 score and was surprised that a feature with mostly zero values got the highest feature importance (permutation importance). With that discovery, I removed the features with mostly zero values and and trained new models again. I noticed the performance of the models got worse than before.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts on why that specific feature becomes so important? Has anyone encountered the same results?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15ft0xx", "is_robot_indexable": true, "report_reasons": null, "author": "deaththekid00", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15ft0xx/help_in_interpreting_why_the_model_gave_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15ft0xx/help_in_interpreting_why_the_model_gave_the/", "subreddit_subscribers": 971053, "created_utc": 1690934247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I\u2019ve never posted on this sub so forgive me if I\u2019m breaking any rules ( I read them as well but just in case lol)\n\nI\u2019ve got this amazing opportunity and started my 6 month long paid internship in a very innovative company with very supportive people. \n\nThey know that I have no real experience in IT and I never lied that I do, only that I\u2019m enrolled in an \u201cIT\u201d program with my college (1 year long, 6 months left to go). \n\nI was afraid that I would do menial tasks and not learn anything but to my surprise it seems to be the other end of that extreme. It was my second day today and I\u2019m analyzing data in ThoughtFlow and I\u2019m supposed to make my own report for the previous month regarding the teams performance. It is a completely new world to me, and although they are aware that I had no previous experience with that, they are encouraging me to play around and figure it out while offering complete support. \nI do understand that I need to ask questions, but I do not want to overdo that and burden my colleagues. I\u2019m just afraid that this is all too complicated even though I managed to create some thing but to be honest, I\u2019m not really sure even how I did it. \n\nFor half an hour I\u2019m thinking I\u2019m super dumb and then for five minutes I think I got it and then again back to square one and like that throughout the whole day.\n\nI even sat on two meetings where they discussed things that almost sounded like a foreign language to me, but I managed to give a constructive feedback after that, even though they didn\u2019t ask. They were appreciative of it, and seem to genuinely think that it was a good feedback.\n\nDo you have any advice for me? I would greatly appreciate it. I really don\u2019t want to ruin this opportunity and I want to learn as much as I can.", "author_fullname": "t2_peti9i4j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internship", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fszu5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690934167.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019ve never posted on this sub so forgive me if I\u2019m breaking any rules ( I read them as well but just in case lol)&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got this amazing opportunity and started my 6 month long paid internship in a very innovative company with very supportive people. &lt;/p&gt;\n\n&lt;p&gt;They know that I have no real experience in IT and I never lied that I do, only that I\u2019m enrolled in an \u201cIT\u201d program with my college (1 year long, 6 months left to go). &lt;/p&gt;\n\n&lt;p&gt;I was afraid that I would do menial tasks and not learn anything but to my surprise it seems to be the other end of that extreme. It was my second day today and I\u2019m analyzing data in ThoughtFlow and I\u2019m supposed to make my own report for the previous month regarding the teams performance. It is a completely new world to me, and although they are aware that I had no previous experience with that, they are encouraging me to play around and figure it out while offering complete support. \nI do understand that I need to ask questions, but I do not want to overdo that and burden my colleagues. I\u2019m just afraid that this is all too complicated even though I managed to create some thing but to be honest, I\u2019m not really sure even how I did it. &lt;/p&gt;\n\n&lt;p&gt;For half an hour I\u2019m thinking I\u2019m super dumb and then for five minutes I think I got it and then again back to square one and like that throughout the whole day.&lt;/p&gt;\n\n&lt;p&gt;I even sat on two meetings where they discussed things that almost sounded like a foreign language to me, but I managed to give a constructive feedback after that, even though they didn\u2019t ask. They were appreciative of it, and seem to genuinely think that it was a good feedback.&lt;/p&gt;\n\n&lt;p&gt;Do you have any advice for me? I would greatly appreciate it. I really don\u2019t want to ruin this opportunity and I want to learn as much as I can.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fszu5", "is_robot_indexable": true, "report_reasons": null, "author": "2doortorro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fszu5/internship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fszu5/internship/", "subreddit_subscribers": 971053, "created_utc": 1690934167.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "https://preview.redd.it/eqg0eowd1kfb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=b77b3e29da55e4712cfa0e7fbc910c0ae25fc0ee\n\nAs a Data Scientist, mastering database management is crucial for efficient data analysis and decision-making. MongoDB, a popular NoSQL database, offers great flexibility and scalability, making it a top choice for handling large and complex datasets. Over the past two years, MongoDB has been an integral part of my professional toolkit, and I've gathered valuable tips and tricks that can elevate your MongoDB experience as a Data Scientist.\n\n## 1. Create a Useful CRUD Wrapper\n\nWorking with MongoDB often involves performing CRUD operations (Create, Read, Update, Delete) on documents. To streamline your database interactions, consider creating a reusable CRUD wrapper. This abstraction layer encapsulates common database tasks and provides a cleaner and more maintainable way to interact with MongoDB.\n\n    import pymongo\n    \n    def get_mongo_client():\n        return pymongo.MongoClient(mongo_connection_string)\n    \n    # Create operation\n    def create_document(collection, document_data):\n        with get_mongo_client() as client:\n            db = client[database_name]\n            col = db[collection]\n            result = col.insert_one(document_data)\n            return result.inserted_id\n    \n    # Read operation by document name\n    def get_document_by_name(collection, record_name):\n        with get_mongo_client() as client:\n            db = client[database_name]\n            col = db[collection]\n            document = col.find_one({\"name\": record_name})\n            return document\n    \n    # Update operation by document name\n    def update_document_by_name(collection, record_name, updated_data):\n        with get_mongo_client() as client:\n            db = client[database_name]\n            col = db[collection]\n            result = col.update_one({\"name\": record_name}, {\"$set\": updated_data})\n            return result.modified_count\n    \n    # Delete operation\n    def delete_document(collection, name):\n        with get_mongo_client() as client:\n            db = client[database_name]\n            col = db[collection]\n            result = col.delete_one({\"name\": name})\n            return result.deleted_count\n\n## 2. Master Aggregation Pipelines\n\nMongoDB's Aggregation Pipeline is a powerful tool for data transformation, aggregation, and analytics. It allows you to perform complex operations on large datasets efficiently. Let's say we have a collection of sales data and want to calculate the total sales for each product category and sorting in descending order:\n\n    pipeline = [\n        { \"$group\": { \"_id\": \"$category\", \"total_sales\": { \"$sum\": \"$amount\" } } },\n    \t\t{ \"$sort\": { \"total_sales\": -1 } }\n    ]\n    \n    result = list(collection.aggregate(pipeline))\n\n## 3. Check for Duplicates Before Updating/Inserting\n\nTo maintain data integrity, it's crucial to prevent duplicate records in your database. Before performing updates or inserts, check if the data already exists to avoid redundancy:\n\n    def update_or_insert_document(collection, data):\n        existing_record = collection.find_one({\"_id\": data[\"_id\"]})\n        \n        if existing_record:\n            collection.update_one({\"_id\": data[\"_id\"]}, {\"$set\": data})\n        else:\n            collection.insert_one(data)\n\n## 4. Utilize Indexes\n\nIndexes play a vital role in optimizing query performance. Identify frequently queried fields and create indexes to speed up data retrieval:\n\n    collection.create_index(\"name\")\n    collection.create_index(\"category\")\n\n## 5. Use Projections Wisely\n\nWhen fetching data from the database, use projections to retrieve only the necessary fields, reducing network overhead and improving query performance:\n\n    projection = {\"_id\": 0, \"name\": 1, \"price\": 1}\n    result = list(collection.find({}, projection)) \n\n## 6. Create Document-Specific Unique Identifiers\n\nWhile MongoDB automatically generates a unique **\\_id** for each document, consider using document-specific unique identifiers for certain entities like for stock market data, we can have unique record as the *stock symbol*. This can enhance query efficiency and ensure data uniqueness:\n\n## 7. Implement Caching Systems\n\nFrequent database queries can impact application performance. Implement caching mechanisms to store frequently accessed data and reduce query load:\n\n    import cachetools\n    \n    @cachetools.cached(cache=cachetools.TTLCache(maxsize=100, ttl=300))\n    def get_stock_data(symbol):\n        # Fetch stock data from MongoDB\n        return collection.find_one({\"symbol\": symbol})\n\n## 8. Maintain Data Integrity\n\nData integrity checks should include validating data types to ensure seamless interactions with MongoDB. MongoDB has specific data type requirements, and it's essential to preprocess the data before insertion to handle data types that MongoDB may not support directly.\n\nFor example, as you mentioned, MongoDB doesn't support **numpy.int64** data type. When encountering such data types, it's advisable to convert them to native Python types like **int** or **float** before inserting into the database.\n\n    def insert_document(data):\n        # Check data types and convert if necessary\n        for key, value in data.items():\n            if isinstance(value, np.int64):\n                data[key] = int(value)\n            elif isinstance(value, np.float64):\n                data[key] = float(value)\n    \t\tcollection.insert_one(data) \n\n## 9. Avoid Unnecessary Operations and Create a Master Dataframe\n\nMinimizing unnecessary database queries is crucial for optimizing the performance of your data science applications. If your code requires data from the same database multiple times, consider querying the database once and creating a master dataframe to serve as a central data source.\n\n## 10. Implement Rate Limiting\n\nTo prevent abuse and maintain resource fairness, apply rate limiting to API endpoints interacting with MongoDB:\n\n    from flask_limiter import Limiter\n    \n    limiter = Limiter(app)\n    \n    @app.route(\"/get_data\")\n    @limiter.limit(\"10 per minute\")\n    def get_data():\n        # Query MongoDB and return data\n        pass\n\nBy adopting these tips and tricks, you can harness the full potential of MongoDB for your data science projects. Understanding these best practices will not only make your code more efficient but also empower you to extract valuable insights from vast datasets. Embrace the continuous learning journey and explore the endless possibilities that MongoDB offers for your data-driven success!\n\nHappy coding and database exploration!", "author_fullname": "t2_hcskz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing MongoDB Usage in Data Science: Tips &amp; Tricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"eqg0eowd1kfb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=058b6882e26d10a3ee7622cd50c2e1a510367159"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9dae904963fb8b58eae7042fdf09582690bc59a1"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=baff6f31f66a14c3d0bd72746bd197e186d1dab7"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9da82d8866c5e2963cbd8377161e993860a01b2d"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=20af0df5e8e75fb7c1c7159bbdaebdf82ab03f8c"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ae728512d4846e0481c2ba253273191aa9bbd69"}], "s": {"y": 1080, "x": 1920, "u": "https://preview.redd.it/eqg0eowd1kfb1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=b77b3e29da55e4712cfa0e7fbc910c0ae25fc0ee"}, "id": "eqg0eowd1kfb1"}}, "name": "t3_15fmzzo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3bcFxtM9EYq_XeP1nW42tJl2msQc5DB5q61tFi_tGKs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690919892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/eqg0eowd1kfb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b77b3e29da55e4712cfa0e7fbc910c0ae25fc0ee\"&gt;https://preview.redd.it/eqg0eowd1kfb1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b77b3e29da55e4712cfa0e7fbc910c0ae25fc0ee&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As a Data Scientist, mastering database management is crucial for efficient data analysis and decision-making. MongoDB, a popular NoSQL database, offers great flexibility and scalability, making it a top choice for handling large and complex datasets. Over the past two years, MongoDB has been an integral part of my professional toolkit, and I&amp;#39;ve gathered valuable tips and tricks that can elevate your MongoDB experience as a Data Scientist.&lt;/p&gt;\n\n&lt;h2&gt;1. Create a Useful CRUD Wrapper&lt;/h2&gt;\n\n&lt;p&gt;Working with MongoDB often involves performing CRUD operations (Create, Read, Update, Delete) on documents. To streamline your database interactions, consider creating a reusable CRUD wrapper. This abstraction layer encapsulates common database tasks and provides a cleaner and more maintainable way to interact with MongoDB.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pymongo\n\ndef get_mongo_client():\n    return pymongo.MongoClient(mongo_connection_string)\n\n# Create operation\ndef create_document(collection, document_data):\n    with get_mongo_client() as client:\n        db = client[database_name]\n        col = db[collection]\n        result = col.insert_one(document_data)\n        return result.inserted_id\n\n# Read operation by document name\ndef get_document_by_name(collection, record_name):\n    with get_mongo_client() as client:\n        db = client[database_name]\n        col = db[collection]\n        document = col.find_one({&amp;quot;name&amp;quot;: record_name})\n        return document\n\n# Update operation by document name\ndef update_document_by_name(collection, record_name, updated_data):\n    with get_mongo_client() as client:\n        db = client[database_name]\n        col = db[collection]\n        result = col.update_one({&amp;quot;name&amp;quot;: record_name}, {&amp;quot;$set&amp;quot;: updated_data})\n        return result.modified_count\n\n# Delete operation\ndef delete_document(collection, name):\n    with get_mongo_client() as client:\n        db = client[database_name]\n        col = db[collection]\n        result = col.delete_one({&amp;quot;name&amp;quot;: name})\n        return result.deleted_count\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;2. Master Aggregation Pipelines&lt;/h2&gt;\n\n&lt;p&gt;MongoDB&amp;#39;s Aggregation Pipeline is a powerful tool for data transformation, aggregation, and analytics. It allows you to perform complex operations on large datasets efficiently. Let&amp;#39;s say we have a collection of sales data and want to calculate the total sales for each product category and sorting in descending order:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pipeline = [\n    { &amp;quot;$group&amp;quot;: { &amp;quot;_id&amp;quot;: &amp;quot;$category&amp;quot;, &amp;quot;total_sales&amp;quot;: { &amp;quot;$sum&amp;quot;: &amp;quot;$amount&amp;quot; } } },\n        { &amp;quot;$sort&amp;quot;: { &amp;quot;total_sales&amp;quot;: -1 } }\n]\n\nresult = list(collection.aggregate(pipeline))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;3. Check for Duplicates Before Updating/Inserting&lt;/h2&gt;\n\n&lt;p&gt;To maintain data integrity, it&amp;#39;s crucial to prevent duplicate records in your database. Before performing updates or inserts, check if the data already exists to avoid redundancy:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def update_or_insert_document(collection, data):\n    existing_record = collection.find_one({&amp;quot;_id&amp;quot;: data[&amp;quot;_id&amp;quot;]})\n\n    if existing_record:\n        collection.update_one({&amp;quot;_id&amp;quot;: data[&amp;quot;_id&amp;quot;]}, {&amp;quot;$set&amp;quot;: data})\n    else:\n        collection.insert_one(data)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;4. Utilize Indexes&lt;/h2&gt;\n\n&lt;p&gt;Indexes play a vital role in optimizing query performance. Identify frequently queried fields and create indexes to speed up data retrieval:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;collection.create_index(&amp;quot;name&amp;quot;)\ncollection.create_index(&amp;quot;category&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;5. Use Projections Wisely&lt;/h2&gt;\n\n&lt;p&gt;When fetching data from the database, use projections to retrieve only the necessary fields, reducing network overhead and improving query performance:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;projection = {&amp;quot;_id&amp;quot;: 0, &amp;quot;name&amp;quot;: 1, &amp;quot;price&amp;quot;: 1}\nresult = list(collection.find({}, projection)) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;6. Create Document-Specific Unique Identifiers&lt;/h2&gt;\n\n&lt;p&gt;While MongoDB automatically generates a unique &lt;strong&gt;_id&lt;/strong&gt; for each document, consider using document-specific unique identifiers for certain entities like for stock market data, we can have unique record as the &lt;em&gt;stock symbol&lt;/em&gt;. This can enhance query efficiency and ensure data uniqueness:&lt;/p&gt;\n\n&lt;h2&gt;7. Implement Caching Systems&lt;/h2&gt;\n\n&lt;p&gt;Frequent database queries can impact application performance. Implement caching mechanisms to store frequently accessed data and reduce query load:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import cachetools\n\n@cachetools.cached(cache=cachetools.TTLCache(maxsize=100, ttl=300))\ndef get_stock_data(symbol):\n    # Fetch stock data from MongoDB\n    return collection.find_one({&amp;quot;symbol&amp;quot;: symbol})\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;8. Maintain Data Integrity&lt;/h2&gt;\n\n&lt;p&gt;Data integrity checks should include validating data types to ensure seamless interactions with MongoDB. MongoDB has specific data type requirements, and it&amp;#39;s essential to preprocess the data before insertion to handle data types that MongoDB may not support directly.&lt;/p&gt;\n\n&lt;p&gt;For example, as you mentioned, MongoDB doesn&amp;#39;t support &lt;strong&gt;numpy.int64&lt;/strong&gt; data type. When encountering such data types, it&amp;#39;s advisable to convert them to native Python types like &lt;strong&gt;int&lt;/strong&gt; or &lt;strong&gt;float&lt;/strong&gt; before inserting into the database.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def insert_document(data):\n    # Check data types and convert if necessary\n    for key, value in data.items():\n        if isinstance(value, np.int64):\n            data[key] = int(value)\n        elif isinstance(value, np.float64):\n            data[key] = float(value)\n        collection.insert_one(data) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;9. Avoid Unnecessary Operations and Create a Master Dataframe&lt;/h2&gt;\n\n&lt;p&gt;Minimizing unnecessary database queries is crucial for optimizing the performance of your data science applications. If your code requires data from the same database multiple times, consider querying the database once and creating a master dataframe to serve as a central data source.&lt;/p&gt;\n\n&lt;h2&gt;10. Implement Rate Limiting&lt;/h2&gt;\n\n&lt;p&gt;To prevent abuse and maintain resource fairness, apply rate limiting to API endpoints interacting with MongoDB:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from flask_limiter import Limiter\n\nlimiter = Limiter(app)\n\n@app.route(&amp;quot;/get_data&amp;quot;)\n@limiter.limit(&amp;quot;10 per minute&amp;quot;)\ndef get_data():\n    # Query MongoDB and return data\n    pass\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;By adopting these tips and tricks, you can harness the full potential of MongoDB for your data science projects. Understanding these best practices will not only make your code more efficient but also empower you to extract valuable insights from vast datasets. Embrace the continuous learning journey and explore the endless possibilities that MongoDB offers for your data-driven success!&lt;/p&gt;\n\n&lt;p&gt;Happy coding and database exploration!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fmzzo", "is_robot_indexable": true, "report_reasons": null, "author": "vishank97", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fmzzo/optimizing_mongodb_usage_in_data_science_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fmzzo/optimizing_mongodb_usage_in_data_science_tips/", "subreddit_subscribers": 971053, "created_utc": 1690919892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all - for part of my next newsletter post I'm working on a rough / high level visual to help people in the data field understand the paths open to them and in some cases to help understand which path they're currently on.\n\nThoughts on the early draft below? Is it too high level?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/uhln4549rjfb1.png?width=1406&amp;format=png&amp;auto=webp&amp;s=0351a7d9932a83fa2f61ec34a96d6c22adac70bd\n\nNewsletter: [https://forefrontofdata.substack.com/](https://forefrontofdata.substack.com/)\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_i7c9bj9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career paths in data analytics / science / engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"uhln4549rjfb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 117, "x": 108, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4d2c11a18bfd3d906539087455930a0772daa158"}, {"y": 235, "x": 216, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=91272d8cc1809d9b0231e02fda88ec97cddbc241"}, {"y": 348, "x": 320, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2e47e286ef844023dc5a2b4d669cf073e9e2b90a"}, {"y": 697, "x": 640, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9507d86cf45e3baf8998fbf2acd12426d1a0fcaa"}, {"y": 1046, "x": 960, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fcac84e253035a06d26a795ad1be9c612c644b77"}, {"y": 1176, "x": 1080, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1d4f2e0631da9f1065e8bc0fe51535861c40228f"}], "s": {"y": 1532, "x": 1406, "u": "https://preview.redd.it/uhln4549rjfb1.png?width=1406&amp;format=png&amp;auto=webp&amp;s=0351a7d9932a83fa2f61ec34a96d6c22adac70bd"}, "id": "uhln4549rjfb1"}}, "name": "t3_15flkk0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/-pVDWn9-3bPMag8_jncpgPNYsy_5j1MOUFljuqYfIr8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690916650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all - for part of my next newsletter post I&amp;#39;m working on a rough / high level visual to help people in the data field understand the paths open to them and in some cases to help understand which path they&amp;#39;re currently on.&lt;/p&gt;\n\n&lt;p&gt;Thoughts on the early draft below? Is it too high level?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/uhln4549rjfb1.png?width=1406&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0351a7d9932a83fa2f61ec34a96d6c22adac70bd\"&gt;https://preview.redd.it/uhln4549rjfb1.png?width=1406&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0351a7d9932a83fa2f61ec34a96d6c22adac70bd&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Newsletter: &lt;a href=\"https://forefrontofdata.substack.com/\"&gt;https://forefrontofdata.substack.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15flkk0", "is_robot_indexable": true, "report_reasons": null, "author": "DataAnalystNewslettr", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15flkk0/career_paths_in_data_analytics_science_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15flkk0/career_paths_in_data_analytics_science_engineering/", "subreddit_subscribers": 971053, "created_utc": 1690916650.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi reddit community,\n\nI am working on developing a process where we are creating a working model for econometrics combining OLS modeling with Bayesian. The idea is to use OLS to build a strong base model and then transfer this model into Bayesian where we feed our beliefs about a subset of variables such as media. We use this to calibrate these variables based on previous model updates and maintain continuity in our results. The reason why we aren't just extending the historical models is because of issues related to data quality over time and some additional changes to our KPIs. Everyone in my team is very much on board with this idea as it has the potential to save a lot of precious time, however, I am curious to hear an objective opinion in order to be better able to weigh in on the postives/negatives of this approach. Any thoughts? :)", "author_fullname": "t2_3p8oqkl3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using OLS &amp; Bayesian regression on an econometrics project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fg5og", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690904552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi reddit community,&lt;/p&gt;\n\n&lt;p&gt;I am working on developing a process where we are creating a working model for econometrics combining OLS modeling with Bayesian. The idea is to use OLS to build a strong base model and then transfer this model into Bayesian where we feed our beliefs about a subset of variables such as media. We use this to calibrate these variables based on previous model updates and maintain continuity in our results. The reason why we aren&amp;#39;t just extending the historical models is because of issues related to data quality over time and some additional changes to our KPIs. Everyone in my team is very much on board with this idea as it has the potential to save a lot of precious time, however, I am curious to hear an objective opinion in order to be better able to weigh in on the postives/negatives of this approach. Any thoughts? :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fg5og", "is_robot_indexable": true, "report_reasons": null, "author": "necplorer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fg5og/using_ols_bayesian_regression_on_an_econometrics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fg5og/using_ols_bayesian_regression_on_an_econometrics/", "subreddit_subscribers": 971053, "created_utc": 1690904552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I wasn\u2019t sure where I should post this one. \n\nI\u2019ve written a few scripts in the last week or two that are designed to collect a LOT of data. In fact, I\u2019m rotating API keys every 30 minutes or so with my latest - and final - data collection effort. I\u2019ve written the script to automatically rotate across 6 keys for this particular API.\n\nMy average API calls per day has been right around 210,000 over the last three days.\n\nHowever, the last 24 hours it\u2019s dropped to 200 calls a day. I\u2019m not sure why. I\u2019ve swapped VPN connections; API keys - all of them - and I\u2019m still not seeing any real change.\n\nI\u2019m not violating the ToS. I\u2019m only collecting open source data and the API is designed to handle what I\u2019m doing. \n\nMy internet connection is really strong. 250-300mb down and 40-50mb up. I\u2019m running my MacBook using the caffeinate  command in my terminal to ensure my connection is solid and not disconnecting. \n\nI am writing this data to an external HD over USB/C.. which should be my only limitation realistically\u2026 but it\u2019s not even 5% at capacity. This isn\u2019t the issue. \n\nDoes anyone have any ideas here? My VPN is Nord and a paid account I\u2019ve used successfully for years.\n\nThis is massively slowing development down; I need a solution and fast. Thoughts?", "author_fullname": "t2_ufzvkub2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ISP Throttling?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fde64", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690898290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wasn\u2019t sure where I should post this one. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve written a few scripts in the last week or two that are designed to collect a LOT of data. In fact, I\u2019m rotating API keys every 30 minutes or so with my latest - and final - data collection effort. I\u2019ve written the script to automatically rotate across 6 keys for this particular API.&lt;/p&gt;\n\n&lt;p&gt;My average API calls per day has been right around 210,000 over the last three days.&lt;/p&gt;\n\n&lt;p&gt;However, the last 24 hours it\u2019s dropped to 200 calls a day. I\u2019m not sure why. I\u2019ve swapped VPN connections; API keys - all of them - and I\u2019m still not seeing any real change.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not violating the ToS. I\u2019m only collecting open source data and the API is designed to handle what I\u2019m doing. &lt;/p&gt;\n\n&lt;p&gt;My internet connection is really strong. 250-300mb down and 40-50mb up. I\u2019m running my MacBook using the caffeinate  command in my terminal to ensure my connection is solid and not disconnecting. &lt;/p&gt;\n\n&lt;p&gt;I am writing this data to an external HD over USB/C.. which should be my only limitation realistically\u2026 but it\u2019s not even 5% at capacity. This isn\u2019t the issue. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any ideas here? My VPN is Nord and a paid account I\u2019ve used successfully for years.&lt;/p&gt;\n\n&lt;p&gt;This is massively slowing development down; I need a solution and fast. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fde64", "is_robot_indexable": true, "report_reasons": null, "author": "LoadingALIAS", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/15fde64/isp_throttling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/15fde64/isp_throttling/", "subreddit_subscribers": 971053, "created_utc": 1690898290.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}