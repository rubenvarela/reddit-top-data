{"kind": "Listing", "data": {"after": "t3_15fzvzl", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fancy dashboards with volatile data pipelines!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_15f9uab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 264, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 264, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/oobJRhUq11ypQd6ORR5C1NJqHvTrhV-ExRdMWWG5DkA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690889349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/diy1dfnohhfb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/diy1dfnohhfb1.jpg?auto=webp&amp;s=aab9a9bf0ffefd5dd1011be3f55dc8a791b2a469", "width": 1080, "height": 1086}, "resolutions": [{"url": "https://preview.redd.it/diy1dfnohhfb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e8fd68ca9073a5402c8b9de902ac69269454e158", "width": 108, "height": 108}, {"url": "https://preview.redd.it/diy1dfnohhfb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7802054d5f087fd31a7be9d87c305ff7932f8fa0", "width": 216, "height": 217}, {"url": "https://preview.redd.it/diy1dfnohhfb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=66a437e2055d545bdda60c484901f0075b8446b8", "width": 320, "height": 321}, {"url": "https://preview.redd.it/diy1dfnohhfb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=20bcdc3a633f354ee8eb5659e49ae0be07ab5a62", "width": 640, "height": 643}, {"url": "https://preview.redd.it/diy1dfnohhfb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e9939508dcee511ca598c8b6e86508f7ea114894", "width": 960, "height": 965}, {"url": "https://preview.redd.it/diy1dfnohhfb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d7e3ff9a59361ff9d15b7729f0418be4d7c03805", "width": 1080, "height": 1086}], "variants": {}, "id": "3vgjKztySW59Dcgfgden_jtRhjVXOmTKeW8oPi4gdqI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "15f9uab", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15f9uab/fancy_dashboards_with_volatile_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/diy1dfnohhfb1.jpg", "subreddit_subscribers": 119904, "created_utc": 1690889349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a very experienced DE, I have built very complex data models for huge commercial entities, and nobody has been able to explain to me what a webhook is in non-technical terms. I work with students but I am still in the dark.", "author_fullname": "t2_8p2u7cmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Honest admittance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15flpsj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690916981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a very experienced DE, I have built very complex data models for huge commercial entities, and nobody has been able to explain to me what a webhook is in non-technical terms. I work with students but I am still in the dark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15flpsj", "is_robot_indexable": true, "report_reasons": null, "author": "Jamese0", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15flpsj/honest_admittance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15flpsj/honest_admittance/", "subreddit_subscribers": 119904, "created_utc": 1690916981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 100 json files with 100k rows each that we need to combine in one single file for ingestion into a custom vendor process.\n\n\nAlthough this is an ad-hoc task, I was wondering how do I make this performant if we had to do it daily. Certainly, if I use pandas, I'd be disappointed. \n\nTotal data size is 15gb.", "author_fullname": "t2_7s3yj3p2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to combine 100 JSON files with 100k rows each?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fyvw4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690950926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 100 json files with 100k rows each that we need to combine in one single file for ingestion into a custom vendor process.&lt;/p&gt;\n\n&lt;p&gt;Although this is an ad-hoc task, I was wondering how do I make this performant if we had to do it daily. Certainly, if I use pandas, I&amp;#39;d be disappointed. &lt;/p&gt;\n\n&lt;p&gt;Total data size is 15gb.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15fyvw4", "is_robot_indexable": true, "report_reasons": null, "author": "workthrowaway12wk", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fyvw4/how_to_combine_100_json_files_with_100k_rows_each/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fyvw4/how_to_combine_100_json_files_with_100k_rows_each/", "subreddit_subscribers": 119904, "created_utc": 1690950926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for a large beverage corp. One you've likely seen on commercials in between NBA and NFL games. \n\nObviously we work with a large...large amount of sales data and drink cases  volume data. But we don't actually have a team of data engineers in our company. \n\nWe do have two companies that we pay to host Data services for us but wouldn't it be beneficial to have an internal data engineering team? \n\nThis is a non-tech company btw. Our team has pitched this idea to some highers ups only to be met with \"why? Jobs getting done now isn't it?\"", "author_fullname": "t2_f4m0dd2qo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does every big-ish company need data engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15foo1o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690923649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a large beverage corp. One you&amp;#39;ve likely seen on commercials in between NBA and NFL games. &lt;/p&gt;\n\n&lt;p&gt;Obviously we work with a large...large amount of sales data and drink cases  volume data. But we don&amp;#39;t actually have a team of data engineers in our company. &lt;/p&gt;\n\n&lt;p&gt;We do have two companies that we pay to host Data services for us but wouldn&amp;#39;t it be beneficial to have an internal data engineering team? &lt;/p&gt;\n\n&lt;p&gt;This is a non-tech company btw. Our team has pitched this idea to some highers ups only to be met with &amp;quot;why? Jobs getting done now isn&amp;#39;t it?&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15foo1o", "is_robot_indexable": true, "report_reasons": null, "author": "Sacred_Tomato", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15foo1o/does_every_bigish_company_need_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15foo1o/does_every_bigish_company_need_data_engineers/", "subreddit_subscribers": 119904, "created_utc": 1690923649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2tv9i42n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing the dbt adapter for Synapse Data Warehouse in Microsoft Fabric | Microsoft Fabric Blog | Microsoft Fabric", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_15fwrgn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": "#46d160", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XUtw2b0bFRD8GrKfMzYdSVtIPP92KLCEFLL7XHF1Fug.jpg", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690944608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.fabric.microsoft.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.fabric.microsoft.com/en-US/blog/introducing-the-dbt-adapter-for-synapse-data-warehouse-in-microsoft-fabric/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9OgxD9uh612gWs0ucRa4D3jel7Q6DtNYt8JoOWI9C00.jpg?auto=webp&amp;s=e9b312d7f4a0accde23530f7ab78a21d2aaed6f2", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/9OgxD9uh612gWs0ucRa4D3jel7Q6DtNYt8JoOWI9C00.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ec05a8624fe7dfd5b5701633c73015aa2f99e2a", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/9OgxD9uh612gWs0ucRa4D3jel7Q6DtNYt8JoOWI9C00.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=63abef67a8dc5ecc08b2848e8df9daf5325072ab", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/9OgxD9uh612gWs0ucRa4D3jel7Q6DtNYt8JoOWI9C00.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8d67bf7b8497160fa0a4f19f2e8a4e3155c4bb68", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/9OgxD9uh612gWs0ucRa4D3jel7Q6DtNYt8JoOWI9C00.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4288e60c09fcf3914017b5416bfc88f4e5c81104", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/9OgxD9uh612gWs0ucRa4D3jel7Q6DtNYt8JoOWI9C00.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b48d6781a59d68e21346c588c8323ee34a1b660f", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/9OgxD9uh612gWs0ucRa4D3jel7Q6DtNYt8JoOWI9C00.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=de18174cffe5f04431332550e6a2bbc4505f30e3", "width": 1080, "height": 567}], "variants": {}, "id": "84tE6pfK-TFR9kevFYpB0r99mOTdEJRLnoMwoUdIYAg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod | Sr. Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15fwrgn", "is_robot_indexable": true, "report_reasons": null, "author": "theporterhaus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/15fwrgn/introducing_the_dbt_adapter_for_synapse_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.fabric.microsoft.com/en-US/blog/introducing-the-dbt-adapter-for-synapse-data-warehouse-in-microsoft-fabric/", "subreddit_subscribers": 119904, "created_utc": 1690944608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "i\u2019ve been in the tech industry since 2010. throughout that time, i\u2019ve been a GIS Analyst, Support Engineer, Manager, Solutions Architect and now the last 6 years as a Data Engineer. \n\ni\u2019m skilled in nearly everything that a data engineer does, but the last 3-4 years ive noticed that DE roles now require python experience. i just haven\u2019t had to use ot. and if i did, i just borrowed snippet code and modified. \n\nthis lack of python experience appears to be the bane of my existence on being able to be marketable. it makes me feel trapped on my current role. ive taken boot camps for python in the past, but it didn\u2019t stick. life and or work projects take priority. \n\nshould i just get into management and forgo this gap in skills to move on?", "author_fullname": "t2_gx0db", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "date engineer seeking career advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fuadn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690937658.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i\u2019ve been in the tech industry since 2010. throughout that time, i\u2019ve been a GIS Analyst, Support Engineer, Manager, Solutions Architect and now the last 6 years as a Data Engineer. &lt;/p&gt;\n\n&lt;p&gt;i\u2019m skilled in nearly everything that a data engineer does, but the last 3-4 years ive noticed that DE roles now require python experience. i just haven\u2019t had to use ot. and if i did, i just borrowed snippet code and modified. &lt;/p&gt;\n\n&lt;p&gt;this lack of python experience appears to be the bane of my existence on being able to be marketable. it makes me feel trapped on my current role. ive taken boot camps for python in the past, but it didn\u2019t stick. life and or work projects take priority. &lt;/p&gt;\n\n&lt;p&gt;should i just get into management and forgo this gap in skills to move on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15fuadn", "is_robot_indexable": true, "report_reasons": null, "author": "uwrwilke", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fuadn/date_engineer_seeking_career_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fuadn/date_engineer_seeking_career_advice/", "subreddit_subscribers": 119904, "created_utc": 1690937658.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A lot of projects, guides, even literature mostly covers production centric pipelines &amp; architectures. I'm curious how you or your company is handling situations where you not only have a production app but also a QA / UAT environment and potentially even a stable development environment. \n\nTo better explain: \n\n| Environment | Name        | Purpose                                       | Example Source URL                            | Example Source System    |\n|-------------|-------------|-----------------------------------------------|---------------------------------------|--------------------------|\n| Production  | prod  | Live environment for real-world data usage   | https://app.domain.com/   | the \"live\" app                |\n| UAT         | uat         | User Acceptance Testing before production    | https://app-uat.domain.com/           | the \"uat\" app            |\n| Develop     | develop     | Development and testing of new features      | https://app-dev.domain.com/      | the \"dev\" app    |\n\n\nDo you treat those all as separate pipelines? Is it pure configuration? \nWhat about end results? Do you have a separate \"reporting\" / \"analytics\" exposure per environment?  \n\nThanks.", "author_fullname": "t2_1icoacpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is your company handling pipelines for non-prod data sources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fp9m6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690924984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A lot of projects, guides, even literature mostly covers production centric pipelines &amp;amp; architectures. I&amp;#39;m curious how you or your company is handling situations where you not only have a production app but also a QA / UAT environment and potentially even a stable development environment. &lt;/p&gt;\n\n&lt;p&gt;To better explain: &lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Environment&lt;/th&gt;\n&lt;th&gt;Name&lt;/th&gt;\n&lt;th&gt;Purpose&lt;/th&gt;\n&lt;th&gt;Example Source URL&lt;/th&gt;\n&lt;th&gt;Example Source System&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Production&lt;/td&gt;\n&lt;td&gt;prod&lt;/td&gt;\n&lt;td&gt;Live environment for real-world data usage&lt;/td&gt;\n&lt;td&gt;&lt;a href=\"https://app.domain.com/\"&gt;https://app.domain.com/&lt;/a&gt;&lt;/td&gt;\n&lt;td&gt;the &amp;quot;live&amp;quot; app&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;UAT&lt;/td&gt;\n&lt;td&gt;uat&lt;/td&gt;\n&lt;td&gt;User Acceptance Testing before production&lt;/td&gt;\n&lt;td&gt;&lt;a href=\"https://app-uat.domain.com/\"&gt;https://app-uat.domain.com/&lt;/a&gt;&lt;/td&gt;\n&lt;td&gt;the &amp;quot;uat&amp;quot; app&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;Develop&lt;/td&gt;\n&lt;td&gt;develop&lt;/td&gt;\n&lt;td&gt;Development and testing of new features&lt;/td&gt;\n&lt;td&gt;&lt;a href=\"https://app-dev.domain.com/\"&gt;https://app-dev.domain.com/&lt;/a&gt;&lt;/td&gt;\n&lt;td&gt;the &amp;quot;dev&amp;quot; app&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Do you treat those all as separate pipelines? Is it pure configuration? \nWhat about end results? Do you have a separate &amp;quot;reporting&amp;quot; / &amp;quot;analytics&amp;quot; exposure per environment?  &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15fp9m6", "is_robot_indexable": true, "report_reasons": null, "author": "0_to_1", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fp9m6/how_is_your_company_handling_pipelines_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fp9m6/how_is_your_company_handling_pipelines_for/", "subreddit_subscribers": 119904, "created_utc": 1690924984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Probably a dumb question.\n\nHypothetically, say your transformation logic changes, and you want to run a backfill. \n\nBut say the source database has deleted most of its old data, how is this generally handled?\n\nI get a solution might be to create a \u201craw data area\u201d where you basically ingest data into this area everyday (as an example), and then going forward, you treat this as the source data, rather than relying on the source db.\n\nIf this was the case, would you only run the transformation part of your pipeline, and if so, how would this work in something like ADF? \n\nWould it make sense to create an extraction pipeline and a transformation pipeline, and make sure the team only ever run backfills on the transformation pipeline?", "author_fullname": "t2_7xk4etxe3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does backfilling work if the source db occasionally deletes old data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fmgtz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690918686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Probably a dumb question.&lt;/p&gt;\n\n&lt;p&gt;Hypothetically, say your transformation logic changes, and you want to run a backfill. &lt;/p&gt;\n\n&lt;p&gt;But say the source database has deleted most of its old data, how is this generally handled?&lt;/p&gt;\n\n&lt;p&gt;I get a solution might be to create a \u201craw data area\u201d where you basically ingest data into this area everyday (as an example), and then going forward, you treat this as the source data, rather than relying on the source db.&lt;/p&gt;\n\n&lt;p&gt;If this was the case, would you only run the transformation part of your pipeline, and if so, how would this work in something like ADF? &lt;/p&gt;\n\n&lt;p&gt;Would it make sense to create an extraction pipeline and a transformation pipeline, and make sure the team only ever run backfills on the transformation pipeline?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15fmgtz", "is_robot_indexable": true, "report_reasons": null, "author": "Weekly_Dimension_332", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fmgtz/how_does_backfilling_work_if_the_source_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fmgtz/how_does_backfilling_work_if_the_source_db/", "subreddit_subscribers": 119904, "created_utc": 1690918686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5cgbpdbh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Iceberg Integration with Databend", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "name": "t3_15fwpq7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/deq55O7LVPtUCgdhcrB4Y08y8CyAKO8z_6gmAFcM8rI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690944463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "databend.rs", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://databend.rs/blog/2023-08-01-iceberg-integration", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ipKMbzpOCaIZNYoc10aVc_MfGD1OpIYei_5_WRD16mA.jpg?auto=webp&amp;s=c9289d1f2e6941e3980a31f7f790cece670f7726", "width": 595, "height": 260}, "resolutions": [{"url": "https://external-preview.redd.it/ipKMbzpOCaIZNYoc10aVc_MfGD1OpIYei_5_WRD16mA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cbabc60bb83c5c2f9183f0e2c176e48d4854875c", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/ipKMbzpOCaIZNYoc10aVc_MfGD1OpIYei_5_WRD16mA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7928bb17b1dfacfe62fc9f8e32084eb0bca1d91d", "width": 216, "height": 94}, {"url": "https://external-preview.redd.it/ipKMbzpOCaIZNYoc10aVc_MfGD1OpIYei_5_WRD16mA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c31f7503aa5e85868fd4359c5af1e3099dee3fc5", "width": 320, "height": 139}], "variants": {}, "id": "a6UvO2SVqLWsWC0XsJy63qQHlCfy41ygQfRmuADYK4c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15fwpq7", "is_robot_indexable": true, "report_reasons": null, "author": "PsiACE", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fwpq7/iceberg_integration_with_databend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://databend.rs/blog/2023-08-01-iceberg-integration", "subreddit_subscribers": 119904, "created_utc": 1690944463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys I got a invitation for an Online Technical Interview for McKinsey - Data Engineer - University Students Role. I have been getting rejected to most of the places I apply at, so I was kind of confused that McKinsey send a  interview. I was wondering, does everyone who applies get the Online Technical Interview or is it more selective? I also not the best at taking  Online Technical Interviews so I was wondering if anyone has any tips for that.", "author_fullname": "t2_7k10vnajk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "McKinsey - Data Engineer - University Students Role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fhe6c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690907334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys I got a invitation for an Online Technical Interview for McKinsey - Data Engineer - University Students Role. I have been getting rejected to most of the places I apply at, so I was kind of confused that McKinsey send a  interview. I was wondering, does everyone who applies get the Online Technical Interview or is it more selective? I also not the best at taking  Online Technical Interviews so I was wondering if anyone has any tips for that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "15fhe6c", "is_robot_indexable": true, "report_reasons": null, "author": "WaitPsychological532", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fhe6c/mckinsey_data_engineer_university_students_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fhe6c/mckinsey_data_engineer_university_students_role/", "subreddit_subscribers": 119904, "created_utc": 1690907334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.\n\nJoin our [newsletter](https://dataengineeringcommunity.substack.com/) for regular data engineering community updates, inspiration, and insights.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion - Aug 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h", "t3_128qhe2", "t3_134qgn8", "t3_13xle38", "t3_14nylwl", "t3_15fgn9y"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1690905650.327, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fgn9y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1690905649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n\n&lt;p&gt;Join our &lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;newsletter&lt;/a&gt; for regular data engineering community updates, inspiration, and insights.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5hX88p7Zlx995y2AC0Sb_biZAT_nna3SZcxbz_11hhI.jpg?auto=webp&amp;s=f9359dad1d983347db44f2cccbd0b0f99e16a62c", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/5hX88p7Zlx995y2AC0Sb_biZAT_nna3SZcxbz_11hhI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=04e1b5b7eb03f5443c87c198a1aa6708e2c52eac", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/5hX88p7Zlx995y2AC0Sb_biZAT_nna3SZcxbz_11hhI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8679e56088c4fe736444659cb5fb4e3ef2fff64f", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/5hX88p7Zlx995y2AC0Sb_biZAT_nna3SZcxbz_11hhI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6a80cc7e920d2be12047018c3175d792aa279ab3", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/5hX88p7Zlx995y2AC0Sb_biZAT_nna3SZcxbz_11hhI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=baa6cc1c0ed69575c177c13d6296ff46f82657bf", "width": 640, "height": 333}], "variants": {}, "id": "Qo9qYKD-7P-sb-46EoJ3ZlaOD05VErGXT0coJg6xpxg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15fgn9y", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fgn9y/monthly_general_discussion_aug_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/15fgn9y/monthly_general_discussion_aug_2023/", "subreddit_subscribers": 119904, "created_utc": 1690905649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, \n\nI'm currently given a task to design backend. The problem is to take PDFs convert them to excel then parse the excel files and save the data to a database server. They don't want cloud solutions. Their entire ecosystem is in windows. I tried Airflow but don't understand how to get it up and running in windows.  I made the program(mix of python and C#) but I need it to run automatically and like a service . I have no idea how to make it runnable on a different environment and how to show a demo. Can anyone help me out?", "author_fullname": "t2_7x71cv3h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm an intern, I need help regarding pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fxc6k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690946261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently given a task to design backend. The problem is to take PDFs convert them to excel then parse the excel files and save the data to a database server. They don&amp;#39;t want cloud solutions. Their entire ecosystem is in windows. I tried Airflow but don&amp;#39;t understand how to get it up and running in windows.  I made the program(mix of python and C#) but I need it to run automatically and like a service . I have no idea how to make it runnable on a different environment and how to show a demo. Can anyone help me out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15fxc6k", "is_robot_indexable": true, "report_reasons": null, "author": "YouKnowILoveMyself", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fxc6k/im_an_intern_i_need_help_regarding_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fxc6k/im_an_intern_i_need_help_regarding_pipelines/", "subreddit_subscribers": 119904, "created_utc": 1690946261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When naming folders for ADLS gen2, is there a signficance to the convention of naming a folder '***year=2022***' versus simply, '***2022***'? Is it to make the folders less ambiguous, for compatibilty, performance increases, or any other reasons not mentioned?", "author_fullname": "t2_6bs83", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question About Naming Conventions for ADLS Gen2 Hierarchcal Namespace", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fq4yq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690927001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When naming folders for ADLS gen2, is there a signficance to the convention of naming a folder &amp;#39;&lt;strong&gt;&lt;em&gt;year=2022&lt;/em&gt;&lt;/strong&gt;&amp;#39; versus simply, &amp;#39;&lt;strong&gt;&lt;em&gt;2022&lt;/em&gt;&lt;/strong&gt;&amp;#39;? Is it to make the folders less ambiguous, for compatibilty, performance increases, or any other reasons not mentioned?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15fq4yq", "is_robot_indexable": true, "report_reasons": null, "author": "who-wut", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fq4yq/question_about_naming_conventions_for_adls_gen2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fq4yq/question_about_naming_conventions_for_adls_gen2/", "subreddit_subscribers": 119904, "created_utc": 1690927001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Flink-Doris-Connector 1.4.0 allows users to ingest a whole database (**MySQL** or **Oracle**) that contains thousands of tables into Apache Doris, a real-time analytic database, **in one step**.\n\nWith built-in Flink CDC, the Connector can directly synchronize the table schema and data from the upstream source to Apache Doris, which means users no long have to write a DataStream program or pre-create mapping tables in Doris. \n\nWhen a Flink job starts, the Connector automatically checks for data equivalence between the source database and Apache Doris. If the data source contains tables which do not exist in Doris, the Connector will automatically create those same tables in Doris, and utilizes the side outputs of Flink to facilitate the ingestion of multiple tables at once; if there is a schema change in the source, it will automatically obtain the DDL statement and make the same schema change in Doris.", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Auto-Synchronization of an Entire MySQL Database for Data Analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fbffy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690893548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Flink-Doris-Connector 1.4.0 allows users to ingest a whole database (&lt;strong&gt;MySQL&lt;/strong&gt; or &lt;strong&gt;Oracle&lt;/strong&gt;) that contains thousands of tables into Apache Doris, a real-time analytic database, &lt;strong&gt;in one step&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;With built-in Flink CDC, the Connector can directly synchronize the table schema and data from the upstream source to Apache Doris, which means users no long have to write a DataStream program or pre-create mapping tables in Doris. &lt;/p&gt;\n\n&lt;p&gt;When a Flink job starts, the Connector automatically checks for data equivalence between the source database and Apache Doris. If the data source contains tables which do not exist in Doris, the Connector will automatically create those same tables in Doris, and utilizes the side outputs of Flink to facilitate the ingestion of multiple tables at once; if there is a schema change in the source, it will automatically obtain the DDL statement and make the same schema change in Doris.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15fbffy", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fbffy/autosynchronization_of_an_entire_mysql_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fbffy/autosynchronization_of_an_entire_mysql_database/", "subreddit_subscribers": 119904, "created_utc": 1690893548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently work as a data engineer on a team responsible for creating data structures for strategic analysis (such as the data warehouse), but our team is also responsible for tactical, operational reporting (i.e. a lot of one-off reports directly against transactional data) as well as integrations to provide data to third party applications. I am curious as to how widespread it is to mix these two functions on a single team? Also, for those teams who do cover both strategic and tactical reporting, do you have dedicated report writers, or is this duty handled by your data engineers and BI developers? Thanks!", "author_fullname": "t2_7v6lrwy7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about Operational Reporting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fb0wr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690892489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work as a data engineer on a team responsible for creating data structures for strategic analysis (such as the data warehouse), but our team is also responsible for tactical, operational reporting (i.e. a lot of one-off reports directly against transactional data) as well as integrations to provide data to third party applications. I am curious as to how widespread it is to mix these two functions on a single team? Also, for those teams who do cover both strategic and tactical reporting, do you have dedicated report writers, or is this duty handled by your data engineers and BI developers? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15fb0wr", "is_robot_indexable": true, "report_reasons": null, "author": "Pure-Insanity-1976", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fb0wr/question_about_operational_reporting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fb0wr/question_about_operational_reporting/", "subreddit_subscribers": 119904, "created_utc": 1690892489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am facing some issues regarding the set-up of self-hosted Integration runtime in the Azure data factory in my MacBook, Most of my peers have a Windows PC so I am struggling to find a solution.", "author_fullname": "t2_kef6hr1l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Help In Setting Up Self-Hosted Integration Runtime in ADF on MacBook.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15g50xb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690971420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am facing some issues regarding the set-up of self-hosted Integration runtime in the Azure data factory in my MacBook, Most of my peers have a Windows PC so I am struggling to find a solution.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15g50xb", "is_robot_indexable": true, "report_reasons": null, "author": "Vishesh_Sharma_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15g50xb/need_help_in_setting_up_selfhosted_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15g50xb/need_help_in_setting_up_selfhosted_integration/", "subreddit_subscribers": 119904, "created_utc": 1690971420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you have a really huge table in rdbms.\nHow do you ingest the whole snapshot of the table into parquet or other format.\n\nIt is not so clear to me how to do it in batch with an atomic (capture only the state of the table at the ingestion time) and whether it is possible to distributed the task across multiple workers to speed up.", "author_fullname": "t2_4sx64zdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the approaches to ingest large db", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15g4mit", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690970094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you have a really huge table in rdbms.\nHow do you ingest the whole snapshot of the table into parquet or other format.&lt;/p&gt;\n\n&lt;p&gt;It is not so clear to me how to do it in batch with an atomic (capture only the state of the table at the ingestion time) and whether it is possible to distributed the task across multiple workers to speed up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "15g4mit", "is_robot_indexable": true, "report_reasons": null, "author": "Both_Antelope_9872", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15g4mit/what_are_the_approaches_to_ingest_large_db/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15g4mit/what_are_the_approaches_to_ingest_large_db/", "subreddit_subscribers": 119904, "created_utc": 1690970094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, I am an undergraduate student pursuing a bachelor's degree in computer science (halfway through it). I have been learning Data Science and Machine Learning for two years now and have also worked on many portfolio projects. Lately, I am getting concerned about the job market in data science and am considering switching my career to Data Engineering. I am here to seek advice from experienced professionals who have been in the industry for some time on whether I should change my career to Data Engineering or stay focused on Data Science.\n\nThe transition to Data Engineering might not be too challenging for me, as I am already familiar with data concepts and techniques. If I start learning Data Engineering now, by the time I graduate, I will have the necessary skills to pursue a career in this field.\n\nI would truly appreciate any insights, suggestions, or experiences you could share with me. Thank you in advance!", "author_fullname": "t2_6oagcr1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I switch from Data Science to Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15g1rc5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690960349.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I am an undergraduate student pursuing a bachelor&amp;#39;s degree in computer science (halfway through it). I have been learning Data Science and Machine Learning for two years now and have also worked on many portfolio projects. Lately, I am getting concerned about the job market in data science and am considering switching my career to Data Engineering. I am here to seek advice from experienced professionals who have been in the industry for some time on whether I should change my career to Data Engineering or stay focused on Data Science.&lt;/p&gt;\n\n&lt;p&gt;The transition to Data Engineering might not be too challenging for me, as I am already familiar with data concepts and techniques. If I start learning Data Engineering now, by the time I graduate, I will have the necessary skills to pursue a career in this field.&lt;/p&gt;\n\n&lt;p&gt;I would truly appreciate any insights, suggestions, or experiences you could share with me. Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "15g1rc5", "is_robot_indexable": true, "report_reasons": null, "author": "hashirbhatti", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15g1rc5/should_i_switch_from_data_science_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15g1rc5/should_i_switch_from_data_science_to_data/", "subreddit_subscribers": 119904, "created_utc": 1690960349.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have lots of synapse notebooks that I have been calling with other \u201cmaster notebooks\u201d using the magic %run command.  \nI recently found the mssparkutils.notebook.run() method of invoking a notebook.\nI like the latter method because you can format the parameters section on multiple lines, however there seems to be issues calling notebooks this way.\nI had one complete with an error today but the cell with the .run command completed successfully.\nIf error trapping doesn\u2019t work then it\u2019s worthless to me.\nHow do you call notebooks from other notebooks?  Which is the most ideal way?\nI\u2019d love to hear your insights.", "author_fullname": "t2_4270ek0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to call Synapse notebook from another notebook?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15funyx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690938671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have lots of synapse notebooks that I have been calling with other \u201cmaster notebooks\u201d using the magic %run command.&lt;br/&gt;\nI recently found the mssparkutils.notebook.run() method of invoking a notebook.\nI like the latter method because you can format the parameters section on multiple lines, however there seems to be issues calling notebooks this way.\nI had one complete with an error today but the cell with the .run command completed successfully.\nIf error trapping doesn\u2019t work then it\u2019s worthless to me.\nHow do you call notebooks from other notebooks?  Which is the most ideal way?\nI\u2019d love to hear your insights.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15funyx", "is_robot_indexable": true, "report_reasons": null, "author": "mr_electric_wizard", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15funyx/best_way_to_call_synapse_notebook_from_another/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15funyx/best_way_to_call_synapse_notebook_from_another/", "subreddit_subscribers": 119904, "created_utc": 1690938671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_v5yztiz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ambarish Donga DatabricKS Solution Architedct interview Tips", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_15fs76t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/eLCcNRT5BlA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Databricks Solutions Architect Interview - Process, Presentation &amp;amp; Code\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Databricks Solutions Architect Interview - Process, Presentation &amp; Code", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/eLCcNRT5BlA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Databricks Solutions Architect Interview - Process, Presentation &amp;amp; Code\"&gt;&lt;/iframe&gt;", "author_name": "Ambarish Dongre", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/eLCcNRT5BlA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ambarish-dongre"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/eLCcNRT5BlA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Databricks Solutions Architect Interview - Process, Presentation &amp;amp; Code\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/15fs76t", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/q2e8JYSHKfkFF2d2h9ttSvS5U40GVk55EZCkHuBd9vc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690932105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=eLCcNRT5BlA", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/86cP69tubnXslziLOt8q-HmdFZhGkUb7PUFH2htHLHM.jpg?auto=webp&amp;s=af5564a3ee31eaebfc1e1b7b0ba133532a6d2547", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/86cP69tubnXslziLOt8q-HmdFZhGkUb7PUFH2htHLHM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9296ebbab03acee34f85ada2e3559773ebdd0910", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/86cP69tubnXslziLOt8q-HmdFZhGkUb7PUFH2htHLHM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7f0f6dc2d5bc05134a9a207d7a2ddefac4698f48", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/86cP69tubnXslziLOt8q-HmdFZhGkUb7PUFH2htHLHM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e78ee1ad598734e174063be6d8cd06064387a5b7", "width": 320, "height": 240}], "variants": {}, "id": "5bWcoUiTrYKGEVjd-54FD6EPFLgSO7adNFq6g3H0VsU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15fs76t", "is_robot_indexable": true, "report_reasons": null, "author": "jonyeanu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fs76t/ambarish_donga_databricks_solution_architedct/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=eLCcNRT5BlA", "subreddit_subscribers": 119904, "created_utc": 1690932105.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Databricks Solutions Architect Interview - Process, Presentation &amp; Code", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/eLCcNRT5BlA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Databricks Solutions Architect Interview - Process, Presentation &amp;amp; Code\"&gt;&lt;/iframe&gt;", "author_name": "Ambarish Dongre", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/eLCcNRT5BlA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ambarish-dongre"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am a university student looking to go into data engineering/science in the future. I have a side project in mind with the following data flow:\n\n\\- Real-time data input from an API\n\n\\- There exists a couple of data tables (&lt; 10 GB), which the data \"goes through\" to calculate relatively simple statistical stuff\n\n\\- Each instance of the data &amp; statistical results gets posted on a website\n\n\\- I want this to be automated even when my computer is off\n\nAny advice on which tools to use that are free or cheap? I looked into Azure or AWS cloud computing, but they seem to be costly when I go over a couple of GB of storage. I'm not even sure if I can integrate that to a website. I want to use Python + I have experience in building simple websites but nothing like this before.\n\nIf you have any other advice or helpful comments I would appreciate it.\n\nThank you!", "author_fullname": "t2_vtvvzldg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Side Project Advice Needed For a Data Noob", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fqg3f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690929533.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690927726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am a university student looking to go into data engineering/science in the future. I have a side project in mind with the following data flow:&lt;/p&gt;\n\n&lt;p&gt;- Real-time data input from an API&lt;/p&gt;\n\n&lt;p&gt;- There exists a couple of data tables (&amp;lt; 10 GB), which the data &amp;quot;goes through&amp;quot; to calculate relatively simple statistical stuff&lt;/p&gt;\n\n&lt;p&gt;- Each instance of the data &amp;amp; statistical results gets posted on a website&lt;/p&gt;\n\n&lt;p&gt;- I want this to be automated even when my computer is off&lt;/p&gt;\n\n&lt;p&gt;Any advice on which tools to use that are free or cheap? I looked into Azure or AWS cloud computing, but they seem to be costly when I go over a couple of GB of storage. I&amp;#39;m not even sure if I can integrate that to a website. I want to use Python + I have experience in building simple websites but nothing like this before.&lt;/p&gt;\n\n&lt;p&gt;If you have any other advice or helpful comments I would appreciate it.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15fqg3f", "is_robot_indexable": true, "report_reasons": null, "author": "dhwi1ue9dj", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fqg3f/side_project_advice_needed_for_a_data_noob/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fqg3f/side_project_advice_needed_for_a_data_noob/", "subreddit_subscribers": 119904, "created_utc": 1690927726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rku02rf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DuckDB vs. MotherDuck \u2014 should you switch to the cloud version?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fow15", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1690924136.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kestra.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kestra.io/blogs/2023-07-28-duckdb-vs-motherduck", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15fow15", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fow15/duckdb_vs_motherduck_should_you_switch_to_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kestra.io/blogs/2023-07-28-duckdb-vs-motherduck", "subreddit_subscribers": 119904, "created_utc": 1690924136.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bridging Financial Data Streams: A Look at ASOF Join in Pathway", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_15fdzts", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kxdq3LLiOR-PXY6L3hztsGd4K_iIjyxavmOIpeyOyPU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690899667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "pathway.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://pathway.com/developers/tutorials/finance_ts_asof_join/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FoW1C_FqDkjZRZjxWcWt_IX5fvhTuqTN9ccAwcaI7XQ.jpg?auto=webp&amp;s=e6f91da76270ca4c0015aaa3e1952f9cda8e3fa8", "width": 370, "height": 280}, "resolutions": [{"url": "https://external-preview.redd.it/FoW1C_FqDkjZRZjxWcWt_IX5fvhTuqTN9ccAwcaI7XQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=37f452fcba51ebf8eff92cd1dbd6385b1653d355", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/FoW1C_FqDkjZRZjxWcWt_IX5fvhTuqTN9ccAwcaI7XQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b833c651a0cd954d03c1298544ab2e54e0e5db9e", "width": 216, "height": 163}, {"url": "https://external-preview.redd.it/FoW1C_FqDkjZRZjxWcWt_IX5fvhTuqTN9ccAwcaI7XQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=153555937cc589bf46883c90f8b57b8a44ed6c59", "width": 320, "height": 242}], "variants": {}, "id": "7qeD-kRV2e7yimDjWZ-wHpsZfXWaosE7nRfyQNoR26E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15fdzts", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fdzts/bridging_financial_data_streams_a_look_at_asof/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://pathway.com/developers/tutorials/finance_ts_asof_join/", "subreddit_subscribers": 119904, "created_utc": 1690899667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I help lots of people use Python in cloud (I work on Dask, an OSS library for parallel computing).  Some people don't need the complexity of Dask (it can do a lot) they just need to run some simple processing function 1000 times on data in the cloud.  I tell them that Dask is overkill.\n\nBut working with users, it seems like cloud solutions to this don't provide a great UX.  Why not?  Surely this can't be that hard.\n\nI wrote a small blog post about this here: [https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc](https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc) .  It (shamelessly) advertises and thing we built on top of Dask + Coiled to do make this more palatable for non-cloud-conversant Python folks.  I'd welcome feedback/critique.  This was kind of a slapdash effort, but seems ok?", "author_fullname": "t2_ay1q1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud services to run a Python function in the cloud seem suboptimal", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fbu8g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690894559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I help lots of people use Python in cloud (I work on Dask, an OSS library for parallel computing).  Some people don&amp;#39;t need the complexity of Dask (it can do a lot) they just need to run some simple processing function 1000 times on data in the cloud.  I tell them that Dask is overkill.&lt;/p&gt;\n\n&lt;p&gt;But working with users, it seems like cloud solutions to this don&amp;#39;t provide a great UX.  Why not?  Surely this can&amp;#39;t be that hard.&lt;/p&gt;\n\n&lt;p&gt;I wrote a small blog post about this here: &lt;a href=\"https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc\"&gt;https://medium.com/coiled-hq/easy-heavyweight-serverless-functions-1983288c9ebc&lt;/a&gt; .  It (shamelessly) advertises and thing we built on top of Dask + Coiled to do make this more palatable for non-cloud-conversant Python folks.  I&amp;#39;d welcome feedback/critique.  This was kind of a slapdash effort, but seems ok?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?auto=webp&amp;s=2500e20c454938762e145ed937b5f672c7107662", "width": 896, "height": 400}, "resolutions": [{"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5bcad2d83ba44812cde35a979f693e85f02ddaf9", "width": 108, "height": 48}, {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=52a97dc310c1b8265ad9a42ec3aee06746e66741", "width": 216, "height": 96}, {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dbdbe143a144ea4988a66c1ce8b17371b5656b35", "width": 320, "height": 142}, {"url": "https://external-preview.redd.it/6HcL-2BC7zRPCEdYMpiVd8tlLMS2ZrIzsLG7fn5EbMA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e527de6f5793a0b076997f0214c37ae589620340", "width": 640, "height": 285}], "variants": {}, "id": "bOYGIMA5j7XFBgY_b1492O6l7ahrAYsoMlsFe7s2tWQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "15fbu8g", "is_robot_indexable": true, "report_reasons": null, "author": "mrocklin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fbu8g/cloud_services_to_run_a_python_function_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fbu8g/cloud_services_to_run_a_python_function_in_the/", "subreddit_subscribers": 119904, "created_utc": 1690894559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,  \nI'm a Data Visualization Engineer trying to transition to data engineering. I would like to build some projects to develop my DE skills. I wish to do it with a complex dataset so I get to learn it extensively, covering all the aspects. Could you guys suggest such datasets that you've seen or previously worked on?", "author_fullname": "t2_740yhxnt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Request-Real-world datasets to practice Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fzvzl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690954058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;br/&gt;\nI&amp;#39;m a Data Visualization Engineer trying to transition to data engineering. I would like to build some projects to develop my DE skills. I wish to do it with a complex dataset so I get to learn it extensively, covering all the aspects. Could you guys suggest such datasets that you&amp;#39;ve seen or previously worked on?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "15fzvzl", "is_robot_indexable": true, "report_reasons": null, "author": "Gokul321", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/15fzvzl/requestrealworld_datasets_to_practice_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/15fzvzl/requestrealworld_datasets_to_practice_data/", "subreddit_subscribers": 119904, "created_utc": 1690954058.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}