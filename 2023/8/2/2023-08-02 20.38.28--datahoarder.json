{"kind": "Listing", "data": {"after": "t3_15fwyhb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_uf7as41t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Western Digital HDD capacity hits 28TB as Seagate looks to 30TB and beyond", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_15ftz33", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 421, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 421, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/EuQJdkAUSDwD3d2ujxEdjBRKSBApD6VtGO_qaxP7JMc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690936789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arstechnica.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://arstechnica.com/gadgets/2023/08/western-digital-hdd-capacity-hits-28tb-as-seagate-looks-to-30tb-and-beyond/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/y7TsL0CYYyZxwPEnpmddBXOhqmqBBaaSIQi7vmvLiCM.jpg?auto=webp&amp;s=2c4266cb1d001a82ef88b1d6a223661ff5c9c4d7", "width": 760, "height": 380}, "resolutions": [{"url": "https://external-preview.redd.it/y7TsL0CYYyZxwPEnpmddBXOhqmqBBaaSIQi7vmvLiCM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da46d2be9ecfbdf105f2eab6b9022058283dd221", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/y7TsL0CYYyZxwPEnpmddBXOhqmqBBaaSIQi7vmvLiCM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=69b07b878bff20c6fe864bdb3670ff2483a79730", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/y7TsL0CYYyZxwPEnpmddBXOhqmqBBaaSIQi7vmvLiCM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=675cc365bc1d9dd33d858bc621a568a89bfc4e73", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/y7TsL0CYYyZxwPEnpmddBXOhqmqBBaaSIQi7vmvLiCM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bb8cd15683aab5ff1a5a0ca9b7d20d49deb6ae8c", "width": 640, "height": 320}], "variants": {}, "id": "5cybmiXjM9KdLA1mjYQvVp5cP7gRcyoTx9Mg2Vqc02c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ftz33", "is_robot_indexable": true, "report_reasons": null, "author": "DeathClawdVanDamn", "discussion_type": null, "num_comments": 113, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ftz33/western_digital_hdd_capacity_hits_28tb_as_seagate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://arstechnica.com/gadgets/2023/08/western-digital-hdd-capacity-hits-28tb-as-seagate-looks-to-30tb-and-beyond/", "subreddit_subscribers": 695980, "created_utc": 1690936789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know the reported limit was supposed to be limited increases to 10TB per week, 40TB per month, but they recently changed it again, to be 1TB per month, 250GB per week, which works out at around 35.7GB per day.\n\nAt the price they charge (requiring 3 users), it really is pathetically bad.\n\nI have no idea what effect this has on enterprise users.", "author_fullname": "t2_m2qke", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dropbox now limiting advanced plans to 1TB per month, 250GB per week, 35.7GB per day.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gf2rc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Cloud", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690997311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know the reported limit was supposed to be limited increases to 10TB per week, 40TB per month, but they recently changed it again, to be 1TB per month, 250GB per week, which works out at around 35.7GB per day.&lt;/p&gt;\n\n&lt;p&gt;At the price they charge (requiring 3 users), it really is pathetically bad.&lt;/p&gt;\n\n&lt;p&gt;I have no idea what effect this has on enterprise users.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "688TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15gf2rc", "is_robot_indexable": true, "report_reasons": null, "author": "jl94x4", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15gf2rc/dropbox_now_limiting_advanced_plans_to_1tb_per/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gf2rc/dropbox_now_limiting_advanced_plans_to_1tb_per/", "subreddit_subscribers": 695980, "created_utc": 1690997311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I joined a course and to view the course content I have to install specific player which does not allow screenshot/screen recorders etc. So the only way I can think of maintaining a copy for myself is to record the screen with a secondary camera. But that sounds extremely 90s :)\n\nI am wondering if any of you have found a way to workaround this?", "author_fullname": "t2_aawlefye", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a DRM video that only runs with its own player - how do I record and maintain via a secondary cam?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15g9f16", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690984133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I joined a course and to view the course content I have to install specific player which does not allow screenshot/screen recorders etc. So the only way I can think of maintaining a copy for myself is to record the screen with a secondary camera. But that sounds extremely 90s :)&lt;/p&gt;\n\n&lt;p&gt;I am wondering if any of you have found a way to workaround this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15g9f16", "is_robot_indexable": true, "report_reasons": null, "author": "gosteneonic", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15g9f16/i_have_a_drm_video_that_only_runs_with_its_own/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15g9f16/i_have_a_drm_video_that_only_runs_with_its_own/", "subreddit_subscribers": 695980, "created_utc": 1690984133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! I'm a freelance videographer, and recently I've been having issues with storage management. \n\nI own a 2TB MacBook Pro, a 4TB Samsung T7 SSD, a 2TB SanDisk Extreme Pro, and a 1TB SanDisk Extreme Pro. Usually I delete the footage once the project is complete, but I've recently have had storage issues when I take on multiple projects at once. Each project consists of around 1.5TB of BRAW. files.\n\nIn addition to this, my 2TB SanDisk Extreme Pro has been failing a lot recently, so I consider it unreliable for further use. I also have begun production on a documentary, which will have around 2 years of footage when finished (not sure how much storage this will take). My internet is pretty spotty as well, so it isn't ideal to upload to the cloud.\n\nMy goal is to create some sort of physical drive tower where I can dump multiple copies of the footage across several (preferably 3) drives. It doesn't have to be fast or small. I just need something that is reliable and has a ton of storage in case one of my SSDs fails.\n\nDoes anyone have any suggestions on what to do? Thank you!", "author_fullname": "t2_bxgfd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a physical place to dump footage.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15forp7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690923867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I&amp;#39;m a freelance videographer, and recently I&amp;#39;ve been having issues with storage management. &lt;/p&gt;\n\n&lt;p&gt;I own a 2TB MacBook Pro, a 4TB Samsung T7 SSD, a 2TB SanDisk Extreme Pro, and a 1TB SanDisk Extreme Pro. Usually I delete the footage once the project is complete, but I&amp;#39;ve recently have had storage issues when I take on multiple projects at once. Each project consists of around 1.5TB of BRAW. files.&lt;/p&gt;\n\n&lt;p&gt;In addition to this, my 2TB SanDisk Extreme Pro has been failing a lot recently, so I consider it unreliable for further use. I also have begun production on a documentary, which will have around 2 years of footage when finished (not sure how much storage this will take). My internet is pretty spotty as well, so it isn&amp;#39;t ideal to upload to the cloud.&lt;/p&gt;\n\n&lt;p&gt;My goal is to create some sort of physical drive tower where I can dump multiple copies of the footage across several (preferably 3) drives. It doesn&amp;#39;t have to be fast or small. I just need something that is reliable and has a ton of storage in case one of my SSDs fails.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any suggestions on what to do? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15forp7", "is_robot_indexable": true, "report_reasons": null, "author": "biollante", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15forp7/looking_for_a_physical_place_to_dump_footage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15forp7/looking_for_a_physical_place_to_dump_footage/", "subreddit_subscribers": 695980, "created_utc": 1690923867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am just wondering why there are no 3.5\" SSDs.\nIt could be a 3.5\" plastic housing fully stacked with flash storage.\nMaybe I could not find them but if there aren't: Why?", "author_fullname": "t2_d8wthq9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are there no 3.5\" SDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gfewp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690998067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am just wondering why there are no 3.5&amp;quot; SSDs.\nIt could be a 3.5&amp;quot; plastic housing fully stacked with flash storage.\nMaybe I could not find them but if there aren&amp;#39;t: Why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gfewp", "is_robot_indexable": true, "report_reasons": null, "author": "ajfriesen", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gfewp/why_are_there_no_35_sdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gfewp/why_are_there_no_35_sdds/", "subreddit_subscribers": 695980, "created_utc": 1690998067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a way to view link rot from imgur due to that stupid policy? Either by replacing the original imgur link with the new link (maybe link come from archive database (could be from ArchiveTeam or not)) with an extension or Android redirect app?\n\nEdit: looks like the database is https://archive.org/details/archiveteam_imgur , however I'm not sure if there tool to redirect imgur link to that db?", "author_fullname": "t2_ish5z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imgur link rot viewer? Or viewing whatever ArchiveTeam grabbed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gf3hw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690997363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a way to view link rot from imgur due to that stupid policy? Either by replacing the original imgur link with the new link (maybe link come from archive database (could be from ArchiveTeam or not)) with an extension or Android redirect app?&lt;/p&gt;\n\n&lt;p&gt;Edit: looks like the database is &lt;a href=\"https://archive.org/details/archiveteam_imgur\"&gt;https://archive.org/details/archiveteam_imgur&lt;/a&gt; , however I&amp;#39;m not sure if there tool to redirect imgur link to that db?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "50TB TrueNAS MiniX+ | 2TB OneDrive", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gf3hw", "is_robot_indexable": true, "report_reasons": null, "author": "Trung0246", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15gf3hw/imgur_link_rot_viewer_or_viewing_whatever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gf3hw/imgur_link_rot_viewer_or_viewing_whatever/", "subreddit_subscribers": 695980, "created_utc": 1690997363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_34nci", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trash Picker finds HP server rack thrown out in the trash jump to the 9:35 mark to see it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_15ghm1o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/AA32E5p-WTM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The Best Kind Of Trash Picking Day! - Ep. 786\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The Best Kind Of Trash Picking Day! - Ep. 786", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/AA32E5p-WTM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The Best Kind Of Trash Picking Day! - Ep. 786\"&gt;&lt;/iframe&gt;", "author_name": "Taco Stacks", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/AA32E5p-WTM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TacoStacks"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/AA32E5p-WTM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The Best Kind Of Trash Picking Day! - Ep. 786\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/15ghm1o", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iqQGIggSM0_5MpPEcyhUSOq_j023ihqyN_Ufh7cqjmU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1691003004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=AA32E5p-WTM", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rAHuyl4VBXsN_jOhiP8lfOd2TKDT5CFFnUcL6xQdYV4.jpg?auto=webp&amp;s=f891f54e726edb8176e4a0431442cbdf39451bca", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/rAHuyl4VBXsN_jOhiP8lfOd2TKDT5CFFnUcL6xQdYV4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f425b67188805c9e92be302f3e55f7a149851cee", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/rAHuyl4VBXsN_jOhiP8lfOd2TKDT5CFFnUcL6xQdYV4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9f91a8f8348ca02e6f17abececa2cae2a2916c1a", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/rAHuyl4VBXsN_jOhiP8lfOd2TKDT5CFFnUcL6xQdYV4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2060bedc345803d83544ec5470972037ca30759f", "width": 320, "height": 240}], "variants": {}, "id": "NPZOBeTm3CgVKF3QBODMybREm3Um0nHS7Wswe-LnMMU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15ghm1o", "is_robot_indexable": true, "report_reasons": null, "author": "DJboutit", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ghm1o/trash_picker_finds_hp_server_rack_thrown_out_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=AA32E5p-WTM", "subreddit_subscribers": 695980, "created_utc": 1691003004.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The Best Kind Of Trash Picking Day! - Ep. 786", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/AA32E5p-WTM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The Best Kind Of Trash Picking Day! - Ep. 786\"&gt;&lt;/iframe&gt;", "author_name": "Taco Stacks", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/AA32E5p-WTM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TacoStacks"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have seen multiple comments on some buyers from specific Hard Drive models which in common are bigger than usual (over 10 TB), the reviewers saying they make more noise than usual. Is this a common trait from all the newer HDDs? Or just a few of them?\n\nP.S. I just discovered a thread from 1 year ago asking the same:\n\n[https://www.reddit.com/r/DataHoarder/comments/st97qo/question\\_do\\_hard\\_drives\\_get\\_louder\\_as\\_they\\_get/](https://www.reddit.com/r/DataHoarder/comments/st97qo/question_do_hard_drives_get_louder_as_they_get/)\n\nIt looks like I wasn't the only one noticing this. And I wanted to ask this here even before finding out that thread!", "author_fullname": "t2_1utoiwm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's all this complaint about bigger HDDs being noisier?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gd0wo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690992625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have seen multiple comments on some buyers from specific Hard Drive models which in common are bigger than usual (over 10 TB), the reviewers saying they make more noise than usual. Is this a common trait from all the newer HDDs? Or just a few of them?&lt;/p&gt;\n\n&lt;p&gt;P.S. I just discovered a thread from 1 year ago asking the same:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/st97qo/question_do_hard_drives_get_louder_as_they_get/\"&gt;https://www.reddit.com/r/DataHoarder/comments/st97qo/question_do_hard_drives_get_louder_as_they_get/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It looks like I wasn&amp;#39;t the only one noticing this. And I wanted to ask this here even before finding out that thread!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gd0wo", "is_robot_indexable": true, "report_reasons": null, "author": "Maratocarde", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gd0wo/whats_all_this_complaint_about_bigger_hdds_being/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gd0wo/whats_all_this_complaint_about_bigger_hdds_being/", "subreddit_subscribers": 695980, "created_utc": 1690992625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello Fellow hoarders.  \n\n\nBeen looking at setting up a Raid Z2 file system with 6x &gt;12TB Drives (**planning to double it in the future to 12 drives total**)  \nBudget is capable of non-pro drives but can stretch it to pro drives if necessary.  \nThey're ONLY for plex (up to 3 streams AT MOST) so I don't need high read/writes, not to concerned with noise as it will be in a define R5 Silent (with extra DIY soundproofing on the inside).  \n\n\n**Title:**  \nThe main thing of Concern is the \"**Up to 8 drives**\" for N300's &amp; non-pro WD or Seagate drives.  \nwhat do you think about this? do you think this is a recommendation aimed for home users? or datacenter? my drives will only ever be in a Define R5 (or Define 7 XL in the future), so maybe they're not packed together as much? they will probably be sleeping most of the time as they're just for plex. for long term storage (10+ years) would you say the pro drives are necessary?  \n\n\nPlease share you thoughts &lt;3", "author_fullname": "t2_qh7y6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Up to 8 drives\" Your interpretation.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15g1ozl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690960127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Fellow hoarders.  &lt;/p&gt;\n\n&lt;p&gt;Been looking at setting up a Raid Z2 file system with 6x &amp;gt;12TB Drives (&lt;strong&gt;planning to double it in the future to 12 drives total&lt;/strong&gt;)&lt;br/&gt;\nBudget is capable of non-pro drives but can stretch it to pro drives if necessary.&lt;br/&gt;\nThey&amp;#39;re ONLY for plex (up to 3 streams AT MOST) so I don&amp;#39;t need high read/writes, not to concerned with noise as it will be in a define R5 Silent (with extra DIY soundproofing on the inside).  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Title:&lt;/strong&gt;&lt;br/&gt;\nThe main thing of Concern is the &amp;quot;&lt;strong&gt;Up to 8 drives&lt;/strong&gt;&amp;quot; for N300&amp;#39;s &amp;amp; non-pro WD or Seagate drives.&lt;br/&gt;\nwhat do you think about this? do you think this is a recommendation aimed for home users? or datacenter? my drives will only ever be in a Define R5 (or Define 7 XL in the future), so maybe they&amp;#39;re not packed together as much? they will probably be sleeping most of the time as they&amp;#39;re just for plex. for long term storage (10+ years) would you say the pro drives are necessary?  &lt;/p&gt;\n\n&lt;p&gt;Please share you thoughts &amp;lt;3&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15g1ozl", "is_robot_indexable": true, "report_reasons": null, "author": "MrHakisak", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15g1ozl/up_to_8_drives_your_interpretation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15g1ozl/up_to_8_drives_your_interpretation/", "subreddit_subscribers": 695980, "created_utc": 1690960127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VHS-Decode Demo Media - The Internet Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fv786", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "author_fullname": "t2_413nr2z7", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "vhsdecode", "selftext": "After a very worrying inital state of things regarding [Google Workspaces new 5TB storage limit policy](https://www.reddit.com/r/vhsdecode/comments/14ncciq/community_shared_drive_changes_issues/).\n\n[The VHS-Decode project](https://github.com/oyvindln/vhs-decode/wiki)\n\nIs very happy to make the announcement we are migrating not only 1:1 tape [FM RF](https://github.com/oyvindln/vhs-decode/wiki/RF-Capture-Guide) captures but as time permits many full demo sets (RF+TBC+Video+Audio) and full re-masters of tapes from our community and userbase of including but not limted to lost media.\n\nWith the first upload being my much loved for testing [The Munday Demo Tape](https://archive.org/details/vhs-decode-munday-demo-tape-2022).\n\nThis includes [Itewreed's 5.7TB of German TV Archive Media containing a wealth of Teletext data](https://drive.google.com/open?id=1NvVDPjMbZ06CemD\\_a4kiXhGDnm5OnSpA&amp;usp=drive\\_fs) with its first set being [uploaded here](https://archive.org/details/Itewreed-tape-rf-archive-tapes-150-200).\n\nYou can find our [Offical Internet Archive page here](https://archive.org/details/@decode_team_fm_rf_archives) alongside our somewhat infrequent [Odysse Demo](https://odysee.com/@vhs-decode:7?view=content) postings.\n\nNeverforgeting the wonderful decoded watchable preservation work shown on [The Rewindings Channel](https://odysee.com/@therewinding:4) and [The Video Dump Channel](https://www.youtube.com/@videodumpchannel)", "author_fullname": "t2_413nr2z7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VHS-Decode Demo Media - The Internet Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/vhsdecode", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15edfin", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": "#00a6a5", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "733732ba-9566-11ed-883a-c2b6a81770fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690989216.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1690802556.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.vhsdecode", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After a very worrying inital state of things regarding &lt;a href=\"https://www.reddit.com/r/vhsdecode/comments/14ncciq/community_shared_drive_changes_issues/\"&gt;Google Workspaces new 5TB storage limit policy&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/oyvindln/vhs-decode/wiki\"&gt;The VHS-Decode project&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is very happy to make the announcement we are migrating not only 1:1 tape &lt;a href=\"https://github.com/oyvindln/vhs-decode/wiki/RF-Capture-Guide\"&gt;FM RF&lt;/a&gt; captures but as time permits many full demo sets (RF+TBC+Video+Audio) and full re-masters of tapes from our community and userbase of including but not limted to lost media.&lt;/p&gt;\n\n&lt;p&gt;With the first upload being my much loved for testing &lt;a href=\"https://archive.org/details/vhs-decode-munday-demo-tape-2022\"&gt;The Munday Demo Tape&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;This includes &lt;a href=\"https://drive.google.com/open?id=1NvVDPjMbZ06CemD_a4kiXhGDnm5OnSpA&amp;amp;usp=drive_fs\"&gt;Itewreed&amp;#39;s 5.7TB of German TV Archive Media containing a wealth of Teletext data&lt;/a&gt; with its first set being &lt;a href=\"https://archive.org/details/Itewreed-tape-rf-archive-tapes-150-200\"&gt;uploaded here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;You can find our &lt;a href=\"https://archive.org/details/@decode_team_fm_rf_archives\"&gt;Offical Internet Archive page here&lt;/a&gt; alongside our somewhat infrequent &lt;a href=\"https://odysee.com/@vhs-decode:7?view=content\"&gt;Odysse Demo&lt;/a&gt; postings.&lt;/p&gt;\n\n&lt;p&gt;Neverforgeting the wonderful decoded watchable preservation work shown on &lt;a href=\"https://odysee.com/@therewinding:4\"&gt;The Rewindings Channel&lt;/a&gt; and &lt;a href=\"https://www.youtube.com/@videodumpchannel\"&gt;The Video Dump Channel&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?auto=webp&amp;s=d35c4a57c6675c7b82a9cad26f1ab64489a4a4e9", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=842f6b95b71798678064898014394fdc42774acf", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ef2cabc93c2686b2e861c60d67ffbb9fc23f91a7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=58919fe80d181e500efe2a321eec89b0304258f6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e34144164024896fca79eab754e0c80c350d2fe0", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6822f931c7efd7c2d037f5eab37ea4812ef7cef0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b23b0637677ade8c444ccce9bae8eedd41c564bb", "width": 1080, "height": 540}], "variants": {}, "id": "-STMU2HjCdLhiKyRE-439CghsGUpYVGL7_8BNuH3U_Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "The Documentor ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_5zwnn5", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15edfin", "is_robot_indexable": true, "report_reasons": null, "author": "TheRealHarrypm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/vhsdecode/comments/15edfin/vhsdecode_demo_media_the_internet_archive/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/vhsdecode/comments/15edfin/vhsdecode_demo_media_the_internet_archive/", "subreddit_subscribers": 74, "created_utc": 1690802556.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1690940169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.vhsdecode", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/vhsdecode/comments/15edfin/vhsdecode_demo_media_the_internet_archive/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?auto=webp&amp;s=d35c4a57c6675c7b82a9cad26f1ab64489a4a4e9", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=842f6b95b71798678064898014394fdc42774acf", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ef2cabc93c2686b2e861c60d67ffbb9fc23f91a7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=58919fe80d181e500efe2a321eec89b0304258f6", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e34144164024896fca79eab754e0c80c350d2fe0", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6822f931c7efd7c2d037f5eab37ea4812ef7cef0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/SFK_mjbAqDyAmLPE9RDGuRjbHzzN15W7CuC9a-cb1z8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b23b0637677ade8c444ccce9bae8eedd41c564bb", "width": 1080, "height": 540}], "variants": {}, "id": "-STMU2HjCdLhiKyRE-439CghsGUpYVGL7_8BNuH3U_Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "80TB \ud83c\udfe0 27TB \u2601\ufe0f 50TB \ud83d\udcfc  1TB \ud83d\udcbf", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15fv786", "is_robot_indexable": true, "report_reasons": null, "author": "TheRealHarrypm", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_15edfin", "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15fv786/vhsdecode_demo_media_the_internet_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/vhsdecode/comments/15edfin/vhsdecode_demo_media_the_internet_archive/", "subreddit_subscribers": 695980, "created_utc": 1690940169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all. I am fairly new to the data hoarding game and need some advice. I currently have an M2 MacMini that I am running headless as my media server. I have two 14TB WD easystore drives connected, using the primary drive to store my media and the other drive as a clone. This has worked well for me so far, but I have run out of capacity. I am looking for advice on the best way to expand my setup. I don't think I need a \"real\" NAS like Synology. I was wondering about getting an enclosure and shucking my drives. I also don't know if I need a RAID setup or if I can just use 2 drives for storage and clone them on to the other 2. Any suggestions and advice would be appreciated. Thanks!", "author_fullname": "t2_chaqq7o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice For Expanding My Current 28TB Media Server Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fu876", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690937485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all. I am fairly new to the data hoarding game and need some advice. I currently have an M2 MacMini that I am running headless as my media server. I have two 14TB WD easystore drives connected, using the primary drive to store my media and the other drive as a clone. This has worked well for me so far, but I have run out of capacity. I am looking for advice on the best way to expand my setup. I don&amp;#39;t think I need a &amp;quot;real&amp;quot; NAS like Synology. I was wondering about getting an enclosure and shucking my drives. I also don&amp;#39;t know if I need a RAID setup or if I can just use 2 drives for storage and clone them on to the other 2. Any suggestions and advice would be appreciated. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15fu876", "is_robot_indexable": true, "report_reasons": null, "author": "nativeofnashville", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15fu876/advice_for_expanding_my_current_28tb_media_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15fu876/advice_for_expanding_my_current_28tb_media_server/", "subreddit_subscribers": 695980, "created_utc": 1690937485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I'm still pretty new to network attached storage (using an RPi4 currently) and am looking to upgrade!\n\nMy NAS is used for Plex 4K H.265 video, including transcoding to some older devices I have, and for storing Nvidia recordings at max bitrate (130Mbps).\n\nI can't imagine needing more than 2 drive bays since I'm happy to go for a JBOD setup, and it's very unlikely I'll ever be streaming to or uploading/downloading to/from more than one device at a time.\n\nAre there any alternative NAS enclosures you'd recommend over waiting for the DS224+ to release? Thanks", "author_fullname": "t2_bq2sf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the Synology DS224+ for me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ftds0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690935157.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m still pretty new to network attached storage (using an RPi4 currently) and am looking to upgrade!&lt;/p&gt;\n\n&lt;p&gt;My NAS is used for Plex 4K H.265 video, including transcoding to some older devices I have, and for storing Nvidia recordings at max bitrate (130Mbps).&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t imagine needing more than 2 drive bays since I&amp;#39;m happy to go for a JBOD setup, and it&amp;#39;s very unlikely I&amp;#39;ll ever be streaming to or uploading/downloading to/from more than one device at a time.&lt;/p&gt;\n\n&lt;p&gt;Are there any alternative NAS enclosures you&amp;#39;d recommend over waiting for the DS224+ to release? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ftds0", "is_robot_indexable": true, "report_reasons": null, "author": "Jamdude", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ftds0/is_the_synology_ds224_for_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ftds0/is_the_synology_ds224_for_me/", "subreddit_subscribers": 695980, "created_utc": 1690935157.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been looking at WD elements which are my go-to, I can get 16tb for \u00a3260, but I'm hearing about how using raspberry pi and RAID6 something you can get way way more than that. Sorry for the noob question.", "author_fullname": "t2_cuqhq2ekx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much data storage could I get with \u00a31000?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fpusw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690926334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking at WD elements which are my go-to, I can get 16tb for \u00a3260, but I&amp;#39;m hearing about how using raspberry pi and RAID6 something you can get way way more than that. Sorry for the noob question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15fpusw", "is_robot_indexable": true, "report_reasons": null, "author": "alternatethingacc", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15fpusw/how_much_data_storage_could_i_get_with_1000/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15fpusw/how_much_data_storage_could_i_get_with_1000/", "subreddit_subscribers": 695980, "created_utc": 1690926334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 970 EVO Plus 1tb in a Ugreen enclosure. I heard of the firmware updates so I downloaded Samsung magician and it shows my other drives as up to date but doesn\u2019t say anything about my NVME?\n\nWhat should I do or should I ignore it? Thanks", "author_fullname": "t2_5bcqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Updating 970 EVO Plus Firmware not available?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15gh4au", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691001886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 970 EVO Plus 1tb in a Ugreen enclosure. I heard of the firmware updates so I downloaded Samsung magician and it shows my other drives as up to date but doesn\u2019t say anything about my NVME?&lt;/p&gt;\n\n&lt;p&gt;What should I do or should I ignore it? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gh4au", "is_robot_indexable": true, "report_reasons": null, "author": "hipsterinplaid", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gh4au/updating_970_evo_plus_firmware_not_available/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gh4au/updating_970_evo_plus_firmware_not_available/", "subreddit_subscribers": 695980, "created_utc": 1691001886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm working on a NAS that will scrape a variety of music websites for new content and download the files. Is there any program that can, say, once a day, scan the storage for new files and e-mail me with a list of the new files it finds?\n\nThis is intended to be used for music, and getting an e-mail saying something to the effect of \"these files were downloaded recently\" seems like it would be a very good way of keeping up to date on my favorite artists releasing new music.", "author_fullname": "t2_fc92z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Program that scans for new files and e-mails me details?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gglev", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691000694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a NAS that will scrape a variety of music websites for new content and download the files. Is there any program that can, say, once a day, scan the storage for new files and e-mail me with a list of the new files it finds?&lt;/p&gt;\n\n&lt;p&gt;This is intended to be used for music, and getting an e-mail saying something to the effect of &amp;quot;these files were downloaded recently&amp;quot; seems like it would be a very good way of keeping up to date on my favorite artists releasing new music.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gglev", "is_robot_indexable": true, "report_reasons": null, "author": "dstarr3", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gglev/program_that_scans_for_new_files_and_emails_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gglev/program_that_scans_for_new_files_and_emails_me/", "subreddit_subscribers": 695980, "created_utc": 1691000694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_yu95m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Issue with a new WD Red Plus 8TB CMR drive: Windows 10 can't detect more than 1308GB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 62, "top_awarded_type": null, "hide_score": false, "name": "t3_15ge9zw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/zxhkgcSA-TTMfWEiiRjTHEfKmC1pn9PeSTmgE7LKzvI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1690995508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/n0eoadak9qfb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/n0eoadak9qfb1.png?auto=webp&amp;s=d1cf07fcfa57da6e12655ce3709100ccfa6c0f1c", "width": 510, "height": 229}, "resolutions": [{"url": "https://preview.redd.it/n0eoadak9qfb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7fecdd3d2ebd164b57595945289840be9beca655", "width": 108, "height": 48}, {"url": "https://preview.redd.it/n0eoadak9qfb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b82caea711a3f22717163c754c578ad2f421612", "width": 216, "height": 96}, {"url": "https://preview.redd.it/n0eoadak9qfb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5197959b16caf93ac76f8a01148851b3cd661121", "width": 320, "height": 143}], "variants": {}, "id": "0NfVQm1iaxy79zoGgdH4EEpJQl0_3B3Qq2SGFPlJb8k"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15ge9zw", "is_robot_indexable": true, "report_reasons": null, "author": "SpaceGenesis", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ge9zw/issue_with_a_new_wd_red_plus_8tb_cmr_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/n0eoadak9qfb1.png", "subreddit_subscribers": 695980, "created_utc": 1690995508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone perhaps know how HAMR is expected to affect noise levels?   \n\n\nIt seems past the 14TB mark, all larger drives are noisy as hell. I am wondering if the new HAMR drives might potentially be quieter? Anyone have any educated guesses and/or leaked spec sheets? ", "author_fullname": "t2_95cy1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate HAMR noise/specs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15ge5at", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690995203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone perhaps know how HAMR is expected to affect noise levels?   &lt;/p&gt;\n\n&lt;p&gt;It seems past the 14TB mark, all larger drives are noisy as hell. I am wondering if the new HAMR drives might potentially be quieter? Anyone have any educated guesses and/or leaked spec sheets? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15ge5at", "is_robot_indexable": true, "report_reasons": null, "author": "rankiwi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15ge5at/seagate_hamr_noisespecs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15ge5at/seagate_hamr_noisespecs/", "subreddit_subscribers": 695980, "created_utc": 1690995203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi Datahoarders! It's time to run another giveaway thread. This round, we are giving away a 480GB IronWolf Pro 125 SSD to one lucky winner in this thread.\n\nThe prize is: one 480GB IronWolf Pro 125 SSD\n\nHow to enter: Just reply to this post once with a comment about how the drive would help your datahoarding ways. We ask entrants to please include the terms RunWithIronWolf and Seagate in your comment to be considered for the prize drawing.\n\n\nSelection process/rules\n\nOne entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until Aug 16, 2023 at 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.\n\nGeographic restrictions:\n\nOur policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don\u2019t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions.\n\nUS\n\nCanada (will require a basic skills-based question if winner is chosen by law)\n\nBrazil\n\nSouth America\n\nUnited Kingdom\n\nGermany\n\nFrance\n\nIberia\n\nAustralia\n\nNew Zealand\n\nKorea\n\nIndia\n\nMalaysia\n\nSingapore\n\nChina\n\n\n---\nSeagate Technology | Official Forums Team\n\n---", "author_fullname": "t2_16nn7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Official Giveaway: August 2023 Seagate IronWolf SSD Giveaway!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gcq97", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": "", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "OFFICIAL", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690991995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Datahoarders! It&amp;#39;s time to run another giveaway thread. This round, we are giving away a 480GB IronWolf Pro 125 SSD to one lucky winner in this thread.&lt;/p&gt;\n\n&lt;p&gt;The prize is: one 480GB IronWolf Pro 125 SSD&lt;/p&gt;\n\n&lt;p&gt;How to enter: Just reply to this post once with a comment about how the drive would help your datahoarding ways. We ask entrants to please include the terms RunWithIronWolf and Seagate in your comment to be considered for the prize drawing.&lt;/p&gt;\n\n&lt;p&gt;Selection process/rules&lt;/p&gt;\n\n&lt;p&gt;One entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until Aug 16, 2023 at 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, and not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.&lt;/p&gt;\n\n&lt;p&gt;Geographic restrictions:&lt;/p&gt;\n\n&lt;p&gt;Our policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don\u2019t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions.&lt;/p&gt;\n\n&lt;p&gt;US&lt;/p&gt;\n\n&lt;p&gt;Canada (will require a basic skills-based question if winner is chosen by law)&lt;/p&gt;\n\n&lt;p&gt;Brazil&lt;/p&gt;\n\n&lt;p&gt;South America&lt;/p&gt;\n\n&lt;p&gt;United Kingdom&lt;/p&gt;\n\n&lt;p&gt;Germany&lt;/p&gt;\n\n&lt;p&gt;France&lt;/p&gt;\n\n&lt;p&gt;Iberia&lt;/p&gt;\n\n&lt;p&gt;Australia&lt;/p&gt;\n\n&lt;p&gt;New Zealand&lt;/p&gt;\n\n&lt;p&gt;Korea&lt;/p&gt;\n\n&lt;p&gt;India&lt;/p&gt;\n\n&lt;p&gt;Malaysia&lt;/p&gt;\n\n&lt;p&gt;Singapore&lt;/p&gt;\n\n&lt;p&gt;China&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Seagate Technology | Official Forums Team&lt;/p&gt;\n\n&lt;hr/&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "81f0a58e-b3f5-11ea-95d7-0e4db8ecc231", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "OFFICIAL SEAGATE", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "15gcq97", "is_robot_indexable": true, "report_reasons": null, "author": "Seagate_Surfer", "discussion_type": null, "num_comments": 21, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/15gcq97/official_giveaway_august_2023_seagate_ironwolf/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/15gcq97/official_giveaway_august_2023_seagate_ironwolf/", "subreddit_subscribers": 695980, "created_utc": 1690991995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "While playing with SnapRAID/MergerFS and rtorrent, I came across problems with hash checking. It was noticeably slower compared to using a native (non-FUSE) filesystem such as ZFS. It sometimes even caused rtorrent to crash.\n\nMergerFS documentation explains you need to use special configuration (cache.files=partial) because of rtorrent's use of mmap syscall. Without it, hash checking won't even start. Problem is, the file caching has performance implications and in my case also leads to serious instability.\n\nUnhappy with this situation, I thought about possible workarounds and came up with a library which will modify file IO calls, essentially bypassing mergerfs, so that rtorrent can work directly with the underlying filesystem (then you can use the cache.files=off flag and rtorrent together).\n\nAFAIK, there's initiative to bring similar functionality into linux kernel which would give us the ultimate (and universal) solution. While waiting for future kernels and mergerfs 3.0, you're welcome to try  [nohajc/mergerfs-io-passthrough: A library for direct mergerfs file access. (github.com)](https://github.com/nohajc/mergerfs-io-passthrough).\n\nNote that while this method is not in principle limited to rtorrent, it is the only app I've tested so far.", "author_fullname": "t2_12z91w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MergerFS with rtorrent - performance/stability improvement", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gcd9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690991152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While playing with SnapRAID/MergerFS and rtorrent, I came across problems with hash checking. It was noticeably slower compared to using a native (non-FUSE) filesystem such as ZFS. It sometimes even caused rtorrent to crash.&lt;/p&gt;\n\n&lt;p&gt;MergerFS documentation explains you need to use special configuration (cache.files=partial) because of rtorrent&amp;#39;s use of mmap syscall. Without it, hash checking won&amp;#39;t even start. Problem is, the file caching has performance implications and in my case also leads to serious instability.&lt;/p&gt;\n\n&lt;p&gt;Unhappy with this situation, I thought about possible workarounds and came up with a library which will modify file IO calls, essentially bypassing mergerfs, so that rtorrent can work directly with the underlying filesystem (then you can use the cache.files=off flag and rtorrent together).&lt;/p&gt;\n\n&lt;p&gt;AFAIK, there&amp;#39;s initiative to bring similar functionality into linux kernel which would give us the ultimate (and universal) solution. While waiting for future kernels and mergerfs 3.0, you&amp;#39;re welcome to try  &lt;a href=\"https://github.com/nohajc/mergerfs-io-passthrough\"&gt;nohajc/mergerfs-io-passthrough: A library for direct mergerfs file access. (github.com)&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Note that while this method is not in principle limited to rtorrent, it is the only app I&amp;#39;ve tested so far.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gcd9o", "is_robot_indexable": true, "report_reasons": null, "author": "nohajc", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gcd9o/mergerfs_with_rtorrent_performancestability/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gcd9o/mergerfs_with_rtorrent_performancestability/", "subreddit_subscribers": 695980, "created_utc": 1690991152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "# Need advice on digitizing old photos.\n\n**TLDR:** I want to digitize my old photos with high quality and low cost. Which scanner should I buy?\n\nI need some advice on digitizing my thousands of printed album pictures. I have only Photo prints, and I don't have the negatives or slides. After trying PhotoMyne, I was not happy with the image quality, even though I used a photo tent and a phone stand with my iPhone 14 Pro Max.\n\nI am thinking of buying a scanner to get better results. I did some research and found three models that seem promising: FastFoto FF-680W High-speed Scanning System, Epson Perfection 19 II, and Epson Perfection 39 II. My main concern is image quality, not speed, and I want to spend as little as possible. The prices vary from around $80 to $560.\n\nMy pictures are mostly 15x10 cm, but some are larger or smaller. I like the option to auto-enhance or auto-edit them after scanning.\n\nCan anyone recommend the best scanner for my needs? Or suggest another option that I haven't considered? I would appreciate feedback from other Redditors who have experience with digitizing photos.", "author_fullname": "t2_s099iylx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on digitizing old photos.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15g7jnm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690979033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Need advice on digitizing old photos.&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR:&lt;/strong&gt; I want to digitize my old photos with high quality and low cost. Which scanner should I buy?&lt;/p&gt;\n\n&lt;p&gt;I need some advice on digitizing my thousands of printed album pictures. I have only Photo prints, and I don&amp;#39;t have the negatives or slides. After trying PhotoMyne, I was not happy with the image quality, even though I used a photo tent and a phone stand with my iPhone 14 Pro Max.&lt;/p&gt;\n\n&lt;p&gt;I am thinking of buying a scanner to get better results. I did some research and found three models that seem promising: FastFoto FF-680W High-speed Scanning System, Epson Perfection 19 II, and Epson Perfection 39 II. My main concern is image quality, not speed, and I want to spend as little as possible. The prices vary from around $80 to $560.&lt;/p&gt;\n\n&lt;p&gt;My pictures are mostly 15x10 cm, but some are larger or smaller. I like the option to auto-enhance or auto-edit them after scanning.&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend the best scanner for my needs? Or suggest another option that I haven&amp;#39;t considered? I would appreciate feedback from other Redditors who have experience with digitizing photos.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "15g7jnm", "is_robot_indexable": true, "report_reasons": null, "author": "ArgyleDiamonds", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15g7jnm/need_advice_on_digitizing_old_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15g7jnm/need_advice_on_digitizing_old_photos/", "subreddit_subscribers": 695980, "created_utc": 1690979033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High-precision r/place 2023 timelapse data (min 5s per image) &amp; scraping script", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fymfb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_g6arok6z1", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "u_WildsRanger", "selftext": "**Update:** r/place has been closed and the API of the canvas history viewer is no longer usable. Just head for the data.\n\nIn case r/place online canvas history viewer gets shut down someday and you don't want to download the huge placement data or deal with annoying CSV files, I scraped the timelapse data and saved them in simple JSON files.\n\nThe data are obtained by mocking API requests of the canvas history viewer and analyzing the responses. The canvas at each moment is broken down into up to six 1000x1000 fragments and provided as image URLs in each record. These images are not bundled, so you still need to download them (much easier though; you can just cURL them) and merge the fragments if necessary.\n\n### Links\n\n**30s per record, based on the \"official\" timeline in the canvas history viewer**  \n[timelapse-official-30s.json](https://github.com/WRtux/r-placeDataProc/releases/download/timelapse-v1/timelapse-official-30s.json)\n\n**15s per record, based on the placement dataset timeline**  \n[timelapse-15s.json](https://github.com/WRtux/r-placeDataProc/releases/download/timelapse-v1/timelapse-15s.json)\n\n**5s per record, based on the placement dataset timeline**  \n[timelapse-5s.json](https://github.com/WRtux/r-placeDataProc/releases/download/timelapse-v1/timelapse-5s.json)\n\n* **\"Official\" timeline:** From `2023-07-20T13:04:18Z` to `2023-07-25T21:34:53Z`\n* **Placement dataset timeline:** From `2023-07-20T13:00:00Z` to about `2023-07-25T21:38:36Z`\n\nBesides, I've released the **source code** used to generate these files in [the GitHub repo WRtux/r-placeDataProc](https://github.com/WRtux/r-placeDataProc).\n\n### Possible questions\n\n* *How to open/view the downloaded files?*  \n  I just coded the scraper and collected the timelapse data, no viewers. You may need some programming knowledge to make use of them. Sorry :'(\n* *How long are the image URLs in the JSON files valid for?*  \n  I don't know. These images are delivered by Reddit CDN. It's possible that they will delete images after the event.\n* *Why you use **JavaScript** to do data processing?*  \n  I'm simply not into Python ;)", "author_fullname": "t2_g6arok6z1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloadable high-precision r/place 2023 timelapse data (max 5s per image) &amp; source code", "link_flair_richtext": [], "subreddit_name_prefixed": "u/WildsRanger", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fnjxl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "user", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1690948850.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690921138.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.WildsRanger", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; &lt;a href=\"/r/place\"&gt;r/place&lt;/a&gt; has been closed and the API of the canvas history viewer is no longer usable. Just head for the data.&lt;/p&gt;\n\n&lt;p&gt;In case &lt;a href=\"/r/place\"&gt;r/place&lt;/a&gt; online canvas history viewer gets shut down someday and you don&amp;#39;t want to download the huge placement data or deal with annoying CSV files, I scraped the timelapse data and saved them in simple JSON files.&lt;/p&gt;\n\n&lt;p&gt;The data are obtained by mocking API requests of the canvas history viewer and analyzing the responses. The canvas at each moment is broken down into up to six 1000x1000 fragments and provided as image URLs in each record. These images are not bundled, so you still need to download them (much easier though; you can just cURL them) and merge the fragments if necessary.&lt;/p&gt;\n\n&lt;h3&gt;Links&lt;/h3&gt;\n\n&lt;p&gt;&lt;strong&gt;30s per record, based on the &amp;quot;official&amp;quot; timeline in the canvas history viewer&lt;/strong&gt;&lt;br/&gt;\n&lt;a href=\"https://github.com/WRtux/r-placeDataProc/releases/download/timelapse-v1/timelapse-official-30s.json\"&gt;timelapse-official-30s.json&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;15s per record, based on the placement dataset timeline&lt;/strong&gt;&lt;br/&gt;\n&lt;a href=\"https://github.com/WRtux/r-placeDataProc/releases/download/timelapse-v1/timelapse-15s.json\"&gt;timelapse-15s.json&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;5s per record, based on the placement dataset timeline&lt;/strong&gt;&lt;br/&gt;\n&lt;a href=\"https://github.com/WRtux/r-placeDataProc/releases/download/timelapse-v1/timelapse-5s.json\"&gt;timelapse-5s.json&lt;/a&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&amp;quot;Official&amp;quot; timeline:&lt;/strong&gt; From &lt;code&gt;2023-07-20T13:04:18Z&lt;/code&gt; to &lt;code&gt;2023-07-25T21:34:53Z&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Placement dataset timeline:&lt;/strong&gt; From &lt;code&gt;2023-07-20T13:00:00Z&lt;/code&gt; to about &lt;code&gt;2023-07-25T21:38:36Z&lt;/code&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Besides, I&amp;#39;ve released the &lt;strong&gt;source code&lt;/strong&gt; used to generate these files in &lt;a href=\"https://github.com/WRtux/r-placeDataProc\"&gt;the GitHub repo WRtux/r-placeDataProc&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h3&gt;Possible questions&lt;/h3&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;em&gt;How to open/view the downloaded files?&lt;/em&gt;&lt;br/&gt;\nI just coded the scraper and collected the timelapse data, no viewers. You may need some programming knowledge to make use of them. Sorry :&amp;#39;(&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;How long are the image URLs in the JSON files valid for?&lt;/em&gt;&lt;br/&gt;\nI don&amp;#39;t know. These images are delivered by Reddit CDN. It&amp;#39;s possible that they will delete images after the event.&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Why you use *&lt;/em&gt;JavaScript** to do data processing?*&lt;br/&gt;\nI&amp;#39;m simply not into Python ;)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_8y0pyy", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "15fnjxl", "is_robot_indexable": true, "report_reasons": null, "author": "WildsRanger", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/u_WildsRanger/comments/15fnjxl/downloadable_highprecision_rplace_2023_timelapse/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/u_WildsRanger/comments/15fnjxl/downloadable_highprecision_rplace_2023_timelapse/", "subreddit_subscribers": 0, "created_utc": 1690921138.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1690950113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.WildsRanger", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/u_WildsRanger/comments/15fnjxl/downloadable_highprecision_rplace_2023_timelapse/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15fymfb", "is_robot_indexable": true, "report_reasons": null, "author": "WildsRanger", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_15fnjxl", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15fymfb/highprecision_rplace_2023_timelapse_data_min_5s/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/u_WildsRanger/comments/15fnjxl/downloadable_highprecision_rplace_2023_timelapse/", "subreddit_subscribers": 695980, "created_utc": 1690950113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I upgraded my windows computers internal NVMe and put it in a Ugreen enclosure and I have a SanDisk Extreme Portable SSD. I plan on using one as a Time Machine backup for my mac and the other to be formatted at NTFS (or maybe partition to be able to be used for both OSX and windows).\n\nWhich would be better for long term storage that would potentially last the longest without being plugged in?", "author_fullname": "t2_5bcqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SanDisk Extreme Portable SSD vs 970 EVO Plus in an enclosure for long term storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_15gi5ef", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1691004240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I upgraded my windows computers internal NVMe and put it in a Ugreen enclosure and I have a SanDisk Extreme Portable SSD. I plan on using one as a Time Machine backup for my mac and the other to be formatted at NTFS (or maybe partition to be able to be used for both OSX and windows).&lt;/p&gt;\n\n&lt;p&gt;Which would be better for long term storage that would potentially last the longest without being plugged in?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gi5ef", "is_robot_indexable": true, "report_reasons": null, "author": "hipsterinplaid", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gi5ef/sandisk_extreme_portable_ssd_vs_970_evo_plus_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gi5ef/sandisk_extreme_portable_ssd_vs_970_evo_plus_in/", "subreddit_subscribers": 695980, "created_utc": 1691004240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am getting some data of disks and then gonna burn to dual layer disks\n\nI used to use DVD Fab, crating ISO files in 30 minutes or less\n\n&amp;#x200B;\n\nTrying IMG BURN today because so many like it, well I am at the 2 hours mark, shows 0% complete, what to do?\n\nThe destination folder properties shows 6.96 GB so something is happening but it has been on 6.96 for a while", "author_fullname": "t2_viuwzrr1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IMG Burn taking several hours just to create an ISO file?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15gahsc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690986780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am getting some data of disks and then gonna burn to dual layer disks&lt;/p&gt;\n\n&lt;p&gt;I used to use DVD Fab, crating ISO files in 30 minutes or less&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Trying IMG BURN today because so many like it, well I am at the 2 hours mark, shows 0% complete, what to do?&lt;/p&gt;\n\n&lt;p&gt;The destination folder properties shows 6.96 GB so something is happening but it has been on 6.96 for a while&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15gahsc", "is_robot_indexable": true, "report_reasons": null, "author": "Rotisseriejedi", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15gahsc/img_burn_taking_several_hours_just_to_create_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15gahsc/img_burn_taking_several_hours_just_to_create_an/", "subreddit_subscribers": 695980, "created_utc": 1690986780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm clearing out a storage area for my state gov, and I have hundreds of old disks, diskettes, cds, and more. I'm not sure if this is the right place, but I'm trying to give my lead sound advice. Is any of this worth selling?\n\nThere are a lot of old versions of Adobe, old drives and readers, set ups disks for different programs and more, some with instructions or original packaging.", "author_fullname": "t2_7j9opawj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on old data stockpile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15g88l7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690981008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m clearing out a storage area for my state gov, and I have hundreds of old disks, diskettes, cds, and more. I&amp;#39;m not sure if this is the right place, but I&amp;#39;m trying to give my lead sound advice. Is any of this worth selling?&lt;/p&gt;\n\n&lt;p&gt;There are a lot of old versions of Adobe, old drives and readers, set ups disks for different programs and more, some with instructions or original packaging.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15g88l7", "is_robot_indexable": true, "report_reasons": null, "author": "soulwind42", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15g88l7/advice_on_old_data_stockpile/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15g88l7/advice_on_old_data_stockpile/", "subreddit_subscribers": 695980, "created_utc": 1690981008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm thinking of using AI in order to sort out the many tens of thousands of photos I have. Mostly train it to recognise faces and sort files by subject.\n\n&amp;#x200B;\n\nAnyone already using such technology? Any recommendations on where to start? Anything that works out of the box?", "author_fullname": "t2_2rewrxo6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "*NIX AI to sort out tons of files (mostly photos)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_15fwyhb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1690945172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m thinking of using AI in order to sort out the many tens of thousands of photos I have. Mostly train it to recognise faces and sort files by subject.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyone already using such technology? Any recommendations on where to start? Anything that works out of the box?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "15fwyhb", "is_robot_indexable": true, "report_reasons": null, "author": "iPodClassic7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/15fwyhb/nix_ai_to_sort_out_tons_of_files_mostly_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/15fwyhb/nix_ai_to_sort_out_tons_of_files_mostly_photos/", "subreddit_subscribers": 695980, "created_utc": 1690945172.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}