{"kind": "Listing", "data": {"after": "t3_10xdsvo", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_f4j5rtvj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10y2rrx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 266, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 266, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aos3_0ql6Inql1uKk6l-bhoXEkMgiKK2koakdHFtuMY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675968872.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/l269tf8x39ha1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/l269tf8x39ha1.jpg?auto=webp&amp;v=enabled&amp;s=b497120c6ff27accc7f470fe1b829d37a74dc058", "width": 1080, "height": 2400}, "resolutions": [{"url": "https://preview.redd.it/l269tf8x39ha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a6c8691ff94b26f49c9b9cee199721c120469652", "width": 108, "height": 216}, {"url": "https://preview.redd.it/l269tf8x39ha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d20327ff2dddc499c6e34882c0dc0f219e9f96d6", "width": 216, "height": 432}, {"url": "https://preview.redd.it/l269tf8x39ha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb3ba0d24ba79f343163ca78b2ae7b508bfdf3d7", "width": 320, "height": 640}, {"url": "https://preview.redd.it/l269tf8x39ha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88ca3446d7d42711b854bddc20bade4a4fc03742", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/l269tf8x39ha1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a457e82f312108f69c58f166c32405ae603270a", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/l269tf8x39ha1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c363547829feb14cd29d69c30462c1734ae20c0f", "width": 1080, "height": 2160}], "variants": {}, "id": "CSDSAQ0XQFxKUySp5uP-ayfyIzZi1qurOo2X_RusvK0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10y2rrx", "is_robot_indexable": true, "report_reasons": null, "author": "Gentlecriminal14", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10y2rrx/thoughts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/l269tf8x39ha1.jpg", "subreddit_subscribers": 846232, "created_utc": 1675968872.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m looking for good blog / news sites for learning new topics and staying up on everything data science / machine learning related. Medium seems to be perfect for that but I wanted to know if there was any other suggestions anyone has; Is medium worth the $5 / month $50/ yearly pay wall?", "author_fullname": "t2_k9fo56cm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Medium worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xcnjs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 140, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 140, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675894664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for good blog / news sites for learning new topics and staying up on everything data science / machine learning related. Medium seems to be perfect for that but I wanted to know if there was any other suggestions anyone has; Is medium worth the $5 / month $50/ yearly pay wall?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xcnjs", "is_robot_indexable": true, "report_reasons": null, "author": "DetailedKing", "discussion_type": null, "num_comments": 110, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xcnjs/is_medium_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xcnjs/is_medium_worth_it/", "subreddit_subscribers": 846232, "created_utc": 1675894664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I interviewed at this workplace for a Data Scientist role , I am a junior with no experience besides an intership I did. The market is my country is brutal and Im struggling to find a job for 3 months already.\n\nI did however find a workplace which is mostly low tech hardware type of company but they have a data science &amp; algorithms division. However kn the CEO interview he directly told me they are a conservative workplace - almost everyone are in their 50s and 60s, been there for 20-30 years already, they work on site only and they want someone to stay with them for several years because they do not want to waste time on people \"from my generation\" (in their words) who would leave after a year. Salary is also not high but for a junior I didnt expect much.\n\nIt did stress me a bit because I dont think I will be a fit for their culture. + its a 1 hour drive each direction so it will be hard, and I dont want to waste time and not enjoy there and being not motivated to come to work. However Im financially stressed and I do need the money and its being hell to find jobs for juniors here.\n\nWanted to ask you guys if you think I should go for it and do leave after half a year or a year until the market recovers?", "author_fullname": "t2_rxcyu5rh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I compromise on a conservative workplace?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xuykf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 77, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 77, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675949895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I interviewed at this workplace for a Data Scientist role , I am a junior with no experience besides an intership I did. The market is my country is brutal and Im struggling to find a job for 3 months already.&lt;/p&gt;\n\n&lt;p&gt;I did however find a workplace which is mostly low tech hardware type of company but they have a data science &amp;amp; algorithms division. However kn the CEO interview he directly told me they are a conservative workplace - almost everyone are in their 50s and 60s, been there for 20-30 years already, they work on site only and they want someone to stay with them for several years because they do not want to waste time on people &amp;quot;from my generation&amp;quot; (in their words) who would leave after a year. Salary is also not high but for a junior I didnt expect much.&lt;/p&gt;\n\n&lt;p&gt;It did stress me a bit because I dont think I will be a fit for their culture. + its a 1 hour drive each direction so it will be hard, and I dont want to waste time and not enjoy there and being not motivated to come to work. However Im financially stressed and I do need the money and its being hell to find jobs for juniors here.&lt;/p&gt;\n\n&lt;p&gt;Wanted to ask you guys if you think I should go for it and do leave after half a year or a year until the market recovers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xuykf", "is_robot_indexable": true, "report_reasons": null, "author": "EmotionalLiving9112", "discussion_type": null, "num_comments": 69, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xuykf/should_i_compromise_on_a_conservative_workplace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xuykf/should_i_compromise_on_a_conservative_workplace/", "subreddit_subscribers": 846232, "created_utc": 1675949895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I got a promotion from Senior DS (150 base, 175 TC) to Lead DS (160 base, 185 TC).\n\nI have about 3.5 years experience leading teams, 6.5 years total. I joined this company a little over a year ago as an IC for the pay bump and was asked to lead the team after a couple of months.\n\nThe model I inherited made &lt; $1mm annually, and now it's on track for $2.5 - $3 mm since I took over. All stakeholders are happy, and I'm well liked within DS according to my boss and his boss. 10k feels like a very small difference, not a large enough difference for the promo or the scope of responsibility. Thoughts?", "author_fullname": "t2_ha2yf9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Salary Bump from Senior to Lead DS Feels Small", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xhyye", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675907596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got a promotion from Senior DS (150 base, 175 TC) to Lead DS (160 base, 185 TC).&lt;/p&gt;\n\n&lt;p&gt;I have about 3.5 years experience leading teams, 6.5 years total. I joined this company a little over a year ago as an IC for the pay bump and was asked to lead the team after a couple of months.&lt;/p&gt;\n\n&lt;p&gt;The model I inherited made &amp;lt; $1mm annually, and now it&amp;#39;s on track for $2.5 - $3 mm since I took over. All stakeholders are happy, and I&amp;#39;m well liked within DS according to my boss and his boss. 10k feels like a very small difference, not a large enough difference for the promo or the scope of responsibility. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xhyye", "is_robot_indexable": true, "report_reasons": null, "author": "HungryQuant", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xhyye/salary_bump_from_senior_to_lead_ds_feels_small/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xhyye/salary_bump_from_senior_to_lead_ds_feels_small/", "subreddit_subscribers": 846232, "created_utc": 1675907596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_f4j5rtvj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10y2s9z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/u5smjm1yaUcYcY5KIILmVgId4POvzAvpE2nZ6h8P9hk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675968906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/p8p0xd2149ha1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/p8p0xd2149ha1.jpg?auto=webp&amp;v=enabled&amp;s=ecefe5977dc6cd86c8ac523f322603e5e355dbbe", "width": 1080, "height": 2400}, "resolutions": [{"url": "https://preview.redd.it/p8p0xd2149ha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc0be213ee9b35104e7d4a9cce1087d473e0ae0f", "width": 108, "height": 216}, {"url": "https://preview.redd.it/p8p0xd2149ha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2bcc6be692b6e0629a232a7723fa0f9e3d2add2", "width": 216, "height": 432}, {"url": "https://preview.redd.it/p8p0xd2149ha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccb109ed49eb263b2407ccdf9cfc50665343cdcc", "width": 320, "height": 640}, {"url": "https://preview.redd.it/p8p0xd2149ha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=637d3260f6be4a8a5ec1196ba6c37c9a2772e1a6", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/p8p0xd2149ha1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d80f148cc2f0acf719c82c14890b634058468a8", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/p8p0xd2149ha1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57f2f0e21992615c09daef9157f27bf6355c5a2a", "width": 1080, "height": 2160}], "variants": {}, "id": "E5KR9q4h8y01WVPhoBgy6I-QZrwD4vQ0wJkr7cYbvpo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10y2s9z", "is_robot_indexable": true, "report_reasons": null, "author": "Gentlecriminal14", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10y2s9z/thoughts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/p8p0xd2149ha1.jpg", "subreddit_subscribers": 846232, "created_utc": 1675968906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am solving a regression case for an interview. They gave a dataset with 12 features and 800 observations. I made a regression model in LightGBM and it performed really well in the validation dataset. \n\nThe problem is that it is the only model I made and I would like to try more things to show to my interviewer. Some thoughts:\n\n&amp;#x200B;\n\n1. I thought about making a traditional linear regression to compare LightGBM with but the data they gave does not hold the assumptions of a linear model (i.e. residuals not normally dist.)\n2. I thought about XGBoost but, as far as I know, its performance is similar to LightGBM but LightGBM is faster and uses less memory\n3. Neural networks are not even considered given the size of the dataset\n\nThe instructions of the case say that the company is not so well interested in the prediction itself. They explicit say that the approach used to solve the task is more important than the prediction, especially because the data was randomly generated. In this case should I stress with making more models? \n\nGiven that the instructions talk about the approach, I did an extensively EDA, stated all my findings, why I chose to use LightGBM, etc.", "author_fullname": "t2_r2cqw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview - Which models to compare LightGBM with?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xf4vc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675900407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am solving a regression case for an interview. They gave a dataset with 12 features and 800 observations. I made a regression model in LightGBM and it performed really well in the validation dataset. &lt;/p&gt;\n\n&lt;p&gt;The problem is that it is the only model I made and I would like to try more things to show to my interviewer. Some thoughts:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I thought about making a traditional linear regression to compare LightGBM with but the data they gave does not hold the assumptions of a linear model (i.e. residuals not normally dist.)&lt;/li&gt;\n&lt;li&gt;I thought about XGBoost but, as far as I know, its performance is similar to LightGBM but LightGBM is faster and uses less memory&lt;/li&gt;\n&lt;li&gt;Neural networks are not even considered given the size of the dataset&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The instructions of the case say that the company is not so well interested in the prediction itself. They explicit say that the approach used to solve the task is more important than the prediction, especially because the data was randomly generated. In this case should I stress with making more models? &lt;/p&gt;\n\n&lt;p&gt;Given that the instructions talk about the approach, I did an extensively EDA, stated all my findings, why I chose to use LightGBM, etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xf4vc", "is_robot_indexable": true, "report_reasons": null, "author": "rods2292", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xf4vc/interview_which_models_to_compare_lightgbm_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xf4vc/interview_which_models_to_compare_lightgbm_with/", "subreddit_subscribers": 846232, "created_utc": 1675900407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_5blbvj00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Noob question] Why are notebooks not used in production ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xsy5t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675943736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xsy5t", "is_robot_indexable": true, "report_reasons": null, "author": "SaltySarcasticJohn", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xsy5t/noob_question_why_are_notebooks_not_used_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xsy5t/noob_question_why_are_notebooks_not_used_in/", "subreddit_subscribers": 846232, "created_utc": 1675943736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, we have a large dataset (500 mil rows after aggregations) and our end users want to access it as a table. I thought about maybe connect it to tableau and put parameters to limit what they can show/ pull down to csv at once, but sounded like they are interested to do exploration on the entire dataset since it\u2019s so new. \nFor more color, we have tableau, power BI, and Databricks. \n\nIs there a good way or a tool to deal with this? Appreciate any advice", "author_fullname": "t2_16kgog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Give end users access to big data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xddi6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675896307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, we have a large dataset (500 mil rows after aggregations) and our end users want to access it as a table. I thought about maybe connect it to tableau and put parameters to limit what they can show/ pull down to csv at once, but sounded like they are interested to do exploration on the entire dataset since it\u2019s so new. \nFor more color, we have tableau, power BI, and Databricks. &lt;/p&gt;\n\n&lt;p&gt;Is there a good way or a tool to deal with this? Appreciate any advice&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xddi6", "is_robot_indexable": true, "report_reasons": null, "author": "balpby1989", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xddi6/give_end_users_access_to_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xddi6/give_end_users_access_to_big_data/", "subreddit_subscribers": 846232, "created_utc": 1675896307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applications of Data Science in Education", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10xo76f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_8coqq29x", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9Ty0axV_9v4ea3KoqrsRpk7g3MJ15M1kTzRR5rMooAU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Knowledge_Center", "selftext": "", "author_fullname": "t2_8coqq29x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applications of Data Science in Education", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Knowledge_Center", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10xo5ug", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9Ty0axV_9v4ea3KoqrsRpk7g3MJ15M1kTzRR5rMooAU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1675926027.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/v4p9v82z24ha1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/v4p9v82z24ha1.png?auto=webp&amp;v=enabled&amp;s=ba85e39de898f35074e6cc9e3c607245d2d4a49e", "width": 1080, "height": 1080}, "resolutions": [{"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1eeca757fc0d8a4717abdce2f3c9c98f1f4b8ba5", "width": 108, "height": 108}, {"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=081b3c82943bdd011b6bc03ade4dba1952704b59", "width": 216, "height": 216}, {"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28e6dc29fe3de7394d7ed059b495ce66cef6e836", "width": 320, "height": 320}, {"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8462a9631881438ee0880291046653f5a1f54c91", "width": 640, "height": 640}, {"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b3e75890f6cfac48e55ba0a601e6ba3d71620b7", "width": 960, "height": 960}, {"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33b1ceee9495c8fd7dc7683ad22f69da4a20d8af", "width": 1080, "height": 1080}], "variants": {}, "id": "Y9T5s_o693ZHsgxJQ95k-3WdN5m5fIsJWKtMCgcZd14"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_60fvy2", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xo5ug", "is_robot_indexable": true, "report_reasons": null, "author": "TarunFuleraJi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Knowledge_Center/comments/10xo5ug/applications_of_data_science_in_education/", "parent_whitelist_status": null, "stickied": false, "url": "https://i.redd.it/v4p9v82z24ha1.png", "subreddit_subscribers": 231, "created_utc": 1675926027.0, "num_crossposts": 10, "media": null, "is_video": false}], "created": 1675926146.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/v4p9v82z24ha1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/v4p9v82z24ha1.png?auto=webp&amp;v=enabled&amp;s=ba85e39de898f35074e6cc9e3c607245d2d4a49e", "width": 1080, "height": 1080}, "resolutions": [{"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1eeca757fc0d8a4717abdce2f3c9c98f1f4b8ba5", "width": 108, "height": 108}, {"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=081b3c82943bdd011b6bc03ade4dba1952704b59", "width": 216, "height": 216}, {"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28e6dc29fe3de7394d7ed059b495ce66cef6e836", "width": 320, "height": 320}, {"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8462a9631881438ee0880291046653f5a1f54c91", "width": 640, "height": 640}, {"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b3e75890f6cfac48e55ba0a601e6ba3d71620b7", "width": 960, "height": 960}, {"url": "https://preview.redd.it/v4p9v82z24ha1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33b1ceee9495c8fd7dc7683ad22f69da4a20d8af", "width": 1080, "height": 1080}], "variants": {}, "id": "Y9T5s_o693ZHsgxJQ95k-3WdN5m5fIsJWKtMCgcZd14"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xo76f", "is_robot_indexable": true, "report_reasons": null, "author": "TarunFuleraJi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_10xo5ug", "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xo76f/applications_of_data_science_in_education/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/v4p9v82z24ha1.png", "subreddit_subscribers": 846232, "created_utc": 1675926146.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all\n\nI'm sampling around 2% of the dataset to build a classification model using XGBOOST.\n\nI notice that when I re-run the whole pipeline I get quiet different results, something that could be explained by the sampling process. That's an issue when I compare to different models and the differences are small (i.e., not sure if they due to chance or not).\n\nHow do you normally deal with that? Is there a way to build a 95% CI around the PR curve?", "author_fullname": "t2_5hjxl4ya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with randomness (e.g., sampling) when evaluating models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xnwpe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675925144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sampling around 2% of the dataset to build a classification model using XGBOOST.&lt;/p&gt;\n\n&lt;p&gt;I notice that when I re-run the whole pipeline I get quiet different results, something that could be explained by the sampling process. That&amp;#39;s an issue when I compare to different models and the differences are small (i.e., not sure if they due to chance or not).&lt;/p&gt;\n\n&lt;p&gt;How do you normally deal with that? Is there a way to build a 95% CI around the PR curve?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xnwpe", "is_robot_indexable": true, "report_reasons": null, "author": "PlainPiano9", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xnwpe/how_to_deal_with_randomness_eg_sampling_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xnwpe/how_to_deal_with_randomness_eg_sampling_when/", "subreddit_subscribers": 846232, "created_utc": 1675925144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi. \nI try to find a job as data scientist (EU)\nI want to do some projects divide by categories.\nQuestions:\n1) where would I put the projects, and then link them in the CV?(right now they are from a GitHub site done with Hugo)\n2) how many projects and what kind should I do?\n3) how to present them?(tableau, Jupiter notebook, power bi, Google slides, other)", "author_fullname": "t2_ulsp2wdh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "some question about portfolio projects.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10y754n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675979538.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675978993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. \nI try to find a job as data scientist (EU)\nI want to do some projects divide by categories.\nQuestions:\n1) where would I put the projects, and then link them in the CV?(right now they are from a GitHub site done with Hugo)\n2) how many projects and what kind should I do?\n3) how to present them?(tableau, Jupiter notebook, power bi, Google slides, other)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10y754n", "is_robot_indexable": true, "report_reasons": null, "author": "Aristocle-", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10y754n/some_question_about_portfolio_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10y754n/some_question_about_portfolio_projects/", "subreddit_subscribers": 846232, "created_utc": 1675978993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I 22m recently finished my bachelor's last year and have decided to apply for a masters in Data Science abroad which will take some time to prepare, which brings me to my dilemma. Some backstory: During the pandemic (apologies if I brought unpleasant memories) I started my self taught journey in data science, which involved watching a lot of tutorials, reading articles which somewhat gave me the jist of what algorithms and fundamentals (statistics, python,sql) are in the line of work. I watched some courses on statistics to try actually understand some concept like probability and especially harmonic mean lol, learnt SQL but never got to know how I'd use SQL to actually get data from a database anf use it for modeling. 2 years later, I honestly don't even know what am doing anymore, I wake up, log in to kaggle, find an interesting dataset, formulate a problem that might need solving (no matter how ridiculous it is) and do some analysis or build a model, and by the end of the day I contemplate whether what am doing is enough to actually land a job in the coming years. Don't get me wrong but I actually am very interested in the field.\n\nWith a all the blogs and multiple YouTubers around providing information on what data science is all about I end up questioning the very name of the field, what the actual **** is data science? Feels like I have been doing nothing in the past few years (jus 2 lol) I have made some models with which I am proud of especially a food recommendation system that I ended up presenting as my finals project..in addition, I read a lot of threads in the sub of what employers are looking for during interviews and realize that there's so so much I still don't fully understand....\n\nApologies for the rant, but today is jus one of those days that I question my efforts in the field..\nId really like to get some advice on how to continue on..", "author_fullname": "t2_65clz0c0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A bit of guidance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xuwwh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675949749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I 22m recently finished my bachelor&amp;#39;s last year and have decided to apply for a masters in Data Science abroad which will take some time to prepare, which brings me to my dilemma. Some backstory: During the pandemic (apologies if I brought unpleasant memories) I started my self taught journey in data science, which involved watching a lot of tutorials, reading articles which somewhat gave me the jist of what algorithms and fundamentals (statistics, python,sql) are in the line of work. I watched some courses on statistics to try actually understand some concept like probability and especially harmonic mean lol, learnt SQL but never got to know how I&amp;#39;d use SQL to actually get data from a database anf use it for modeling. 2 years later, I honestly don&amp;#39;t even know what am doing anymore, I wake up, log in to kaggle, find an interesting dataset, formulate a problem that might need solving (no matter how ridiculous it is) and do some analysis or build a model, and by the end of the day I contemplate whether what am doing is enough to actually land a job in the coming years. Don&amp;#39;t get me wrong but I actually am very interested in the field.&lt;/p&gt;\n\n&lt;p&gt;With a all the blogs and multiple YouTubers around providing information on what data science is all about I end up questioning the very name of the field, what the actual **** is data science? Feels like I have been doing nothing in the past few years (jus 2 lol) I have made some models with which I am proud of especially a food recommendation system that I ended up presenting as my finals project..in addition, I read a lot of threads in the sub of what employers are looking for during interviews and realize that there&amp;#39;s so so much I still don&amp;#39;t fully understand....&lt;/p&gt;\n\n&lt;p&gt;Apologies for the rant, but today is jus one of those days that I question my efforts in the field..\nId really like to get some advice on how to continue on..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xuwwh", "is_robot_indexable": true, "report_reasons": null, "author": "CryVisible8424", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xuwwh/a_bit_of_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xuwwh/a_bit_of_guidance/", "subreddit_subscribers": 846232, "created_utc": 1675949749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Where can I download free datasets to use for practice? All the ones I\u2019ve found are only possible through payment // is power bi &amp; excel good enough to make someone a data analyst?", "author_fullname": "t2_e6u3rbzd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xrfi9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675938240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where can I download free datasets to use for practice? All the ones I\u2019ve found are only possible through payment // is power bi &amp;amp; excel good enough to make someone a data analyst?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xrfi9", "is_robot_indexable": true, "report_reasons": null, "author": "dammy_redd", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xrfi9/datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xrfi9/datasets/", "subreddit_subscribers": 846232, "created_utc": 1675938240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi! I am new to ML and was wondering which encoding I should use.\n\n&amp;#x200B;\n\nFirst, my mission:  \nPredict flight coefficient based on historical data.\n\nMy data:\n\nInt: year, month, day, week\\_day (of the flight)\n\nstring: classname (like UberX or Uber\\_Select), departure\\_country, departure\\_city, departure\\_airport, arrival\\_airport, arrival\\_city, arrival\\_country\n\n&amp;#x200B;\n\ntarget - coefficient: float\n\n&amp;#x200B;\n\nSo **a lot** of categorical data.\n\nI attempted pandas get\\_dummy and OneHotEncoding, which create those really large sparse matrixes. I read an article suggesting TargetEncoding, but that would make it harder for my model to find inter-relationships among this data (and I am sure there are)\n\n&amp;#x200B;\n\nSo if anyone can help me out choosing the right method, I would appreciate it greatly!\n\nI work with python, just in case", "author_fullname": "t2_fmamadvj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is the best way to encode my data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xphdz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675930824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I am new to ML and was wondering which encoding I should use.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;First, my mission:&lt;br/&gt;\nPredict flight coefficient based on historical data.&lt;/p&gt;\n\n&lt;p&gt;My data:&lt;/p&gt;\n\n&lt;p&gt;Int: year, month, day, week_day (of the flight)&lt;/p&gt;\n\n&lt;p&gt;string: classname (like UberX or Uber_Select), departure_country, departure_city, departure_airport, arrival_airport, arrival_city, arrival_country&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;target - coefficient: float&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So &lt;strong&gt;a lot&lt;/strong&gt; of categorical data.&lt;/p&gt;\n\n&lt;p&gt;I attempted pandas get_dummy and OneHotEncoding, which create those really large sparse matrixes. I read an article suggesting TargetEncoding, but that would make it harder for my model to find inter-relationships among this data (and I am sure there are)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So if anyone can help me out choosing the right method, I would appreciate it greatly!&lt;/p&gt;\n\n&lt;p&gt;I work with python, just in case&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xphdz", "is_robot_indexable": true, "report_reasons": null, "author": "FoxSinofSloth", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xphdz/which_is_the_best_way_to_encode_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xphdz/which_is_the_best_way_to_encode_my_data/", "subreddit_subscribers": 846232, "created_utc": 1675930824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm so nervous, I've never been interviewed by a company for a data science internship (specifically for undergrads, so I don't have to go up against masters or phd students lol). I've only ever interviewed for labs at my university, non profits, or high school interviews. I have a lot of anxiety around this and have no idea about what kind of questions they'll ask me. Any tips, tricks, heads ups for an anxious third year in undergrad? TIA !! :)", "author_fullname": "t2_7wz5utln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First data science college internship interview!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xkamg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675913895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m so nervous, I&amp;#39;ve never been interviewed by a company for a data science internship (specifically for undergrads, so I don&amp;#39;t have to go up against masters or phd students lol). I&amp;#39;ve only ever interviewed for labs at my university, non profits, or high school interviews. I have a lot of anxiety around this and have no idea about what kind of questions they&amp;#39;ll ask me. Any tips, tricks, heads ups for an anxious third year in undergrad? TIA !! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xkamg", "is_robot_indexable": true, "report_reasons": null, "author": "WittySide", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xkamg/first_data_science_college_internship_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xkamg/first_data_science_college_internship_interview/", "subreddit_subscribers": 846232, "created_utc": 1675913895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/w3txiyn398ha1.png?width=354&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=56540245a1226c843fb84ffbba89443d512d87ee", "author_fullname": "t2_743yyd5u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have valentine meme/puns related to data or tech? I'm looking for a funny or creative one!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"w3txiyn398ha1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 122, "x": 108, "u": "https://preview.redd.it/w3txiyn398ha1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ad7f18f5e2bba2046e69c649ea3730fda64965b"}, {"y": 244, "x": 216, "u": "https://preview.redd.it/w3txiyn398ha1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4fe239efc8a97d730e168fa7c06cdbd48991fbe"}, {"y": 362, "x": 320, "u": "https://preview.redd.it/w3txiyn398ha1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91900bee316cdf77a33482e06d39004bf693c411"}], "s": {"y": 401, "x": 354, "u": "https://preview.redd.it/w3txiyn398ha1.png?width=354&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=56540245a1226c843fb84ffbba89443d512d87ee"}, "id": "w3txiyn398ha1"}}, "name": "t3_10y63f7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/x5Up_4Y_s2ACYqzEJJkqbyjgVo8sUrFt9rXRkfYVIfs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675976514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/w3txiyn398ha1.png?width=354&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=56540245a1226c843fb84ffbba89443d512d87ee\"&gt;https://preview.redd.it/w3txiyn398ha1.png?width=354&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=56540245a1226c843fb84ffbba89443d512d87ee&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10y63f7", "is_robot_indexable": true, "report_reasons": null, "author": "gyeah7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10y63f7/anyone_have_valentine_memepuns_related_to_data_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10y63f7/anyone_have_valentine_memepuns_related_to_data_or/", "subreddit_subscribers": 846232, "created_utc": 1675976514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " The question is this. \"I need to know the statistical data types of my values, in order to decide what methods I will use on this data for machine learning. How can I do it en masse within a dataset with 100.000 columns?\"\n\nthe .dtypes give me computer data value (int64 etc.) but I want statistical type (interval, ratio, discrete, nominal etc.) also, if I'm using numerical data for ordinal things or 1 and 0 as boolean, that shouldn't get stuck in my function.\n\nI had a heated arguement with ChatGPT and it's final suggestion is:\n\n    \n    import pandas as pd  \n    \n    # Load the data into a pandas dataframe\n    df = pd.read_csv('your_data.csv')  \n    \n    # Get summary statistics for each column \n    summary_stats = df.describe()  \n    \n    # Identify columns that contain ratio or interval numerical data \n    numerical_columns = [col for col in df.columns if df[col].dtype in [float, int] and                      (df[col].min() &gt; 0 or df[col].max()/df[col].min() &gt; 1 if df[col].min() != 0 else False)]  \n    \n    # Identify columns that contain nominal or ordinal categorical data \n    categorical_columns = [col for col in df.columns if df[col].nunique() &lt; df.shape[0]*0.05]  \n    \n    # Convert the data type of the categorical columns for col in categorical_columns:     df[col] = df[col].astype('category')  \n    \n    # Validate the change of data type \n    for col in categorical_columns:     \n        assert df[col].dtype == 'category', f\"{col} is not a categorical type\" \n    for col in numerical_columns:     \n        assert df[col].dtype in [float, int], f\"{col} is not a numerical type\"\n    \n    --------------------------------------------------------------------------\n    AssertionError                            Traceback (most recent call last)\n    ~\\AppData\\Local\\Temp\\ipykernel_26568\\177826119.py in &lt;module&gt;\n         24 \n         25 for col in numerical_columns:\n    ---&gt; 26     assert df[col].dtype in [float, int], f\"{col} is not a numerical type\"\n    \n    AssertionError: floors is not a numerical type\n\nRealistically, \"floors\" is a controversial value. Some say it's continous because there can be 1.5 floors, I'd say it's discrete numerical value.\n\nHow do I get out of this? I can't manually check 100.000 columns", "author_fullname": "t2_m826ekr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I check the statistical datatypes of all columns en masse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10y60km", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675976346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The question is this. &amp;quot;I need to know the statistical data types of my values, in order to decide what methods I will use on this data for machine learning. How can I do it en masse within a dataset with 100.000 columns?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;the .dtypes give me computer data value (int64 etc.) but I want statistical type (interval, ratio, discrete, nominal etc.) also, if I&amp;#39;m using numerical data for ordinal things or 1 and 0 as boolean, that shouldn&amp;#39;t get stuck in my function.&lt;/p&gt;\n\n&lt;p&gt;I had a heated arguement with ChatGPT and it&amp;#39;s final suggestion is:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pandas as pd  \n\n# Load the data into a pandas dataframe\ndf = pd.read_csv(&amp;#39;your_data.csv&amp;#39;)  \n\n# Get summary statistics for each column \nsummary_stats = df.describe()  \n\n# Identify columns that contain ratio or interval numerical data \nnumerical_columns = [col for col in df.columns if df[col].dtype in [float, int] and                      (df[col].min() &amp;gt; 0 or df[col].max()/df[col].min() &amp;gt; 1 if df[col].min() != 0 else False)]  \n\n# Identify columns that contain nominal or ordinal categorical data \ncategorical_columns = [col for col in df.columns if df[col].nunique() &amp;lt; df.shape[0]*0.05]  \n\n# Convert the data type of the categorical columns for col in categorical_columns:     df[col] = df[col].astype(&amp;#39;category&amp;#39;)  \n\n# Validate the change of data type \nfor col in categorical_columns:     \n    assert df[col].dtype == &amp;#39;category&amp;#39;, f&amp;quot;{col} is not a categorical type&amp;quot; \nfor col in numerical_columns:     \n    assert df[col].dtype in [float, int], f&amp;quot;{col} is not a numerical type&amp;quot;\n\n--------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel_26568\\177826119.py in &amp;lt;module&amp;gt;\n     24 \n     25 for col in numerical_columns:\n---&amp;gt; 26     assert df[col].dtype in [float, int], f&amp;quot;{col} is not a numerical type&amp;quot;\n\nAssertionError: floors is not a numerical type\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Realistically, &amp;quot;floors&amp;quot; is a controversial value. Some say it&amp;#39;s continous because there can be 1.5 floors, I&amp;#39;d say it&amp;#39;s discrete numerical value.&lt;/p&gt;\n\n&lt;p&gt;How do I get out of this? I can&amp;#39;t manually check 100.000 columns&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10y60km", "is_robot_indexable": true, "report_reasons": null, "author": "Utterizi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10y60km/how_can_i_check_the_statistical_datatypes_of_all/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10y60km/how_can_i_check_the_statistical_datatypes_of_all/", "subreddit_subscribers": 846232, "created_utc": 1675976346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Curious to see what others have experienced in terms of their interview process. It feels like data science interviews are much like streamlined compared to regular software engineer gigs.", "author_fullname": "t2_mhvcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What did the interview for your current role consist of? Were you given LeetCode style questions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10y4uu1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675973567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious to see what others have experienced in terms of their interview process. It feels like data science interviews are much like streamlined compared to regular software engineer gigs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10y4uu1", "is_robot_indexable": true, "report_reasons": null, "author": "RawCS", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10y4uu1/what_did_the_interview_for_your_current_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10y4uu1/what_did_the_interview_for_your_current_role/", "subreddit_subscribers": 846232, "created_utc": 1675973567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Consider a problem where the target variable can take on 10 possible values but only 6 of them are shown in your training data. It\u2019s likely that the other 4 values show up in the test set but you cannot see the labels. What algorithms are you confident would be able to achieve relatively meaningful results?", "author_fullname": "t2_524iawau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Classification Techniques for Extrapolation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10y40ad", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675971615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Consider a problem where the target variable can take on 10 possible values but only 6 of them are shown in your training data. It\u2019s likely that the other 4 values show up in the test set but you cannot see the labels. What algorithms are you confident would be able to achieve relatively meaningful results?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10y40ad", "is_robot_indexable": true, "report_reasons": null, "author": "bassabyss", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10y40ad/classification_techniques_for_extrapolation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10y40ad/classification_techniques_for_extrapolation/", "subreddit_subscribers": 846232, "created_utc": 1675971615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, I'm currently a high school senior who is going on a pre med track into my undergrad. However, I also have a strong interest in data science, especially bioinformatics, for computational biology research. I have a lot of time now that my college applications are over and want to learn as much as I can in data science. Pasted below is my current plan on what I want to do. I'm trying my best to finish them all by September, but it is very likely to bleed into my first year at uni.\n\n1. Fundamentals of Computing Specialization\n\n[https://www.coursera.org/specializations/computer-fundamentals](https://www.coursera.org/specializations/computer-fundamentals)\n\n&amp;#x200B;\n\n2. Introduction to Mathematical Thinking\n\n[https://www.coursecra.org/learn/mathematical-thinking](https://www.coursera.org/learn/mathematical-thinking)\n\n&amp;#x200B;\n\n3. Discreet Math\n\nOption 1: UCSD Specialization\n\n[https://www.coursera.org/specializations/discrete-mathematics](https://www.coursera.org/specializations/discrete-mathematics)\n\nOption 2: Rosen textbook\n\nOption 3: MIT course\n\n[https://openlearninglibrary.mit.edu/courses/course-v1:OCW+6.042J+2T2019/about](https://openlearninglibrary.mit.edu/courses/course-v1:OCW+6.042J+2T2019/about)\n\n&amp;#x200B;\n\n4. Algorithms Specialization\n\n[https://www.coursera.org/specializations/algorithms](https://www.coursera.org/specializations/algorithms)\n\n&amp;#x200B;\n\n5. Data Structures and Algorithms Specialization\n\n[https://www.coursera.org/specializations/data-structures-algorithms](https://www.coursera.org/specializations/data-structures-algorithms)\n\n&amp;#x200B;\n\n6. Bioinformatics Specialization\n\n[https://www.coursera.org/specializations/bioinformatics](https://www.coursera.org/specializations/bioinformatics)\n\n&amp;#x200B;\n\n7. Single Variable Calculus XSeries\n\n[https://www.edx.org/xseries/mitx-18.01x-single-variable-calculus](https://www.edx.org/xseries/mitx-18.01x-single-variable-calculus)\n\n&amp;#x200B;\n\n8. Mathematics for Engineers\n\n[https://www.coursera.org/specializations/mathematics-engineers](https://www.coursera.org/specializations/mathematics-engineers)\n\n&amp;#x200B;\n\n9. Mathematics for Machine Learning Specialization (First 2 courses)\n\n[https://www.coursera.org/specializations/mathematics-machine-learning](https://www.coursera.org/specializations/mathematics-machine-learning)\n\n&amp;#x200B;\n\n10. Data Science MicroMasters (First 2 courses)\n\n[https://www.edx.org/micromasters/uc-san-diegox-data-science](https://www.edx.org/micromasters/uc-san-diegox-data-science)\n\n&amp;#x200B;\n\nAfter I finish all of these, I intend on diving into ML with the goal of eventually utilizing it for research. I know that this is a lot, but I would really appreciate any feedback on my current plan and if there's any changes that could be made or any other resource I should use.", "author_fullname": "t2_861iepnn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Path for a High Schooler", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10y3rak", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675971475.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675971049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m currently a high school senior who is going on a pre med track into my undergrad. However, I also have a strong interest in data science, especially bioinformatics, for computational biology research. I have a lot of time now that my college applications are over and want to learn as much as I can in data science. Pasted below is my current plan on what I want to do. I&amp;#39;m trying my best to finish them all by September, but it is very likely to bleed into my first year at uni.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Fundamentals of Computing Specialization&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.coursera.org/specializations/computer-fundamentals\"&gt;https://www.coursera.org/specializations/computer-fundamentals&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Introduction to Mathematical Thinking&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.coursera.org/learn/mathematical-thinking\"&gt;https://www.coursecra.org/learn/mathematical-thinking&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Discreet Math&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Option 1: UCSD Specialization&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.coursera.org/specializations/discrete-mathematics\"&gt;https://www.coursera.org/specializations/discrete-mathematics&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Option 2: Rosen textbook&lt;/p&gt;\n\n&lt;p&gt;Option 3: MIT course&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://openlearninglibrary.mit.edu/courses/course-v1:OCW+6.042J+2T2019/about\"&gt;https://openlearninglibrary.mit.edu/courses/course-v1:OCW+6.042J+2T2019/about&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Algorithms Specialization&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.coursera.org/specializations/algorithms\"&gt;https://www.coursera.org/specializations/algorithms&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Structures and Algorithms Specialization&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.coursera.org/specializations/data-structures-algorithms\"&gt;https://www.coursera.org/specializations/data-structures-algorithms&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Bioinformatics Specialization&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.coursera.org/specializations/bioinformatics\"&gt;https://www.coursera.org/specializations/bioinformatics&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Single Variable Calculus XSeries&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.edx.org/xseries/mitx-18.01x-single-variable-calculus\"&gt;https://www.edx.org/xseries/mitx-18.01x-single-variable-calculus&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Mathematics for Engineers&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.coursera.org/specializations/mathematics-engineers\"&gt;https://www.coursera.org/specializations/mathematics-engineers&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Mathematics for Machine Learning Specialization (First 2 courses)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.coursera.org/specializations/mathematics-machine-learning\"&gt;https://www.coursera.org/specializations/mathematics-machine-learning&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Science MicroMasters (First 2 courses)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.edx.org/micromasters/uc-san-diegox-data-science\"&gt;https://www.edx.org/micromasters/uc-san-diegox-data-science&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;After I finish all of these, I intend on diving into ML with the goal of eventually utilizing it for research. I know that this is a lot, but I would really appreciate any feedback on my current plan and if there&amp;#39;s any changes that could be made or any other resource I should use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ridk7rC1D4ltm1CDpEeCLyGie6kptA5IpzyTuFnkaNQ.jpg?auto=webp&amp;v=enabled&amp;s=2e92aa268702ba4189151bf300fe0b318c2eebe8", "width": 1772, "height": 928}, "resolutions": [{"url": "https://external-preview.redd.it/ridk7rC1D4ltm1CDpEeCLyGie6kptA5IpzyTuFnkaNQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45f11a88551596064141bcb4cf6d415234ca8b00", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ridk7rC1D4ltm1CDpEeCLyGie6kptA5IpzyTuFnkaNQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9b0028cc3cd616e7d5de09515fe6b035a8d91ea", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ridk7rC1D4ltm1CDpEeCLyGie6kptA5IpzyTuFnkaNQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08dca310771827ea8f84f5eeaf9888a815f89ff3", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/ridk7rC1D4ltm1CDpEeCLyGie6kptA5IpzyTuFnkaNQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00b40b4fdff01f4a1c9f0009723921ff30cba90e", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/ridk7rC1D4ltm1CDpEeCLyGie6kptA5IpzyTuFnkaNQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b90bc3c6d82fefa41b1d3f1cb12f67aa8c75a6c", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/ridk7rC1D4ltm1CDpEeCLyGie6kptA5IpzyTuFnkaNQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29ddfce5413da28af07124301ff6f36f94d9ba1f", "width": 1080, "height": 565}], "variants": {}, "id": "0ssEcV96f2Z7P11gVH0IJ5n7Yd1cfqx4fM8Oh_11L10"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10y3rak", "is_robot_indexable": true, "report_reasons": null, "author": "SnooAdvice5820", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10y3rak/learning_path_for_a_high_schooler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10y3rak/learning_path_for_a_high_schooler/", "subreddit_subscribers": 846232, "created_utc": 1675971049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI'm going to have an interview with an intern tomorrow. He is studying business informatics. It's my first job interview on the other side as an interviewer. I want to make the interview as fair as possible. So no super nasty or hard questions. What are good questions in relation to business intelligence, databases, statistics and data science?\n\nThese are some questions I have written down:  \n\\-What is the difference between sql and nosql? What advantages does a nosql database offer? Are there any disadvantages?  \n\\-Why do you do so-called normalizations in connection with databases?  \n\\-Which libraries have you already worked with in python?  \n\\-In connection with statistics, the p-value can often be read. what does the p-value say and what is it used for?", "author_fullname": "t2_jl102v3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview questions for an intern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xvdw3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675951087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m going to have an interview with an intern tomorrow. He is studying business informatics. It&amp;#39;s my first job interview on the other side as an interviewer. I want to make the interview as fair as possible. So no super nasty or hard questions. What are good questions in relation to business intelligence, databases, statistics and data science?&lt;/p&gt;\n\n&lt;p&gt;These are some questions I have written down:&lt;br/&gt;\n-What is the difference between sql and nosql? What advantages does a nosql database offer? Are there any disadvantages?&lt;br/&gt;\n-Why do you do so-called normalizations in connection with databases?&lt;br/&gt;\n-Which libraries have you already worked with in python?&lt;br/&gt;\n-In connection with statistics, the p-value can often be read. what does the p-value say and what is it used for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xvdw3", "is_robot_indexable": true, "report_reasons": null, "author": "Fluid-Improvement-84", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xvdw3/interview_questions_for_an_intern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xvdw3/interview_questions_for_an_intern/", "subreddit_subscribers": 846232, "created_utc": 1675951087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a personally-scraped and curated dataset that I'd like to open source. Primarily, I was thinking somewhere down the line I'd write a tutorial on my [blog](https://www.ddanieltan.com/) and I'd like to point readers to a link to get the same data I'm working with.\n\n**Q: What's the best and most sane way to do this?**\n\nLeft to my own devices, I'd probably just upload the data to a Github repository. Any updates to the data can be git tracked.\n\nBut, I'm also aware that there are dedicated platforms to catalog and share data (e.g. [https://www.dolthub.com/](https://www.dolthub.com/), [https://data.world/](https://data.world/)), and that uploading data on Github, in general, doesn't seem best practise.", "author_fullname": "t2_3i0xn3gy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to open source a my dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xijpg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675909106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a personally-scraped and curated dataset that I&amp;#39;d like to open source. Primarily, I was thinking somewhere down the line I&amp;#39;d write a tutorial on my &lt;a href=\"https://www.ddanieltan.com/\"&gt;blog&lt;/a&gt; and I&amp;#39;d like to point readers to a link to get the same data I&amp;#39;m working with.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Q: What&amp;#39;s the best and most sane way to do this?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Left to my own devices, I&amp;#39;d probably just upload the data to a Github repository. Any updates to the data can be git tracked.&lt;/p&gt;\n\n&lt;p&gt;But, I&amp;#39;m also aware that there are dedicated platforms to catalog and share data (e.g. &lt;a href=\"https://www.dolthub.com/\"&gt;https://www.dolthub.com/&lt;/a&gt;, &lt;a href=\"https://data.world/\"&gt;https://data.world/&lt;/a&gt;), and that uploading data on Github, in general, doesn&amp;#39;t seem best practise.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xijpg", "is_robot_indexable": true, "report_reasons": null, "author": "ddanieltan", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xijpg/best_way_to_open_source_a_my_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xijpg/best_way_to_open_source_a_my_dataset/", "subreddit_subscribers": 846232, "created_utc": 1675909106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I'm trying to revert scipy to version 1.5.4, but I can't find it on Anaconda, through any of the channels on my machine, and even when I go to the Anaconda website and search scipy, I can't find any that the version I am looking to install. I know this is an older version (my current version is 1.10.0 which I think is the most up to date), but can anyone help me figure out how to revert back to this earlier version? All the stackoverflows and github error pages I'm finding have solutions that haven't worked for me.\n\nFor reference, in Anaconda prompt, I am using\n\n`conda install -c conda-forge scipy=1.5.4`\n\nand also\n\n`conda install scipy=1.5.4`\n\nwhich both return\n\n    PackagesNotFoundError: The following packages are not available from current channels:   \n    - https://conda.anaconda.org/conda-forge/win-64   \n    - https://conda.anaconda.org/conda-forge/noarch   \n    - https://repo.anaconda.com/pkgs/main/win-64   \n    - https://repo.anaconda.com/pkgs/main/noarch   \n    - https://repo.anaconda.com/pkgs/r/win-64   \n    - https://repo.anaconda.com/pkgs/r/noarch   \n    - https://repo.anaconda.com/pkgs/msys2/win-64   \n    - https://repo.anaconda.com/pkgs/msys2/noarch", "author_fullname": "t2_31lmg3kf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Issue trying to revert a Python package: can't find desired version in Anaconda?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xi9od", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675908364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to revert scipy to version 1.5.4, but I can&amp;#39;t find it on Anaconda, through any of the channels on my machine, and even when I go to the Anaconda website and search scipy, I can&amp;#39;t find any that the version I am looking to install. I know this is an older version (my current version is 1.10.0 which I think is the most up to date), but can anyone help me figure out how to revert back to this earlier version? All the stackoverflows and github error pages I&amp;#39;m finding have solutions that haven&amp;#39;t worked for me.&lt;/p&gt;\n\n&lt;p&gt;For reference, in Anaconda prompt, I am using&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;conda install -c conda-forge scipy=1.5.4&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;and also&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;conda install scipy=1.5.4&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;which both return&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;PackagesNotFoundError: The following packages are not available from current channels:   \n- https://conda.anaconda.org/conda-forge/win-64   \n- https://conda.anaconda.org/conda-forge/noarch   \n- https://repo.anaconda.com/pkgs/main/win-64   \n- https://repo.anaconda.com/pkgs/main/noarch   \n- https://repo.anaconda.com/pkgs/r/win-64   \n- https://repo.anaconda.com/pkgs/r/noarch   \n- https://repo.anaconda.com/pkgs/msys2/win-64   \n- https://repo.anaconda.com/pkgs/msys2/noarch\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xi9od", "is_robot_indexable": true, "report_reasons": null, "author": "Amun-Aion", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xi9od/issue_trying_to_revert_a_python_package_cant_find/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xi9od/issue_trying_to_revert_a_python_package_cant_find/", "subreddit_subscribers": 846232, "created_utc": 1675908364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all. \n\nSome context: My background is in engineering (not data science). I work at a manufacturing plant as a process engineer. Although my background is not in data, a bulk of the work I do in my current role involves analyzing large datasets to identify defect trends and rectify quality issues. I learned python, JMP on the job and use these for data visualization and statistical analysis.\n\nThe problem: my process involves making (cutting) multiple parts out of a single ingot. The parts are cut simultaneously. A single ingot can yield up to 7 parts. The process takes about 5 hrs. The machine records data of key machine parameters (inputs) every 5 seconds. So, each cut (production run) produces about 3600 rows of data from ~10 different parameters.\n\nAt the end of a cut, each part is inspected on a CMM for surface features. When I plot the readings of the surface features of each part from each cut on a time series graph, I notice that the surface feature readings tend to drift with time (variation between cuts). I want to know what is causing the drift. \n\nWhat I need help with: I want to know if there is a correlation between a certain machine parameter and the surface readings. I have 3600 data points from my input and 7 data points from my output compared over n number of production runs. This is a lot of data to deal with and it is very difficult to draw any conclusions from such a comparison. Is there a way to simplify the analysis? I guess what I am asking is what type of analysis would make sense in this situation?", "author_fullname": "t2_lz5kb89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A work problem involving data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xhn6x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675906930.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675906747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all. &lt;/p&gt;\n\n&lt;p&gt;Some context: My background is in engineering (not data science). I work at a manufacturing plant as a process engineer. Although my background is not in data, a bulk of the work I do in my current role involves analyzing large datasets to identify defect trends and rectify quality issues. I learned python, JMP on the job and use these for data visualization and statistical analysis.&lt;/p&gt;\n\n&lt;p&gt;The problem: my process involves making (cutting) multiple parts out of a single ingot. The parts are cut simultaneously. A single ingot can yield up to 7 parts. The process takes about 5 hrs. The machine records data of key machine parameters (inputs) every 5 seconds. So, each cut (production run) produces about 3600 rows of data from ~10 different parameters.&lt;/p&gt;\n\n&lt;p&gt;At the end of a cut, each part is inspected on a CMM for surface features. When I plot the readings of the surface features of each part from each cut on a time series graph, I notice that the surface feature readings tend to drift with time (variation between cuts). I want to know what is causing the drift. &lt;/p&gt;\n\n&lt;p&gt;What I need help with: I want to know if there is a correlation between a certain machine parameter and the surface readings. I have 3600 data points from my input and 7 data points from my output compared over n number of production runs. This is a lot of data to deal with and it is very difficult to draw any conclusions from such a comparison. Is there a way to simplify the analysis? I guess what I am asking is what type of analysis would make sense in this situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xhn6x", "is_robot_indexable": true, "report_reasons": null, "author": "halfman1231", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xhn6x/a_work_problem_involving_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xhn6x/a_work_problem_involving_data/", "subreddit_subscribers": 846232, "created_utc": 1675906747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I (24M) got a medical degree but decided that this field is not for me and I've did some amount of research to say that i wanted to get started in the data field as an analyst. I wanted to know what route to take, I basically self taught myself medicine and wondered if i should just follow a roadmap or should i go to formal schooling and get a certificate. If there's any other route as well, please let me know or any thoughts that you guys might have. I really just want to get started on the journey.", "author_fullname": "t2_aq7jspmg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting started as data analyst eventually working towards Data scientist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xdsvo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675897263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I (24M) got a medical degree but decided that this field is not for me and I&amp;#39;ve did some amount of research to say that i wanted to get started in the data field as an analyst. I wanted to know what route to take, I basically self taught myself medicine and wondered if i should just follow a roadmap or should i go to formal schooling and get a certificate. If there&amp;#39;s any other route as well, please let me know or any thoughts that you guys might have. I really just want to get started on the journey.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10xdsvo", "is_robot_indexable": true, "report_reasons": null, "author": "LeeAckermann", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10xdsvo/getting_started_as_data_analyst_eventually/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10xdsvo/getting_started_as_data_analyst_eventually/", "subreddit_subscribers": 846232, "created_utc": 1675897263.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}