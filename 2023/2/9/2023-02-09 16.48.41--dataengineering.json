{"kind": "Listing", "data": {"after": "t3_10xw9f0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering who has the best data orchestration tool at the moment?\n\nI am currently using prefect on a virtual machine to handle all of my flows that primarily execute dbt. I have also looked into dagster and mage, but prefect seems to be the most comprehensive? Are there any other orchestration tools that have a valid integration with dbt that are more useful?", "author_fullname": "t2_3h5wixaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Orchestration Tool to run dbt projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x4n7n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675875782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering who has the best data orchestration tool at the moment?&lt;/p&gt;\n\n&lt;p&gt;I am currently using prefect on a virtual machine to handle all of my flows that primarily execute dbt. I have also looked into dagster and mage, but prefect seems to be the most comprehensive? Are there any other orchestration tools that have a valid integration with dbt that are more useful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10x4n7n", "is_robot_indexable": true, "report_reasons": null, "author": "J0hnDutt00n", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x4n7n/best_orchestration_tool_to_run_dbt_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x4n7n/best_orchestration_tool_to_run_dbt_projects/", "subreddit_subscribers": 88987, "created_utc": 1675875782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Airflow DAGs on Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10x7ixs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xj-OOmT7UPCIw2j_Lx_3S8AHW76__BIAQrEKjDXV9zg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675882755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/dagster-airflow-migration", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?auto=webp&amp;v=enabled&amp;s=c77b3d2e139b81d19d91fb093a86fe06147f0df0", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45e3a502f6f0c45e678d1e3a816b67206bdd859a", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5aba134ef347285f14a6c5d66c07d140a3cf23e3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=532ff18bf5f7f538f7d0ca18f882c7c899b321d6", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8e963ae3df8798a882ecf920c3aa3f3b63ddc03", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=549d4c7458892fb76b4988dcccb5061b27094060", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0137b5793ef5b51c305bfb024e7e5991eff28cf", "width": 1080, "height": 567}], "variants": {}, "id": "qrMeQRAkw-xrrf9moY8jwZFpUX5vOWb6xdHFQo2DDJg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10x7ixs", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x7ixs/running_airflow_dags_on_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/dagster-airflow-migration", "subreddit_subscribers": 88987, "created_utc": 1675882755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a **technical** interview coming up with a big chocolate manufacturer for an Azure data engineer role, and I'm wondering if the traditional advice of practicing leetcode questions still applies. I'm really good at solving SQL problems, but my Python algos are sort of lacking.\n\nShould I just focus on preparing for questions on things like data modeling, data warehouses, migrations, transformations, storage options, pipelines, etc? Or should I mostly focus on grinding easy/mid leetcode python questions?\n\nAppreciate any advice, I'm kind of stressing over what to study...", "author_fullname": "t2_115k4e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do data engineer interviews look like at non-technical companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xn42u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675922725.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675922506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a &lt;strong&gt;technical&lt;/strong&gt; interview coming up with a big chocolate manufacturer for an Azure data engineer role, and I&amp;#39;m wondering if the traditional advice of practicing leetcode questions still applies. I&amp;#39;m really good at solving SQL problems, but my Python algos are sort of lacking.&lt;/p&gt;\n\n&lt;p&gt;Should I just focus on preparing for questions on things like data modeling, data warehouses, migrations, transformations, storage options, pipelines, etc? Or should I mostly focus on grinding easy/mid leetcode python questions?&lt;/p&gt;\n\n&lt;p&gt;Appreciate any advice, I&amp;#39;m kind of stressing over what to study...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer @ Startup", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10xn42u", "is_robot_indexable": true, "report_reasons": null, "author": "-5677-", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10xn42u/how_do_data_engineer_interviews_look_like_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xn42u/how_do_data_engineer_interviews_look_like_at/", "subreddit_subscribers": 88987, "created_utc": 1675922506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nRecently I saw someone post asking about a mentor. I'm looking for the same, or at the very least someone who can help validate or improve my plan for the next \\~6 months.\n\nA bit of context: I'm a lead Data Scientist at a startup. When I joined, I was an intern and we were 3 people. I grew quickly into the role and became the lead, managing a team of 6 in a company of 35 people.\n\nWhile my title is Lead Data Scientist, we do a lot of data cleaning &amp; data validation, build ETL pipelines...our tool stack consists predominantly of python, django, pandas, airflow, GCP. We do statistical analysis but no machine learning, very little predictive algorightms...\n\nI actually feel more like an Analytics Engineer/borderline Data Engineer depsite my title. However, I still have a lot to learn. For example, we use pandas far more than SQL (so I have basic sql querying experience but can improve), and I've never used Spark or Hadoop...\n\nI've loved the company and helping it grow, but we're based in Paris, France, and believe it or not I miss a lot about America (I'm originally from California). So a while ago I discussed with our CTO and have let them know that I'll no longer work for them starting April 2022, so I can focus on moving my family to the states.\n\nI'd like to transition into a role as a full-fledged Data Engineer, as I think it's very interesting and has the best future. I plan on moving to the states by January 2024 at the latest.\n\nSo essentially from April - December 2023 I'm saved enough to be able to focus on personal projects and developing data engineering skills in addition to networking and applying to places later in the year.\n\nIf someone could mentor me, I would love to chat! If not, here's my plan for these months:\n\n* Do the entire DataEngineeringClup Zoomcamp 2023 (despite not being able to start with the rest of the students this past January)\n* Reading: Fundamentals of Data Engineering- Housley and Reis, Designing Data Intensive Applications - Kleppmann, Data Warehouse Toolkit - Kimball\n* Maybe giving Data Engineering with Python a go?\n\n&amp;#x200B;\n\nThis is a huge personal project that'll change my life as well as my family's. I wanna set us up as nicely as possible, so I'm taking a shot in the dark here and asking for any help I can get! **If you read to here, thank you**\n\n&amp;#x200B;\n\n*Edit: Adding* Data Pipelines Pocket Reference *as a resource I'll be reading in case others wanna try the same approach!*", "author_fullname": "t2_gcq3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a mentor or someone to help validate my plan to transition into Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x4ir5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675934458.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675875514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;Recently I saw someone post asking about a mentor. I&amp;#39;m looking for the same, or at the very least someone who can help validate or improve my plan for the next ~6 months.&lt;/p&gt;\n\n&lt;p&gt;A bit of context: I&amp;#39;m a lead Data Scientist at a startup. When I joined, I was an intern and we were 3 people. I grew quickly into the role and became the lead, managing a team of 6 in a company of 35 people.&lt;/p&gt;\n\n&lt;p&gt;While my title is Lead Data Scientist, we do a lot of data cleaning &amp;amp; data validation, build ETL pipelines...our tool stack consists predominantly of python, django, pandas, airflow, GCP. We do statistical analysis but no machine learning, very little predictive algorightms...&lt;/p&gt;\n\n&lt;p&gt;I actually feel more like an Analytics Engineer/borderline Data Engineer depsite my title. However, I still have a lot to learn. For example, we use pandas far more than SQL (so I have basic sql querying experience but can improve), and I&amp;#39;ve never used Spark or Hadoop...&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve loved the company and helping it grow, but we&amp;#39;re based in Paris, France, and believe it or not I miss a lot about America (I&amp;#39;m originally from California). So a while ago I discussed with our CTO and have let them know that I&amp;#39;ll no longer work for them starting April 2022, so I can focus on moving my family to the states.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to transition into a role as a full-fledged Data Engineer, as I think it&amp;#39;s very interesting and has the best future. I plan on moving to the states by January 2024 at the latest.&lt;/p&gt;\n\n&lt;p&gt;So essentially from April - December 2023 I&amp;#39;m saved enough to be able to focus on personal projects and developing data engineering skills in addition to networking and applying to places later in the year.&lt;/p&gt;\n\n&lt;p&gt;If someone could mentor me, I would love to chat! If not, here&amp;#39;s my plan for these months:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Do the entire DataEngineeringClup Zoomcamp 2023 (despite not being able to start with the rest of the students this past January)&lt;/li&gt;\n&lt;li&gt;Reading: Fundamentals of Data Engineering- Housley and Reis, Designing Data Intensive Applications - Kleppmann, Data Warehouse Toolkit - Kimball&lt;/li&gt;\n&lt;li&gt;Maybe giving Data Engineering with Python a go?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is a huge personal project that&amp;#39;ll change my life as well as my family&amp;#39;s. I wanna set us up as nicely as possible, so I&amp;#39;m taking a shot in the dark here and asking for any help I can get! &lt;strong&gt;If you read to here, thank you&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Edit: Adding&lt;/em&gt; Data Pipelines Pocket Reference &lt;em&gt;as a resource I&amp;#39;ll be reading in case others wanna try the same approach!&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10x4ir5", "is_robot_indexable": true, "report_reasons": null, "author": "johnsonfrusciante", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x4ir5/looking_for_a_mentor_or_someone_to_help_validate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x4ir5/looking_for_a_mentor_or_someone_to_help_validate/", "subreddit_subscribers": 88987, "created_utc": 1675875514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " **Context:**  \nI'm the only data scientist/analyst/guy at my company. I mainly do some query and data manipulation using R or Python, present results and my company finds me absolutely amazing and indispensable.\n\n**Present:**  \nMy company acquired shares of another company which doesn't have any data guys whatsoever, and offered them me to do some data work for them, to help them get started.\n\n**The work to be done:**  \nThis company is more of a group of companies which is has data from many sources (data from insurance, banking, health care, etc.). They want to create a data warehouse using these numerous databases, and start using their data. Some databases are cloud, other on prem, will have to use API for another, etc. It will be very small data, like 5000 clients. A girl at that company pull all the data manually and put it in excel for example but still..\n\n**The problem:**  \nI have no idea how to do a data warehouse and keep it updated. I told this to my superiors but they're not worried and said \"meh anything is fine, it's very small data, don't worry. Anything you do will be a great help already\". I know if I just pull data, put it in an excel, do this daily automatically, it will be fine. But there's also talks of having the data warehouse \"live\", as in, with all the data replicated live. And they want to build a \"customer hub\" on top of it, something that a user can access and input data if needed  \nThere's a guy at my company who will setup a SQL Server locally, but after that it will be all me.\n\n**My question:**  \nCan someone point me to some resources to help me with the situation? I was *absolutely freaking out* in the meeting this was decided. I was brought to this meeting without knowing what they were going to say and then they tell them \"sure this guy will do it for you\". I have no idea how to tackle this.", "author_fullname": "t2_3msnawl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Urgent Help Needed] Create data warehouse - disfunctional company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x4qav", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675875984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt;&lt;br/&gt;\nI&amp;#39;m the only data scientist/analyst/guy at my company. I mainly do some query and data manipulation using R or Python, present results and my company finds me absolutely amazing and indispensable.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Present:&lt;/strong&gt;&lt;br/&gt;\nMy company acquired shares of another company which doesn&amp;#39;t have any data guys whatsoever, and offered them me to do some data work for them, to help them get started.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The work to be done:&lt;/strong&gt;&lt;br/&gt;\nThis company is more of a group of companies which is has data from many sources (data from insurance, banking, health care, etc.). They want to create a data warehouse using these numerous databases, and start using their data. Some databases are cloud, other on prem, will have to use API for another, etc. It will be very small data, like 5000 clients. A girl at that company pull all the data manually and put it in excel for example but still..&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The problem:&lt;/strong&gt;&lt;br/&gt;\nI have no idea how to do a data warehouse and keep it updated. I told this to my superiors but they&amp;#39;re not worried and said &amp;quot;meh anything is fine, it&amp;#39;s very small data, don&amp;#39;t worry. Anything you do will be a great help already&amp;quot;. I know if I just pull data, put it in an excel, do this daily automatically, it will be fine. But there&amp;#39;s also talks of having the data warehouse &amp;quot;live&amp;quot;, as in, with all the data replicated live. And they want to build a &amp;quot;customer hub&amp;quot; on top of it, something that a user can access and input data if needed&lt;br/&gt;\nThere&amp;#39;s a guy at my company who will setup a SQL Server locally, but after that it will be all me.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My question:&lt;/strong&gt;&lt;br/&gt;\nCan someone point me to some resources to help me with the situation? I was &lt;em&gt;absolutely freaking out&lt;/em&gt; in the meeting this was decided. I was brought to this meeting without knowing what they were going to say and then they tell them &amp;quot;sure this guy will do it for you&amp;quot;. I have no idea how to tackle this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10x4qav", "is_robot_indexable": true, "report_reasons": null, "author": "Prettywaffleman", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x4qav/urgent_help_needed_create_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x4qav/urgent_help_needed_create_data_warehouse/", "subreddit_subscribers": 88987, "created_utc": 1675875984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rethinking Stream Processing and Streaming Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_10x5uwh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JTZl3_bfA5KMAGrk_C5fQcEFrOewP0X7RCml78nbIWw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675878668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "risingwave-labs.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.risingwave-labs.com/blog/Rethinking_stream_processing_and_streaming_databases/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?auto=webp&amp;v=enabled&amp;s=5840241cc2d9a277f350dbf7130265842eb394b4", "width": 1365, "height": 767}, "resolutions": [{"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1d26575d826dc84ec92247cbbfcc2c2fb2a855a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1353be1e737d336024d2e5f47264f8827d85215", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=990050d6d47fab5e5fa82f0fab5dc98a55d2fa27", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2f233e718a694a52ce5f56ff81057dc200b65df", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96ad0358d7447cd21305d06736139f5e0315cc2b", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2aa49201f3cb9ba460e2c4ba6ae51b4e0ba2f5b", "width": 1080, "height": 606}], "variants": {}, "id": "QqxYaazblEVaBxyQJDXb4w-J1BYZ2l_cfoLGuvtUy3c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10x5uwh", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x5uwh/rethinking_stream_processing_and_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.risingwave-labs.com/blog/Rethinking_stream_processing_and_streaming_databases/", "subreddit_subscribers": 88987, "created_utc": 1675878668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got a technical screen coming up about Python and SQL and while I do have experience in both, I was hoping to read or watch (Udemy) resources regarding best practices. For instance, I imagine I'll have to answer questions similar to \"Walk me through how you'd remove duplicates in a dataset\" for SQL or \"Tell me how you'd de-dupe a list\" for Python which - while I have done both before - I'm unsure if the way I go about this aligns with best practice.\n\nFor SQL, I read through some posts and saw the following resources recommended:\n\n* T-SQL Fundamentals by Itzik Ben-Gan\n* T-SQL Querying by Itzik Ben-Gan\n* Learning SQL by O'Reilly publisher\n\nHowever, I'm unsure if those books only talk about the basics (e.g., \"Here's how to query filtered data\") or if they go into advanced topics regarding best practices and whatnot. Does anyone have insight here?\n\nAs for Python, I wouldn't even know where to start looking for such.\n\nAny insight or feedback would be greatly appreciate as I've largely gone through my data engineering career without much mentorship.\n\n*Additional context: they specifically said it's not \"Leetcode-like\".*", "author_fullname": "t2_hwg7lsz6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for SQL and Python Best Practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x4i50", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675875474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a technical screen coming up about Python and SQL and while I do have experience in both, I was hoping to read or watch (Udemy) resources regarding best practices. For instance, I imagine I&amp;#39;ll have to answer questions similar to &amp;quot;Walk me through how you&amp;#39;d remove duplicates in a dataset&amp;quot; for SQL or &amp;quot;Tell me how you&amp;#39;d de-dupe a list&amp;quot; for Python which - while I have done both before - I&amp;#39;m unsure if the way I go about this aligns with best practice.&lt;/p&gt;\n\n&lt;p&gt;For SQL, I read through some posts and saw the following resources recommended:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;T-SQL Fundamentals by Itzik Ben-Gan&lt;/li&gt;\n&lt;li&gt;T-SQL Querying by Itzik Ben-Gan&lt;/li&gt;\n&lt;li&gt;Learning SQL by O&amp;#39;Reilly publisher&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;However, I&amp;#39;m unsure if those books only talk about the basics (e.g., &amp;quot;Here&amp;#39;s how to query filtered data&amp;quot;) or if they go into advanced topics regarding best practices and whatnot. Does anyone have insight here?&lt;/p&gt;\n\n&lt;p&gt;As for Python, I wouldn&amp;#39;t even know where to start looking for such.&lt;/p&gt;\n\n&lt;p&gt;Any insight or feedback would be greatly appreciate as I&amp;#39;ve largely gone through my data engineering career without much mentorship.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Additional context: they specifically said it&amp;#39;s not &amp;quot;Leetcode-like&amp;quot;.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10x4i50", "is_robot_indexable": true, "report_reasons": null, "author": "spicy_pierogi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10x4i50/resources_for_sql_and_python_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x4i50/resources_for_sql_and_python_best_practices/", "subreddit_subscribers": 88987, "created_utc": 1675875474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New here, what would be the best one to learn and why? \n\nPrefect or Airflow?\n\nI seen Zoomcamp changed their tool from Airflow to Prefect for the 2023 cohort and I was just wondering what would be the tool of choice in 2023 for you guys.", "author_fullname": "t2_j68xrjb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Orchestration tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x9uq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675888218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New here, what would be the best one to learn and why? &lt;/p&gt;\n\n&lt;p&gt;Prefect or Airflow?&lt;/p&gt;\n\n&lt;p&gt;I seen Zoomcamp changed their tool from Airflow to Prefect for the 2023 cohort and I was just wondering what would be the tool of choice in 2023 for you guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10x9uq0", "is_robot_indexable": true, "report_reasons": null, "author": "Yimmy_90", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x9uq0/orchestration_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x9uq0/orchestration_tools/", "subreddit_subscribers": 88987, "created_utc": 1675888218.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you switched to any Airflow alternative? I would love to hear the reasons.\n\n[View Poll](https://www.reddit.com/poll/10x8qj1)", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you switched to any Airflow alternative? Please comment why yes/no", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x8qj1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675885633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you switched to any Airflow alternative? I would love to hear the reasons.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10x8qj1\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10x8qj1", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1676231233706, "options": [{"text": "Dagster", "id": "21501894"}, {"text": "Prefect", "id": "21501895"}, {"text": "Mage", "id": "21501896"}, {"text": "Other (please comment what)", "id": "21501897"}, {"text": "Still Airflow", "id": "21501898"}, {"text": "Show me the results", "id": "21501899"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 324, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x8qj1/have_you_switched_to_any_airflow_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10x8qj1/have_you_switched_to_any_airflow_alternative/", "subreddit_subscribers": 88987, "created_utc": 1675885633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, y\u2019all \n\n\nI landed a technical interview for an MLE position at Toyota. \n\nWould yall happen to know what should I expect? I haven\u2019t found any resources online. It is a 30min online interview. \n\n\nThanks!", "author_fullname": "t2_3zbbn8s2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Toyota Machine Learning Engineer Technical interview; what to expect?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xiwu8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675910073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, y\u2019all &lt;/p&gt;\n\n&lt;p&gt;I landed a technical interview for an MLE position at Toyota. &lt;/p&gt;\n\n&lt;p&gt;Would yall happen to know what should I expect? I haven\u2019t found any resources online. It is a 30min online interview. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10xiwu8", "is_robot_indexable": true, "report_reasons": null, "author": "RaunchyAppleSauce", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xiwu8/toyota_machine_learning_engineer_technical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xiwu8/toyota_machine_learning_engineer_technical/", "subreddit_subscribers": 88987, "created_utc": 1675910073.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nAfter evaluating needs of our team, we are looking to implement Delta on EMR for incremental data processing. I am wondering if anyone can share their experiences dealing with OSS Delta on EMR.\n\nHad decent success with PoC but looking to understand any issues to be known at scale. Be it operational, scale etc.", "author_fullname": "t2_j1zb3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Success with Delta on AWS EMR", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xhiau", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675906387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;After evaluating needs of our team, we are looking to implement Delta on EMR for incremental data processing. I am wondering if anyone can share their experiences dealing with OSS Delta on EMR.&lt;/p&gt;\n\n&lt;p&gt;Had decent success with PoC but looking to understand any issues to be known at scale. Be it operational, scale etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10xhiau", "is_robot_indexable": true, "report_reasons": null, "author": "abhi5025", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xhiau/success_with_delta_on_aws_emr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xhiau/success_with_delta_on_aws_emr/", "subreddit_subscribers": 88987, "created_utc": 1675906387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI need to build an Azure data infrastructure, which ingests data from different on-prem source systems (but mainly from relational databases and from text files), loads the data to some sort of data lake (it could be something else too, like delta lake, all that matters is to have a platform from which various departments can access the data for various reasons), makes it possible to do transformations on this data (we are possibly talking about big amounts), then load the data to some kind of SQL Database / DWH System. This final platform needs to be something that provides seamless integration with cloud Dynamics 365 and Power BI.\n\nMy question for you is what kind of architecture would you use in this situation?\n\nSo far, I have explored the following options:\n\n- Data Factory / Azure Synapse Pipelines for copying data from on-prem to the data lake, and copying data from data lake to SQL Database. Also a possible option for starting scheduled Databricks jobs\n- Azure Data Lake Gen 2 as a data lake -&gt; this would be where raw, ingested data is stored (mainly text files, parquet files)\n- Azure Databricks  -&gt; For doing transformations on the ingested data. I have also explored the possibility of using Azure Delta Lake options. I am not sure what I the best practice in this situation. Is it worth to maintain a Data Lake AND a Delta Lake?\n- Azure Synapse Serverless / Dedicated SQL Pool OR SQL database / managed instance -&gt; this would be the platform which is the backend of the Dynamics 365 system. I'm really not sure if I should use Synapse for this whole process. It might be overkill for my needs.\n\nI understand this is probably a bit chaotic, Azure architecture is new to me. I'd appreciate any advice, any tips on best practices which help me decide between my options. \n\nTL;DR: Need to set up an Azure infrastructure for integrating data from on-prem DB and text files, storing raw data available for multiple use cases, enabling scheduled transformations, and providing some sort of SQL DB which can easily be integrated with Dynamics 365.", "author_fullname": "t2_vun99h9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for bringing data to Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xvxpw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675952523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I need to build an Azure data infrastructure, which ingests data from different on-prem source systems (but mainly from relational databases and from text files), loads the data to some sort of data lake (it could be something else too, like delta lake, all that matters is to have a platform from which various departments can access the data for various reasons), makes it possible to do transformations on this data (we are possibly talking about big amounts), then load the data to some kind of SQL Database / DWH System. This final platform needs to be something that provides seamless integration with cloud Dynamics 365 and Power BI.&lt;/p&gt;\n\n&lt;p&gt;My question for you is what kind of architecture would you use in this situation?&lt;/p&gt;\n\n&lt;p&gt;So far, I have explored the following options:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data Factory / Azure Synapse Pipelines for copying data from on-prem to the data lake, and copying data from data lake to SQL Database. Also a possible option for starting scheduled Databricks jobs&lt;/li&gt;\n&lt;li&gt;Azure Data Lake Gen 2 as a data lake -&amp;gt; this would be where raw, ingested data is stored (mainly text files, parquet files)&lt;/li&gt;\n&lt;li&gt;Azure Databricks  -&amp;gt; For doing transformations on the ingested data. I have also explored the possibility of using Azure Delta Lake options. I am not sure what I the best practice in this situation. Is it worth to maintain a Data Lake AND a Delta Lake?&lt;/li&gt;\n&lt;li&gt;Azure Synapse Serverless / Dedicated SQL Pool OR SQL database / managed instance -&amp;gt; this would be the platform which is the backend of the Dynamics 365 system. I&amp;#39;m really not sure if I should use Synapse for this whole process. It might be overkill for my needs.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I understand this is probably a bit chaotic, Azure architecture is new to me. I&amp;#39;d appreciate any advice, any tips on best practices which help me decide between my options. &lt;/p&gt;\n\n&lt;p&gt;TL;DR: Need to set up an Azure infrastructure for integrating data from on-prem DB and text files, storing raw data available for multiple use cases, enabling scheduled transformations, and providing some sort of SQL DB which can easily be integrated with Dynamics 365.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10xvxpw", "is_robot_indexable": true, "report_reasons": null, "author": "justadataengineer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xvxpw/best_practices_for_bringing_data_to_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xvxpw/best_practices_for_bringing_data_to_azure/", "subreddit_subscribers": 88987, "created_utc": 1675952523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I became a data engineer, most of the data engineers were coming from BI/ETL, usually after having spent a few years doing BI.\n\nHow do people get to engineering now? I saw many get to it via data science for a couple of years before they specialised\n\n[View Poll](https://www.reddit.com/poll/10xus1c)", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New data engineers (0-3y in the job): How did you get into data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xus1c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675949395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I became a data engineer, most of the data engineers were coming from BI/ETL, usually after having spent a few years doing BI.&lt;/p&gt;\n\n&lt;p&gt;How do people get to engineering now? I saw many get to it via data science for a couple of years before they specialised&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10xus1c\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10xus1c", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1676208595272, "options": [{"text": "I started as a data scientist and later moved to DE", "id": "21513133"}, {"text": "I started as a software developer and later moved to DE", "id": "21513134"}, {"text": "I started as a BI/DWH/business analyst and moved to DE", "id": "21513135"}, {"text": "I started my career directly as DE", "id": "21513136"}, {"text": "I have more than 3y experience, so I am out of scope of the question.", "id": "21513137"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 284, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xus1c/new_data_engineers_03y_in_the_job_how_did_you_get/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10xus1c/new_data_engineers_03y_in_the_job_how_did_you_get/", "subreddit_subscribers": 88987, "created_utc": 1675949395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering,\n\nI am a data science professional, currently unemployed and looking for work.  A contact told me about a potential project her company might need, and I wanted to get your input on how much work the project might take.  They need to migrate text data from 400 PDFs into a database for use by some software system.  It really does not seem that complicated, but I wanted to gauge how much work this might take to set a reasonable price and give them a realistic estimation for how long it will take to complete.\n\nAppreciate your thoughts!", "author_fullname": "t2_aewcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Consulting Project Viability - Migrate Text from 400 PDFs Into Database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xhwqp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675907432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I am a data science professional, currently unemployed and looking for work.  A contact told me about a potential project her company might need, and I wanted to get your input on how much work the project might take.  They need to migrate text data from 400 PDFs into a database for use by some software system.  It really does not seem that complicated, but I wanted to gauge how much work this might take to set a reasonable price and give them a realistic estimation for how long it will take to complete.&lt;/p&gt;\n\n&lt;p&gt;Appreciate your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10xhwqp", "is_robot_indexable": true, "report_reasons": null, "author": "i_am_baldilocks", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xhwqp/consulting_project_viability_migrate_text_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xhwqp/consulting_project_viability_migrate_text_from/", "subreddit_subscribers": 88987, "created_utc": 1675907432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Current situation: \n\n* large government contact for an agency, best job security in the country without giving away more info\n* Salary $88,500 with a 7% match to 401K, 3 weeks vacation that accrues fast, 4 weeks paternity leave, frequent raises (pay went up 14% in the past 2 years I've been here), and a 9/80 schedule. COMPLETE WFH\n* Using outdated tools (Talend, Denodo, and newer qlik replicate), we will never use the cloud, and bringing in newer technologies is a fucking nightmare that takes months if not years. \n* They are currently offering a retention program. if you sign a 2 year agreeement to stay you will receive a 15K bonus immediately (pay back if you leave of course) 10k after taxes\n* Very good work-life balance and flexibility. I never feel stressed about work and have a well managed work load with an awesome manager and a good team.\n\nFuture opportunity: \n\n* Data engineer at a large freight company that does several things in the industry. \n* Pay would be 105-125k with an annual bonus ( not sure how much) , 4% 401k match I believe, this might be wrong. Fully paid medical benefits (not sure how good coverage is), and not sure how vacation is. Haven't received the full offer yet but they are sending it over soon.\n* They use the latest and greatest tools (aws, airflow, terraform, dbt, python ) just to name a few. They move fast and can whip up new POCs very quickly. I would like to have this skill set as I grow in my carerr\n* Might not have a good work-life balance, not sure how it is there. Boss wants people in most of the time but is okay with some remote work. \n\nMy situation: We are currently doing well financially, my wife has a great job although her company is doing another round of layoffs she has been identified as a top performer and we don't really have concerns of her being effected. We recently just had a baby and she is 7 weeks old WITHOUT DAYCARE. We had our daycare lady leave the country so we are planning to WFH and take care of baby until October until she can get in. Really torn on what to do.\n\nTLDR: Have a cushy job now with a shitty toolset but offering more money, getting a offer for more money and a better toolset but would have to go into the office more with a baby at home.", "author_fullname": "t2_18qay50v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Really need help with a Career decision.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xfbh3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675900835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Current situation: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;large government contact for an agency, best job security in the country without giving away more info&lt;/li&gt;\n&lt;li&gt;Salary $88,500 with a 7% match to 401K, 3 weeks vacation that accrues fast, 4 weeks paternity leave, frequent raises (pay went up 14% in the past 2 years I&amp;#39;ve been here), and a 9/80 schedule. COMPLETE WFH&lt;/li&gt;\n&lt;li&gt;Using outdated tools (Talend, Denodo, and newer qlik replicate), we will never use the cloud, and bringing in newer technologies is a fucking nightmare that takes months if not years. &lt;/li&gt;\n&lt;li&gt;They are currently offering a retention program. if you sign a 2 year agreeement to stay you will receive a 15K bonus immediately (pay back if you leave of course) 10k after taxes&lt;/li&gt;\n&lt;li&gt;Very good work-life balance and flexibility. I never feel stressed about work and have a well managed work load with an awesome manager and a good team.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Future opportunity: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data engineer at a large freight company that does several things in the industry. &lt;/li&gt;\n&lt;li&gt;Pay would be 105-125k with an annual bonus ( not sure how much) , 4% 401k match I believe, this might be wrong. Fully paid medical benefits (not sure how good coverage is), and not sure how vacation is. Haven&amp;#39;t received the full offer yet but they are sending it over soon.&lt;/li&gt;\n&lt;li&gt;They use the latest and greatest tools (aws, airflow, terraform, dbt, python ) just to name a few. They move fast and can whip up new POCs very quickly. I would like to have this skill set as I grow in my carerr&lt;/li&gt;\n&lt;li&gt;Might not have a good work-life balance, not sure how it is there. Boss wants people in most of the time but is okay with some remote work. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My situation: We are currently doing well financially, my wife has a great job although her company is doing another round of layoffs she has been identified as a top performer and we don&amp;#39;t really have concerns of her being effected. We recently just had a baby and she is 7 weeks old WITHOUT DAYCARE. We had our daycare lady leave the country so we are planning to WFH and take care of baby until October until she can get in. Really torn on what to do.&lt;/p&gt;\n\n&lt;p&gt;TLDR: Have a cushy job now with a shitty toolset but offering more money, getting a offer for more money and a better toolset but would have to go into the office more with a baby at home.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10xfbh3", "is_robot_indexable": true, "report_reasons": null, "author": "Doyale_royale", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xfbh3/really_need_help_with_a_career_decision/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xfbh3/really_need_help_with_a_career_decision/", "subreddit_subscribers": 88987, "created_utc": 1675900835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey people,\n\n&amp;#x200B;\n\nok so, \"data as code\" is a simple idea: *put all your data (especially all that is newly created) into code, and treat it like any other software component. Put it in version control (in SOME way), test it before \"deploying it\" to production, run CD over it.*\n\n&amp;#x200B;\n\nI've been writing about this for some time and technology has moved quite a bit to make data as code real easy to do... So I'm still confused that it hasn't caught on.\n\n&amp;#x200B;\n\nThe benefit of having data in VC is pretty simple, it allows a level of reproducibility that is insane, and we don't have at all right now. It is also more secure, allows for more robust data stacks, and more...\n\n**So what is your take on \"data as code\"?** \n\n&amp;#x200B;\n\n**Notes:**\n\n\\- \"having it in version control\" for data obviously doesn't mean having huge amounts of data in VC. Instead, all reasonable solutions like lakeFS, DVC use metadata to make it fast and easy to switch between different \"versions\". \n\n\\- A simple implementation for reporting could look like this:\n\n   1. Your CI Pipeline (e.g. GitHub Actions or GitLab) triggers your Data Ingestion. The data gets ingested  and gets stored inbetween inside S3 with a new $COMMITHASH identifier. \n\n   2. Your CI Pipeline then (best in parallel!) pushes the data into your snowflake schema snowflake schema called \"cicd\\_$COMMITHASH\"; \n\n   3. Your CI Pipeline then triggers the dbt model runs, on \"cicd\\_$COMMITHASH\".\n\n4. You then run all your tests over your snowflake schema. if you're happy, you do a \"swap\" operation inside snowflake replacing the production schema with your new data.\n\n5. should something break, you trigger a \"roll-back to last version\" button inside your CI Pipeline that simply does a \"swap back\"\n\n6. Should you need to reproduce way older results, you simply trigger your CI Pipeline starting at step 2 with a different DVC data input set. \n\n\\- data as code works just fine for all the major kinds of data. For analytical data (reporting, dashboarding), for machine learning system and even for operational data (although this is way down the line in terms of importance).\n\n\\- yes in all applications (as you can see in the implementation) you do have to be careful to always use metadata like data movement operations (that are super fast) as not to slow down your pipelines, but there's enough technology available now to make that possible.", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data as code - why doesn't it catch on? What's your take?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xob67", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675926523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey people,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;ok so, &amp;quot;data as code&amp;quot; is a simple idea: &lt;em&gt;put all your data (especially all that is newly created) into code, and treat it like any other software component. Put it in version control (in SOME way), test it before &amp;quot;deploying it&amp;quot; to production, run CD over it.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been writing about this for some time and technology has moved quite a bit to make data as code real easy to do... So I&amp;#39;m still confused that it hasn&amp;#39;t caught on.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The benefit of having data in VC is pretty simple, it allows a level of reproducibility that is insane, and we don&amp;#39;t have at all right now. It is also more secure, allows for more robust data stacks, and more...&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;So what is your take on &amp;quot;data as code&amp;quot;?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- &amp;quot;having it in version control&amp;quot; for data obviously doesn&amp;#39;t mean having huge amounts of data in VC. Instead, all reasonable solutions like lakeFS, DVC use metadata to make it fast and easy to switch between different &amp;quot;versions&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;- A simple implementation for reporting could look like this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Your CI Pipeline (e.g. GitHub Actions or GitLab) triggers your Data Ingestion. The data gets ingested  and gets stored inbetween inside S3 with a new $COMMITHASH identifier. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Your CI Pipeline then (best in parallel!) pushes the data into your snowflake schema snowflake schema called &amp;quot;cicd_$COMMITHASH&amp;quot;; &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Your CI Pipeline then triggers the dbt model runs, on &amp;quot;cicd_$COMMITHASH&amp;quot;.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;You then run all your tests over your snowflake schema. if you&amp;#39;re happy, you do a &amp;quot;swap&amp;quot; operation inside snowflake replacing the production schema with your new data.&lt;/li&gt;\n&lt;li&gt;should something break, you trigger a &amp;quot;roll-back to last version&amp;quot; button inside your CI Pipeline that simply does a &amp;quot;swap back&amp;quot;&lt;/li&gt;\n&lt;li&gt;Should you need to reproduce way older results, you simply trigger your CI Pipeline starting at step 2 with a different DVC data input set. &lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;- data as code works just fine for all the major kinds of data. For analytical data (reporting, dashboarding), for machine learning system and even for operational data (although this is way down the line in terms of importance).&lt;/p&gt;\n\n&lt;p&gt;- yes in all applications (as you can see in the implementation) you do have to be careful to always use metadata like data movement operations (that are super fast) as not to slow down your pipelines, but there&amp;#39;s enough technology available now to make that possible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10xob67", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xob67/data_as_code_why_doesnt_it_catch_on_whats_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xob67/data_as_code_why_doesnt_it_catch_on_whats_your/", "subreddit_subscribers": 88987, "created_utc": 1675926523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I really love R, and want to use it as much as I can for analysis and visualizations.  (Although I am open to criticism)\n\nMy understanding of the two Synapse pools:\n\n1. Dedicated SQL pool: I think I should be able to fetch data with R using RODBC and the like, to work on the data in RStudio locally, in memory (assuming I pull something down that fits in local memory).  Is this true??\n\n2. Serverless SQL pool (parquet files in data lake):   Serverless natively \u201csupports R\u201d now in Azure with notebooks, but it seems like it\u2019s watered down, and not at all like running R in the RStudio IDE with the plethora of packages and features.  I may be wrong. Someone please tell me I\u2019m dumb and wrong.\n\nCan I point RStudio/RODBC to the Serverless pool?", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to use R for data analysis/viz - do I have a choice between Synapse Dedicated SQL pool vs Serverless (parquet)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xndv6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675923383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I really love R, and want to use it as much as I can for analysis and visualizations.  (Although I am open to criticism)&lt;/p&gt;\n\n&lt;p&gt;My understanding of the two Synapse pools:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Dedicated SQL pool: I think I should be able to fetch data with R using RODBC and the like, to work on the data in RStudio locally, in memory (assuming I pull something down that fits in local memory).  Is this true??&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Serverless SQL pool (parquet files in data lake):   Serverless natively \u201csupports R\u201d now in Azure with notebooks, but it seems like it\u2019s watered down, and not at all like running R in the RStudio IDE with the plethora of packages and features.  I may be wrong. Someone please tell me I\u2019m dumb and wrong.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Can I point RStudio/RODBC to the Serverless pool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10xndv6", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xndv6/i_want_to_use_r_for_data_analysisviz_do_i_have_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xndv6/i_want_to_use_r_for_data_analysisviz_do_i_have_a/", "subreddit_subscribers": 88987, "created_utc": 1675923383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I feel like there was a lot of noise and they showed some impressive benchmarks a while back. But from people I've spoken to and heard from at conferences I'm not aware of anyone using it. Is the project waning or just still super early? It's barely mentioned on this sub.", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone use Redpanda?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xn9l4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675923013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I feel like there was a lot of noise and they showed some impressive benchmarks a while back. But from people I&amp;#39;ve spoken to and heard from at conferences I&amp;#39;m not aware of anyone using it. Is the project waning or just still super early? It&amp;#39;s barely mentioned on this sub.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10xn9l4", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xn9l4/anyone_use_redpanda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xn9l4/anyone_use_redpanda/", "subreddit_subscribers": 88987, "created_utc": 1675923013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello team,\nWe\u2019ve got an ETL pipeline that draws data from PostgreSQL, and sends it to Redshift. Yes, we\u2019re in AWS entirely. Something about the setup irks me. I\u2019ll elaborate.\n\nWe use GLUE to read from RDS Postgres. We do NOT use the Crawler because our Glue jobs use jdbc connections to read from Postgres. Now, toward the destination, we also use jdbc to write the data to Redshift. Problem(?): The target table must already exist, and its structure must be perfectly matched to the source.\n\nTo me, I was hoping that the structure would be inferred, but most importantly, created on the target (Redshift). Instead, we have to meticulously update the schema on Redshift, if the source tables change.\n\nThis raises a big questions for me - Is this normal or Best practice? Some people at my company claim that this level of awareness of the data is good. Some say its too much maintenance and error prone. What do you think?\n\nNote: You may wonder why we don\u2019t use Crawlers. I\u2019ll justify that here. For the source db, we didn\u2019t need it. We needed a jdbc connection so that we could specify custom jobBookmarkKeys. When you do that, the Glue Catalogue table isn\u2019t actually used. Superfluous. For the target, there is also no point. In the case where the table doesn\u2019t exist, the Crawler will not work. In the case that the table did exist, you wouldn\u2019t need a Crawler anyway.\n\nAny advice? Please and thank you.", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manual schema updates in Data Warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xk9to", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675913829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello team,\nWe\u2019ve got an ETL pipeline that draws data from PostgreSQL, and sends it to Redshift. Yes, we\u2019re in AWS entirely. Something about the setup irks me. I\u2019ll elaborate.&lt;/p&gt;\n\n&lt;p&gt;We use GLUE to read from RDS Postgres. We do NOT use the Crawler because our Glue jobs use jdbc connections to read from Postgres. Now, toward the destination, we also use jdbc to write the data to Redshift. Problem(?): The target table must already exist, and its structure must be perfectly matched to the source.&lt;/p&gt;\n\n&lt;p&gt;To me, I was hoping that the structure would be inferred, but most importantly, created on the target (Redshift). Instead, we have to meticulously update the schema on Redshift, if the source tables change.&lt;/p&gt;\n\n&lt;p&gt;This raises a big questions for me - Is this normal or Best practice? Some people at my company claim that this level of awareness of the data is good. Some say its too much maintenance and error prone. What do you think?&lt;/p&gt;\n\n&lt;p&gt;Note: You may wonder why we don\u2019t use Crawlers. I\u2019ll justify that here. For the source db, we didn\u2019t need it. We needed a jdbc connection so that we could specify custom jobBookmarkKeys. When you do that, the Glue Catalogue table isn\u2019t actually used. Superfluous. For the target, there is also no point. In the case where the table doesn\u2019t exist, the Crawler will not work. In the case that the table did exist, you wouldn\u2019t need a Crawler anyway.&lt;/p&gt;\n\n&lt;p&gt;Any advice? Please and thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10xk9to", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xk9to/manual_schema_updates_in_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xk9to/manual_schema_updates_in_data_warehouse/", "subreddit_subscribers": 88987, "created_utc": 1675913829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Gurus,\n\nMy question may be very basic so apologies in advance.\n\nI want to implement a pyspark code that will read data from BigQuery and perform a simple spark task. I cannot install spark on my local machine so was looking for ways on how to do this on a IDE where I can use spark directly from the cluster.\n\nI do have the .json file for service account authentication.\n\nThanks!", "author_fullname": "t2_6it6xybd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connect IDE to Big Query and use Dataproc cluster\u2019s spark environment.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xfux3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675902141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Gurus,&lt;/p&gt;\n\n&lt;p&gt;My question may be very basic so apologies in advance.&lt;/p&gt;\n\n&lt;p&gt;I want to implement a pyspark code that will read data from BigQuery and perform a simple spark task. I cannot install spark on my local machine so was looking for ways on how to do this on a IDE where I can use spark directly from the cluster.&lt;/p&gt;\n\n&lt;p&gt;I do have the .json file for service account authentication.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10xfux3", "is_robot_indexable": true, "report_reasons": null, "author": "bobasucks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xfux3/connect_ide_to_big_query_and_use_dataproc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xfux3/connect_ide_to_big_query_and_use_dataproc/", "subreddit_subscribers": 88987, "created_utc": 1675902141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The nurse can be called to a specific room , now what is the cardinality between the nurse and the room ? ( There are multiple examination rooms and Nurse)\n\nMy logic is that:\n\n it's m:n  because any nurse can be called to any room \n\nAm I right ?", "author_fullname": "t2_2ah0kkor", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Er diagram question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10xp7l7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675929752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The nurse can be called to a specific room , now what is the cardinality between the nurse and the room ? ( There are multiple examination rooms and Nurse)&lt;/p&gt;\n\n&lt;p&gt;My logic is that:&lt;/p&gt;\n\n&lt;p&gt;it&amp;#39;s m:n  because any nurse can be called to any room &lt;/p&gt;\n\n&lt;p&gt;Am I right ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10xp7l7", "is_robot_indexable": true, "report_reasons": null, "author": "omidhhh", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xp7l7/er_diagram_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10xp7l7/er_diagram_question/", "subreddit_subscribers": 88987, "created_utc": 1675929752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our startup is &lt;50 people and our stack is: fivetran, dbt, snowflake and preset. \n\nWe have some use cases where people in the company need access to user email addresses for research purposes. How do your teams think about PII (emails specifically) &amp; exposing that in your BI tool?", "author_fullname": "t2_j1vd6s00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PII in Business Intelligence tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x7kvn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675882868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our startup is &amp;lt;50 people and our stack is: fivetran, dbt, snowflake and preset. &lt;/p&gt;\n\n&lt;p&gt;We have some use cases where people in the company need access to user email addresses for research purposes. How do your teams think about PII (emails specifically) &amp;amp; exposing that in your BI tool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10x7kvn", "is_robot_indexable": true, "report_reasons": null, "author": "crhumble", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x7kvn/pii_in_business_intelligence_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x7kvn/pii_in_business_intelligence_tool/", "subreddit_subscribers": 88987, "created_utc": 1675882868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team is considering both options but wanted to understand what your teams find a bit more useful. \n\nSegment keeps pushing their CDP but I only care about event tracking + collection.   \nSnowplow seems decent but looks infra heavy. \n\nThoughts?", "author_fullname": "t2_j1vd6s00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Segment or Snowplow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x7j7k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675882774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team is considering both options but wanted to understand what your teams find a bit more useful. &lt;/p&gt;\n\n&lt;p&gt;Segment keeps pushing their CDP but I only care about event tracking + collection.&lt;br/&gt;\nSnowplow seems decent but looks infra heavy. &lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10x7j7k", "is_robot_indexable": true, "report_reasons": null, "author": "crhumble", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x7j7k/segment_or_snowplow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x7j7k/segment_or_snowplow/", "subreddit_subscribers": 88987, "created_utc": 1675882774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Read Raster Data From Postgis Using Python](https://preview.redd.it/3vjp0t4yzzga1.png?width=597&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=56fdd37c413af378ff444bf929ec79ae4b82a15e)\n\n[Read Raster Data From Postgis Using Python](https://spatial-dev.guru/2023/02/04/read-raster-data-from-postgis-using-python/)", "author_fullname": "t2_avt84u4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Read Raster Data From Postgis Using Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3vjp0t4yzzga1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/3vjp0t4yzzga1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60cb9c81810919cf094ea6060531e5fc2bc37e42"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/3vjp0t4yzzga1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2de9cdfd7aeda3d4be6563924ee5b64ca3021f83"}, {"y": 168, "x": 320, "u": "https://preview.redd.it/3vjp0t4yzzga1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6560f9772a7feb511d1339c98369320ef051f1ee"}], "s": {"y": 314, "x": 597, "u": "https://preview.redd.it/3vjp0t4yzzga1.png?width=597&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=56fdd37c413af378ff444bf929ec79ae4b82a15e"}, "id": "3vjp0t4yzzga1"}}, "name": "t3_10x4ziw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jjOq3MTN5HCfwKGJUv9kmQ76JpDyh4yQUvrsNaC3M0o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675876590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3vjp0t4yzzga1.png?width=597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=56fdd37c413af378ff444bf929ec79ae4b82a15e\"&gt;Read Raster Data From Postgis Using Python&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://spatial-dev.guru/2023/02/04/read-raster-data-from-postgis-using-python/\"&gt;Read Raster Data From Postgis Using Python&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10x4ziw", "is_robot_indexable": true, "report_reasons": null, "author": "iamgeoknight", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x4ziw/read_raster_data_from_postgis_using_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x4ziw/read_raster_data_from_postgis_using_python/", "subreddit_subscribers": 88987, "created_utc": 1675876590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fb83g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Querying 1 Billion Rows of AWS Cost Data 100X Faster with DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 83, "top_awarded_type": null, "hide_score": false, "name": "t3_10xw9f0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-0aQIqmXqp2my4VxPbjhZXmebP2OS68ue_K6fPhCpTc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675953372.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "vantage.sh", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.vantage.sh/blog/querying-aws-cost-data-duckdb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pMpfHhXYugqhHSyLlUydTg9-V8Jx-uWKUj3t18sul8A.jpg?auto=webp&amp;v=enabled&amp;s=9f0238778e1ee72ab50629878190a93a3adca59c", "width": 2540, "height": 1520}, "resolutions": [{"url": "https://external-preview.redd.it/pMpfHhXYugqhHSyLlUydTg9-V8Jx-uWKUj3t18sul8A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=786e823d297bfd470e7032bb81c80bb9e519ad49", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/pMpfHhXYugqhHSyLlUydTg9-V8Jx-uWKUj3t18sul8A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81134544132584f87ad324085ed7baab9e82d8fb", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/pMpfHhXYugqhHSyLlUydTg9-V8Jx-uWKUj3t18sul8A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=745ede3c1a390215a1a14e700fd51f25995aa7c1", "width": 320, "height": 191}, {"url": "https://external-preview.redd.it/pMpfHhXYugqhHSyLlUydTg9-V8Jx-uWKUj3t18sul8A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d43866963ec48799e7e8a961fc44ee5942742e25", "width": 640, "height": 382}, {"url": "https://external-preview.redd.it/pMpfHhXYugqhHSyLlUydTg9-V8Jx-uWKUj3t18sul8A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=97c71936c8524fd624420049d7ce1d066da23f0d", "width": 960, "height": 574}, {"url": "https://external-preview.redd.it/pMpfHhXYugqhHSyLlUydTg9-V8Jx-uWKUj3t18sul8A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=24f013a94ee32dbf47ef52e053864a386807b084", "width": 1080, "height": 646}], "variants": {}, "id": "fFFOps9uNyZKaT6C1uHqRiZJAv21eiUxoFEL-ZkhJHM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10xw9f0", "is_robot_indexable": true, "report_reasons": null, "author": "include_stdio_h", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10xw9f0/querying_1_billion_rows_of_aws_cost_data_100x/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.vantage.sh/blog/querying-aws-cost-data-duckdb", "subreddit_subscribers": 88987, "created_utc": 1675953372.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}