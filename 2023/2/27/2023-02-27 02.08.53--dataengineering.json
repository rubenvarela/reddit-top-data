{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks - a lot of the roles that I'm interested in happen to involve big data technologies and almost always has one or both of the following requirements:\n\n* \"Must have experience working with datasets of Big Data volumes\"\n* \"Deeply versed in one of the following big data technologies: Presto, Spark, etc.\"\n\nI feel a bit trapped because I have 4+ years of data engineering (7+ YOE total) and I qualify for a lot of Senior Data Engineer roles, but I've had recruiters decline me because of not having real-world working experience with big data technologies (per their words). This is despite having read books on various technologies, doing small projects implementing and using them, etc.\n\nI don't believe in resume-driven development at work so I'm curious how one can get out of this rut. Should I be applying to non-Senior Data Engineer roles that involve Big Data tech stacks, despite exceeding their YOE requirements? Or should I step up my side projects and fork over some money to replicate a real-world data system within AWS? Or am I striking bad luck with the recruiters?\n\n*Disclaimer: And no, this is not about wanting higher salaries nor perceiving these technologies as better than others. It's mostly an interest of mine to break into this field and work with these volumes of data. I hope that makes sense.*", "author_fullname": "t2_hwg7lsz6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to break into Big Data Engineering jobs without having Big Data experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ckktt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677426957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks - a lot of the roles that I&amp;#39;m interested in happen to involve big data technologies and almost always has one or both of the following requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;Must have experience working with datasets of Big Data volumes&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;Deeply versed in one of the following big data technologies: Presto, Spark, etc.&amp;quot;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I feel a bit trapped because I have 4+ years of data engineering (7+ YOE total) and I qualify for a lot of Senior Data Engineer roles, but I&amp;#39;ve had recruiters decline me because of not having real-world working experience with big data technologies (per their words). This is despite having read books on various technologies, doing small projects implementing and using them, etc.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t believe in resume-driven development at work so I&amp;#39;m curious how one can get out of this rut. Should I be applying to non-Senior Data Engineer roles that involve Big Data tech stacks, despite exceeding their YOE requirements? Or should I step up my side projects and fork over some money to replicate a real-world data system within AWS? Or am I striking bad luck with the recruiters?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Disclaimer: And no, this is not about wanting higher salaries nor perceiving these technologies as better than others. It&amp;#39;s mostly an interest of mine to break into this field and work with these volumes of data. I hope that makes sense.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11ckktt", "is_robot_indexable": true, "report_reasons": null, "author": "spicy_pierogi", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11ckktt/how_to_break_into_big_data_engineering_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ckktt/how_to_break_into_big_data_engineering_jobs/", "subreddit_subscribers": 91223, "created_utc": 1677426957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, I have an interview on this Wednesday and Thursday. I am so stressed about it.. If anyone has any experience about it, could you please share your experiences? What type of questions should I expect, or what should I revise? I am looking forward to hearing from you... Please heelpp", "author_fullname": "t2_8yrfmc1z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EA Data Engineer Intern Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c6k7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677390110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I have an interview on this Wednesday and Thursday. I am so stressed about it.. If anyone has any experience about it, could you please share your experiences? What type of questions should I expect, or what should I revise? I am looking forward to hearing from you... Please heelpp&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11c6k7j", "is_robot_indexable": true, "report_reasons": null, "author": "nihadaen", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c6k7j/ea_data_engineer_intern_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c6k7j/ea_data_engineer_intern_interview/", "subreddit_subscribers": 91223, "created_utc": 1677390110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can anyone point me to resources that teach you how you can take a script and put it into a production environment that allows you to schedule it? Most courses I\u2019ve taken and videos I watch go through the process of pulling data from a source and pushing it into a destination, but I can\u2019t find any resources on how you actually get something into production. Excuse me if this is a trivial question, I\u2019m just genuinely struggling. Thank you in advance.", "author_fullname": "t2_3eirbc33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to put a pipeline into production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c8fjj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677397110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone point me to resources that teach you how you can take a script and put it into a production environment that allows you to schedule it? Most courses I\u2019ve taken and videos I watch go through the process of pulling data from a source and pushing it into a destination, but I can\u2019t find any resources on how you actually get something into production. Excuse me if this is a trivial question, I\u2019m just genuinely struggling. Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11c8fjj", "is_robot_indexable": true, "report_reasons": null, "author": "pbxmy", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c8fjj/how_to_put_a_pipeline_into_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c8fjj/how_to_put_a_pipeline_into_production/", "subreddit_subscribers": 91223, "created_utc": 1677397110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a PM and we are hiring a data engineer for our team. I would like to \"classify\" different motivational type of candidates.\n\nI imagine that there are the ones which are very technology driven who like to learn and work with different and new technologies.\n\nThen, maybe other who want to have end-to-end responsibility from source to even building DWH or even Dashboards.\n\nDoes this make sense ? What kind of \"types\" exists?", "author_fullname": "t2_e4028dc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What motivates a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ca12v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677403515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a PM and we are hiring a data engineer for our team. I would like to &amp;quot;classify&amp;quot; different motivational type of candidates.&lt;/p&gt;\n\n&lt;p&gt;I imagine that there are the ones which are very technology driven who like to learn and work with different and new technologies.&lt;/p&gt;\n\n&lt;p&gt;Then, maybe other who want to have end-to-end responsibility from source to even building DWH or even Dashboards.&lt;/p&gt;\n\n&lt;p&gt;Does this make sense ? What kind of &amp;quot;types&amp;quot; exists?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ca12v", "is_robot_indexable": true, "report_reasons": null, "author": "tzt1324", "discussion_type": null, "num_comments": 60, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ca12v/what_motivates_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ca12v/what_motivates_a_data_engineer/", "subreddit_subscribers": 91223, "created_utc": 1677403515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, sorry for a lengthy post. I am looking to have a discussion with you guys about designing data-marts for business reporting where the data for the marts are extracted and transformed from a centralized Data Lake.\n\nWe have an Extract and Load process from our sources into an Azure Data Lake. Data in the lake is currently only used in ML or data-driven applications, not really for traditional BI uses. However, as we are advancing our platform to increase our value to the business, we are needing to enable these types of traditional BI reporting capabilities on top of the data we ingest into our data lake. Everything we develop is project-specific and must be approved by a portfolio board. So, the plan is to develop project-based data-marts in an Azure dedicated SQL pool (Azure Data warehouse).\n\n[Extract and Load into the Data Store\\/Central Repository. Parquets stored in Azure Data Lake Storage](https://preview.redd.it/muy6ytyxhkka1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8d835743a515c4c89058bf970c5eaa403770350a)\n\n&gt;*I will preface that I am in an awkward position, because I come from BI and analytics, not architecture or engineering. Nonetheless, I transitioned into an IT role last year, where we do not have a senior data engineer, or any dedicated engineer at all that can help with this advancement. I am looking to fill that piece of the team, but am basically a junior DE with no senior DE to learn from... I have been running the POC's and want to make sure the way I plan the data-marts at least make sense. I know I won't create the perfect solution the first-time around, but I want to at least start in the right direction. I don't love having to go to reddit to have these discussions, but it is really my only option at this point...*\n\nThe Data Lake will serve as the central repository/data store for all downstream use-cases. The transformation process will be Dockerized python-based data pipelines running on a Kubernetes cluster. The pipeline will extract data from the lake, perform the data transformations needed for the business use-case (business rules, joins, conditions, filters, etc...), and load the transformed data into a data-mart in the warehouse.\n\n**I am just really confused as to how these data-marts should be modeled in the warehouse. Some options I can think of are:**\n\n1. The transformation results in a denormalized OBT structure that is stored in a specific schema. In this option, 1 database schema = 1 data mart, and the data mart is just a single OBT. New data are loaded into the lake, transformed with python (Docker + Kubernetes), and records are then inserted into the OBT/mart in the warehouse. Although this makes sense to me, I feel like it isn't best, as every mart would just a single table in a specific database schema. If the business needs lots of potential dimensions at their immediate disposal in the semantic model, this method doesn't seem to be practical.\n\n[1 data warehouse schema = 1 data mart, where each mart is just a denormalized OBT](https://preview.redd.it/v8wkifdnhkka1.jpg?width=1362&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=bbcbb646a00bd8a24e4787f550fa320049576907)\n\n2. The transformation results in a star-schema structure that is stored in a specific database schema. With this option, 1 data mart = 1 database schema, and the table schema resembles a star-schema. The issue with this is I think I would just be duplicating dimensions in different database schemas. Maybe this is okay? If I create a mart to track delivery performance for logistics, I would need to source the customers table from the lake. If later I create another mart to track sales, I would also need to source the customer table from the lake. Now I have two customer tables in different schemas of the warehouse. This honestly might not be a big deal since the dimensions are sourced from the sample data in the data lake.\n\n[1 data warehouse schema = 1 data mart, where each mart is a single fact table with multiple dimensions](https://preview.redd.it/bgusekfphkka1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=abd7ac824d2ba3844ac27856b17bc8ab835fafcb)\n\n3. A combination of 1 and 2. I can imagine some marts are better off as a OBT structure, while others would benefit from a star schema. Could also create a constellation structure if multiple facts are required.\n\n4. I am way off all together, and I am not thinking about this correctly (which honestly may be the case and explains why I am so confused). Like what if I need to have a combination of non-aggregated fact tables alongside aggregated tables for easier analysis? Would I just throw all of these inside the same data warehouse schema?", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Structuring Data Marts from a Data Lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 46, "top_awarded_type": null, "hide_score": false, "media_metadata": {"muy6ytyxhkka1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 35, "x": 108, "u": "https://preview.redd.it/muy6ytyxhkka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95bce96dac5e270970c084124a1d0859886c5ef6"}, {"y": 71, "x": 216, "u": "https://preview.redd.it/muy6ytyxhkka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=113c6c4a3beb5caea7e6ded48ec99c81b09d97a7"}, {"y": 106, "x": 320, "u": "https://preview.redd.it/muy6ytyxhkka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=349d949cedab9301e2a6a982492617bcc17f6211"}, {"y": 212, "x": 640, "u": "https://preview.redd.it/muy6ytyxhkka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d92a0117e40e910b8ce2d91211ab749f0916a6e"}, {"y": 318, "x": 960, "u": "https://preview.redd.it/muy6ytyxhkka1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d20e8ece0e3641b3c705d93eed2452cc2f445c5"}, {"y": 358, "x": 1080, "u": "https://preview.redd.it/muy6ytyxhkka1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=531f4a3eed6cbcd6236b3dc2d6e93e75b836f08b"}], "s": {"y": 425, "x": 1280, "u": "https://preview.redd.it/muy6ytyxhkka1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8d835743a515c4c89058bf970c5eaa403770350a"}, "id": "muy6ytyxhkka1"}, "v8wkifdnhkka1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 63, "x": 108, "u": "https://preview.redd.it/v8wkifdnhkka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e79104064177a718ca9ab583e3588211d3bcc6cf"}, {"y": 127, "x": 216, "u": "https://preview.redd.it/v8wkifdnhkka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=03885bfbcf1e3fb7f697d76e499026bd6780d265"}, {"y": 189, "x": 320, "u": "https://preview.redd.it/v8wkifdnhkka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36e565016e2838b7c15c012fb629b5bccb078af9"}, {"y": 378, "x": 640, "u": "https://preview.redd.it/v8wkifdnhkka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e431e121d004ccc261a5c81406d3b96ccb012b6"}, {"y": 568, "x": 960, "u": "https://preview.redd.it/v8wkifdnhkka1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=59002e9fee89774b8fda6c0156eca7955ae4a24b"}, {"y": 639, "x": 1080, "u": "https://preview.redd.it/v8wkifdnhkka1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ad26f9eca5f6eaeb0514784871810f16fa30af2"}], "s": {"y": 806, "x": 1362, "u": "https://preview.redd.it/v8wkifdnhkka1.jpg?width=1362&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=bbcbb646a00bd8a24e4787f550fa320049576907"}, "id": "v8wkifdnhkka1"}, "bgusekfphkka1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/bgusekfphkka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d33a3932fdffe47c214cc5e2f22d9ebd46ef5785"}, {"y": 133, "x": 216, "u": "https://preview.redd.it/bgusekfphkka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2eac2caf21c94d44b4900657fb165355021bf23b"}, {"y": 198, "x": 320, "u": "https://preview.redd.it/bgusekfphkka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08f918d4e1f8637846eb10f213133bcc905d747e"}, {"y": 396, "x": 640, "u": "https://preview.redd.it/bgusekfphkka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36e2e95b834ca4fff739b8860af110d168fd2087"}, {"y": 594, "x": 960, "u": "https://preview.redd.it/bgusekfphkka1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c09af06c4048cced0de8c78c059b44496e0b20df"}, {"y": 669, "x": 1080, "u": "https://preview.redd.it/bgusekfphkka1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f1360c260994dd057961c33591da59c9c17f58b"}], "s": {"y": 793, "x": 1280, "u": "https://preview.redd.it/bgusekfphkka1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=abd7ac824d2ba3844ac27856b17bc8ab835fafcb"}, "id": "bgusekfphkka1"}}, "name": "t3_11cneq2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/E3et4EkiFQ4cyykMDvikWt6rKtGfeLUQlquJ_QMQCmk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677433180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, sorry for a lengthy post. I am looking to have a discussion with you guys about designing data-marts for business reporting where the data for the marts are extracted and transformed from a centralized Data Lake.&lt;/p&gt;\n\n&lt;p&gt;We have an Extract and Load process from our sources into an Azure Data Lake. Data in the lake is currently only used in ML or data-driven applications, not really for traditional BI uses. However, as we are advancing our platform to increase our value to the business, we are needing to enable these types of traditional BI reporting capabilities on top of the data we ingest into our data lake. Everything we develop is project-specific and must be approved by a portfolio board. So, the plan is to develop project-based data-marts in an Azure dedicated SQL pool (Azure Data warehouse).&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/muy6ytyxhkka1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8d835743a515c4c89058bf970c5eaa403770350a\"&gt;Extract and Load into the Data Store/Central Repository. Parquets stored in Azure Data Lake Storage&lt;/a&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;em&gt;I will preface that I am in an awkward position, because I come from BI and analytics, not architecture or engineering. Nonetheless, I transitioned into an IT role last year, where we do not have a senior data engineer, or any dedicated engineer at all that can help with this advancement. I am looking to fill that piece of the team, but am basically a junior DE with no senior DE to learn from... I have been running the POC&amp;#39;s and want to make sure the way I plan the data-marts at least make sense. I know I won&amp;#39;t create the perfect solution the first-time around, but I want to at least start in the right direction. I don&amp;#39;t love having to go to reddit to have these discussions, but it is really my only option at this point...&lt;/em&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The Data Lake will serve as the central repository/data store for all downstream use-cases. The transformation process will be Dockerized python-based data pipelines running on a Kubernetes cluster. The pipeline will extract data from the lake, perform the data transformations needed for the business use-case (business rules, joins, conditions, filters, etc...), and load the transformed data into a data-mart in the warehouse.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I am just really confused as to how these data-marts should be modeled in the warehouse. Some options I can think of are:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The transformation results in a denormalized OBT structure that is stored in a specific schema. In this option, 1 database schema = 1 data mart, and the data mart is just a single OBT. New data are loaded into the lake, transformed with python (Docker + Kubernetes), and records are then inserted into the OBT/mart in the warehouse. Although this makes sense to me, I feel like it isn&amp;#39;t best, as every mart would just a single table in a specific database schema. If the business needs lots of potential dimensions at their immediate disposal in the semantic model, this method doesn&amp;#39;t seem to be practical.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/v8wkifdnhkka1.jpg?width=1362&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=bbcbb646a00bd8a24e4787f550fa320049576907\"&gt;1 data warehouse schema = 1 data mart, where each mart is just a denormalized OBT&lt;/a&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The transformation results in a star-schema structure that is stored in a specific database schema. With this option, 1 data mart = 1 database schema, and the table schema resembles a star-schema. The issue with this is I think I would just be duplicating dimensions in different database schemas. Maybe this is okay? If I create a mart to track delivery performance for logistics, I would need to source the customers table from the lake. If later I create another mart to track sales, I would also need to source the customer table from the lake. Now I have two customer tables in different schemas of the warehouse. This honestly might not be a big deal since the dimensions are sourced from the sample data in the data lake.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bgusekfphkka1.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=abd7ac824d2ba3844ac27856b17bc8ab835fafcb\"&gt;1 data warehouse schema = 1 data mart, where each mart is a single fact table with multiple dimensions&lt;/a&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;A combination of 1 and 2. I can imagine some marts are better off as a OBT structure, while others would benefit from a star schema. Could also create a constellation structure if multiple facts are required.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I am way off all together, and I am not thinking about this correctly (which honestly may be the case and explains why I am so confused). Like what if I need to have a combination of non-aggregated fact tables alongside aggregated tables for easier analysis? Would I just throw all of these inside the same data warehouse schema?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11cneq2", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11cneq2/structuring_data_marts_from_a_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11cneq2/structuring_data_marts_from_a_data_lake/", "subreddit_subscribers": 91223, "created_utc": 1677433180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For example, go on Indeed, and look at data engineering jobs posted recently in big tech cities like San Francisco.  There are very few data engineering jobs being posted (about 1 page of recent jobs), even a couple of months after the new year.\n\n\n\n\nIf a data engineer was laid off, what kind of job would they then look for?  Would they try to become software engineers, go into devops, or look for data analyst openings?  I've only worked in data, so I feel like I would have to learn an entirely new domain.", "author_fullname": "t2_bc6dzgi9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it me, or has the recession especially affected the data engineering job market?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11cm4ax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677430700.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677430391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, go on Indeed, and look at data engineering jobs posted recently in big tech cities like San Francisco.  There are very few data engineering jobs being posted (about 1 page of recent jobs), even a couple of months after the new year.&lt;/p&gt;\n\n&lt;p&gt;If a data engineer was laid off, what kind of job would they then look for?  Would they try to become software engineers, go into devops, or look for data analyst openings?  I&amp;#39;ve only worked in data, so I feel like I would have to learn an entirely new domain.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11cm4ax", "is_robot_indexable": true, "report_reasons": null, "author": "wfh_forever1", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11cm4ax/is_it_me_or_has_the_recession_especially_affected/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11cm4ax/is_it_me_or_has_the_recession_especially_affected/", "subreddit_subscribers": 91223, "created_utc": 1677430391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nI head towards data science before 1 year ago which ended up with realizing after six month that the field is enourmously saturated. I was 2 years experienced with mobile development (Java), so working with software was a lot more engaging and efficient for me so I decided to go on maybe Data Engineering.\n\nAs far as I see, data engineering is not much hyped as being a crazy data scientist or AI/ML engineer. I think people generally stay away from data engineering because of the need of software development background, and they step into data science because they do not aware of the holy math behind the scene.\n\nThose are my guess. I wonder if it is true.\n\nToday junior data analyst positions are full for most regions. However i encounter with jr data engineer positions.\n\nI ask if there is life in data engineering :) If it is over-saturated too, I will focus on cloud engineering before I finish the university (kinda sophomore student).", "author_fullname": "t2_t1xjvr55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data engineering over-hyped too like data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ctwrk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677448410.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I head towards data science before 1 year ago which ended up with realizing after six month that the field is enourmously saturated. I was 2 years experienced with mobile development (Java), so working with software was a lot more engaging and efficient for me so I decided to go on maybe Data Engineering.&lt;/p&gt;\n\n&lt;p&gt;As far as I see, data engineering is not much hyped as being a crazy data scientist or AI/ML engineer. I think people generally stay away from data engineering because of the need of software development background, and they step into data science because they do not aware of the holy math behind the scene.&lt;/p&gt;\n\n&lt;p&gt;Those are my guess. I wonder if it is true.&lt;/p&gt;\n\n&lt;p&gt;Today junior data analyst positions are full for most regions. However i encounter with jr data engineer positions.&lt;/p&gt;\n\n&lt;p&gt;I ask if there is life in data engineering :) If it is over-saturated too, I will focus on cloud engineering before I finish the university (kinda sophomore student).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11ctwrk", "is_robot_indexable": true, "report_reasons": null, "author": "gxslash", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ctwrk/is_data_engineering_overhyped_too_like_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ctwrk/is_data_engineering_overhyped_too_like_data/", "subreddit_subscribers": 91223, "created_utc": 1677448410.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been in a complex dilemma of getting low-latency data available into the data lake. While I understand that low latency data should be either handled into an application itself or an engine/motor that enables fast aggregations like Apache Druid - I've been trying to get into a sweet spot where I can both have a low latency + ok reading performance, but I progressed little and without much confidence. \n\nWhat you guys have been using? How do you manage small files without having latency over a minute or having to interrupt the streaming ingestion to run an optimize/aggregation operation?", "author_fullname": "t2_10pv8n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Low latency streaming data into Datalake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11cv28g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677451110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been in a complex dilemma of getting low-latency data available into the data lake. While I understand that low latency data should be either handled into an application itself or an engine/motor that enables fast aggregations like Apache Druid - I&amp;#39;ve been trying to get into a sweet spot where I can both have a low latency + ok reading performance, but I progressed little and without much confidence. &lt;/p&gt;\n\n&lt;p&gt;What you guys have been using? How do you manage small files without having latency over a minute or having to interrupt the streaming ingestion to run an optimize/aggregation operation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11cv28g", "is_robot_indexable": true, "report_reasons": null, "author": "naniviaa", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11cv28g/low_latency_streaming_data_into_datalake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11cv28g/low_latency_streaming_data_into_datalake/", "subreddit_subscribers": 91223, "created_utc": 1677451110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that data engineers work mostly oriented with data. Building pipelines, scheduling tasks, manipluating data, mining it etc. What I dont know is what is it that cloud engineers really do.\n\nNow, while I was looking for intern positions on data engineering I've realized that the job ads mostly include those:\n\nCloud software Aws etc, containers (docker etc), scheduling (airflow etc), parallel computation frameworks (hdfs, spark etc), bashscript, linux server knowledge.\n\nHowever it seems to me that 70% of requirements do match with cloud engineering requirements.\n\nI dont know where to ask this question. It matters both fields. But is it easy to switch between cloud and data engineering? Does they do mostly the same job. If it is, what are the most differing parts?", "author_fullname": "t2_t1xjvr55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weird Question: What Really Differs Data Engineers from Cloud Engineers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ctnxh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677447827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that data engineers work mostly oriented with data. Building pipelines, scheduling tasks, manipluating data, mining it etc. What I dont know is what is it that cloud engineers really do.&lt;/p&gt;\n\n&lt;p&gt;Now, while I was looking for intern positions on data engineering I&amp;#39;ve realized that the job ads mostly include those:&lt;/p&gt;\n\n&lt;p&gt;Cloud software Aws etc, containers (docker etc), scheduling (airflow etc), parallel computation frameworks (hdfs, spark etc), bashscript, linux server knowledge.&lt;/p&gt;\n\n&lt;p&gt;However it seems to me that 70% of requirements do match with cloud engineering requirements.&lt;/p&gt;\n\n&lt;p&gt;I dont know where to ask this question. It matters both fields. But is it easy to switch between cloud and data engineering? Does they do mostly the same job. If it is, what are the most differing parts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ctnxh", "is_robot_indexable": true, "report_reasons": null, "author": "gxslash", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ctnxh/weird_question_what_really_differs_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ctnxh/weird_question_what_really_differs_data_engineers/", "subreddit_subscribers": 91223, "created_utc": 1677447827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's the somewhat industry standard now for building models and data transformations.\n\nMy company is evaluating the need for it for our analysts.\n\nThis sub has users of dbt and I've seen many posts. Can you help advise me :\n\n\\- What does dbt do really well?\n\n\\- What are the shortcomings and how do you overcome them?\n\n\\- What can dbt Cloud give that you can't build on your own?\n\n\\- Has anyone thought of rewriting or forking to improve it? Is there a better dbt out there?", "author_fullname": "t2_w0uodzp2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions around using dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ct7o9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677446773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s the somewhat industry standard now for building models and data transformations.&lt;/p&gt;\n\n&lt;p&gt;My company is evaluating the need for it for our analysts.&lt;/p&gt;\n\n&lt;p&gt;This sub has users of dbt and I&amp;#39;ve seen many posts. Can you help advise me :&lt;/p&gt;\n\n&lt;p&gt;- What does dbt do really well?&lt;/p&gt;\n\n&lt;p&gt;- What are the shortcomings and how do you overcome them?&lt;/p&gt;\n\n&lt;p&gt;- What can dbt Cloud give that you can&amp;#39;t build on your own?&lt;/p&gt;\n\n&lt;p&gt;- Has anyone thought of rewriting or forking to improve it? Is there a better dbt out there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ct7o9", "is_robot_indexable": true, "report_reasons": null, "author": "Accurate-Peak4856", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ct7o9/questions_around_using_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ct7o9/questions_around_using_dbt/", "subreddit_subscribers": 91223, "created_utc": 1677446773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I see this course recommended in this sub and lots of other places around the internet, but I am finding the environment set up to be incredibly frustrating. I have deleted my GCP instance and started over from scratch about 13 times so far and I keep having various issues. This is absolutely maddening. Is there like an easy version for dummies, or a guide to set this up on a windows machine without using gitbash?", "author_fullname": "t2_4nbvm2s0m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Zoomcamp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11crlpv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677443060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see this course recommended in this sub and lots of other places around the internet, but I am finding the environment set up to be incredibly frustrating. I have deleted my GCP instance and started over from scratch about 13 times so far and I keep having various issues. This is absolutely maddening. Is there like an easy version for dummies, or a guide to set this up on a windows machine without using gitbash?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11crlpv", "is_robot_indexable": true, "report_reasons": null, "author": "Visible-Tennis4144", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11crlpv/data_engineering_zoomcamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11crlpv/data_engineering_zoomcamp/", "subreddit_subscribers": 91223, "created_utc": 1677443060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'll get to the point quick. I wish to create a database where each item is associated with a set of information and values, which in turn is associated with a set of information and values\n\nA simplified representation:\n\nA:{a:{1,x},b:{2,y}c:{3,z}}\n\nB:{d:{1,z}e:{2,z}f:{3,y}}\n\nC:{g:{1,y},h:{2,x},i{3,x}}\n\nThe sets within the largest set can be seen as a sequence (by which I mean that the data is ordered according to the same metadata (I think in SQL they call this a 'key') always). This is all a simplification, but I would expect every top tier set to contain about 2000 sets and 10 values and each of those 2nd tier sets to contain about 20 sets and 10 values and for each of those 20 sets to be associated with 20 values.\n\nI'm not entirely sure if a relational database is best suited for this; and my Google searches haven't helped. Many thanks in advance!\n\n(If you want to know what this to be used for, it's for a linguistic corpus where every work is divided into sentences and every sentence is divided into words and each sentence and words is associated with certain values. I understand that there are already software for corpora, but they do not work well for either the language I research or the questions I ask, so that's why I ask the question in relation to sets)", "author_fullname": "t2_graxcz2q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Quick Question] Best way to make a database of databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11cmmbk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677431474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll get to the point quick. I wish to create a database where each item is associated with a set of information and values, which in turn is associated with a set of information and values&lt;/p&gt;\n\n&lt;p&gt;A simplified representation:&lt;/p&gt;\n\n&lt;p&gt;A:{a:{1,x},b:{2,y}c:{3,z}}&lt;/p&gt;\n\n&lt;p&gt;B:{d:{1,z}e:{2,z}f:{3,y}}&lt;/p&gt;\n\n&lt;p&gt;C:{g:{1,y},h:{2,x},i{3,x}}&lt;/p&gt;\n\n&lt;p&gt;The sets within the largest set can be seen as a sequence (by which I mean that the data is ordered according to the same metadata (I think in SQL they call this a &amp;#39;key&amp;#39;) always). This is all a simplification, but I would expect every top tier set to contain about 2000 sets and 10 values and each of those 2nd tier sets to contain about 20 sets and 10 values and for each of those 20 sets to be associated with 20 values.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not entirely sure if a relational database is best suited for this; and my Google searches haven&amp;#39;t helped. Many thanks in advance!&lt;/p&gt;\n\n&lt;p&gt;(If you want to know what this to be used for, it&amp;#39;s for a linguistic corpus where every work is divided into sentences and every sentence is divided into words and each sentence and words is associated with certain values. I understand that there are already software for corpora, but they do not work well for either the language I research or the questions I ask, so that&amp;#39;s why I ask the question in relation to sets)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11cmmbk", "is_robot_indexable": true, "report_reasons": null, "author": "alpolvovolvere", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11cmmbk/quick_question_best_way_to_make_a_database_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11cmmbk/quick_question_best_way_to_make_a_database_of/", "subreddit_subscribers": 91223, "created_utc": 1677431474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a consulting firm and have been looking for technical opportunities, specifically more traditional software engineering opportunities. That unfortunately hasn\u2019t worked out, so I took a project for data engineering. My main responsibilities are supposed to be PySpark developer. The thing is, I have a foundational understanding of Spark, but I have pretty much no real world experience with it outside of a short stint creating some basic jobs in Databricks for a few days on my last project. Also, my SQL skills are okay. I was mostly a data analyst on my last project and used it on a daily basis, but most queries were basic select statements with a filter or 2 and maybe a simple join as well. I have faith in myself to pickup new technologies, but I also need to be realistic with myself here. I plan on doing some PySpark crash courses this weekend, but I wanted to get some feedback from the community if y\u2019all think I\u2019m crazy for hopping on this project (which starts in 2 weeks)", "author_fullname": "t2_1fco9rqs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I setting myself up for failure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11colje", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677435868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a consulting firm and have been looking for technical opportunities, specifically more traditional software engineering opportunities. That unfortunately hasn\u2019t worked out, so I took a project for data engineering. My main responsibilities are supposed to be PySpark developer. The thing is, I have a foundational understanding of Spark, but I have pretty much no real world experience with it outside of a short stint creating some basic jobs in Databricks for a few days on my last project. Also, my SQL skills are okay. I was mostly a data analyst on my last project and used it on a daily basis, but most queries were basic select statements with a filter or 2 and maybe a simple join as well. I have faith in myself to pickup new technologies, but I also need to be realistic with myself here. I plan on doing some PySpark crash courses this weekend, but I wanted to get some feedback from the community if y\u2019all think I\u2019m crazy for hopping on this project (which starts in 2 weeks)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11colje", "is_robot_indexable": true, "report_reasons": null, "author": "gencoupethrowaway69", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11colje/am_i_setting_myself_up_for_failure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11colje/am_i_setting_myself_up_for_failure/", "subreddit_subscribers": 91223, "created_utc": 1677435868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have the following scenario (lets imagine every step is daily data load):\n\n\nFirstly, I save the parquet file with 3 columns 'a', 'b', 'c'.\n\n    d = {'a':[1], 'b':[2], 'c':[3]}\n    df = pd.DataFrame.from_dict(d)\n    df.to_parquet('schema/schema1.parquet')\n\nThen I save another file with only 2 columns 'a', 'b'\n\n    d = {'a':[1], 'c':[3]}\n    df = pd.DataFrame.from_dict(d)\n    df.to_parquet('schema/schema2.parquet')\n\nThen I add another file with 4 columns 'a', 'b', 'c', 'd'\n\n    d = {'a':[1], 'b':[2], 'c':[3], 'd':[4]}\n    df = pd.DataFrame.from_dict(d)\n    df.to_parquet('schema/schema3.parquet')\n\nNow, the issue is that when I read the parquet files using pandas (\\`pd.read\\_parquet('schema/')\\`), I get 3 rows (correct) but also only 3 columns (wrong) - I would expect getting 4 columns as the last file introduced the new column. Polars cannot even read the files as it complains straight away about a different number of columns.\n\nPossible solutions that come to my mind:\n\n1. Have some python library where all schemas would be defined so I would use this defined schema (python class) and try to parse the input data using the class attributes and in case any attribute is missing put there a None value. But that could be pretty complicated to implement probably. I would probably have to iterate over the files one by one and check schema conformity.\n2. Iterate over the files one by one and then concatenate (union) them. (Not too different from the previous actually)\n3. Any better solution?\n\nHow do you handle such cases?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parquet schema evolution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c9zr5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677403826.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677403358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have the following scenario (lets imagine every step is daily data load):&lt;/p&gt;\n\n&lt;p&gt;Firstly, I save the parquet file with 3 columns &amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;d = {&amp;#39;a&amp;#39;:[1], &amp;#39;b&amp;#39;:[2], &amp;#39;c&amp;#39;:[3]}\ndf = pd.DataFrame.from_dict(d)\ndf.to_parquet(&amp;#39;schema/schema1.parquet&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then I save another file with only 2 columns &amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;d = {&amp;#39;a&amp;#39;:[1], &amp;#39;c&amp;#39;:[3]}\ndf = pd.DataFrame.from_dict(d)\ndf.to_parquet(&amp;#39;schema/schema2.parquet&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then I add another file with 4 columns &amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;d&amp;#39;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;d = {&amp;#39;a&amp;#39;:[1], &amp;#39;b&amp;#39;:[2], &amp;#39;c&amp;#39;:[3], &amp;#39;d&amp;#39;:[4]}\ndf = pd.DataFrame.from_dict(d)\ndf.to_parquet(&amp;#39;schema/schema3.parquet&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Now, the issue is that when I read the parquet files using pandas (`pd.read_parquet(&amp;#39;schema/&amp;#39;)`), I get 3 rows (correct) but also only 3 columns (wrong) - I would expect getting 4 columns as the last file introduced the new column. Polars cannot even read the files as it complains straight away about a different number of columns.&lt;/p&gt;\n\n&lt;p&gt;Possible solutions that come to my mind:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Have some python library where all schemas would be defined so I would use this defined schema (python class) and try to parse the input data using the class attributes and in case any attribute is missing put there a None value. But that could be pretty complicated to implement probably. I would probably have to iterate over the files one by one and check schema conformity.&lt;/li&gt;\n&lt;li&gt;Iterate over the files one by one and then concatenate (union) them. (Not too different from the previous actually)&lt;/li&gt;\n&lt;li&gt;Any better solution?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;How do you handle such cases?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11c9zr5", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c9zr5/parquet_schema_evolution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c9zr5/parquet_schema_evolution/", "subreddit_subscribers": 91223, "created_utc": 1677403358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI've read the book cover to cover. But things change, topics aren't covered to the level they could be, and, it's been some years since I actually built a DV2.0 warehouse. Hoping to have a couple of questions answered by the community.\n\nEasy one first - at what point do you apply business naming conventions to the fields? Is it when you get to the point of the star schema, or do you do it before?\n\nNext one is a bit more complex:\n\nI have a \\`hub\\_customer\\` table. It was built off a Kafka event. The business key is customer\\_id. I have the following columns:\n\n* customer\\_hash\\_key\n* load\\_date\n* record\\_source\n* customer\\_id\n\nAll good so far. \n\nWe now need to ingest customers from Salesforce, where data is maintained across the \\`account\\` and \\`contact\\` tables. My understanding is that this should go into the 'same' hub, with a same-as-link table that creates the relation between the Kafka customer and the Salesforce account/contact.\n\nHow would you suggest adding the Salesforce dataset into the vault? \n\nShould the original \\`hub\\_customer\\` actually have be named \\`hub\\_customer0001\\`, and a new \\`hub\\_customer0002\\` be created that now has the following columns:\n\n* customer\\_hash\\_key\n* load\\_date\n* record\\_source\n* customer\\_id\n* account\\_id\n* contact\\_id\n\nOr would you just add the new columns to the existing table, or would you simply concat the account\\_id and contact\\_id into the customer\\_id column that already exists?\n\nPresumably if you went with the option of a new version number hub, it would be back-populated from a Kafka perspective and the \\`sat\\_customer\\_kafka\\` would then be used against this moving forward, and a new \\`sat\\_account\\_sf\\` and \\`sat\\_contact\\_sf\\` would also be generated that would point back to this same hub?\n\nI hope that makes sense?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Vault modelling questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c5mf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677386815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read the book cover to cover. But things change, topics aren&amp;#39;t covered to the level they could be, and, it&amp;#39;s been some years since I actually built a DV2.0 warehouse. Hoping to have a couple of questions answered by the community.&lt;/p&gt;\n\n&lt;p&gt;Easy one first - at what point do you apply business naming conventions to the fields? Is it when you get to the point of the star schema, or do you do it before?&lt;/p&gt;\n\n&lt;p&gt;Next one is a bit more complex:&lt;/p&gt;\n\n&lt;p&gt;I have a `hub_customer` table. It was built off a Kafka event. The business key is customer_id. I have the following columns:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;customer_hash_key&lt;/li&gt;\n&lt;li&gt;load_date&lt;/li&gt;\n&lt;li&gt;record_source&lt;/li&gt;\n&lt;li&gt;customer_id&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;All good so far. &lt;/p&gt;\n\n&lt;p&gt;We now need to ingest customers from Salesforce, where data is maintained across the `account` and `contact` tables. My understanding is that this should go into the &amp;#39;same&amp;#39; hub, with a same-as-link table that creates the relation between the Kafka customer and the Salesforce account/contact.&lt;/p&gt;\n\n&lt;p&gt;How would you suggest adding the Salesforce dataset into the vault? &lt;/p&gt;\n\n&lt;p&gt;Should the original `hub_customer` actually have be named `hub_customer0001`, and a new `hub_customer0002` be created that now has the following columns:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;customer_hash_key&lt;/li&gt;\n&lt;li&gt;load_date&lt;/li&gt;\n&lt;li&gt;record_source&lt;/li&gt;\n&lt;li&gt;customer_id&lt;/li&gt;\n&lt;li&gt;account_id&lt;/li&gt;\n&lt;li&gt;contact_id&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Or would you just add the new columns to the existing table, or would you simply concat the account_id and contact_id into the customer_id column that already exists?&lt;/p&gt;\n\n&lt;p&gt;Presumably if you went with the option of a new version number hub, it would be back-populated from a Kafka perspective and the `sat_customer_kafka` would then be used against this moving forward, and a new `sat_account_sf` and `sat_contact_sf` would also be generated that would point back to this same hub?&lt;/p&gt;\n\n&lt;p&gt;I hope that makes sense?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11c5mf7", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c5mf7/data_vault_modelling_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c5mf7/data_vault_modelling_questions/", "subreddit_subscribers": 91223, "created_utc": 1677386815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3nak9yqd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tall Buildings Structural Systems And Aerodynamic Form", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11cx8kn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TR6I4PnR8j9_1AYo5WIqZbVDtg4p1mBfKPWcnc0Cz2w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677456375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "engineerrefe.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://engineerrefe.com/book/tall-buildings-structural-systems-and-aerodynamic-form/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yPekr8SdmaWLLJ7JpUkgOl7qpo0Lqu_Qi0NKUWTIYMQ.jpg?auto=webp&amp;v=enabled&amp;s=46e5e5168c653963b2f2fcc606172706e85913fe", "width": 604, "height": 857}, "resolutions": [{"url": "https://external-preview.redd.it/yPekr8SdmaWLLJ7JpUkgOl7qpo0Lqu_Qi0NKUWTIYMQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=149da4b25bfe0114e684d25426e573f91a1747fb", "width": 108, "height": 153}, {"url": "https://external-preview.redd.it/yPekr8SdmaWLLJ7JpUkgOl7qpo0Lqu_Qi0NKUWTIYMQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ca409e0afc44934deff573c0fd3e9f2eb45b4fb", "width": 216, "height": 306}, {"url": "https://external-preview.redd.it/yPekr8SdmaWLLJ7JpUkgOl7qpo0Lqu_Qi0NKUWTIYMQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=03e4359a59b610962771f4dfa80b71fd0f6f6e57", "width": 320, "height": 454}], "variants": {}, "id": "4FW_6fTpp2R7JH1zcAwq38eQDr_EKTg6NqrJJM4fZY8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11cx8kn", "is_robot_indexable": true, "report_reasons": null, "author": "ahmed1631993", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11cx8kn/tall_buildings_structural_systems_and_aerodynamic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://engineerrefe.com/book/tall-buildings-structural-systems-and-aerodynamic-form/", "subreddit_subscribers": 91223, "created_utc": 1677456375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there, I wanted to know how hard it is to start working as a data engineer and what tools I should learn.\nProvide some examples if possible :)\nThanks!", "author_fullname": "t2_5e5ycckj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard it is to break into Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11cwce3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677454209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, I wanted to know how hard it is to start working as a data engineer and what tools I should learn.\nProvide some examples if possible :)\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11cwce3", "is_robot_indexable": true, "report_reasons": null, "author": "alonmega100", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11cwce3/how_hard_it_is_to_break_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11cwce3/how_hard_it_is_to_break_into_data_engineering/", "subreddit_subscribers": 91223, "created_utc": 1677454209.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}