{"kind": "Listing", "data": {"after": "t3_10txeas", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been promoted twice to manager now of data science and I find myself in meetings talking more than I spend (if any) working on technical stuff\n\nIs this normal? I get paid almost $200k to say stuff \ud83e\udd14", "author_fullname": "t2_aji4iba3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal for data scientists to move to non technical roles as they move up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10trfwo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 155, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 155, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675545142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been promoted twice to manager now of data science and I find myself in meetings talking more than I spend (if any) working on technical stuff&lt;/p&gt;\n\n&lt;p&gt;Is this normal? I get paid almost $200k to say stuff \ud83e\udd14&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10trfwo", "is_robot_indexable": true, "report_reasons": null, "author": "whowasphones", "discussion_type": null, "num_comments": 83, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10trfwo/is_it_normal_for_data_scientists_to_move_to_non/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10trfwo/is_it_normal_for_data_scientists_to_move_to_non/", "subreddit_subscribers": 844922, "created_utc": 1675545142.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_cdrji8bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "isn't this just too much for a take home assignment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 128, "top_awarded_type": null, "hide_score": false, "name": "t3_10ueevu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 148, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 148, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XnRi7AnPeriE520osDIV_l4HSuSyW6V4Pqmgzwssu3U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675609107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/jdtrxsz2efga1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?auto=webp&amp;v=enabled&amp;s=0985c44cfb4efe1d0d8d1b2de411f169d1397444", "width": 1080, "height": 988}, "resolutions": [{"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9778e6b16ef078d8351f11b5bc596c767f347c61", "width": 108, "height": 98}, {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e324d275de5af34fb37faf87ebba87c31511359e", "width": 216, "height": 197}, {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=877115ce24bf001cacfab00f83aa24e614986e24", "width": 320, "height": 292}, {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c83730ae4f0e3084cc0fd0199364a1152fbdba7a", "width": 640, "height": 585}, {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=796a00f9173ceee148da202d9b210376e44d156d", "width": 960, "height": 878}, {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66778d27c72b94c31cc1cf62b358cfa6a6060739", "width": 1080, "height": 988}], "variants": {}, "id": "E6xrcS-8woaqKln1AI0fuEzDUlz5ZTUf60J2TsPbvy4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ueevu", "is_robot_indexable": true, "report_reasons": null, "author": "questionaboutpsy", "discussion_type": null, "num_comments": 144, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ueevu/isnt_this_just_too_much_for_a_take_home_assignment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/jdtrxsz2efga1.jpg", "subreddit_subscribers": 844922, "created_utc": 1675609107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for a small engineering firm. I have been tasked by my CEO to train an AI to solve what is essentially a regression problem (although he doesn't know that, he just wants it to \"make predictions.\" AI/ML is not his expertise). There are only 4 features (all numerical) to this dataset, but unfortunately there are also only 25 samples. Collecting test samples for this application is expensive, and no relevant public data exists. In a few months, we should be able to collect 25-30 more samples. There will not be another chance after that to collect more data before the contract ends. It also doesn't help that I'm not even sure we can trust that the data we do have was collected properly (there are some serious anomalies) but that's besides the point I guess.\n\nI've tried explaining to my CEO why this is extremely difficult to work with and why it is hard to trust the predictions of the model. He says that we get paid to do the impossible. I cannot seem to convince him or get him to understand how absurdly small 25 samples is for training an AI model. He originally wanted us to use a deep neural net. Right now I'm trying a simple ANN (mostly to placate him) and also a support vector machine. \n\nAny advice on how to handle this, whether technically or professionally? Are there better models or any standard practices for when working with such limited data? Any way I can explain to my boss when this inevitably fails why it's not my fault?", "author_fullname": "t2_ll6fgzm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working with extremely limited data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u61v7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675579221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a small engineering firm. I have been tasked by my CEO to train an AI to solve what is essentially a regression problem (although he doesn&amp;#39;t know that, he just wants it to &amp;quot;make predictions.&amp;quot; AI/ML is not his expertise). There are only 4 features (all numerical) to this dataset, but unfortunately there are also only 25 samples. Collecting test samples for this application is expensive, and no relevant public data exists. In a few months, we should be able to collect 25-30 more samples. There will not be another chance after that to collect more data before the contract ends. It also doesn&amp;#39;t help that I&amp;#39;m not even sure we can trust that the data we do have was collected properly (there are some serious anomalies) but that&amp;#39;s besides the point I guess.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried explaining to my CEO why this is extremely difficult to work with and why it is hard to trust the predictions of the model. He says that we get paid to do the impossible. I cannot seem to convince him or get him to understand how absurdly small 25 samples is for training an AI model. He originally wanted us to use a deep neural net. Right now I&amp;#39;m trying a simple ANN (mostly to placate him) and also a support vector machine. &lt;/p&gt;\n\n&lt;p&gt;Any advice on how to handle this, whether technically or professionally? Are there better models or any standard practices for when working with such limited data? Any way I can explain to my boss when this inevitably fails why it&amp;#39;s not my fault?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10u61v7", "is_robot_indexable": true, "report_reasons": null, "author": "CyanDean", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10u61v7/working_with_extremely_limited_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10u61v7/working_with_extremely_limited_data/", "subreddit_subscribers": 844922, "created_utc": 1675579221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to see which house prices in my dataset are outliers based on other feature columns like sqft, waterfront or year built. \n\nSome of these are more important and play significant role on deciding if a data point is an outlier. \n\nWhat is the logic/literature behind this? How can I go about building this code?", "author_fullname": "t2_m826ekr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multivariate Outlier Detection in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u7wfw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675586319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to see which house prices in my dataset are outliers based on other feature columns like sqft, waterfront or year built. &lt;/p&gt;\n\n&lt;p&gt;Some of these are more important and play significant role on deciding if a data point is an outlier. &lt;/p&gt;\n\n&lt;p&gt;What is the logic/literature behind this? How can I go about building this code?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10u7wfw", "is_robot_indexable": true, "report_reasons": null, "author": "Utterizi", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10u7wfw/multivariate_outlier_detection_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10u7wfw/multivariate_outlier_detection_in_python/", "subreddit_subscribers": 844922, "created_utc": 1675586319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m assuming network science and data science share some ties so asking here. I know it\u2019s a newer field but I\u2019m still surprised it isn\u2019t more prominent. Ex there\u2019s not even a functioning subreddit for it", "author_fullname": "t2_10l3hp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone know why network science isn\u2019t a more popular discipline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tyivq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675563981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m assuming network science and data science share some ties so asking here. I know it\u2019s a newer field but I\u2019m still surprised it isn\u2019t more prominent. Ex there\u2019s not even a functioning subreddit for it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tyivq", "is_robot_indexable": true, "report_reasons": null, "author": "tropicalparzival", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tyivq/anyone_know_why_network_science_isnt_a_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tyivq/anyone_know_why_network_science_isnt_a_more/", "subreddit_subscribers": 844922, "created_utc": 1675563981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I read before on Reddit as well as on blog posts about data science professionals landing a job and thinking that they finally get to apply their skills to do something cool, when they had to instead do analysis on excel. \n\nAlso data scientists in some companies who aren\u2019t sure what goal they are hired to achieve. Or they don\u2019t even have the right data to work on. Or their work never makes it to production because of some reason or another. And they get disillusioned.\n\nRecently I came across this post on data science in finance. And the description looks pretty interesting. \n\nhttps://careerfoundry.com/en/blog/data-analytics/data-science-in-finance/\n\nAre any current Data science professionals who are in the financial industry. Who can shed some light on this? \n\nIs the work really as described? Or is it better? \n\nDo you get interesting problems to work on? \n\nDo you feel you get an opportunity to make an impact with your work? \n\nDo your models make it to production?", "author_fullname": "t2_kxuu98cn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do data scientists in the financial industry really get to do this cool stuff?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u8jio", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675588918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read before on Reddit as well as on blog posts about data science professionals landing a job and thinking that they finally get to apply their skills to do something cool, when they had to instead do analysis on excel. &lt;/p&gt;\n\n&lt;p&gt;Also data scientists in some companies who aren\u2019t sure what goal they are hired to achieve. Or they don\u2019t even have the right data to work on. Or their work never makes it to production because of some reason or another. And they get disillusioned.&lt;/p&gt;\n\n&lt;p&gt;Recently I came across this post on data science in finance. And the description looks pretty interesting. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://careerfoundry.com/en/blog/data-analytics/data-science-in-finance/\"&gt;https://careerfoundry.com/en/blog/data-analytics/data-science-in-finance/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Are any current Data science professionals who are in the financial industry. Who can shed some light on this? &lt;/p&gt;\n\n&lt;p&gt;Is the work really as described? Or is it better? &lt;/p&gt;\n\n&lt;p&gt;Do you get interesting problems to work on? &lt;/p&gt;\n\n&lt;p&gt;Do you feel you get an opportunity to make an impact with your work? &lt;/p&gt;\n\n&lt;p&gt;Do your models make it to production?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?auto=webp&amp;v=enabled&amp;s=b1f342a687094de675f38a3e1341bf42c650e76d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4727ec8b4b2e5fc969314fc8266ea394739d8b72", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=308b97f9105b3d61c1643e7574f2d47ab264a8f8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63f7f446d229be98f5fe796d53520d6fee17a829", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=893f0a3204b4464fd58384ebee7bc9c1412a49ab", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90b27af958090d65f4f044916ece584e64c0d794", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb3198f892353fe206a82b36e271cb6653aff306", "width": 1080, "height": 540}], "variants": {}, "id": "pxpxKEZtpLgEYvmWS0rEj_u-yqmAkUOclPNab-nMANI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10u8jio", "is_robot_indexable": true, "report_reasons": null, "author": "lnfrarad", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10u8jio/do_data_scientists_in_the_financial_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10u8jio/do_data_scientists_in_the_financial_industry/", "subreddit_subscribers": 844922, "created_utc": 1675588918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There are a lot of things going on in the field, how to you keep track of all the new stuff coming up. \n\nMy main resource at the moment is my linkedIn feed with focused research after finding something interesting.", "author_fullname": "t2_ds7pgpee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Staying up to date after graduation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tu44b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675551885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are a lot of things going on in the field, how to you keep track of all the new stuff coming up. &lt;/p&gt;\n\n&lt;p&gt;My main resource at the moment is my linkedIn feed with focused research after finding something interesting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tu44b", "is_robot_indexable": true, "report_reasons": null, "author": "Tukdu", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tu44b/staying_up_to_date_after_graduation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tu44b/staying_up_to_date_after_graduation/", "subreddit_subscribers": 844922, "created_utc": 1675551885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I've watched a few tutorials on topic modeling in Python, with some open source libraries (gensim, spacy, etc). What I want to be able to do is tag a large group of reviews (such as yelp reviews) with one or more appropriately named topics. In the [above mentioned tutorials](https://youtu.be/UEn3xHNBXJU?t=867) I see the results as clusters that contain common terms, but I don't yet see how to go about adding an appropriate name to these clusters, and then ultimately assigning this name, or tag, back to individual reviews. How do I get from the initial analysis (LDA or what have you), to actually tagging a review with one or more appropriate categories? For example, a review talking about how expensive a hamburger is, might get assigned a \"price\" tag/category. Maybe LDA isn't the right method? Thanks for your tips and/or recommended tutorials!", "author_fullname": "t2_z075s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP: naming topics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tr7zr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675544875.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675544583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;ve watched a few tutorials on topic modeling in Python, with some open source libraries (gensim, spacy, etc). What I want to be able to do is tag a large group of reviews (such as yelp reviews) with one or more appropriately named topics. In the &lt;a href=\"https://youtu.be/UEn3xHNBXJU?t=867\"&gt;above mentioned tutorials&lt;/a&gt; I see the results as clusters that contain common terms, but I don&amp;#39;t yet see how to go about adding an appropriate name to these clusters, and then ultimately assigning this name, or tag, back to individual reviews. How do I get from the initial analysis (LDA or what have you), to actually tagging a review with one or more appropriate categories? For example, a review talking about how expensive a hamburger is, might get assigned a &amp;quot;price&amp;quot; tag/category. Maybe LDA isn&amp;#39;t the right method? Thanks for your tips and/or recommended tutorials!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jVTARUg3iTtvmYrVAujuKvGg4Gzsxj-WRpJgwnO7_XI.jpg?auto=webp&amp;v=enabled&amp;s=3658bcd4877612422d23235b8db678090d990d6a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/jVTARUg3iTtvmYrVAujuKvGg4Gzsxj-WRpJgwnO7_XI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69631c225060a3f0e6103f258394901054dfa227", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/jVTARUg3iTtvmYrVAujuKvGg4Gzsxj-WRpJgwnO7_XI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d80d05728c007c6050747177975e48bc6878803", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/jVTARUg3iTtvmYrVAujuKvGg4Gzsxj-WRpJgwnO7_XI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a047e862301da93e9c39613205b9a2b505c09166", "width": 320, "height": 240}], "variants": {}, "id": "pi2z2Pelp3SX_k0jIvGaPYOqkKb7lrZb4a1lg9essRw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tr7zr", "is_robot_indexable": true, "report_reasons": null, "author": "mogla", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tr7zr/nlp_naming_topics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tr7zr/nlp_naming_topics/", "subreddit_subscribers": 844922, "created_utc": 1675544583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys,\n\nI'm a junior in an undergrad BS Data Science program at a small Christian university in the Midwest. I've been searching for a summer internship in Data Science/Data Analytics since September and have had no luck. I've reached out to people in my network and those of my family and professors wherever possible, and I've visited my university's career center several times for resume revisions and have adopted the various strategies they have suggested. I've submitted somewhere in the ballpark of 200 applications in the last 6 months, and I've been ghosted by most recruiters. Of the 200 applications, I received 4 callbacks for interviews, and of those 4, only 1 resulted in a follow-up interview. For this last position, I was well-prepared and felt that I performed well in both interviews, but alas, I finally received yet another rejection letter last week.\n\nI'm frustrated and disappointed, to say the least. I understand that these numbers are pretty typical in the current tech job market, and other Redditors frequently call it a \"numbers game.\" While merely continuing a barrage of new applications may work for new graduates and recently laid-off junior positions, I'm fighting against time since I'm looking for a summer internship that ends before I resume classes in the fall. At this current rate, I'd have to submit another 50 applications to get a chance of even one more interview, which is incredibly time-consuming. The job search process wore me out months ago - I'm discouraged and exhausted - and it takes valuable time away from actually practicing my skills and learning new topics. On top of that, it already feels too late. My academic advisor told me in October to try to have something figured out by the end of December since many internship positions would already be filled beyond that point. It's now February. If my odds were bad 6 months ago, it's only going to get worse.\n\nI'm kind of at my wits' end. I also am approaching the point where I need to have some concrete summer plans so I can coordinate schedules with family and friends, not just \"I'm looking for an internship\" because that doesn't seem to be panning out. Here are a few of my options:\n\n1. Go back to the summer camp where I worked for the last two years.\n   1. Pros: I already have friends there and I'm 99% guaranteed a job if I apply. I'll also be on the West Coast, which is where I want to be.\n   2. Cons: The pay is little more than a volunteer stipend. I won't have much opportunity to develop tech skills or otherwise advance my career.\n2. Stay at home for the summer. I could split my time between learning through online MOOCs and potentially look for a low-skill job such as administrative assistant or data entry. Or a gig like Doordash. \n   1. Pros: I can live with my family for free. I'll also be on the West Coast and will have the flexibility to pursue my outdoor hobbies while working on tech skills. The wage floor is also pretty high in my state.\n   2. Cons: There's no guarantee that I can find a job, especially for something that only lasts the summer when employers may be wanting something more permanent. It also feels kind of humiliating that I failed to find a job in my industry?\n3. Look for internships in adjacent fields that involve data. I've seen this suggested to people looking to make a career switch but I'm not sure if these exist or if they will work for me. I also won't have the mentorship in DS/DA that I'm specifically looking for. \n\nWhat factors should I take into consideration when I look at my options for this summer? Is there anything else as far as career development that I should also think about? \n\nI'm also wondering if the current scarcity of tech positions is homogeneous across the industry. DS doesn't seem as attractive as it was a few years ago, and now I feel unsure about all of my career/academic choices to date.\n\nFirst, I feel like DS was hyped up to more than it was when I first started college as a freshman, and now it seems that a lot of people on the internet also think that it's now on the decline. It also seems to be the consensus that the best path into DS is through a more established undergrad program in CS, Math, or Stats, rather than a DS degree because they tend to be so broad in nature that you learn a little bit about many topics but nothing sufficiently in-depth to be useful. Unfortunately, that seems to be my experience - I don't feel like I'm learning anything in classes so I'm taking time outside of class to work on Kaggle Learn courses and the Andrew Ng Coursera ML course. If I could go back in time, I would have gone into CS and started at a different university. I'm not particularly fond of my university or the Midwest (I long to be back on the West Coast) and it's a long story of how I ended up here, but suffice it to say that the reason I'm still here is because I'm on a full-tuition scholarship which I'd lose if I transferred elsewhere. But I can't go back in time. I'm a junior and should be graduating in two more semesters after this semester, so I had been OK with sticking it out under the assumption that I could get a decent job when I graduate and move back to the West Coast. But I'm at the point where I question if any of that is true. \n\nSecond, I'm not even sure anymore if this is really what I want to do. In my senior year of high school I became really interested in finance, and DS seemed like the perfect way to join my long standing interest in tech with what a growing interest in math (which, sidenote, may have died after I took Intro to Linear Algebra. I like to think it was just a bad professor) and my new interest in business topics. In the last semester or so, I've clarified my long-term goals and want to break into the ML field and eventually become an MLE. However, in working with scikit-learn and other ML frameworks in Kaggle Learn courses, it feels dull and I'm just doing it because I have gaps in my knowledge. I don't really find myself loving it. Is this normal? I know it's preferable to work on my own projects rather than repetitive activities, but I still don't feel that I know enough skills to work on my own projects. I often wonder if I'd be better off in a more standard CS track towards become an SWE or backend web dev. But there's huge gaps in my knowledge there as well. And if I switch majors, I'll probably have to take an extra semester or two because my current DS requirements don't include any of the dev, networking, or security classes. \n\nI guess to summarize, I went into this degree track with certain expectations and everything has turned out to be a disappointment. I'm not sure what to do anymore because although I'm willing to work hard, it's difficult to maintain the motivation to do so when I'm not sure if everything I'm doing is mere futility. Thanks for taking the time to read through all this and I appreciate any advice/feedback you may have.", "author_fullname": "t2_s15825ic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Failed internship search in a difficult job market: Bad timing or is DS a bubble?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ulcdc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675626029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a junior in an undergrad BS Data Science program at a small Christian university in the Midwest. I&amp;#39;ve been searching for a summer internship in Data Science/Data Analytics since September and have had no luck. I&amp;#39;ve reached out to people in my network and those of my family and professors wherever possible, and I&amp;#39;ve visited my university&amp;#39;s career center several times for resume revisions and have adopted the various strategies they have suggested. I&amp;#39;ve submitted somewhere in the ballpark of 200 applications in the last 6 months, and I&amp;#39;ve been ghosted by most recruiters. Of the 200 applications, I received 4 callbacks for interviews, and of those 4, only 1 resulted in a follow-up interview. For this last position, I was well-prepared and felt that I performed well in both interviews, but alas, I finally received yet another rejection letter last week.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m frustrated and disappointed, to say the least. I understand that these numbers are pretty typical in the current tech job market, and other Redditors frequently call it a &amp;quot;numbers game.&amp;quot; While merely continuing a barrage of new applications may work for new graduates and recently laid-off junior positions, I&amp;#39;m fighting against time since I&amp;#39;m looking for a summer internship that ends before I resume classes in the fall. At this current rate, I&amp;#39;d have to submit another 50 applications to get a chance of even one more interview, which is incredibly time-consuming. The job search process wore me out months ago - I&amp;#39;m discouraged and exhausted - and it takes valuable time away from actually practicing my skills and learning new topics. On top of that, it already feels too late. My academic advisor told me in October to try to have something figured out by the end of December since many internship positions would already be filled beyond that point. It&amp;#39;s now February. If my odds were bad 6 months ago, it&amp;#39;s only going to get worse.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m kind of at my wits&amp;#39; end. I also am approaching the point where I need to have some concrete summer plans so I can coordinate schedules with family and friends, not just &amp;quot;I&amp;#39;m looking for an internship&amp;quot; because that doesn&amp;#39;t seem to be panning out. Here are a few of my options:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Go back to the summer camp where I worked for the last two years.\n\n&lt;ol&gt;\n&lt;li&gt;Pros: I already have friends there and I&amp;#39;m 99% guaranteed a job if I apply. I&amp;#39;ll also be on the West Coast, which is where I want to be.&lt;/li&gt;\n&lt;li&gt;Cons: The pay is little more than a volunteer stipend. I won&amp;#39;t have much opportunity to develop tech skills or otherwise advance my career.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Stay at home for the summer. I could split my time between learning through online MOOCs and potentially look for a low-skill job such as administrative assistant or data entry. Or a gig like Doordash. \n\n&lt;ol&gt;\n&lt;li&gt;Pros: I can live with my family for free. I&amp;#39;ll also be on the West Coast and will have the flexibility to pursue my outdoor hobbies while working on tech skills. The wage floor is also pretty high in my state.&lt;/li&gt;\n&lt;li&gt;Cons: There&amp;#39;s no guarantee that I can find a job, especially for something that only lasts the summer when employers may be wanting something more permanent. It also feels kind of humiliating that I failed to find a job in my industry?&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Look for internships in adjacent fields that involve data. I&amp;#39;ve seen this suggested to people looking to make a career switch but I&amp;#39;m not sure if these exist or if they will work for me. I also won&amp;#39;t have the mentorship in DS/DA that I&amp;#39;m specifically looking for. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What factors should I take into consideration when I look at my options for this summer? Is there anything else as far as career development that I should also think about? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also wondering if the current scarcity of tech positions is homogeneous across the industry. DS doesn&amp;#39;t seem as attractive as it was a few years ago, and now I feel unsure about all of my career/academic choices to date.&lt;/p&gt;\n\n&lt;p&gt;First, I feel like DS was hyped up to more than it was when I first started college as a freshman, and now it seems that a lot of people on the internet also think that it&amp;#39;s now on the decline. It also seems to be the consensus that the best path into DS is through a more established undergrad program in CS, Math, or Stats, rather than a DS degree because they tend to be so broad in nature that you learn a little bit about many topics but nothing sufficiently in-depth to be useful. Unfortunately, that seems to be my experience - I don&amp;#39;t feel like I&amp;#39;m learning anything in classes so I&amp;#39;m taking time outside of class to work on Kaggle Learn courses and the Andrew Ng Coursera ML course. If I could go back in time, I would have gone into CS and started at a different university. I&amp;#39;m not particularly fond of my university or the Midwest (I long to be back on the West Coast) and it&amp;#39;s a long story of how I ended up here, but suffice it to say that the reason I&amp;#39;m still here is because I&amp;#39;m on a full-tuition scholarship which I&amp;#39;d lose if I transferred elsewhere. But I can&amp;#39;t go back in time. I&amp;#39;m a junior and should be graduating in two more semesters after this semester, so I had been OK with sticking it out under the assumption that I could get a decent job when I graduate and move back to the West Coast. But I&amp;#39;m at the point where I question if any of that is true. &lt;/p&gt;\n\n&lt;p&gt;Second, I&amp;#39;m not even sure anymore if this is really what I want to do. In my senior year of high school I became really interested in finance, and DS seemed like the perfect way to join my long standing interest in tech with what a growing interest in math (which, sidenote, may have died after I took Intro to Linear Algebra. I like to think it was just a bad professor) and my new interest in business topics. In the last semester or so, I&amp;#39;ve clarified my long-term goals and want to break into the ML field and eventually become an MLE. However, in working with scikit-learn and other ML frameworks in Kaggle Learn courses, it feels dull and I&amp;#39;m just doing it because I have gaps in my knowledge. I don&amp;#39;t really find myself loving it. Is this normal? I know it&amp;#39;s preferable to work on my own projects rather than repetitive activities, but I still don&amp;#39;t feel that I know enough skills to work on my own projects. I often wonder if I&amp;#39;d be better off in a more standard CS track towards become an SWE or backend web dev. But there&amp;#39;s huge gaps in my knowledge there as well. And if I switch majors, I&amp;#39;ll probably have to take an extra semester or two because my current DS requirements don&amp;#39;t include any of the dev, networking, or security classes. &lt;/p&gt;\n\n&lt;p&gt;I guess to summarize, I went into this degree track with certain expectations and everything has turned out to be a disappointment. I&amp;#39;m not sure what to do anymore because although I&amp;#39;m willing to work hard, it&amp;#39;s difficult to maintain the motivation to do so when I&amp;#39;m not sure if everything I&amp;#39;m doing is mere futility. Thanks for taking the time to read through all this and I appreciate any advice/feedback you may have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ulcdc", "is_robot_indexable": true, "report_reasons": null, "author": "mountainstarpenguin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ulcdc/failed_internship_search_in_a_difficult_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ulcdc/failed_internship_search_in_a_difficult_job/", "subreddit_subscribers": 844922, "created_utc": 1675626029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3op9qx89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science managers, what core skills (and to what depth of knowledge) are you looking for in a Data Scientist hire in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ul9n4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675625837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ul9n4", "is_robot_indexable": true, "report_reasons": null, "author": "LatterConcentrate6", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ul9n4/data_science_managers_what_core_skills_and_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ul9n4/data_science_managers_what_core_skills_and_to/", "subreddit_subscribers": 844922, "created_utc": 1675625837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m looking for data collection tool suggestions. We periodically need to collect data from teams via drop downs and free fields and Excel is proving difficult to manage (people keep deleting things, changing formulas, etc). Does anyone have any experience with another data collection tool?\n\nIdeally this tool would save the question results and the team could go back and see what the entered originally and make changes when we repeat the exercise, which we plan on doing a few times a year.", "author_fullname": "t2_qnn4s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Collection Tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10uk3la", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675625519.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675623074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for data collection tool suggestions. We periodically need to collect data from teams via drop downs and free fields and Excel is proving difficult to manage (people keep deleting things, changing formulas, etc). Does anyone have any experience with another data collection tool?&lt;/p&gt;\n\n&lt;p&gt;Ideally this tool would save the question results and the team could go back and see what the entered originally and make changes when we repeat the exercise, which we plan on doing a few times a year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uk3la", "is_robot_indexable": true, "report_reasons": null, "author": "Aoiumi1234", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uk3la/data_collection_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uk3la/data_collection_tool/", "subreddit_subscribers": 844922, "created_utc": 1675623074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to come up with a feature/set of features, and getting a bit stuck. For the purpose of this question lets say its the ratio of number of times a person clicks on an ad (abbreviated ac) on a website/ time they are on the website.  Here is an example of what I'm thinking about:\n\nsubject 1:  3 hrs on reddit, 2 ac.  One hour on facebook, 5 ac\n\nsubject 2: 1 hour on reddit, 0 ac, three hours on twitter, 2 ac\n\nsubject 3:  5 hours on live journal, 1 ac.\n\nIn this example I would create 4 features:  ac/hour reddit, ac/hour facebook, ac/hour twitter, and ac/hour livejournal.   I'm having trouble with the fact that these four features will have a lot of missing data.  In this particular example, pretend that I've collapsed the webiste categories as much as possible.   What are some other options of dealing with the data?  How does one use data like this in a model without imputing the missing values? I'm open to not using a ratio for this feature set - but I do want exposure to the website to be included somehow.\n\nThanks!\n\nEdited to add, the missingness comes from the situation when someone has 0 hours on the website, its 0 clicks/0 hours so its undefined. This is a different situation than a zero someone who is on the webiste for 5 hours but never clicked on an ad.", "author_fullname": "t2_14fn4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stuck on a feature engineering problem with missing data.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uiv7r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675621876.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675620151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to come up with a feature/set of features, and getting a bit stuck. For the purpose of this question lets say its the ratio of number of times a person clicks on an ad (abbreviated ac) on a website/ time they are on the website.  Here is an example of what I&amp;#39;m thinking about:&lt;/p&gt;\n\n&lt;p&gt;subject 1:  3 hrs on reddit, 2 ac.  One hour on facebook, 5 ac&lt;/p&gt;\n\n&lt;p&gt;subject 2: 1 hour on reddit, 0 ac, three hours on twitter, 2 ac&lt;/p&gt;\n\n&lt;p&gt;subject 3:  5 hours on live journal, 1 ac.&lt;/p&gt;\n\n&lt;p&gt;In this example I would create 4 features:  ac/hour reddit, ac/hour facebook, ac/hour twitter, and ac/hour livejournal.   I&amp;#39;m having trouble with the fact that these four features will have a lot of missing data.  In this particular example, pretend that I&amp;#39;ve collapsed the webiste categories as much as possible.   What are some other options of dealing with the data?  How does one use data like this in a model without imputing the missing values? I&amp;#39;m open to not using a ratio for this feature set - but I do want exposure to the website to be included somehow.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;Edited to add, the missingness comes from the situation when someone has 0 hours on the website, its 0 clicks/0 hours so its undefined. This is a different situation than a zero someone who is on the webiste for 5 hours but never clicked on an ad.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uiv7r", "is_robot_indexable": true, "report_reasons": null, "author": "Ohio_Bean", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uiv7r/stuck_on_a_feature_engineering_problem_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uiv7r/stuck_on_a_feature_engineering_problem_with/", "subreddit_subscribers": 844922, "created_utc": 1675620151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello people! I hope my question is appropriate for this community. I have the following plot (figure), and I would like to show that in the central region there is a linear pattern, and find the correct line with linear regression (I know how to do linear regression). \n\nThe problem here is how do I decide to exclude the data that stands on a line parallel to y axis or x axis? Is there any statistical test to do that?\n\nThe data is the measure of two continuous variables, so there is not an \"a priori\" method to exclude some of them. \n\nThank you in advance!", "author_fullname": "t2_nuspi80u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to distinguish between 3 linear regressions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uieee", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675619013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello people! I hope my question is appropriate for this community. I have the following plot (figure), and I would like to show that in the central region there is a linear pattern, and find the correct line with linear regression (I know how to do linear regression). &lt;/p&gt;\n\n&lt;p&gt;The problem here is how do I decide to exclude the data that stands on a line parallel to y axis or x axis? Is there any statistical test to do that?&lt;/p&gt;\n\n&lt;p&gt;The data is the measure of two continuous variables, so there is not an &amp;quot;a priori&amp;quot; method to exclude some of them. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uieee", "is_robot_indexable": true, "report_reasons": null, "author": "Trattopino", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uieee/how_to_distinguish_between_3_linear_regressions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uieee/how_to_distinguish_between_3_linear_regressions/", "subreddit_subscribers": 844922, "created_utc": 1675619013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHi,\n\nFor those who struggle with all the GitLab/GitHub commands in the Internet, this article will give you nearly all you need in your daily work. The targeted audience is Data Scientist/Data Engineer, with no experience or medium experience with Git.\n\n[8 minutes to cover 99 of your Git needs](https://medium.com/towards-data-science/8-minutes-to-cover-99-of-your-git-needs-2c904c43590a)", "author_fullname": "t2_ssf8k2ti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitLab/GitHub survival kit for noobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ufcxo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675611526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;For those who struggle with all the GitLab/GitHub commands in the Internet, this article will give you nearly all you need in your daily work. The targeted audience is Data Scientist/Data Engineer, with no experience or medium experience with Git.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/towards-data-science/8-minutes-to-cover-99-of-your-git-needs-2c904c43590a\"&gt;8 minutes to cover 99 of your Git needs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?auto=webp&amp;v=enabled&amp;s=fcbe6260658080408ba0815f24355835547f5bd4", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55326b67339827aa92eb4223a65f3bc6dadb7ce6", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a57870679304b43b391df0e2f9caf42a85f78d3", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bafbd70fa4e880ec0728502774b9910a1246b1d0", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d31d0d812d7c54e8ca75cb2f8e6c2a7742a53ba0", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0077063957792017bd30a97c21d426f0159ca9d9", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc084837e71f56f02dadfb772cf01269e6f5b1f6", "width": 1080, "height": 720}], "variants": {}, "id": "Lvsd3i4VAfg5ik6r83gGp6xjxoSWoyC3D9SdzOS1CqQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ufcxo", "is_robot_indexable": true, "report_reasons": null, "author": "Arli84", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ufcxo/gitlabgithub_survival_kit_for_noobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ufcxo/gitlabgithub_survival_kit_for_noobs/", "subreddit_subscribers": 844922, "created_utc": 1675611526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently we're just using google sheets to document stuff and while its working, it's been a hassle keeping it up. A miss in the updates can break the whole thing, which can be frustrating rather than focusing on my tests. Also it becomes tedious too when someone checks up on it and it takes a long time to backtrack on everything.\n\nWe've tried using the timeline feature or tasking in Asana but its quite tedious as well to track and keep tickets or are we just doing it wrong? Lately we've been planning on trying out to setup like a kanban thing but just wondering if there are any best practices for this?", "author_fullname": "t2_7u37sy3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What practices/tools/platforms are best on documenting undergoing tests (AB tests, and etc.) and strategies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u9kkw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675593106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently we&amp;#39;re just using google sheets to document stuff and while its working, it&amp;#39;s been a hassle keeping it up. A miss in the updates can break the whole thing, which can be frustrating rather than focusing on my tests. Also it becomes tedious too when someone checks up on it and it takes a long time to backtrack on everything.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve tried using the timeline feature or tasking in Asana but its quite tedious as well to track and keep tickets or are we just doing it wrong? Lately we&amp;#39;ve been planning on trying out to setup like a kanban thing but just wondering if there are any best practices for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10u9kkw", "is_robot_indexable": true, "report_reasons": null, "author": "Aggressive-Pup-28", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10u9kkw/what_practicestoolsplatforms_are_best_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10u9kkw/what_practicestoolsplatforms_are_best_on/", "subreddit_subscribers": 844922, "created_utc": 1675593106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How I sometimes feel about Data Science... anybody know the quote?\n\n\"...some day the piecing together of dissociated knowledge will open up such terrifying vistas of reality, and of our frightful position therein, that we shall either go mad from the revelation or flee from the deadly light into the peace and safety of a new dark age.\"", "author_fullname": "t2_pl4q8ng7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "a placid island of ignorance in the midst of black seas of infinity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uht0x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675617608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How I sometimes feel about Data Science... anybody know the quote?&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;...some day the piecing together of dissociated knowledge will open up such terrifying vistas of reality, and of our frightful position therein, that we shall either go mad from the revelation or flee from the deadly light into the peace and safety of a new dark age.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uht0x", "is_robot_indexable": true, "report_reasons": null, "author": "droppedorphan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uht0x/a_placid_island_of_ignorance_in_the_midst_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uht0x/a_placid_island_of_ignorance_in_the_midst_of/", "subreddit_subscribers": 844922, "created_utc": 1675617608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am learning to use SQL server. I am trying to create a catalog but get the following highlighted error. Have tried searching for the solution couldn't solve it. Please HELP.\n\nhttps://preview.redd.it/4muv1k1brcga1.png?width=1689&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c4fe922dea4efa6fe772f498751deda348c86755", "author_fullname": "t2_7d59jl16", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with MS SQL Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4muv1k1brcga1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef1f77a3df412e367407909de948c593ce004d7f"}, {"y": 94, "x": 216, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=897522d4750e603fa0e99ee04c22facaf1fc2b53"}, {"y": 140, "x": 320, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0e31d574314b709a63102eb4d6ee8977c62b2e4"}, {"y": 281, "x": 640, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1767a0cec2de7ffd4b9437c9b5315b66d8e0fb5c"}, {"y": 421, "x": 960, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8da764bbfe7f013436d7e79c101aab3e907f112f"}, {"y": 474, "x": 1080, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ac1815401aa272a9385ae472ff1b93775b3acc9"}], "s": {"y": 742, "x": 1689, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=1689&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c4fe922dea4efa6fe772f498751deda348c86755"}, "id": "4muv1k1brcga1"}}, "name": "t3_10ua3yf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WvJ-7fpbXA6W6HNNu2RWjt0i9hzdATaA0DJOPllYGhU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675595270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning to use SQL server. I am trying to create a catalog but get the following highlighted error. Have tried searching for the solution couldn&amp;#39;t solve it. Please HELP.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4muv1k1brcga1.png?width=1689&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c4fe922dea4efa6fe772f498751deda348c86755\"&gt;https://preview.redd.it/4muv1k1brcga1.png?width=1689&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c4fe922dea4efa6fe772f498751deda348c86755&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ua3yf", "is_robot_indexable": true, "report_reasons": null, "author": "yujshr", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ua3yf/need_help_with_ms_sql_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ua3yf/need_help_with_ms_sql_server/", "subreddit_subscribers": 844922, "created_utc": 1675595270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is there anyone using Rust in Data Science? In which applications and when could I use rust instead of python?", "author_fullname": "t2_4kmmt5rr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone using Rust in Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ujkv5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675626088.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675621838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there anyone using Rust in Data Science? In which applications and when could I use rust instead of python?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ujkv5", "is_robot_indexable": true, "report_reasons": null, "author": "diepala", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ujkv5/is_anyone_using_rust_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ujkv5/is_anyone_using_rust_in_data_science/", "subreddit_subscribers": 844922, "created_utc": 1675621838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you know RPA experts or IT companies with RPA experience in LATAM region? Looking for new partners for PIXRPA.", "author_fullname": "t2_ng6r5urd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RPA advice needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uinbv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675619632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you know RPA experts or IT companies with RPA experience in LATAM region? Looking for new partners for PIXRPA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uinbv", "is_robot_indexable": true, "report_reasons": null, "author": "vkadimirvi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uinbv/rpa_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uinbv/rpa_advice_needed/", "subreddit_subscribers": 844922, "created_utc": 1675619632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2hocwgkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What product or service could be sold by data science professionals at scale?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uho9q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675617289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uho9q", "is_robot_indexable": true, "report_reasons": null, "author": "Mark_Collins", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uho9q/what_product_or_service_could_be_sold_by_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uho9q/what_product_or_service_could_be_sold_by_data/", "subreddit_subscribers": 844922, "created_utc": 1675617289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I am interested in the tools and framework (in particular automation tools) everyone uses when working with big data. I am a solution engineer, but always wanted to be a data analyst or data scientist because I believe that data can be harnessed for many practical application e.g., (chatgpt craze). Regardless, this takes me to my few questions:\n\n&amp;#x200B;\n\n1.) What tools and framework have you used recently for your big data analytics project, and would you considered adding any tools (automation) to your tools set in order to simplify your data process? \n\n2.)How does the framework you are using scale to handle the ever-growing big data?\n\n3.) Are some of your clients that you work with driving the adoption of AI and automation? I know my company I work for is already looking at integrating Microsoft teams premium because of the features found in chatgpt and how some of my clients wants the to be able have the capacity to automatically generate notes in case they miss the meeting.", "author_fullname": "t2_s2o8t6mt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you democratize your data process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uhdqh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675616598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I am interested in the tools and framework (in particular automation tools) everyone uses when working with big data. I am a solution engineer, but always wanted to be a data analyst or data scientist because I believe that data can be harnessed for many practical application e.g., (chatgpt craze). Regardless, this takes me to my few questions:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;1.) What tools and framework have you used recently for your big data analytics project, and would you considered adding any tools (automation) to your tools set in order to simplify your data process? &lt;/p&gt;\n\n&lt;p&gt;2.)How does the framework you are using scale to handle the ever-growing big data?&lt;/p&gt;\n\n&lt;p&gt;3.) Are some of your clients that you work with driving the adoption of AI and automation? I know my company I work for is already looking at integrating Microsoft teams premium because of the features found in chatgpt and how some of my clients wants the to be able have the capacity to automatically generate notes in case they miss the meeting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uhdqh", "is_robot_indexable": true, "report_reasons": null, "author": "osa1501", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uhdqh/how_do_you_democratize_your_data_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uhdqh/how_do_you_democratize_your_data_process/", "subreddit_subscribers": 844922, "created_utc": 1675616598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A while back, my close colleague at work had an interview with Sr. Director of Analytics (or maybe just a Director, I forgot), for data related opening. \n\nHe was asked to describe what would he do with 3 data points, representing 3 months, say month of January through March.\n\nI confirmed with my colleague that it was not 3-month (or 90 days data), it was just literally 3 data points, for example sales revenue for those 3 months.\n\nMy hunch at that time was, either the person smoked something, or he blew the interview on purpose, as the recruiter told him the very next day as they decided to \u201cpromote\u201d from within.\n\nI did try to think a variety of ways to derive meaningful reference based on 3 numbers, but eventually I told my colleague that most likely the interview was fake.\n\nI guess I want to know from different perspective, whether you can actually use 3 data points in a meaningful way, for business.\n\nAny taker?\n\nUpdate: as suggested, the company he interviewed with was F100, big in Telco.", "author_fullname": "t2_ul5y0kdu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What can you do with 3 data points?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uh0at", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675620628.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675615684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A while back, my close colleague at work had an interview with Sr. Director of Analytics (or maybe just a Director, I forgot), for data related opening. &lt;/p&gt;\n\n&lt;p&gt;He was asked to describe what would he do with 3 data points, representing 3 months, say month of January through March.&lt;/p&gt;\n\n&lt;p&gt;I confirmed with my colleague that it was not 3-month (or 90 days data), it was just literally 3 data points, for example sales revenue for those 3 months.&lt;/p&gt;\n\n&lt;p&gt;My hunch at that time was, either the person smoked something, or he blew the interview on purpose, as the recruiter told him the very next day as they decided to \u201cpromote\u201d from within.&lt;/p&gt;\n\n&lt;p&gt;I did try to think a variety of ways to derive meaningful reference based on 3 numbers, but eventually I told my colleague that most likely the interview was fake.&lt;/p&gt;\n\n&lt;p&gt;I guess I want to know from different perspective, whether you can actually use 3 data points in a meaningful way, for business.&lt;/p&gt;\n\n&lt;p&gt;Any taker?&lt;/p&gt;\n\n&lt;p&gt;Update: as suggested, the company he interviewed with was F100, big in Telco.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uh0at", "is_robot_indexable": true, "report_reasons": null, "author": "kyleireddit", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uh0at/what_can_you_do_with_3_data_points/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uh0at/what_can_you_do_with_3_data_points/", "subreddit_subscribers": 844922, "created_utc": 1675615684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm curious because in my \"small\" experience of +4 years last friday I did an interview for a small company, when they asked me about using git or control version somehow I was totally honest and said something a long the lines \"look I know what it is and how it works but because I like to learn but in these bigs companies in my resume at the end of the day they care more about having results as soon as possible with nothing or very little documentation rather than doing things properly, so I did as they ask\".\nThey started laughing like some joke saying \"oh wow I cant imagine working like that what a mess\" I dont think they really care since as they also said is something you should get used to easily (plus I'm gonna reject them). \n\nSo I'm just curious how many of you really work using git? \nPS: My profile is data scientist/analyst using Python.\n\nUpdate: \nAs Im reading all of you I see that I need to change that because for me and the company so... this week I'll start to use it 100%.\nAlso I'm giving some more info about why I think I didnt really work with it in the past:\n- No production deployment (\"if you can run it locally why waste money?\")\n- Really small teams where normally very few projects where really done by more than the person itself.\n- When I tried to bring it in the past It was kind of a mess for me without anybody helping, and It was hard for me to defend why since I really didnt know either.\n- Normally when I tried to learn something new I used to focus on new libreries, best techniques/coding practices and my next step was about docker and production deployment but before that Im focus on the git.\n\nI want to thank all of you for your thoughts, I'll keep replying later.", "author_fullname": "t2_x2mp516", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many of you really work using control version like git rather than local files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uf7ws", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675620348.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675611169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious because in my &amp;quot;small&amp;quot; experience of +4 years last friday I did an interview for a small company, when they asked me about using git or control version somehow I was totally honest and said something a long the lines &amp;quot;look I know what it is and how it works but because I like to learn but in these bigs companies in my resume at the end of the day they care more about having results as soon as possible with nothing or very little documentation rather than doing things properly, so I did as they ask&amp;quot;.\nThey started laughing like some joke saying &amp;quot;oh wow I cant imagine working like that what a mess&amp;quot; I dont think they really care since as they also said is something you should get used to easily (plus I&amp;#39;m gonna reject them). &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m just curious how many of you really work using git? \nPS: My profile is data scientist/analyst using Python.&lt;/p&gt;\n\n&lt;p&gt;Update: \nAs Im reading all of you I see that I need to change that because for me and the company so... this week I&amp;#39;ll start to use it 100%.\nAlso I&amp;#39;m giving some more info about why I think I didnt really work with it in the past:\n- No production deployment (&amp;quot;if you can run it locally why waste money?&amp;quot;)\n- Really small teams where normally very few projects where really done by more than the person itself.\n- When I tried to bring it in the past It was kind of a mess for me without anybody helping, and It was hard for me to defend why since I really didnt know either.\n- Normally when I tried to learn something new I used to focus on new libreries, best techniques/coding practices and my next step was about docker and production deployment but before that Im focus on the git.&lt;/p&gt;\n\n&lt;p&gt;I want to thank all of you for your thoughts, I&amp;#39;ll keep replying later.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uf7ws", "is_robot_indexable": true, "report_reasons": null, "author": "KingdomXander", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uf7ws/how_many_of_you_really_work_using_control_version/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uf7ws/how_many_of_you_really_work_using_control_version/", "subreddit_subscribers": 844922, "created_utc": 1675611169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello there, I am trying to detect a fraud detection model which outputs risk as Low Medium or High, I have a customers id in one data frame and in another data frame i have their data that from which customer (source) id to which (target) how much money 'emt' is being transferred. Now I want to drop customer id from the initial data frame and add a new column containing a series of transaction for both sources and targets. How do i do this and is there a better way to do this?", "author_fullname": "t2_amimzgo5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to process additional data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u69ua", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675580037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there, I am trying to detect a fraud detection model which outputs risk as Low Medium or High, I have a customers id in one data frame and in another data frame i have their data that from which customer (source) id to which (target) how much money &amp;#39;emt&amp;#39; is being transferred. Now I want to drop customer id from the initial data frame and add a new column containing a series of transaction for both sources and targets. How do i do this and is there a better way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10u69ua", "is_robot_indexable": true, "report_reasons": null, "author": "Old_Stick_9560", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10u69ua/how_to_process_additional_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10u69ua/how_to_process_additional_data/", "subreddit_subscribers": 844922, "created_utc": 1675580037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI was tasked with finding videos for product releases for several companies from a very large Excel file with headlines of new articles. The Excel has only the headline of the product release article &amp; the company names. there are about 10,000 headlines.\n\nHow can I approach this problem and ultimately automate it?", "author_fullname": "t2_4jekmmq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding Products Advertisement Videos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10txeas", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675560727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I was tasked with finding videos for product releases for several companies from a very large Excel file with headlines of new articles. The Excel has only the headline of the product release article &amp;amp; the company names. there are about 10,000 headlines.&lt;/p&gt;\n\n&lt;p&gt;How can I approach this problem and ultimately automate it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10txeas", "is_robot_indexable": true, "report_reasons": null, "author": "mouayedlajnef", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10txeas/finding_products_advertisement_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10txeas/finding_products_advertisement_videos/", "subreddit_subscribers": 844922, "created_utc": 1675560727.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}