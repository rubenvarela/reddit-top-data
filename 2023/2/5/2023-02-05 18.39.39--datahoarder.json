{"kind": "Listing", "data": {"after": "t3_10tyvgf", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " OP([https://www.reddit.com/r/DevelEire/comments/10sz476/app\\_that\\_lets\\_you\\_see\\_a\\_reddit\\_user\\_pics\\_that\\_i/](https://www.reddit.com/r/DevelEire/comments/10sz476/app_that_lets_you_see_a_reddit_user_pics_that_i/))\n\nI'm always drained after each work day even though I don't work that much so I'm pretty happy that I managed to patch it together. Hope you guys enjoy it, I suck at UI. This is the first version, I know it needs a lot of extra features so please do provide feedback.\n\nExample usage (safe for work):\n\nGo to the user you are interested in, for example\n\n[https://www.reddit.com/user/andrewrimanic](https://www.reddit.com/user/andrewrimanic)\n\nAdd \"-up\" after reddit and voila:\n\n[https://www.reddit-up.com/user/andrewrimanic](https://www.reddit-up.com/user/andrewrimanic)", "author_fullname": "t2_ipbf10dq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "App that lets you see a reddit user pics/photographs that I wrote in my free time. Maybe somebody can use it to download all photos from a user.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tumc0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 304, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 304, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675553184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;OP(&lt;a href=\"https://www.reddit.com/r/DevelEire/comments/10sz476/app_that_lets_you_see_a_reddit_user_pics_that_i/\"&gt;https://www.reddit.com/r/DevelEire/comments/10sz476/app_that_lets_you_see_a_reddit_user_pics_that_i/&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m always drained after each work day even though I don&amp;#39;t work that much so I&amp;#39;m pretty happy that I managed to patch it together. Hope you guys enjoy it, I suck at UI. This is the first version, I know it needs a lot of extra features so please do provide feedback.&lt;/p&gt;\n\n&lt;p&gt;Example usage (safe for work):&lt;/p&gt;\n\n&lt;p&gt;Go to the user you are interested in, for example&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/user/andrewrimanic\"&gt;https://www.reddit.com/user/andrewrimanic&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Add &amp;quot;-up&amp;quot; after reddit and voila:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit-up.com/user/andrewrimanic\"&gt;https://www.reddit-up.com/user/andrewrimanic&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10tumc0", "is_robot_indexable": true, "report_reasons": null, "author": "Notalabel_4566", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10tumc0/app_that_lets_you_see_a_reddit_user/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10tumc0/app_that_lets_you_see_a_reddit_user/", "subreddit_subscribers": 668724, "created_utc": 1675553184.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "We just cleaned out my mom's house after her death. We have 3 large tubs of photos that I'd like to scan. Is there either an affordable service or machine that will rapidly scan these? This is a rather daunting task.", "author_fullname": "t2_bru5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scanning hundreds of photos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ttth8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675551120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We just cleaned out my mom&amp;#39;s house after her death. We have 3 large tubs of photos that I&amp;#39;d like to scan. Is there either an affordable service or machine that will rapidly scan these? This is a rather daunting task.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ttth8", "is_robot_indexable": true, "report_reasons": null, "author": "Stryker412", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ttth8/scanning_hundreds_of_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ttth8/scanning_hundreds_of_photos/", "subreddit_subscribers": 668724, "created_utc": 1675551120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_jmx0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WDC WD20EARX-OOPASBO are awesome \ud83e\udd29", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 138, "top_awarded_type": null, "hide_score": false, "name": "t3_10ucqb9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NpeoA3QyiyraqvqN2DeQfg3gBzvh1WXJoz77Fz7DWYE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675604496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/na9rwfag0fga1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/na9rwfag0fga1.jpg?auto=webp&amp;v=enabled&amp;s=324eefd4f82488b9656d8a450a62fcf6584f2d38", "width": 941, "height": 929}, "resolutions": [{"url": "https://preview.redd.it/na9rwfag0fga1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=257426f10f61050d939199d30bce27839fbfac44", "width": 108, "height": 106}, {"url": "https://preview.redd.it/na9rwfag0fga1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cff805da5ae4ae3931ca4115cad3914fb75e8a10", "width": 216, "height": 213}, {"url": "https://preview.redd.it/na9rwfag0fga1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ca81680a0c5c1dbda0b7d5c71774d459a2cf8fb", "width": 320, "height": 315}, {"url": "https://preview.redd.it/na9rwfag0fga1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1739262f33fceff766d678249992d0c6b16f8fef", "width": 640, "height": 631}], "variants": {}, "id": "dORDMCE4XiTQt8WS4lbp4UczG3ZHBZT4rt1qRmOXjKc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ucqb9", "is_robot_indexable": true, "report_reasons": null, "author": "GreenPRanger", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ucqb9/wdc_wd20earxoopasbo_are_awesome/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/na9rwfag0fga1.jpg", "subreddit_subscribers": 668724, "created_utc": 1675604496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For context,over the last couple of years I have gone from just watching TV and films on Netflix or whatever to creating a modest home theatre (if you could call it that) and doing all my watching via Plex. \n\nI am definitely a cinephile and the idea of continuing to build my digital movie collection and not deleting anything is appealing to me. \n\nI am a bit of a snob when it comes to the quality of the films I watch, so I tend to lean towards downloading larger files. I will not run out of space any time soon but I am just starting to future plan a little bit. I know its a tricky question to answer but does it get very expensive to keep large amount of high quality movies or is there reasonably affordable ways to do it that I should explore. I have limited technological knowledge and would be reluctant to go into anything  too complex. \n\nI currently have 6tb and 16tb drives plugged into my nvidia shield which also acts as my Plex server. This will not fill up for quiet a while. To simplify my question, is it a big deal to just infinitely grow my collection over the years or should i be more in the mindset of staying within the storage i have. Thank to anyone who has thoughts", "author_fullname": "t2_dv2nbwns", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should i continue and go deeper...or should I turn back...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uagom", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675596717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context,over the last couple of years I have gone from just watching TV and films on Netflix or whatever to creating a modest home theatre (if you could call it that) and doing all my watching via Plex. &lt;/p&gt;\n\n&lt;p&gt;I am definitely a cinephile and the idea of continuing to build my digital movie collection and not deleting anything is appealing to me. &lt;/p&gt;\n\n&lt;p&gt;I am a bit of a snob when it comes to the quality of the films I watch, so I tend to lean towards downloading larger files. I will not run out of space any time soon but I am just starting to future plan a little bit. I know its a tricky question to answer but does it get very expensive to keep large amount of high quality movies or is there reasonably affordable ways to do it that I should explore. I have limited technological knowledge and would be reluctant to go into anything  too complex. &lt;/p&gt;\n\n&lt;p&gt;I currently have 6tb and 16tb drives plugged into my nvidia shield which also acts as my Plex server. This will not fill up for quiet a while. To simplify my question, is it a big deal to just infinitely grow my collection over the years or should i be more in the mindset of staying within the storage i have. Thank to anyone who has thoughts&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10uagom", "is_robot_indexable": true, "report_reasons": null, "author": "bluelotus101", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10uagom/should_i_continue_and_go_deeperor_should_i_turn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10uagom/should_i_continue_and_go_deeperor_should_i_turn/", "subreddit_subscribers": 668724, "created_utc": 1675596717.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "theres an artist, Heems, of Das Racist, who used to post alot of his songs on tumblr in 2011-2016, when flash was still used for most of the audio. his page was either havked or deleted or i dont know a few years back and most of the audio is lost. ive looked through a bunch of reblogs on fan pages and general followers of his music on tumblr and recovered alot of songs but still not the majority. wondering if anyone had any ideas? His page was originally nehrujackets.", "author_fullname": "t2_8klngbgy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any way to recover Tumblr audio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tvl4w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675555750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;theres an artist, Heems, of Das Racist, who used to post alot of his songs on tumblr in 2011-2016, when flash was still used for most of the audio. his page was either havked or deleted or i dont know a few years back and most of the audio is lost. ive looked through a bunch of reblogs on fan pages and general followers of his music on tumblr and recovered alot of songs but still not the majority. wondering if anyone had any ideas? His page was originally nehrujackets.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10tvl4w", "is_robot_indexable": true, "report_reasons": null, "author": "z-gyke-1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10tvl4w/any_way_to_recover_tumblr_audio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10tvl4w/any_way_to_recover_tumblr_audio/", "subreddit_subscribers": 668724, "created_utc": 1675555750.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just installed an HBA (LSI  SAS HBA 9200-8I IT Mode) and a SAS Expander ( 468406-B21 487738-001 468405-001 468405-002 HP 24 BAY 3GB SAS EXPANDER CARD US ). I have 19 sata drives connected to the expander card. I made sure and the cables are forward breakout. When I boot the computer, I see a message about the LSI card being configured and gives me an ooption to Crtl+C. After that I see a message saying that it is looking at port 0 for devices. The screen refreshes and I see what appears as all of my sata drives. Then, Windows 10 starts to boot and loads up properly. There are no errors at any time. When I look at the disk manager, none of the drives are listed. The drives were attached to the computer using a SATA card previously. There are lights on the HBA (1 solid and 1 blinking) and HP Expander card (1 blinking and 3 pairs of solid ). Device manager shows the LSI card and there does not appear to be any issues.\n\nMy motherboard is a ASUS TUF SABERTOOTH 990FX R2.0\n\nIt seems to me like the hardware is working properly but there is a setting that needs to be changed to allow the drives to be recognized. I tried searching this forum and I found the following link but I am not sure if that will fix my issue.\n\n[https://www.reddit.com/r/DataHoarder/comments/rgzm3q/lsi\\_sas92118i\\_hba\\_drives\\_not\\_showing\\_up\\_in/](https://www.reddit.com/r/DataHoarder/comments/rgzm3q/lsi_sas92118i_hba_drives_not_showing_up_in/)", "author_fullname": "t2_2xaznlt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Drives not showing up", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ud1ar", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675605398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just installed an HBA (LSI  SAS HBA 9200-8I IT Mode) and a SAS Expander ( 468406-B21 487738-001 468405-001 468405-002 HP 24 BAY 3GB SAS EXPANDER CARD US ). I have 19 sata drives connected to the expander card. I made sure and the cables are forward breakout. When I boot the computer, I see a message about the LSI card being configured and gives me an ooption to Crtl+C. After that I see a message saying that it is looking at port 0 for devices. The screen refreshes and I see what appears as all of my sata drives. Then, Windows 10 starts to boot and loads up properly. There are no errors at any time. When I look at the disk manager, none of the drives are listed. The drives were attached to the computer using a SATA card previously. There are lights on the HBA (1 solid and 1 blinking) and HP Expander card (1 blinking and 3 pairs of solid ). Device manager shows the LSI card and there does not appear to be any issues.&lt;/p&gt;\n\n&lt;p&gt;My motherboard is a ASUS TUF SABERTOOTH 990FX R2.0&lt;/p&gt;\n\n&lt;p&gt;It seems to me like the hardware is working properly but there is a setting that needs to be changed to allow the drives to be recognized. I tried searching this forum and I found the following link but I am not sure if that will fix my issue.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/rgzm3q/lsi_sas92118i_hba_drives_not_showing_up_in/\"&gt;https://www.reddit.com/r/DataHoarder/comments/rgzm3q/lsi_sas92118i_hba_drives_not_showing_up_in/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ud1ar", "is_robot_indexable": true, "report_reasons": null, "author": "Robot_Amish", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ud1ar/drives_not_showing_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ud1ar/drives_not_showing_up/", "subreddit_subscribers": 668724, "created_utc": 1675605398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4frov7lr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "refurbished 12tb drives for $125 right now. Finally I got a decent deal", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10tt5ko", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/d0LYOKCaC-SLYYX4EbMAuSpM5wxbzwWiipYZcxyOo9Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675549415.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/mrrwtoxngaga1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/mrrwtoxngaga1.jpg?auto=webp&amp;v=enabled&amp;s=94bd86a539e9eeaefb7ebd30ef4d255a1ed5d8e4", "width": 1439, "height": 1600}, "resolutions": [{"url": "https://preview.redd.it/mrrwtoxngaga1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5a744ee3c8d8a16b293c284b33ea2d2deded8a3", "width": 108, "height": 120}, {"url": "https://preview.redd.it/mrrwtoxngaga1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25ec9050692b4f0c7507ca7f684126c0e3ad7ad5", "width": 216, "height": 240}, {"url": "https://preview.redd.it/mrrwtoxngaga1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b19c22f91d93b258f8e9cc9388ebfe5465877a86", "width": 320, "height": 355}, {"url": "https://preview.redd.it/mrrwtoxngaga1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15b60428558b9efd699099d9f3f1f931615593f1", "width": 640, "height": 711}, {"url": "https://preview.redd.it/mrrwtoxngaga1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e6b947dfe07a49ff8bc49eaa59d2a43b9774c161", "width": 960, "height": 1067}, {"url": "https://preview.redd.it/mrrwtoxngaga1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c2ee1aed59abcf85068895a39f7e14bc8a5ad486", "width": 1080, "height": 1200}], "variants": {}, "id": "Kqv9kSl9c0qtH17iOgA14-UGNQOuHXkWXZ_-181xzUs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tt5ko", "is_robot_indexable": true, "report_reasons": null, "author": "Trevor792221", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10tt5ko/refurbished_12tb_drives_for_125_right_now_finally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/mrrwtoxngaga1.jpg", "subreddit_subscribers": 668724, "created_utc": 1675549415.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A common suggestion for data hoarder back ups is the 3-2-1 strategy, which dictates 2 local copies of data, and a third copy offsite. The cloud is often put forward as a good way to secure your data offsite. It doesn't require the creation of a second NAS at a friends house, or the transport of external drives between locations for updates / storage. Cloud solutions are fully managed from the hardware side, and provide a great deal of convenience, often providing a great deal of reliability as well.\n\nThe main drawback of cloud solutions is that they are expensive. Unlimited personal clouds almost don't exist anymore, so most of us are paying by GB for our cloud storage. B2 from Backblaze is often recommended as a high quality and cheap cloud option, the cost is $5/TB /Month. There are other competitors to Backblaze, like Wasabi, with comparable pricing. Something that is brought up less often, is the use of enterprise cloud providers AWS, Azure and GCP. They offer deep archival storage options that run in the neighborhood of $1/TB/Month, a full fifth of the cost of B2. The catch, is they have very high egress fees. Getting your data out of those services is expensive. A full recovery of your data can easily run into the $2000 range depending on how much you're storing. This is usually the main point brought up against using them. These archival services also have have a 6-48 hour wait time before you are able to retrieve data.\n\nI'm in the neighborhood for a new 3-2-1 strategy to store 20TB of data, so I did a little math and speculation to compare storing data in B2, versus using AWS Glacier Deep Archive.\n\n**Speculation, Disaster Recovery**\n\nTo me, my cloud back up is a last resort. I will have two copies of my data locally, one of a NAS, and one on an external drive. If the external drive breaks, buy a new one and restore from the NAS. If the NAS fails, repair the NAS and restore it from the external drive. The danger comes in simultaneous failure. What if my NAS fails \\*AND\\* my external drive fail together. This could technically just happen simultaneously due to failing drives, but it's more likely an external event would trigger this failure, the eponymous disaster, of disaster recovery. This disaster could be small, like a toddler spilling a pitcher of juice on your homelab, or it could be big, like a house fire or flooding. Either way, without another copy of your data somewhere else you're SOL. That's why the 3-2-1 backup strategy recommends an offsite back up.\n\nBut really, how often do disasters happen to you ? Having both of your local copies fail should be an unlikely event, so unlikely I would argue that its a real possibility you could live out your full adult life and never have that simultaneous failure. Depends on where you live of course, I don't live near the threat of wildfires and flooding, some people do. But most of the people I know have never had a house fire, or lost a home to flood. And if they have, I don't know any who have had it happen more than once (though I am sure it happens).\n\nThis isn't to argue against an offsite back up. Disasters happen, and they could happen to you. Multiple times even. But they should be rare. Your local backup should be able to handle most problems.\n\n**Egress Fees for AWS**\n\nEgress fees from AWS (Azure and GCP will be different, but should be roughly comparable) actually aren't entirely intuitive to figure out. There is the cost to retrieve the data from S3, and the cost to send it to you via the internet, but at a certain point it becomes cheaper to use AWS snowball (or Azure Data Box) to get them to mail you a big ass box with all your data in it. It's still expensive, but by my estimates once you start to hit about 10TB of data, Snowball starts to become cheaper.\n\nFor non snowball data, the total S3 Transfer cost is a whopping $92.5 per TB, assuming you're using the US east data centers. For snowball data, there is the fixed cost of shipping, varies but estimate $200, then a $300 service fee, and then $50 per TB.\n\n(That $50 number should be a worse case actually. It might be as low as $30 per TB but the [AWS pricing website](https://aws.amazon.com/snowball/pricing/) examples are inconsistent. One uses only the standard glacier egress price, one uses the snowball transfer price + the standard glacier egress price. I would have thought it is only the snowball transfer price, but if anyone knows for sure please let me know.)\n\n**The Math**\n\nSo okay, we know how to calculate our S3 egress fees, we know what B2 costs compared to glacier deep archive, and we know disasters are rare. So lets plug in some numbers and look at the total cost of using B2 VS AWS for disaster recovery over a 10 year period. We can treat the number of full restores as a variable.  That way we can see at what point AWS becomes more expensive than B2\n\n|Data Size (TB)|Number of Disasters|Total Cost B2 (10 Years)|Total Cost AWS (10 Years)|\n|:-|:-|:-|:-|\n|20|1|$12200|$3900|\n|20|2|$12400|$5400|\n|20|3|$12600|$6900|\n|20|4|$12800|$8400|\n|20|5|$13000|$9900|\n|20|6|$13200|$11400|\n|20|7|$13400|$12900|\n|20|8|$13600|$14400|\n\nSo for a 20TB back up, we would need to do 8 full recoveries from the cloud, suffering a disaster almost every year, in order for B2 to be cheaper overall.\n\nAt lower amounts of data this changes slightly, since we are no longer using snowball, but the idea is still similar. 5TB of data require 6 total disaster recoveries for B2 to be cheaper.\n\n**Discussion**\n\nThis post isn't a knock against B2, I think Backblaze is a great company and B2 has some great use cases. It's just in the realm of disaster recovery, which is what I want my offsite back up to be, I think B2 is not the optimal choice of product. I think its clear to me, that in terms of cost optimization there aren't any providers that beat the main enterprise cloud providers. There are of course, other disadvantages potentially. I work with AWS in my day-to-day, so I'm familiar with the CLI / SDK and how to build tools that let me make good use of it. It might not be so intuitive for normal home use.\n\nAlso, at lower amount of data, the total difference starts to become smaller and smaller. If you only have 5TB of data, and the Backblaze interface is one your comfortable with and love, or you don't want to have to wait 48 hours to retrieve your data, or have AWS mail you a data box, then it totally makes sense to go with Backblaze. But when looking at backing up the 20TB that I am, the difference in cost over 10 years is incredibly significant.\n\nFinally, AWS Glacier Deep Archive is a terrible choice for you, if you are not planning on using it solely for disaster recovery. The premise of the analysis is that really, you're only ever going to need to pay the data egress fees when everything has gone to shit. If you're *not* doing a 3-2-1 back up, and you *don't* have 2 local copies, you're gonna need to pay the egress fees every time *anything* goes wrong, not just for simultaneous failure.", "author_fullname": "t2_5tjkd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glacier Deep Archive is Far Superior to Backblaze B2 in Terms of Cost Optimization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10uh8l3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675616264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A common suggestion for data hoarder back ups is the 3-2-1 strategy, which dictates 2 local copies of data, and a third copy offsite. The cloud is often put forward as a good way to secure your data offsite. It doesn&amp;#39;t require the creation of a second NAS at a friends house, or the transport of external drives between locations for updates / storage. Cloud solutions are fully managed from the hardware side, and provide a great deal of convenience, often providing a great deal of reliability as well.&lt;/p&gt;\n\n&lt;p&gt;The main drawback of cloud solutions is that they are expensive. Unlimited personal clouds almost don&amp;#39;t exist anymore, so most of us are paying by GB for our cloud storage. B2 from Backblaze is often recommended as a high quality and cheap cloud option, the cost is $5/TB /Month. There are other competitors to Backblaze, like Wasabi, with comparable pricing. Something that is brought up less often, is the use of enterprise cloud providers AWS, Azure and GCP. They offer deep archival storage options that run in the neighborhood of $1/TB/Month, a full fifth of the cost of B2. The catch, is they have very high egress fees. Getting your data out of those services is expensive. A full recovery of your data can easily run into the $2000 range depending on how much you&amp;#39;re storing. This is usually the main point brought up against using them. These archival services also have have a 6-48 hour wait time before you are able to retrieve data.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the neighborhood for a new 3-2-1 strategy to store 20TB of data, so I did a little math and speculation to compare storing data in B2, versus using AWS Glacier Deep Archive.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Speculation, Disaster Recovery&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;To me, my cloud back up is a last resort. I will have two copies of my data locally, one of a NAS, and one on an external drive. If the external drive breaks, buy a new one and restore from the NAS. If the NAS fails, repair the NAS and restore it from the external drive. The danger comes in simultaneous failure. What if my NAS fails *AND* my external drive fail together. This could technically just happen simultaneously due to failing drives, but it&amp;#39;s more likely an external event would trigger this failure, the eponymous disaster, of disaster recovery. This disaster could be small, like a toddler spilling a pitcher of juice on your homelab, or it could be big, like a house fire or flooding. Either way, without another copy of your data somewhere else you&amp;#39;re SOL. That&amp;#39;s why the 3-2-1 backup strategy recommends an offsite back up.&lt;/p&gt;\n\n&lt;p&gt;But really, how often do disasters happen to you ? Having both of your local copies fail should be an unlikely event, so unlikely I would argue that its a real possibility you could live out your full adult life and never have that simultaneous failure. Depends on where you live of course, I don&amp;#39;t live near the threat of wildfires and flooding, some people do. But most of the people I know have never had a house fire, or lost a home to flood. And if they have, I don&amp;#39;t know any who have had it happen more than once (though I am sure it happens).&lt;/p&gt;\n\n&lt;p&gt;This isn&amp;#39;t to argue against an offsite back up. Disasters happen, and they could happen to you. Multiple times even. But they should be rare. Your local backup should be able to handle most problems.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Egress Fees for AWS&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Egress fees from AWS (Azure and GCP will be different, but should be roughly comparable) actually aren&amp;#39;t entirely intuitive to figure out. There is the cost to retrieve the data from S3, and the cost to send it to you via the internet, but at a certain point it becomes cheaper to use AWS snowball (or Azure Data Box) to get them to mail you a big ass box with all your data in it. It&amp;#39;s still expensive, but by my estimates once you start to hit about 10TB of data, Snowball starts to become cheaper.&lt;/p&gt;\n\n&lt;p&gt;For non snowball data, the total S3 Transfer cost is a whopping $92.5 per TB, assuming you&amp;#39;re using the US east data centers. For snowball data, there is the fixed cost of shipping, varies but estimate $200, then a $300 service fee, and then $50 per TB.&lt;/p&gt;\n\n&lt;p&gt;(That $50 number should be a worse case actually. It might be as low as $30 per TB but the &lt;a href=\"https://aws.amazon.com/snowball/pricing/\"&gt;AWS pricing website&lt;/a&gt; examples are inconsistent. One uses only the standard glacier egress price, one uses the snowball transfer price + the standard glacier egress price. I would have thought it is only the snowball transfer price, but if anyone knows for sure please let me know.)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Math&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;So okay, we know how to calculate our S3 egress fees, we know what B2 costs compared to glacier deep archive, and we know disasters are rare. So lets plug in some numbers and look at the total cost of using B2 VS AWS for disaster recovery over a 10 year period. We can treat the number of full restores as a variable.  That way we can see at what point AWS becomes more expensive than B2&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Data Size (TB)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Number of Disasters&lt;/th&gt;\n&lt;th align=\"left\"&gt;Total Cost B2 (10 Years)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Total Cost AWS (10 Years)&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;$12200&lt;/td&gt;\n&lt;td align=\"left\"&gt;$3900&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;$12400&lt;/td&gt;\n&lt;td align=\"left\"&gt;$5400&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;$12600&lt;/td&gt;\n&lt;td align=\"left\"&gt;$6900&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;$12800&lt;/td&gt;\n&lt;td align=\"left\"&gt;$8400&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;5&lt;/td&gt;\n&lt;td align=\"left\"&gt;$13000&lt;/td&gt;\n&lt;td align=\"left\"&gt;$9900&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;6&lt;/td&gt;\n&lt;td align=\"left\"&gt;$13200&lt;/td&gt;\n&lt;td align=\"left\"&gt;$11400&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;7&lt;/td&gt;\n&lt;td align=\"left\"&gt;$13400&lt;/td&gt;\n&lt;td align=\"left\"&gt;$12900&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;20&lt;/td&gt;\n&lt;td align=\"left\"&gt;8&lt;/td&gt;\n&lt;td align=\"left\"&gt;$13600&lt;/td&gt;\n&lt;td align=\"left\"&gt;$14400&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;So for a 20TB back up, we would need to do 8 full recoveries from the cloud, suffering a disaster almost every year, in order for B2 to be cheaper overall.&lt;/p&gt;\n\n&lt;p&gt;At lower amounts of data this changes slightly, since we are no longer using snowball, but the idea is still similar. 5TB of data require 6 total disaster recoveries for B2 to be cheaper.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Discussion&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This post isn&amp;#39;t a knock against B2, I think Backblaze is a great company and B2 has some great use cases. It&amp;#39;s just in the realm of disaster recovery, which is what I want my offsite back up to be, I think B2 is not the optimal choice of product. I think its clear to me, that in terms of cost optimization there aren&amp;#39;t any providers that beat the main enterprise cloud providers. There are of course, other disadvantages potentially. I work with AWS in my day-to-day, so I&amp;#39;m familiar with the CLI / SDK and how to build tools that let me make good use of it. It might not be so intuitive for normal home use.&lt;/p&gt;\n\n&lt;p&gt;Also, at lower amount of data, the total difference starts to become smaller and smaller. If you only have 5TB of data, and the Backblaze interface is one your comfortable with and love, or you don&amp;#39;t want to have to wait 48 hours to retrieve your data, or have AWS mail you a data box, then it totally makes sense to go with Backblaze. But when looking at backing up the 20TB that I am, the difference in cost over 10 years is incredibly significant.&lt;/p&gt;\n\n&lt;p&gt;Finally, AWS Glacier Deep Archive is a terrible choice for you, if you are not planning on using it solely for disaster recovery. The premise of the analysis is that really, you&amp;#39;re only ever going to need to pay the data egress fees when everything has gone to shit. If you&amp;#39;re &lt;em&gt;not&lt;/em&gt; doing a 3-2-1 back up, and you &lt;em&gt;don&amp;#39;t&lt;/em&gt; have 2 local copies, you&amp;#39;re gonna need to pay the egress fees every time &lt;em&gt;anything&lt;/em&gt; goes wrong, not just for simultaneous failure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?auto=webp&amp;v=enabled&amp;s=96305e240e32ef61b596395e1bd74cdd2b5ddc9f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=668115d5116a9321c9d15551b8d546a68f75112b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488bc7dc46930436614152debfa68b6926b8196b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=181b543f38a37bffa9070ec5c73a2cbcd66cc8f4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d81e093ae625b1e109af99de0c72a0ebea0f0088", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10b559f8887295a4ee5c2790c34a42f8e3690847", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=836e2bf75ddac523506ae28bf3813f47697700e2", "width": 1080, "height": 567}], "variants": {}, "id": "RUqh18uQTwuGJocqdUcC-6UfvfWS63SRDdr8AQqU3uM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10uh8l3", "is_robot_indexable": true, "report_reasons": null, "author": "Madman200", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10uh8l3/aws_glacier_deep_archive_is_far_superior_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10uh8l3/aws_glacier_deep_archive_is_far_superior_to/", "subreddit_subscribers": 668724, "created_utc": 1675616264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it possible to back up content from my phone straight to an external drive, without copying everything to my computer in between? I assume yes, but my searches have failed me thus far. Is there an app (Android) or another utility that I would use to run the backups? Or do you have to do it more manually (select files and then copy)? I appreciate any feedback or advice anyone has for doing this.", "author_fullname": "t2_v55ro0s9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backing up straight to external drive from phone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tu60d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675552020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to back up content from my phone straight to an external drive, without copying everything to my computer in between? I assume yes, but my searches have failed me thus far. Is there an app (Android) or another utility that I would use to run the backups? Or do you have to do it more manually (select files and then copy)? I appreciate any feedback or advice anyone has for doing this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10tu60d", "is_robot_indexable": true, "report_reasons": null, "author": "em-staro", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10tu60d/backing_up_straight_to_external_drive_from_phone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10tu60d/backing_up_straight_to_external_drive_from_phone/", "subreddit_subscribers": 668724, "created_utc": 1675552020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, \n\nI have been saving dashcam videos of various roadtrips over the years and as many of you know, dashcams oftentimes save videos in 1-2 Minute increments only. \n\nSo now I am facing a situation, where I have a few dozen folders with 20-50 individual video files each that I want to merge. Is there a software that I can let run in the background (preferably within truenas scale), that goes folder by folder, merging all the video files alphabetically? \n\nThanks!", "author_fullname": "t2_2jn30iqh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool do batch-merge video files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tt2z0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675549235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;I have been saving dashcam videos of various roadtrips over the years and as many of you know, dashcams oftentimes save videos in 1-2 Minute increments only. &lt;/p&gt;\n\n&lt;p&gt;So now I am facing a situation, where I have a few dozen folders with 20-50 individual video files each that I want to merge. Is there a software that I can let run in the background (preferably within truenas scale), that goes folder by folder, merging all the video files alphabetically? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10tt2z0", "is_robot_indexable": true, "report_reasons": null, "author": "SupernickyZH", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10tt2z0/tool_do_batchmerge_video_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10tt2z0/tool_do_batchmerge_video_files/", "subreddit_subscribers": 668724, "created_utc": 1675549235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The best I have found is asrock racks [ROMED6U-2L2T](https://mitxpc.com/products/romed6u-2l2t) but its from a retailer I haven't heard before and I can't find it in stock anywhere else. Same for their similar boards such as [ROMED8U-2T](https://www.asrockrack.com/general/productdetail.asp?Model=ROMED8U-2T#Specifications) but that seems to be completely sold out. Other board manufacturers don't seem to have what I want.\n\nI've been looking at the Epyc 7302P or threadripper 2920x for the high core count  but more so for the pcie lanes which consumer cpus have very few of and there relatively cheap on eBay. I'm not too informed on what xeons have to offer but they seem to generally have fewer pcie lanes but that may be only for the older ones so I'm not sure.\n\nI suppose I should clarify that I'm going to use this for proxmox to host truenas core and potentially a windows vm and some other things down the line.\n\nI do have my own 10g nic so its not necessary for the board to have it but would be nice and I will have a hba in it for drives and potentially a graphics card (not a large one) for windows since it would be for games. Having integrated ipmi would also be a plus. If any one has a recommendation on a good Micro Atx board that fits the criteria that would be helpful.", "author_fullname": "t2_1v9ndvba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Know of any good micro atx server motherboards for tr4 or sp3?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tpr2q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675540943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The best I have found is asrock racks &lt;a href=\"https://mitxpc.com/products/romed6u-2l2t\"&gt;ROMED6U-2L2T&lt;/a&gt; but its from a retailer I haven&amp;#39;t heard before and I can&amp;#39;t find it in stock anywhere else. Same for their similar boards such as &lt;a href=\"https://www.asrockrack.com/general/productdetail.asp?Model=ROMED8U-2T#Specifications\"&gt;ROMED8U-2T&lt;/a&gt; but that seems to be completely sold out. Other board manufacturers don&amp;#39;t seem to have what I want.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking at the Epyc 7302P or threadripper 2920x for the high core count  but more so for the pcie lanes which consumer cpus have very few of and there relatively cheap on eBay. I&amp;#39;m not too informed on what xeons have to offer but they seem to generally have fewer pcie lanes but that may be only for the older ones so I&amp;#39;m not sure.&lt;/p&gt;\n\n&lt;p&gt;I suppose I should clarify that I&amp;#39;m going to use this for proxmox to host truenas core and potentially a windows vm and some other things down the line.&lt;/p&gt;\n\n&lt;p&gt;I do have my own 10g nic so its not necessary for the board to have it but would be nice and I will have a hba in it for drives and potentially a graphics card (not a large one) for windows since it would be for games. Having integrated ipmi would also be a plus. If any one has a recommendation on a good Micro Atx board that fits the criteria that would be helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/y_sBOgfyeh78vbOir_StUmCArpSyv2X_Rx2d5h3r9j8.jpg?auto=webp&amp;v=enabled&amp;s=2b41253281f11a519656f705c8a219615de79efc", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/y_sBOgfyeh78vbOir_StUmCArpSyv2X_Rx2d5h3r9j8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4224f3abf8f9a1fb070841ad40a00972890c5bf3", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/y_sBOgfyeh78vbOir_StUmCArpSyv2X_Rx2d5h3r9j8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a462e130b2be24802fd8d9f06235f721e61dc274", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/y_sBOgfyeh78vbOir_StUmCArpSyv2X_Rx2d5h3r9j8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2419d6462093d71f2f2d653cfb619272602e954c", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/y_sBOgfyeh78vbOir_StUmCArpSyv2X_Rx2d5h3r9j8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb200207a8475434be2268d11ef4148b634b5305", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/y_sBOgfyeh78vbOir_StUmCArpSyv2X_Rx2d5h3r9j8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=97bdae103ecc5f30e9f209fbb8903caba11df295", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/y_sBOgfyeh78vbOir_StUmCArpSyv2X_Rx2d5h3r9j8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38af8e5bbc402c1be19fdb61ce54c5cdcbc721d0", "width": 1080, "height": 567}], "variants": {}, "id": "6ItYogP8TQIsQrjQcTsbUi4b_prau6S08RUfpRF_ccE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10tpr2q", "is_robot_indexable": true, "report_reasons": null, "author": "quantumechanicalhose", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10tpr2q/know_of_any_good_micro_atx_server_motherboards/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10tpr2q/know_of_any_good_micro_atx_server_motherboards/", "subreddit_subscribers": 668724, "created_utc": 1675540943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just purchased a shucked 12tb WD white label drive. When I try to use this hard drive with any sort of external enclosure or SATA to USB adapter, it only shows up as a 1tb drive. Only when I stick it inside of my desktop do I see the full capacity. I have the third pin taped over, so not sure why I'm experiencing this. Any thoughts?", "author_fullname": "t2_wlo3t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using a shucked WD HDD w/ a SATA to USB 3.0 cable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10twfdw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675558044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just purchased a shucked 12tb WD white label drive. When I try to use this hard drive with any sort of external enclosure or SATA to USB adapter, it only shows up as a 1tb drive. Only when I stick it inside of my desktop do I see the full capacity. I have the third pin taped over, so not sure why I&amp;#39;m experiencing this. Any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10twfdw", "is_robot_indexable": true, "report_reasons": null, "author": "chug84", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10twfdw/using_a_shucked_wd_hdd_w_a_sata_to_usb_30_cable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10twfdw/using_a_shucked_wd_hdd_w_a_sata_to_usb_30_cable/", "subreddit_subscribers": 668724, "created_utc": 1675558044.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_bdy8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone tell what chassis this is? I got it from a surplus auction and it\u2019s missing 4 drive sleds. I can\u2019t find a model number anywhere on it, the SAS backplanes are 12-6507-00B", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_10tw9lg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FnNsUsuA%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FnNsUsuA&amp;image=https%3A%2F%2Fi.imgur.com%2FaKpkG7w.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"490\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "height": 490}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": {"type": "imgur.com", "oembed": {"provider_url": "http://imgur.com", "description": "Post with 0 views.", "title": "Imgur", "url": "https://imgur.com/a/nNsUsuA", "type": "rich", "thumbnail_width": 600, "height": 490, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FnNsUsuA%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FnNsUsuA&amp;image=https%3A%2F%2Fi.imgur.com%2FaKpkG7w.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"490\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Imgur", "thumbnail_url": "https://i.imgur.com/aKpkG7w.jpg?fb", "thumbnail_height": 315}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FnNsUsuA%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FnNsUsuA&amp;image=https%3A%2F%2Fi.imgur.com%2FaKpkG7w.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"490\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "width": 600, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/10tw9lg", "height": 490}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ga0O7RwC2MnDX8CTAeAEVIIkJzGfcNZSfhlolg6bAbI.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675557603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://imgur.com/a/nNsUsuA/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aQpnVCzxygQqY0yHrf-_njcAFXqeD9RXb5DAnk7d7Ec.jpg?auto=webp&amp;v=enabled&amp;s=4d4de2aae260a873b27e3f09707473e78b8c22ca", "width": 2000, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/aQpnVCzxygQqY0yHrf-_njcAFXqeD9RXb5DAnk7d7Ec.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e351b4a5ad17f5bb728e7dc84ddaf22ca146904", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/aQpnVCzxygQqY0yHrf-_njcAFXqeD9RXb5DAnk7d7Ec.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=62c7863950a1037654ad187e11cb8c4758ffd4a0", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/aQpnVCzxygQqY0yHrf-_njcAFXqeD9RXb5DAnk7d7Ec.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95ed6e997ac164d0b41125b7a9c952835feeec31", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/aQpnVCzxygQqY0yHrf-_njcAFXqeD9RXb5DAnk7d7Ec.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4bb719e8d83e75eee445e570705f31cb60ed33dc", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/aQpnVCzxygQqY0yHrf-_njcAFXqeD9RXb5DAnk7d7Ec.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0321ff078ecbf890d19bab79c2bbce35dc23b2a", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/aQpnVCzxygQqY0yHrf-_njcAFXqeD9RXb5DAnk7d7Ec.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88e3853b1d6ca28eaef695b48aa86ad8dca97a0f", "width": 1080, "height": 810}], "variants": {}, "id": "NP5Nz9UKpyrjndGZYiFuHNr3sSrOZDmgDEpAjdagcZQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "70+TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10tw9lg", "is_robot_indexable": true, "report_reasons": null, "author": "Technoguyfication", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10tw9lg/can_anyone_tell_what_chassis_this_is_i_got_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://imgur.com/a/nNsUsuA/", "subreddit_subscribers": 668724, "created_utc": 1675557603.0, "num_crossposts": 0, "media": {"type": "imgur.com", "oembed": {"provider_url": "http://imgur.com", "description": "Post with 0 views.", "title": "Imgur", "url": "https://imgur.com/a/nNsUsuA", "type": "rich", "thumbnail_width": 600, "height": 490, "width": 600, "html": "&lt;iframe class=\"embedly-embed\" src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fimgur.com%2Fa%2FnNsUsuA%2Fembed%3Fpub%3Dtrue%26ref%3Dhttps%253A%252F%252Fembed.ly%26w%3D900&amp;display_name=Imgur&amp;url=https%3A%2F%2Fimgur.com%2Fa%2FnNsUsuA&amp;image=https%3A%2F%2Fi.imgur.com%2FaKpkG7w.jpg%3Ffb&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=imgur\" width=\"600\" height=\"490\" scrolling=\"no\" title=\"Imgur embed\" frameborder=\"0\" allow=\"autoplay; fullscreen\" allowfullscreen=\"true\"&gt;&lt;/iframe&gt;", "version": "1.0", "provider_name": "Imgur", "thumbnail_url": "https://i.imgur.com/aKpkG7w.jpg?fb", "thumbnail_height": 315}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all! \n\nI got my LTO6 drive in (great deal on ebay, looks like whoever had it before mainly kept it on, but rarely ran tapes in it) and have my tapes ready to backup my data. What I'm now considering is how to compress and encrypt them.\n\nObviously, I want to be sure that a single bit failure doesn't destroy my ability to decrypt and recover my backups, so I'm thinking I need to encrypt them using a block-level cipher and use a compression like bz2 that can handle failures in one or more blocks and still decompress the rest of the file, so to that end I think I'd have to use bz2 + GPG using block cipher mode. \n\nOn the other hand, I found out about par2 and was thinking I could maybe use that and then be free to use something like lzma and age for compression/encryption.. but I've never used par2 before, so I'm pretty unsure.\n\nMaybe there's an even better idea I've missed altogether! Any input from the hivemind here would be welcome! What have you done or what would you do?", "author_fullname": "t2_vmt91h67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Encrypted LTO Backups and Managing Bitrot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tny9z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675536540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! &lt;/p&gt;\n\n&lt;p&gt;I got my LTO6 drive in (great deal on ebay, looks like whoever had it before mainly kept it on, but rarely ran tapes in it) and have my tapes ready to backup my data. What I&amp;#39;m now considering is how to compress and encrypt them.&lt;/p&gt;\n\n&lt;p&gt;Obviously, I want to be sure that a single bit failure doesn&amp;#39;t destroy my ability to decrypt and recover my backups, so I&amp;#39;m thinking I need to encrypt them using a block-level cipher and use a compression like bz2 that can handle failures in one or more blocks and still decompress the rest of the file, so to that end I think I&amp;#39;d have to use bz2 + GPG using block cipher mode. &lt;/p&gt;\n\n&lt;p&gt;On the other hand, I found out about par2 and was thinking I could maybe use that and then be free to use something like lzma and age for compression/encryption.. but I&amp;#39;ve never used par2 before, so I&amp;#39;m pretty unsure.&lt;/p&gt;\n\n&lt;p&gt;Maybe there&amp;#39;s an even better idea I&amp;#39;ve missed altogether! Any input from the hivemind here would be welcome! What have you done or what would you do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "64TB BTRFS RAID10 + LTO6 (In-Progress)", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10tny9z", "is_robot_indexable": true, "report_reasons": null, "author": "BanTheGovernment", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10tny9z/encrypted_lto_backups_and_managing_bitrot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10tny9z/encrypted_lto_backups_and_managing_bitrot/", "subreddit_subscribers": 668724, "created_utc": 1675536540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nBeen running TrueNAS for a while with SATA drives, but I just picked up a couple refurbished SAS drives off ebay to expand my pool with. \n\nCurrent pool is 3 8TB SATA drives in a RAIDZ1. I picked up 4 8TB SAS disks, 3 to use, 1 as a spare in case of a failure.\n\nI have an 9211-8i HBA card flashed to IT mode, but I don't have the correct breakout cables to connect the disks.\n\nWhat kind of breakout cables do I need in this scenario? Googling has me kind of overwhelmed and I don't want to buy the wrong thing.\n\nI want to say it's a mini SAS connector to 29 pin SAS - but will this still require external SATA power? Will I need to cover any pins with kapton tape like I had to for some of my earlier shucks?\n\nThese are the drives I bought - https://www.ebay.com/itm/195408198055\n\nAnd this is the HBA. https://www.ebay.com/itm/133481123885\n\nI'm aware it's a SAS2 controller vs SAS3 drives, but should still be compatible, right? All the SAS3 controllers were much more expensive and almost impossible to find apart from Chinese sellers.\n\nThanks for any help!", "author_fullname": "t2_40um1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Connecting SAS drives to HBA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ugpt8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675614951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Been running TrueNAS for a while with SATA drives, but I just picked up a couple refurbished SAS drives off ebay to expand my pool with. &lt;/p&gt;\n\n&lt;p&gt;Current pool is 3 8TB SATA drives in a RAIDZ1. I picked up 4 8TB SAS disks, 3 to use, 1 as a spare in case of a failure.&lt;/p&gt;\n\n&lt;p&gt;I have an 9211-8i HBA card flashed to IT mode, but I don&amp;#39;t have the correct breakout cables to connect the disks.&lt;/p&gt;\n\n&lt;p&gt;What kind of breakout cables do I need in this scenario? Googling has me kind of overwhelmed and I don&amp;#39;t want to buy the wrong thing.&lt;/p&gt;\n\n&lt;p&gt;I want to say it&amp;#39;s a mini SAS connector to 29 pin SAS - but will this still require external SATA power? Will I need to cover any pins with kapton tape like I had to for some of my earlier shucks?&lt;/p&gt;\n\n&lt;p&gt;These are the drives I bought - &lt;a href=\"https://www.ebay.com/itm/195408198055\"&gt;https://www.ebay.com/itm/195408198055&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And this is the HBA. &lt;a href=\"https://www.ebay.com/itm/133481123885\"&gt;https://www.ebay.com/itm/133481123885&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware it&amp;#39;s a SAS2 controller vs SAS3 drives, but should still be compatible, right? All the SAS3 controllers were much more expensive and almost impossible to find apart from Chinese sellers.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/kh-xrBxr9gGuY6GVkASmjn0kEsTx97YXOElE8eETvao.jpg?auto=webp&amp;v=enabled&amp;s=38393d6c8bcab41823db9574e03a089573244a8c", "width": 400, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/kh-xrBxr9gGuY6GVkASmjn0kEsTx97YXOElE8eETvao.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e543f9bb1069e0d67992b1f9596bfedbdc1f3a8", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/kh-xrBxr9gGuY6GVkASmjn0kEsTx97YXOElE8eETvao.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a56088297d45c1713b9e38e544c2a61f158d004", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/kh-xrBxr9gGuY6GVkASmjn0kEsTx97YXOElE8eETvao.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=200564587c446ec28651c60e17c440455186858e", "width": 320, "height": 240}], "variants": {}, "id": "LzD-_IBtf8koC379kCjvDlBntc8O9piQkEbyCSKtCQE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "55TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ugpt8", "is_robot_indexable": true, "report_reasons": null, "author": "skooterz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10ugpt8/connecting_sas_drives_to_hba/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ugpt8/connecting_sas_drives_to_hba/", "subreddit_subscribers": 668724, "created_utc": 1675614951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I keep accounts on all sort of sites, when all I need is an item logger\n- today i have seen this film\n- today i have played this board game\n- today i have read this book\n\nSometimes I just need to interrogate the software : have I seen / done this ever?\n\nSometimes I want to see how often have I opened this book? How often have I seen this film? When was the last time? Do I play this game more often in the evening? On Sundays?", "author_fullname": "t2_z2hswkf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does the OSS world has a logger (as in seen movies log) ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ugj6k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675614494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I keep accounts on all sort of sites, when all I need is an item logger\n- today i have seen this film\n- today i have played this board game\n- today i have read this book&lt;/p&gt;\n\n&lt;p&gt;Sometimes I just need to interrogate the software : have I seen / done this ever?&lt;/p&gt;\n\n&lt;p&gt;Sometimes I want to see how often have I opened this book? How often have I seen this film? When was the last time? Do I play this game more often in the evening? On Sundays?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ugj6k", "is_robot_indexable": true, "report_reasons": null, "author": "MosaicIncaSleds", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ugj6k/does_the_oss_world_has_a_logger_as_in_seen_movies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ugj6k/does_the_oss_world_has_a_logger_as_in_seen_movies/", "subreddit_subscribers": 668724, "created_utc": 1675614494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Server*\n\nLong story short my storage server has been off and stored away in a cold Michigan basement. In the next few weeks I will be setting it up and turning it on in the same basement. \n\nAre there any concerns I should have? Any advice is welcome.", "author_fullname": "t2_1g0zb8ts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting up a sever after 3 year in storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tx8yx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675600267.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675560317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Server*&lt;/p&gt;\n\n&lt;p&gt;Long story short my storage server has been off and stored away in a cold Michigan basement. In the next few weeks I will be setting it up and turning it on in the same basement. &lt;/p&gt;\n\n&lt;p&gt;Are there any concerns I should have? Any advice is welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10tx8yx", "is_robot_indexable": true, "report_reasons": null, "author": "BrushesAndAxes", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10tx8yx/starting_up_a_sever_after_3_year_in_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10tx8yx/starting_up_a_sever_after_3_year_in_storage/", "subreddit_subscribers": 668724, "created_utc": 1675560317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was cleaning out a closet and found an old iPad. I am not sure what surprised me more, when it charged and turned on or when I remembered the password (probably need to change passwords more often). I do not have a computer with iTunes or MacOS. I have a computer with win7 and one I can put various linux distros on. How do I get the pictures off the iPad and onto a computer? Thanks!", "author_fullname": "t2_usun3qeu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "iPad Data Retrieval", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10trdpa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675544993.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was cleaning out a closet and found an old iPad. I am not sure what surprised me more, when it charged and turned on or when I remembered the password (probably need to change passwords more often). I do not have a computer with iTunes or MacOS. I have a computer with win7 and one I can put various linux distros on. How do I get the pictures off the iPad and onto a computer? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10trdpa", "is_robot_indexable": true, "report_reasons": null, "author": "PuzzleheadedTennis23", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10trdpa/ipad_data_retrieval/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10trdpa/ipad_data_retrieval/", "subreddit_subscribers": 668724, "created_utc": 1675544993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, after reading about it in multiple posts in this sub, I ran Starwind Deduplication Analyzer on my main hard drive and it returned a \"Deduplication Ratio\" of 94.3%\n\nDoes this mean 5.7% of my files are dupes, or that I could recover 5.7% of my used space by removing duplicate files?\n\nI read the starwind website and it wasn't quite clear to me, sorry if this is a noob question.", "author_fullname": "t2_tuvv7t9j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starwind Deduplication Analyzer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tnqzz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675536050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, after reading about it in multiple posts in this sub, I ran Starwind Deduplication Analyzer on my main hard drive and it returned a &amp;quot;Deduplication Ratio&amp;quot; of 94.3%&lt;/p&gt;\n\n&lt;p&gt;Does this mean 5.7% of my files are dupes, or that I could recover 5.7% of my used space by removing duplicate files?&lt;/p&gt;\n\n&lt;p&gt;I read the starwind website and it wasn&amp;#39;t quite clear to me, sorry if this is a noob question.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10tnqzz", "is_robot_indexable": true, "report_reasons": null, "author": "PipersPickledPeppers", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10tnqzz/starwind_deduplication_analyzer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10tnqzz/starwind_deduplication_analyzer/", "subreddit_subscribers": 668724, "created_utc": 1675536050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i have recently boght a backup drive and want to backup my data. I am suing rsync to copy the files. bit i have lots of smol files. so the copying slows down to 1-2MB/s and sometimes less then 1MB. on windows robocopy would have multithreding so it would be mutch faster there but i am on linux. i have treied to use this comand that i found on stack overflow but it is still slow \"ls /from/here/ | xargs -n1 -P4 -I% rsync -Pa % /to/here/\" i think the proplem is that rsync has no multithreding and i thoght that this comand fixes it. how can i speed up the file coping?", "author_fullname": "t2_qf9k42c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how can i speed up cooping lots of smol files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10ui4nn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675618370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have recently boght a backup drive and want to backup my data. I am suing rsync to copy the files. bit i have lots of smol files. so the copying slows down to 1-2MB/s and sometimes less then 1MB. on windows robocopy would have multithreding so it would be mutch faster there but i am on linux. i have treied to use this comand that i found on stack overflow but it is still slow &amp;quot;ls /from/here/ | xargs -n1 -P4 -I% rsync -Pa % /to/here/&amp;quot; i think the proplem is that rsync has no multithreding and i thoght that this comand fixes it. how can i speed up the file coping?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "40TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ui4nn", "is_robot_indexable": true, "report_reasons": null, "author": "TheManni1000", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10ui4nn/how_can_i_speed_up_cooping_lots_of_smol_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ui4nn/how_can_i_speed_up_cooping_lots_of_smol_files/", "subreddit_subscribers": 668724, "created_utc": 1675618370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I typically don't worry too much with data backups, but after speaking with a friend it's gotten into my mind a bit, and as on right now I just have a Dropbox and an external WD SDD that hold most of my data for work, and I wanted to grant myself a bit more safety since I use the SDD for hot storage, and I really don't have something I only use purely to hold my data and backup every once in awhile.\n\nI was thinking of either grabbing a pair of externals or something like https://www.amazon.com/gp/aw/d/B07GZLKQSN/ref=cm_cr_othr_mb_bdcrb_top?ie=UTF8#cm_cr_carousel_images_section\n\nAlongside 2 internals, but I just don't know which and what I should grab to fulfill my needs, what would work best/I can store in a desk and not worry about damage, erosion, or something. \n\nMoney is also not an object here (well I don't want to spend thousands on some setup, but if there's some super-last forever drive that's proven to work at 500-1000 I wouldn't shy away from a pair).\n\nAlso this isn't a TON of data, atleast not yet. I'm currently around 500gb and that's with nearly ten years of work.\n\nThank you for your help, and sorry if anything I said is wrong or off, like I said, newbie.", "author_fullname": "t2_2ju9f6ga", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for drives for backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ugf12", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675614206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I typically don&amp;#39;t worry too much with data backups, but after speaking with a friend it&amp;#39;s gotten into my mind a bit, and as on right now I just have a Dropbox and an external WD SDD that hold most of my data for work, and I wanted to grant myself a bit more safety since I use the SDD for hot storage, and I really don&amp;#39;t have something I only use purely to hold my data and backup every once in awhile.&lt;/p&gt;\n\n&lt;p&gt;I was thinking of either grabbing a pair of externals or something like &lt;a href=\"https://www.amazon.com/gp/aw/d/B07GZLKQSN/ref=cm_cr_othr_mb_bdcrb_top?ie=UTF8#cm_cr_carousel_images_section\"&gt;https://www.amazon.com/gp/aw/d/B07GZLKQSN/ref=cm_cr_othr_mb_bdcrb_top?ie=UTF8#cm_cr_carousel_images_section&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Alongside 2 internals, but I just don&amp;#39;t know which and what I should grab to fulfill my needs, what would work best/I can store in a desk and not worry about damage, erosion, or something. &lt;/p&gt;\n\n&lt;p&gt;Money is also not an object here (well I don&amp;#39;t want to spend thousands on some setup, but if there&amp;#39;s some super-last forever drive that&amp;#39;s proven to work at 500-1000 I wouldn&amp;#39;t shy away from a pair).&lt;/p&gt;\n\n&lt;p&gt;Also this isn&amp;#39;t a TON of data, atleast not yet. I&amp;#39;m currently around 500gb and that&amp;#39;s with nearly ten years of work.&lt;/p&gt;\n\n&lt;p&gt;Thank you for your help, and sorry if anything I said is wrong or off, like I said, newbie.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ugf12", "is_robot_indexable": true, "report_reasons": null, "author": "Miniker", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ugf12/looking_for_drives_for_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ugf12/looking_for_drives_for_backup/", "subreddit_subscribers": 668724, "created_utc": 1675614206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 9300-8i + Adaptec 82885T expander in my box, with 16x Seagate 5TB HDD + 8x 860 Evo 2TB SSDs attached.\n\nI  was recently able to get my hands on some decommissioned PM1633a  15.36TB drives (Dell branded, from an EMC array), but they don't show up  both in OS (/dev/disk in Ubuntu) and in the HBA BIOS config.\n\nDrives are all connected through Icy Dock SAS/SATA compatible cages that support SAS 12Gbps.\n\nThings I've tried / am checking out:\n\n1. I've tried attaching the PM1633a both direct to a 9300 port and via one of the 82885T ports. No joy on both.\n2. I'm checking out whether it's a 520B issue (no experience with this, am reading).\n3. My understanding is mixing SAS/SATA drives is fine, even on expanders?", "author_fullname": "t2_j2b6gdd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSI 9300 does not see PM1633a (but SATA HDD/SSDs are detected)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10udhj3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675606633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 9300-8i + Adaptec 82885T expander in my box, with 16x Seagate 5TB HDD + 8x 860 Evo 2TB SSDs attached.&lt;/p&gt;\n\n&lt;p&gt;I  was recently able to get my hands on some decommissioned PM1633a  15.36TB drives (Dell branded, from an EMC array), but they don&amp;#39;t show up  both in OS (/dev/disk in Ubuntu) and in the HBA BIOS config.&lt;/p&gt;\n\n&lt;p&gt;Drives are all connected through Icy Dock SAS/SATA compatible cages that support SAS 12Gbps.&lt;/p&gt;\n\n&lt;p&gt;Things I&amp;#39;ve tried / am checking out:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I&amp;#39;ve tried attaching the PM1633a both direct to a 9300 port and via one of the 82885T ports. No joy on both.&lt;/li&gt;\n&lt;li&gt;I&amp;#39;m checking out whether it&amp;#39;s a 520B issue (no experience with this, am reading).&lt;/li&gt;\n&lt;li&gt;My understanding is mixing SAS/SATA drives is fine, even on expanders?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "64TB ZFS 2.5\"", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10udhj3", "is_robot_indexable": true, "report_reasons": null, "author": "mystandardusername", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10udhj3/lsi_9300_does_not_see_pm1633a_but_sata_hddssds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10udhj3/lsi_9300_does_not_see_pm1633a_but_sata_hddssds/", "subreddit_subscribers": 668724, "created_utc": 1675606633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it too good to be true? Or am I just way too gullible and about to be scammed?\n\nhttps://www.gumtree.com.au/s-ad/flemington/hard-drives-usb-sticks/new-wd-seagate-18tb-16tb-14tb-12tb-hard-drive-sata-tb-pc-nas-hdd-3-5/1307454154", "author_fullname": "t2_tbvry9u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "$249 USD (equivalent) for 12TB of a new Exos drive.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u5f37", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675576960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it too good to be true? Or am I just way too gullible and about to be scammed?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.gumtree.com.au/s-ad/flemington/hard-drives-usb-sticks/new-wd-seagate-18tb-16tb-14tb-12tb-hard-drive-sata-tb-pc-nas-hdd-3-5/1307454154\"&gt;https://www.gumtree.com.au/s-ad/flemington/hard-drives-usb-sticks/new-wd-seagate-18tb-16tb-14tb-12tb-hard-drive-sata-tb-pc-nas-hdd-3-5/1307454154&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iuFyx5FZfnfSNgPAkANeM5ykzPWZarDSVtKwqL94VUM.jpg?auto=webp&amp;v=enabled&amp;s=42f16d711274170e213615fc3df02e2158c2cadb", "width": 579, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/iuFyx5FZfnfSNgPAkANeM5ykzPWZarDSVtKwqL94VUM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7475bbbb4633720688f56c4905daa43d773759f3", "width": 108, "height": 119}, {"url": "https://external-preview.redd.it/iuFyx5FZfnfSNgPAkANeM5ykzPWZarDSVtKwqL94VUM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ea5a69c902c03564c342afdb70c39da97b82742", "width": 216, "height": 238}, {"url": "https://external-preview.redd.it/iuFyx5FZfnfSNgPAkANeM5ykzPWZarDSVtKwqL94VUM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=406ff771e9af4fa3749b64f92138a59303b6830a", "width": 320, "height": 353}], "variants": {}, "id": "gVheL6bLaXnwMwEKKSTY3Vj4LZmaoPU8zPLT_8iMyPY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10u5f37", "is_robot_indexable": true, "report_reasons": null, "author": "UnfairerThree2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10u5f37/249_usd_equivalent_for_12tb_of_a_new_exos_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10u5f37/249_usd_equivalent_for_12tb_of_a_new_exos_drive/", "subreddit_subscribers": 668724, "created_utc": 1675576960.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a fairly large photo library and like to be able to take everything with me when I travel. I like to go back through old shoots when I have downtime and do some edits. I was planning to use a Glyph Atom RAID 4TB external SSD for this purpose. I formatted as EXFAT for compatibility between Mac and Windows. Unsurprisingly, I started having a lot of issues with the drive. Eventually, it just showed as RAW and since I have everything backed up I decided to format as HFS+ and use Paragon. This went fine, but then as I was transferring everything back to the external I got an error that the drive no longer existed. Since then I haven't been able to format the drive as HFS+ or NTFS using windows cmd, Mac OS, Paragon or some other software I've tried.\n\nThe latest thing I've tried is running a check in AOMEI. Sure enough, it seems I have some damaged sectors. As of today it's been running for 144 hours and still stuck on the same \"block\" in AOMEI, so I'm thinking I'm not getting any further with this process.\n\nIs there a way to fix the external SSD? I would think there would be a piece of software that could format it and \"lock off\" the bad sectors so that it just functions like normal. Or, am I better off tossing the drive and starting anew? I can't return it as I'm way past the return window.\n\nEDIT: [link to drive](https://www.bhphotovideo.com/c/product/1401259-REG/glyph_technologies_ar4000blk_atom_raid_4tb_ssd.html)", "author_fullname": "t2_g8n4d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4TB External SSD Won't Mount or Format. Bad sectors.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u1bk5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675580137.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675571386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a fairly large photo library and like to be able to take everything with me when I travel. I like to go back through old shoots when I have downtime and do some edits. I was planning to use a Glyph Atom RAID 4TB external SSD for this purpose. I formatted as EXFAT for compatibility between Mac and Windows. Unsurprisingly, I started having a lot of issues with the drive. Eventually, it just showed as RAW and since I have everything backed up I decided to format as HFS+ and use Paragon. This went fine, but then as I was transferring everything back to the external I got an error that the drive no longer existed. Since then I haven&amp;#39;t been able to format the drive as HFS+ or NTFS using windows cmd, Mac OS, Paragon or some other software I&amp;#39;ve tried.&lt;/p&gt;\n\n&lt;p&gt;The latest thing I&amp;#39;ve tried is running a check in AOMEI. Sure enough, it seems I have some damaged sectors. As of today it&amp;#39;s been running for 144 hours and still stuck on the same &amp;quot;block&amp;quot; in AOMEI, so I&amp;#39;m thinking I&amp;#39;m not getting any further with this process.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to fix the external SSD? I would think there would be a piece of software that could format it and &amp;quot;lock off&amp;quot; the bad sectors so that it just functions like normal. Or, am I better off tossing the drive and starting anew? I can&amp;#39;t return it as I&amp;#39;m way past the return window.&lt;/p&gt;\n\n&lt;p&gt;EDIT: &lt;a href=\"https://www.bhphotovideo.com/c/product/1401259-REG/glyph_technologies_ar4000blk_atom_raid_4tb_ssd.html\"&gt;link to drive&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VBZh9d0nofPFWKddRzImB3FmfSpIsD0tHmiE7bLn_zk.jpg?auto=webp&amp;v=enabled&amp;s=3ace722f07a97cad28d0119edc3c8a2c64a9ca47", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/VBZh9d0nofPFWKddRzImB3FmfSpIsD0tHmiE7bLn_zk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=268c5648890d189548378b929d83d057c847fa61", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/VBZh9d0nofPFWKddRzImB3FmfSpIsD0tHmiE7bLn_zk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e8f5c989415c842404994f9dcc436eb7e31d261", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/VBZh9d0nofPFWKddRzImB3FmfSpIsD0tHmiE7bLn_zk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eca1920da4fd1b2cd7aa4fe5415f30b0fce244eb", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/VBZh9d0nofPFWKddRzImB3FmfSpIsD0tHmiE7bLn_zk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d248c0e6a2e62109d085e87f15df047bee3b6227", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/VBZh9d0nofPFWKddRzImB3FmfSpIsD0tHmiE7bLn_zk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1fbdd68993d9ab8693b9256f315a80c53c6526ad", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/VBZh9d0nofPFWKddRzImB3FmfSpIsD0tHmiE7bLn_zk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=df9da950904c26e5b11d91476cade14e6a412c95", "width": 1080, "height": 567}], "variants": {}, "id": "fGUOvJzZlyDBarZ-J2CcB1h_1DuI30ArwIrukDqkQqk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10u1bk5", "is_robot_indexable": true, "report_reasons": null, "author": "Clutch51", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10u1bk5/4tb_external_ssd_wont_mount_or_format_bad_sectors/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10u1bk5/4tb_external_ssd_wont_mount_or_format_bad_sectors/", "subreddit_subscribers": 668724, "created_utc": 1675571386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI am in the process of moving about 2,5TB of files to a offsite server using ssh. My goal is to mirror the local directory tree, with the ability to pause and resume the transfer.\n\nHere's the rsync command I came up with:\n\n    rsync -P --append-verify -e 'ssh -p23' --recursive * user@server:target/\n\nWhy these options/arguments?:\n\n**-P** *Print progress and don't \"abandon\" partial files*\n\n**--append-verify** *Verify partial files and resume the transfer*\n\n**--recursive** *Recurse into directories*\n\n&amp;#x200B;\n\n**Are there any improvements I could make here?** \n\nI want to make sure all files get transferred while wasting as little time as possible.\n\nI'd also like a way to confirm checksums when the transfer is complete. Since I don't have access to most tools on the remote server so I can't do something like:  \n\n    find . -type f -exec sha256sum {} \\; | sort &gt; hash.sha256", "author_fullname": "t2_33ezpybq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving and verifying large amount of files with rsync while wasting no time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tyvgf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675565001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am in the process of moving about 2,5TB of files to a offsite server using ssh. My goal is to mirror the local directory tree, with the ability to pause and resume the transfer.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the rsync command I came up with:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;rsync -P --append-verify -e &amp;#39;ssh -p23&amp;#39; --recursive * user@server:target/\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Why these options/arguments?:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;-P&lt;/strong&gt; &lt;em&gt;Print progress and don&amp;#39;t &amp;quot;abandon&amp;quot; partial files&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;--append-verify&lt;/strong&gt; &lt;em&gt;Verify partial files and resume the transfer&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;--recursive&lt;/strong&gt; &lt;em&gt;Recurse into directories&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Are there any improvements I could make here?&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;I want to make sure all files get transferred while wasting as little time as possible.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d also like a way to confirm checksums when the transfer is complete. Since I don&amp;#39;t have access to most tools on the remote server so I can&amp;#39;t do something like:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;find . -type f -exec sha256sum {} \\; | sort &amp;gt; hash.sha256\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "10TB - RAID5", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10tyvgf", "is_robot_indexable": true, "report_reasons": null, "author": "Watn3y", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/10tyvgf/moving_and_verifying_large_amount_of_files_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10tyvgf/moving_and_verifying_large_amount_of_files_with/", "subreddit_subscribers": 668724, "created_utc": 1675565001.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}