{"kind": "Listing", "data": {"after": "t3_10tkwkt", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Has anyone experienced this? I'm 2 weeks into a new job and had a meeting with my manager where he said he was concerned I was working slowly.  However I've finished the two tasks he's assigned me each a day early..", "author_fullname": "t2_2d6rhe2a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Completing Tasks before the finish date but manager says I'm slow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tjqwi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 140, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 140, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675526359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone experienced this? I&amp;#39;m 2 weeks into a new job and had a meeting with my manager where he said he was concerned I was working slowly.  However I&amp;#39;ve finished the two tasks he&amp;#39;s assigned me each a day early..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tjqwi", "is_robot_indexable": true, "report_reasons": null, "author": "HappyKoalaCub", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tjqwi/completing_tasks_before_the_finish_date_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tjqwi/completing_tasks_before_the_finish_date_but/", "subreddit_subscribers": 844676, "created_utc": 1675526359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Here is the link to the article: https://towardsdatascience.com/today-i-quit-data-sciences-here-are-7-reasons-why-15c29e51d032", "author_fullname": "t2_mv20pew7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expectations for Data Scientists, a very interesting perspective", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10tnpsw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 75, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 75, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QkJnpthDPFBmmUR3V94UIbp1ZfZ2xZ1wSW30oz5-9dw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675535970.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here is the link to the article: &lt;a href=\"https://towardsdatascience.com/today-i-quit-data-sciences-here-are-7-reasons-why-15c29e51d032\"&gt;https://towardsdatascience.com/today-i-quit-data-sciences-here-are-7-reasons-why-15c29e51d032&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/j6jjlhvoc9ga1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/j6jjlhvoc9ga1.jpg?auto=webp&amp;v=enabled&amp;s=723856c1f3a56e4f57869e84c989d5046ccfe54d", "width": 1179, "height": 1637}, "resolutions": [{"url": "https://preview.redd.it/j6jjlhvoc9ga1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a2fdfcd36388505ebc77874a2573ed827abc7c3", "width": 108, "height": 149}, {"url": "https://preview.redd.it/j6jjlhvoc9ga1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f02a59fab63b11a67f9fa8e9f651f2eb95c82bf", "width": 216, "height": 299}, {"url": "https://preview.redd.it/j6jjlhvoc9ga1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b89ae0e07f114d4e669dc55221599cf6b40d600", "width": 320, "height": 444}, {"url": "https://preview.redd.it/j6jjlhvoc9ga1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ea54189da0b48e9084736b2e2bd7308d53b4c4e", "width": 640, "height": 888}, {"url": "https://preview.redd.it/j6jjlhvoc9ga1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e44e0dfdf6d476c7a066a556df5d689dca96f693", "width": 960, "height": 1332}, {"url": "https://preview.redd.it/j6jjlhvoc9ga1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=914eed27bbee9e3dcf13d3587831c89d21f2b566", "width": 1080, "height": 1499}], "variants": {}, "id": "ALeTGh-u0ujUsoTVmsd6yjnZOItqRA0QfPgcJq3IeKw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tnpsw", "is_robot_indexable": true, "report_reasons": null, "author": "Calm_Inky", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tnpsw/expectations_for_data_scientists_a_very/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/j6jjlhvoc9ga1.jpg", "subreddit_subscribers": 844676, "created_utc": 1675535970.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been promoted twice to manager now of data science and I find myself in meetings talking more than I spend (if any) working on technical stuff\n\nIs this normal? I get paid almost $200k to say stuff \ud83e\udd14", "author_fullname": "t2_aji4iba3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal for data scientists to move to non technical roles as they move up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10trfwo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675545142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been promoted twice to manager now of data science and I find myself in meetings talking more than I spend (if any) working on technical stuff&lt;/p&gt;\n\n&lt;p&gt;Is this normal? I get paid almost $200k to say stuff \ud83e\udd14&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10trfwo", "is_robot_indexable": true, "report_reasons": null, "author": "whowasphones", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10trfwo/is_it_normal_for_data_scientists_to_move_to_non/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10trfwo/is_it_normal_for_data_scientists_to_move_to_non/", "subreddit_subscribers": 844676, "created_utc": 1675545142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am teaching a course on Big Data starting next week and had planned a project with the twitter API for exercising spark structured streaming. Of course, that might be rather difficult now. So I am wondering if there is a similar alternative to get a stream of text using an api which is either saved in a directory or kafka. I have mostly found examples where you would have to poll continuously like facebook. \n\nAny ideas? Thanks!", "author_fullname": "t2_dnnob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitter API alternative?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10t6ana", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675489456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am teaching a course on Big Data starting next week and had planned a project with the twitter API for exercising spark structured streaming. Of course, that might be rather difficult now. So I am wondering if there is a similar alternative to get a stream of text using an api which is either saved in a directory or kafka. I have mostly found examples where you would have to poll continuously like facebook. &lt;/p&gt;\n\n&lt;p&gt;Any ideas? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10t6ana", "is_robot_indexable": true, "report_reasons": null, "author": "aziriel", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10t6ana/twitter_api_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10t6ana/twitter_api_alternative/", "subreddit_subscribers": 844676, "created_utc": 1675489456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How hard/easy will it be for me to get a data science job having this under my belt:\n\n\\- 2 years working as a Data Analyst\n\n\\- 2 years as Computational biologist in undergrad\n\n\\- Masters in Data Science", "author_fullname": "t2_6xabempy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need some perspective (related to the DS job market):", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tnx8m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675536470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How hard/easy will it be for me to get a data science job having this under my belt:&lt;/p&gt;\n\n&lt;p&gt;- 2 years working as a Data Analyst&lt;/p&gt;\n\n&lt;p&gt;- 2 years as Computational biologist in undergrad&lt;/p&gt;\n\n&lt;p&gt;- Masters in Data Science&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tnx8m", "is_robot_indexable": true, "report_reasons": null, "author": "marjose2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tnx8m/i_need_some_perspective_related_to_the_ds_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tnx8m/i_need_some_perspective_related_to_the_ds_job/", "subreddit_subscribers": 844676, "created_utc": 1675536470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There are a lot of things going on in the field, how to you keep track of all the new stuff coming up. \n\nMy main resource at the moment is my linkedIn feed with focused research after finding something interesting.", "author_fullname": "t2_ds7pgpee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Staying up to date after graduation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tu44b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675551885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are a lot of things going on in the field, how to you keep track of all the new stuff coming up. &lt;/p&gt;\n\n&lt;p&gt;My main resource at the moment is my linkedIn feed with focused research after finding something interesting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tu44b", "is_robot_indexable": true, "report_reasons": null, "author": "Tukdu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tu44b/staying_up_to_date_after_graduation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tu44b/staying_up_to_date_after_graduation/", "subreddit_subscribers": 844676, "created_utc": 1675551885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm curious about the UPenn MSE in Data Science program's statistics, and timeline. I was also wondering if anyone here has any experience with it. If you have, I'd love to hear about:\n\n1. Did you or someone you know enroll in the program?\n2. What was your admission stats like?\n3. How long did it take for the decision to arrive?\n4. What kind of job opportunities came up after finishing the program?\n5. Would you recommend the program to others who are already data scientists?\n\nAny info or thoughts you have would be awesome. Thanks!", "author_fullname": "t2_6gpihliq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSE DS (Online) U Penn Admission Statistics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10t2zba", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675478786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious about the UPenn MSE in Data Science program&amp;#39;s statistics, and timeline. I was also wondering if anyone here has any experience with it. If you have, I&amp;#39;d love to hear about:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Did you or someone you know enroll in the program?&lt;/li&gt;\n&lt;li&gt;What was your admission stats like?&lt;/li&gt;\n&lt;li&gt;How long did it take for the decision to arrive?&lt;/li&gt;\n&lt;li&gt;What kind of job opportunities came up after finishing the program?&lt;/li&gt;\n&lt;li&gt;Would you recommend the program to others who are already data scientists?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any info or thoughts you have would be awesome. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10t2zba", "is_robot_indexable": true, "report_reasons": null, "author": "wardrobe_creator", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10t2zba/mse_ds_online_u_penn_admission_statistics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10t2zba/mse_ds_online_u_penn_admission_statistics/", "subreddit_subscribers": 844676, "created_utc": 1675478786.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I've watched a few tutorials on topic modeling in Python, with some open source libraries (gensim, spacy, etc). What I want to be able to do is tag a large group of reviews (such as yelp reviews) with one or more appropriately named topics. In the [above mentioned tutorials](https://youtu.be/UEn3xHNBXJU?t=867) I see the results as clusters that contain common terms, but I don't yet see how to go about adding an appropriate name to these clusters, and then ultimately assigning this name, or tag, back to individual reviews. How do I get from the initial analysis (LDA or what have you), to actually tagging a review with one or more appropriate categories? For example, a review talking about how expensive a hamburger is, might get assigned a \"price\" tag/category. Maybe LDA isn't the right method? Thanks for your tips and/or recommended tutorials!", "author_fullname": "t2_z075s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP: naming topics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tr7zr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675544875.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675544583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;ve watched a few tutorials on topic modeling in Python, with some open source libraries (gensim, spacy, etc). What I want to be able to do is tag a large group of reviews (such as yelp reviews) with one or more appropriately named topics. In the &lt;a href=\"https://youtu.be/UEn3xHNBXJU?t=867\"&gt;above mentioned tutorials&lt;/a&gt; I see the results as clusters that contain common terms, but I don&amp;#39;t yet see how to go about adding an appropriate name to these clusters, and then ultimately assigning this name, or tag, back to individual reviews. How do I get from the initial analysis (LDA or what have you), to actually tagging a review with one or more appropriate categories? For example, a review talking about how expensive a hamburger is, might get assigned a &amp;quot;price&amp;quot; tag/category. Maybe LDA isn&amp;#39;t the right method? Thanks for your tips and/or recommended tutorials!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jVTARUg3iTtvmYrVAujuKvGg4Gzsxj-WRpJgwnO7_XI.jpg?auto=webp&amp;v=enabled&amp;s=3658bcd4877612422d23235b8db678090d990d6a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/jVTARUg3iTtvmYrVAujuKvGg4Gzsxj-WRpJgwnO7_XI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69631c225060a3f0e6103f258394901054dfa227", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/jVTARUg3iTtvmYrVAujuKvGg4Gzsxj-WRpJgwnO7_XI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d80d05728c007c6050747177975e48bc6878803", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/jVTARUg3iTtvmYrVAujuKvGg4Gzsxj-WRpJgwnO7_XI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a047e862301da93e9c39613205b9a2b505c09166", "width": 320, "height": 240}], "variants": {}, "id": "pi2z2Pelp3SX_k0jIvGaPYOqkKb7lrZb4a1lg9essRw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tr7zr", "is_robot_indexable": true, "report_reasons": null, "author": "mogla", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tr7zr/nlp_naming_topics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tr7zr/nlp_naming_topics/", "subreddit_subscribers": 844676, "created_utc": 1675544583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a problem where I'm looking at API calls and downstream impact. Not really a specific question to answer, but predicting performance of the calls based on path through the audit trail would be interesting to do. Or, anomaly detection (i.e, this API is defective in 10% of transactions)  \n\n\nI have thought of two approaches. One of them is regarding the data contained within the request/response payloads. The issue is, it's all text based, or changes depending on the specific API, so the data transformation aspect is very tough. Encoding one API's response to compare to a different API's response would be challenging. Perhaps there is an opportunity for deep learning here.  \n\n\nThe other approach I'm thinking about, is treating this as a graph problem. The majority of these transactions will form a tree-like structure, but some of them don't have a true root, so its more of a directed, acyclic graph (think it's called a polytree?). My approach would be to use graph theory principals such as degrees, closeness, vertex distance, etc. as features instead of parsing the very dynamic payloads. Since these are rules-based systems, I would love to be able to model the underlying relationships between these calls, that way when one transaction chain doesn't match the model, it's likely an anomaly.   \n\n\nDoes this make sense to do? Has anyone here done something similar? Any recommended literature? I've tried googling it, but when you search \"machine learning approach to tree-based systems\", you get a lot of papers or articles referencing tree-based ML models, which is not exactly what I'm looking for yet. Thoughts?", "author_fullname": "t2_1wcsnihu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Applying Graph Theory in Machine Learning problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10to95b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675537246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a problem where I&amp;#39;m looking at API calls and downstream impact. Not really a specific question to answer, but predicting performance of the calls based on path through the audit trail would be interesting to do. Or, anomaly detection (i.e, this API is defective in 10% of transactions)  &lt;/p&gt;\n\n&lt;p&gt;I have thought of two approaches. One of them is regarding the data contained within the request/response payloads. The issue is, it&amp;#39;s all text based, or changes depending on the specific API, so the data transformation aspect is very tough. Encoding one API&amp;#39;s response to compare to a different API&amp;#39;s response would be challenging. Perhaps there is an opportunity for deep learning here.  &lt;/p&gt;\n\n&lt;p&gt;The other approach I&amp;#39;m thinking about, is treating this as a graph problem. The majority of these transactions will form a tree-like structure, but some of them don&amp;#39;t have a true root, so its more of a directed, acyclic graph (think it&amp;#39;s called a polytree?). My approach would be to use graph theory principals such as degrees, closeness, vertex distance, etc. as features instead of parsing the very dynamic payloads. Since these are rules-based systems, I would love to be able to model the underlying relationships between these calls, that way when one transaction chain doesn&amp;#39;t match the model, it&amp;#39;s likely an anomaly.   &lt;/p&gt;\n\n&lt;p&gt;Does this make sense to do? Has anyone here done something similar? Any recommended literature? I&amp;#39;ve tried googling it, but when you search &amp;quot;machine learning approach to tree-based systems&amp;quot;, you get a lot of papers or articles referencing tree-based ML models, which is not exactly what I&amp;#39;m looking for yet. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10to95b", "is_robot_indexable": true, "report_reasons": null, "author": "tigerclaw468", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10to95b/applying_graph_theory_in_machine_learning_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10to95b/applying_graph_theory_in_machine_learning_problem/", "subreddit_subscribers": 844676, "created_utc": 1675537246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "as someone from non tech which books help you understand language/ software without spending too much time in technical jargon and verbose", "author_fullname": "t2_7gkixkov", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you're new to databases should you start with the book Database Design for Mere Mortals or SQL Queries for Mere Mortals or Head first with sql", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tadz8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675500777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;as someone from non tech which books help you understand language/ software without spending too much time in technical jargon and verbose&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tadz8", "is_robot_indexable": true, "report_reasons": null, "author": "One_Valuable7049", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tadz8/if_youre_new_to_databases_should_you_start_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tadz8/if_youre_new_to_databases_should_you_start_with/", "subreddit_subscribers": 844676, "created_utc": 1675500777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\nI'm currently working on my masters and I'm having a hard time choosing which electives to choose from. I want to make sure I come out of the program as well-equipped as possible. I am able to choose four out of the following five classes as my remaining electives. I've also provided a synopsis of what each course will cover:  \n  \n\n* **Data Science for Business**: This course explores the various ways data and science can be applied to business contexts. Particular emphasis will be placed on using data to make informed business decisions.\n* **Principles of Python Programming**: Programming, problem solving and algorithmic thinking in Python. Topics include variables, input/output, conditional, statements/logic, Boolean expressions, flow control, loops and functions \n* **Data Manipulation**: This course focuses on the loading, manipulating, processing, cleaning, aggregating, and grouping of data. Students will practice on real world data sets, learning how to manipulate data using Python and continue their study of intermediate and advanced topics from the NumPy and Pandas libraries\n* **Information Visualization**: each students the best practices in Data Visualization, the key trends in the industry, and how to become great storytellers with data. Students taking this class will learn the importance of using actionable dashboards that enable their organizations to make data-driven decisions. For this class students will be exposed to Qlik and Tableau\n* **Applied Machine Learning**: This course will further explore modern machine learning applications such as decision trees and various ensemble learning methods including random forests. Special attention will be given to performing hyperparameter tuning to improve our models. Students will also focus on different dimensionality reduction techniques with emphasis on using principal component analysis. Students will explore the K-Nearest Neighbors algorithm and use it to build a machine learning project from scratch. Finally, students will study an introduction to using artificial neural networks to solve classification and regression problems. This course is entirely taught in Python.\n\nAny advice is much appreciated!", "author_fullname": "t2_1x7s010", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Masters Elective Selection Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10t4rdc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675516985.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675484275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working on my masters and I&amp;#39;m having a hard time choosing which electives to choose from. I want to make sure I come out of the program as well-equipped as possible. I am able to choose four out of the following five classes as my remaining electives. I&amp;#39;ve also provided a synopsis of what each course will cover:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Data Science for Business&lt;/strong&gt;: This course explores the various ways data and science can be applied to business contexts. Particular emphasis will be placed on using data to make informed business decisions.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Principles of Python Programming&lt;/strong&gt;: Programming, problem solving and algorithmic thinking in Python. Topics include variables, input/output, conditional, statements/logic, Boolean expressions, flow control, loops and functions &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data Manipulation&lt;/strong&gt;: This course focuses on the loading, manipulating, processing, cleaning, aggregating, and grouping of data. Students will practice on real world data sets, learning how to manipulate data using Python and continue their study of intermediate and advanced topics from the NumPy and Pandas libraries&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Information Visualization&lt;/strong&gt;: each students the best practices in Data Visualization, the key trends in the industry, and how to become great storytellers with data. Students taking this class will learn the importance of using actionable dashboards that enable their organizations to make data-driven decisions. For this class students will be exposed to Qlik and Tableau&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Applied Machine Learning&lt;/strong&gt;: This course will further explore modern machine learning applications such as decision trees and various ensemble learning methods including random forests. Special attention will be given to performing hyperparameter tuning to improve our models. Students will also focus on different dimensionality reduction techniques with emphasis on using principal component analysis. Students will explore the K-Nearest Neighbors algorithm and use it to build a machine learning project from scratch. Finally, students will study an introduction to using artificial neural networks to solve classification and regression problems. This course is entirely taught in Python.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any advice is much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10t4rdc", "is_robot_indexable": true, "report_reasons": null, "author": "HercHuntsdirty", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10t4rdc/masters_elective_selection_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10t4rdc/masters_elective_selection_advice/", "subreddit_subscribers": 844676, "created_utc": 1675484275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI was tasked with finding videos for product releases for several companies from a very large Excel file with headlines of new articles. The Excel has only the headline of the product release article &amp; the company names. there are about 10,000 headlines.\n\nHow can I approach this problem and ultimately automate it?", "author_fullname": "t2_4jekmmq3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding Products Advertisement Videos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10txeas", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675560727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I was tasked with finding videos for product releases for several companies from a very large Excel file with headlines of new articles. The Excel has only the headline of the product release article &amp;amp; the company names. there are about 10,000 headlines.&lt;/p&gt;\n\n&lt;p&gt;How can I approach this problem and ultimately automate it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10txeas", "is_robot_indexable": true, "report_reasons": null, "author": "mouayedlajnef", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10txeas/finding_products_advertisement_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10txeas/finding_products_advertisement_videos/", "subreddit_subscribers": 844676, "created_utc": 1675560727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Non-data-scientist here.\n\nI came across this huggingface webpage ([https://huggingface.co/docs/transformers/main/model\\_doc/biogpt](https://huggingface.co/docs/transformers/main/model_doc/biogpt)) and saw this bullet point:\n\n&gt;BioGPT is a model with absolute position embeddings so it\u2019s usually advised to pad the inputs on the right rather than the left.\n\nWhat does that mean?\n\nTIA.", "author_fullname": "t2_rvu8sqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELI5: \"to pad the inputs on the right rather than the left.\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10trq62", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675545850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Non-data-scientist here.&lt;/p&gt;\n\n&lt;p&gt;I came across this huggingface webpage (&lt;a href=\"https://huggingface.co/docs/transformers/main/model_doc/biogpt\"&gt;https://huggingface.co/docs/transformers/main/model_doc/biogpt&lt;/a&gt;) and saw this bullet point:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;BioGPT is a model with absolute position embeddings so it\u2019s usually advised to pad the inputs on the right rather than the left.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What does that mean?&lt;/p&gt;\n\n&lt;p&gt;TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?auto=webp&amp;v=enabled&amp;s=09310ab6255bb753ca4a771c0314bc214f78d2ac", "width": 1200, "height": 648}, "resolutions": [{"url": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d98fc28f03459191933e04a79947277468884240", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63df823a11fd89a126d46aa7fe24a61e8802e772", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=320261cc71f0e3ceb4e3bf8a0d13183bec39c51d", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1ad1e1c2f09bcd80fcb1946c0b9fd262bd87956", "width": 640, "height": 345}, {"url": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d11d529124019d86e37cdf83869dc778034a7213", "width": 960, "height": 518}, {"url": "https://external-preview.redd.it/Bixm6H31yqw0RCcD8LB0e8eIdtJeMUaF4N5ZipM_BQY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4946d1e6be18d75acabb03d041038e3d4fa8e686", "width": 1080, "height": 583}], "variants": {}, "id": "jfeVG47nZdEkz9kXfW1CcS-Sy8l4DXGb9JErx6bLKfU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10trq62", "is_robot_indexable": true, "report_reasons": null, "author": "babysharkdoodoodoo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10trq62/eli5_to_pad_the_inputs_on_the_right_rather_than/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10trq62/eli5_to_pad_the_inputs_on_the_right_rather_than/", "subreddit_subscribers": 844676, "created_utc": 1675545850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I recently became aware of the application of data mining in flushing out bugs or anomalies using pattern detection. Have you seen this applied before in the industry or is it one of those things you only see in academic research?", "author_fullname": "t2_pdclzxln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Application of software bug mining techniques in the software industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tq7xe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675542076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently became aware of the application of data mining in flushing out bugs or anomalies using pattern detection. Have you seen this applied before in the industry or is it one of those things you only see in academic research?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tq7xe", "is_robot_indexable": true, "report_reasons": null, "author": "LongjumpingWheel11", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tq7xe/application_of_software_bug_mining_techniques_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tq7xe/application_of_software_bug_mining_techniques_in/", "subreddit_subscribers": 844676, "created_utc": 1675542076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey all, I just finished my bachelor's degree in industrial engineering. I was checking this coursera degree in data science and I want to know if it's a good option to pursue since I want to have work while studying for a graduate degree. so my questions are the following:\n\n  \nis the degree worth it?\n\n  \ncan I find a FAANG job after getting this degree or at least in a niche start-up? I know it needs extra work but would it help, my current university is in eastern Europe.\n\n  \nI gladly want to hear about the experience of people who enrolled.", "author_fullname": "t2_t5qwf09f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "concerning coursera based colorado boulder ms degree in data science.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10trdwi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675545005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I just finished my bachelor&amp;#39;s degree in industrial engineering. I was checking this coursera degree in data science and I want to know if it&amp;#39;s a good option to pursue since I want to have work while studying for a graduate degree. so my questions are the following:&lt;/p&gt;\n\n&lt;p&gt;is the degree worth it?&lt;/p&gt;\n\n&lt;p&gt;can I find a FAANG job after getting this degree or at least in a niche start-up? I know it needs extra work but would it help, my current university is in eastern Europe.&lt;/p&gt;\n\n&lt;p&gt;I gladly want to hear about the experience of people who enrolled.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10trdwi", "is_robot_indexable": true, "report_reasons": null, "author": "electronengine19", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10trdwi/concerning_coursera_based_colorado_boulder_ms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10trdwi/concerning_coursera_based_colorado_boulder_ms/", "subreddit_subscribers": 844676, "created_utc": 1675545005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI'm considering getting a post grad credential from the list in the title and looking for input from others who have done/are doing similar.  \n\nMy Background: BS in Mgmt, Concentration Info Sys; UT MBA, Concentration IM/Tech Strategy.  I'm late career (mid 50), have been in high tech (HW) about 25 years and want to work another 4-7.  After that I would consult til tired.  \n\nCurrently facing tech layoff and looking, but no immediate financial pressure for 1 - 2 years. \n\nPrograms I'm considering:\n\n1. Newly announced UT Masters in AI. Would likely do an AI cert in the meanwhile or assumed pre-reqs (coding, linear algebra).  Sounds technical and not sure I'd get accepted.  est. \\~2 years to complete.\n2. GT Masters in Analytics, with a few added AI courses.  Would likely play catchup on the Micromasters to get that out of the way.  est. \\~2 years to complete.\n3. IBM or UT AI Cert and other as needed.  6-9 mos to complete.\n\nLikely would need a Udemy in Python coding in all 3 cases.  For those who have done, or looked at doing, any of these, what would you do/do differently?  \n\nAll input welcome.  Thanks!", "author_fullname": "t2_5vkcyd9u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "UT Masters in AI v. GT OMA v. an AI Cert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tru1d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675546131.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering getting a post grad credential from the list in the title and looking for input from others who have done/are doing similar.  &lt;/p&gt;\n\n&lt;p&gt;My Background: BS in Mgmt, Concentration Info Sys; UT MBA, Concentration IM/Tech Strategy.  I&amp;#39;m late career (mid 50), have been in high tech (HW) about 25 years and want to work another 4-7.  After that I would consult til tired.  &lt;/p&gt;\n\n&lt;p&gt;Currently facing tech layoff and looking, but no immediate financial pressure for 1 - 2 years. &lt;/p&gt;\n\n&lt;p&gt;Programs I&amp;#39;m considering:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Newly announced UT Masters in AI. Would likely do an AI cert in the meanwhile or assumed pre-reqs (coding, linear algebra).  Sounds technical and not sure I&amp;#39;d get accepted.  est. ~2 years to complete.&lt;/li&gt;\n&lt;li&gt;GT Masters in Analytics, with a few added AI courses.  Would likely play catchup on the Micromasters to get that out of the way.  est. ~2 years to complete.&lt;/li&gt;\n&lt;li&gt;IBM or UT AI Cert and other as needed.  6-9 mos to complete.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Likely would need a Udemy in Python coding in all 3 cases.  For those who have done, or looked at doing, any of these, what would you do/do differently?  &lt;/p&gt;\n\n&lt;p&gt;All input welcome.  Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tru1d", "is_robot_indexable": true, "report_reasons": null, "author": "bart_grewup", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tru1d/ut_masters_in_ai_v_gt_oma_v_an_ai_cert/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tru1d/ut_masters_in_ai_v_gt_oma_v_an_ai_cert/", "subreddit_subscribers": 844676, "created_utc": 1675546131.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, looking for ideas to start a NLP project! Any recommendation is appreciated", "author_fullname": "t2_a62fpcxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10touwy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675538753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, looking for ideas to start a NLP project! Any recommendation is appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10touwy", "is_robot_indexable": true, "report_reasons": null, "author": "mems_m", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10touwy/nlp_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10touwy/nlp_project/", "subreddit_subscribers": 844676, "created_utc": 1675538753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TL; DR:  I explore a hypothetical scenario where widget makers of varying experience are compared according to defect rate over a 5 year window.  To make things comparable (accounting for the experience problem), I inquire whether using a weighted moving average is a good strategy for balancing the problem of experience out or whether there is a better technique/solution to employ.  \n\n&amp;#x200B;\n\nThe Scenario:\n\n* Assume you were to look at the historical performance of  several widget makers who manually produce widgets.  These widget makers could be active employees at present  or left at some point during the window.\n* You want to compare the historical performance of the widget makers in terms of defect rate over the last 5 years (2018-2022).  My definition of defect rate is simply the  total number of defects/number of widgets produced (inclusive of defects)\n* Some makers have decades of experience while other makers only have 1 year of experience (minimum required for this analysis)\n* The original data is by year (2018,2019,...).  Let's assume Maker A, who started their career over a decade ago, made widgets over the entire window. Maker B has 3 years of experience but was let go sometime before 2022.  Maker C was recently hired and worked all of 2022.\n* To make things more intuitive (hopefully) and comparable, I converted the table from calendar years to years of experience within the time window. So Year 1 doesn't necessarily translate to 2018, it's simply represents the first year worked  in that time window. See table below.\n\n&amp;#x200B;\n\n|Maker|Year 1|2|3|4|5|\n|:-|:-|:-|:-|:-|:-|\n|A|2/17|2/15|3/11|1/8|2/10|\n|B|5/15|3/12|3/13|||\n|C|2/7|||||\n\n&amp;#x200B;\n\n*  Their defect rate is recorded over the last 5 years. For example Maker A produced 17 widgets of which 2 were defective in the first year of the time window, then produced 15 widgets in which 2 were defective Year 2, and so on...  Note that demand could be variable for widget production.\n* Simply looking at the defect rate above, my calculations  show Maker A would have an overall defect rate of .25, B would have .35 and C would have .43.  The problem I see  is less experience penalizes more heavily than more experience; so if this were a bar graph the 'worst performers' would likely always be the least experienced and that may not be very fair or  informative and at worst, hiding poor performers with a lot of experience.\n\nSo, this implies that some sort of smoothing or weighting is needed in order to make things more comparable. I was wondering if it made sense to use a weighted moving average.  My weighted average would look like the following:\n\n&amp;#x200B;\n\n* Each year of the window has an arbitrary weight associated to it.  For this example we want to downweight that first year  and gradually increase weights later on:\n\n&amp;#x200B;\n\n|Year |1|2|3|4|5|\n|:-|:-|:-|:-|:-|:-|\n|Weight|.6|.7|.8|.9|1|\n\n&amp;#x200B;\n\n* I obtain the sum of the product of each year's weight by  the maker's  defect rate  for each year they worked divided by the sum of the weights for the length of time that the maker worked.  Clarifying this last part - Maker A's denominator would be the sum of all 5 weights, B would be the sum of 3 weights and C would be only the Year 1 weight\n* Using the weight and formulas mentioned, I show that A has a weighted average defect rate of .17, B has .43 and C has .29, suggesting that B is producing more defects relative to their experience compared to the other two.\n\nThis results make some intuitive sense to me as B continued their career with a higher rate of defects relative to A.  My concern is that 1) weighting is arbitrary  and that 2) this method might cause an inverse problem from the one I was originally attempting to solve - giving too much leniency to the inexperienced and overly penalizing experience. I understand there is no perfect answer here but wondering if this is a sound approach or there are better, more intuitive ways to approach this. \n\nTIA", "author_fullname": "t2_2nzhcx9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is This A Good Method for Weighting Varying Levels of Experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tl1jk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675529596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL; DR:  I explore a hypothetical scenario where widget makers of varying experience are compared according to defect rate over a 5 year window.  To make things comparable (accounting for the experience problem), I inquire whether using a weighted moving average is a good strategy for balancing the problem of experience out or whether there is a better technique/solution to employ.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The Scenario:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Assume you were to look at the historical performance of  several widget makers who manually produce widgets.  These widget makers could be active employees at present  or left at some point during the window.&lt;/li&gt;\n&lt;li&gt;You want to compare the historical performance of the widget makers in terms of defect rate over the last 5 years (2018-2022).  My definition of defect rate is simply the  total number of defects/number of widgets produced (inclusive of defects)&lt;/li&gt;\n&lt;li&gt;Some makers have decades of experience while other makers only have 1 year of experience (minimum required for this analysis)&lt;/li&gt;\n&lt;li&gt;The original data is by year (2018,2019,...).  Let&amp;#39;s assume Maker A, who started their career over a decade ago, made widgets over the entire window. Maker B has 3 years of experience but was let go sometime before 2022.  Maker C was recently hired and worked all of 2022.&lt;/li&gt;\n&lt;li&gt;To make things more intuitive (hopefully) and comparable, I converted the table from calendar years to years of experience within the time window. So Year 1 doesn&amp;#39;t necessarily translate to 2018, it&amp;#39;s simply represents the first year worked  in that time window. See table below.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Maker&lt;/th&gt;\n&lt;th align=\"left\"&gt;Year 1&lt;/th&gt;\n&lt;th align=\"left\"&gt;2&lt;/th&gt;\n&lt;th align=\"left\"&gt;3&lt;/th&gt;\n&lt;th align=\"left\"&gt;4&lt;/th&gt;\n&lt;th align=\"left\"&gt;5&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;A&lt;/td&gt;\n&lt;td align=\"left\"&gt;2/17&lt;/td&gt;\n&lt;td align=\"left\"&gt;2/15&lt;/td&gt;\n&lt;td align=\"left\"&gt;3/11&lt;/td&gt;\n&lt;td align=\"left\"&gt;1/8&lt;/td&gt;\n&lt;td align=\"left\"&gt;2/10&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;B&lt;/td&gt;\n&lt;td align=\"left\"&gt;5/15&lt;/td&gt;\n&lt;td align=\"left\"&gt;3/12&lt;/td&gt;\n&lt;td align=\"left\"&gt;3/13&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;C&lt;/td&gt;\n&lt;td align=\"left\"&gt;2/7&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt; Their defect rate is recorded over the last 5 years. For example Maker A produced 17 widgets of which 2 were defective in the first year of the time window, then produced 15 widgets in which 2 were defective Year 2, and so on...  Note that demand could be variable for widget production.&lt;/li&gt;\n&lt;li&gt;Simply looking at the defect rate above, my calculations  show Maker A would have an overall defect rate of .25, B would have .35 and C would have .43.  The problem I see  is less experience penalizes more heavily than more experience; so if this were a bar graph the &amp;#39;worst performers&amp;#39; would likely always be the least experienced and that may not be very fair or  informative and at worst, hiding poor performers with a lot of experience.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So, this implies that some sort of smoothing or weighting is needed in order to make things more comparable. I was wondering if it made sense to use a weighted moving average.  My weighted average would look like the following:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Each year of the window has an arbitrary weight associated to it.  For this example we want to downweight that first year  and gradually increase weights later on:&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Year&lt;/th&gt;\n&lt;th align=\"left\"&gt;1&lt;/th&gt;\n&lt;th align=\"left\"&gt;2&lt;/th&gt;\n&lt;th align=\"left\"&gt;3&lt;/th&gt;\n&lt;th align=\"left\"&gt;4&lt;/th&gt;\n&lt;th align=\"left\"&gt;5&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Weight&lt;/td&gt;\n&lt;td align=\"left\"&gt;.6&lt;/td&gt;\n&lt;td align=\"left\"&gt;.7&lt;/td&gt;\n&lt;td align=\"left\"&gt;.8&lt;/td&gt;\n&lt;td align=\"left\"&gt;.9&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I obtain the sum of the product of each year&amp;#39;s weight by  the maker&amp;#39;s  defect rate  for each year they worked divided by the sum of the weights for the length of time that the maker worked.  Clarifying this last part - Maker A&amp;#39;s denominator would be the sum of all 5 weights, B would be the sum of 3 weights and C would be only the Year 1 weight&lt;/li&gt;\n&lt;li&gt;Using the weight and formulas mentioned, I show that A has a weighted average defect rate of .17, B has .43 and C has .29, suggesting that B is producing more defects relative to their experience compared to the other two.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This results make some intuitive sense to me as B continued their career with a higher rate of defects relative to A.  My concern is that 1) weighting is arbitrary  and that 2) this method might cause an inverse problem from the one I was originally attempting to solve - giving too much leniency to the inexperienced and overly penalizing experience. I understand there is no perfect answer here but wondering if this is a sound approach or there are better, more intuitive ways to approach this. &lt;/p&gt;\n\n&lt;p&gt;TIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tl1jk", "is_robot_indexable": true, "report_reasons": null, "author": "outskirtsofparadise", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tl1jk/is_this_a_good_method_for_weighting_varying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tl1jk/is_this_a_good_method_for_weighting_varying/", "subreddit_subscribers": 844676, "created_utc": 1675529596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm given a school assignment and one of the requirements is to visualize the important aspects and give meaningful realization of a real world dataset.\nSo I was wondering I someone could recommend me a dataset that is simple, real world, has some real use", "author_fullname": "t2_i3uokfwb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please give data set recommendation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tj322", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675524660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m given a school assignment and one of the requirements is to visualize the important aspects and give meaningful realization of a real world dataset.\nSo I was wondering I someone could recommend me a dataset that is simple, real world, has some real use&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tj322", "is_robot_indexable": true, "report_reasons": null, "author": "A_B_1_2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tj322/please_give_data_set_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tj322/please_give_data_set_recommendation/", "subreddit_subscribers": 844676, "created_utc": 1675524660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I have multivariate dataset which i need to predict 4 variables off of it. I know that these 4 variables decline over time and have a relationship with the other dependent variables. So I want to predict these 4 variables and their trend for the next year. Obviously I do not have the data for the dependent variables over next year. Any ideas on how to start? I built an LSTM model to predict the 4 variables already but it needs of course the dependent variables as input for next year.", "author_fullname": "t2_966j5hjl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time Series Analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10t3ejl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675480082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have multivariate dataset which i need to predict 4 variables off of it. I know that these 4 variables decline over time and have a relationship with the other dependent variables. So I want to predict these 4 variables and their trend for the next year. Obviously I do not have the data for the dependent variables over next year. Any ideas on how to start? I built an LSTM model to predict the 4 variables already but it needs of course the dependent variables as input for next year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10t3ejl", "is_robot_indexable": true, "report_reasons": null, "author": "Klutzy_Court1591", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10t3ejl/time_series_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10t3ejl/time_series_analysis/", "subreddit_subscribers": 844676, "created_utc": 1675480082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "First off, I want to say I know close to nothing about data science and I'm kinda learning on my own.\n\nHere's my project: I have a bunch of logs where people write statuses of different tasks and I want to identify was was done and what is left to do.\n\n&amp;#x200B;\n\nFor example, I can have logs that say:\n\n\"X was replaced and need inspection\"\n\nWhat would you do to identify that X was replaced and that X still need to be inspected?\n\n&amp;#x200B;\n\nAlso, the logs contains lots of abbreviations like:\n\n\"X was RP and nd inspect\"\n\nHow do you deal with this?\n\n&amp;#x200B;\n\nAny help would be greatly appreciated! TIA!!", "author_fullname": "t2_t0zhhdeb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to identify tasks in logs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10toc9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675537457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First off, I want to say I know close to nothing about data science and I&amp;#39;m kinda learning on my own.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my project: I have a bunch of logs where people write statuses of different tasks and I want to identify was was done and what is left to do.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For example, I can have logs that say:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;X was replaced and need inspection&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;What would you do to identify that X was replaced and that X still need to be inspected?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also, the logs contains lots of abbreviations like:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;X was RP and nd inspect&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;How do you deal with this?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any help would be greatly appreciated! TIA!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10toc9m", "is_robot_indexable": true, "report_reasons": null, "author": "eltchacham", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10toc9m/how_to_identify_tasks_in_logs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10toc9m/how_to_identify_tasks_in_logs/", "subreddit_subscribers": 844676, "created_utc": 1675537457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_b71e9j7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Happiness and Meaning in What We Do", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "name": "t3_10tkcts", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QUsQw0AQYHzN9jfM5MniTiDOMTzeUYYRu9QeubFh41U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675527852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "flowingdata.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://flowingdata.com/2023/01/11/happiness-and-meaning/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sjEJtXRbyOYwUGQtZxyBSS4rKcwR1LfOXkHuawZLQNs.jpg?auto=webp&amp;v=enabled&amp;s=021a7d0111ed3a520890d19700459aaf9ef6ba71", "width": 2002, "height": 1384}, "resolutions": [{"url": "https://external-preview.redd.it/sjEJtXRbyOYwUGQtZxyBSS4rKcwR1LfOXkHuawZLQNs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9077316aa3da2500d96d9faac26bdcb2b03e0d11", "width": 108, "height": 74}, {"url": "https://external-preview.redd.it/sjEJtXRbyOYwUGQtZxyBSS4rKcwR1LfOXkHuawZLQNs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=285f586d50982f85347f71360137e14269ffbc6f", "width": 216, "height": 149}, {"url": "https://external-preview.redd.it/sjEJtXRbyOYwUGQtZxyBSS4rKcwR1LfOXkHuawZLQNs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c49429ab851f7ba714eb6e292e2735ff87296bc3", "width": 320, "height": 221}, {"url": "https://external-preview.redd.it/sjEJtXRbyOYwUGQtZxyBSS4rKcwR1LfOXkHuawZLQNs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d319403f4d62209f1d22d7f9b2773269d5444e4", "width": 640, "height": 442}, {"url": "https://external-preview.redd.it/sjEJtXRbyOYwUGQtZxyBSS4rKcwR1LfOXkHuawZLQNs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3cc6865ef5ff462da12de89fa39069dbd6f3af55", "width": 960, "height": 663}, {"url": "https://external-preview.redd.it/sjEJtXRbyOYwUGQtZxyBSS4rKcwR1LfOXkHuawZLQNs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8a0770c97242367e386083afaf4e3eefd3176a8", "width": 1080, "height": 746}], "variants": {}, "id": "44qKXOapwlucIy6lsY36iDrLifWLEcJhv2rdvR-x3x8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tkcts", "is_robot_indexable": true, "report_reasons": null, "author": "fchung", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tkcts/happiness_and_meaning_in_what_we_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://flowingdata.com/2023/01/11/happiness-and-meaning/", "subreddit_subscribers": 844676, "created_utc": 1675527852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHi, Anyone has an idea how can i perform the regression between the convolution result and the vecto r of non black voxels? I just tried so many times\n\n%procedure in order to eliminate the black voxel (the background)\n\nthreshold = 250;\n\ndata(data &lt; threshold) = 0;\n\n% Get linear indices of non-zero voxels\n\nnonZeroIndices = find(data);\n\n% Convert linear indices to (x, y, z) coordinates\n\n\\[x, y, z\\] = ind2sub(size(data), nonZeroIndices);\n\nvector=\\[x,y,z\\];\n\n% Create new histogram with non-zero voxels\n\nhist(data(nonZeroIndices));\n\nxlabel('gray level')\n\nylabel('Frequency')\n\ntitle('Histogram without black voxels')\n\n%defining the signals during the stimuli and during the resting phase\n\nt = 0:1:160; % time vector\n\nf = 1/20; % frequency of the square signal\n\nsquare\\_signal = zeros(size(t)); % initialize square\\_signal as a vector of zeros\n\nsquare\\_signal(mod(t, 2\\*1/f) &lt; 1/f) = 1; % set values within one period to 1 using ones function\n\nsquare\\_signal(end-floor(1/f):end) = 0; % set the last period to zero\n\n%convolution between the signal and the bold equation\n\na1=6;\n\na2=12;\n\nb1=0.9;\n\nb2=0.9;\n\nc=0.35;\n\nd1=a1\\*b1;\n\nd2=a2\\*b2;\n\nbold\\_eq= @(t) ((t/d1).\\^(a1)).\\*exp(-(t-d1)/b1)-c.\\*((t/d2).\\^(a2)).\\*exp(-(t-d2)/b2);\n\n% zero-pad the bold\\_eq to the same length as t\n\nbold\\_eq\\_pad = zeros(1, length(t) + length(square\\_signal) - 1);\n\nbold\\_eq\\_pad(1:length(t)) = bold\\_eq(t);\n\n% perform the convolution\n\nresult = conv(square\\_signal, bold\\_eq\\_pad);", "author_fullname": "t2_uj49bh3f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Regression Matlab", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tdkup", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675507493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, Anyone has an idea how can i perform the regression between the convolution result and the vecto r of non black voxels? I just tried so many times&lt;/p&gt;\n\n&lt;p&gt;%procedure in order to eliminate the black voxel (the background)&lt;/p&gt;\n\n&lt;p&gt;threshold = 250;&lt;/p&gt;\n\n&lt;p&gt;data(data &amp;lt; threshold) = 0;&lt;/p&gt;\n\n&lt;p&gt;% Get linear indices of non-zero voxels&lt;/p&gt;\n\n&lt;p&gt;nonZeroIndices = find(data);&lt;/p&gt;\n\n&lt;p&gt;% Convert linear indices to (x, y, z) coordinates&lt;/p&gt;\n\n&lt;p&gt;[x, y, z] = ind2sub(size(data), nonZeroIndices);&lt;/p&gt;\n\n&lt;p&gt;vector=[x,y,z];&lt;/p&gt;\n\n&lt;p&gt;% Create new histogram with non-zero voxels&lt;/p&gt;\n\n&lt;p&gt;hist(data(nonZeroIndices));&lt;/p&gt;\n\n&lt;p&gt;xlabel(&amp;#39;gray level&amp;#39;)&lt;/p&gt;\n\n&lt;p&gt;ylabel(&amp;#39;Frequency&amp;#39;)&lt;/p&gt;\n\n&lt;p&gt;title(&amp;#39;Histogram without black voxels&amp;#39;)&lt;/p&gt;\n\n&lt;p&gt;%defining the signals during the stimuli and during the resting phase&lt;/p&gt;\n\n&lt;p&gt;t = 0:1:160; % time vector&lt;/p&gt;\n\n&lt;p&gt;f = 1/20; % frequency of the square signal&lt;/p&gt;\n\n&lt;p&gt;square_signal = zeros(size(t)); % initialize square_signal as a vector of zeros&lt;/p&gt;\n\n&lt;p&gt;square_signal(mod(t, 2*1/f) &amp;lt; 1/f) = 1; % set values within one period to 1 using ones function&lt;/p&gt;\n\n&lt;p&gt;square_signal(end-floor(1/f):end) = 0; % set the last period to zero&lt;/p&gt;\n\n&lt;p&gt;%convolution between the signal and the bold equation&lt;/p&gt;\n\n&lt;p&gt;a1=6;&lt;/p&gt;\n\n&lt;p&gt;a2=12;&lt;/p&gt;\n\n&lt;p&gt;b1=0.9;&lt;/p&gt;\n\n&lt;p&gt;b2=0.9;&lt;/p&gt;\n\n&lt;p&gt;c=0.35;&lt;/p&gt;\n\n&lt;p&gt;d1=a1*b1;&lt;/p&gt;\n\n&lt;p&gt;d2=a2*b2;&lt;/p&gt;\n\n&lt;p&gt;bold_eq= @(t) ((t/d1).^(a1)).*exp(-(t-d1)/b1)-c.*((t/d2).^(a2)).*exp(-(t-d2)/b2);&lt;/p&gt;\n\n&lt;p&gt;% zero-pad the bold_eq to the same length as t&lt;/p&gt;\n\n&lt;p&gt;bold_eq_pad = zeros(1, length(t) + length(square_signal) - 1);&lt;/p&gt;\n\n&lt;p&gt;bold_eq_pad(1:length(t)) = bold_eq(t);&lt;/p&gt;\n\n&lt;p&gt;% perform the convolution&lt;/p&gt;\n\n&lt;p&gt;result = conv(square_signal, bold_eq_pad);&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tdkup", "is_robot_indexable": true, "report_reasons": null, "author": "MrBrain_99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tdkup/regression_matlab/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tdkup/regression_matlab/", "subreddit_subscribers": 844676, "created_utc": 1675507493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So as title says i have advanced to the next round of interviews. I am not really sure what to do next. For first round I got project to do at home (company really liked the results). Not really sure what to prepare next or even how many rounds there will be. Any suggestions on what to shift my focus to for next interview? It will be held by current data scientists of the firm.    \n    \nThis is my first interview for position of data scientist so i don't really know how it goes, any tips or guidance would be appriciated. Thanks.", "author_fullname": "t2_tv2fyu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advancing to the next round of interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10tc11j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675503997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So as title says i have advanced to the next round of interviews. I am not really sure what to do next. For first round I got project to do at home (company really liked the results). Not really sure what to prepare next or even how many rounds there will be. Any suggestions on what to shift my focus to for next interview? It will be held by current data scientists of the firm.    &lt;/p&gt;\n\n&lt;p&gt;This is my first interview for position of data scientist so i don&amp;#39;t really know how it goes, any tips or guidance would be appriciated. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tc11j", "is_robot_indexable": true, "report_reasons": null, "author": "CherryGG2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tc11j/advancing_to_the_next_round_of_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10tc11j/advancing_to_the_next_round_of_interviews/", "subreddit_subscribers": 844676, "created_utc": 1675503997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_pzr91bdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BoyWithUke AI Animation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_10tkwkt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/UrY5UQx4TUk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"BoywithUKE | AI Animation | Side by Side Comparision\"&gt;&lt;/iframe&gt;", "width": 267, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "BoywithUKE | AI Animation | Side by Side Comparision", "type": "video", "thumbnail_width": 480, "height": 200, "width": 267, "html": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/UrY5UQx4TUk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"BoywithUKE | AI Animation | Side by Side Comparision\"&gt;&lt;/iframe&gt;", "author_name": "What The AI", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UrY5UQx4TUk/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WhattheAI"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/UrY5UQx4TUk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"BoywithUKE | AI Animation | Side by Side Comparision\"&gt;&lt;/iframe&gt;", "width": 267, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/10tkwkt", "height": 200}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ff3baNHG4MHBfC9OwzOw8meOLnJ3o2iO3BXiaTe3s4k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675529251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=UrY5UQx4TUk", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T3hHaLItDA_cnkbETEq5VCyQ1VnUMuNcK0KDKRQNS3E.jpg?auto=webp&amp;v=enabled&amp;s=1c847b355f3b76d2f5c4949567f513960a95a946", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/T3hHaLItDA_cnkbETEq5VCyQ1VnUMuNcK0KDKRQNS3E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08338801f68cd6404d813c39e5b5924fb9c46b96", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/T3hHaLItDA_cnkbETEq5VCyQ1VnUMuNcK0KDKRQNS3E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2efe30ce80132b9eb279985fb255b67b741a7e05", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/T3hHaLItDA_cnkbETEq5VCyQ1VnUMuNcK0KDKRQNS3E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa570352083be99ad7011d75836c35ba29d7f36e", "width": 320, "height": 240}], "variants": {}, "id": "mtSXWTVBGIpoTE9zoshl7ijfNW8GvfQtwmVjagWy5l0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10tkwkt", "is_robot_indexable": true, "report_reasons": null, "author": "oridnary_artist", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10tkwkt/boywithuke_ai_animation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=UrY5UQx4TUk", "subreddit_subscribers": 844676, "created_utc": 1675529251.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "BoywithUKE | AI Animation | Side by Side Comparision", "type": "video", "thumbnail_width": 480, "height": 200, "width": 267, "html": "&lt;iframe width=\"267\" height=\"200\" src=\"https://www.youtube.com/embed/UrY5UQx4TUk?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"BoywithUKE | AI Animation | Side by Side Comparision\"&gt;&lt;/iframe&gt;", "author_name": "What The AI", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/UrY5UQx4TUk/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WhattheAI"}}, "is_video": false}}], "before": null}}