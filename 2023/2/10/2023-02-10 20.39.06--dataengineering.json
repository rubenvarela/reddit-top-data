{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So after building a near real time pipeline with super complex parsing and data quality in record speed your dashboard gal/guy sends an email to C-level showing her/his awesome dashboard and just cc you in the email.\n\n\n\nNobody would know \n\n\u2014 time spent to find optimal parallelism\n\n\n\u2014 time spent for solving weird dq issues\n\n\n\u2014 time spent to make the pipeline dynamically handle schema change\n\n\n\u2014 time spent for threading it all together in orchestrator\n\n\nAfter all these years still hurts on how thankless this job is.\n\nOnly lesson : Thank your plumber next time you meet him.", "author_fullname": "t2_5ifseipu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thanking my plumber every time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ybytx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 166, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 166, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675990984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So after building a near real time pipeline with super complex parsing and data quality in record speed your dashboard gal/guy sends an email to C-level showing her/his awesome dashboard and just cc you in the email.&lt;/p&gt;\n\n&lt;p&gt;Nobody would know &lt;/p&gt;\n\n&lt;p&gt;\u2014 time spent to find optimal parallelism&lt;/p&gt;\n\n&lt;p&gt;\u2014 time spent for solving weird dq issues&lt;/p&gt;\n\n&lt;p&gt;\u2014 time spent to make the pipeline dynamically handle schema change&lt;/p&gt;\n\n&lt;p&gt;\u2014 time spent for threading it all together in orchestrator&lt;/p&gt;\n\n&lt;p&gt;After all these years still hurts on how thankless this job is.&lt;/p&gt;\n\n&lt;p&gt;Only lesson : Thank your plumber next time you meet him.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ybytx", "is_robot_indexable": true, "report_reasons": null, "author": "Smart-Weird", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ybytx/thanking_my_plumber_every_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ybytx/thanking_my_plumber_every_time/", "subreddit_subscribers": 89107, "created_utc": 1675990984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I\u2019m a manager at Big 4 consulting and I\u2019m trying to find resources which I can show my engineers to help them understand best practices &amp; common patterns in developing production ready applications / code bases. \n\nSome things I can think of that I\u2019ve had to teach them:\n\n1. Git\n2. Environment specific parameters\n3. Writing Unittests, mocking cloud services\n4. What is CI/CD", "author_fullname": "t2_ay99iuoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do we learn SWE best practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ye0ji", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675996673.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019m a manager at Big 4 consulting and I\u2019m trying to find resources which I can show my engineers to help them understand best practices &amp;amp; common patterns in developing production ready applications / code bases. &lt;/p&gt;\n\n&lt;p&gt;Some things I can think of that I\u2019ve had to teach them:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Git&lt;/li&gt;\n&lt;li&gt;Environment specific parameters&lt;/li&gt;\n&lt;li&gt;Writing Unittests, mocking cloud services&lt;/li&gt;\n&lt;li&gt;What is CI/CD&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ye0ji", "is_robot_indexable": true, "report_reasons": null, "author": "Rich_Repair", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ye0ji/how_do_we_learn_swe_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ye0ji/how_do_we_learn_swe_best_practices/", "subreddit_subscribers": 89107, "created_utc": 1675996673.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi team,  \nWe used to migrate data with a CDC based architecture. Then one day, someone said:\n\n\"What if we discover some contaminated data? We'd need to fix the data in the source, and then replay the migration from that point. Does your architecture handle that?\"  \n\n\n\\*gulp\\*  \n\n\nQuestion: How does CDC fit into your company? Is it an *extra* migration pipeline that feeds real-time solutions? Do you still have an \"SQL-based\" pipeline just in case?", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CDC and Backfill", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ytfl3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676039499.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi team,&lt;br/&gt;\nWe used to migrate data with a CDC based architecture. Then one day, someone said:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;What if we discover some contaminated data? We&amp;#39;d need to fix the data in the source, and then replay the migration from that point. Does your architecture handle that?&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;*gulp*  &lt;/p&gt;\n\n&lt;p&gt;Question: How does CDC fit into your company? Is it an &lt;em&gt;extra&lt;/em&gt; migration pipeline that feeds real-time solutions? Do you still have an &amp;quot;SQL-based&amp;quot; pipeline just in case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ytfl3", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ytfl3/cdc_and_backfill/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ytfl3/cdc_and_backfill/", "subreddit_subscribers": 89107, "created_utc": 1676039499.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it good enough to receive terabytes of data from api using simple python request module in glue and spark to store it in s3 with delta format? The project is to process daily data from company db to s3, and the company will provide an api to access the data.\n\nMy current concern is size limit of data that api can handle, is there any limit for an api? I don't know what kind of api will be given because this is for a project in poc phase. \n\nI am fairly new in data engineering so feel free to give any advice, thank you.", "author_fullname": "t2_ityodnp4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Processing terabytes from api in aws glue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10yuub4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676043015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it good enough to receive terabytes of data from api using simple python request module in glue and spark to store it in s3 with delta format? The project is to process daily data from company db to s3, and the company will provide an api to access the data.&lt;/p&gt;\n\n&lt;p&gt;My current concern is size limit of data that api can handle, is there any limit for an api? I don&amp;#39;t know what kind of api will be given because this is for a project in poc phase. &lt;/p&gt;\n\n&lt;p&gt;I am fairly new in data engineering so feel free to give any advice, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10yuub4", "is_robot_indexable": true, "report_reasons": null, "author": "LimeDine", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10yuub4/processing_terabytes_from_api_in_aws_glue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10yuub4/processing_terabytes_from_api_in_aws_glue/", "subreddit_subscribers": 89107, "created_utc": 1676043015.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Aggregate Combinators in ClickHouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_10ymgce", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RFnbn_Th7B7VHl0xfx7w8R9Igi5UxtiPf6cmlU6-AFs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676021073.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "clickhouse.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://clickhouse.com/blog/aggregate-functions-combinators-in-clickhouse-for-arrays-maps-and-states", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vd2eervNd-SJGKQQ5cTNRSg-Bk2bWu_TVeO6xRH_RnQ.jpg?auto=webp&amp;v=enabled&amp;s=cd239d606e97421b4ecf0fbe89750920297358e4", "width": 1576, "height": 888}, "resolutions": [{"url": "https://external-preview.redd.it/vd2eervNd-SJGKQQ5cTNRSg-Bk2bWu_TVeO6xRH_RnQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3268a14fd20c70a15f1049a9cc190eb4e7137715", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/vd2eervNd-SJGKQQ5cTNRSg-Bk2bWu_TVeO6xRH_RnQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a15d0c264885ec7e06180f237faebe2d7e404416", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/vd2eervNd-SJGKQQ5cTNRSg-Bk2bWu_TVeO6xRH_RnQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=999dc6e15cd6329e185392ace1625d6f512934a6", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/vd2eervNd-SJGKQQ5cTNRSg-Bk2bWu_TVeO6xRH_RnQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=863abd8d5a71065339ac5d671a03f1dce0b7126e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/vd2eervNd-SJGKQQ5cTNRSg-Bk2bWu_TVeO6xRH_RnQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2079f3c7d5c8d3408a80d28ec7fc7dd8f5a2a374", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/vd2eervNd-SJGKQQ5cTNRSg-Bk2bWu_TVeO6xRH_RnQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b594b457ea42efb2329dcf45c8f397ed53c650e", "width": 1080, "height": 608}], "variants": {}, "id": "EszfP3ZeRjCe_uXMGl4zs8W6bXQkIcIFjknp0SByRjw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10ymgce", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ymgce/using_aggregate_combinators_in_clickhouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://clickhouse.com/blog/aggregate-functions-combinators-in-clickhouse-for-arrays-maps-and-states", "subreddit_subscribers": 89107, "created_utc": 1676021073.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I am going through the understanding of  end to end data engineering process. I understand how things work, however, I have not found one resource to understand how the data is saved in such cloud storage by the enterprises?\n\nI mean, I understand data can come from anywhere like, website, mobile application or any app that is storing users details like facebooks user details. Now how does these data like, connected into (injested) into cloud storage? How are they mounted? A few real world examples or cases can help to understand. \n\nFor example: I like a post, or create a user account in Facebook, this data is saved in some database which is mounted to cloud storage? is this is it? and we go on with next from there?", "author_fullname": "t2_lngymjsb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what is the idle scenario where a data in stored in azure blog or any cloud storage like S3.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10yb413", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675988622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I am going through the understanding of  end to end data engineering process. I understand how things work, however, I have not found one resource to understand how the data is saved in such cloud storage by the enterprises?&lt;/p&gt;\n\n&lt;p&gt;I mean, I understand data can come from anywhere like, website, mobile application or any app that is storing users details like facebooks user details. Now how does these data like, connected into (injested) into cloud storage? How are they mounted? A few real world examples or cases can help to understand. &lt;/p&gt;\n\n&lt;p&gt;For example: I like a post, or create a user account in Facebook, this data is saved in some database which is mounted to cloud storage? is this is it? and we go on with next from there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10yb413", "is_robot_indexable": true, "report_reasons": null, "author": "iamdhage", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10yb413/what_is_the_idle_scenario_where_a_data_in_stored/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10yb413/what_is_the_idle_scenario_where_a_data_in_stored/", "subreddit_subscribers": 89107, "created_utc": 1675988622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_zus64vk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data imputation in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_10y9rwp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/upxsp65nnsAGtTc-gAoMDIllQnv_ZRo1odB1CqnmtpQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675985209.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hubs.li", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://hubs.li/Q01BW4NT0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-vmmwYqhrWGPbN3V0o0gS0905RPlMVcXDT7EXXZUmhw.jpg?auto=webp&amp;v=enabled&amp;s=7e35df19320e1aad03aadd059f628000aeead487", "width": 800, "height": 526}, "resolutions": [{"url": "https://external-preview.redd.it/-vmmwYqhrWGPbN3V0o0gS0905RPlMVcXDT7EXXZUmhw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6ca36cd4a5a93b0c47d6e70a1c198501108da83", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/-vmmwYqhrWGPbN3V0o0gS0905RPlMVcXDT7EXXZUmhw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=416c8300fc41b7723d9ebe3786248688a509aeb1", "width": 216, "height": 142}, {"url": "https://external-preview.redd.it/-vmmwYqhrWGPbN3V0o0gS0905RPlMVcXDT7EXXZUmhw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e656629a9830f76ea20131566c7d5cb268153ca", "width": 320, "height": 210}, {"url": "https://external-preview.redd.it/-vmmwYqhrWGPbN3V0o0gS0905RPlMVcXDT7EXXZUmhw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f68309c60f31f46fdfc36020d446292538d58788", "width": 640, "height": 420}], "variants": {}, "id": "nGnUWldmoOF3Mysh8RqBH_abXJv3jq3i_pyrYZ3w6oc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10y9rwp", "is_robot_indexable": true, "report_reasons": null, "author": "oli_k", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10y9rwp/data_imputation_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://hubs.li/Q01BW4NT0", "subreddit_subscribers": 89107, "created_utc": 1675985209.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm getting quite confused about this. So it's very typical in a transactional system to have header line data, like purchase order and purchase line.\n\nWhen I bring this into a data warehouse and I'm designing the fact tables, how do I model this relationship? If I add columns for the header detail I'll have tonnes of redundant, repeated data. But having 2 linked facts is also not correct.\n\nAny help is appreciated thanks!", "author_fullname": "t2_32y0tqx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to model header line data in a DWH without duplicating data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10yxiy6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676049784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m getting quite confused about this. So it&amp;#39;s very typical in a transactional system to have header line data, like purchase order and purchase line.&lt;/p&gt;\n\n&lt;p&gt;When I bring this into a data warehouse and I&amp;#39;m designing the fact tables, how do I model this relationship? If I add columns for the header detail I&amp;#39;ll have tonnes of redundant, repeated data. But having 2 linked facts is also not correct.&lt;/p&gt;\n\n&lt;p&gt;Any help is appreciated thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10yxiy6", "is_robot_indexable": true, "report_reasons": null, "author": "MrWriter1234", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10yxiy6/how_to_model_header_line_data_in_a_dwh_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10yxiy6/how_to_model_header_line_data_in_a_dwh_without/", "subreddit_subscribers": 89107, "created_utc": 1676049784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So our security division is extracting data from a big cloud security system into our analytics server and there is a lot of beef between our data team and their team, they are messing our analytics server performance, delaying our subscriptions and so on, and our rules of bouncing every query that is taking more than 2 hours is messing up with their scripts.(Tbf not even sure why their queries are taking more than 2 hours)\n\nI need to mention that we use the data extracted for analytics as well, but they also use it for monitoring and dashboarding.\n\nNow I want to take this issue in my hands and do something about it, but for that I need to convince my manager.\n\nNow I am thinking this should be a pretty easy fix, we either create another server specifically for the security team where they can use it for whatever they want, and we connect to their server to extract the data to build our dwh, or we move them on our etl server, but I am looking more into the first option.\n\nThat\u2019s why Im posting here, I would like some opinions from more seasoned Data Engineers.\n\nHope you guys can help me with some insights.", "author_fullname": "t2_4lcvdsdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beef between security and data team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10yvm1y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676044891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So our security division is extracting data from a big cloud security system into our analytics server and there is a lot of beef between our data team and their team, they are messing our analytics server performance, delaying our subscriptions and so on, and our rules of bouncing every query that is taking more than 2 hours is messing up with their scripts.(Tbf not even sure why their queries are taking more than 2 hours)&lt;/p&gt;\n\n&lt;p&gt;I need to mention that we use the data extracted for analytics as well, but they also use it for monitoring and dashboarding.&lt;/p&gt;\n\n&lt;p&gt;Now I want to take this issue in my hands and do something about it, but for that I need to convince my manager.&lt;/p&gt;\n\n&lt;p&gt;Now I am thinking this should be a pretty easy fix, we either create another server specifically for the security team where they can use it for whatever they want, and we connect to their server to extract the data to build our dwh, or we move them on our etl server, but I am looking more into the first option.&lt;/p&gt;\n\n&lt;p&gt;That\u2019s why Im posting here, I would like some opinions from more seasoned Data Engineers.&lt;/p&gt;\n\n&lt;p&gt;Hope you guys can help me with some insights.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10yvm1y", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional_Key", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10yvm1y/beef_between_security_and_data_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10yvm1y/beef_between_security_and_data_team/", "subreddit_subscribers": 89107, "created_utc": 1676044891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I left an SSIS ETL gig about 8 years ago to join a much bigger company as a Business Intelligence (glorified reporting guy). I have kept working on side gigs using SSIS and DBT\u2026 now, because I have a giant gap of not related Data engineering positions.  I get an automatic rejection from HR and I\u2019m at lost.  I hate doing tableau and making things pretty for idiotic reasons.  I need to get back home and I need some feedback on how to fix my resume.", "author_fullname": "t2_4i6f73l2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get back into data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10yssm1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676037807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I left an SSIS ETL gig about 8 years ago to join a much bigger company as a Business Intelligence (glorified reporting guy). I have kept working on side gigs using SSIS and DBT\u2026 now, because I have a giant gap of not related Data engineering positions.  I get an automatic rejection from HR and I\u2019m at lost.  I hate doing tableau and making things pretty for idiotic reasons.  I need to get back home and I need some feedback on how to fix my resume.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10yssm1", "is_robot_indexable": true, "report_reasons": null, "author": "SadDogOwner27", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10yssm1/how_to_get_back_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10yssm1/how_to_get_back_into_data_engineering/", "subreddit_subscribers": 89107, "created_utc": 1676037807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to ask what skills can I acquire now and put on my resume to get noticed by hiring managers and recruiters. I graduated with a CS bachelors degree in 2021, tried to get a data science job, couldn't get one, enrolled in masters but will be dropping out in the middle because I need to find a job asap. I look at data engineer job postings and some of them have an overwhelming number of tools listed for an entry level job. At the same time, the most recurring skills I keep hearing are python, sql and data warehousing.Can I honestly score a DE position with the knowledge of just these 3? My dead end search for a data science position taught me that DS isn't really an area where recent graduates are accepted. That is why I'm looking for DE roles now because of transferable skills and newbie friendliness but it looks like I'm going down the same road again. Plus, I am also at a stalemate for DE projects. For DS, I've made web apps that take input and predict a result. But I'm not able to come up with ideas for DE projects. Can scraping data off the web and loading it into a CSV qualify? Please help.", "author_fullname": "t2_e6tzy246", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting into DE straight after college?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10yqih5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676031338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to ask what skills can I acquire now and put on my resume to get noticed by hiring managers and recruiters. I graduated with a CS bachelors degree in 2021, tried to get a data science job, couldn&amp;#39;t get one, enrolled in masters but will be dropping out in the middle because I need to find a job asap. I look at data engineer job postings and some of them have an overwhelming number of tools listed for an entry level job. At the same time, the most recurring skills I keep hearing are python, sql and data warehousing.Can I honestly score a DE position with the knowledge of just these 3? My dead end search for a data science position taught me that DS isn&amp;#39;t really an area where recent graduates are accepted. That is why I&amp;#39;m looking for DE roles now because of transferable skills and newbie friendliness but it looks like I&amp;#39;m going down the same road again. Plus, I am also at a stalemate for DE projects. For DS, I&amp;#39;ve made web apps that take input and predict a result. But I&amp;#39;m not able to come up with ideas for DE projects. Can scraping data off the web and loading it into a CSV qualify? Please help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10yqih5", "is_robot_indexable": true, "report_reasons": null, "author": "al8k", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10yqih5/getting_into_de_straight_after_college/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10yqih5/getting_into_de_straight_after_college/", "subreddit_subscribers": 89107, "created_utc": 1676031338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently out of a job because I recently moved to a new country and sorting out a work permit.\n\nI'm currently volunteering at an NGO, they do not have a data warehouse. They manually manage data on their records management system. I see some ways I can leverage open-source modern data stack tools to automate the processes.\n\nShould finance be an issue for cloud storage, then I can do with them provisioning me with a server-like machine for the on-prem Postgres warehouse. \n\nMy concern however is, since this NGO is funded by the government, I have concerns about how the project can be scalable and won\u2019t eventually become an irrelevant project in the long run.\n\nJust to save me from \u201cif it ain\u2019t broke, don\u2019t fix it\u201d.\n\nI\u2019ll appreciate related experience and/or advice.", "author_fullname": "t2_c36b59fk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a Open-Source Data Stack for the NGO I\u2019m volunteering at - it it worth the effort?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10yhj68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676007903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently out of a job because I recently moved to a new country and sorting out a work permit.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently volunteering at an NGO, they do not have a data warehouse. They manually manage data on their records management system. I see some ways I can leverage open-source modern data stack tools to automate the processes.&lt;/p&gt;\n\n&lt;p&gt;Should finance be an issue for cloud storage, then I can do with them provisioning me with a server-like machine for the on-prem Postgres warehouse. &lt;/p&gt;\n\n&lt;p&gt;My concern however is, since this NGO is funded by the government, I have concerns about how the project can be scalable and won\u2019t eventually become an irrelevant project in the long run.&lt;/p&gt;\n\n&lt;p&gt;Just to save me from \u201cif it ain\u2019t broke, don\u2019t fix it\u201d.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ll appreciate related experience and/or advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10yhj68", "is_robot_indexable": true, "report_reasons": null, "author": "Odd-Flow220", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10yhj68/building_a_opensource_data_stack_for_the_ngo_im/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10yhj68/building_a_opensource_data_stack_for_the_ngo_im/", "subreddit_subscribers": 89107, "created_utc": 1676007903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What should I prepare for new grad application and interview?", "author_fullname": "t2_cl5t0lrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer New Grad Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10yfnqa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676001660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What should I prepare for new grad application and interview?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10yfnqa", "is_robot_indexable": true, "report_reasons": null, "author": "Unlucky-Difficulty86", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10yfnqa/data_engineer_new_grad_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10yfnqa/data_engineer_new_grad_interview/", "subreddit_subscribers": 89107, "created_utc": 1676001660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I have been working with DE for about 3 years and my current company after a long discussion decided to settle for SSIS, does anyone have some good courses or source material on it? I know it can\u2019t be that hard to learn for someone with SQL and coding background but any help is appreciated.", "author_fullname": "t2_592klrfg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSIS material", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10y6hhl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675977451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I have been working with DE for about 3 years and my current company after a long discussion decided to settle for SSIS, does anyone have some good courses or source material on it? I know it can\u2019t be that hard to learn for someone with SQL and coding background but any help is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10y6hhl", "is_robot_indexable": true, "report_reasons": null, "author": "pvic234", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10y6hhl/ssis_material/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10y6hhl/ssis_material/", "subreddit_subscribers": 89107, "created_utc": 1675977451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Clickbaity title but this former Google BigQuery engineer has some really interesting things to say about why most companies do not or should not utilize big data.", "author_fullname": "t2_t3ffq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big Data is Dead", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_10z1ft9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": "transparent", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1pO0RBiV6vwhGezwNmiqCZro0ztqzvrl3hQ2Ib5SB8A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676059302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "motherduck.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Clickbaity title but this former Google BigQuery engineer has some really interesting things to say about why most companies do not or should not utilize big data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://motherduck.com/blog/big-data-is-dead/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TqQR4yr7OcSlC9Ff2n9_e25bqRinYrh6yPODZ9k0L-c.jpg?auto=webp&amp;v=enabled&amp;s=422507ff3e1d876f1565f9afa286ac2a3b12b70d", "width": 1024, "height": 535}, "resolutions": [{"url": "https://external-preview.redd.it/TqQR4yr7OcSlC9Ff2n9_e25bqRinYrh6yPODZ9k0L-c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eea8d6f5a4b37bc287fcc1bd5d4b8364089b4589", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/TqQR4yr7OcSlC9Ff2n9_e25bqRinYrh6yPODZ9k0L-c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84293dc6fd5ff654378e1403be79188e69070a05", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/TqQR4yr7OcSlC9Ff2n9_e25bqRinYrh6yPODZ9k0L-c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8c1be6a0050d06000aac1c8326148e53643be6b", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/TqQR4yr7OcSlC9Ff2n9_e25bqRinYrh6yPODZ9k0L-c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1af5f5964cf9dc80b6d7c498f369c8505d1a4dc3", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/TqQR4yr7OcSlC9Ff2n9_e25bqRinYrh6yPODZ9k0L-c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1ab1c4a64b03a27503a012ea8235765e4de0220", "width": 960, "height": 501}], "variants": {}, "id": "C3v2JVQcD5hONfZJ0FsXvcBoNEQPQWKeM2eQkWh2PMw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10z1ft9", "is_robot_indexable": true, "report_reasons": null, "author": "FortunOfficial", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10z1ft9/big_data_is_dead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://motherduck.com/blog/big-data-is-dead/", "subreddit_subscribers": 89107, "created_utc": 1676059302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say I want to design a data warehouse to support BI workloads, where a BI Developer can create semantic models (sourced from the warehouse) to support various business reports. In the design of the warehouse, I know I can create multiple schemas to organize groups of tables with CREATE SCHEMA followed by several CREATE TABLE's to add tables within a particular schema. \n\nLet's say that the data engineers at an organization favor to load only denormalized tables (OBT) into their data warehouse for the BI workloads. My question is: would the data engineers create individual schemas in the warehouse for each one of these denormalized tables (Each schema has only 1 wide table)? So it is like a 1:1 mapping of schema to table.\n\nIf a different data engineering team favored the star schema instead, would there just be a single star schema inside of each schema?\n\nWe can also assume that there is no need to create schemas for security/permission reasons. All BI developers will have access to the entire warehouse.\n\nIs there ever a scenario where schema separation is irrelevant in a data warehouse?\n\nThanks in advanced for any help!", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Confused about Data Warehouse Schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10z19dl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676058884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say I want to design a data warehouse to support BI workloads, where a BI Developer can create semantic models (sourced from the warehouse) to support various business reports. In the design of the warehouse, I know I can create multiple schemas to organize groups of tables with CREATE SCHEMA followed by several CREATE TABLE&amp;#39;s to add tables within a particular schema. &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say that the data engineers at an organization favor to load only denormalized tables (OBT) into their data warehouse for the BI workloads. My question is: would the data engineers create individual schemas in the warehouse for each one of these denormalized tables (Each schema has only 1 wide table)? So it is like a 1:1 mapping of schema to table.&lt;/p&gt;\n\n&lt;p&gt;If a different data engineering team favored the star schema instead, would there just be a single star schema inside of each schema?&lt;/p&gt;\n\n&lt;p&gt;We can also assume that there is no need to create schemas for security/permission reasons. All BI developers will have access to the entire warehouse.&lt;/p&gt;\n\n&lt;p&gt;Is there ever a scenario where schema separation is irrelevant in a data warehouse?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advanced for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10z19dl", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10z19dl/confused_about_data_warehouse_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10z19dl/confused_about_data_warehouse_schema/", "subreddit_subscribers": 89107, "created_utc": 1676058884.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9lgq0ecy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer with 2 YOE. Planning to switch job and could use some feedback on my resume. Thanks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10yzbes", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2Y_0eQhgojj2j2fUXstl9GFd8dj8SoLazIrDfk2_-aA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676054271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/rk2hpmv8oeha1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/rk2hpmv8oeha1.jpg?auto=webp&amp;v=enabled&amp;s=b171d707c1a2e73333dadf28a78aba7b31326f60", "width": 2448, "height": 3168}, "resolutions": [{"url": "https://preview.redd.it/rk2hpmv8oeha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d2245c1513fe2b24b5ab8fe434461cbac0f9708f", "width": 108, "height": 139}, {"url": "https://preview.redd.it/rk2hpmv8oeha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=432323d4d8f6f4ee1bd390fc4fb6e20911b329a3", "width": 216, "height": 279}, {"url": "https://preview.redd.it/rk2hpmv8oeha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63fac91e58370395915433b01e12bd505b767f20", "width": 320, "height": 414}, {"url": "https://preview.redd.it/rk2hpmv8oeha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70135d9062705597112dbe132edabc43e992ba85", "width": 640, "height": 828}, {"url": "https://preview.redd.it/rk2hpmv8oeha1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b24744cef3725732e11797790c9a7e82e045e6a", "width": 960, "height": 1242}, {"url": "https://preview.redd.it/rk2hpmv8oeha1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fddfc6e2b158e20fe09fc0cc682a2617d666174d", "width": 1080, "height": 1397}], "variants": {}, "id": "7peITHwvur8hWLbPyVoHk48EMh-la5ctDhFU5pDTyfw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10yzbes", "is_robot_indexable": true, "report_reasons": null, "author": "deeLi007", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10yzbes/data_engineer_with_2_yoe_planning_to_switch_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/rk2hpmv8oeha1.jpg", "subreddit_subscribers": 89107, "created_utc": 1676054271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We'd like to use Production data to test performance in our dev environment. But the company doesn't allow us to use production data in dev. So we're looking to replace characters in specific fields in the parquet to the point where it's not considered production data so we can test it in dev. The requirement is that the data structure/characteristics must remain the same. Meaning, if we change \"John\" to \"Alex\" then all \"John\" must change to \"Alex\", same for addresses, phone numbers, IP addresses etc.\n\nCan we easily achieve this somehow with parquet files?  \n\n\nAfter doing a bit of research, seems like the best way to do this is:  \n1. Convert parquet to a CSV  \n2. Make changes to CSV  \n3. Create parquet files based on CSV", "author_fullname": "t2_1tbzh2ae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Replacing characters &amp; numbers in parquet files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10yy44g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676051311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;d like to use Production data to test performance in our dev environment. But the company doesn&amp;#39;t allow us to use production data in dev. So we&amp;#39;re looking to replace characters in specific fields in the parquet to the point where it&amp;#39;s not considered production data so we can test it in dev. The requirement is that the data structure/characteristics must remain the same. Meaning, if we change &amp;quot;John&amp;quot; to &amp;quot;Alex&amp;quot; then all &amp;quot;John&amp;quot; must change to &amp;quot;Alex&amp;quot;, same for addresses, phone numbers, IP addresses etc.&lt;/p&gt;\n\n&lt;p&gt;Can we easily achieve this somehow with parquet files?  &lt;/p&gt;\n\n&lt;p&gt;After doing a bit of research, seems like the best way to do this is:&lt;br/&gt;\n1. Convert parquet to a CSV&lt;br/&gt;\n2. Make changes to CSV&lt;br/&gt;\n3. Create parquet files based on CSV&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10yy44g", "is_robot_indexable": true, "report_reasons": null, "author": "TeslaMecca", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10yy44g/replacing_characters_numbers_in_parquet_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10yy44g/replacing_characters_numbers_in_parquet_files/", "subreddit_subscribers": 89107, "created_utc": 1676051311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI'm new here.\n\n**tl;dr: need help creating a pipeline, not a data engineer**\n\n&amp;#x200B;\n\nI work solely on the front side, data governance/management, with some modeling, analysis, and visualization. Above average interest in the back-end, infrastructure, systems design, studied CS before B-school. After doing research on job openings for a manager/leadership role, in 80% one of the things I should have is essential knowledge and experience with data pipelines. Not to actually do pipeline-related tasks, but to understand the entire journey from source to delivery.\n\nSince I'm interested in that side anyway, figured it would be a great challenge to create my own pipeline, nothing fancy with a gazillion tasks, lines, jobs, requiring high-tier cloud subscriptions, but something simple that ticks off the box on common phases.\n\nWhat I like to make is this:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/fpkwwrgorbha1.png?width=1623&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=19cd66c464b0d6de96fbcfcb54f20ff353833128\n\nThree major blocks.\n\n\\- Starting with the one on the right, I have experience with PowerBI and know how to connect a data source.  \n\\- In the center, I have experience with SQL databases, but *not* connecting them  \n\\- On the left, this is the part I do not have experience in at all. I googled on creating random data and found Python tutorials, somewhat able to read and understand the code.\n\nMust-haves:\n\n\\- first two blocks in the cloud, providers with free tier is highly preferred  \n\\- automation of three daily jobs (as far as I can tell); creating the data, storing it, sending it and store it in the second database\n\nNice-to-have\n\n\\- having the data creation and first storage in the same app\n\nAbsolutely-not-have\n\n\\- anything that requires a Command Line, I still have a trauma on this from CS school\n\n&amp;#x200B;\n\n**Objective**\n\nHaving a daily feed of new data in the second database, fully automated\n\n**Goal**\n\nAbility to refresh my BI dashboard/reports on a weekly/daily basis with new and unknown data, ready to be analyzed.\n\n&amp;#x200B;\n\n**Need help with**\n\n\\- does my flow makes sense?  \n\\- cloud app with free tier recommendations for the first phase, if Python is great for this, the app would need both Python and SQL, not sure if this kind of app exist; if you think there is a better solution, would love to learn about it  \n\\- how do I get the data from block 1 to block 2, all automated? what kind of app do I need for this, how are these apps called? something like Hevo or Keboola, or am I confused on what they do?\n\nIn case I'm missing things, feel free to mention.\n\nThanks in advance.", "author_fullname": "t2_kh3ubtce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a pipeline as non-engineer - Need Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "media_metadata": {"fpkwwrgorbha1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/fpkwwrgorbha1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=835eeb1bddf21c38d55b2341caf4d18d9fa5755f"}, {"y": 111, "x": 216, "u": "https://preview.redd.it/fpkwwrgorbha1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b7053441140ae6e9a9be23b18bc8211110e59db"}, {"y": 165, "x": 320, "u": "https://preview.redd.it/fpkwwrgorbha1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3087ef3d4bfa601a8840cddd3d82b386d134a631"}, {"y": 330, "x": 640, "u": "https://preview.redd.it/fpkwwrgorbha1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=94f34b46da302456874e65e0f3fc94e61feffd7b"}, {"y": 496, "x": 960, "u": "https://preview.redd.it/fpkwwrgorbha1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13028159d458fa31b1b0b351862bee48e7cf6a0f"}, {"y": 558, "x": 1080, "u": "https://preview.redd.it/fpkwwrgorbha1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d8ef44cf47992a189c6037e4683bd0baf271ac1"}], "s": {"y": 839, "x": 1623, "u": "https://preview.redd.it/fpkwwrgorbha1.png?width=1623&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=19cd66c464b0d6de96fbcfcb54f20ff353833128"}, "id": "fpkwwrgorbha1"}}, "name": "t3_10ym8zp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fmqM1uf6pHirZaZn4ECVC6Fc40uXxgDgImD9oNnW3yI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676020678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new here.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;tl;dr: need help creating a pipeline, not a data engineer&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I work solely on the front side, data governance/management, with some modeling, analysis, and visualization. Above average interest in the back-end, infrastructure, systems design, studied CS before B-school. After doing research on job openings for a manager/leadership role, in 80% one of the things I should have is essential knowledge and experience with data pipelines. Not to actually do pipeline-related tasks, but to understand the entire journey from source to delivery.&lt;/p&gt;\n\n&lt;p&gt;Since I&amp;#39;m interested in that side anyway, figured it would be a great challenge to create my own pipeline, nothing fancy with a gazillion tasks, lines, jobs, requiring high-tier cloud subscriptions, but something simple that ticks off the box on common phases.&lt;/p&gt;\n\n&lt;p&gt;What I like to make is this:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fpkwwrgorbha1.png?width=1623&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=19cd66c464b0d6de96fbcfcb54f20ff353833128\"&gt;https://preview.redd.it/fpkwwrgorbha1.png?width=1623&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=19cd66c464b0d6de96fbcfcb54f20ff353833128&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Three major blocks.&lt;/p&gt;\n\n&lt;p&gt;- Starting with the one on the right, I have experience with PowerBI and know how to connect a data source.&lt;br/&gt;\n- In the center, I have experience with SQL databases, but &lt;em&gt;not&lt;/em&gt; connecting them&lt;br/&gt;\n- On the left, this is the part I do not have experience in at all. I googled on creating random data and found Python tutorials, somewhat able to read and understand the code.&lt;/p&gt;\n\n&lt;p&gt;Must-haves:&lt;/p&gt;\n\n&lt;p&gt;- first two blocks in the cloud, providers with free tier is highly preferred&lt;br/&gt;\n- automation of three daily jobs (as far as I can tell); creating the data, storing it, sending it and store it in the second database&lt;/p&gt;\n\n&lt;p&gt;Nice-to-have&lt;/p&gt;\n\n&lt;p&gt;- having the data creation and first storage in the same app&lt;/p&gt;\n\n&lt;p&gt;Absolutely-not-have&lt;/p&gt;\n\n&lt;p&gt;- anything that requires a Command Line, I still have a trauma on this from CS school&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Objective&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Having a daily feed of new data in the second database, fully automated&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Goal&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Ability to refresh my BI dashboard/reports on a weekly/daily basis with new and unknown data, ready to be analyzed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Need help with&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- does my flow makes sense?&lt;br/&gt;\n- cloud app with free tier recommendations for the first phase, if Python is great for this, the app would need both Python and SQL, not sure if this kind of app exist; if you think there is a better solution, would love to learn about it&lt;br/&gt;\n- how do I get the data from block 1 to block 2, all automated? what kind of app do I need for this, how are these apps called? something like Hevo or Keboola, or am I confused on what they do?&lt;/p&gt;\n\n&lt;p&gt;In case I&amp;#39;m missing things, feel free to mention.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ym8zp", "is_robot_indexable": true, "report_reasons": null, "author": "SquidsAndMartians", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ym8zp/creating_a_pipeline_as_nonengineer_need_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ym8zp/creating_a_pipeline_as_nonengineer_need_help/", "subreddit_subscribers": 89107, "created_utc": 1676020678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are in process of building a Lakehouse architecture using S3 + Trino. I am a little bit worried about a potential cases where this setup would not be enough. So far I have not came up with any scenario this setup would not be sufficient but wanted to ask more experienced ones if there is some scenario in your mind where the S3 + Trino (or any other engine) would not be sufficient, meaning it would be required to add for example a relational database on top of the S3 or something else?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Specific cases where Lakehouse is not enough?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10z03o2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676056137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are in process of building a Lakehouse architecture using S3 + Trino. I am a little bit worried about a potential cases where this setup would not be enough. So far I have not came up with any scenario this setup would not be sufficient but wanted to ask more experienced ones if there is some scenario in your mind where the S3 + Trino (or any other engine) would not be sufficient, meaning it would be required to add for example a relational database on top of the S3 or something else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10z03o2", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10z03o2/specific_cases_where_lakehouse_is_not_enough/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10z03o2/specific_cases_where_lakehouse_is_not_enough/", "subreddit_subscribers": 89107, "created_utc": 1676056137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to engage some Collibra developers but the Collibra subreddit is gone now - what is the right place to find smart and interesting Collibra people? Thank you!", "author_fullname": "t2_4gb7k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do Collibra developers find jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10yxr90", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676050377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to engage some Collibra developers but the Collibra subreddit is gone now - what is the right place to find smart and interesting Collibra people? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10yxr90", "is_robot_indexable": true, "report_reasons": null, "author": "xiangw", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10yxr90/where_do_collibra_developers_find_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10yxr90/where_do_collibra_developers_find_jobs/", "subreddit_subscribers": 89107, "created_utc": 1676050377.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}