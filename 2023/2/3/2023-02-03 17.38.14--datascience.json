{"kind": "Listing", "data": {"after": "t3_10rz2bl", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_63eafwy9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What else is left? Should I continue with my masters in DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "name": "t3_10rx6tv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 480, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 480, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/G8x6k03gm8EMgwlFCMpo5i-MSm13IcOIML_f1xgkSFo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675363158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/os2nnoqt2vfa1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/os2nnoqt2vfa1.jpg?auto=webp&amp;v=enabled&amp;s=dde8a050326cc84e3e2cc38977c0cd7bf224fbc8", "width": 824, "height": 540}, "resolutions": [{"url": "https://preview.redd.it/os2nnoqt2vfa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08e88963fe6fc163997af1884b22cf1c40c687c1", "width": 108, "height": 70}, {"url": "https://preview.redd.it/os2nnoqt2vfa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1479ef56d0127f7ff066e3f28da403de60bf6f87", "width": 216, "height": 141}, {"url": "https://preview.redd.it/os2nnoqt2vfa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3240d7c2edf80b25501d7dff8351e6a9a33f9ff7", "width": 320, "height": 209}, {"url": "https://preview.redd.it/os2nnoqt2vfa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c1678644064c0c0951763cfd373d9baa393ed2a", "width": 640, "height": 419}], "variants": {}, "id": "3fj2zmyayudF7pay9-JbEcRJ0uKBsPc0YNqHRP_0jvk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10rx6tv", "is_robot_indexable": true, "report_reasons": null, "author": "burralohit01", "discussion_type": null, "num_comments": 240, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10rx6tv/what_else_is_left_should_i_continue_with_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/os2nnoqt2vfa1.jpg", "subreddit_subscribers": 844315, "created_utc": 1675363158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4uatr91l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are ML masters cash grabs by the uni? How do I evaluate how good the masters programs are?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ruv3a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 182, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 182, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675357446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ruv3a", "is_robot_indexable": true, "report_reasons": null, "author": "ambitiouslearner123", "discussion_type": null, "num_comments": 101, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ruv3a/are_ml_masters_cash_grabs_by_the_uni_how_do_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ruv3a/are_ml_masters_cash_grabs_by_the_uni_how_do_i/", "subreddit_subscribers": 844315, "created_utc": 1675357446.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Edit: Adding my information\n\nI'm working as a Data Scientist for a service company and currently working for a Fortune 50 client. I would ideally like to work directly for a Fortune 500 product company. \n\nI have 6 yrs exp and would I feel it will be most helpful to talk to and have mock interview with a Data Scientist rather than going through interview questions online or on youtube.", "author_fullname": "t2_3zcri4m6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any group or site where we can connect with Data Scientists and maybe have mock interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10sayrq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Job Search", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675436413.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675398244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edit: Adding my information&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working as a Data Scientist for a service company and currently working for a Fortune 50 client. I would ideally like to work directly for a Fortune 500 product company. &lt;/p&gt;\n\n&lt;p&gt;I have 6 yrs exp and would I feel it will be most helpful to talk to and have mock interview with a Data Scientist rather than going through interview questions online or on youtube.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "71803d7a-469d-11e9-890b-0e5d959976c8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "10sayrq", "is_robot_indexable": true, "report_reasons": null, "author": "secret_4ever13", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10sayrq/is_there_any_group_or_site_where_we_can_connect/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10sayrq/is_there_any_group_or_site_where_we_can_connect/", "subreddit_subscribers": 844315, "created_utc": 1675398244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_13neu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The y-axis is R^2 and the x-axis is the 8 blocks on my task. The fit changes as more data collects for each block. I am trying to make an argument to reduce the number of blocks after a certain point. I know there is an analysis to tell me when change becomes stable but I can't remember.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 85, "top_awarded_type": null, "hide_score": false, "name": "t3_10sjt6x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kmpEFdawsmUBE8R5sMcqi2_S-WPh17GYGVz-jt2wCzU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675429393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/vjai0ljy0zfa1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/vjai0ljy0zfa1.png?auto=webp&amp;v=enabled&amp;s=66f24496c36cadefa4a86b0de0f6806c3e94ee2d", "width": 1128, "height": 691}, "resolutions": [{"url": "https://preview.redd.it/vjai0ljy0zfa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b5ad28700d370509c06c42fa140969a8198336d", "width": 108, "height": 66}, {"url": "https://preview.redd.it/vjai0ljy0zfa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=814e53e38f0c1f092cbd3f6b353410ff8c97756b", "width": 216, "height": 132}, {"url": "https://preview.redd.it/vjai0ljy0zfa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d9d54ec5629ec02017aa01e2698cae6f20933a4", "width": 320, "height": 196}, {"url": "https://preview.redd.it/vjai0ljy0zfa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0053fa997a0003833dabaad474961bedb592fd01", "width": 640, "height": 392}, {"url": "https://preview.redd.it/vjai0ljy0zfa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=756eea73727f9039beeb09d7506eb4c3e771f423", "width": 960, "height": 588}, {"url": "https://preview.redd.it/vjai0ljy0zfa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2a3a8b91cca848133dda844b1fcfb46cc8974d1", "width": 1080, "height": 661}], "variants": {}, "id": "YtdkvY66_yowiLjcOHDP1T5mc4bFVQD-wqqeBmVQwq4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10sjt6x", "is_robot_indexable": true, "report_reasons": null, "author": "PsychShake", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10sjt6x/the_yaxis_is_r2_and_the_xaxis_is_the_8_blocks_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/vjai0ljy0zfa1.png", "subreddit_subscribers": 844315, "created_utc": 1675429393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m a hiring manager for a Data Science team. I\u2019m looking for a Junior DS and my methodology is:\n\n- I don\u2019t do coding interviews: I trust you know how to code, if you really want to be in this field you\u2019ll learn tools and languages on your own.\n\n- I don\u2019t do case study: I don\u2019t really have the time for this, I want my \u201ctechnical interviews\u201d to be 15-30 mins.\n\n- I want to know if you understand the basics of math/stats and if you can reason through unknowns. I want to see how you process through problems.\n\nLately I\u2019ve been getting candidates who make it to my round and when I ask them some basic concepts, they completely flunk it.\n\nSo I\u2019m wondering\u2026are my questions too hard?\n\nThe questions:\n\n1) You are given a tabular dataset that you have no prior knowledge about. Walk me though how you would profile this data? What steps would you take to explore this data? Explain to me your EDA process.\n\n2) How would you evaluate a linear regression model? What are the metrics and what does it represent?\n\n3) Explain the difference between Standardisation vs Normalisation.\n\n4) Explain what a type I and type II error are.\n\nThese last 2 questions I don\u2019t hold against them and which is why I ask last, and I let the candidates know it\u2019s good to know but not required. It would set them apart.\n\n5) Say you\u2019ve got a ETL job that needs to be ran daily, say it\u2019s a dataset that you need to pull from a server, do ETL, and upload it to a database or storage of sorts. How would you go about automating this task? What tools, methods would you use? The world is your oyster, any and all tools out there in the world are available.\n\n6) Can you give me a use case where you have worked in Cloud (ie. AWS/Azure) to support your data science projects?\n\nEdit: I have dialog when they answer questions or if they have questions for me. My style is, dialogue! Just chat with me.\n\nAre my questions too hard? Can I ask these questions in a better way without getting too elaborate? \n\n\nAppreciate the feedback and help.", "author_fullname": "t2_4hpiqt08", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Better interview questions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10s0mv9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675371675.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675371398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a hiring manager for a Data Science team. I\u2019m looking for a Junior DS and my methodology is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;I don\u2019t do coding interviews: I trust you know how to code, if you really want to be in this field you\u2019ll learn tools and languages on your own.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I don\u2019t do case study: I don\u2019t really have the time for this, I want my \u201ctechnical interviews\u201d to be 15-30 mins.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I want to know if you understand the basics of math/stats and if you can reason through unknowns. I want to see how you process through problems.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Lately I\u2019ve been getting candidates who make it to my round and when I ask them some basic concepts, they completely flunk it.&lt;/p&gt;\n\n&lt;p&gt;So I\u2019m wondering\u2026are my questions too hard?&lt;/p&gt;\n\n&lt;p&gt;The questions:&lt;/p&gt;\n\n&lt;p&gt;1) You are given a tabular dataset that you have no prior knowledge about. Walk me though how you would profile this data? What steps would you take to explore this data? Explain to me your EDA process.&lt;/p&gt;\n\n&lt;p&gt;2) How would you evaluate a linear regression model? What are the metrics and what does it represent?&lt;/p&gt;\n\n&lt;p&gt;3) Explain the difference between Standardisation vs Normalisation.&lt;/p&gt;\n\n&lt;p&gt;4) Explain what a type I and type II error are.&lt;/p&gt;\n\n&lt;p&gt;These last 2 questions I don\u2019t hold against them and which is why I ask last, and I let the candidates know it\u2019s good to know but not required. It would set them apart.&lt;/p&gt;\n\n&lt;p&gt;5) Say you\u2019ve got a ETL job that needs to be ran daily, say it\u2019s a dataset that you need to pull from a server, do ETL, and upload it to a database or storage of sorts. How would you go about automating this task? What tools, methods would you use? The world is your oyster, any and all tools out there in the world are available.&lt;/p&gt;\n\n&lt;p&gt;6) Can you give me a use case where you have worked in Cloud (ie. AWS/Azure) to support your data science projects?&lt;/p&gt;\n\n&lt;p&gt;Edit: I have dialog when they answer questions or if they have questions for me. My style is, dialogue! Just chat with me.&lt;/p&gt;\n\n&lt;p&gt;Are my questions too hard? Can I ask these questions in a better way without getting too elaborate? &lt;/p&gt;\n\n&lt;p&gt;Appreciate the feedback and help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10s0mv9", "is_robot_indexable": true, "report_reasons": null, "author": "CmdrAstroNaughty", "discussion_type": null, "num_comments": 51, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10s0mv9/better_interview_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10s0mv9/better_interview_questions/", "subreddit_subscribers": 844315, "created_utc": 1675371398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "so really by no means am I a data scientist. i sit on a strategy team with a new role of decision science. so i started yesterday taking over a process that had been in the past done throughout 3 teams, one of which is data and analytics team \n\n\nlong story short, the output from the many complex sql queries that have been being ran is most likely inaccurate and then the analysis done on it is independently shit. took me many many hours to figure this out and i\u2019m exhausted. i blew the whistle today because the deliverable goes out to major clients. my complaint is being taken seriously but still wtf \n\nhow can so many people be complicit in this?\n\nedit grammar\n\nfor context: i can write complex sql queries and know my way around R but I don\u2019t know complex stats,math, logic etc that goes into building ML, Ai etc models. Idky this is being downvoted so hard. know am young and probably wearing too heavily coated rose colored glasses, but i think this is a valid question to the sub :/", "author_fullname": "t2_icde9du6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incompetence is unethical?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10rw81j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675367271.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675360841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;so really by no means am I a data scientist. i sit on a strategy team with a new role of decision science. so i started yesterday taking over a process that had been in the past done throughout 3 teams, one of which is data and analytics team &lt;/p&gt;\n\n&lt;p&gt;long story short, the output from the many complex sql queries that have been being ran is most likely inaccurate and then the analysis done on it is independently shit. took me many many hours to figure this out and i\u2019m exhausted. i blew the whistle today because the deliverable goes out to major clients. my complaint is being taken seriously but still wtf &lt;/p&gt;\n\n&lt;p&gt;how can so many people be complicit in this?&lt;/p&gt;\n\n&lt;p&gt;edit grammar&lt;/p&gt;\n\n&lt;p&gt;for context: i can write complex sql queries and know my way around R but I don\u2019t know complex stats,math, logic etc that goes into building ML, Ai etc models. Idky this is being downvoted so hard. know am young and probably wearing too heavily coated rose colored glasses, but i think this is a valid question to the sub :/&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10rw81j", "is_robot_indexable": true, "report_reasons": null, "author": "suzzz4", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10rw81j/incompetence_is_unethical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10rw81j/incompetence_is_unethical/", "subreddit_subscribers": 844315, "created_utc": 1675360841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Spent around a month doing online search and study to learn more about the metrics related to Market Basket Analysis (lift, leverage, confidence, gain, etc).\n\nThe challenge is that most materials online are blogs that fail to provide more context on the metrics, or educational literature that simply summarizes all metrics but don\u2019t have any industry use cases.\n\nAny recommendations on industry/conference literatures or books, that go deep into Market Basket analysis?", "author_fullname": "t2_48648", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Industry Literature on Market Basket Analysis Metrics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10sd1ei", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675404794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Spent around a month doing online search and study to learn more about the metrics related to Market Basket Analysis (lift, leverage, confidence, gain, etc).&lt;/p&gt;\n\n&lt;p&gt;The challenge is that most materials online are blogs that fail to provide more context on the metrics, or educational literature that simply summarizes all metrics but don\u2019t have any industry use cases.&lt;/p&gt;\n\n&lt;p&gt;Any recommendations on industry/conference literatures or books, that go deep into Market Basket analysis?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10sd1ei", "is_robot_indexable": true, "report_reasons": null, "author": "forbiscuit", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10sd1ei/industry_literature_on_market_basket_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10sd1ei/industry_literature_on_market_basket_analysis/", "subreddit_subscribers": 844315, "created_utc": 1675404794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to work on a new project and create a web application that integrates deep learning.\n\nI've always wanted to try my hand at making a chatbot, but as a beginner in data science, I could use some help. \n\nCan anyone share some creative ideas or exciting topics to make my chatbot stand out? Also, any tips on finding or creating a suitable dataset would be greatly appreciated. Thank you!", "author_fullname": "t2_9816q5sg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Inspiration for Deep Learning Chatbot Project: Ideas &amp; Dataset Resources Needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10skop8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675431997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to work on a new project and create a web application that integrates deep learning.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve always wanted to try my hand at making a chatbot, but as a beginner in data science, I could use some help. &lt;/p&gt;\n\n&lt;p&gt;Can anyone share some creative ideas or exciting topics to make my chatbot stand out? Also, any tips on finding or creating a suitable dataset would be greatly appreciated. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10skop8", "is_robot_indexable": true, "report_reasons": null, "author": "ClickJolly", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10skop8/seeking_inspiration_for_deep_learning_chatbot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10skop8/seeking_inspiration_for_deep_learning_chatbot/", "subreddit_subscribers": 844315, "created_utc": 1675431997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I just joined a software company's support operations team as a data scientist. My first project is to improve the current forecasting model predicting future support case volume over the next 12 months to be used as an input for capacity planning.\n\nThe company has multiple software products and the current forecasting models that have been used are all just univariate forecast models that have been only trained on using the historical case volume for each product. These models in general perform pretty well in terms of forecasting accuracy, but the business stakeholders are complaining about how \"un-explainable\" these forecast values are. They want to break down each forecast values into multiple components, but the current model class won't allow them to do so because the these forecasts are only derived from analyzing the past volume's seasonality, holiday effects, and running trends (either increasing or decreasing year over year).\n\nWhen I chat with my business stakeholders, they said that the case volume is driven by factors such as active customer count/distribution of customer size across different regions, product maturity measure, case deflection rate (how self-serviceable the company's Knowledge articles and navigations are), and others. We do have these drivers and the stakeholders want to use them and their expectations of the future trends for these drivers in the upcoming forecasts.\n\nLooks like I can try multivariate models such as VAR, VMA, VARMA, or VARMAX. However, I'm not really sure how reliable they would be. If they won't result in something that will be adopted, then I would prioritize improving the current model's accuracy.\n\nSo my question is, have you also run into the similar problem? Are multivariate forecasts actually even used in Capacity planning? Which model class can I look into?", "author_fullname": "t2_g22fgoun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Explainable Forecasting used in practice? Multivariate Forecast vs Univariate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10rxl4n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675364096.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just joined a software company&amp;#39;s support operations team as a data scientist. My first project is to improve the current forecasting model predicting future support case volume over the next 12 months to be used as an input for capacity planning.&lt;/p&gt;\n\n&lt;p&gt;The company has multiple software products and the current forecasting models that have been used are all just univariate forecast models that have been only trained on using the historical case volume for each product. These models in general perform pretty well in terms of forecasting accuracy, but the business stakeholders are complaining about how &amp;quot;un-explainable&amp;quot; these forecast values are. They want to break down each forecast values into multiple components, but the current model class won&amp;#39;t allow them to do so because the these forecasts are only derived from analyzing the past volume&amp;#39;s seasonality, holiday effects, and running trends (either increasing or decreasing year over year).&lt;/p&gt;\n\n&lt;p&gt;When I chat with my business stakeholders, they said that the case volume is driven by factors such as active customer count/distribution of customer size across different regions, product maturity measure, case deflection rate (how self-serviceable the company&amp;#39;s Knowledge articles and navigations are), and others. We do have these drivers and the stakeholders want to use them and their expectations of the future trends for these drivers in the upcoming forecasts.&lt;/p&gt;\n\n&lt;p&gt;Looks like I can try multivariate models such as VAR, VMA, VARMA, or VARMAX. However, I&amp;#39;m not really sure how reliable they would be. If they won&amp;#39;t result in something that will be adopted, then I would prioritize improving the current model&amp;#39;s accuracy.&lt;/p&gt;\n\n&lt;p&gt;So my question is, have you also run into the similar problem? Are multivariate forecasts actually even used in Capacity planning? Which model class can I look into?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10rxl4n", "is_robot_indexable": true, "report_reasons": null, "author": "welcomestats", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10rxl4n/is_explainable_forecasting_used_in_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10rxl4n/is_explainable_forecasting_used_in_practice/", "subreddit_subscribers": 844315, "created_utc": 1675364096.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI am doing workforce planning for a business center, but I am stumped.\n\nIn my workplace, in 2022, a total of 102 cases (i.e. work that needs to be done for this workplace) arrived, on average 1 case every 3.5 days. The response time for these jobs is given as approximately 30 days. The jobs received are solved in an average of 14 days.\n\nThe problem is that with Erlang C I cannot find out how many staff I need in this scenario.\n\nThe other problem is that my manager wants answers to the questions \"How many staff will we need if it will be answered in 15 days, how many staff will we need if it will be answered in 60 days, how many staff will we need if it will be answered in 90 days?\".\n\nIn other words, he is asking me how many staff I will need for each of the cases to be answered in 15-30-60-90 days respectively. I tried to do it with Python &amp; Erlang C but I couldn't solve it. I am sharing with you both the code I wrote and a section from the excel file.\n\nPlease tell me what I am doing wrong and how I can fix it.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/zb7sc2ib5tfa1.png?width=1833&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=075110a150b7204517fff1221fa5628189dd5a64\n\nhttps://preview.redd.it/ptu5o4ib5tfa1.png?width=1841&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c247482cb7ef772f030a7bdd8b490e508e7ab2e1", "author_fullname": "t2_vrqmp7zh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Workforce Planning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 18, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zb7sc2ib5tfa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 14, "x": 108, "u": "https://preview.redd.it/zb7sc2ib5tfa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9dc0af14c861dc55375394b62c391fda6610745e"}, {"y": 28, "x": 216, "u": "https://preview.redd.it/zb7sc2ib5tfa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ef3fe3a9268b844bb47c441ce07391235334c83"}, {"y": 42, "x": 320, "u": "https://preview.redd.it/zb7sc2ib5tfa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3c707552a3f00ae379268df84322ea3992cb5cae"}, {"y": 85, "x": 640, "u": "https://preview.redd.it/zb7sc2ib5tfa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=846da110a408cbe265c2dd02da720bf3dec83f87"}, {"y": 128, "x": 960, "u": "https://preview.redd.it/zb7sc2ib5tfa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72773d5cb9863a60797fba50ed11924d6e26a9f5"}, {"y": 144, "x": 1080, "u": "https://preview.redd.it/zb7sc2ib5tfa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d90c197c6c8a7abc400e51afdb4649ac80985d0"}], "s": {"y": 245, "x": 1833, "u": "https://preview.redd.it/zb7sc2ib5tfa1.png?width=1833&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=075110a150b7204517fff1221fa5628189dd5a64"}, "id": "zb7sc2ib5tfa1"}, "ptu5o4ib5tfa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 38, "x": 108, "u": "https://preview.redd.it/ptu5o4ib5tfa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=baf59db93fe08d61b63fc8a73ab70ed3dae5c019"}, {"y": 76, "x": 216, "u": "https://preview.redd.it/ptu5o4ib5tfa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=03f45d7d290dfdae8b00af2e0429f04ae2c7e3e1"}, {"y": 113, "x": 320, "u": "https://preview.redd.it/ptu5o4ib5tfa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bf5140baa85847446124662e735a52358ee4e2c8"}, {"y": 227, "x": 640, "u": "https://preview.redd.it/ptu5o4ib5tfa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47372ae54fab2669a859e7e1423a17167bc30b24"}, {"y": 340, "x": 960, "u": "https://preview.redd.it/ptu5o4ib5tfa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6a5af65f2d97b2b5570b5222a3a7aae3ac2b1641"}, {"y": 383, "x": 1080, "u": "https://preview.redd.it/ptu5o4ib5tfa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=07a73068c9996d2f8108f69085ace0c077a7c88f"}], "s": {"y": 653, "x": 1841, "u": "https://preview.redd.it/ptu5o4ib5tfa1.png?width=1841&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c247482cb7ef772f030a7bdd8b490e508e7ab2e1"}, "id": "ptu5o4ib5tfa1"}}, "name": "t3_10rv09v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5YzxF8EjcwQjq0Fo2fwzh3F8xGPJvJUd01PJV37bvyg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675357803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am doing workforce planning for a business center, but I am stumped.&lt;/p&gt;\n\n&lt;p&gt;In my workplace, in 2022, a total of 102 cases (i.e. work that needs to be done for this workplace) arrived, on average 1 case every 3.5 days. The response time for these jobs is given as approximately 30 days. The jobs received are solved in an average of 14 days.&lt;/p&gt;\n\n&lt;p&gt;The problem is that with Erlang C I cannot find out how many staff I need in this scenario.&lt;/p&gt;\n\n&lt;p&gt;The other problem is that my manager wants answers to the questions &amp;quot;How many staff will we need if it will be answered in 15 days, how many staff will we need if it will be answered in 60 days, how many staff will we need if it will be answered in 90 days?&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;In other words, he is asking me how many staff I will need for each of the cases to be answered in 15-30-60-90 days respectively. I tried to do it with Python &amp;amp; Erlang C but I couldn&amp;#39;t solve it. I am sharing with you both the code I wrote and a section from the excel file.&lt;/p&gt;\n\n&lt;p&gt;Please tell me what I am doing wrong and how I can fix it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zb7sc2ib5tfa1.png?width=1833&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=075110a150b7204517fff1221fa5628189dd5a64\"&gt;https://preview.redd.it/zb7sc2ib5tfa1.png?width=1833&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=075110a150b7204517fff1221fa5628189dd5a64&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ptu5o4ib5tfa1.png?width=1841&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c247482cb7ef772f030a7bdd8b490e508e7ab2e1\"&gt;https://preview.redd.it/ptu5o4ib5tfa1.png?width=1841&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c247482cb7ef772f030a7bdd8b490e508e7ab2e1&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10rv09v", "is_robot_indexable": true, "report_reasons": null, "author": "vborlfc", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10rv09v/workforce_planning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10rv09v/workforce_planning/", "subreddit_subscribers": 844315, "created_utc": 1675357803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Can somebody help me with this, dms are welcome:)", "author_fullname": "t2_8d65lpw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you show a serverless architecture for ML Versioning, Data Drift, Model Drift using Databricks, MLFlow and Kubernetes ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10sp1ca", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675443112.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can somebody help me with this, dms are welcome:)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10sp1ca", "is_robot_indexable": true, "report_reasons": null, "author": "mush26_7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10sp1ca/can_you_show_a_serverless_architecture_for_ml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10sp1ca/can_you_show_a_serverless_architecture_for_ml/", "subreddit_subscribers": 844315, "created_utc": 1675443112.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We have a predictive model that is built using a Minitab decision tree. The model has a 70% accuracy compared to a most frequent dummy classifier that would have an 80% accuracy. I suggested that we use Python and a more modern ML method to approach this problem. She, and I quote, said, \u201cthat\u2019s a terrible idea.\u201d\n\nTo be honest the whole process is terrible, there was no evidence of EDA, feature engineering, or anything I would consider to be a normal part of the ML process. The model is \u201cput into production\u201d by recreating the tree\u2019s logic in SQL, resulting in a SQL query 600 lines long.\n\nIt is my task to review this model and present my findings to management. How do I work with this?", "author_fullname": "t2_i0nlm1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any experience dealing with a non-technical manager?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10soqdd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675442353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a predictive model that is built using a Minitab decision tree. The model has a 70% accuracy compared to a most frequent dummy classifier that would have an 80% accuracy. I suggested that we use Python and a more modern ML method to approach this problem. She, and I quote, said, \u201cthat\u2019s a terrible idea.\u201d&lt;/p&gt;\n\n&lt;p&gt;To be honest the whole process is terrible, there was no evidence of EDA, feature engineering, or anything I would consider to be a normal part of the ML process. The model is \u201cput into production\u201d by recreating the tree\u2019s logic in SQL, resulting in a SQL query 600 lines long.&lt;/p&gt;\n\n&lt;p&gt;It is my task to review this model and present my findings to management. How do I work with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10soqdd", "is_robot_indexable": true, "report_reasons": null, "author": "benchalldat", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10soqdd/any_experience_dealing_with_a_nontechnical_manager/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10soqdd/any_experience_dealing_with_a_nontechnical_manager/", "subreddit_subscribers": 844315, "created_utc": 1675442353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For instance, i am now plotting the density of a data set that is very sparse. thats why i would like to use some smoothing with a convolution. but then extrema won't remain the same. but i know the data was obtained via a stochastic process. so i guess i can omit extrema. whats your perspectives on that subject ?", "author_fullname": "t2_vo95ey45", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you choose the threshold for interpolation, smoothing, outlier detection methods ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10snuzn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675440220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For instance, i am now plotting the density of a data set that is very sparse. thats why i would like to use some smoothing with a convolution. but then extrema won&amp;#39;t remain the same. but i know the data was obtained via a stochastic process. so i guess i can omit extrema. whats your perspectives on that subject ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10snuzn", "is_robot_indexable": true, "report_reasons": null, "author": "BlacksmithNo4415", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10snuzn/where_do_you_choose_the_threshold_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10snuzn/where_do_you_choose_the_threshold_for/", "subreddit_subscribers": 844315, "created_utc": 1675440220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, we\u2019re a team of 3 Data Scientists and I\u2019m the Senior Data Scientist in the team. I\u2019m thinking of introducing a Friday Coding Challenge where we solve from Data Structures problem or familiar LeetCode problem where all of us can practice how we deal with solving coding problems.\nIs it a good idea? Has anyone tried and it wasn\u2019t a good idea?", "author_fullname": "t2_90pyvsip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Friday Coding Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10simm1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675425554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, we\u2019re a team of 3 Data Scientists and I\u2019m the Senior Data Scientist in the team. I\u2019m thinking of introducing a Friday Coding Challenge where we solve from Data Structures problem or familiar LeetCode problem where all of us can practice how we deal with solving coding problems.\nIs it a good idea? Has anyone tried and it wasn\u2019t a good idea?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10simm1", "is_robot_indexable": true, "report_reasons": null, "author": "Gagan_Ku2905", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10simm1/friday_coding_challenge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10simm1/friday_coding_challenge/", "subreddit_subscribers": 844315, "created_utc": 1675425554.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset full of Twitter tweets, with a column for the text of the tweet. For each tweet, one word has been selected as a keyword and each such word is in another column called \"keyword.\" '\n\nFor my purposes, these keywords serve as a label.\n\nMy goal is to create a model to label a Tweet, but I'm having trouble deciding how to encode the label so that I can properly label the Tweets.\n\nMy vocabulary size is 41,886 words, so figure the number of bits for one-hot encoding is 41,886. My training set has 5709 rows and my test set 1904 rows, so 7613 rows in all, so if I try to one-hot encode the keywords, figure roughly 319 million elements in the resulting one-hot encoding array.\n\nUsing word2vec would be problematic, I think, because you can't classify vectors without running the risk of floating-point-related errors.\n\nWhat's the most optimal encoding specifically for this purpose?", "author_fullname": "t2_5zg4jvtk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimal encoding for labelling of a target word", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10s4jge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675380677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset full of Twitter tweets, with a column for the text of the tweet. For each tweet, one word has been selected as a keyword and each such word is in another column called &amp;quot;keyword.&amp;quot; &amp;#39;&lt;/p&gt;\n\n&lt;p&gt;For my purposes, these keywords serve as a label.&lt;/p&gt;\n\n&lt;p&gt;My goal is to create a model to label a Tweet, but I&amp;#39;m having trouble deciding how to encode the label so that I can properly label the Tweets.&lt;/p&gt;\n\n&lt;p&gt;My vocabulary size is 41,886 words, so figure the number of bits for one-hot encoding is 41,886. My training set has 5709 rows and my test set 1904 rows, so 7613 rows in all, so if I try to one-hot encode the keywords, figure roughly 319 million elements in the resulting one-hot encoding array.&lt;/p&gt;\n\n&lt;p&gt;Using word2vec would be problematic, I think, because you can&amp;#39;t classify vectors without running the risk of floating-point-related errors.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the most optimal encoding specifically for this purpose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10s4jge", "is_robot_indexable": true, "report_reasons": null, "author": "Comprehensive-Ad3963", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10s4jge/optimal_encoding_for_labelling_of_a_target_word/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10s4jge/optimal_encoding_for_labelling_of_a_target_word/", "subreddit_subscribers": 844315, "created_utc": 1675380677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The traditional route to data science seems to be at least a Masters in Maths &gt; DS &gt; ML etc.\n\nThis is obviously a good start and will hopefully instil good DS foundations - in terms of the theory and tech skills (Python/R etc).\n\nOne key ingredient that is missing is an emphasis on pro-activity. You go through school being told exactly what to do. You go to uni, again being told what to do. And then you get an entry level DS job and they tell you what to do.\n\nAn important skill to develop is being able to asses the tools and materials available to you and come up with something that adds value all on your own. E.g. if you are a data anaylst or DE? well you have access to a shit load of data. Say your company has commercial interests i.e. they want more sales etc. Can you use some advanced analysis to either review customer behaviour or potentially create a model to predict sales?", "author_fullname": "t2_54mhvh20", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You don't need to wait for someone to tell you what to do", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10s1dcn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675373142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The traditional route to data science seems to be at least a Masters in Maths &amp;gt; DS &amp;gt; ML etc.&lt;/p&gt;\n\n&lt;p&gt;This is obviously a good start and will hopefully instil good DS foundations - in terms of the theory and tech skills (Python/R etc).&lt;/p&gt;\n\n&lt;p&gt;One key ingredient that is missing is an emphasis on pro-activity. You go through school being told exactly what to do. You go to uni, again being told what to do. And then you get an entry level DS job and they tell you what to do.&lt;/p&gt;\n\n&lt;p&gt;An important skill to develop is being able to asses the tools and materials available to you and come up with something that adds value all on your own. E.g. if you are a data anaylst or DE? well you have access to a shit load of data. Say your company has commercial interests i.e. they want more sales etc. Can you use some advanced analysis to either review customer behaviour or potentially create a model to predict sales?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10s1dcn", "is_robot_indexable": true, "report_reasons": null, "author": "bum_dog_timemachine", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10s1dcn/you_dont_need_to_wait_for_someone_to_tell_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10s1dcn/you_dont_need_to_wait_for_someone_to_tell_you/", "subreddit_subscribers": 844315, "created_utc": 1675373142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm curious if any of you cuss at work. Feel free to leave longer remarks in the comment section if you feel the want.\n\n[View Poll](https://www.reddit.com/poll/10s66rc)", "author_fullname": "t2_nq8r4b4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you cuss while at work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10s66rc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675384919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious if any of you cuss at work. Feel free to leave longer remarks in the comment section if you feel the want.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10s66rc\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": null, "id": "10s66rc", "is_robot_indexable": true, "report_reasons": null, "author": "ModusLordMaxiumus", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1675557719567, "options": [{"text": "Yes, openly", "id": "21393540"}, {"text": "No never", "id": "21393541"}, {"text": "Yes, when no one is around", "id": "21393542"}, {"text": "Yes, only around a few people", "id": "21393543"}, {"text": "I'm just interested in responses", "id": "21393544"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 542, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10s66rc/do_you_cuss_while_at_work/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/datascience/comments/10s66rc/do_you_cuss_while_at_work/", "subreddit_subscribers": 844315, "created_utc": 1675384919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello good people I have not a clue about data science, but I have always liked spreadsheets and organizing stuff and I would like to learn whatever I can as a hobby and something to put in the cave where should I start?\n\nThank you in advance", "author_fullname": "t2_58gzih12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dilettante in search of guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10s0tzi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675371848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello good people I have not a clue about data science, but I have always liked spreadsheets and organizing stuff and I would like to learn whatever I can as a hobby and something to put in the cave where should I start?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10s0tzi", "is_robot_indexable": true, "report_reasons": null, "author": "G0tm0g", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10s0tzi/dilettante_in_search_of_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10s0tzi/dilettante_in_search_of_guidance/", "subreddit_subscribers": 844315, "created_utc": 1675371848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have xml files of bugzilla bug severity data which I want to use in my ml model to predict severity of a bug, but all fields of bug like id,title,description are into different xml files but they have a common attribute of bug\\_id. I want to merge them all into a CSV files so that i can work on them to create my prediction model. I need this for my college project.", "author_fullname": "t2_7n4a9r4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to merge mulriple xml files into single csv file?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10s04rl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675370180.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have xml files of bugzilla bug severity data which I want to use in my ml model to predict severity of a bug, but all fields of bug like id,title,description are into different xml files but they have a common attribute of bug_id. I want to merge them all into a CSV files so that i can work on them to create my prediction model. I need this for my college project.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10s04rl", "is_robot_indexable": true, "report_reasons": null, "author": "CreativeGold5336", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10s04rl/how_to_merge_mulriple_xml_files_into_single_csv/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10s04rl/how_to_merge_mulriple_xml_files_into_single_csv/", "subreddit_subscribers": 844315, "created_utc": 1675370180.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all.  I'm not quite a data scientist, but I'm pretty data literate, though I haven't gotten my hands dirty in a few years. While I was quite proficient with doing analytics with excel when I'd just download a bunch of data, now that things are embracing single-source-of-truth, automation and cloud-based approaches, doing basic manual things has gotten a lot harder, even with desktop excel.  I've learned a lot of new stuff, but some key things are eluding me.  If I was doing a big enterprise-scale, future-forward solution, I actually feel like I could move forward well, but trying to utilize these tools in my personal life has been hard.\n\nTo start my current use case of personal finances (and its only step one of getting a good personal finance dashboard), I need to merge, categorize, and ignore some data in spreadsheets *that have the same column schema*, and that alone has ended up being really hard to do.  Not even getting to mapping tables or anything like that yet.\n\nMy big, *core* issue is that I can do queries, make transformation rules, but I can't seem to find a way to edit/add data once I get it all in one place (got forbid I want to make the edits when I actually see the data on a powerBI dashboard)  Googling this has been hard (ex: googling edit source data returns results for editing data locations), and he educational materials I've found all seem to focus on big enterprise level data where the solution is not to have any manual editing at all.\n\nCase in point:  Categorizing expenses from venmo (which only lets you download one month at a time).  I can query the sheets.  In old-school excel, I'd copy all the rows together, sort by vendor, and then manually batch categorize.  It's take me ten minutes tops, and then I'd use that as a sort of 'silver' data set to import in to my final dataset.  Now, I can query the individual sheets via power query (venmo only lets you download a month at a time), but adding categorization or deciding to remove a row seems impossible.  Right now it seems like the only thing I could do is write a python script, or go super manual any time I want to merge some data and copy&amp;paste individual rows from many different sheets.  I'd love to streamline and utilize the new stuff, but it seems like the more manual side of data cleaning has to happen alllll the way down at the raw source and that kinda sucks when you have similar data across twenty different sources, or want to add data (like a category) at a higher level.\n\n&amp;#x200B;\n\nSorry for the long post.  I fully expect that the real problem is I'm just thinking about things too old-school somehow and need to do somehow change my paradigm with all of this.", "author_fullname": "t2_p4eu0tpa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Editing source data in modern toolsets, especially excel/powerBI", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10rzsbj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675369342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all.  I&amp;#39;m not quite a data scientist, but I&amp;#39;m pretty data literate, though I haven&amp;#39;t gotten my hands dirty in a few years. While I was quite proficient with doing analytics with excel when I&amp;#39;d just download a bunch of data, now that things are embracing single-source-of-truth, automation and cloud-based approaches, doing basic manual things has gotten a lot harder, even with desktop excel.  I&amp;#39;ve learned a lot of new stuff, but some key things are eluding me.  If I was doing a big enterprise-scale, future-forward solution, I actually feel like I could move forward well, but trying to utilize these tools in my personal life has been hard.&lt;/p&gt;\n\n&lt;p&gt;To start my current use case of personal finances (and its only step one of getting a good personal finance dashboard), I need to merge, categorize, and ignore some data in spreadsheets &lt;em&gt;that have the same column schema&lt;/em&gt;, and that alone has ended up being really hard to do.  Not even getting to mapping tables or anything like that yet.&lt;/p&gt;\n\n&lt;p&gt;My big, &lt;em&gt;core&lt;/em&gt; issue is that I can do queries, make transformation rules, but I can&amp;#39;t seem to find a way to edit/add data once I get it all in one place (got forbid I want to make the edits when I actually see the data on a powerBI dashboard)  Googling this has been hard (ex: googling edit source data returns results for editing data locations), and he educational materials I&amp;#39;ve found all seem to focus on big enterprise level data where the solution is not to have any manual editing at all.&lt;/p&gt;\n\n&lt;p&gt;Case in point:  Categorizing expenses from venmo (which only lets you download one month at a time).  I can query the sheets.  In old-school excel, I&amp;#39;d copy all the rows together, sort by vendor, and then manually batch categorize.  It&amp;#39;s take me ten minutes tops, and then I&amp;#39;d use that as a sort of &amp;#39;silver&amp;#39; data set to import in to my final dataset.  Now, I can query the individual sheets via power query (venmo only lets you download a month at a time), but adding categorization or deciding to remove a row seems impossible.  Right now it seems like the only thing I could do is write a python script, or go super manual any time I want to merge some data and copy&amp;amp;paste individual rows from many different sheets.  I&amp;#39;d love to streamline and utilize the new stuff, but it seems like the more manual side of data cleaning has to happen alllll the way down at the raw source and that kinda sucks when you have similar data across twenty different sources, or want to add data (like a category) at a higher level.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Sorry for the long post.  I fully expect that the real problem is I&amp;#39;m just thinking about things too old-school somehow and need to do somehow change my paradigm with all of this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10rzsbj", "is_robot_indexable": true, "report_reasons": null, "author": "pdxstolemyvan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10rzsbj/editing_source_data_in_modern_toolsets_especially/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10rzsbj/editing_source_data_in_modern_toolsets_especially/", "subreddit_subscribers": 844315, "created_utc": 1675369342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_uzoqx6k0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does the Support Vector Machine algorithm handle self-learning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ruyq4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675357697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ruyq4", "is_robot_indexable": true, "report_reasons": null, "author": "Haritha37", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ruyq4/how_does_the_support_vector_machine_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ruyq4/how_does_the_support_vector_machine_algorithm/", "subreddit_subscribers": 844315, "created_utc": 1675357697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_5fuisbcu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analysis using SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 60, "top_awarded_type": null, "hide_score": false, "name": "t3_10ruvd5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JJI5_J4OsIF404VJR5Nf2Z_YzIQRP90STP3q1OyiCHs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675357463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/p/4f9a1403cce8", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iMSm8MDbaS9npXmEDGxvbrTzTsJfKp_r_qAaW9k8jss.jpg?auto=webp&amp;v=enabled&amp;s=001f54fa5685ddf3821ce164f14969a8e5630745", "width": 710, "height": 305}, "resolutions": [{"url": "https://external-preview.redd.it/iMSm8MDbaS9npXmEDGxvbrTzTsJfKp_r_qAaW9k8jss.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ccafee2309b9b50d07bbc0be3b86d26570dcf9e", "width": 108, "height": 46}, {"url": "https://external-preview.redd.it/iMSm8MDbaS9npXmEDGxvbrTzTsJfKp_r_qAaW9k8jss.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e717bf17f70d49c6f4e5a5c0432e76c20dc53272", "width": 216, "height": 92}, {"url": "https://external-preview.redd.it/iMSm8MDbaS9npXmEDGxvbrTzTsJfKp_r_qAaW9k8jss.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8cc8894695d1b1893c60b1c2f201c11688af330", "width": 320, "height": 137}, {"url": "https://external-preview.redd.it/iMSm8MDbaS9npXmEDGxvbrTzTsJfKp_r_qAaW9k8jss.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=927e1b6ba5016ed7be7d44e6a282db309b4a9d50", "width": 640, "height": 274}], "variants": {}, "id": "NrWtgsDbL0-9mrcUrXxmnWP4OK6owdtE7PsND7CNsTk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ruvd5", "is_robot_indexable": true, "report_reasons": null, "author": "Friendly-Chemist4773", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ruvd5/data_analysis_using_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/p/4f9a1403cce8", "subreddit_subscribers": 844315, "created_utc": 1675357463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\ni have been given a problem statement for a certain dataset . \n\n\" analyzing the various core industries and GROUP the business categories like Retail, Poultry,\n\nAgriculture, Manufacturing etc  \"\n\ni dont know WHAT TO DO or where to start", "author_fullname": "t2_ref7gqwu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP group by columns", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10s529r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675382030.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have been given a problem statement for a certain dataset . &lt;/p&gt;\n\n&lt;p&gt;&amp;quot; analyzing the various core industries and GROUP the business categories like Retail, Poultry,&lt;/p&gt;\n\n&lt;p&gt;Agriculture, Manufacturing etc  &amp;quot;&lt;/p&gt;\n\n&lt;p&gt;i dont know WHAT TO DO or where to start&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10s529r", "is_robot_indexable": true, "report_reasons": null, "author": "New-Row-7664", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10s529r/nlp_group_by_columns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10s529r/nlp_group_by_columns/", "subreddit_subscribers": 844315, "created_utc": 1675382030.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Has anyone gained a certificate from this program? \n\nWhat are your thoughts?\n\nIn anyone\u2019s opinion; is this certificate valuable enough to gain employment?", "author_fullname": "t2_5qv0ouw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MIT Professional Education Applied Data Science Program Certificate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10s0t7m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675371797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone gained a certificate from this program? &lt;/p&gt;\n\n&lt;p&gt;What are your thoughts?&lt;/p&gt;\n\n&lt;p&gt;In anyone\u2019s opinion; is this certificate valuable enough to gain employment?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10s0t7m", "is_robot_indexable": true, "report_reasons": null, "author": "OppositeOwn5734", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10s0t7m/mit_professional_education_applied_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10s0t7m/mit_professional_education_applied_data_science/", "subreddit_subscribers": 844315, "created_utc": 1675371797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Building some context. \nI have an MIS degree. Worked as a data analyst at two different companies, adding up to 3 years. \nJust completing my first year as a Software Engineer focused on a Data pipeline features. \nI am very comfortable with Python, object oriented programming and even have a few DS projects on my resume. \n\nThe last couple of years have been miserable for me and I'm mentally exhausted.\n \nI'm looking for a way to get out of my current job. It isn't the best place to be for a variety of reasons. Been interviewing for DE, Analytics Engineer roles for a couple of months, but haven't gotten too far. DS has been a field of interest for me but I never got any calls because of lack of relevant experience. \n \n1. With some experience as a SWE, do I have better odds getting hired as a DS/MLE?\n\n2. How do I approach the job applications? Please suggest any projects/skills that will get my resume some traction for these roles? \n\nI'm feeling severely hopeless, please be kind. Thank you!", "author_fullname": "t2_8wthcj3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding my first job as a data scientist.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10rz2bl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675367613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Building some context. \nI have an MIS degree. Worked as a data analyst at two different companies, adding up to 3 years. \nJust completing my first year as a Software Engineer focused on a Data pipeline features. \nI am very comfortable with Python, object oriented programming and even have a few DS projects on my resume. &lt;/p&gt;\n\n&lt;p&gt;The last couple of years have been miserable for me and I&amp;#39;m mentally exhausted.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a way to get out of my current job. It isn&amp;#39;t the best place to be for a variety of reasons. Been interviewing for DE, Analytics Engineer roles for a couple of months, but haven&amp;#39;t gotten too far. DS has been a field of interest for me but I never got any calls because of lack of relevant experience. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;With some experience as a SWE, do I have better odds getting hired as a DS/MLE?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do I approach the job applications? Please suggest any projects/skills that will get my resume some traction for these roles? &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m feeling severely hopeless, please be kind. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10rz2bl", "is_robot_indexable": true, "report_reasons": null, "author": "PLTR60", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10rz2bl/finding_my_first_job_as_a_data_scientist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10rz2bl/finding_my_first_job_as_a_data_scientist/", "subreddit_subscribers": 844315, "created_utc": 1675367613.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}