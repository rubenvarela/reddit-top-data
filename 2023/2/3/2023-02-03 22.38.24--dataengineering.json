{"kind": "Listing", "data": {"after": "t3_10s83x0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been refactoring some code lately from using Pandas to Polars and I'm just blown away by the speed increases on locally run tasks (I'm running python 3.11.1 too which probably helps a wee bit as well).\n\nI'm yet to employ it for work but it looks like the perfect library for AWS Lambdas or GCP Cloud Functions where billing is by the millisecond.\n\nI've also noticed that Polars is much more similar to PySpark than Pandas with some of the naming conventions, lazy execution function-chaining etc, and can't help but think that's the benchmark or 'target' for lack of a better term.\n\nThe documentation is really coming together well and I'm just looking for stories or experiences of polars being used by DE's in industry.\n\nI think it's incredible but of course, in our game adoption is everything.", "author_fullname": "t2_so5msnka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Polars over Pandas or PySpark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10seqay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675410773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been refactoring some code lately from using Pandas to Polars and I&amp;#39;m just blown away by the speed increases on locally run tasks (I&amp;#39;m running python 3.11.1 too which probably helps a wee bit as well).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m yet to employ it for work but it looks like the perfect library for AWS Lambdas or GCP Cloud Functions where billing is by the millisecond.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also noticed that Polars is much more similar to PySpark than Pandas with some of the naming conventions, lazy execution function-chaining etc, and can&amp;#39;t help but think that&amp;#39;s the benchmark or &amp;#39;target&amp;#39; for lack of a better term.&lt;/p&gt;\n\n&lt;p&gt;The documentation is really coming together well and I&amp;#39;m just looking for stories or experiences of polars being used by DE&amp;#39;s in industry.&lt;/p&gt;\n\n&lt;p&gt;I think it&amp;#39;s incredible but of course, in our game adoption is everything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10seqay", "is_robot_indexable": true, "report_reasons": null, "author": "Playful_Rate31", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10seqay/using_polars_over_pandas_or_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10seqay/using_polars_over_pandas_or_pyspark/", "subreddit_subscribers": 88376, "created_utc": 1675410773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I thought this one from Dropbox was a good walk though of how they evaluated Superset as their data exploration tool. \n\nhttps://dropbox.tech/application/why-we-chose-apache-superset-as-our-data-exploration-platform\n\nAnyone have an article or post you thought was really good?", "author_fullname": "t2_2tu8n7l9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have an article or post you thought was really good?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10s9ir1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675394066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I thought this one from Dropbox was a good walk though of how they evaluated Superset as their data exploration tool. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://dropbox.tech/application/why-we-chose-apache-superset-as-our-data-exploration-platform\"&gt;https://dropbox.tech/application/why-we-chose-apache-superset-as-our-data-exploration-platform&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Anyone have an article or post you thought was really good?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ftQFWS0urYS6RnM3uIPiErgAPYfGcbEEtYxnlyr5nLM.jpg?auto=webp&amp;v=enabled&amp;s=d88046b1c10e917ce9328e8176942abaff8fbd1e", "width": 2400, "height": 1256}, "resolutions": [{"url": "https://external-preview.redd.it/ftQFWS0urYS6RnM3uIPiErgAPYfGcbEEtYxnlyr5nLM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2923738749d6e021106bd6297e54288d209f19d4", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ftQFWS0urYS6RnM3uIPiErgAPYfGcbEEtYxnlyr5nLM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e640e9f4233fffafecb3fa8c7aac10cb5c88ea9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ftQFWS0urYS6RnM3uIPiErgAPYfGcbEEtYxnlyr5nLM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c60ee671e0633f2f725299b96b8b4e3e7b95303", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/ftQFWS0urYS6RnM3uIPiErgAPYfGcbEEtYxnlyr5nLM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65d8d1f28c8dd19c21a10eab0dc66a9167a70010", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/ftQFWS0urYS6RnM3uIPiErgAPYfGcbEEtYxnlyr5nLM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96a61c1d89c3718a83dee5cafe231555d900c667", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/ftQFWS0urYS6RnM3uIPiErgAPYfGcbEEtYxnlyr5nLM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45b24c5ad94ffb4446ae48a9625121e2796cc820", "width": 1080, "height": 565}], "variants": {}, "id": "KHAUyVrz367ReJixlZWl-U3AAADJorWInyAjksLb74k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10s9ir1", "is_robot_indexable": true, "report_reasons": null, "author": "Firm_Bit", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10s9ir1/anyone_have_an_article_or_post_you_thought_was/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10s9ir1/anyone_have_an_article_or_post_you_thought_was/", "subreddit_subscribers": 88376, "created_utc": 1675394066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently in the middle of evaluating if our team should make the jump and migrate to non-Airflow -- primarily Dagster or Prefect. At this point, the main thing that would convince me that we *need* to switch would be if there are realistic use cases where Airflow simply would fail. Things like: complex dependency structures or ML pipelines, where e.g. thinking in terms of \"data assets\" (dagster) etc. literally enable you to do something that you couldn't reasonably do in Airflow. \n\nMy goal: future-proof our orchestrator as the team (and company) grows. I want to be confident that we can support such tasks when the time comes. \n\nSo -- have you ever hit a reasonable instance where you actually couldn't support what you wanted to support in Airflow? Can you offer a concrete example? My intuition and research suggests that although some things might be easier in or better suited for Dagster/Prefect, I should be able to get the same stuff done in Airflow in the end.", "author_fullname": "t2_7ifq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there job/task structure that Airflow CANNOT support, but competitors (dagster, prefect) can?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10s79ht", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675387805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently in the middle of evaluating if our team should make the jump and migrate to non-Airflow -- primarily Dagster or Prefect. At this point, the main thing that would convince me that we &lt;em&gt;need&lt;/em&gt; to switch would be if there are realistic use cases where Airflow simply would fail. Things like: complex dependency structures or ML pipelines, where e.g. thinking in terms of &amp;quot;data assets&amp;quot; (dagster) etc. literally enable you to do something that you couldn&amp;#39;t reasonably do in Airflow. &lt;/p&gt;\n\n&lt;p&gt;My goal: future-proof our orchestrator as the team (and company) grows. I want to be confident that we can support such tasks when the time comes. &lt;/p&gt;\n\n&lt;p&gt;So -- have you ever hit a reasonable instance where you actually couldn&amp;#39;t support what you wanted to support in Airflow? Can you offer a concrete example? My intuition and research suggests that although some things might be easier in or better suited for Dagster/Prefect, I should be able to get the same stuff done in Airflow in the end.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10s79ht", "is_robot_indexable": true, "report_reasons": null, "author": "cjr605", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10s79ht/is_there_jobtask_structure_that_airflow_cannot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10s79ht/is_there_jobtask_structure_that_airflow_cannot/", "subreddit_subscribers": 88376, "created_utc": 1675387805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone work for a hedge fund/Quant firm or has interviewed for DE positions?\n\nI've had a look at some job specs and I haven't seen anything out of the ordinary: Python, SQL, some cloud, Kafka, Spark, Kubernetes, Docker. Some of them mention C++/Rust/Java as additional languages - fair enough.\n\nDo these roles usually require financial markets knowledge? Do they care much about specific degrees and target schools for experienced hires (5 yoe so it's too late anyway).\n\nWhat does the interview process look like? Is it a lot of DSA and Leetcode or focused on SQL and systems design?\n\nIs there anything in particular I could do to make my CV stand out? Any additional technologies I should pick up that you wouldn't use in other DE roles?", "author_fullname": "t2_vsf3ige5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer at hedge funds/Quant firms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10sivgs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675426368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone work for a hedge fund/Quant firm or has interviewed for DE positions?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had a look at some job specs and I haven&amp;#39;t seen anything out of the ordinary: Python, SQL, some cloud, Kafka, Spark, Kubernetes, Docker. Some of them mention C++/Rust/Java as additional languages - fair enough.&lt;/p&gt;\n\n&lt;p&gt;Do these roles usually require financial markets knowledge? Do they care much about specific degrees and target schools for experienced hires (5 yoe so it&amp;#39;s too late anyway).&lt;/p&gt;\n\n&lt;p&gt;What does the interview process look like? Is it a lot of DSA and Leetcode or focused on SQL and systems design?&lt;/p&gt;\n\n&lt;p&gt;Is there anything in particular I could do to make my CV stand out? Any additional technologies I should pick up that you wouldn&amp;#39;t use in other DE roles?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10sivgs", "is_robot_indexable": true, "report_reasons": null, "author": "Agitated_Ad_1108", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10sivgs/data_engineer_at_hedge_fundsquant_firms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10sivgs/data_engineer_at_hedge_fundsquant_firms/", "subreddit_subscribers": 88376, "created_utc": 1675426368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nWe are looking for a solution or tool that allows a data exploration in a real time scenario. \n\nWe have some streaming processes (Kafka ecosystem) that generate final data. This data must be consumed by BI staff in real time. Monitoring tasks but with some freedom to choose what data should be presented.\n\nFor now, we are surviving with NiFi + postgresql + PowerBI.\n\n&amp;#x200B;\n\nBut what new or better options are there for this? \n\nI throw some options: Superset? Elastic+Kibana? others?\n\nThanks in advance.", "author_fullname": "t2_83c4agcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming data exploration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10skpl2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675432067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;We are looking for a solution or tool that allows a data exploration in a real time scenario. &lt;/p&gt;\n\n&lt;p&gt;We have some streaming processes (Kafka ecosystem) that generate final data. This data must be consumed by BI staff in real time. Monitoring tasks but with some freedom to choose what data should be presented.&lt;/p&gt;\n\n&lt;p&gt;For now, we are surviving with NiFi + postgresql + PowerBI.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But what new or better options are there for this? &lt;/p&gt;\n\n&lt;p&gt;I throw some options: Superset? Elastic+Kibana? others?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10skpl2", "is_robot_indexable": true, "report_reasons": null, "author": "jscrls", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10skpl2/streaming_data_exploration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10skpl2/streaming_data_exploration/", "subreddit_subscribers": 88376, "created_utc": 1675432067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started working on a distributed task queue library a few months back. The library is available as a python package to install a start using : [daskqueue - pypi package](https://pypi.org/project/daskqueue/)\n\nFor all its greatness, Dask implements a central scheduler (basically a simple tornado event loop) involved in every decision, which can sometimes create a central bottleneck. **This is a pretty serious limitation when trying to use Dask in high-throughput situations**.\n\nDaskqueue is a small python library built on top of Dask and Dask Distributed that implements a very lightweight **Distributed Task Queue.** Daskqueue also implements persistent queues for holding tasks on disk and surviving Dask cluster restart.\n\nI also wrote an article about implementation details: [https://medium.com/@aminedirhoussi1/daskqueue-dask-based-distributed-task-queue-6fb95517dfea](https://medium.com/@aminedirhoussi1/daskqueue-dask-based-distributed-task-queue-6fb95517dfea)\n\n&amp;#x200B;\n\nHope you enjoy it, can't wait to hear about your feedback :) !", "author_fullname": "t2_zga5i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Daskqueue: Dask-based distributed task queue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10sqxhh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675447731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started working on a distributed task queue library a few months back. The library is available as a python package to install a start using : &lt;a href=\"https://pypi.org/project/daskqueue/\"&gt;daskqueue - pypi package&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For all its greatness, Dask implements a central scheduler (basically a simple tornado event loop) involved in every decision, which can sometimes create a central bottleneck. &lt;strong&gt;This is a pretty serious limitation when trying to use Dask in high-throughput situations&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Daskqueue is a small python library built on top of Dask and Dask Distributed that implements a very lightweight &lt;strong&gt;Distributed Task Queue.&lt;/strong&gt; Daskqueue also implements persistent queues for holding tasks on disk and surviving Dask cluster restart.&lt;/p&gt;\n\n&lt;p&gt;I also wrote an article about implementation details: &lt;a href=\"https://medium.com/@aminedirhoussi1/daskqueue-dask-based-distributed-task-queue-6fb95517dfea\"&gt;https://medium.com/@aminedirhoussi1/daskqueue-dask-based-distributed-task-queue-6fb95517dfea&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hope you enjoy it, can&amp;#39;t wait to hear about your feedback :) !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?auto=webp&amp;v=enabled&amp;s=f0cc8dce4c4d114433073f7ec64bf299623fcef9", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b8865fd719f17e774b2178948603d0c4bfb2673", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/0kryPnq0tdgIBps0GUhMZoZ9rxHjvu2Jd-BPJ8vovPA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7f78455787f3622b85aa8394a3ee4b6f14e35c1", "width": 216, "height": 216}], "variants": {}, "id": "IUHM4ctLZQorzkPuYJ4IkGSag8BtaIqZoyqL1L53KuM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "10sqxhh", "is_robot_indexable": true, "report_reasons": null, "author": "amindiro", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10sqxhh/daskqueue_daskbased_distributed_task_queue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10sqxhh/daskqueue_daskbased_distributed_task_queue/", "subreddit_subscribers": 88376, "created_utc": 1675447731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any (open-source) alternative to the \"old-school\" JupyterHub? I am aware of e.g. Deepnote but that's not really open source. Also found not exactly alternative but pretty similar thing - Querybook.\n\nIt would be nice to have \"nicer\" JupyterHub ideally with better options to work with Database (some SQL editor/browser) , to share the notebooks with others and also to be able to spawn notebook servers with parametrizable resources.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Better JupyterHub?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10soo5g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675442193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any (open-source) alternative to the &amp;quot;old-school&amp;quot; JupyterHub? I am aware of e.g. Deepnote but that&amp;#39;s not really open source. Also found not exactly alternative but pretty similar thing - Querybook.&lt;/p&gt;\n\n&lt;p&gt;It would be nice to have &amp;quot;nicer&amp;quot; JupyterHub ideally with better options to work with Database (some SQL editor/browser) , to share the notebooks with others and also to be able to spawn notebook servers with parametrizable resources.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10soo5g", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10soo5g/better_jupyterhub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10soo5g/better_jupyterhub/", "subreddit_subscribers": 88376, "created_utc": 1675442193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m going to do masters in US. I have 4 years experience with 3 years as a data engineer. \n\n\nCould you guys share what type of questions are asked in interviews in US companies for DE roles?\nAlso what are the skills which are mainly helping you in your current job?\nYour experiences and any tips for me to clear some crucial topics. I wanna do some kickass work there, so want to be prepared my best.\n\nHave a great day guys!", "author_fullname": "t2_ajjg3i2t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insights about US tech market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10sn3jc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675438307.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m going to do masters in US. I have 4 years experience with 3 years as a data engineer. &lt;/p&gt;\n\n&lt;p&gt;Could you guys share what type of questions are asked in interviews in US companies for DE roles?\nAlso what are the skills which are mainly helping you in your current job?\nYour experiences and any tips for me to clear some crucial topics. I wanna do some kickass work there, so want to be prepared my best.&lt;/p&gt;\n\n&lt;p&gt;Have a great day guys!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10sn3jc", "is_robot_indexable": true, "report_reasons": null, "author": "MediumZealousideal29", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10sn3jc/insights_about_us_tech_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10sn3jc/insights_about_us_tech_market/", "subreddit_subscribers": 88376, "created_utc": 1675438307.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\nWorking in a company that deploys data science pipelines for several customers I often find myself working on quite heterogenous stacks to do what in the end Is a conceptually simple thing. This most often happens for smaller projects having simple tasks.\n\nAre you used to visual data processing/pipelining tools? I am assuming the UI may facilitate the High level understanding of the projects, while a managed infra tends to do the job well in simple scenario. I am also scared of the learning curve, rigidity and lock ins of such solutions, so reality want to here your thoughts. I have heard of AWS data wrangler, KNIME and data haiku so far.\n\nA sample scenario: get a batch of data from a database, another from from a datalake, join them, fitpredict, save predictions and save to a third db. The typical volume of data is small (megabytes) and the scheduling frequencies quite low.\n\n\n\nP.s. Hope It Is the right community - the topic Is a bit crossdisciplinary", "author_fullname": "t2_5w9jnbsn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Visual data pipelining tools - KNIME datahaiku and competitors", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10slgyi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675434068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,\nWorking in a company that deploys data science pipelines for several customers I often find myself working on quite heterogenous stacks to do what in the end Is a conceptually simple thing. This most often happens for smaller projects having simple tasks.&lt;/p&gt;\n\n&lt;p&gt;Are you used to visual data processing/pipelining tools? I am assuming the UI may facilitate the High level understanding of the projects, while a managed infra tends to do the job well in simple scenario. I am also scared of the learning curve, rigidity and lock ins of such solutions, so reality want to here your thoughts. I have heard of AWS data wrangler, KNIME and data haiku so far.&lt;/p&gt;\n\n&lt;p&gt;A sample scenario: get a batch of data from a database, another from from a datalake, join them, fitpredict, save predictions and save to a third db. The typical volume of data is small (megabytes) and the scheduling frequencies quite low.&lt;/p&gt;\n\n&lt;p&gt;P.s. Hope It Is the right community - the topic Is a bit crossdisciplinary&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10slgyi", "is_robot_indexable": true, "report_reasons": null, "author": "BenXavier", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10slgyi/visual_data_pipelining_tools_knime_datahaiku_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10slgyi/visual_data_pipelining_tools_knime_datahaiku_and/", "subreddit_subscribers": 88376, "created_utc": 1675434068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a Platform DE on a customer-facing data product. Our pipeline is basically Confluent Kafka -&gt; Databricks -&gt; DBT -&gt; BI (embedded in our application). We have separate dev, test, and prod environments in all tools, and we use blue/green deployments for releases. This is just to give QA and Product time to check that the data is looking good before cutting over.\n\nWe've really been struggling with aligning our \"backend\" (Databricks/DBT) and \"frontend\" (BI) releases. The backend portion of our releases has been relatively smooth because we can more or less automate our tests, use version control, etc. \n\nThe frontend portion of our releases has been really painful for a few main reasons:\n\n* Inability to feature flag or cherry-pick features in BI (we have to copy our whole stage space to off-color prod when we deploy, which blocks any changes in stage until release and makes it so if anything doesn't pass QA or acceptance testing, it has to be manually removed from stage prior to copy)\n* Inability to automate tests for BI -- we currently do a lot of manual checking of pages to ensure the embedded reports are funcitonal after copying BI from stage to prod and building the data\n\nDo you sync up your frontend and backend releases? Do you stagger them? Do you have a process for managing changes in a shitty BI tool that doesn't allow for you to version control it in any way?", "author_fullname": "t2_n0d7a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your team coordinate backend and frontend releases when using a BI tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10sbwrd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675401140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a Platform DE on a customer-facing data product. Our pipeline is basically Confluent Kafka -&amp;gt; Databricks -&amp;gt; DBT -&amp;gt; BI (embedded in our application). We have separate dev, test, and prod environments in all tools, and we use blue/green deployments for releases. This is just to give QA and Product time to check that the data is looking good before cutting over.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve really been struggling with aligning our &amp;quot;backend&amp;quot; (Databricks/DBT) and &amp;quot;frontend&amp;quot; (BI) releases. The backend portion of our releases has been relatively smooth because we can more or less automate our tests, use version control, etc. &lt;/p&gt;\n\n&lt;p&gt;The frontend portion of our releases has been really painful for a few main reasons:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Inability to feature flag or cherry-pick features in BI (we have to copy our whole stage space to off-color prod when we deploy, which blocks any changes in stage until release and makes it so if anything doesn&amp;#39;t pass QA or acceptance testing, it has to be manually removed from stage prior to copy)&lt;/li&gt;\n&lt;li&gt;Inability to automate tests for BI -- we currently do a lot of manual checking of pages to ensure the embedded reports are funcitonal after copying BI from stage to prod and building the data&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Do you sync up your frontend and backend releases? Do you stagger them? Do you have a process for managing changes in a shitty BI tool that doesn&amp;#39;t allow for you to version control it in any way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10sbwrd", "is_robot_indexable": true, "report_reasons": null, "author": "aormiston", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10sbwrd/how_does_your_team_coordinate_backend_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10sbwrd/how_does_your_team_coordinate_backend_and/", "subreddit_subscribers": 88376, "created_utc": 1675401140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any SQL editor/database browser (something like pgAdmin/MySQL workbench/Adminer) that could be hosted as a \"server\" using e.g. docker container and can connect to Trino? I found only SQLPad which is apparently deprecated.\n\nEdit: not BI tool please", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hostable SQL editor with Trino support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10soq7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675445669.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675442341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any SQL editor/database browser (something like pgAdmin/MySQL workbench/Adminer) that could be hosted as a &amp;quot;server&amp;quot; using e.g. docker container and can connect to Trino? I found only SQLPad which is apparently deprecated.&lt;/p&gt;\n\n&lt;p&gt;Edit: not BI tool please&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10soq7b", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10soq7b/hostable_sql_editor_with_trino_support/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10soq7b/hostable_sql_editor_with_trino_support/", "subreddit_subscribers": 88376, "created_utc": 1675442341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, I've created my resume in HTML and CSS. I know only the basics of front-end, but I think it looks pretty decent, but I am probably biased. Please review it and inform me if I should change something.\n\nThe pink color is for hyperlinks.\n\nhttps://preview.redd.it/kq7ci8h7yzfa1.jpg?width=1653&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8cb76df3c5f376dc0df51e2168bb3237b9a2457d", "author_fullname": "t2_99xm7vrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HTML + CSS resume", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"kq7ci8h7yzfa1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 152, "x": 108, "u": "https://preview.redd.it/kq7ci8h7yzfa1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=600125b76ed8d4fc203d6a32eaf66273e9484756"}, {"y": 305, "x": 216, "u": "https://preview.redd.it/kq7ci8h7yzfa1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ddbe97f3f420a1a68fa0a8d8d67bd681615aa74"}, {"y": 452, "x": 320, "u": "https://preview.redd.it/kq7ci8h7yzfa1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2c16c1940f4ce1e131de3dc63d27153fa629385"}, {"y": 905, "x": 640, "u": "https://preview.redd.it/kq7ci8h7yzfa1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a59e41cb4c6baeed4b7fee3e73a2ca0634a26d89"}, {"y": 1358, "x": 960, "u": "https://preview.redd.it/kq7ci8h7yzfa1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8f4f778052ebf12aa73838687d74a453701bd05"}, {"y": 1528, "x": 1080, "u": "https://preview.redd.it/kq7ci8h7yzfa1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a31423e096dfea17b55c01c3fde9129028c7a31a"}], "s": {"y": 2339, "x": 1653, "u": "https://preview.redd.it/kq7ci8h7yzfa1.jpg?width=1653&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8cb76df3c5f376dc0df51e2168bb3237b9a2457d"}, "id": "kq7ci8h7yzfa1"}}, "name": "t3_10snua0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Resume Review", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/tNH4FQZXD2bJgkWeqmzCV0eqCSqhYrOzl5W0S5Dbesc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675440174.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I&amp;#39;ve created my resume in HTML and CSS. I know only the basics of front-end, but I think it looks pretty decent, but I am probably biased. Please review it and inform me if I should change something.&lt;/p&gt;\n\n&lt;p&gt;The pink color is for hyperlinks.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/kq7ci8h7yzfa1.jpg?width=1653&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8cb76df3c5f376dc0df51e2168bb3237b9a2457d\"&gt;https://preview.redd.it/kq7ci8h7yzfa1.jpg?width=1653&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=8cb76df3c5f376dc0df51e2168bb3237b9a2457d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "47fd10c4-3440-11ed-99b0-ce1be0dd6276", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#007373", "id": "10snua0", "is_robot_indexable": true, "report_reasons": null, "author": "Brief_Priority_2193", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10snua0/html_css_resume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10snua0/html_css_resume/", "subreddit_subscribers": 88376, "created_utc": 1675440174.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im a college student, do portfolio matter for a fresh grad who want to pursue DE? I wanna pursue DE after college. i know basic-intermediate of python and sql period, i dont know what to do with my python and sql knowledge, do i have to make a DE portfolio for me to make it to the field after graduating? Or i still do have chance to enter DE after college without portfolio?\n\nI dont have enough time to make portfolio though i want to, because of my school sched. With my school sched im having a hard time to make a personal project. I am a graduating CS student without any personal project that's why im overthinking about the portfolio thing. Any advice/insight/tips?", "author_fullname": "t2_i8exxe4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "i dont know what to do next", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10sidkc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675424630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a college student, do portfolio matter for a fresh grad who want to pursue DE? I wanna pursue DE after college. i know basic-intermediate of python and sql period, i dont know what to do with my python and sql knowledge, do i have to make a DE portfolio for me to make it to the field after graduating? Or i still do have chance to enter DE after college without portfolio?&lt;/p&gt;\n\n&lt;p&gt;I dont have enough time to make portfolio though i want to, because of my school sched. With my school sched im having a hard time to make a personal project. I am a graduating CS student without any personal project that&amp;#39;s why im overthinking about the portfolio thing. Any advice/insight/tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10sidkc", "is_robot_indexable": true, "report_reasons": null, "author": "Initial-Routine4506", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10sidkc/i_dont_know_what_to_do_next/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10sidkc/i_dont_know_what_to_do_next/", "subreddit_subscribers": 88376, "created_utc": 1675424630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am learning more about Trino/Presto and am currently playing around with it on local Docker. Very early in the process but I have connected to my S3 bucket via the Glue catalog, a MySQL database, and Google Sheets.  I have a question about materializing data in terms of functionality as well as best practice architecture. I may be looking at this the wrong way so please correct my assumptions.\n\nIf I have a query that joins tables from all three data sources, I believe I have the capability to create a table in certain catalogs (like Glue/Hive). If executed, is this table written to the storage location? Trying to understand the difference between a Trino table vs view vs materialized view. The comparison I am making is to two architectures I use today: Snowflake and Dremio. Snowflake is like a typical structured database but Dremio processes it's datasets as views in memory with the option to materialize datasets using its Reflections feature. Dremio can also CTAS to locations on object storage as parquet (and iceberg).\n\nHow does Trino relate to this? For my use case, doing everything like a view is satisfactory in terms of performance. But if I am working in an enterprise trying to use Trino for ETL processes, I am assuming that there is functionality to materialize data at some point? Or is that not a best practice/the right use case for Trino? I am also relating it to some of Starburst's (enterprise Trino) marketing, which has ETL data processing as a use case.", "author_fullname": "t2_ywrol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trino/Presto materialization and storing query results", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10suc08", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675456471.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675456121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning more about Trino/Presto and am currently playing around with it on local Docker. Very early in the process but I have connected to my S3 bucket via the Glue catalog, a MySQL database, and Google Sheets.  I have a question about materializing data in terms of functionality as well as best practice architecture. I may be looking at this the wrong way so please correct my assumptions.&lt;/p&gt;\n\n&lt;p&gt;If I have a query that joins tables from all three data sources, I believe I have the capability to create a table in certain catalogs (like Glue/Hive). If executed, is this table written to the storage location? Trying to understand the difference between a Trino table vs view vs materialized view. The comparison I am making is to two architectures I use today: Snowflake and Dremio. Snowflake is like a typical structured database but Dremio processes it&amp;#39;s datasets as views in memory with the option to materialize datasets using its Reflections feature. Dremio can also CTAS to locations on object storage as parquet (and iceberg).&lt;/p&gt;\n\n&lt;p&gt;How does Trino relate to this? For my use case, doing everything like a view is satisfactory in terms of performance. But if I am working in an enterprise trying to use Trino for ETL processes, I am assuming that there is functionality to materialize data at some point? Or is that not a best practice/the right use case for Trino? I am also relating it to some of Starburst&amp;#39;s (enterprise Trino) marketing, which has ETL data processing as a use case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10suc08", "is_robot_indexable": true, "report_reasons": null, "author": "DarkmoonDingo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10suc08/trinopresto_materialization_and_storing_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10suc08/trinopresto_materialization_and_storing_query/", "subreddit_subscribers": 88376, "created_utc": 1675456121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI am looking to break into data engineering and I am laying out a roadmap of tools to learn and be marketable for an entry level job.  All my learning is through courses on Udemy, after which I will build my own projects!\n\nThat being said, I feel I am going overboard and overlapping / not being consistent with my tech stack choices.  Really looking forward to your input on this learning roadmap (in order of learning first to last) below.\n\nPlease critique my order of learning (edit: they're all 1s after Reddit formatting - assume order of importance is descending from top to bottom of my list) or critique my tool/skill selections!\n\n1. The Basics\n- SQL, Python\n\n2. Visualization\n- PowerBI\n\n3. Data Warehouse\n- Snowflake\n\n4. Cloud Provider\n- Azure\n\n5. Version Control &amp; CI/CD\n- GitHub\n\n6. [Question] \n- Assuming I learn Snowflake and Azure Cloud, would I benefit more from simply learning a tool like Talend, OR should I try to learn Apache Kafka or Spark?\n\n 7. Containerization\n- Docker &amp; Kubernetes\n\n8. Scheduling\n- Airflow\n\n9. Transformation\n- dbt\n\nNOTE: I know next to nothing about any of these - I only know the foundations of data warehousing.\n\nIf anyone is interested in being a short-term mentor (compensated) on data engineering and this stack, please hmu in my chat!\n\nThanks in advance", "author_fullname": "t2_iohcck8w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which of these tools compliment each other? + Looking for a mentor", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ssko0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675451794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I am looking to break into data engineering and I am laying out a roadmap of tools to learn and be marketable for an entry level job.  All my learning is through courses on Udemy, after which I will build my own projects!&lt;/p&gt;\n\n&lt;p&gt;That being said, I feel I am going overboard and overlapping / not being consistent with my tech stack choices.  Really looking forward to your input on this learning roadmap (in order of learning first to last) below.&lt;/p&gt;\n\n&lt;p&gt;Please critique my order of learning (edit: they&amp;#39;re all 1s after Reddit formatting - assume order of importance is descending from top to bottom of my list) or critique my tool/skill selections!&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The Basics&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;SQL, Python&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Visualization&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;PowerBI&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data Warehouse&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Snowflake&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Cloud Provider&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Azure&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Version Control &amp;amp; CI/CD&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;GitHub&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;[Question] &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Assuming I learn Snowflake and Azure Cloud, would I benefit more from simply learning a tool like Talend, OR should I try to learn Apache Kafka or Spark?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Containerization&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Docker &amp;amp; Kubernetes&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Scheduling&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Airflow&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Transformation&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;dbt&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;NOTE: I know next to nothing about any of these - I only know the foundations of data warehousing.&lt;/p&gt;\n\n&lt;p&gt;If anyone is interested in being a short-term mentor (compensated) on data engineering and this stack, please hmu in my chat!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ssko0", "is_robot_indexable": true, "report_reasons": null, "author": "LieutenantDaredevil", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ssko0/which_of_these_tools_compliment_each_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ssko0/which_of_these_tools_compliment_each_other/", "subreddit_subscribers": 88376, "created_utc": 1675451794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all!\n\nI'm currently a data analyst (\\~1.5y) looking to transition into a data engineering role. I've had my current role since I have graduated (with a business degree) so I do not have an experience creating a resume for a tech based role. \n\nMy main questions are:  \n1) I understand that stating your tech stack is the most important in a resume. How exactly do I display that I have experience with a specific tech stack, but am not the best in it? E.g. I learned about docker/spark/airflow through a bootcamp but I'm obviously not the most well-versed at it. Do I state something along the lines of airflow(basic competency) ?  \n2) How important is it to have an online resume? I've been seeing people create their own 'resume/portfolio' on websites and having it linked on their actual resume/linkedin.\n\n(Please feel free to pm me as well. I am looking for people who can provide me additional advise on my transition, thank you!)", "author_fullname": "t2_cpluh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to creating tech-based resume. Need some help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10slb85", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675433656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently a data analyst (~1.5y) looking to transition into a data engineering role. I&amp;#39;ve had my current role since I have graduated (with a business degree) so I do not have an experience creating a resume for a tech based role. &lt;/p&gt;\n\n&lt;p&gt;My main questions are:&lt;br/&gt;\n1) I understand that stating your tech stack is the most important in a resume. How exactly do I display that I have experience with a specific tech stack, but am not the best in it? E.g. I learned about docker/spark/airflow through a bootcamp but I&amp;#39;m obviously not the most well-versed at it. Do I state something along the lines of airflow(basic competency) ?&lt;br/&gt;\n2) How important is it to have an online resume? I&amp;#39;ve been seeing people create their own &amp;#39;resume/portfolio&amp;#39; on websites and having it linked on their actual resume/linkedin.&lt;/p&gt;\n\n&lt;p&gt;(Please feel free to pm me as well. I am looking for people who can provide me additional advise on my transition, thank you!)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10slb85", "is_robot_indexable": true, "report_reasons": null, "author": "Slideout", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10slb85/new_to_creating_techbased_resume_need_some_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10slb85/new_to_creating_techbased_resume_need_some_help/", "subreddit_subscribers": 88376, "created_utc": 1675433656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For every company I worked for (3 of them), the data team managed to pull out a certain yaml/jinja based \"solution\" to wrap up Airflow. So basically developers write yaml instead of Python. But why? Everytime I had to learn a new syntax, and not everytime the \"solution\" has all functionalities we want. The guy who made it had a lot of fun for sure, but everyone else is not having fun. Why can't they just let people write Python?\n\nSure the reason might be -- oh BI developers don't want to learn Python or don't have best practices. Well the first reason doesn't hold up because they do (and do write in another repo), and the second reason...well I assume your yaml based solution has the best practices then?\n\nI'm not even going to complain how little documentation each one has. One company managed to invent a second suite of wrappers when I was there, Jesus...\n\nSincerely, I'd like to know why. I don't really see any benefit. I mean whatever your \"syntax\" can do, Airflow can do that too. I don't see man, I don't really see.", "author_fullname": "t2_bmsha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why do people re-invent wrappers for Airflow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10svt5y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675459675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For every company I worked for (3 of them), the data team managed to pull out a certain yaml/jinja based &amp;quot;solution&amp;quot; to wrap up Airflow. So basically developers write yaml instead of Python. But why? Everytime I had to learn a new syntax, and not everytime the &amp;quot;solution&amp;quot; has all functionalities we want. The guy who made it had a lot of fun for sure, but everyone else is not having fun. Why can&amp;#39;t they just let people write Python?&lt;/p&gt;\n\n&lt;p&gt;Sure the reason might be -- oh BI developers don&amp;#39;t want to learn Python or don&amp;#39;t have best practices. Well the first reason doesn&amp;#39;t hold up because they do (and do write in another repo), and the second reason...well I assume your yaml based solution has the best practices then?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not even going to complain how little documentation each one has. One company managed to invent a second suite of wrappers when I was there, Jesus...&lt;/p&gt;\n\n&lt;p&gt;Sincerely, I&amp;#39;d like to know why. I don&amp;#39;t really see any benefit. I mean whatever your &amp;quot;syntax&amp;quot; can do, Airflow can do that too. I don&amp;#39;t see man, I don&amp;#39;t really see.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10svt5y", "is_robot_indexable": true, "report_reasons": null, "author": "levelworm", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10svt5y/why_do_people_reinvent_wrappers_for_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10svt5y/why_do_people_reinvent_wrappers_for_airflow/", "subreddit_subscribers": 88376, "created_utc": 1675459675.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nMy use case is I will have oracle dump file in S3 and I will need to select some tables from the dump file and store it back to s3 and then transform and back to s3 then read using Athena\n\nI will get the dump file weekly and each time it will have full data and not incremental load.\n\nI am planning to use Oracle RDS instance to load data selectively - only need few tables and not all of the tables, then store data back to s3 as csv/parquet for furter processing using Athena.\n\nSince, I do not need the RDS instance for any other activity until the next load and also because every load is a full load, I also plan to delete this instance / drop data and stop the instance (basically not be billed for it).\n\nSince I am only starting out with AWS and Data engineering as a whole, I know there are knowledge gaps here that need to be filled. Also I would appreciate if you could guide with an overall approach for the same.", "author_fullname": "t2_9rp533dt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pull data from Oracle dump file to S3 bucket", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ssdt8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675451325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My use case is I will have oracle dump file in S3 and I will need to select some tables from the dump file and store it back to s3 and then transform and back to s3 then read using Athena&lt;/p&gt;\n\n&lt;p&gt;I will get the dump file weekly and each time it will have full data and not incremental load.&lt;/p&gt;\n\n&lt;p&gt;I am planning to use Oracle RDS instance to load data selectively - only need few tables and not all of the tables, then store data back to s3 as csv/parquet for furter processing using Athena.&lt;/p&gt;\n\n&lt;p&gt;Since, I do not need the RDS instance for any other activity until the next load and also because every load is a full load, I also plan to delete this instance / drop data and stop the instance (basically not be billed for it).&lt;/p&gt;\n\n&lt;p&gt;Since I am only starting out with AWS and Data engineering as a whole, I know there are knowledge gaps here that need to be filled. Also I would appreciate if you could guide with an overall approach for the same.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ssdt8", "is_robot_indexable": true, "report_reasons": null, "author": "prasanna_aatma", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ssdt8/pull_data_from_oracle_dump_file_to_s3_bucket/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ssdt8/pull_data_from_oracle_dump_file_to_s3_bucket/", "subreddit_subscribers": 88376, "created_utc": 1675451325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello ,  \n\n\nWhat is the best way to read data from kafka and write to ES with higher throughput at around 200-300k messages per second. I want to explore real time dashboarding , hence asking", "author_fullname": "t2_sr3rc27q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "reading from kafka and pushing to elastic search?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10squa4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675447514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello ,  &lt;/p&gt;\n\n&lt;p&gt;What is the best way to read data from kafka and write to ES with higher throughput at around 200-300k messages per second. I want to explore real time dashboarding , hence asking&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10squa4", "is_robot_indexable": true, "report_reasons": null, "author": "honey12123", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10squa4/reading_from_kafka_and_pushing_to_elastic_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10squa4/reading_from_kafka_and_pushing_to_elastic_search/", "subreddit_subscribers": 88376, "created_utc": 1675447514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am working on a PowerBI report that consists of multiple dashboards. The data needed is from a single table with 100K rows of data in DWH . The table stores all the variables and values for different stores, as shown in the picture below.\n\nhttps://preview.redd.it/erq3lxzfkxfa1.png?width=571&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=471443e5e2305116a846457f5d6a3e2272a572a4\n\nCurrently, we are creating new table in data mart for each separate dashboard, such as total profit in each country, total number of staff in each country etc. However, I realize I can do the same using Power Query without adding new tables for my data mart. So I am curious which approach is better?\n\nAnd this leads to another question I always have, when we need a tranformed table for dashboard, shoud we create new tables in data mart, or should we do it in the BI tool such as PBI or Tableau? I think performance is a factor to be considered, but not sure about the other factors.\n\nAppreciate if anyone can share your opinion.", "author_fullname": "t2_5h4fly5z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I create new table in data mart or use Power Query for each new dashboard?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "media_metadata": {"erq3lxzfkxfa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 32, "x": 108, "u": "https://preview.redd.it/erq3lxzfkxfa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eac981cc6ca31e9ce197ac874a4ddec7c6e645a5"}, {"y": 64, "x": 216, "u": "https://preview.redd.it/erq3lxzfkxfa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c09584540e4c27d235beb80fa583cfab74ac7f2"}, {"y": 95, "x": 320, "u": "https://preview.redd.it/erq3lxzfkxfa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ec2c56545543e6f5aa54ad3819b81a5e382491a"}], "s": {"y": 171, "x": 571, "u": "https://preview.redd.it/erq3lxzfkxfa1.png?width=571&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=471443e5e2305116a846457f5d6a3e2272a572a4"}, "id": "erq3lxzfkxfa1"}}, "name": "t3_10sf39a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/a6xeIFf_6zzP1EhlzqKqzbbMF5EjTHiG_-tSduViA3o.jpg", "edited": 1675413040.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675412079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am working on a PowerBI report that consists of multiple dashboards. The data needed is from a single table with 100K rows of data in DWH . The table stores all the variables and values for different stores, as shown in the picture below.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/erq3lxzfkxfa1.png?width=571&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=471443e5e2305116a846457f5d6a3e2272a572a4\"&gt;https://preview.redd.it/erq3lxzfkxfa1.png?width=571&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=471443e5e2305116a846457f5d6a3e2272a572a4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Currently, we are creating new table in data mart for each separate dashboard, such as total profit in each country, total number of staff in each country etc. However, I realize I can do the same using Power Query without adding new tables for my data mart. So I am curious which approach is better?&lt;/p&gt;\n\n&lt;p&gt;And this leads to another question I always have, when we need a tranformed table for dashboard, shoud we create new tables in data mart, or should we do it in the BI tool such as PBI or Tableau? I think performance is a factor to be considered, but not sure about the other factors.&lt;/p&gt;\n\n&lt;p&gt;Appreciate if anyone can share your opinion.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10sf39a", "is_robot_indexable": true, "report_reasons": null, "author": "motttyy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10sf39a/should_i_create_new_table_in_data_mart_or_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10sf39a/should_i_create_new_table_in_data_mart_or_use/", "subreddit_subscribers": 88376, "created_utc": 1675412079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my first post at reddit. Hello everyone!\n\nI am a senior software engineer and have 12+ years of experience. I came to US before 3 years and working as a contractor. Initially I started as some development work in Data team at client side and eventually I got moved to data engineering work. \n\nIn this project I am using matillion ETL tool which is more like UI drag and drop. Initially I liked that work as I love data and have more WLB but now I miss my old programming days. I want to switch job now but since last 3 years I worked in data team it is hard to crack interview for software engineer role and no one will take me for senior data engineer. I see there are many tools in data engineering which is more on programming side. I am happy to learn that as well but I am directionless.\n\nI work for a contracting company right now so I am not earning much like product company. For better financial growth and career perspective I am not sure if I should go back to software engineering or I should learn more in data engineering and proceed in data only. One friend told me that salary for data engineer will be very low than software engineer.  Data science engineer will have more programming and better salary but they only hire phd person for that.\n\nLooks like I am stuck at this situation and need some guidance from fellow engineers.\n\nKindly share your opinion in this matter. Your any feedback will be greatly helpful.", "author_fullname": "t2_99nnwpys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advise - SSE or Data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10svsyd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675459660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my first post at reddit. Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I am a senior software engineer and have 12+ years of experience. I came to US before 3 years and working as a contractor. Initially I started as some development work in Data team at client side and eventually I got moved to data engineering work. &lt;/p&gt;\n\n&lt;p&gt;In this project I am using matillion ETL tool which is more like UI drag and drop. Initially I liked that work as I love data and have more WLB but now I miss my old programming days. I want to switch job now but since last 3 years I worked in data team it is hard to crack interview for software engineer role and no one will take me for senior data engineer. I see there are many tools in data engineering which is more on programming side. I am happy to learn that as well but I am directionless.&lt;/p&gt;\n\n&lt;p&gt;I work for a contracting company right now so I am not earning much like product company. For better financial growth and career perspective I am not sure if I should go back to software engineering or I should learn more in data engineering and proceed in data only. One friend told me that salary for data engineer will be very low than software engineer.  Data science engineer will have more programming and better salary but they only hire phd person for that.&lt;/p&gt;\n\n&lt;p&gt;Looks like I am stuck at this situation and need some guidance from fellow engineers.&lt;/p&gt;\n\n&lt;p&gt;Kindly share your opinion in this matter. Your any feedback will be greatly helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10svsyd", "is_robot_indexable": true, "report_reasons": null, "author": "seattleshawk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10svsyd/need_advise_sse_or_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10svsyd/need_advise_sse_or_data_engineering/", "subreddit_subscribers": 88376, "created_utc": 1675459660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Questions?", "author_fullname": "t2_u6wwqmo8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What insights are driven by standard deviations and variance and z score in real-life business decisions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10smhq2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675436778.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Questions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10smhq2", "is_robot_indexable": true, "report_reasons": null, "author": "PriyankaLanka", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10smhq2/what_insights_are_driven_by_standard_deviations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10smhq2/what_insights_are_driven_by_standard_deviations/", "subreddit_subscribers": 88376, "created_utc": 1675436778.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to learn some Metabase and Superset by exploring some public datasets. Ideally I would like to minimize the time spent downloading, cleaning and loading these datasets into Postgres (or whatever).\n\nSo, is there some docker-friendly webapp that will help me do that? I've seen OpenRefine but haven't used it - does it fit the bill?\n\nAt a previous job we used Dataiku DSS and it was great for this. You could load a csv (or mysqldump, I think), edit the column types and do quite some cleaning and transformations and then save it as a new table in the db. Yes there is a free version (that I'll likely end up using if I can't find anything else) but I would rather rely on open-source plus it is way overkill because it does so much more stuff.\n\nWhat would be REALLY cool, if is such an app existed that already had a list of public datasets availalble, so I can just search and load them directly within app", "author_fullname": "t2_lhyqnuxf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-hosted no-code data prep tool? Maybe OpenRefine?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10slv07", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675435122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to learn some Metabase and Superset by exploring some public datasets. Ideally I would like to minimize the time spent downloading, cleaning and loading these datasets into Postgres (or whatever).&lt;/p&gt;\n\n&lt;p&gt;So, is there some docker-friendly webapp that will help me do that? I&amp;#39;ve seen OpenRefine but haven&amp;#39;t used it - does it fit the bill?&lt;/p&gt;\n\n&lt;p&gt;At a previous job we used Dataiku DSS and it was great for this. You could load a csv (or mysqldump, I think), edit the column types and do quite some cleaning and transformations and then save it as a new table in the db. Yes there is a free version (that I&amp;#39;ll likely end up using if I can&amp;#39;t find anything else) but I would rather rely on open-source plus it is way overkill because it does so much more stuff.&lt;/p&gt;\n\n&lt;p&gt;What would be REALLY cool, if is such an app existed that already had a list of public datasets availalble, so I can just search and load them directly within app&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "10slv07", "is_robot_indexable": true, "report_reasons": null, "author": "leqlatte", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10slv07/selfhosted_nocode_data_prep_tool_maybe_openrefine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10slv07/selfhosted_nocode_data_prep_tool_maybe_openrefine/", "subreddit_subscribers": 88376, "created_utc": 1675435122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone! I've come across a few troubles while processing .zip files from S3. I need to extract files from .zip archives and put them back in an S3 bucket. \nThe first problem is reading .zip files into memory - can I construct a ZipFile object to iterate over it directly from S3?\nThe second problem is that some files are too big (up to 40GB) and are in fact multi-part, so Python zipfile package fails to read them\nAre there any best practices for solving such tasks?\nThanks", "author_fullname": "t2_1qtw7ivc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Processing big .zip files from S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10sh10u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675419592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! I&amp;#39;ve come across a few troubles while processing .zip files from S3. I need to extract files from .zip archives and put them back in an S3 bucket. \nThe first problem is reading .zip files into memory - can I construct a ZipFile object to iterate over it directly from S3?\nThe second problem is that some files are too big (up to 40GB) and are in fact multi-part, so Python zipfile package fails to read them\nAre there any best practices for solving such tasks?\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10sh10u", "is_robot_indexable": true, "report_reasons": null, "author": "redcat10601", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10sh10u/processing_big_zip_files_from_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10sh10u/processing_big_zip_files_from_s3/", "subreddit_subscribers": 88376, "created_utc": 1675419592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " (Reposted from the r/datascience)\n\nHi everyone! (First time posting in this subreddit!!)\n\nI recently just got a programming and behavioral interview offer for a data engineering intern position! However, I am still relatively new to the field and not 100% confident about what skills/concepts I would need to practice/hone before the big day. I would love any tips and pointers!", "author_fullname": "t2_3zcfasss", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tips for data engineering programming interviews?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10s83x0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675390128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Reposted from the &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Hi everyone! (First time posting in this subreddit!!)&lt;/p&gt;\n\n&lt;p&gt;I recently just got a programming and behavioral interview offer for a data engineering intern position! However, I am still relatively new to the field and not 100% confident about what skills/concepts I would need to practice/hone before the big day. I would love any tips and pointers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10s83x0", "is_robot_indexable": true, "report_reasons": null, "author": "akatyusha", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10s83x0/any_tips_for_data_engineering_programming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10s83x0/any_tips_for_data_engineering_programming/", "subreddit_subscribers": 88376, "created_utc": 1675390128.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}