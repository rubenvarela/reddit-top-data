{"kind": "Listing", "data": {"after": "t3_10z6hui", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8ql6tbbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Runtime Disconnected\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 121, "top_awarded_type": null, "hide_score": false, "name": "t3_10zocpb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 293, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 293, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Ud5wejhZN1cSJzbiUOE1ILy8m5SNd1zWCe89_19KUV8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676124186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/lg4tr16rxlha1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/lg4tr16rxlha1.jpg?auto=webp&amp;v=enabled&amp;s=d64394bd8dfcc8ce77d367a5b1f3614dce8fb558", "width": 573, "height": 499}, "resolutions": [{"url": "https://preview.redd.it/lg4tr16rxlha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9eaf9588adbd7f9e090b73a7dc26fbbdf9d2deb", "width": 108, "height": 94}, {"url": "https://preview.redd.it/lg4tr16rxlha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2dd026782b8f003cfab88c6f47e3106dbd420f30", "width": 216, "height": 188}, {"url": "https://preview.redd.it/lg4tr16rxlha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e7d41660c7b1dc0ddfa11bb5e2b478ea77b5328", "width": 320, "height": 278}], "variants": {}, "id": "dPIZQ8vbvgtxZN-u-eXL8e5AbkwWbbDOtRqciEb7NgI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zocpb", "is_robot_indexable": true, "report_reasons": null, "author": "Successful_Pomelo701", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zocpb/runtime_disconnected/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/lg4tr16rxlha1.jpg", "subreddit_subscribers": 846834, "created_utc": 1676124186.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So long story short, my undergrad was in international affairs, nothing technical. I touched R a little bit but nothing extensive. I decided during the pandemic I was going to push to get a STEM masters to supplement my undergrad and I knocked it out. I really enjoyed it and I can use a ton of tools to develop ML solutions and deploy models leveraging tools like Sagemaker. I\u2019ve even become an OK programmer. The issue I have is many of these solutions and tools are black box. I can apply the tool to solve a problem but I don\u2019t always know how it works and, being honest, there\u2019s a lot of effing tools. \n\nI feel like I\u2019ve got a good warm and fuzzy about what data science and ML can do and what it can\u2019t but I find a lot of jobs will post their need for people with extensive education in quantitative skills, or vast experience with A/B testing which I understand but haven\u2019t done extensively, or 6 years building solutions with Tensorflow. Thus, I feel like I might be wildly under skilled despite the degree. \n\nMaybe the industry is just so flooded now that DS roles really require a deep specialized knowledge because it\u2019s so competitive. Seems like there are lots of PhD roles in industry these days. \n\nWould it make sense for me to go back and hammer out the math? Another undergrad? Another masters maybe? Push forward and do a PhD and lose steady income for the 4 years maybe more?\n\nMaybe this is classic imposter syndrome. I digress. But anyway, advice is always good to have.", "author_fullname": "t2_4dmjsv6g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I have a Masters in Data Science but I feel behind on some basics. Should I go back to school to pick up the math and stats I think I\u2019m missing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zcaet", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 112, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 112, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1676140484.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676090244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So long story short, my undergrad was in international affairs, nothing technical. I touched R a little bit but nothing extensive. I decided during the pandemic I was going to push to get a STEM masters to supplement my undergrad and I knocked it out. I really enjoyed it and I can use a ton of tools to develop ML solutions and deploy models leveraging tools like Sagemaker. I\u2019ve even become an OK programmer. The issue I have is many of these solutions and tools are black box. I can apply the tool to solve a problem but I don\u2019t always know how it works and, being honest, there\u2019s a lot of effing tools. &lt;/p&gt;\n\n&lt;p&gt;I feel like I\u2019ve got a good warm and fuzzy about what data science and ML can do and what it can\u2019t but I find a lot of jobs will post their need for people with extensive education in quantitative skills, or vast experience with A/B testing which I understand but haven\u2019t done extensively, or 6 years building solutions with Tensorflow. Thus, I feel like I might be wildly under skilled despite the degree. &lt;/p&gt;\n\n&lt;p&gt;Maybe the industry is just so flooded now that DS roles really require a deep specialized knowledge because it\u2019s so competitive. Seems like there are lots of PhD roles in industry these days. &lt;/p&gt;\n\n&lt;p&gt;Would it make sense for me to go back and hammer out the math? Another undergrad? Another masters maybe? Push forward and do a PhD and lose steady income for the 4 years maybe more?&lt;/p&gt;\n\n&lt;p&gt;Maybe this is classic imposter syndrome. I digress. But anyway, advice is always good to have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zcaet", "is_robot_indexable": true, "report_reasons": null, "author": "sonictoddler", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zcaet/i_have_a_masters_in_data_science_but_i_feel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zcaet/i_have_a_masters_in_data_science_but_i_feel/", "subreddit_subscribers": 846834, "created_utc": 1676090244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Based on your own experience, formulate a one to two liner on what makes DS **not** for someone. It could be simple like \"you dislike math\" or something more complicated.", "author_fullname": "t2_39s7scwo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you know DS is NOT for you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zddes", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676093869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Based on your own experience, formulate a one to two liner on what makes DS &lt;strong&gt;not&lt;/strong&gt; for someone. It could be simple like &amp;quot;you dislike math&amp;quot; or something more complicated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zddes", "is_robot_indexable": true, "report_reasons": null, "author": "ImaCPAMD", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zddes/how_do_you_know_ds_is_not_for_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zddes/how_do_you_know_ds_is_not_for_you/", "subreddit_subscribers": 846834, "created_utc": 1676093869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "After landing my first data analyst job after getting my MS in in Data Analytics as an adult learner,  I am now being told that I am not a good fit and I should start looking for other roles.  Freakin sucks, only 9 months in. But to be fair, I was not great. But I was progressing\n\nThere is so much to learn in a real business setting than what I could ever imagine. (my employer is a huge telco so LOTS of data). Anyway, feeling like maybe I should give up on this data stuff. But I do actually enjoy the work so maybe looking for some encouragement... Has something similar ever happened to any of you? And advice on how to pick yourself up and keep on going?", "author_fullname": "t2_3r917tqn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "not a good fit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10z8isy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676078319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After landing my first data analyst job after getting my MS in in Data Analytics as an adult learner,  I am now being told that I am not a good fit and I should start looking for other roles.  Freakin sucks, only 9 months in. But to be fair, I was not great. But I was progressing&lt;/p&gt;\n\n&lt;p&gt;There is so much to learn in a real business setting than what I could ever imagine. (my employer is a huge telco so LOTS of data). Anyway, feeling like maybe I should give up on this data stuff. But I do actually enjoy the work so maybe looking for some encouragement... Has something similar ever happened to any of you? And advice on how to pick yourself up and keep on going?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10z8isy", "is_robot_indexable": true, "report_reasons": null, "author": "MiiBone", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10z8isy/not_a_good_fit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10z8isy/not_a_good_fit/", "subreddit_subscribers": 846834, "created_utc": 1676078319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "GPT is getting competition from open-source.\n\nA group of researchers, around the YouTuber [Yannic Kilcher](https://www.ykilcher.com/), have announced that they are working on [Open Assistant](https://github.com/LAION-AI/Open-Assistant). The goal is to produce a chat-based language model that is much smaller than GPT-3 while maintaining similar performance.\n\nIf you want to support them, they are crowd-sourcing training data [here](https://open-assistant.io/).\n\n**What Does This Mean?**\n\nCurrent language models are too big.\n\nThey require millions of dollars of hardware to train and use. Hence, access to this technology is limited to big organizations. Smaller firms and universities are effectively shut out from the developments.\n\nShrinking and open-sourcing models will facilitate academic research and niche applications.\n\nProjects such as Open Assistant will help to make language models a commodity. Lowering the barrier to entry will increase access and accelerate innovation.\n\nWhat an exciting time to be alive! \n\nThank you for reading! I really enjoyed making this for you!  \nThe Decoding \u2b55 is a thoughtful weekly 5-minute email that keeps you in the loop about machine research and the data economy. [Click here to sign up](https://thedecoding.net/)!", "author_fullname": "t2_az3v2qdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u2b55 New Open-Source Version Of ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zepub", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676098771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;GPT is getting competition from open-source.&lt;/p&gt;\n\n&lt;p&gt;A group of researchers, around the YouTuber &lt;a href=\"https://www.ykilcher.com/\"&gt;Yannic Kilcher&lt;/a&gt;, have announced that they are working on &lt;a href=\"https://github.com/LAION-AI/Open-Assistant\"&gt;Open Assistant&lt;/a&gt;. The goal is to produce a chat-based language model that is much smaller than GPT-3 while maintaining similar performance.&lt;/p&gt;\n\n&lt;p&gt;If you want to support them, they are crowd-sourcing training data &lt;a href=\"https://open-assistant.io/\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What Does This Mean?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Current language models are too big.&lt;/p&gt;\n\n&lt;p&gt;They require millions of dollars of hardware to train and use. Hence, access to this technology is limited to big organizations. Smaller firms and universities are effectively shut out from the developments.&lt;/p&gt;\n\n&lt;p&gt;Shrinking and open-sourcing models will facilitate academic research and niche applications.&lt;/p&gt;\n\n&lt;p&gt;Projects such as Open Assistant will help to make language models a commodity. Lowering the barrier to entry will increase access and accelerate innovation.&lt;/p&gt;\n\n&lt;p&gt;What an exciting time to be alive! &lt;/p&gt;\n\n&lt;p&gt;Thank you for reading! I really enjoyed making this for you!&lt;br/&gt;\nThe Decoding \u2b55 is a thoughtful weekly 5-minute email that keeps you in the loop about machine research and the data economy. &lt;a href=\"https://thedecoding.net/\"&gt;Click here to sign up&lt;/a&gt;!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zepub", "is_robot_indexable": true, "report_reasons": null, "author": "LesleyFair", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zepub/new_opensource_version_of_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zepub/new_opensource_version_of_chatgpt/", "subreddit_subscribers": 846834, "created_utc": 1676098771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am interviewing with a systematic hedge fund for a quant research role (I am a statistics masters student currently) . I have an all-day onsite interview coming up in which I am told I will be given a dataset at 9am, and will have to \"present my findings\" at about 4pm. The data is not necessarily financial; it could be something like weather or sports.\n\nThe explicit requirements for the role are familiarity with Python, Pandas etc., and good background in stats -- not necessarily Kaggle whizz. It's hard to imagine making much progress on quite an undirected task in that little time, particularly when random bugs and errors are basically bound to happen and cost time at some point, and when some time at the end needs to be spent preparing a presentation.\n\nI would be very grateful for some advice from anyone who knows about junior data science roles (particularly in finance):\n\n\\-   What sort of level of analysis would be expected in this timeframe?\n\n\\-   Given that a large chunk of time will need to be spent on doing very basic explorations and plots, and on preparing a presentation, how is it possible to impress in an interview like this?\n\nMany thanks for any help, this interview seems like quite a daunting task!", "author_fullname": "t2_smteol2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to expect from day-long dataset interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zn9tr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676120967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am interviewing with a systematic hedge fund for a quant research role (I am a statistics masters student currently) . I have an all-day onsite interview coming up in which I am told I will be given a dataset at 9am, and will have to &amp;quot;present my findings&amp;quot; at about 4pm. The data is not necessarily financial; it could be something like weather or sports.&lt;/p&gt;\n\n&lt;p&gt;The explicit requirements for the role are familiarity with Python, Pandas etc., and good background in stats -- not necessarily Kaggle whizz. It&amp;#39;s hard to imagine making much progress on quite an undirected task in that little time, particularly when random bugs and errors are basically bound to happen and cost time at some point, and when some time at the end needs to be spent preparing a presentation.&lt;/p&gt;\n\n&lt;p&gt;I would be very grateful for some advice from anyone who knows about junior data science roles (particularly in finance):&lt;/p&gt;\n\n&lt;p&gt;-   What sort of level of analysis would be expected in this timeframe?&lt;/p&gt;\n\n&lt;p&gt;-   Given that a large chunk of time will need to be spent on doing very basic explorations and plots, and on preparing a presentation, how is it possible to impress in an interview like this?&lt;/p&gt;\n\n&lt;p&gt;Many thanks for any help, this interview seems like quite a daunting task!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zn9tr", "is_robot_indexable": true, "report_reasons": null, "author": "OldWafer2833", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zn9tr/what_to_expect_from_daylong_dataset_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zn9tr/what_to_expect_from_daylong_dataset_interview/", "subreddit_subscribers": 846834, "created_utc": 1676120967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teach Yourself Programming in Ten Years", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zhmph", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_frho0e24", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "programming", "selftext": "", "author_fullname": "t2_2qa94c49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Teach Yourself Programming in Ten Years", "link_flair_richtext": [], "subreddit_name_prefixed": "r/programming", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10yydr6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 104, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 104, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1676052007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "norvig.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://norvig.com/21-days.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2fwo", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10yydr6", "is_robot_indexable": true, "report_reasons": null, "author": "mitousa", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/programming/comments/10yydr6/teach_yourself_programming_in_ten_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://norvig.com/21-days.html", "subreddit_subscribers": 5177516, "created_utc": 1676052007.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1676110080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "norvig.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://norvig.com/21-days.html", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zhmph", "is_robot_indexable": true, "report_reasons": null, "author": "space-ish", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_10yydr6", "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zhmph/teach_yourself_programming_in_ten_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://norvig.com/21-days.html", "subreddit_subscribers": 846834, "created_utc": 1676110080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My last post got taken down because I linked to the original video - my bad.\n\nAnyway, I interviewed 24 data scientists and asked them this: \"if you could start over, what would you do differently.\"\n\nInstead of linking the video, I'll give you a summary of what they said: (some people had multiple answers)\n\n1. Did Kaggle competitions and hackathons earlier.\n2. Collaborated more with other people, instead of always working by myself.\n3. Spent more time understanding the business problem and the impact of my work.\n4. Learned more about computer architecture and object-oriented programming.\n5. Joined a user group for support.\n6. Enrolled in a data science bootcamp earlier on.\n7. Tried more online courses BEFORE enrolling in a master's program.\n8. Spent more time thinking about WHY I want to be a data scientist.\n9. Pursued a mathematical degree.\n10. Spent a few years exploring applied data science fields.\n11. Had more initiative at the start of my career.\n12. Went straight into industry so that I could have made more money.\n13. Aligned myself with exceptionally smart and talented people.\n14. Figured out where data science was going 10-15 years from current to find ways to get ahead.\n15. Studied computer science or statistics.\n16. Understood that data science is purpose driven.\n17. Understood that the data science field is so vast that you'll never learn everything.\n18. Knew to always have a goal.\n19. Understood that it doesn't matter how many tools you learn, especially because each company will have a slightly different tool stack.\n20. Learned more computer science knowledge, and did more coding tutorials online.\n21. Understood that the work you do won't be perfect, but you need to start quickly.\n22. Enrolled myself in a data science bootcamp.\n23. Started smaller.\n24. Focused more on business development and finance so that I could properly position myself to be a manager instead of a data scientist.\n25. Focused more on becoming a data analyst, since that's the entry level position in the field.\n26. Learned SQL, ETL, and Power BI at the get-go.\n27. Focused more on taking as many internships as possible.\n28. Had a mentor.\n29. Had asked for more help from other people, especially on LinkedIn.\n30. Learned data structures, dictionaries, and object-oriented programming earlier on.\n31. Waited to take my advanced modeling classes. \n32. Focused more on learning business knowledge.\n33. Focused more on how to take things to production.\n34. Learned to keep my mouth shut in certain work situations.\n\nif you're interested in seeing the full video, you'll have to visit my [YouTube channel](https://www.youtube.com/channel/UCYqWj7wOxYTjeo3LRWYkcCA). The video goes more in-depth and I provide all the data scientists background info (years of exp, title, industry, size of company, location, etc).\n\nSomething else worth mentioning is that I asked the data scientists about 12 questions, so I intend to turn each question into a list like this to share with Reddit and post on YouTube.\n\nI also want to thank all the people who contributed. Many of the people I interviewed were a part of r/datascience.", "author_fullname": "t2_uod0yb3y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "24 data scientists explain what they'd do differently if they started over", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zuuoy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676141523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My last post got taken down because I linked to the original video - my bad.&lt;/p&gt;\n\n&lt;p&gt;Anyway, I interviewed 24 data scientists and asked them this: &amp;quot;if you could start over, what would you do differently.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Instead of linking the video, I&amp;#39;ll give you a summary of what they said: (some people had multiple answers)&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Did Kaggle competitions and hackathons earlier.&lt;/li&gt;\n&lt;li&gt;Collaborated more with other people, instead of always working by myself.&lt;/li&gt;\n&lt;li&gt;Spent more time understanding the business problem and the impact of my work.&lt;/li&gt;\n&lt;li&gt;Learned more about computer architecture and object-oriented programming.&lt;/li&gt;\n&lt;li&gt;Joined a user group for support.&lt;/li&gt;\n&lt;li&gt;Enrolled in a data science bootcamp earlier on.&lt;/li&gt;\n&lt;li&gt;Tried more online courses BEFORE enrolling in a master&amp;#39;s program.&lt;/li&gt;\n&lt;li&gt;Spent more time thinking about WHY I want to be a data scientist.&lt;/li&gt;\n&lt;li&gt;Pursued a mathematical degree.&lt;/li&gt;\n&lt;li&gt;Spent a few years exploring applied data science fields.&lt;/li&gt;\n&lt;li&gt;Had more initiative at the start of my career.&lt;/li&gt;\n&lt;li&gt;Went straight into industry so that I could have made more money.&lt;/li&gt;\n&lt;li&gt;Aligned myself with exceptionally smart and talented people.&lt;/li&gt;\n&lt;li&gt;Figured out where data science was going 10-15 years from current to find ways to get ahead.&lt;/li&gt;\n&lt;li&gt;Studied computer science or statistics.&lt;/li&gt;\n&lt;li&gt;Understood that data science is purpose driven.&lt;/li&gt;\n&lt;li&gt;Understood that the data science field is so vast that you&amp;#39;ll never learn everything.&lt;/li&gt;\n&lt;li&gt;Knew to always have a goal.&lt;/li&gt;\n&lt;li&gt;Understood that it doesn&amp;#39;t matter how many tools you learn, especially because each company will have a slightly different tool stack.&lt;/li&gt;\n&lt;li&gt;Learned more computer science knowledge, and did more coding tutorials online.&lt;/li&gt;\n&lt;li&gt;Understood that the work you do won&amp;#39;t be perfect, but you need to start quickly.&lt;/li&gt;\n&lt;li&gt;Enrolled myself in a data science bootcamp.&lt;/li&gt;\n&lt;li&gt;Started smaller.&lt;/li&gt;\n&lt;li&gt;Focused more on business development and finance so that I could properly position myself to be a manager instead of a data scientist.&lt;/li&gt;\n&lt;li&gt;Focused more on becoming a data analyst, since that&amp;#39;s the entry level position in the field.&lt;/li&gt;\n&lt;li&gt;Learned SQL, ETL, and Power BI at the get-go.&lt;/li&gt;\n&lt;li&gt;Focused more on taking as many internships as possible.&lt;/li&gt;\n&lt;li&gt;Had a mentor.&lt;/li&gt;\n&lt;li&gt;Had asked for more help from other people, especially on LinkedIn.&lt;/li&gt;\n&lt;li&gt;Learned data structures, dictionaries, and object-oriented programming earlier on.&lt;/li&gt;\n&lt;li&gt;Waited to take my advanced modeling classes. &lt;/li&gt;\n&lt;li&gt;Focused more on learning business knowledge.&lt;/li&gt;\n&lt;li&gt;Focused more on how to take things to production.&lt;/li&gt;\n&lt;li&gt;Learned to keep my mouth shut in certain work situations.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;if you&amp;#39;re interested in seeing the full video, you&amp;#39;ll have to visit my &lt;a href=\"https://www.youtube.com/channel/UCYqWj7wOxYTjeo3LRWYkcCA\"&gt;YouTube channel&lt;/a&gt;. The video goes more in-depth and I provide all the data scientists background info (years of exp, title, industry, size of company, location, etc).&lt;/p&gt;\n\n&lt;p&gt;Something else worth mentioning is that I asked the data scientists about 12 questions, so I intend to turn each question into a list like this to share with Reddit and post on YouTube.&lt;/p&gt;\n\n&lt;p&gt;I also want to thank all the people who contributed. Many of the people I interviewed were a part of &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5FYITxgsjbfXKleI8OsLbd2nLoE-gHhHEJEH5x9EqB4.jpg?auto=webp&amp;v=enabled&amp;s=ad5530c11951e4553e92abbf547aeb537253eced", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/5FYITxgsjbfXKleI8OsLbd2nLoE-gHhHEJEH5x9EqB4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d95e8cdb4a4bb553901d248fc42a4371fd6eb70a", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/5FYITxgsjbfXKleI8OsLbd2nLoE-gHhHEJEH5x9EqB4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5254cf70b8e7f75ed610132e9c8fb531f5b03606", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/5FYITxgsjbfXKleI8OsLbd2nLoE-gHhHEJEH5x9EqB4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3da0e53b0c70565056af9fc4a42a4734504e17ef", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/5FYITxgsjbfXKleI8OsLbd2nLoE-gHhHEJEH5x9EqB4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c471802e4f05c89cec9f4213577c92bb888b5d17", "width": 640, "height": 640}], "variants": {}, "id": "iHLkEqNkNqzvep4yKP5JEIzntiNLDPivocMXp2Tm5cY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zuuoy", "is_robot_indexable": true, "report_reasons": null, "author": "JohnDS1503", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zuuoy/24_data_scientists_explain_what_theyd_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zuuoy/24_data_scientists_explain_what_theyd_do/", "subreddit_subscribers": 846834, "created_utc": 1676141523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_cjpqb171", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Courses/ Resources To Learn NLP From Basics ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zcpnu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676091621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zcpnu", "is_robot_indexable": true, "report_reasons": null, "author": "Most_Series6588", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zcpnu/best_courses_resources_to_learn_nlp_from_basics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zcpnu/best_courses_resources_to_learn_nlp_from_basics/", "subreddit_subscribers": 846834, "created_utc": 1676091621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Couple of months ago I took part in a hackathon related to scouting football players for Sevilla FC. The data had more than 80,000 columns, and no proper information on the data being presented.\n\nThe data that was provided had column names as \"X_0,X_1,...\". We are given scouting data which has age team played for performance but along with this 80000 columns with absolutely no context. So I can't infer anything, nor do I have skills to tackle such data.\n\nAs I am a student with work experience only as a software tester I generally practice data science using open source data or kaggle. On these platforms we have some insights on each attributes of the data.\n\nHow will you guys go about processing the data before creating a Ml model for such cases where dimensions are high so manually doing eda is very hard?", "author_fullname": "t2_k7ds1cx7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn to deal with data that has high dimensionality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zax1m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676085829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Couple of months ago I took part in a hackathon related to scouting football players for Sevilla FC. The data had more than 80,000 columns, and no proper information on the data being presented.&lt;/p&gt;\n\n&lt;p&gt;The data that was provided had column names as &amp;quot;X_0,X_1,...&amp;quot;. We are given scouting data which has age team played for performance but along with this 80000 columns with absolutely no context. So I can&amp;#39;t infer anything, nor do I have skills to tackle such data.&lt;/p&gt;\n\n&lt;p&gt;As I am a student with work experience only as a software tester I generally practice data science using open source data or kaggle. On these platforms we have some insights on each attributes of the data.&lt;/p&gt;\n\n&lt;p&gt;How will you guys go about processing the data before creating a Ml model for such cases where dimensions are high so manually doing eda is very hard?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zax1m", "is_robot_indexable": true, "report_reasons": null, "author": "Intelligent_Put8678", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zax1m/how_to_learn_to_deal_with_data_that_has_high/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zax1m/how_to_learn_to_deal_with_data_that_has_high/", "subreddit_subscribers": 846834, "created_utc": 1676085829.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7d1s5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Calling all NLP gurus, Meta is paying top dollar \ud83d\ude02", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 116, "top_awarded_type": null, "hide_score": false, "name": "t3_10zvb04", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_B4jOxrHtMRnlzYITWxxhtoaj48STPW4bnKDKdee9ws.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676142693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ywof5cgsgnha1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ywof5cgsgnha1.jpg?auto=webp&amp;v=enabled&amp;s=c228359bf9a36409e12b055b86b127b9eb1b2f18", "width": 750, "height": 624}, "resolutions": [{"url": "https://preview.redd.it/ywof5cgsgnha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd4fbb23dd9d1dc2ef8df808f7503208ba546264", "width": 108, "height": 89}, {"url": "https://preview.redd.it/ywof5cgsgnha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e23f359580d59da31822659b03df62baca4ddba9", "width": 216, "height": 179}, {"url": "https://preview.redd.it/ywof5cgsgnha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d051d94005a297bdc55a9655ec8b2a2fec4123c0", "width": 320, "height": 266}, {"url": "https://preview.redd.it/ywof5cgsgnha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10e8c9906ab777e400a7a99649d50b8a64d8be2e", "width": 640, "height": 532}], "variants": {}, "id": "GigBTZdgf8_oHp-ZHda6uja_P2x3Ghb51FXS6rhpQHg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zvb04", "is_robot_indexable": true, "report_reasons": null, "author": "enDelt09", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zvb04/calling_all_nlp_gurus_meta_is_paying_top_dollar/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ywof5cgsgnha1.jpg", "subreddit_subscribers": 846834, "created_utc": 1676142693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I currently have 7 YOE but I still enjoy learning whenever I can. Since free time is pretty scarce between work priorities and family life, I\u2019m very particular about topics I should study and qualify of material. Does anyone have any recommendations for a tool I could use to\n\n1. Keep track of topics I want to cover whether I\u2019ve completed it, currently working on it or want to get to it in the future\n\n2. Store links to material covering that topic that I\u2019ve decided is worth it\n\n3. Make note of where I am in the material, just a note to self where I left off if I need to break for a few week. (YouTube series, books, moocs etc\u2026)\n\n4. Store my notes regarding each topic for later reference. Could be a link or file attachment etc\u2026\n\nI was initially thinking trello, but I\u2019m curious if anyone else is overthinks their learning as much as I do and what you\u2019re using.", "author_fullname": "t2_bcbozi6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reccomendations to keep track of learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zrnv3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676133318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have 7 YOE but I still enjoy learning whenever I can. Since free time is pretty scarce between work priorities and family life, I\u2019m very particular about topics I should study and qualify of material. Does anyone have any recommendations for a tool I could use to&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Keep track of topics I want to cover whether I\u2019ve completed it, currently working on it or want to get to it in the future&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Store links to material covering that topic that I\u2019ve decided is worth it&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Make note of where I am in the material, just a note to self where I left off if I need to break for a few week. (YouTube series, books, moocs etc\u2026)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Store my notes regarding each topic for later reference. Could be a link or file attachment etc\u2026&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I was initially thinking trello, but I\u2019m curious if anyone else is overthinks their learning as much as I do and what you\u2019re using.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zrnv3", "is_robot_indexable": true, "report_reasons": null, "author": "sizable_data", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zrnv3/reccomendations_to_keep_track_of_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zrnv3/reccomendations_to_keep_track_of_learning/", "subreddit_subscribers": 846834, "created_utc": 1676133318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR: a 31 y.o. DS\\\\researcher working mostly with time-series wearables data, lagging behind modern development stack. Willing to become a more demanded and better paid pro, possibly in an adjacent field. How should I spend 6 months (fulltime) with the maximum benefit?\n\nI will be laid off in March-April because of the reorg and will have 6 month of from-work-to-work time (employer's termination notice). I won't be expected to do much, but I want to use that time with the maximum profit for myself. I can find another similar job, but see this as an opportunity to reinvent myself. What should I do?   \n\\- change profession to data engineering (I kinda miss research aspect there, but there are so many vacancies...)  \n\\- refocus to a different sexy domain (trading algos, video AI, blockchain,...?)  \nI think the best way to go is to learn stuff by doing and develop my portfolio at the same time (public github, kaggle competitions). \n\nDoes anyone has ideas on the roadmap? Thanks.", "author_fullname": "t2_f3y80e7s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use 6 month to become a better specialist and get paid more?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zpdwr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676127824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: a 31 y.o. DS\\researcher working mostly with time-series wearables data, lagging behind modern development stack. Willing to become a more demanded and better paid pro, possibly in an adjacent field. How should I spend 6 months (fulltime) with the maximum benefit?&lt;/p&gt;\n\n&lt;p&gt;I will be laid off in March-April because of the reorg and will have 6 month of from-work-to-work time (employer&amp;#39;s termination notice). I won&amp;#39;t be expected to do much, but I want to use that time with the maximum profit for myself. I can find another similar job, but see this as an opportunity to reinvent myself. What should I do?&lt;br/&gt;\n- change profession to data engineering (I kinda miss research aspect there, but there are so many vacancies...)&lt;br/&gt;\n- refocus to a different sexy domain (trading algos, video AI, blockchain,...?)&lt;br/&gt;\nI think the best way to go is to learn stuff by doing and develop my portfolio at the same time (public github, kaggle competitions). &lt;/p&gt;\n\n&lt;p&gt;Does anyone has ideas on the roadmap? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zpdwr", "is_robot_indexable": true, "report_reasons": null, "author": "docoja1739", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zpdwr/how_to_use_6_month_to_become_a_better_specialist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zpdwr/how_to_use_6_month_to_become_a_better_specialist/", "subreddit_subscribers": 846834, "created_utc": 1676127824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was sharing some of my work with a SWD I have a lot of respect for. My most recent project is scraping a bunch of esports data that I then did some basic EDA with and was looking for interesting questions to move forward. His statement to me seemed odd\n\n&gt; I don't really think that is the right approach here. Typically we'd go into something like this by starting with a model that we design intuitively, then compare with the game results, and spend time trying to identify what causes differences between the game and model\nHow can there be a descriptive understanding without a model\n\nI have an MS in Data analytics (not from a great school but still) and every one of my courses started with \"Do EDA to ensure you can model your data first\"\n\nAM I missing some nuance here about when to do EDA or when to immediately go \"linear regression\"", "author_fullname": "t2_cytbx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Start with EDA or a model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10zwtlc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676146619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was sharing some of my work with a SWD I have a lot of respect for. My most recent project is scraping a bunch of esports data that I then did some basic EDA with and was looking for interesting questions to move forward. His statement to me seemed odd&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I don&amp;#39;t really think that is the right approach here. Typically we&amp;#39;d go into something like this by starting with a model that we design intuitively, then compare with the game results, and spend time trying to identify what causes differences between the game and model\nHow can there be a descriptive understanding without a model&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I have an MS in Data analytics (not from a great school but still) and every one of my courses started with &amp;quot;Do EDA to ensure you can model your data first&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;AM I missing some nuance here about when to do EDA or when to immediately go &amp;quot;linear regression&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zwtlc", "is_robot_indexable": true, "report_reasons": null, "author": "Smcgb1844", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zwtlc/start_with_eda_or_a_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zwtlc/start_with_eda_or_a_model/", "subreddit_subscribers": 846834, "created_utc": 1676146619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If anyone is familar with this style of visualization, is there any python package that allows me to represent the percentages as circles out of 100 like this? \n\nhttps://preview.redd.it/e5gdjsi0slha1.png?width=1730&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=15977365b31636d24c986c53249109b5f1ab5ba3", "author_fullname": "t2_rrw7orx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Question] Percentage Represented as Circles ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 34, "top_awarded_type": null, "hide_score": false, "media_metadata": {"e5gdjsi0slha1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 26, "x": 108, "u": "https://preview.redd.it/e5gdjsi0slha1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3066de30aa3162c19e1240ff5f32beca81821696"}, {"y": 53, "x": 216, "u": "https://preview.redd.it/e5gdjsi0slha1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc3ca4ba9b7353af1c8792d7633b324555b8cd3c"}, {"y": 79, "x": 320, "u": "https://preview.redd.it/e5gdjsi0slha1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7be45f73e51c82158e0910c63eb04eaa37280b5d"}, {"y": 159, "x": 640, "u": "https://preview.redd.it/e5gdjsi0slha1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ccad2873c3f85c702b13ef388eff98755b48fb8"}, {"y": 239, "x": 960, "u": "https://preview.redd.it/e5gdjsi0slha1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fa11aca31873f8781482cfa51d786dc2a9a3b4a"}, {"y": 269, "x": 1080, "u": "https://preview.redd.it/e5gdjsi0slha1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=17d051e38d181bd7c493871309fa61c7344a9445"}], "s": {"y": 432, "x": 1730, "u": "https://preview.redd.it/e5gdjsi0slha1.png?width=1730&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=15977365b31636d24c986c53249109b5f1ab5ba3"}, "id": "e5gdjsi0slha1"}}, "name": "t3_10zue7t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9RH4M3Q0oCleTRGJcW0Kztzepukc80ttlK72e5F-35M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676140334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If anyone is familar with this style of visualization, is there any python package that allows me to represent the percentages as circles out of 100 like this? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/e5gdjsi0slha1.png?width=1730&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=15977365b31636d24c986c53249109b5f1ab5ba3\"&gt;https://preview.redd.it/e5gdjsi0slha1.png?width=1730&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=15977365b31636d24c986c53249109b5f1ab5ba3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zue7t", "is_robot_indexable": true, "report_reasons": null, "author": "sfriedmanssf", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zue7t/question_percentage_represented_as_circles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zue7t/question_percentage_represented_as_circles/", "subreddit_subscribers": 846834, "created_utc": 1676140334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working as BI Analyst and have about 2 years of experience. My goal is to stay in my current position for at least another year and move onto a more technical data role such as a BI Developer. I've been looking into Masters programs but it's been difficult to commit to going back to school (time/ money). My ultimate goal is to become a data scientist, and I know a Masters degree will one day be required for me to move into this role. How long did you guys wait until you went back to school? Is a masters worth it? Or could I do a graduate certificate instead?", "author_fullname": "t2_aeasv6jq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current Data Scientists: how long did you wait to get your masters degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zpbkp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676127588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working as BI Analyst and have about 2 years of experience. My goal is to stay in my current position for at least another year and move onto a more technical data role such as a BI Developer. I&amp;#39;ve been looking into Masters programs but it&amp;#39;s been difficult to commit to going back to school (time/ money). My ultimate goal is to become a data scientist, and I know a Masters degree will one day be required for me to move into this role. How long did you guys wait until you went back to school? Is a masters worth it? Or could I do a graduate certificate instead?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zpbkp", "is_robot_indexable": true, "report_reasons": null, "author": "RepresentativeBid238", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zpbkp/current_data_scientists_how_long_did_you_wait_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zpbkp/current_data_scientists_how_long_did_you_wait_to/", "subreddit_subscribers": 846834, "created_utc": 1676127588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If someone refers to a linear and non-linear model in an ML context, does this have to mean a regression type model or are there other types of linear / non-linear models? I'm curious because I wanted to learn more about the differences between the two but most sources I've found refer to linear 'regression' models specifically which makes me think that 'linear model' is shorthand for 'linear regression model'. Sorry for the newb question!", "author_fullname": "t2_f6mw4dmp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Linear + non linear models in ML context: regression types only?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10z4qtc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676067728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If someone refers to a linear and non-linear model in an ML context, does this have to mean a regression type model or are there other types of linear / non-linear models? I&amp;#39;m curious because I wanted to learn more about the differences between the two but most sources I&amp;#39;ve found refer to linear &amp;#39;regression&amp;#39; models specifically which makes me think that &amp;#39;linear model&amp;#39; is shorthand for &amp;#39;linear regression model&amp;#39;. Sorry for the newb question!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10z4qtc", "is_robot_indexable": true, "report_reasons": null, "author": "Imaginary_Local_5320", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10z4qtc/linear_non_linear_models_in_ml_context_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10z4qtc/linear_non_linear_models_in_ml_context_regression/", "subreddit_subscribers": 846834, "created_utc": 1676067728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I would like to share with you my recent article about utilizing the power of a neuro-symbolic framework - PyNeuraLogic, to implement different kinds of Transformers, including the one used in GPT-3.\n\n[https://towardsdatascience.com/beyond-transformers-with-pyneuralogic-10b70cdc5e45](https://towardsdatascience.com/beyond-transformers-with-pyneuralogic-10b70cdc5e45)\n\nI would appreciate any feedback down in the comments. Thank you.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/4ore6fmgpfha1.png?width=1400&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3c9533e3abbe780b9e952f93d55a00eba5f1d33b", "author_fullname": "t2_omrbonjm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beyond Transformers \ud83e\udd16 with a neuro-symbolic framework!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 52, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4ore6fmgpfha1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 40, "x": 108, "u": "https://preview.redd.it/4ore6fmgpfha1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afd4d32ed8ab4cb4f562fa4817f332e528e0c788"}, {"y": 81, "x": 216, "u": "https://preview.redd.it/4ore6fmgpfha1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09b6efdb606b25848684bc0eb58a37e3e28167cd"}, {"y": 120, "x": 320, "u": "https://preview.redd.it/4ore6fmgpfha1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f6c274b0b502a6bed9f9847eac4ea8cea6a5912"}, {"y": 240, "x": 640, "u": "https://preview.redd.it/4ore6fmgpfha1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ed79fb99ce908a96bfb716ad6c38548400ac046"}, {"y": 361, "x": 960, "u": "https://preview.redd.it/4ore6fmgpfha1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9247d75b877b9f085b427e0e8a7972730af04702"}, {"y": 406, "x": 1080, "u": "https://preview.redd.it/4ore6fmgpfha1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29babac8866dd1ee54dbf0b2673ec387cac4a677"}], "s": {"y": 527, "x": 1400, "u": "https://preview.redd.it/4ore6fmgpfha1.png?width=1400&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3c9533e3abbe780b9e952f93d55a00eba5f1d33b"}, "id": "4ore6fmgpfha1"}}, "name": "t3_10z4fkp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/kF5FkDIt2E9gIDWjavSDZz57RcuocToIEQbQBln_4D0.jpg", "edited": 1676067429.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1676066786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I would like to share with you my recent article about utilizing the power of a neuro-symbolic framework - PyNeuraLogic, to implement different kinds of Transformers, including the one used in GPT-3.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://towardsdatascience.com/beyond-transformers-with-pyneuralogic-10b70cdc5e45\"&gt;https://towardsdatascience.com/beyond-transformers-with-pyneuralogic-10b70cdc5e45&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I would appreciate any feedback down in the comments. Thank you.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4ore6fmgpfha1.png?width=1400&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3c9533e3abbe780b9e952f93d55a00eba5f1d33b\"&gt;https://preview.redd.it/4ore6fmgpfha1.png?width=1400&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3c9533e3abbe780b9e952f93d55a00eba5f1d33b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mNyNznpzUQ1m0wbw25hrld8EgC1oxNvRDZFEreeDK3U.jpg?auto=webp&amp;v=enabled&amp;s=aa6af6d83bec6937177a8a85043eb9af736068bc", "width": 1200, "height": 451}, "resolutions": [{"url": "https://external-preview.redd.it/mNyNznpzUQ1m0wbw25hrld8EgC1oxNvRDZFEreeDK3U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bafdbe1ebdaeb30601621672a74b23a114206263", "width": 108, "height": 40}, {"url": "https://external-preview.redd.it/mNyNznpzUQ1m0wbw25hrld8EgC1oxNvRDZFEreeDK3U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e23249fc69af6c8267a8c8c73c52b2d1d88c52ad", "width": 216, "height": 81}, {"url": "https://external-preview.redd.it/mNyNznpzUQ1m0wbw25hrld8EgC1oxNvRDZFEreeDK3U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd6eaccf518033dedbfc7185e6a4e83026356c1a", "width": 320, "height": 120}, {"url": "https://external-preview.redd.it/mNyNznpzUQ1m0wbw25hrld8EgC1oxNvRDZFEreeDK3U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=12460ba6ac208def8e4bae55de2feb7f40c0093d", "width": 640, "height": 240}, {"url": "https://external-preview.redd.it/mNyNznpzUQ1m0wbw25hrld8EgC1oxNvRDZFEreeDK3U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a78ca22e64d882fbeb3b64444efa0b2f491cc801", "width": 960, "height": 360}, {"url": "https://external-preview.redd.it/mNyNznpzUQ1m0wbw25hrld8EgC1oxNvRDZFEreeDK3U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=314ca8ee70b0ec4a0b49462500721f694c149569", "width": 1080, "height": 405}], "variants": {}, "id": "wT02XSnDEOFTwrOx1mE7EaKqAOU8sODC8M0Mw0R1OHM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10z4fkp", "is_robot_indexable": true, "report_reasons": null, "author": "Lukas_Zahradnik", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10z4fkp/beyond_transformers_with_a_neurosymbolic_framework/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10z4fkp/beyond_transformers_with_a_neurosymbolic_framework/", "subreddit_subscribers": 846834, "created_utc": 1676066786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys I have very minimal (1.5 years) of experience in DS. That was from a Fintech company. \n\nNow after pursuing my masters I'm applying for jobs again. \n\nBut I'm finding that most, if not all of the interview requests are coming from fintech companies. \n\nThe reason why I pursued masters was to change the industry I worked in. \n\nI want to get into medicine industry. Kind of like biostatistics to be precise. I want to work on huge govt health datasets and help guide the decision making. \n\nI have done MOOCs and courses online about biostats and to show that I have knowledge of biology/medicine. \n\nAnd yet, it feels very hard to change the industry. \n\nDo you guys have any suggestions? So that atleast I get responses from health sector... I am at a point where I'm willing to get paid less than what I was getting in my previous role. But I know that this is the sector where I want to utilize my skills in.\n\nThanks in advance.", "author_fullname": "t2_jo4irqsu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to escape industry typecasting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10zxpdh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676148939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys I have very minimal (1.5 years) of experience in DS. That was from a Fintech company. &lt;/p&gt;\n\n&lt;p&gt;Now after pursuing my masters I&amp;#39;m applying for jobs again. &lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m finding that most, if not all of the interview requests are coming from fintech companies. &lt;/p&gt;\n\n&lt;p&gt;The reason why I pursued masters was to change the industry I worked in. &lt;/p&gt;\n\n&lt;p&gt;I want to get into medicine industry. Kind of like biostatistics to be precise. I want to work on huge govt health datasets and help guide the decision making. &lt;/p&gt;\n\n&lt;p&gt;I have done MOOCs and courses online about biostats and to show that I have knowledge of biology/medicine. &lt;/p&gt;\n\n&lt;p&gt;And yet, it feels very hard to change the industry. &lt;/p&gt;\n\n&lt;p&gt;Do you guys have any suggestions? So that atleast I get responses from health sector... I am at a point where I&amp;#39;m willing to get paid less than what I was getting in my previous role. But I know that this is the sector where I want to utilize my skills in.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zxpdh", "is_robot_indexable": true, "report_reasons": null, "author": "thanderrine", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zxpdh/how_to_escape_industry_typecasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zxpdh/how_to_escape_industry_typecasting/", "subreddit_subscribers": 846834, "created_utc": 1676148939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://medium.com/p/f0c8176c9cbd](https://medium.com/p/f0c8176c9cbd)", "author_fullname": "t2_vb57b4y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Create a Basic AI ChatBot using Python in 5 Minutes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zv78a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676142424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/p/f0c8176c9cbd\"&gt;https://medium.com/p/f0c8176c9cbd&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_zDj6qhQ5sBRWcv8Ot8n_RZir1RC0TU6c9Rx9MFVt-E.jpg?auto=webp&amp;v=enabled&amp;s=188e30b4955fc3b96ca8815de6fdd6391a8d01c0", "width": 512, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/_zDj6qhQ5sBRWcv8Ot8n_RZir1RC0TU6c9Rx9MFVt-E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=feed1bf0ac31f57c1f2ad72f5374ea08c5ab4222", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/_zDj6qhQ5sBRWcv8Ot8n_RZir1RC0TU6c9Rx9MFVt-E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c3cb861dadc00e88011d31719e7247f0f0dabfc", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/_zDj6qhQ5sBRWcv8Ot8n_RZir1RC0TU6c9Rx9MFVt-E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a6572b921cd0e46249d38452f942078919226dd7", "width": 320, "height": 320}], "variants": {}, "id": "06t2xiXy1t3QCptshfc2a_qVbSkurnv85rZtoSP0DUg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zv78a", "is_robot_indexable": true, "report_reasons": null, "author": "Historical-Pen9653", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zv78a/how_to_create_a_basic_ai_chatbot_using_python_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zv78a/how_to_create_a_basic_ai_chatbot_using_python_in/", "subreddit_subscribers": 846834, "created_utc": 1676142424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to fine tune open ai's davinci-003 to write email campaigns based on data. The expected output is an email campaign wrapped in html as opposed to purely text based/content. I was thinking about using a colon delimitter between input variables (e.g some data : location : email address... ) Given the output is expected to be around 4000 tokens am I going about this all wrong? Do I need to shorten and simplify the expected output e.g. remove the html wrap, break the output into smaller chunks OR is this all within the scope of what is possible with enough training data?", "author_fullname": "t2_dc6jrdk6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How best to fine tune davnci-003?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zv42t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676142193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to fine tune open ai&amp;#39;s davinci-003 to write email campaigns based on data. The expected output is an email campaign wrapped in html as opposed to purely text based/content. I was thinking about using a colon delimitter between input variables (e.g some data : location : email address... ) Given the output is expected to be around 4000 tokens am I going about this all wrong? Do I need to shorten and simplify the expected output e.g. remove the html wrap, break the output into smaller chunks OR is this all within the scope of what is possible with enough training data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zv42t", "is_robot_indexable": true, "report_reasons": null, "author": "GreatStats4ItsCost", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zv42t/how_best_to_fine_tune_davnci003/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zv42t/how_best_to_fine_tune_davnci003/", "subreddit_subscribers": 846834, "created_utc": 1676142193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Given at how job listings look, I have a feeling that my future career will be in a data science or adjacent field. I am currently completing a BA in Econ and a BA in geography. I am between an MS  in ISOM and an MA in Econ. The [MS-ISOM curriculum](https://warrington.ufl.edu/master-of-science-in-information-systems-and-operations-management/courses-and-curriculum/) can be found here and the [Econ MA curriculum](https://economics.clas.ufl.edu/academics/curriculum/) can be found here. I was hoping for some advice on which program to peruse to best prepare me for a future with data.", "author_fullname": "t2_nbgc9pco", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Currently in undergrad and need advice on a masters program.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zsz32", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676136698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Given at how job listings look, I have a feeling that my future career will be in a data science or adjacent field. I am currently completing a BA in Econ and a BA in geography. I am between an MS  in ISOM and an MA in Econ. The &lt;a href=\"https://warrington.ufl.edu/master-of-science-in-information-systems-and-operations-management/courses-and-curriculum/\"&gt;MS-ISOM curriculum&lt;/a&gt; can be found here and the &lt;a href=\"https://economics.clas.ufl.edu/academics/curriculum/\"&gt;Econ MA curriculum&lt;/a&gt; can be found here. I was hoping for some advice on which program to peruse to best prepare me for a future with data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zsz32", "is_robot_indexable": true, "report_reasons": null, "author": "Brief_Piglet3241", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zsz32/currently_in_undergrad_and_need_advice_on_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zsz32/currently_in_undergrad_and_need_advice_on_a/", "subreddit_subscribers": 846834, "created_utc": 1676136698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI want to write my own script (?) to export metrics from various social media platforms to Google Spreadsheets. None of the existing tools seem to answer my data analytics questions. \n\nI wonder where I should start, which programming language I should use, etc.\n\nAny advice is appreciated!", "author_fullname": "t2_rycrd8ah", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Instagram API to Google Spreadsheets: How to program yourself?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zmlid", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676118805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I want to write my own script (?) to export metrics from various social media platforms to Google Spreadsheets. None of the existing tools seem to answer my data analytics questions. &lt;/p&gt;\n\n&lt;p&gt;I wonder where I should start, which programming language I should use, etc.&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zmlid", "is_robot_indexable": true, "report_reasons": null, "author": "Own_Island5749", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zmlid/instagram_api_to_google_spreadsheets_how_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zmlid/instagram_api_to_google_spreadsheets_how_to/", "subreddit_subscribers": 846834, "created_utc": 1676118805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Interviewing for DS/ML position what part of the interview did you like? Or was there a companies interview process that was very memorable?", "author_fullname": "t2_50nc8p00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What was your best interview experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zb1vl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676086254.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Interviewing for DS/ML position what part of the interview did you like? Or was there a companies interview process that was very memorable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10zb1vl", "is_robot_indexable": true, "report_reasons": null, "author": "IwantSpaceX", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10zb1vl/what_was_your_best_interview_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10zb1vl/what_was_your_best_interview_experience/", "subreddit_subscribers": 846834, "created_utc": 1676086254.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi!\n\nFor work I need to analyse 52 workbooks with 5 sheets per workbook. I need to add everything into one workbook so that me and my boss can analyse the data.\n\nThe data however is a bit messy. The first two rows contain headers that I need, but the second header needs to be turned into columns to measure the hours spend on something per name. There is also data under the screenshot that is not needed, but that data is in different rows every sheet.\n\nThere are no tables in the sheets, only some visible formatting but no data formatting.\n\nThe screenshot is one example of a sheet from the workbooks i need to analyse. Every sheet contain about 100 rows and 30 columns, but the amount of rows is different for each sheet.\n\nI've tried analysing with Power Query, then python and started to think about SQL when I couldn't figure it out.\n\nI'm a bit stuck about making the decision which language to use. If some of you could point me in the right direction I can continue and be on my way. I'm just startin to doubt myself and my method.\n\nWould you recommend using Python, SQL, Power Query or something different?\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/rwp3ho4k9gha1.png?width=1854&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a1a0fcbce39be34be8b992e447e6e346da87709e", "author_fullname": "t2_gngsym6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which language/method to use", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 16, "top_awarded_type": null, "hide_score": false, "media_metadata": {"rwp3ho4k9gha1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 12, "x": 108, "u": "https://preview.redd.it/rwp3ho4k9gha1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7acad756d4c54ca525d43890601a8276695ff2f0"}, {"y": 25, "x": 216, "u": "https://preview.redd.it/rwp3ho4k9gha1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c789618ca5984894f7c436d3ec7cfc8acd908fc8"}, {"y": 37, "x": 320, "u": "https://preview.redd.it/rwp3ho4k9gha1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=138425ca38449768b4fa46b34b0f935d0231c6bc"}, {"y": 74, "x": 640, "u": "https://preview.redd.it/rwp3ho4k9gha1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b4e37cd92278abb0b85d84575cde4703a84b63ba"}, {"y": 111, "x": 960, "u": "https://preview.redd.it/rwp3ho4k9gha1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41e3beb985a3d6ba31206263fc15107dc9d54916"}, {"y": 125, "x": 1080, "u": "https://preview.redd.it/rwp3ho4k9gha1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea7483c042c800ceb7ea05a3acd715f390bc5cc6"}], "s": {"y": 215, "x": 1854, "u": "https://preview.redd.it/rwp3ho4k9gha1.png?width=1854&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a1a0fcbce39be34be8b992e447e6e346da87709e"}, "id": "rwp3ho4k9gha1"}}, "name": "t3_10z6hui", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Zq8wY1GH6chtzXBov0eOqwL3YL7HOZkEX9TFJJ39hes.jpg", "edited": 1676073515.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676072543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;For work I need to analyse 52 workbooks with 5 sheets per workbook. I need to add everything into one workbook so that me and my boss can analyse the data.&lt;/p&gt;\n\n&lt;p&gt;The data however is a bit messy. The first two rows contain headers that I need, but the second header needs to be turned into columns to measure the hours spend on something per name. There is also data under the screenshot that is not needed, but that data is in different rows every sheet.&lt;/p&gt;\n\n&lt;p&gt;There are no tables in the sheets, only some visible formatting but no data formatting.&lt;/p&gt;\n\n&lt;p&gt;The screenshot is one example of a sheet from the workbooks i need to analyse. Every sheet contain about 100 rows and 30 columns, but the amount of rows is different for each sheet.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried analysing with Power Query, then python and started to think about SQL when I couldn&amp;#39;t figure it out.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a bit stuck about making the decision which language to use. If some of you could point me in the right direction I can continue and be on my way. I&amp;#39;m just startin to doubt myself and my method.&lt;/p&gt;\n\n&lt;p&gt;Would you recommend using Python, SQL, Power Query or something different?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rwp3ho4k9gha1.png?width=1854&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a1a0fcbce39be34be8b992e447e6e346da87709e\"&gt;https://preview.redd.it/rwp3ho4k9gha1.png?width=1854&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a1a0fcbce39be34be8b992e447e6e346da87709e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10z6hui", "is_robot_indexable": true, "report_reasons": null, "author": "forexslettt", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10z6hui/which_languagemethod_to_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10z6hui/which_languagemethod_to_use/", "subreddit_subscribers": 846834, "created_utc": 1676072543.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}