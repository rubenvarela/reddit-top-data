{"kind": "Listing", "data": {"after": "t3_110scdj", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Side projects? Reading? Courses?\n\nAs someone with no formal background in SWE/tech, most of my improvement has come from the desire to learn more about things. Not the most structured approach though, just curious to know how everyone else keeps their skills sharp!", "author_fullname": "t2_15ztlh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you personally do to improve as a DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110gth0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 93, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 93, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676211704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Side projects? Reading? Courses?&lt;/p&gt;\n\n&lt;p&gt;As someone with no formal background in SWE/tech, most of my improvement has come from the desire to learn more about things. Not the most structured approach though, just curious to know how everyone else keeps their skills sharp!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110gth0", "is_robot_indexable": true, "report_reasons": null, "author": "rlyply", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110gth0/what_do_you_personally_do_to_improve_as_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110gth0/what_do_you_personally_do_to_improve_as_a_de/", "subreddit_subscribers": 89440, "created_utc": 1676211704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, my friend wants to learn SQL what would you recommend as the best way of learning SQL ?", "author_fullname": "t2_3xupopvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL tips", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110hva6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676214594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, my friend wants to learn SQL what would you recommend as the best way of learning SQL ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "110hva6", "is_robot_indexable": true, "report_reasons": null, "author": "Sulaiman_m97", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110hva6/sql_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110hva6/sql_tips/", "subreddit_subscribers": 89440, "created_utc": 1676214594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm at the point in my learning where I need to pick between AWS, GCP, or Azure to learn and get certified in. However, I'm not sure which one is the best first pick.\n\nI don't work for a company, and I am not currently applying for jobs at one. I am trying to build up my skill set so that I can begin applying for entry level jobs soon.", "author_fullname": "t2_ny5wu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help deciding which cloud service to learn first", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110ux8l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676248624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m at the point in my learning where I need to pick between AWS, GCP, or Azure to learn and get certified in. However, I&amp;#39;m not sure which one is the best first pick.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t work for a company, and I am not currently applying for jobs at one. I am trying to build up my skill set so that I can begin applying for entry level jobs soon.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110ux8l", "is_robot_indexable": true, "report_reasons": null, "author": "CoronaBlue", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110ux8l/help_deciding_which_cloud_service_to_learn_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110ux8l/help_deciding_which_cloud_service_to_learn_first/", "subreddit_subscribers": 89440, "created_utc": 1676248624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nCurrently my org is making a strategic move from a onprem solution to the Azure Public Cloud.\n\nThe current onprem datawarehouse has a few limited usecases and can be identified as small. Its based on SQL SP + SSIS, with views on top of the datamart which joins all the needed data together for PowerBI.\n\nThe datawarehouse will probaly grow in the longer term to more different kind of usecases then only reporting. Think about statistiscal models in Python &amp; scenario simulations &amp; other analysis not known yet.\n\nIn regards of sheer datasize its all really limited( Max  5 mil records a day) Types of Datafeeds are API\"s or SFTP's.\n\n So what is a good dataplatform setup for these kind of usecases in the Azure Cloud? Powerbi is the chosen reporting tool already.\n\n1. Snowflake: Not an option due to regulatory compliance\n2: ADL gen 2 + Databricks: maybe overkill for the given amount of data? But python and R can be excuted on the same dataset as our reports which is a + in terms of auditablility and one dataplatform for the organisation.\n3. Synapse: No clue, same overkill?\n4. Azure SQL server + ADF: is this futute proof for also more potential advanced usecases?\n\nI would like to have 1 generic envoirement where we can implement all our dataproducts and make then available for the organisation.\n\nP.s. there is no technical knowledge currently avalaible in the org. So in terms of choosing the stack it doesnt matter", "author_fullname": "t2_mv3d8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving OnPrem to Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1112tdq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676274940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Currently my org is making a strategic move from a onprem solution to the Azure Public Cloud.&lt;/p&gt;\n\n&lt;p&gt;The current onprem datawarehouse has a few limited usecases and can be identified as small. Its based on SQL SP + SSIS, with views on top of the datamart which joins all the needed data together for PowerBI.&lt;/p&gt;\n\n&lt;p&gt;The datawarehouse will probaly grow in the longer term to more different kind of usecases then only reporting. Think about statistiscal models in Python &amp;amp; scenario simulations &amp;amp; other analysis not known yet.&lt;/p&gt;\n\n&lt;p&gt;In regards of sheer datasize its all really limited( Max  5 mil records a day) Types of Datafeeds are API&amp;quot;s or SFTP&amp;#39;s.&lt;/p&gt;\n\n&lt;p&gt;So what is a good dataplatform setup for these kind of usecases in the Azure Cloud? Powerbi is the chosen reporting tool already.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Snowflake: Not an option due to regulatory compliance\n2: ADL gen 2 + Databricks: maybe overkill for the given amount of data? But python and R can be excuted on the same dataset as our reports which is a + in terms of auditablility and one dataplatform for the organisation.&lt;/li&gt;\n&lt;li&gt;Synapse: No clue, same overkill?&lt;/li&gt;\n&lt;li&gt;Azure SQL server + ADF: is this futute proof for also more potential advanced usecases?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I would like to have 1 generic envoirement where we can implement all our dataproducts and make then available for the organisation.&lt;/p&gt;\n\n&lt;p&gt;P.s. there is no technical knowledge currently avalaible in the org. So in terms of choosing the stack it doesnt matter&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1112tdq", "is_robot_indexable": true, "report_reasons": null, "author": "artopaper", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1112tdq/moving_onprem_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1112tdq/moving_onprem_to_cloud/", "subreddit_subscribers": 89440, "created_utc": 1676274940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to build a project portfolio but not sure where to commit. Thank you for the suggestions in advance.", "author_fullname": "t2_m9qt65bk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling to find practice projects. Is Leetcode good enough?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110o9s2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676230848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to build a project portfolio but not sure where to commit. Thank you for the suggestions in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110o9s2", "is_robot_indexable": true, "report_reasons": null, "author": "beakyblindar", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110o9s2/struggling_to_find_practice_projects_is_leetcode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110o9s2/struggling_to_find_practice_projects_is_leetcode/", "subreddit_subscribers": 89440, "created_utc": 1676230848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Folks,   \nWhat are some of the best CDC options available? How schema changes are handled in CDC?  \nDo we need to dedup data once data is written at S3? How deletes are handled?", "author_fullname": "t2_sr3rc27q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CDC Implementation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110jbvv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676218401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Folks,&lt;br/&gt;\nWhat are some of the best CDC options available? How schema changes are handled in CDC?&lt;br/&gt;\nDo we need to dedup data once data is written at S3? How deletes are handled?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110jbvv", "is_robot_indexable": true, "report_reasons": null, "author": "honey12123", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/110jbvv/cdc_implementation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110jbvv/cdc_implementation/", "subreddit_subscribers": 89440, "created_utc": 1676218401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen them floating around the industry. They strike me as a slightly modern Palantir/IBM consultant oriented shop. But Google is partnering with them to use their GPT-3 competitor in their products so I was curious what their products even are/do.\n\nAnyone have experience with it?", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone use any c3.ai products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1111vos", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676271268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen them floating around the industry. They strike me as a slightly modern Palantir/IBM consultant oriented shop. But Google is partnering with them to use their GPT-3 competitor in their products so I was curious what their products even are/do.&lt;/p&gt;\n\n&lt;p&gt;Anyone have experience with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1111vos", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1111vos/anyone_use_any_c3ai_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1111vos/anyone_use_any_c3ai_products/", "subreddit_subscribers": 89440, "created_utc": 1676271268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m pretty new to this, so I apologise if I\u2019m not asking the question in the right way.  But say I have a Parquet table, and in storage, it\u2019s saved in 3 parts. Next, I have a Databricks compute with autoscaling that is reading data from the table. For one read activity on that single table from Databricks, will that count as 1 read, or would it be 3 reads (one for each parquet part file)? Also, since Databricks uses distributed compute, could there be multiple caller IPs for one read activity, or does it count as one based on driver node? Does this mean, if Databricks was scaled to 3 workers, (plus a driver), one read on one table could count as 3 part files x 4 compute = 12 read activities?", "author_fullname": "t2_59ggcmrq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does Log Analytics count read activities to Parquet files in ADLSg2 from distributed compute, such as Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11118td", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676268880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m pretty new to this, so I apologise if I\u2019m not asking the question in the right way.  But say I have a Parquet table, and in storage, it\u2019s saved in 3 parts. Next, I have a Databricks compute with autoscaling that is reading data from the table. For one read activity on that single table from Databricks, will that count as 1 read, or would it be 3 reads (one for each parquet part file)? Also, since Databricks uses distributed compute, could there be multiple caller IPs for one read activity, or does it count as one based on driver node? Does this mean, if Databricks was scaled to 3 workers, (plus a driver), one read on one table could count as 3 part files x 4 compute = 12 read activities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11118td", "is_robot_indexable": true, "report_reasons": null, "author": "jinbe-san", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11118td/how_does_log_analytics_count_read_activities_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11118td/how_does_log_analytics_count_read_activities_to/", "subreddit_subscribers": 89440, "created_utc": 1676268880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to come up with a data model where customer can have multiple subscriptions and  subscription is just a type of many other products, so when customer buys  subscription then product with type subscription is being added to the  order and order has a payment fk. When payment is successful then  subscription is added to the subscription table with (user fk, order fk,  start date, end date, price, is\\_active).\n\nBut how to approach subscription recurring payment?\n\n1. Since  subscription is a product that is part of the order, should new ordered  and new payment be created every time when subscription recurring payment happens?\n2. Or  should subscription have 1:m relationship with payment tbl, and only  new payment should be created on the subscription renewal? but this  approach seem little weird since initial subscription purchase payment  was in the order table.\n\nHow to go about it?", "author_fullname": "t2_glxz8l6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you model multiple subscriptions if subscription is a type of a product?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111171s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676268685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to come up with a data model where customer can have multiple subscriptions and  subscription is just a type of many other products, so when customer buys  subscription then product with type subscription is being added to the  order and order has a payment fk. When payment is successful then  subscription is added to the subscription table with (user fk, order fk,  start date, end date, price, is_active).&lt;/p&gt;\n\n&lt;p&gt;But how to approach subscription recurring payment?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Since  subscription is a product that is part of the order, should new ordered  and new payment be created every time when subscription recurring payment happens?&lt;/li&gt;\n&lt;li&gt;Or  should subscription have 1:m relationship with payment tbl, and only  new payment should be created on the subscription renewal? but this  approach seem little weird since initial subscription purchase payment  was in the order table.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;How to go about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "111171s", "is_robot_indexable": true, "report_reasons": null, "author": "No-Race8789", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/111171s/how_do_you_model_multiple_subscriptions_if/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/111171s/how_do_you_model_multiple_subscriptions_if/", "subreddit_subscribers": 89440, "created_utc": 1676268685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From reading through this sub and articles like [this](https://medium.com/bluecore-engineering/were-all-using-airflow-wrong-and-how-to-fix-it-a56f14cb0753), there's definitely arguments for containerizing all Airflow tasks to separate execution logic from orchestration logic. Whether it's easier onboarding of new devs, package conflicts between tasks, simpler debugging, etc., it all sounds great in theory. But I'm curious how many teams actually build their DAGs like this and whether it's worth it?\n\n[View Poll](https://www.reddit.com/poll/110qo3h)", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you execute all Airflow tasks in containers to separate execution logic from orchestration logic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110qo3h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676236961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From reading through this sub and articles like &lt;a href=\"https://medium.com/bluecore-engineering/were-all-using-airflow-wrong-and-how-to-fix-it-a56f14cb0753\"&gt;this&lt;/a&gt;, there&amp;#39;s definitely arguments for containerizing all Airflow tasks to separate execution logic from orchestration logic. Whether it&amp;#39;s easier onboarding of new devs, package conflicts between tasks, simpler debugging, etc., it all sounds great in theory. But I&amp;#39;m curious how many teams actually build their DAGs like this and whether it&amp;#39;s worth it?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/110qo3h\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?auto=webp&amp;v=enabled&amp;s=c4c33040015af6b9b895354919a038471d8ebd2d", "width": 752, "height": 427}, "resolutions": [{"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00c7c68e97652e6b3530ab5eba5ea327b38a8942", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=943e5fa8fa60e636733f063d1d720572ccbc59a4", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=040eb5e59874649b8347f423c89e973bd8cc13e8", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=daa1a474f8dfc6b5bb91f396ddd49601bc8a0a8c", "width": 640, "height": 363}], "variants": {}, "id": "sf2SA2a5dF3sFQeNi3Z_FOLTkemkNklRDj4S8DgYVz0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110qo3h", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1676668961870, "options": [{"text": "Yes we containerize and it's worth it", "id": "21568710"}, {"text": "Yes we containerize but it's not worth it", "id": "21568711"}, {"text": "No we don't containerize but we're interested", "id": "21568712"}, {"text": "No we don't containerize and we're not interested", "id": "21568713"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 96, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110qo3h/do_you_execute_all_airflow_tasks_in_containers_to/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/110qo3h/do_you_execute_all_airflow_tasks_in_containers_to/", "subreddit_subscribers": 89440, "created_utc": 1676236961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I\u2019ve been working with my company as a data engineer in our business intelligence department for the last 3 years. Over the last 3 years our team has been severely neglected by our leadership causing many people in my team to move to new opportunities. This has lead to my team being over worked and underpaid (making $81k in austin) I can never find time to work on projects as I\u2019m constantly being pulled into fire drills due to bad data in Salesforce. \n\nOur current infrastructure is SSMS enterprise data warehouse using SSIS and SSAS cubes. There are plans for our team to move to the cloud but with my current leadership, I don\u2019t see the move to cloud happening anytime soon. I\u2019ve also build data pipelines using python and pulling data from source system apis\n\nI really would like to move to a new company but in job listings I feel like everyone is only looking for DEs that work with different cloud technologies.\n\nI was wondering if anyone could give me advice on ways I can make myself more appealing to employers. Any recommendations are helpful from courses to certifications would be greatly appreciated.", "author_fullname": "t2_2jf9pj50", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help moving to a cloud base DE role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110pk9f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676234132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019ve been working with my company as a data engineer in our business intelligence department for the last 3 years. Over the last 3 years our team has been severely neglected by our leadership causing many people in my team to move to new opportunities. This has lead to my team being over worked and underpaid (making $81k in austin) I can never find time to work on projects as I\u2019m constantly being pulled into fire drills due to bad data in Salesforce. &lt;/p&gt;\n\n&lt;p&gt;Our current infrastructure is SSMS enterprise data warehouse using SSIS and SSAS cubes. There are plans for our team to move to the cloud but with my current leadership, I don\u2019t see the move to cloud happening anytime soon. I\u2019ve also build data pipelines using python and pulling data from source system apis&lt;/p&gt;\n\n&lt;p&gt;I really would like to move to a new company but in job listings I feel like everyone is only looking for DEs that work with different cloud technologies.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone could give me advice on ways I can make myself more appealing to employers. Any recommendations are helpful from courses to certifications would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110pk9f", "is_robot_indexable": true, "report_reasons": null, "author": "DankBoyardee", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110pk9f/help_moving_to_a_cloud_base_de_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110pk9f/help_moving_to_a_cloud_base_de_role/", "subreddit_subscribers": 89440, "created_utc": 1676234132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I come from a DE batch project where Events trigger Lambdas, which trigger Step Functions to run all the batch pipelines. I was thinking how to replace Step Functions with Apache Airflow, so I was looking for an example architecture which combines events and Lambda functions to trigger Airflow pipelines. Do you have any reference which I could find useful? Many thanks", "author_fullname": "t2_v3ifff74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(AWS) Events, lambda and Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1115ab2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676284660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I come from a DE batch project where Events trigger Lambdas, which trigger Step Functions to run all the batch pipelines. I was thinking how to replace Step Functions with Apache Airflow, so I was looking for an example architecture which combines events and Lambda functions to trigger Airflow pipelines. Do you have any reference which I could find useful? Many thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1115ab2", "is_robot_indexable": true, "report_reasons": null, "author": "kaismd", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1115ab2/aws_events_lambda_and_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1115ab2/aws_events_lambda_and_airflow/", "subreddit_subscribers": 89440, "created_utc": 1676284660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI have a DW running on On Prem MS SQL. It's a very small setup, around 50 tables, less than 10 sources and no more than 15GB of data at the moment. I'm extracting with python and some IaaS. I load the data in source db, transform in stage db and then load to prod db.\n\nThe DW is still in development, mostly because there is a complete lack of governance when it comes to business process best practices (Lost battle for now, don't even get me started). So once in a while, someone would manage to get out of their way to break some business logic. When this happens, I would just manually fix the affected rows if they are just a few, or just rebuild the table if they are many. And of course I would change my code to include this new case.\n\nThe question is, how can I logically roll back to the previous batch?  I couldn't find anything online.\n\nI hope this made sense.", "author_fullname": "t2_83poggkq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse roll back table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1114jeb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676281807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have a DW running on On Prem MS SQL. It&amp;#39;s a very small setup, around 50 tables, less than 10 sources and no more than 15GB of data at the moment. I&amp;#39;m extracting with python and some IaaS. I load the data in source db, transform in stage db and then load to prod db.&lt;/p&gt;\n\n&lt;p&gt;The DW is still in development, mostly because there is a complete lack of governance when it comes to business process best practices (Lost battle for now, don&amp;#39;t even get me started). So once in a while, someone would manage to get out of their way to break some business logic. When this happens, I would just manually fix the affected rows if they are just a few, or just rebuild the table if they are many. And of course I would change my code to include this new case.&lt;/p&gt;\n\n&lt;p&gt;The question is, how can I logically roll back to the previous batch?  I couldn&amp;#39;t find anything online.&lt;/p&gt;\n\n&lt;p&gt;I hope this made sense.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1114jeb", "is_robot_indexable": true, "report_reasons": null, "author": "Ancient-Entry-6436", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1114jeb/data_warehouse_roll_back_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1114jeb/data_warehouse_roll_back_table/", "subreddit_subscribers": 89440, "created_utc": 1676281807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm just running some labs with Azure Synapse and Databricks on Azure and I wanted someone to validate whether this would be a solid pipeline.  The source is a Postgres db.\n\nExtract: Synapse Pipelines Copy Activity to Azure Data Lake Gen 2 Storage\n\nTransformation: Azure Databricks notebook triggered by Synapse Pipelines. Databricks notebook would be written in PySpark.\n\nLoad: Databricks notebook loads transformed data into Synapse dedicated SQL pool\n\n&amp;#x200B;\n\nAm I missing any steps here? Can Databricks directly load transformed data into a Synapse Dedicated SQL pool?", "author_fullname": "t2_nhdew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Validate my Azure Synapse/Databricks pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110rr24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676239793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m just running some labs with Azure Synapse and Databricks on Azure and I wanted someone to validate whether this would be a solid pipeline.  The source is a Postgres db.&lt;/p&gt;\n\n&lt;p&gt;Extract: Synapse Pipelines Copy Activity to Azure Data Lake Gen 2 Storage&lt;/p&gt;\n\n&lt;p&gt;Transformation: Azure Databricks notebook triggered by Synapse Pipelines. Databricks notebook would be written in PySpark.&lt;/p&gt;\n\n&lt;p&gt;Load: Databricks notebook loads transformed data into Synapse dedicated SQL pool&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Am I missing any steps here? Can Databricks directly load transformed data into a Synapse Dedicated SQL pool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110rr24", "is_robot_indexable": true, "report_reasons": null, "author": "MonkeyMaster64", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110rr24/validate_my_azure_synapsedatabricks_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110rr24/validate_my_azure_synapsedatabricks_pipeline/", "subreddit_subscribers": 89440, "created_utc": 1676239793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would someone kindly let me know whether they have experience working in the supply chain as a data engineer? If so, what is their daily work look like! \nWhat kind of tool you are using and for which purpose!", "author_fullname": "t2_m6lk62t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Role of a Data engineer in a supply chain org !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110nqwv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676229502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would someone kindly let me know whether they have experience working in the supply chain as a data engineer? If so, what is their daily work look like! \nWhat kind of tool you are using and for which purpose!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "110nqwv", "is_robot_indexable": true, "report_reasons": null, "author": "TelevisionDue5491", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110nqwv/role_of_a_data_engineer_in_a_supply_chain_org/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110nqwv/role_of_a_data_engineer_in_a_supply_chain_org/", "subreddit_subscribers": 89440, "created_utc": 1676229502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am 6 year experienced data engineer have worked over last few years on \\[MSBI, tableau , oracle, spark, CDH, various vendor specific pipeline, ES , kibana and little bit on API side as well, but haven't got a chance to work on streaming problems much except few learning POC's and neither in future there is any scope of it. Can you guys please tell how much important it is to know various streaming at scale in production ?, is it that people with hands on streaming problem statements are paid more and preferred in interview ? . I belong from very poor family and have made only limited savings yet, so job safety and money are important to me currently.", "author_fullname": "t2_fftrw7s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "knowledge of Streaming system for data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110lel5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676223610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am 6 year experienced data engineer have worked over last few years on [MSBI, tableau , oracle, spark, CDH, various vendor specific pipeline, ES , kibana and little bit on API side as well, but haven&amp;#39;t got a chance to work on streaming problems much except few learning POC&amp;#39;s and neither in future there is any scope of it. Can you guys please tell how much important it is to know various streaming at scale in production ?, is it that people with hands on streaming problem statements are paid more and preferred in interview ? . I belong from very poor family and have made only limited savings yet, so job safety and money are important to me currently.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "110lel5", "is_robot_indexable": true, "report_reasons": null, "author": "No-Position1673", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110lel5/knowledge_of_streaming_system_for_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110lel5/knowledge_of_streaming_system_for_data_engineer/", "subreddit_subscribers": 89440, "created_utc": 1676223610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company we use jdbcoperator to transform and upload data.\nHowever it would be very useful to see in the logs information like \u201cupdated rows #\u201d after merge or \u201c# of rows\u201d for newly created tables (in particular temporary tables).\n\nI know I can extract those info through a query and output on the logs but is there a more Airflowic way to do so?", "author_fullname": "t2_e4qv08k8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow JdbcOperator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11169ft", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676288474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company we use jdbcoperator to transform and upload data.\nHowever it would be very useful to see in the logs information like \u201cupdated rows #\u201d after merge or \u201c# of rows\u201d for newly created tables (in particular temporary tables).&lt;/p&gt;\n\n&lt;p&gt;I know I can extract those info through a query and output on the logs but is there a more Airflowic way to do so?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11169ft", "is_robot_indexable": true, "report_reasons": null, "author": "Busy_Elderberry8650", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11169ft/airflow_jdbcoperator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11169ft/airflow_jdbcoperator/", "subreddit_subscribers": 89440, "created_utc": 1676288474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi - am looking at ingesting data to s3 from tools like Salesforce.  \n\nI was looking at Airbyte, and then also saw AppFlow.  Any thoughts on tradeoffs?  I was keen on also trying dbt, how do you do that with AppFlow?", "author_fullname": "t2_5gzu4ur4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AppFlow vs Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1115zay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676287394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi - am looking at ingesting data to s3 from tools like Salesforce.  &lt;/p&gt;\n\n&lt;p&gt;I was looking at Airbyte, and then also saw AppFlow.  Any thoughts on tradeoffs?  I was keen on also trying dbt, how do you do that with AppFlow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1115zay", "is_robot_indexable": true, "report_reasons": null, "author": "bluezebra42", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1115zay/appflow_vs_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1115zay/appflow_vs_airbyte/", "subreddit_subscribers": 89440, "created_utc": 1676287394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " So, as title, I have to create an ETL from a Server that overwrites data twice a day. The only solution I have for now to be sure of not losing any data is to run the ETL twice for every overwriting, so 4 times a day. How would you approach such a case?", "author_fullname": "t2_82dwrpz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with data that gets overwrited every time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1115wp6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676287122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, as title, I have to create an ETL from a Server that overwrites data twice a day. The only solution I have for now to be sure of not losing any data is to run the ETL twice for every overwriting, so 4 times a day. How would you approach such a case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1115wp6", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Ad-8440", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1115wp6/how_to_deal_with_data_that_gets_overwrited_every/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1115wp6/how_to_deal_with_data_that_gets_overwrited_every/", "subreddit_subscribers": 89440, "created_utc": 1676287122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in a Manager position at my company and work at a client. I work mostly on the requirements side as a Business Analyst for Data Analytics products (Management Dashboards).\n\nI have two people who report to me and lead a team for ensuring we build what the client asked for.\n\nI do not enjoy it for the sole reason that I do not own any portion of the product. Even requirements are pre-gathered by the client and I make sure on feasibility and looking for gaps. \n\nMy tech skills stop at SQL and how dashboards are built (data views, calcs, and design). But I am an expert in understanding business needs and getting teams to build it. \n\nI make ~120K outside of a HCOL area. 6 YOE. \n\nWith my deep analytics experience, and basic SQL, money wise is it worth it to go the DE route? Would I have to start at the Entry level spot? Or ride the management path and never do the actual building of anything?", "author_fullname": "t2_9630n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition to Data Engineer from a Data Analytics/Business Analyst manager position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110rbqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676239190.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676238661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in a Manager position at my company and work at a client. I work mostly on the requirements side as a Business Analyst for Data Analytics products (Management Dashboards).&lt;/p&gt;\n\n&lt;p&gt;I have two people who report to me and lead a team for ensuring we build what the client asked for.&lt;/p&gt;\n\n&lt;p&gt;I do not enjoy it for the sole reason that I do not own any portion of the product. Even requirements are pre-gathered by the client and I make sure on feasibility and looking for gaps. &lt;/p&gt;\n\n&lt;p&gt;My tech skills stop at SQL and how dashboards are built (data views, calcs, and design). But I am an expert in understanding business needs and getting teams to build it. &lt;/p&gt;\n\n&lt;p&gt;I make ~120K outside of a HCOL area. 6 YOE. &lt;/p&gt;\n\n&lt;p&gt;With my deep analytics experience, and basic SQL, money wise is it worth it to go the DE route? Would I have to start at the Entry level spot? Or ride the management path and never do the actual building of anything?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "110rbqx", "is_robot_indexable": true, "report_reasons": null, "author": "Amanlikeyou", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110rbqx/transition_to_data_engineer_from_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110rbqx/transition_to_data_engineer_from_a_data/", "subreddit_subscribers": 89440, "created_utc": 1676238661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say you have an ELT pipeline that moves data from a source system with CDC to a DWH (e.g. BigQuery), and for some tables you use slowly changing dimension type 2.\n\nTherefore, for these tables, your DWH would have both the latest snapshot as well as all the history of the changes.\n\nOne day you decide to ditch BigQuery to move to a different platform, say Snowflake.\n\nHow do you seamlessly migrate your pipeline AND data to the new platform, while making sure to maintain the changes history?", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you migrate tables with SCD type 2 from one system to another?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110k9rf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676220799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you have an ELT pipeline that moves data from a source system with CDC to a DWH (e.g. BigQuery), and for some tables you use slowly changing dimension type 2.&lt;/p&gt;\n\n&lt;p&gt;Therefore, for these tables, your DWH would have both the latest snapshot as well as all the history of the changes.&lt;/p&gt;\n\n&lt;p&gt;One day you decide to ditch BigQuery to move to a different platform, say Snowflake.&lt;/p&gt;\n\n&lt;p&gt;How do you seamlessly migrate your pipeline AND data to the new platform, while making sure to maintain the changes history?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110k9rf", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110k9rf/how_do_you_migrate_tables_with_scd_type_2_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110k9rf/how_do_you_migrate_tables_with_scd_type_2_from/", "subreddit_subscribers": 89440, "created_utc": 1676220799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI'm new to Data Modelling and I'm currently stumped at a personal project. Allow me to give some context first.\n\nI have been given a preaggregated data set containing preorders at a daily level. Basically everyday I will get a flat file that has the summed up amounts of preorders by day (past, present and future), store, and product category. I don't have customer or product information. \n\nFor example, in the file from yesterday, I would have preorders slated for 13 May 2023 as 13, comprised of any unknown number of customers ordering any number of unknown products. Then when I get today's file, I will see that for 13 May 2023, I now have 5 preorders, meaning either some or all the customers from yesterday's 13 preorders probably cancelled or shifted their preorders to another unknown date. \n\nTo conplicate matters, if for preorder date of 13 May 2023, the amount of preorders went from 13 to 0, I would not get that row with preorder count = 0 in the new file. \n\nThe idea is to have this dataset feed a dashboard so that the end user can track the growth of preorders for any given date and store as time/year progresses.\n\nI looked into SCD2 but I'm not sure if this is the right approach for the task. Because for one, the preorders are facts and it is the facts that are changing, not dimensions, hence I thought slowly changing facts?\n\nAnother reason I think SCD2 is not right because I was told that I shouldn't be using the preorder column as a \"join condition/key\" to check whether or not a record changed (preorder date, store, category as composite keys) from one day's file to another day's file. Otherwise I think I would be doing this with some extra steps in addition to a Merge statement. \n\nSo I'm reaching out for help from all you gurus because I'm getting nowhere despite all the Googling. I'm trying to do this in SQL Server but will eventually move it to Snowflake.\n\nThank you in advance!", "author_fullname": "t2_iv0k1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Data Modelling, how to design for preorders that change as time progresses? Have you done slowly changing \"facts\" in SQL and how would you do it in this case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110ipjw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676216815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new to Data Modelling and I&amp;#39;m currently stumped at a personal project. Allow me to give some context first.&lt;/p&gt;\n\n&lt;p&gt;I have been given a preaggregated data set containing preorders at a daily level. Basically everyday I will get a flat file that has the summed up amounts of preorders by day (past, present and future), store, and product category. I don&amp;#39;t have customer or product information. &lt;/p&gt;\n\n&lt;p&gt;For example, in the file from yesterday, I would have preorders slated for 13 May 2023 as 13, comprised of any unknown number of customers ordering any number of unknown products. Then when I get today&amp;#39;s file, I will see that for 13 May 2023, I now have 5 preorders, meaning either some or all the customers from yesterday&amp;#39;s 13 preorders probably cancelled or shifted their preorders to another unknown date. &lt;/p&gt;\n\n&lt;p&gt;To conplicate matters, if for preorder date of 13 May 2023, the amount of preorders went from 13 to 0, I would not get that row with preorder count = 0 in the new file. &lt;/p&gt;\n\n&lt;p&gt;The idea is to have this dataset feed a dashboard so that the end user can track the growth of preorders for any given date and store as time/year progresses.&lt;/p&gt;\n\n&lt;p&gt;I looked into SCD2 but I&amp;#39;m not sure if this is the right approach for the task. Because for one, the preorders are facts and it is the facts that are changing, not dimensions, hence I thought slowly changing facts?&lt;/p&gt;\n\n&lt;p&gt;Another reason I think SCD2 is not right because I was told that I shouldn&amp;#39;t be using the preorder column as a &amp;quot;join condition/key&amp;quot; to check whether or not a record changed (preorder date, store, category as composite keys) from one day&amp;#39;s file to another day&amp;#39;s file. Otherwise I think I would be doing this with some extra steps in addition to a Merge statement. &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m reaching out for help from all you gurus because I&amp;#39;m getting nowhere despite all the Googling. I&amp;#39;m trying to do this in SQL Server but will eventually move it to Snowflake.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110ipjw", "is_robot_indexable": true, "report_reasons": null, "author": "RoyalStraightFlush", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110ipjw/new_to_data_modelling_how_to_design_for_preorders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110ipjw/new_to_data_modelling_how_to_design_for_preorders/", "subreddit_subscribers": 89440, "created_utc": 1676216815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Maybe it is because english is not my native language but I don't know what number to fill in in their [cost calculator](https://cost.airbyte.com/?_gl=1*yeje9n*_gcl_aw*R0NMLjE2NjI1MDQ3MTguQ2owS0NRanczOXVZQmhDTEFSSXNBRF9Tek1RRlJISDB2eTFKZzlLRldwRDI4OUl0SngtRzF0X3dOc2VKa1I5MThiTmtPT1g1OXl5cWxNVWFBaUFtRUFMd193Y0I.&amp;_ga=2.266664462.1256404185.1665036128-558301217.1646090235&amp;_gac=1.184557403.1662504717.Cj0KCQjw39uYBhCLARIsAD_SzMQFRHH0vy1Jg9KFWpD289ItJx-G1t_wNseJkR918bNkOOX59yyqlMUaAiAmEALw_wcB).\n\nIt says:  'Data to replicate from your database sources'. Does that mean the size of the database? Or the size of the new rows i want to (incrementally) sync each month?", "author_fullname": "t2_6bgrg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about the Airbyte cost calculator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110h36c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676212460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe it is because english is not my native language but I don&amp;#39;t know what number to fill in in their &lt;a href=\"https://cost.airbyte.com/?_gl=1*yeje9n*_gcl_aw*R0NMLjE2NjI1MDQ3MTguQ2owS0NRanczOXVZQmhDTEFSSXNBRF9Tek1RRlJISDB2eTFKZzlLRldwRDI4OUl0SngtRzF0X3dOc2VKa1I5MThiTmtPT1g1OXl5cWxNVWFBaUFtRUFMd193Y0I.&amp;amp;_ga=2.266664462.1256404185.1665036128-558301217.1646090235&amp;amp;_gac=1.184557403.1662504717.Cj0KCQjw39uYBhCLARIsAD_SzMQFRHH0vy1Jg9KFWpD289ItJx-G1t_wNseJkR918bNkOOX59yyqlMUaAiAmEALw_wcB\"&gt;cost calculator&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It says:  &amp;#39;Data to replicate from your database sources&amp;#39;. Does that mean the size of the database? Or the size of the new rows i want to (incrementally) sync each month?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110h36c", "is_robot_indexable": true, "report_reasons": null, "author": "karaqz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110h36c/question_about_the_airbyte_cost_calculator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110h36c/question_about_the_airbyte_cost_calculator/", "subreddit_subscribers": 89440, "created_utc": 1676212460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been in the field of data analytics and data engineering / BI for 10 years now. If I were to start my own firm with this skill set, how do I go about it? How can I look for projects that need help with data?", "author_fullname": "t2_9z5xb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I promote my skills to build my own company.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1113mtq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676278132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been in the field of data analytics and data engineering / BI for 10 years now. If I were to start my own firm with this skill set, how do I go about it? How can I look for projects that need help with data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1113mtq", "is_robot_indexable": true, "report_reasons": null, "author": "agmahi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1113mtq/how_can_i_promote_my_skills_to_build_my_own/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1113mtq/how_can_i_promote_my_skills_to_build_my_own/", "subreddit_subscribers": 89440, "created_utc": 1676278132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI am a fairly new working professional in Software Engineering, who was recently laid off. I am currently in the final interview stages of 2 companies for 2 different roles - data scientist and data engineer. The thing is - I have some experience working within both the domains, and also have a couple of publications in NLP. \n\nWhile I completely understand that the final decision is going to be upto me, I had a few questions for people here - especially for the people who have made a switch from data science to data engineering. \n\n1. How easy was it for you to switch?\n2. Why did you make the switch?\n3. What is something that you really love and really hate about the 2 domains?\n\nThis would help me gain better insight and make an even more informed decision.\n\nThanks!", "author_fullname": "t2_tp3j7tir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insight from data engineers - especially ex data scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110scdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676241330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a fairly new working professional in Software Engineering, who was recently laid off. I am currently in the final interview stages of 2 companies for 2 different roles - data scientist and data engineer. The thing is - I have some experience working within both the domains, and also have a couple of publications in NLP. &lt;/p&gt;\n\n&lt;p&gt;While I completely understand that the final decision is going to be upto me, I had a few questions for people here - especially for the people who have made a switch from data science to data engineering. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How easy was it for you to switch?&lt;/li&gt;\n&lt;li&gt;Why did you make the switch?&lt;/li&gt;\n&lt;li&gt;What is something that you really love and really hate about the 2 domains?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This would help me gain better insight and make an even more informed decision.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110scdj", "is_robot_indexable": true, "report_reasons": null, "author": "djavulsk-perkele", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110scdj/insight_from_data_engineers_especially_ex_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110scdj/insight_from_data_engineers_especially_ex_data/", "subreddit_subscribers": 89440, "created_utc": 1676241330.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}