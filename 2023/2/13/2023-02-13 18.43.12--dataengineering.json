{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nCurrently my org is making a strategic move from a onprem solution to the Azure Public Cloud.\n\nThe current onprem datawarehouse has a few limited usecases and can be identified as small. Its based on SQL SP + SSIS, with views on top of the datamart which joins all the needed data together for PowerBI.\n\nThe datawarehouse will probaly grow in the longer term to more different kind of usecases then only reporting. Think about statistiscal models in Python &amp; scenario simulations &amp; other analysis not known yet.\n\nIn regards of sheer datasize its all really limited( Max  5 mil records a day) Types of Datafeeds are API\"s or SFTP's.\n\n So what is a good dataplatform setup for these kind of usecases in the Azure Cloud? Powerbi is the chosen reporting tool already.\n\n1. Snowflake: Not an option due to regulatory compliance\n2: ADL gen 2 + Databricks: maybe overkill for the given amount of data? But python and R can be excuted on the same dataset as our reports which is a + in terms of auditablility and one dataplatform for the organisation.\n3. Synapse: No clue, same overkill?\n4. Azure SQL server + ADF: is this futute proof for also more potential advanced usecases?\n\nI would like to have 1 generic envoirement where we can implement all our dataproducts and make then available for the organisation.\n\nP.s. there is no technical knowledge currently avalaible in the org. So in terms of choosing the stack it doesnt matter", "author_fullname": "t2_mv3d8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving OnPrem to Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1112tdq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676274940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;Currently my org is making a strategic move from a onprem solution to the Azure Public Cloud.&lt;/p&gt;\n\n&lt;p&gt;The current onprem datawarehouse has a few limited usecases and can be identified as small. Its based on SQL SP + SSIS, with views on top of the datamart which joins all the needed data together for PowerBI.&lt;/p&gt;\n\n&lt;p&gt;The datawarehouse will probaly grow in the longer term to more different kind of usecases then only reporting. Think about statistiscal models in Python &amp;amp; scenario simulations &amp;amp; other analysis not known yet.&lt;/p&gt;\n\n&lt;p&gt;In regards of sheer datasize its all really limited( Max  5 mil records a day) Types of Datafeeds are API&amp;quot;s or SFTP&amp;#39;s.&lt;/p&gt;\n\n&lt;p&gt;So what is a good dataplatform setup for these kind of usecases in the Azure Cloud? Powerbi is the chosen reporting tool already.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Snowflake: Not an option due to regulatory compliance\n2: ADL gen 2 + Databricks: maybe overkill for the given amount of data? But python and R can be excuted on the same dataset as our reports which is a + in terms of auditablility and one dataplatform for the organisation.&lt;/li&gt;\n&lt;li&gt;Synapse: No clue, same overkill?&lt;/li&gt;\n&lt;li&gt;Azure SQL server + ADF: is this futute proof for also more potential advanced usecases?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I would like to have 1 generic envoirement where we can implement all our dataproducts and make then available for the organisation.&lt;/p&gt;\n\n&lt;p&gt;P.s. there is no technical knowledge currently avalaible in the org. So in terms of choosing the stack it doesnt matter&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1112tdq", "is_robot_indexable": true, "report_reasons": null, "author": "artopaper", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1112tdq/moving_onprem_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1112tdq/moving_onprem_to_cloud/", "subreddit_subscribers": 89476, "created_utc": 1676274940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm at the point in my learning where I need to pick between AWS, GCP, or Azure to learn and get certified in. However, I'm not sure which one is the best first pick.\n\nI don't work for a company, and I am not currently applying for jobs at one. I am trying to build up my skill set so that I can begin applying for entry level jobs soon.", "author_fullname": "t2_ny5wu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help deciding which cloud service to learn first", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110ux8l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676248624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m at the point in my learning where I need to pick between AWS, GCP, or Azure to learn and get certified in. However, I&amp;#39;m not sure which one is the best first pick.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t work for a company, and I am not currently applying for jobs at one. I am trying to build up my skill set so that I can begin applying for entry level jobs soon.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110ux8l", "is_robot_indexable": true, "report_reasons": null, "author": "CoronaBlue", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110ux8l/help_deciding_which_cloud_service_to_learn_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110ux8l/help_deciding_which_cloud_service_to_learn_first/", "subreddit_subscribers": 89476, "created_utc": 1676248624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've seen them floating around the industry. They strike me as a slightly modern Palantir/IBM consultant oriented shop. But Google is partnering with them to use their GPT-3 competitor in their products so I was curious what their products even are/do.\n\nAnyone have experience with it?", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone use any c3.ai products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1111vos", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676271268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen them floating around the industry. They strike me as a slightly modern Palantir/IBM consultant oriented shop. But Google is partnering with them to use their GPT-3 competitor in their products so I was curious what their products even are/do.&lt;/p&gt;\n\n&lt;p&gt;Anyone have experience with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1111vos", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1111vos/anyone_use_any_c3ai_products/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1111vos/anyone_use_any_c3ai_products/", "subreddit_subscribers": 89476, "created_utc": 1676271268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to build a project portfolio but not sure where to commit. Thank you for the suggestions in advance.", "author_fullname": "t2_m9qt65bk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling to find practice projects. Is Leetcode good enough?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110o9s2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676230848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to build a project portfolio but not sure where to commit. Thank you for the suggestions in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110o9s2", "is_robot_indexable": true, "report_reasons": null, "author": "beakyblindar", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110o9s2/struggling_to_find_practice_projects_is_leetcode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110o9s2/struggling_to_find_practice_projects_is_leetcode/", "subreddit_subscribers": 89476, "created_utc": 1676230848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[GeoSpatial Analysis Using GeoPandas In Python](https://preview.redd.it/1gryl6sc8zha1.jpg?width=334&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=4ab2a6e45dc5c29b8d26b3d414d1c9e5dc9d3390)\n\n[GeoSpatial Analysis Using GeoPandas In Python](https://spatial-dev.guru/2023/02/05/geospatial-analysis-using-geopandas-in-python/)", "author_fullname": "t2_avt84u4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GeoSpatial Analysis Using GeoPandas In Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"1gryl6sc8zha1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/1gryl6sc8zha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21fc9f983962fe0bdab3349db1eaa52b7aa3f71a"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/1gryl6sc8zha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aaa4437dd3694e6b4978ba205b5e4ffba8283635"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/1gryl6sc8zha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f0e047ee2725c279ca99d8678bbc4eb5e6304e3"}], "s": {"y": 692, "x": 334, "u": "https://preview.redd.it/1gryl6sc8zha1.jpg?width=334&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=4ab2a6e45dc5c29b8d26b3d414d1c9e5dc9d3390"}, "id": "1gryl6sc8zha1"}}, "name": "t3_111c8wl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Wcr2xuzP5RtAv0uH2P0-jD5kaFDnhB3qSNHhvxU9aq4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676303150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/1gryl6sc8zha1.jpg?width=334&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=4ab2a6e45dc5c29b8d26b3d414d1c9e5dc9d3390\"&gt;GeoSpatial Analysis Using GeoPandas In Python&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://spatial-dev.guru/2023/02/05/geospatial-analysis-using-geopandas-in-python/\"&gt;GeoSpatial Analysis Using GeoPandas In Python&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "111c8wl", "is_robot_indexable": true, "report_reasons": null, "author": "iamgeoknight", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/111c8wl/geospatial_analysis_using_geopandas_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/111c8wl/geospatial_analysis_using_geopandas_in_python/", "subreddit_subscribers": 89476, "created_utc": 1676303150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I come from a DE batch project where Events trigger Lambdas, which trigger Step Functions to run all the batch pipelines. I was thinking how to replace Step Functions with Apache Airflow, so I was looking for an example architecture which combines events and Lambda functions to trigger Airflow pipelines. Do you have any reference which I could find useful? Many thanks", "author_fullname": "t2_v3ifff74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(AWS) Events, lambda and Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1115ab2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676284660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I come from a DE batch project where Events trigger Lambdas, which trigger Step Functions to run all the batch pipelines. I was thinking how to replace Step Functions with Apache Airflow, so I was looking for an example architecture which combines events and Lambda functions to trigger Airflow pipelines. Do you have any reference which I could find useful? Many thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1115ab2", "is_robot_indexable": true, "report_reasons": null, "author": "kaismd", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1115ab2/aws_events_lambda_and_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1115ab2/aws_events_lambda_and_airflow/", "subreddit_subscribers": 89476, "created_utc": 1676284660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI have a DW running on On Prem MS SQL. It's a very small setup, around 50 tables, less than 10 sources and no more than 15GB of data at the moment. I'm extracting with python and some IaaS. I load the data in source db, transform in stage db and then load to prod db.\n\nThe DW is still in development, mostly because there is a complete lack of governance when it comes to business process best practices (Lost battle for now, don't even get me started). So once in a while, someone would manage to get out of their way to break some business logic. When this happens, I would just manually fix the affected rows if they are just a few, or just rebuild the table if they are many. And of course I would change my code to include this new case.\n\nThe question is, how can I logically roll back to the previous batch?  I couldn't find anything online.\n\nI hope this made sense.", "author_fullname": "t2_83poggkq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Warehouse roll back table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1114jeb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676281807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have a DW running on On Prem MS SQL. It&amp;#39;s a very small setup, around 50 tables, less than 10 sources and no more than 15GB of data at the moment. I&amp;#39;m extracting with python and some IaaS. I load the data in source db, transform in stage db and then load to prod db.&lt;/p&gt;\n\n&lt;p&gt;The DW is still in development, mostly because there is a complete lack of governance when it comes to business process best practices (Lost battle for now, don&amp;#39;t even get me started). So once in a while, someone would manage to get out of their way to break some business logic. When this happens, I would just manually fix the affected rows if they are just a few, or just rebuild the table if they are many. And of course I would change my code to include this new case.&lt;/p&gt;\n\n&lt;p&gt;The question is, how can I logically roll back to the previous batch?  I couldn&amp;#39;t find anything online.&lt;/p&gt;\n\n&lt;p&gt;I hope this made sense.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1114jeb", "is_robot_indexable": true, "report_reasons": null, "author": "Ancient-Entry-6436", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1114jeb/data_warehouse_roll_back_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1114jeb/data_warehouse_roll_back_table/", "subreddit_subscribers": 89476, "created_utc": 1676281807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m pretty new to this, so I apologise if I\u2019m not asking the question in the right way.  But say I have a Parquet table, and in storage, it\u2019s saved in 3 parts. Next, I have a Databricks compute with autoscaling that is reading data from the table. For one read activity on that single table from Databricks, will that count as 1 read, or would it be 3 reads (one for each parquet part file)? Also, since Databricks uses distributed compute, could there be multiple caller IPs for one read activity, or does it count as one based on driver node? Does this mean, if Databricks was scaled to 3 workers, (plus a driver), one read on one table could count as 3 part files x 4 compute = 12 read activities?", "author_fullname": "t2_59ggcmrq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does Log Analytics count read activities to Parquet files in ADLSg2 from distributed compute, such as Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11118td", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676268880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m pretty new to this, so I apologise if I\u2019m not asking the question in the right way.  But say I have a Parquet table, and in storage, it\u2019s saved in 3 parts. Next, I have a Databricks compute with autoscaling that is reading data from the table. For one read activity on that single table from Databricks, will that count as 1 read, or would it be 3 reads (one for each parquet part file)? Also, since Databricks uses distributed compute, could there be multiple caller IPs for one read activity, or does it count as one based on driver node? Does this mean, if Databricks was scaled to 3 workers, (plus a driver), one read on one table could count as 3 part files x 4 compute = 12 read activities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11118td", "is_robot_indexable": true, "report_reasons": null, "author": "jinbe-san", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11118td/how_does_log_analytics_count_read_activities_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11118td/how_does_log_analytics_count_read_activities_to/", "subreddit_subscribers": 89476, "created_utc": 1676268880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From reading through this sub and articles like [this](https://medium.com/bluecore-engineering/were-all-using-airflow-wrong-and-how-to-fix-it-a56f14cb0753), there's definitely arguments for containerizing all Airflow tasks to separate execution logic from orchestration logic. Whether it's easier onboarding of new devs, package conflicts between tasks, simpler debugging, etc., it all sounds great in theory. But I'm curious how many teams actually build their DAGs like this and whether it's worth it?\n\n[View Poll](https://www.reddit.com/poll/110qo3h)", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you execute all Airflow tasks in containers to separate execution logic from orchestration logic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110qo3h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676236961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From reading through this sub and articles like &lt;a href=\"https://medium.com/bluecore-engineering/were-all-using-airflow-wrong-and-how-to-fix-it-a56f14cb0753\"&gt;this&lt;/a&gt;, there&amp;#39;s definitely arguments for containerizing all Airflow tasks to separate execution logic from orchestration logic. Whether it&amp;#39;s easier onboarding of new devs, package conflicts between tasks, simpler debugging, etc., it all sounds great in theory. But I&amp;#39;m curious how many teams actually build their DAGs like this and whether it&amp;#39;s worth it?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/110qo3h\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?auto=webp&amp;v=enabled&amp;s=c4c33040015af6b9b895354919a038471d8ebd2d", "width": 752, "height": 427}, "resolutions": [{"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00c7c68e97652e6b3530ab5eba5ea327b38a8942", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=943e5fa8fa60e636733f063d1d720572ccbc59a4", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=040eb5e59874649b8347f423c89e973bd8cc13e8", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=daa1a474f8dfc6b5bb91f396ddd49601bc8a0a8c", "width": 640, "height": 363}], "variants": {}, "id": "sf2SA2a5dF3sFQeNi3Z_FOLTkemkNklRDj4S8DgYVz0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110qo3h", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1676668961870, "options": [{"text": "Yes we containerize and it's worth it", "id": "21568710"}, {"text": "Yes we containerize but it's not worth it", "id": "21568711"}, {"text": "No we don't containerize but we're interested", "id": "21568712"}, {"text": "No we don't containerize and we're not interested", "id": "21568713"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 109, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110qo3h/do_you_execute_all_airflow_tasks_in_containers_to/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/110qo3h/do_you_execute_all_airflow_tasks_in_containers_to/", "subreddit_subscribers": 89476, "created_utc": 1676236961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to come up with a data model where customer can have multiple subscriptions and  subscription is just a type of many other products, so when customer buys  subscription then product with type subscription is being added to the  order and order has a payment fk. When payment is successful then  subscription is added to the subscription table with (user fk, order fk,  start date, end date, price, is\\_active).\n\nBut how to approach subscription recurring payment?\n\n1. Since  subscription is a product that is part of the order, should new ordered  and new payment be created every time when subscription recurring payment happens?\n2. Or  should subscription have 1:m relationship with payment tbl, and only  new payment should be created on the subscription renewal? but this  approach seem little weird since initial subscription purchase payment  was in the order table.\n\nHow to go about it?", "author_fullname": "t2_glxz8l6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you model multiple subscriptions if subscription is a type of a product?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111171s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676268685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to come up with a data model where customer can have multiple subscriptions and  subscription is just a type of many other products, so when customer buys  subscription then product with type subscription is being added to the  order and order has a payment fk. When payment is successful then  subscription is added to the subscription table with (user fk, order fk,  start date, end date, price, is_active).&lt;/p&gt;\n\n&lt;p&gt;But how to approach subscription recurring payment?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Since  subscription is a product that is part of the order, should new ordered  and new payment be created every time when subscription recurring payment happens?&lt;/li&gt;\n&lt;li&gt;Or  should subscription have 1:m relationship with payment tbl, and only  new payment should be created on the subscription renewal? but this  approach seem little weird since initial subscription purchase payment  was in the order table.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;How to go about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "111171s", "is_robot_indexable": true, "report_reasons": null, "author": "No-Race8789", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/111171s/how_do_you_model_multiple_subscriptions_if/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/111171s/how_do_you_model_multiple_subscriptions_if/", "subreddit_subscribers": 89476, "created_utc": 1676268685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I\u2019ve been working with my company as a data engineer in our business intelligence department for the last 3 years. Over the last 3 years our team has been severely neglected by our leadership causing many people in my team to move to new opportunities. This has lead to my team being over worked and underpaid (making $81k in austin) I can never find time to work on projects as I\u2019m constantly being pulled into fire drills due to bad data in Salesforce. \n\nOur current infrastructure is SSMS enterprise data warehouse using SSIS and SSAS cubes. There are plans for our team to move to the cloud but with my current leadership, I don\u2019t see the move to cloud happening anytime soon. I\u2019ve also build data pipelines using python and pulling data from source system apis\n\nI really would like to move to a new company but in job listings I feel like everyone is only looking for DEs that work with different cloud technologies.\n\nI was wondering if anyone could give me advice on ways I can make myself more appealing to employers. Any recommendations are helpful from courses to certifications would be greatly appreciated.", "author_fullname": "t2_2jf9pj50", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help moving to a cloud base DE role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110pk9f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676234132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019ve been working with my company as a data engineer in our business intelligence department for the last 3 years. Over the last 3 years our team has been severely neglected by our leadership causing many people in my team to move to new opportunities. This has lead to my team being over worked and underpaid (making $81k in austin) I can never find time to work on projects as I\u2019m constantly being pulled into fire drills due to bad data in Salesforce. &lt;/p&gt;\n\n&lt;p&gt;Our current infrastructure is SSMS enterprise data warehouse using SSIS and SSAS cubes. There are plans for our team to move to the cloud but with my current leadership, I don\u2019t see the move to cloud happening anytime soon. I\u2019ve also build data pipelines using python and pulling data from source system apis&lt;/p&gt;\n\n&lt;p&gt;I really would like to move to a new company but in job listings I feel like everyone is only looking for DEs that work with different cloud technologies.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone could give me advice on ways I can make myself more appealing to employers. Any recommendations are helpful from courses to certifications would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110pk9f", "is_robot_indexable": true, "report_reasons": null, "author": "DankBoyardee", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110pk9f/help_moving_to_a_cloud_base_de_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110pk9f/help_moving_to_a_cloud_base_de_role/", "subreddit_subscribers": 89476, "created_utc": 1676234132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would someone kindly let me know whether they have experience working in the supply chain as a data engineer? If so, what is their daily work look like! \nWhat kind of tool you are using and for which purpose!", "author_fullname": "t2_m6lk62t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Role of a Data engineer in a supply chain org !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110nqwv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676229502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would someone kindly let me know whether they have experience working in the supply chain as a data engineer? If so, what is their daily work look like! \nWhat kind of tool you are using and for which purpose!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "110nqwv", "is_robot_indexable": true, "report_reasons": null, "author": "TelevisionDue5491", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110nqwv/role_of_a_data_engineer_in_a_supply_chain_org/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110nqwv/role_of_a_data_engineer_in_a_supply_chain_org/", "subreddit_subscribers": 89476, "created_utc": 1676229502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company we use jdbcoperator to transform and upload data.\nHowever it would be very useful to see in the logs information like \u201cupdated rows #\u201d after merge or \u201c# of rows\u201d for newly created tables (in particular temporary tables).\n\nI know I can extract those info through a query and output on the logs but is there a more Airflowic way to do so?", "author_fullname": "t2_e4qv08k8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow JdbcOperator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11169ft", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676288474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company we use jdbcoperator to transform and upload data.\nHowever it would be very useful to see in the logs information like \u201cupdated rows #\u201d after merge or \u201c# of rows\u201d for newly created tables (in particular temporary tables).&lt;/p&gt;\n\n&lt;p&gt;I know I can extract those info through a query and output on the logs but is there a more Airflowic way to do so?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11169ft", "is_robot_indexable": true, "report_reasons": null, "author": "Busy_Elderberry8650", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11169ft/airflow_jdbcoperator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11169ft/airflow_jdbcoperator/", "subreddit_subscribers": 89476, "created_utc": 1676288474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi - am looking at ingesting data to s3 from tools like Salesforce.  \n\nI was looking at Airbyte, and then also saw AppFlow.  Any thoughts on tradeoffs?  I was keen on also trying dbt, how do you do that with AppFlow?", "author_fullname": "t2_5gzu4ur4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AppFlow vs Airbyte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1115zay", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676287394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi - am looking at ingesting data to s3 from tools like Salesforce.  &lt;/p&gt;\n\n&lt;p&gt;I was looking at Airbyte, and then also saw AppFlow.  Any thoughts on tradeoffs?  I was keen on also trying dbt, how do you do that with AppFlow?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1115zay", "is_robot_indexable": true, "report_reasons": null, "author": "bluezebra42", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1115zay/appflow_vs_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1115zay/appflow_vs_airbyte/", "subreddit_subscribers": 89476, "created_utc": 1676287394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm just running some labs with Azure Synapse and Databricks on Azure and I wanted someone to validate whether this would be a solid pipeline.  The source is a Postgres db.\n\nExtract: Synapse Pipelines Copy Activity to Azure Data Lake Gen 2 Storage\n\nTransformation: Azure Databricks notebook triggered by Synapse Pipelines. Databricks notebook would be written in PySpark.\n\nLoad: Databricks notebook loads transformed data into Synapse dedicated SQL pool\n\n&amp;#x200B;\n\nAm I missing any steps here? Can Databricks directly load transformed data into a Synapse Dedicated SQL pool?", "author_fullname": "t2_nhdew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Validate my Azure Synapse/Databricks pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110rr24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676239793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m just running some labs with Azure Synapse and Databricks on Azure and I wanted someone to validate whether this would be a solid pipeline.  The source is a Postgres db.&lt;/p&gt;\n\n&lt;p&gt;Extract: Synapse Pipelines Copy Activity to Azure Data Lake Gen 2 Storage&lt;/p&gt;\n\n&lt;p&gt;Transformation: Azure Databricks notebook triggered by Synapse Pipelines. Databricks notebook would be written in PySpark.&lt;/p&gt;\n\n&lt;p&gt;Load: Databricks notebook loads transformed data into Synapse dedicated SQL pool&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Am I missing any steps here? Can Databricks directly load transformed data into a Synapse Dedicated SQL pool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110rr24", "is_robot_indexable": true, "report_reasons": null, "author": "MonkeyMaster64", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110rr24/validate_my_azure_synapsedatabricks_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110rr24/validate_my_azure_synapsedatabricks_pipeline/", "subreddit_subscribers": 89476, "created_utc": 1676239793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Okay so I am on a team of two at a young company. We are doing great but for a variety of reasons we are tasked to build a new data flow while keeping our old one up as a sort of legacy API.\n\nBecause this is new we are open to many ideas. I proposed Rust due to the various advantages it has over Python and my love for Rust - I am an active contributor on a couple big Rust libraries.\n\nThe basic rundown of our pipeline requirements is it all is hosted in AWS. We want to utilize more serverless and allow companies outside the organization get data via API calls. So we store raw data in S3 and analytical data in RDS. I plan to use lambda and step functions for the majority of our pipelines but we also need to keep our database integrated with Salesforce.\n\nAny helpful tips or guides going forward would be great! I'm curious if anyone else here has made the change. Also happy to hear how others have simplified their S3 to RDS pipeline", "author_fullname": "t2_b41hohwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Convinced manager to write our new company pipeline in Rust...now what?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_111fg7i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676311137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay so I am on a team of two at a young company. We are doing great but for a variety of reasons we are tasked to build a new data flow while keeping our old one up as a sort of legacy API.&lt;/p&gt;\n\n&lt;p&gt;Because this is new we are open to many ideas. I proposed Rust due to the various advantages it has over Python and my love for Rust - I am an active contributor on a couple big Rust libraries.&lt;/p&gt;\n\n&lt;p&gt;The basic rundown of our pipeline requirements is it all is hosted in AWS. We want to utilize more serverless and allow companies outside the organization get data via API calls. So we store raw data in S3 and analytical data in RDS. I plan to use lambda and step functions for the majority of our pipelines but we also need to keep our database integrated with Salesforce.&lt;/p&gt;\n\n&lt;p&gt;Any helpful tips or guides going forward would be great! I&amp;#39;m curious if anyone else here has made the change. Also happy to hear how others have simplified their S3 to RDS pipeline&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "111fg7i", "is_robot_indexable": true, "report_reasons": null, "author": "Gutscazerk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/111fg7i/convinced_manager_to_write_our_new_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/111fg7i/convinced_manager_to_write_our_new_company/", "subreddit_subscribers": 89476, "created_utc": 1676311137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in a very security-minded org that has very poor environment parity across all of our source systems.  We have very sparse/non-existent dev data and I'm looking for some solutions and wanted to see if this community has any tooling recommendations to help.\n\nThe requirement is to build out synthetic data with very similar size and shape to our production data and ideally have a framework to do this, maybe at some level use our data and \"de-productionize\" it.  [gretel.ai](https://gretel.ai) looks like it may be a fit, but from what I see I need to upload production data to their environment and that's a no-go.\n\n&amp;#x200B;\n\nHas anyone come across a similar problem and what are some solutions?\n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_3q5hfpq8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Generating Synthetic Data from Prod systems into Dev/UAT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111djgk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676306331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in a very security-minded org that has very poor environment parity across all of our source systems.  We have very sparse/non-existent dev data and I&amp;#39;m looking for some solutions and wanted to see if this community has any tooling recommendations to help.&lt;/p&gt;\n\n&lt;p&gt;The requirement is to build out synthetic data with very similar size and shape to our production data and ideally have a framework to do this, maybe at some level use our data and &amp;quot;de-productionize&amp;quot; it.  &lt;a href=\"https://gretel.ai\"&gt;gretel.ai&lt;/a&gt; looks like it may be a fit, but from what I see I need to upload production data to their environment and that&amp;#39;s a no-go.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Has anyone come across a similar problem and what are some solutions?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Fabxw_Az9CPdZ2ialGX1IUMozM8LSYUqVHUDf2Ln2aA.jpg?auto=webp&amp;v=enabled&amp;s=2ba92a939a095501fb155c357863e8a0c95ca82b", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/Fabxw_Az9CPdZ2ialGX1IUMozM8LSYUqVHUDf2Ln2aA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c4f34c328c74a03183c562084539022e0e4db596", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Fabxw_Az9CPdZ2ialGX1IUMozM8LSYUqVHUDf2Ln2aA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cce563ca19a1be89ed5a347ea1b639594e3bded4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/Fabxw_Az9CPdZ2ialGX1IUMozM8LSYUqVHUDf2Ln2aA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8588b7410b33d54a1d311f88be9432dbe4c23f34", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/Fabxw_Az9CPdZ2ialGX1IUMozM8LSYUqVHUDf2Ln2aA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5efcd2d79f439ba042ed5abeaf109eb20084d6d", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/Fabxw_Az9CPdZ2ialGX1IUMozM8LSYUqVHUDf2Ln2aA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed601ca17686ef686d064a42f9a105f384094833", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/Fabxw_Az9CPdZ2ialGX1IUMozM8LSYUqVHUDf2Ln2aA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7d17ee8c3bb78f99e891c45ad65d95cd31d8450", "width": 1080, "height": 567}], "variants": {}, "id": "o0qqAq5goPMeGx3o_KWtBt4Uz4NUKAsNYfk7pyjJwGM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "111djgk", "is_robot_indexable": true, "report_reasons": null, "author": "timewarp80", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/111djgk/generating_synthetic_data_from_prod_systems_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/111djgk/generating_synthetic_data_from_prod_systems_into/", "subreddit_subscribers": 89476, "created_utc": 1676306331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1bnhotlu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Skills", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 118, "top_awarded_type": null, "hide_score": false, "name": "t3_111cvow", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/53iBsor-oCzGVT3z-ZeCYV_HUqbP5gTxrnUzkNfWHCU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676304692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kanger.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kanger.dev/data-engineering-skills/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4CW8qHkdLuH2At66g-OGyUfAf7CPGBCbrB1h9CGRXWY.jpg?auto=webp&amp;v=enabled&amp;s=39b3c642d8baa96e804371f84d46c64bbc43d0f5", "width": 1024, "height": 870}, "resolutions": [{"url": "https://external-preview.redd.it/4CW8qHkdLuH2At66g-OGyUfAf7CPGBCbrB1h9CGRXWY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36556b16af3c8c71596eef0273de1be6cf0ab0fa", "width": 108, "height": 91}, {"url": "https://external-preview.redd.it/4CW8qHkdLuH2At66g-OGyUfAf7CPGBCbrB1h9CGRXWY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b379b8cb4d088556a744dfd45c4ed2379dc29de6", "width": 216, "height": 183}, {"url": "https://external-preview.redd.it/4CW8qHkdLuH2At66g-OGyUfAf7CPGBCbrB1h9CGRXWY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d367d29b2011774284236d9221ae74f41db0303", "width": 320, "height": 271}, {"url": "https://external-preview.redd.it/4CW8qHkdLuH2At66g-OGyUfAf7CPGBCbrB1h9CGRXWY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=87cab2269fda0e71af3f30aa5ab61ee134612728", "width": 640, "height": 543}, {"url": "https://external-preview.redd.it/4CW8qHkdLuH2At66g-OGyUfAf7CPGBCbrB1h9CGRXWY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=40c2c7a489b2e0f0fdda12859bae1894512c7969", "width": 960, "height": 815}], "variants": {}, "id": "vGNbo-f1adpCvC9ZQ3eQqDvJuX41B2__MhB_agwlzNk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "111cvow", "is_robot_indexable": true, "report_reasons": null, "author": "skj8", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/111cvow/data_engineering_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kanger.dev/data-engineering-skills/", "subreddit_subscribers": 89476, "created_utc": 1676304692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, I am trying to understand the real effort behind running Stitch in production and I have some questions  \n\n\n1. Any maintenance events that take time? If yes, please describe, i wanna understand the effort over a year of running the tool.  \n\n2. Schema evolution supported? including nested fields? I am wondering how it handles multiple levels of nesting (from mongo to BQ) and if it can evolve the schema, or if I need to full reload.  \n\n3. Any SLA considerations? They say they offer SLA but not what it is (contact sales). Do their pipelines break? (ofc they do) what response time do they have?\n\n&amp;#x200B;\n\nMuch appreciated! If you have experience regarding these points with a similar tool, I would be happy to hear about that too.", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stitch Schema migration and maintenance burden?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111btrw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676302066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, I am trying to understand the real effort behind running Stitch in production and I have some questions  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Any maintenance events that take time? If yes, please describe, i wanna understand the effort over a year of running the tool.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Schema evolution supported? including nested fields? I am wondering how it handles multiple levels of nesting (from mongo to BQ) and if it can evolve the schema, or if I need to full reload.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Any SLA considerations? They say they offer SLA but not what it is (contact sales). Do their pipelines break? (ofc they do) what response time do they have?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Much appreciated! If you have experience regarding these points with a similar tool, I would be happy to hear about that too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "111btrw", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/111btrw/stitch_schema_migration_and_maintenance_burden/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/111btrw/stitch_schema_migration_and_maintenance_burden/", "subreddit_subscribers": 89476, "created_utc": 1676302066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n[View Poll](https://www.reddit.com/poll/1118668)", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which big data file formats do you query in your data lake / lakehouse for most of your analytical workloads?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1118668", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676294704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/1118668\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1118668", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1676726704169, "options": [{"text": "primarily Parquet", "id": "21578485"}, {"text": "primarily ORC", "id": "21578486"}, {"text": "primarily AVRO", "id": "21578487"}, {"text": "primarily some other format", "id": "21578488"}, {"text": "we frequently query more than one format", "id": "21578489"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 136, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1118668/which_big_data_file_formats_do_you_query_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/1118668/which_big_data_file_formats_do_you_query_in_your/", "subreddit_subscribers": 89476, "created_utc": 1676294704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " So, as title, I have to create an ETL from a Server that overwrites data twice a day. The only solution I have for now to be sure of not losing any data is to run the ETL twice for every overwriting, so 4 times a day. How would you approach such a case?", "author_fullname": "t2_82dwrpz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with data that gets overwrited every time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1115wp6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676287122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, as title, I have to create an ETL from a Server that overwrites data twice a day. The only solution I have for now to be sure of not losing any data is to run the ETL twice for every overwriting, so 4 times a day. How would you approach such a case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1115wp6", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Ad-8440", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1115wp6/how_to_deal_with_data_that_gets_overwrited_every/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1115wp6/how_to_deal_with_data_that_gets_overwrited_every/", "subreddit_subscribers": 89476, "created_utc": 1676287122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI am a fairly new working professional in Software Engineering, who was recently laid off. I am currently in the final interview stages of 2 companies for 2 different roles - data scientist and data engineer. The thing is - I have some experience working within both the domains, and also have a couple of publications in NLP. \n\nWhile I completely understand that the final decision is going to be upto me, I had a few questions for people here - especially for the people who have made a switch from data science to data engineering. \n\n1. How easy was it for you to switch?\n2. Why did you make the switch?\n3. What is something that you really love and really hate about the 2 domains?\n\nThis would help me gain better insight and make an even more informed decision.\n\nThanks!", "author_fullname": "t2_tp3j7tir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insight from data engineers - especially ex data scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110scdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676241330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a fairly new working professional in Software Engineering, who was recently laid off. I am currently in the final interview stages of 2 companies for 2 different roles - data scientist and data engineer. The thing is - I have some experience working within both the domains, and also have a couple of publications in NLP. &lt;/p&gt;\n\n&lt;p&gt;While I completely understand that the final decision is going to be upto me, I had a few questions for people here - especially for the people who have made a switch from data science to data engineering. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How easy was it for you to switch?&lt;/li&gt;\n&lt;li&gt;Why did you make the switch?&lt;/li&gt;\n&lt;li&gt;What is something that you really love and really hate about the 2 domains?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This would help me gain better insight and make an even more informed decision.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110scdj", "is_robot_indexable": true, "report_reasons": null, "author": "djavulsk-perkele", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110scdj/insight_from_data_engineers_especially_ex_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110scdj/insight_from_data_engineers_especially_ex_data/", "subreddit_subscribers": 89476, "created_utc": 1676241330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been in the field of data analytics and data engineering / BI for 10 years now. If I were to start my own firm with this skill set, how do I go about it? How can I look for projects that need help with data?", "author_fullname": "t2_9z5xb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I promote my skills to build my own company.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1113mtq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676278132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been in the field of data analytics and data engineering / BI for 10 years now. If I were to start my own firm with this skill set, how do I go about it? How can I look for projects that need help with data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1113mtq", "is_robot_indexable": true, "report_reasons": null, "author": "agmahi", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1113mtq/how_can_i_promote_my_skills_to_build_my_own/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1113mtq/how_can_i_promote_my_skills_to_build_my_own/", "subreddit_subscribers": 89476, "created_utc": 1676278132.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}