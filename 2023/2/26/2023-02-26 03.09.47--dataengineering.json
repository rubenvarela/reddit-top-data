{"kind": "Listing", "data": {"after": "t3_11bxx64", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is one of those out-of-the-blue thoughts that you get randomly. I am an expert in sql with many years of experience, but have yet to use Right Joins lol. Is there any specific reason or use-case for this type of join?", "author_fullname": "t2_tln2vge3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do Right Joins even matter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bhvux", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677320954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is one of those out-of-the-blue thoughts that you get randomly. I am an expert in sql with many years of experience, but have yet to use Right Joins lol. Is there any specific reason or use-case for this type of join?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bhvux", "is_robot_indexable": true, "report_reasons": null, "author": "TheQuiteMind", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bhvux/do_right_joins_even_matter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bhvux/do_right_joins_even_matter/", "subreddit_subscribers": 91130, "created_utc": 1677320954.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got an interview for a solution architect (SA) role at Databricks. There is also a possibility of being a specialist solution architect (SSA) as well. \n\nWondering if anyone from Databricks is here and willing to give their perspective on how working at Databricks has been? \n\nInterested in WLB, Culture, Project structure, and the difference between SA &amp; SSA?", "author_fullname": "t2_ay99iuoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solution Architect @ Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bcow5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677301753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got an interview for a solution architect (SA) role at Databricks. There is also a possibility of being a specialist solution architect (SSA) as well. &lt;/p&gt;\n\n&lt;p&gt;Wondering if anyone from Databricks is here and willing to give their perspective on how working at Databricks has been? &lt;/p&gt;\n\n&lt;p&gt;Interested in WLB, Culture, Project structure, and the difference between SA &amp;amp; SSA?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11bcow5", "is_robot_indexable": true, "report_reasons": null, "author": "Rich_Repair", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bcow5/solution_architect_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bcow5/solution_architect_databricks/", "subreddit_subscribers": 91130, "created_utc": 1677301753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've installed the stack (Hadoop, Hive, Spark) into a Centos VM, built everything from sources to make sure it fits together. Then added Delta Lake ([delta.io](https://delta.io)) from their maven repo.\n\nEverything works fine so I finally have my own little playground (we're using Databricks at work)\n\nNow I noticed this little waring when saving a table in delta format to HDFS:\n\n**WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider delta. Persisting data source table \\`vscode\\_vm\\`.\\`hwtable\\_vm\\_vs\\` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.**\n\nIt doesn't seem to be a problem. Everything works right as far I can see. I can read the table in all \"clients\" (jobs) be it a shell, a notebook or jdbc thrift session. Hence, I wonder what it is about...\n\nSession:\n\n    import pyspark\n    from delta import *\n    \n    appName = \"vs_test\"\n    master = \"spark://pc.home:7077\"\n    \n    builder = pyspark.sql.SparkSession.builder \\\n        .appName(appName) \\\n        .master(master) \\\n        .enableHiveSupport() \\\n        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n        .config(\"spark.cores.max\", \"4\") \\\n        .config(\"spark.executor.memory\", \"2g\")\n    \n    spark = configure_spark_with_delta_pip(builder).getOrCreate()\n\n(load df from a .csv in HDFS)\n\nSave as Table (this is what warns me):\n\n    df.write.format(\"delta\").saveAsTable(\"vscode_vm.hwtable_vm_vs\")\n\nLook into HDFS:\n\n    hdfs dfs -ls /user/hive/warehouse/vscode_vm.db/hwtable_vm_vs/\n\n/user/hive/warehouse/vscode\\_vm.db/hwtable\\_vm\\_vs/part-00000-de750267-3c9a-46c6-8860-714fa45a7a9d-c000.snappy.parquet\n\nPS: the delta-jars are in $SPARK\\_HOME/jars", "author_fullname": "t2_337g1dil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDFS/Spark + Delta: Is this warning dangerous?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bk5is", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677328982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve installed the stack (Hadoop, Hive, Spark) into a Centos VM, built everything from sources to make sure it fits together. Then added Delta Lake (&lt;a href=\"https://delta.io\"&gt;delta.io&lt;/a&gt;) from their maven repo.&lt;/p&gt;\n\n&lt;p&gt;Everything works fine so I finally have my own little playground (we&amp;#39;re using Databricks at work)&lt;/p&gt;\n\n&lt;p&gt;Now I noticed this little waring when saving a table in delta format to HDFS:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;WARN HiveExternalCatalog: Couldn&amp;#39;t find corresponding Hive SerDe for data source provider delta. Persisting data source table `vscode_vm`.`hwtable_vm_vs` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;It doesn&amp;#39;t seem to be a problem. Everything works right as far I can see. I can read the table in all &amp;quot;clients&amp;quot; (jobs) be it a shell, a notebook or jdbc thrift session. Hence, I wonder what it is about...&lt;/p&gt;\n\n&lt;p&gt;Session:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pyspark\nfrom delta import *\n\nappName = &amp;quot;vs_test&amp;quot;\nmaster = &amp;quot;spark://pc.home:7077&amp;quot;\n\nbuilder = pyspark.sql.SparkSession.builder \\\n    .appName(appName) \\\n    .master(master) \\\n    .enableHiveSupport() \\\n    .config(&amp;quot;spark.sql.extensions&amp;quot;, &amp;quot;io.delta.sql.DeltaSparkSessionExtension&amp;quot;) \\\n    .config(&amp;quot;spark.sql.catalog.spark_catalog&amp;quot;, &amp;quot;org.apache.spark.sql.delta.catalog.DeltaCatalog&amp;quot;) \\\n    .config(&amp;quot;spark.cores.max&amp;quot;, &amp;quot;4&amp;quot;) \\\n    .config(&amp;quot;spark.executor.memory&amp;quot;, &amp;quot;2g&amp;quot;)\n\nspark = configure_spark_with_delta_pip(builder).getOrCreate()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;(load df from a .csv in HDFS)&lt;/p&gt;\n\n&lt;p&gt;Save as Table (this is what warns me):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df.write.format(&amp;quot;delta&amp;quot;).saveAsTable(&amp;quot;vscode_vm.hwtable_vm_vs&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Look into HDFS:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;hdfs dfs -ls /user/hive/warehouse/vscode_vm.db/hwtable_vm_vs/\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;/user/hive/warehouse/vscode_vm.db/hwtable_vm_vs/part-00000-de750267-3c9a-46c6-8860-714fa45a7a9d-c000.snappy.parquet&lt;/p&gt;\n\n&lt;p&gt;PS: the delta-jars are in $SPARK_HOME/jars&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11bk5is", "is_robot_indexable": true, "report_reasons": null, "author": "eierwerfer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bk5is/hdfsspark_delta_is_this_warning_dangerous/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bk5is/hdfsspark_delta_is_this_warning_dangerous/", "subreddit_subscribers": 91130, "created_utc": 1677328982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nTL;DR Do you think dashboards are really as useful as the amount of work that goes into them?\n\nI've been thinking about this a lot. Sorry for the slightly clickbait title. This may be selection bias but I frequently hear from other data engineers that they build dashboards that don't get used a lot. Or get stuck in infinite scope creep. \n\nWhich is an odd relationship to have because there is definitely a large chunk of analytics focused data engineering work that follows a high level pattern of 'integrate disparate data sources, model data views and metric calculations, make it available to a dashboard' \n\nI wanted to get this community's thoughts about how realistically useful dashboards are, or how often they think the dashboards justify themselves in value.\n\nMy two cents is that one fundamental problem of dashboards is that they are very often built around an assumption of what questions are worth answering. But the universality of that is in flux. The answer's value ebb and flow with time and accumulate nuances and caveats as the business evolves and the markets change. And so what happens then (which causes the infinite scope creep) is that someone with subject matter expertise will look at the dashboard and say 'can you also show, from this subset of whatever, what the breakdown of whatever is?'\n\nI think operations dashboards are necessary. Even just for us to have a simple place to check and see if sh*t is breaking. Operational dashboards simply provide the first order answers of what the hell is going on in very literal terms. Nothing beyond basic aggregations and generally are just a print out of transactions almost. \n\nWould be interested in hearing more people's perspective on this", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on analytical dashboard insanity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bw23f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1677361641.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677359973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR Do you think dashboards are really as useful as the amount of work that goes into them?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been thinking about this a lot. Sorry for the slightly clickbait title. This may be selection bias but I frequently hear from other data engineers that they build dashboards that don&amp;#39;t get used a lot. Or get stuck in infinite scope creep. &lt;/p&gt;\n\n&lt;p&gt;Which is an odd relationship to have because there is definitely a large chunk of analytics focused data engineering work that follows a high level pattern of &amp;#39;integrate disparate data sources, model data views and metric calculations, make it available to a dashboard&amp;#39; &lt;/p&gt;\n\n&lt;p&gt;I wanted to get this community&amp;#39;s thoughts about how realistically useful dashboards are, or how often they think the dashboards justify themselves in value.&lt;/p&gt;\n\n&lt;p&gt;My two cents is that one fundamental problem of dashboards is that they are very often built around an assumption of what questions are worth answering. But the universality of that is in flux. The answer&amp;#39;s value ebb and flow with time and accumulate nuances and caveats as the business evolves and the markets change. And so what happens then (which causes the infinite scope creep) is that someone with subject matter expertise will look at the dashboard and say &amp;#39;can you also show, from this subset of whatever, what the breakdown of whatever is?&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;I think operations dashboards are necessary. Even just for us to have a simple place to check and see if sh*t is breaking. Operational dashboards simply provide the first order answers of what the hell is going on in very literal terms. Nothing beyond basic aggregations and generally are just a print out of transactions almost. &lt;/p&gt;\n\n&lt;p&gt;Would be interested in hearing more people&amp;#39;s perspective on this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bw23f", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bw23f/thoughts_on_analytical_dashboard_insanity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bw23f/thoughts_on_analytical_dashboard_insanity/", "subreddit_subscribers": 91130, "created_utc": 1677359973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First off I\u2019d like to thank this subreddit. Around this time last year I was working in the energy sector in the Project Management space but because of the extensive resources and discussions here I was able to self teach the Python and SQL skills needed for my first DE job!\n\nThis new role is in the finance sector and pays really well for my age (I\u2019m not long out of uni), with lots of additional benefits/bonuses and I\u2019m really enjoying it.\n\nHowever, I\u2019m slightly concerned about the tech stack used. At the moment, I\u2019d say I\u2019m a bit of a reporting/analytics data engineer. We use a mixture of Teradata, SQLS, SSIS and data vis tools. This has really developed my SQL skills but with Python I\u2019m still just self learning in my spare time through projects and then shoe horning into whatever I can at work.\n\nAdditionally, we lack a lot of the software engineering core principles. Only recently utilising git/GitHub properly, no real adoption of TDD etc. As I\u2019m from a Chemical Engineering education, I\u2019ve had no previous education in these and I\u2019m mainly learning by Googling best practices and incorporating in home projects.\n\nTherefore, it\u2019d be great to get some advice from this subreddit as a lot of you have way more experience than I have. Am I putting too much importance on these principles and a modern tech stack? \n\nApologies for the long post, any advice is much appreciated.", "author_fullname": "t2_2o4st1yo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is the tech stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bjv7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677328053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First off I\u2019d like to thank this subreddit. Around this time last year I was working in the energy sector in the Project Management space but because of the extensive resources and discussions here I was able to self teach the Python and SQL skills needed for my first DE job!&lt;/p&gt;\n\n&lt;p&gt;This new role is in the finance sector and pays really well for my age (I\u2019m not long out of uni), with lots of additional benefits/bonuses and I\u2019m really enjoying it.&lt;/p&gt;\n\n&lt;p&gt;However, I\u2019m slightly concerned about the tech stack used. At the moment, I\u2019d say I\u2019m a bit of a reporting/analytics data engineer. We use a mixture of Teradata, SQLS, SSIS and data vis tools. This has really developed my SQL skills but with Python I\u2019m still just self learning in my spare time through projects and then shoe horning into whatever I can at work.&lt;/p&gt;\n\n&lt;p&gt;Additionally, we lack a lot of the software engineering core principles. Only recently utilising git/GitHub properly, no real adoption of TDD etc. As I\u2019m from a Chemical Engineering education, I\u2019ve had no previous education in these and I\u2019m mainly learning by Googling best practices and incorporating in home projects.&lt;/p&gt;\n\n&lt;p&gt;Therefore, it\u2019d be great to get some advice from this subreddit as a lot of you have way more experience than I have. Am I putting too much importance on these principles and a modern tech stack? &lt;/p&gt;\n\n&lt;p&gt;Apologies for the long post, any advice is much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11bjv7c", "is_robot_indexable": true, "report_reasons": null, "author": "el527", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bjv7c/how_important_is_the_tech_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bjv7c/how_important_is_the_tech_stack/", "subreddit_subscribers": 91130, "created_utc": 1677328053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is better to prevent table having duplicate rows - composite primary key or unique index and why? I would guess that PK would be more preferable as unique index would take more disk space? Also is there any other added benefit of having unique index?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Composite primary key or Unique index", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bfpmm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677312531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is better to prevent table having duplicate rows - composite primary key or unique index and why? I would guess that PK would be more preferable as unique index would take more disk space? Also is there any other added benefit of having unique index?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bfpmm", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bfpmm/composite_primary_key_or_unique_index/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bfpmm/composite_primary_key_or_unique_index/", "subreddit_subscribers": 91130, "created_utc": 1677312531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I make it a point to pay attention to trends in the labor markets. \n\nLately, at least for me, there has been an influx of azure job opportunities, and to a lessor extent, snowflake. That in and of itself isn't anything to raise an eyebrow to. But it's been weeks since I've gotten any aws opportunities in my inbox, even more so for databricks. Did microsoft and snowflake give out a bunch of free credits or something? The demand is so great, I'm seeing nil from their competitors. \n\nAnyone else noticed this? What gives?\n\nBonus question: Is this trend inspiring any of yall to upskill in azure? I'm overdue myself.", "author_fullname": "t2_7lvmv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's up with all these azure and snowflake opportunities in the labor markets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bmvtm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677337003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I make it a point to pay attention to trends in the labor markets. &lt;/p&gt;\n\n&lt;p&gt;Lately, at least for me, there has been an influx of azure job opportunities, and to a lessor extent, snowflake. That in and of itself isn&amp;#39;t anything to raise an eyebrow to. But it&amp;#39;s been weeks since I&amp;#39;ve gotten any aws opportunities in my inbox, even more so for databricks. Did microsoft and snowflake give out a bunch of free credits or something? The demand is so great, I&amp;#39;m seeing nil from their competitors. &lt;/p&gt;\n\n&lt;p&gt;Anyone else noticed this? What gives?&lt;/p&gt;\n\n&lt;p&gt;Bonus question: Is this trend inspiring any of yall to upskill in azure? I&amp;#39;m overdue myself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bmvtm", "is_robot_indexable": true, "report_reasons": null, "author": "claytonjr", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bmvtm/whats_up_with_all_these_azure_and_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bmvtm/whats_up_with_all_these_azure_and_snowflake/", "subreddit_subscribers": 91130, "created_utc": 1677337003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this can vary significantly case by case, but mainly thinking in terms of the best structured DE projects that you\u2019ve seen on GitHub.", "author_fullname": "t2_bwp6e1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any examples of DE projects that you feel are the gold standard for how DE projects should be organized?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c06oj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677370463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this can vary significantly case by case, but mainly thinking in terms of the best structured DE projects that you\u2019ve seen on GitHub.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11c06oj", "is_robot_indexable": true, "report_reasons": null, "author": "wild_bill34", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c06oj/any_examples_of_de_projects_that_you_feel_are_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c06oj/any_examples_of_de_projects_that_you_feel_are_the/", "subreddit_subscribers": 91130, "created_utc": 1677370463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have an ELT architecture in our project where data is pulled from multiple sources into cloud storage (GCS)using APIs invoked by cloud functions. \n\nThe files in GCS are then pushed to BigQuery tables (datalakes) using a data transfer service, configured using the BigQuery console UI.\n\nThe raw data in the datalakes are transformed using scheduled BigQuery SQL queries and stores as dimension and fact tables, which are connected to Tableau dashboards as extracts.\n\nWe did not use any orchestration tool till now as the requirement was to batch load the data once a day only. But now, the dependencies and processes have become quite complicated, that we feel the need for an orchestration tool.\n\nThe preferences are:\n1. The system takes advantage of serverless architecture\n2. Ability to use the transfer services and scheduled queries that we have already built\n3. Minimise costs\n4. Manage dependencies\n5. Easy troubleshooting of failures during pipeline execution \n6. Preferable if Tableau extracts can be invoked by an API call at the last step of the pipeline\n\nWe have narrowed down to:\n1. Cloud Composer which is GCP's flavour of Airflow which is a fully managed service. The pipeline is written in Python.\n2. Cloud workflow which is relatively new, that helps to glue together GCP services and retains the serverless aspect. The pipeline is written in YAML.\n\nPlease suggest whether Cloud Composer or Cloud workflow would be better in my case.", "author_fullname": "t2_ojhggjm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP: Cloud composer vs Cloud Workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bclg9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677313819.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677301435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have an ELT architecture in our project where data is pulled from multiple sources into cloud storage (GCS)using APIs invoked by cloud functions. &lt;/p&gt;\n\n&lt;p&gt;The files in GCS are then pushed to BigQuery tables (datalakes) using a data transfer service, configured using the BigQuery console UI.&lt;/p&gt;\n\n&lt;p&gt;The raw data in the datalakes are transformed using scheduled BigQuery SQL queries and stores as dimension and fact tables, which are connected to Tableau dashboards as extracts.&lt;/p&gt;\n\n&lt;p&gt;We did not use any orchestration tool till now as the requirement was to batch load the data once a day only. But now, the dependencies and processes have become quite complicated, that we feel the need for an orchestration tool.&lt;/p&gt;\n\n&lt;p&gt;The preferences are:\n1. The system takes advantage of serverless architecture\n2. Ability to use the transfer services and scheduled queries that we have already built\n3. Minimise costs\n4. Manage dependencies\n5. Easy troubleshooting of failures during pipeline execution \n6. Preferable if Tableau extracts can be invoked by an API call at the last step of the pipeline&lt;/p&gt;\n\n&lt;p&gt;We have narrowed down to:\n1. Cloud Composer which is GCP&amp;#39;s flavour of Airflow which is a fully managed service. The pipeline is written in Python.\n2. Cloud workflow which is relatively new, that helps to glue together GCP services and retains the serverless aspect. The pipeline is written in YAML.&lt;/p&gt;\n\n&lt;p&gt;Please suggest whether Cloud Composer or Cloud workflow would be better in my case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bclg9", "is_robot_indexable": true, "report_reasons": null, "author": "raghucc24", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bclg9/gcp_cloud_composer_vs_cloud_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bclg9/gcp_cloud_composer_vs_cloud_workflow/", "subreddit_subscribers": 91130, "created_utc": 1677301435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The best of the best way to pull the Oracle data using AWS Glue in terms of performance for large tables holding 200M records. JDBC is very common. Is JDBC the best way to pull the data out from Oracle? Here we would like pull the data not Oracle team will extract the data and give to us. What is best way to pull the data.", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to pull the data from Oracle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bpnsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677344163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The best of the best way to pull the Oracle data using AWS Glue in terms of performance for large tables holding 200M records. JDBC is very common. Is JDBC the best way to pull the data out from Oracle? Here we would like pull the data not Oracle team will extract the data and give to us. What is best way to pull the data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bpnsb", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bpnsb/best_way_to_pull_the_data_from_oracle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bpnsb/best_way_to_pull_the_data_from_oracle/", "subreddit_subscribers": 91130, "created_utc": 1677344163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As per the title. Curious on how it went, any challenges, and if you started again whether you\u2019d go the same direction?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone implemented Data Vault in a lake house?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11biyc6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677324873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As per the title. Curious on how it went, any challenges, and if you started again whether you\u2019d go the same direction?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11biyc6", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11biyc6/anyone_implemented_data_vault_in_a_lake_house/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11biyc6/anyone_implemented_data_vault_in_a_lake_house/", "subreddit_subscribers": 91130, "created_utc": 1677324873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "You build pipelines. Presumably some of these end up in an analytics layer, rendered by Tableau or PowerBI or similar. You may take on the duel role of Data Engineer and Analytics Engineer. If so, this question is aimed at you.\n\nData warehouses are, by definition tightly coupled datasets. Micro services on the other hand are loosely coupled. Regardless of sources, does your team have a preference for tightly/loosely coupled data, and if the latter how do you structure your data to allow seamless reporting by your analytics team?\n\nI would love to move towards a more loosely coupled architecture, however downstream of us are the analysts/report developers who want to build consolidated C-suite reports that pull from as much as they possibly can. Maybe the real question is: where do I start?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How tightly/loosely coupled is your data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bebg0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677307361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You build pipelines. Presumably some of these end up in an analytics layer, rendered by Tableau or PowerBI or similar. You may take on the duel role of Data Engineer and Analytics Engineer. If so, this question is aimed at you.&lt;/p&gt;\n\n&lt;p&gt;Data warehouses are, by definition tightly coupled datasets. Micro services on the other hand are loosely coupled. Regardless of sources, does your team have a preference for tightly/loosely coupled data, and if the latter how do you structure your data to allow seamless reporting by your analytics team?&lt;/p&gt;\n\n&lt;p&gt;I would love to move towards a more loosely coupled architecture, however downstream of us are the analysts/report developers who want to build consolidated C-suite reports that pull from as much as they possibly can. Maybe the real question is: where do I start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bebg0", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bebg0/how_tightlyloosely_coupled_is_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bebg0/how_tightlyloosely_coupled_is_your_data/", "subreddit_subscribers": 91130, "created_utc": 1677307361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a Bloom filter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11bxq6i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7YOp1XNFXfb8cGeAnbm-ba6G1toP9kAXObOpwKCGt1E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677364141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luminousmen.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luminousmen.com/post/building-a-bloom-filter", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YUUEFSs9tCHVxhQT7vtDkS3UmDEC1aqIZjIZSbIJuno.jpg?auto=webp&amp;v=enabled&amp;s=260f50370efd3deb993f022c1d941f624f76cc44", "width": 800, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/YUUEFSs9tCHVxhQT7vtDkS3UmDEC1aqIZjIZSbIJuno.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b77af8a5198928133742795ce5cec7ea349cc66f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/YUUEFSs9tCHVxhQT7vtDkS3UmDEC1aqIZjIZSbIJuno.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88d4b8b62de6c7f3c61f86c4d9b6f98de1916fc5", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/YUUEFSs9tCHVxhQT7vtDkS3UmDEC1aqIZjIZSbIJuno.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72475e75eb6754ca87b767e5a4ff13c4b0a829a7", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/YUUEFSs9tCHVxhQT7vtDkS3UmDEC1aqIZjIZSbIJuno.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15816b1901d37457968d0f981c97479bfb307ecb", "width": 640, "height": 480}], "variants": {}, "id": "Fd52pCihM2kNZJ-I4YvuSEGG94JI4-yoqmQcC-O0Us8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11bxq6i", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bxq6i/building_a_bloom_filter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luminousmen.com/post/building-a-bloom-filter", "subreddit_subscribers": 91130, "created_utc": 1677364141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you structure paths in different data lake zones (bronze, silver, gold)? Do you have everywhere the same paths just different bucket? E.g.\n\nbronze/customer/source=a/2023/02/22/raw.json\n\nbronze/customer/source=b/2023/02/22/raw.json\n\nsilver/customer/source=a/2023/02/22/processed.parquet\n\nsilver/customer/source=b/2023/02/22/processed.parquet\n\nSomething like that?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data lake zones structure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bs3f0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677350611.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677350094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you structure paths in different data lake zones (bronze, silver, gold)? Do you have everywhere the same paths just different bucket? E.g.&lt;/p&gt;\n\n&lt;p&gt;bronze/customer/source=a/2023/02/22/raw.json&lt;/p&gt;\n\n&lt;p&gt;bronze/customer/source=b/2023/02/22/raw.json&lt;/p&gt;\n\n&lt;p&gt;silver/customer/source=a/2023/02/22/processed.parquet&lt;/p&gt;\n\n&lt;p&gt;silver/customer/source=b/2023/02/22/processed.parquet&lt;/p&gt;\n\n&lt;p&gt;Something like that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bs3f0", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bs3f0/data_lake_zones_structure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bs3f0/data_lake_zones_structure/", "subreddit_subscribers": 91130, "created_utc": 1677350094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, I am still very new to STAR schema and decided to pick some dataset to try it out. Can someone please have a look at my schema design and give some feedback on it. \n\n&amp;#x200B;\n\nhttps://preview.redd.it/yorodl9wbcka1.png?width=1283&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=cedbf7d5c32c67f45db233572126dd44e77cf7ca\n\nI also add the example of the dataset that I am working on\n\n&amp;#x200B;\n\nhttps://preview.redd.it/ozslnsyybcka1.png?width=2880&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9b4ed1a992f7e3ff46248104c4b3225942b78d3b", "author_fullname": "t2_imktgzwy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design STAR schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "media_metadata": {"yorodl9wbcka1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 77, "x": 108, "u": "https://preview.redd.it/yorodl9wbcka1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c8b992af9da13b54166b0c7ba3a3f5a91cfe85f"}, {"y": 154, "x": 216, "u": "https://preview.redd.it/yorodl9wbcka1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f1159a99169818caf453c5d72673853c88b0a12"}, {"y": 229, "x": 320, "u": "https://preview.redd.it/yorodl9wbcka1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b68c396b379c8a9c768d3b6eb785e42e627933a"}, {"y": 458, "x": 640, "u": "https://preview.redd.it/yorodl9wbcka1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=927433051b577fc00417ba61551690f7e8de856a"}, {"y": 687, "x": 960, "u": "https://preview.redd.it/yorodl9wbcka1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=91a85847d569af2f861a57c33b63387a1785fb94"}, {"y": 773, "x": 1080, "u": "https://preview.redd.it/yorodl9wbcka1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee91d9837c929ff0938534e3ff1105feeb5e056d"}], "s": {"y": 919, "x": 1283, "u": "https://preview.redd.it/yorodl9wbcka1.png?width=1283&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=cedbf7d5c32c67f45db233572126dd44e77cf7ca"}, "id": "yorodl9wbcka1"}, "ozslnsyybcka1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/ozslnsyybcka1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa32de5b2c8805b377f88f1cf361da767f319df8"}, {"y": 135, "x": 216, "u": "https://preview.redd.it/ozslnsyybcka1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad9ac06801b984e3c77b10f80425813e62b12f4c"}, {"y": 200, "x": 320, "u": "https://preview.redd.it/ozslnsyybcka1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f41626b3283b55e7750d7fedb4475729b21498e"}, {"y": 400, "x": 640, "u": "https://preview.redd.it/ozslnsyybcka1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd77abea57383f4d7d7fafbddd8283d283929500"}, {"y": 600, "x": 960, "u": "https://preview.redd.it/ozslnsyybcka1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2def6fd61806928bd5ca081d52902116ff6e2f1f"}, {"y": 675, "x": 1080, "u": "https://preview.redd.it/ozslnsyybcka1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=817859a28f489cc0e82a7fff236ad40f91873c16"}], "s": {"y": 1800, "x": 2880, "u": "https://preview.redd.it/ozslnsyybcka1.png?width=2880&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9b4ed1a992f7e3ff46248104c4b3225942b78d3b"}, "id": "ozslnsyybcka1"}}, "name": "t3_11blma9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rCeRPdY_UyoCfSBFuEAfu8S1yhFwn1AL1Wzn8OnzeIA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677333470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I am still very new to STAR schema and decided to pick some dataset to try it out. Can someone please have a look at my schema design and give some feedback on it. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yorodl9wbcka1.png?width=1283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=cedbf7d5c32c67f45db233572126dd44e77cf7ca\"&gt;https://preview.redd.it/yorodl9wbcka1.png?width=1283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=cedbf7d5c32c67f45db233572126dd44e77cf7ca&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I also add the example of the dataset that I am working on&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ozslnsyybcka1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9b4ed1a992f7e3ff46248104c4b3225942b78d3b\"&gt;https://preview.redd.it/ozslnsyybcka1.png?width=2880&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9b4ed1a992f7e3ff46248104c4b3225942b78d3b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11blma9", "is_robot_indexable": true, "report_reasons": null, "author": "Acrobatic-Mobile-221", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11blma9/design_star_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11blma9/design_star_schema/", "subreddit_subscribers": 91130, "created_utc": 1677333470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which one is better if I want to find a DE job asap? And which one pays higher?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark vs Databricks? Which one should I learn to expect more jobs and higher salaries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11brvxm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677349586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which one is better if I want to find a DE job asap? And which one pays higher?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11brvxm", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11brvxm/apache_spark_vs_databricks_which_one_should_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11brvxm/apache_spark_vs_databricks_which_one_should_i/", "subreddit_subscribers": 91130, "created_utc": 1677349586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_170m1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "European Route Planning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bpmfp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1677344066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tech.marksblogg.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tech.marksblogg.com/route-planning-europe-postgresql-pgrouting.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11bpmfp", "is_robot_indexable": true, "report_reasons": null, "author": "marklit", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bpmfp/european_route_planning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tech.marksblogg.com/route-planning-europe-postgresql-pgrouting.html", "subreddit_subscribers": 91130, "created_utc": 1677344066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So the company I work for has this legacy data warehouse and applications that need to be migrated to an Azure data lake. I'm in charge of one of the biggest solutions which is kinda complex: data has several origins and flows from those sources to the data warehouse, the from there it moves to other databases and returns to the warehouse, etc and has fixes and patches all over the place. Basically it's kind of a mess. I'm in charge of not only migrating this, but also simplyfing and redesign a better solution. Has any of you had any experience with this kind of issue? How would you recommend me to prepare or skillset to have for this kind of task?@", "author_fullname": "t2_wah5l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating data models from legacy IPC workflows and Oracle data warehouse to Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bn94e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677337983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So the company I work for has this legacy data warehouse and applications that need to be migrated to an Azure data lake. I&amp;#39;m in charge of one of the biggest solutions which is kinda complex: data has several origins and flows from those sources to the data warehouse, the from there it moves to other databases and returns to the warehouse, etc and has fixes and patches all over the place. Basically it&amp;#39;s kind of a mess. I&amp;#39;m in charge of not only migrating this, but also simplyfing and redesign a better solution. Has any of you had any experience with this kind of issue? How would you recommend me to prepare or skillset to have for this kind of task?@&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bn94e", "is_robot_indexable": true, "report_reasons": null, "author": "reborndu", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bn94e/migrating_data_models_from_legacy_ipc_workflows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bn94e/migrating_data_models_from_legacy_ipc_workflows/", "subreddit_subscribers": 91130, "created_utc": 1677337983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My data lake has 3 layers: Bronze, Silver and Gold\n\nLet me explain purpose of each layer with an example\n\nWe have 3 files coming into my data lake named A, B and C\n\nIn the Bronze layer, we load all three files into hive layer as it is.\n\nFile data is moved from Bronze to Silver layer only if they pass data quality checks \n\nFinally, for gold layer, we do joins and transformations between multiple tables in Silver layer and load the results into gold layer tables.\n\nNow, this is where I am stumped. Should the golden layer just have views built on top of the Silver layer? What is the point of creating real tables just for golden layer?", "author_fullname": "t2_virernyk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would it be beneficial to have only \"views\" in my final golden layer if downstream users are just going to read the data and never write anything to the golden layer.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bkjve", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677330251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My data lake has 3 layers: Bronze, Silver and Gold&lt;/p&gt;\n\n&lt;p&gt;Let me explain purpose of each layer with an example&lt;/p&gt;\n\n&lt;p&gt;We have 3 files coming into my data lake named A, B and C&lt;/p&gt;\n\n&lt;p&gt;In the Bronze layer, we load all three files into hive layer as it is.&lt;/p&gt;\n\n&lt;p&gt;File data is moved from Bronze to Silver layer only if they pass data quality checks &lt;/p&gt;\n\n&lt;p&gt;Finally, for gold layer, we do joins and transformations between multiple tables in Silver layer and load the results into gold layer tables.&lt;/p&gt;\n\n&lt;p&gt;Now, this is where I am stumped. Should the golden layer just have views built on top of the Silver layer? What is the point of creating real tables just for golden layer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bkjve", "is_robot_indexable": true, "report_reasons": null, "author": "Hitoxi", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bkjve/would_it_be_beneficial_to_have_only_views_in_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bkjve/would_it_be_beneficial_to_have_only_views_in_my/", "subreddit_subscribers": 91130, "created_utc": 1677330251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHi everyone,\n\nI   am fairly new to the tech industry and have been working for a startup   for six months in the support team. My day-to-day tasks involve   identifying and fixing bugs in the company's products. However, I feel   like I am not making much progress in my career in this role and would   like to explore new fields where I can advance and become a senior  professional in a few years as possible as I could.\n\nI   have observed that software engineers are the majority in the field,  and  with more profiles with over five years of experience set to enter  the  job market between now and 2027, I'm concerned that I might not  have a  competitive edge as a software engineer. Therefore, I am  exploring  alternative career paths that are new, in-demand, and have a  high  potential for growth.\n\nI'm   considering pursuing a career in data engineering, DevOps, BI, or   product niche such as SAP. What do you think about these career paths?   Are there any other alternative paths you can suggest? I would   appreciate your advice and insights on this matter.\n\nThank you in advance for your help!", "author_fullname": "t2_d3rgt5sk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think SWE with 5yeo will still hold an edge as now in 2027 ? Is it better to switch to DE ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bztrq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677369529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I   am fairly new to the tech industry and have been working for a startup   for six months in the support team. My day-to-day tasks involve   identifying and fixing bugs in the company&amp;#39;s products. However, I feel   like I am not making much progress in my career in this role and would   like to explore new fields where I can advance and become a senior  professional in a few years as possible as I could.&lt;/p&gt;\n\n&lt;p&gt;I   have observed that software engineers are the majority in the field,  and  with more profiles with over five years of experience set to enter  the  job market between now and 2027, I&amp;#39;m concerned that I might not  have a  competitive edge as a software engineer. Therefore, I am  exploring  alternative career paths that are new, in-demand, and have a  high  potential for growth.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m   considering pursuing a career in data engineering, DevOps, BI, or   product niche such as SAP. What do you think about these career paths?   Are there any other alternative paths you can suggest? I would   appreciate your advice and insights on this matter.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bztrq", "is_robot_indexable": true, "report_reasons": null, "author": "maguire_SV", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bztrq/do_you_think_swe_with_5yeo_will_still_hold_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bztrq/do_you_think_swe_with_5yeo_will_still_hold_an/", "subreddit_subscribers": 91130, "created_utc": 1677369529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "i have been learning Azure recently and i noticed that Databricks is quite more integrated into Azure more that it is in AWS (i worked with AWS for 3 years in my previous employment). It is even a part of the Azure Data engineering certificate questions. \n\n&amp;#x200B;\n\nis there any advantage to using Databricks on Azure rather than AWS/GCP ?", "author_fullname": "t2_64nmnknh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks on AWS vs Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11breh6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677348362.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have been learning Azure recently and i noticed that Databricks is quite more integrated into Azure more that it is in AWS (i worked with AWS for 3 years in my previous employment). It is even a part of the Azure Data engineering certificate questions. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;is there any advantage to using Databricks on Azure rather than AWS/GCP ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11breh6", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDoggos5883", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11breh6/databricks_on_aws_vs_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11breh6/databricks_on_aws_vs_azure/", "subreddit_subscribers": 91130, "created_utc": 1677348362.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a use case where set of containerized workloads send their internal database's state through S3/RESTAPI based on AWS and trying to build an analytics with AWS Glue + Athena for it. I am looking for effective way to capture the changed data (specifically a set of events in the payload) and still make effective use of Glue + Sparks distribution. Here are more details :   \n\n\n1. Devices would be in the numbers of 20K - 30K sending data once/twice a day  \n\n2. The tools in these devices/containers are well written to capture the details of some of its internal database, form a JSON payload and send it. For each device, one example use case payload be like  :   \n{ \"device\\_firmware\": \"val\", \"device\\_name\": \"b\", \"device\\_prop1\": \"\", ... \"all\\_events\": \\[\\] }  \n\n3. As you can see for a particular use case its basically certain properties + all\\_events.  all\\_events is not new events, but all the events that have happened. So day1 for device1 it could be 10, next day 15 (5 new events added). This is because the architecture does not want to load these devices for any computation/diff of what was sent last and write any code to send diff + its possible they may go offiline for days, and once online should sync safely and send their complete state to the server.  \n\n4. Size of these all\\_events is not very large and does not grow a lot everyday but its not small either so expect it'd grow over say few months.  \n\n\n**Questions/comments** :   \n\n\n1. I have experience on Glue + Athena where a new data would land and I'd transform -&gt; parquet and load this into target Glue for Athena consumption, the Spark jobs are simple there.  \n\n2. I understand in above case, I'd have to do the compute/ keep some state of last processed/hash on ids and only load new ones however, I am also okay to fully load the complete state everytime as well and overwrite it. However, it means I'd have to overwrite the Parquet in target and do not know if the Spark workers can scale there as it has to map to that parquet file name when overriding. Want to hear suggestions here..  \n\n3. Hudi/Iceberg could be options here for upserts. If that is the case are there any performance considerations when utilizing large number of workers. E.g. if say I have such data for 20K devices in my S3 bucket and do the upserts, does Spark know how to distribute it in standard spark way where more workers can do this quickly? (each device state is independent so there is no shuffle or joins or anything)   \n\n4. In a traditional warehouses, if we have such use case where source dumps the complete state and not changed data, what is the reading/resources you'd recommend ?", "author_fullname": "t2_qg4yidm6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Data Lake + capturing only changed data from state dumps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bo3cy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677340162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a use case where set of containerized workloads send their internal database&amp;#39;s state through S3/RESTAPI based on AWS and trying to build an analytics with AWS Glue + Athena for it. I am looking for effective way to capture the changed data (specifically a set of events in the payload) and still make effective use of Glue + Sparks distribution. Here are more details :   &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Devices would be in the numbers of 20K - 30K sending data once/twice a day  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The tools in these devices/containers are well written to capture the details of some of its internal database, form a JSON payload and send it. For each device, one example use case payload be like  :&lt;br/&gt;\n{ &amp;quot;device_firmware&amp;quot;: &amp;quot;val&amp;quot;, &amp;quot;device_name&amp;quot;: &amp;quot;b&amp;quot;, &amp;quot;device_prop1&amp;quot;: &amp;quot;&amp;quot;, ... &amp;quot;all_events&amp;quot;: [] }  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;As you can see for a particular use case its basically certain properties + all_events.  all_events is not new events, but all the events that have happened. So day1 for device1 it could be 10, next day 15 (5 new events added). This is because the architecture does not want to load these devices for any computation/diff of what was sent last and write any code to send diff + its possible they may go offiline for days, and once online should sync safely and send their complete state to the server.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Size of these all_events is not very large and does not grow a lot everyday but its not small either so expect it&amp;#39;d grow over say few months.  &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions/comments&lt;/strong&gt; :   &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I have experience on Glue + Athena where a new data would land and I&amp;#39;d transform -&amp;gt; parquet and load this into target Glue for Athena consumption, the Spark jobs are simple there.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I understand in above case, I&amp;#39;d have to do the compute/ keep some state of last processed/hash on ids and only load new ones however, I am also okay to fully load the complete state everytime as well and overwrite it. However, it means I&amp;#39;d have to overwrite the Parquet in target and do not know if the Spark workers can scale there as it has to map to that parquet file name when overriding. Want to hear suggestions here..  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Hudi/Iceberg could be options here for upserts. If that is the case are there any performance considerations when utilizing large number of workers. E.g. if say I have such data for 20K devices in my S3 bucket and do the upserts, does Spark know how to distribute it in standard spark way where more workers can do this quickly? (each device state is independent so there is no shuffle or joins or anything)   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;In a traditional warehouses, if we have such use case where source dumps the complete state and not changed data, what is the reading/resources you&amp;#39;d recommend ?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11bo3cy", "is_robot_indexable": true, "report_reasons": null, "author": "Other_Cartoonist7071", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bo3cy/aws_data_lake_capturing_only_changed_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bo3cy/aws_data_lake_capturing_only_changed_data_from/", "subreddit_subscribers": 91130, "created_utc": 1677340162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lets say I have a DAG that runs every night. Every dag run has assigned start date and end date by default (Airflow built-in). \nOne day I need to rerun some of the tasks in this particular dag run. Currently, our applications rely on the start and end date passed from dag run. The apps take these parameters and based on them loads data between these two dates. So, if we want to rerun some tasks we go to the specific dag run and \u201cclear\u201d the tasks. (btw. we are talking about both - data extraction and transformation apps)\n\nHowever, I am thinking of maybe implementing different approach. That is having \u201cstaging\u201d data area where I would always put the data I want to process and after data is processed, clear up this stage. My motivation for this is that it might simplify rerunning particular tasks for longer history as now if I need to rerun tasks for lets say 30 days - I have to rerun 30 runs (times number of tasks needed to rerun) which is pretty complicated. In this new setup I would just copy all data needed to rerun 30days history into the \u201cstaging\u201d data area and manually trigger new dag run a let entire dag run even if some of the tasks would not have to do any processing. So apps would not rely on specific start and end date parameter but rather on the content of the staging data area. \n\nWhat do you think? Does it make sense? Do you see any potential issues? How do you approach this?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow reruns best practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bin0l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677323745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lets say I have a DAG that runs every night. Every dag run has assigned start date and end date by default (Airflow built-in). \nOne day I need to rerun some of the tasks in this particular dag run. Currently, our applications rely on the start and end date passed from dag run. The apps take these parameters and based on them loads data between these two dates. So, if we want to rerun some tasks we go to the specific dag run and \u201cclear\u201d the tasks. (btw. we are talking about both - data extraction and transformation apps)&lt;/p&gt;\n\n&lt;p&gt;However, I am thinking of maybe implementing different approach. That is having \u201cstaging\u201d data area where I would always put the data I want to process and after data is processed, clear up this stage. My motivation for this is that it might simplify rerunning particular tasks for longer history as now if I need to rerun tasks for lets say 30 days - I have to rerun 30 runs (times number of tasks needed to rerun) which is pretty complicated. In this new setup I would just copy all data needed to rerun 30days history into the \u201cstaging\u201d data area and manually trigger new dag run a let entire dag run even if some of the tasks would not have to do any processing. So apps would not rely on specific start and end date parameter but rather on the content of the staging data area. &lt;/p&gt;\n\n&lt;p&gt;What do you think? Does it make sense? Do you see any potential issues? How do you approach this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bin0l", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bin0l/airflow_reruns_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bin0l/airflow_reruns_best_practices/", "subreddit_subscribers": 91130, "created_utc": 1677323745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Redditors, \n\n&amp;#x200B;\n\nI am working on a research project, where I will have to play around with Spark Scheduler (basically implementing some scheduling algorithms). I have some basic knowledge of Spark, and I am proficient in Python but never used Scala before (I started learning Scala one month ago). \n\nFurthermore, I was wondering whether I should learn Scala and use Spark with Scala to be able to play around with Spark Scheduler, or is this possible using the python API (PySpark) ? \n\n I have around 3 months timeframe to finish this project, but I also have a few years of experience in software engineering with other programming languages (PHP, JS, Java) so learning some Scala to get started with Spark will not be hard I believe. \n\n&amp;#x200B;\n\nThank you !", "author_fullname": "t2_nq65wse7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use Scala or Python to work on Spark Scheduler", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c07vn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677370554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Redditors, &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am working on a research project, where I will have to play around with Spark Scheduler (basically implementing some scheduling algorithms). I have some basic knowledge of Spark, and I am proficient in Python but never used Scala before (I started learning Scala one month ago). &lt;/p&gt;\n\n&lt;p&gt;Furthermore, I was wondering whether I should learn Scala and use Spark with Scala to be able to play around with Spark Scheduler, or is this possible using the python API (PySpark) ? &lt;/p&gt;\n\n&lt;p&gt;I have around 3 months timeframe to finish this project, but I also have a few years of experience in software engineering with other programming languages (PHP, JS, Java) so learning some Scala to get started with Spark will not be hard I believe. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11c07vn", "is_robot_indexable": true, "report_reasons": null, "author": "lancelot_of_camelot", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c07vn/should_i_use_scala_or_python_to_work_on_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c07vn/should_i_use_scala_or_python_to_work_on_spark/", "subreddit_subscribers": 91130, "created_utc": 1677370554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So this year my org is finally taking data governance seriously enough to purchase a data catalog solution. I'm part of the team evaluating solutions, and one of the things I'm hearing constantly is the desire for a good \"out-of-the-box\" experience that will improve adoption among some of our analysts. We'd put together a homebrewed catalog a few years back and had very little adoption among our users, which is why that's now being emphasized.\n\nI'm currently looking at Alation now, but does anybody else have other recommendations? What, in your opinion, counts as a good OoTB experience for an analyst? I'm not an analyst myself and I don't have a ton of experience with what their day-to-day work looks like.", "author_fullname": "t2_jna1cg91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Data Catalog to Help Drive Adoption Among Analysts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bxx64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677364619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So this year my org is finally taking data governance seriously enough to purchase a data catalog solution. I&amp;#39;m part of the team evaluating solutions, and one of the things I&amp;#39;m hearing constantly is the desire for a good &amp;quot;out-of-the-box&amp;quot; experience that will improve adoption among some of our analysts. We&amp;#39;d put together a homebrewed catalog a few years back and had very little adoption among our users, which is why that&amp;#39;s now being emphasized.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking at Alation now, but does anybody else have other recommendations? What, in your opinion, counts as a good OoTB experience for an analyst? I&amp;#39;m not an analyst myself and I don&amp;#39;t have a ton of experience with what their day-to-day work looks like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11bxx64", "is_robot_indexable": true, "report_reasons": null, "author": "MaintenanceSad913", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bxx64/best_data_catalog_to_help_drive_adoption_among/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bxx64/best_data_catalog_to_help_drive_adoption_among/", "subreddit_subscribers": 91130, "created_utc": 1677364619.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}