{"kind": "Listing", "data": {"after": "t3_11bng86", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know this can vary significantly case by case, but mainly thinking in terms of the best structured DE projects that you\u2019ve seen on GitHub.", "author_fullname": "t2_bwp6e1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any examples of DE projects that you feel are the gold standard for how DE projects should be organized?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c06oj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677370463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this can vary significantly case by case, but mainly thinking in terms of the best structured DE projects that you\u2019ve seen on GitHub.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11c06oj", "is_robot_indexable": true, "report_reasons": null, "author": "wild_bill34", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c06oj/any_examples_of_de_projects_that_you_feel_are_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c06oj/any_examples_of_de_projects_that_you_feel_are_the/", "subreddit_subscribers": 91169, "created_utc": 1677370463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nTL;DR Do you think dashboards are really as useful as the amount of work that goes into them?\n\nI've been thinking about this a lot. Sorry for the slightly clickbait title. This may be selection bias but I frequently hear from other data engineers that they build dashboards that don't get used a lot. Or get stuck in infinite scope creep. \n\nWhich is an odd relationship to have because there is definitely a large chunk of analytics focused data engineering work that follows a high level pattern of 'integrate disparate data sources, model data views and metric calculations, make it available to a dashboard' \n\nI wanted to get this community's thoughts about how realistically useful dashboards are, or how often they think the dashboards justify themselves in value.\n\nMy two cents is that one fundamental problem of dashboards is that they are very often built around an assumption of what questions are worth answering. But the universality of that is in flux. The answer's value ebb and flow with time and accumulate nuances and caveats as the business evolves and the markets change. And so what happens then (which causes the infinite scope creep) is that someone with subject matter expertise will look at the dashboard and say 'can you also show, from this subset of whatever, what the breakdown of whatever is?'\n\nI think operations dashboards are necessary. Even just for us to have a simple place to check and see if sh*t is breaking. Operational dashboards simply provide the first order answers of what the hell is going on in very literal terms. Nothing beyond basic aggregations and generally are just a print out of transactions almost. \n\nWould be interested in hearing more people's perspective on this", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on analytical dashboard insanity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bw23f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1677361641.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677359973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR Do you think dashboards are really as useful as the amount of work that goes into them?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been thinking about this a lot. Sorry for the slightly clickbait title. This may be selection bias but I frequently hear from other data engineers that they build dashboards that don&amp;#39;t get used a lot. Or get stuck in infinite scope creep. &lt;/p&gt;\n\n&lt;p&gt;Which is an odd relationship to have because there is definitely a large chunk of analytics focused data engineering work that follows a high level pattern of &amp;#39;integrate disparate data sources, model data views and metric calculations, make it available to a dashboard&amp;#39; &lt;/p&gt;\n\n&lt;p&gt;I wanted to get this community&amp;#39;s thoughts about how realistically useful dashboards are, or how often they think the dashboards justify themselves in value.&lt;/p&gt;\n\n&lt;p&gt;My two cents is that one fundamental problem of dashboards is that they are very often built around an assumption of what questions are worth answering. But the universality of that is in flux. The answer&amp;#39;s value ebb and flow with time and accumulate nuances and caveats as the business evolves and the markets change. And so what happens then (which causes the infinite scope creep) is that someone with subject matter expertise will look at the dashboard and say &amp;#39;can you also show, from this subset of whatever, what the breakdown of whatever is?&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;I think operations dashboards are necessary. Even just for us to have a simple place to check and see if sh*t is breaking. Operational dashboards simply provide the first order answers of what the hell is going on in very literal terms. Nothing beyond basic aggregations and generally are just a print out of transactions almost. &lt;/p&gt;\n\n&lt;p&gt;Would be interested in hearing more people&amp;#39;s perspective on this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bw23f", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bw23f/thoughts_on_analytical_dashboard_insanity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bw23f/thoughts_on_analytical_dashboard_insanity/", "subreddit_subscribers": 91169, "created_utc": 1677359973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a Bloom filter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11bxq6i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7YOp1XNFXfb8cGeAnbm-ba6G1toP9kAXObOpwKCGt1E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677364141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luminousmen.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luminousmen.com/post/building-a-bloom-filter", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YUUEFSs9tCHVxhQT7vtDkS3UmDEC1aqIZjIZSbIJuno.jpg?auto=webp&amp;v=enabled&amp;s=260f50370efd3deb993f022c1d941f624f76cc44", "width": 800, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/YUUEFSs9tCHVxhQT7vtDkS3UmDEC1aqIZjIZSbIJuno.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b77af8a5198928133742795ce5cec7ea349cc66f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/YUUEFSs9tCHVxhQT7vtDkS3UmDEC1aqIZjIZSbIJuno.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88d4b8b62de6c7f3c61f86c4d9b6f98de1916fc5", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/YUUEFSs9tCHVxhQT7vtDkS3UmDEC1aqIZjIZSbIJuno.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72475e75eb6754ca87b767e5a4ff13c4b0a829a7", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/YUUEFSs9tCHVxhQT7vtDkS3UmDEC1aqIZjIZSbIJuno.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=15816b1901d37457968d0f981c97479bfb307ecb", "width": 640, "height": 480}], "variants": {}, "id": "Fd52pCihM2kNZJ-I4YvuSEGG94JI4-yoqmQcC-O0Us8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11bxq6i", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bxq6i/building_a_bloom_filter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luminousmen.com/post/building-a-bloom-filter", "subreddit_subscribers": 91169, "created_utc": 1677364141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, I have an interview on this Wednesday and Thursday. I am so stressed about it.. If anyone has any experience about it, could you please share your experiences? What type of questions should I expect, or what should I revise? I am looking forward to hearing from you... Please heelpp", "author_fullname": "t2_8yrfmc1z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "EA Data Engineer Intern Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c6k7j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677390110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I have an interview on this Wednesday and Thursday. I am so stressed about it.. If anyone has any experience about it, could you please share your experiences? What type of questions should I expect, or what should I revise? I am looking forward to hearing from you... Please heelpp&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11c6k7j", "is_robot_indexable": true, "report_reasons": null, "author": "nihadaen", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c6k7j/ea_data_engineer_intern_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c6k7j/ea_data_engineer_intern_interview/", "subreddit_subscribers": 91169, "created_utc": 1677390110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I make it a point to pay attention to trends in the labor markets. \n\nLately, at least for me, there has been an influx of azure job opportunities, and to a lessor extent, snowflake. That in and of itself isn't anything to raise an eyebrow to. But it's been weeks since I've gotten any aws opportunities in my inbox, even more so for databricks. Did microsoft and snowflake give out a bunch of free credits or something? The demand is so great, I'm seeing nil from their competitors. \n\nAnyone else noticed this? What gives?\n\nBonus question: Is this trend inspiring any of yall to upskill in azure? I'm overdue myself.", "author_fullname": "t2_7lvmv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's up with all these azure and snowflake opportunities in the labor markets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bmvtm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677337003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I make it a point to pay attention to trends in the labor markets. &lt;/p&gt;\n\n&lt;p&gt;Lately, at least for me, there has been an influx of azure job opportunities, and to a lessor extent, snowflake. That in and of itself isn&amp;#39;t anything to raise an eyebrow to. But it&amp;#39;s been weeks since I&amp;#39;ve gotten any aws opportunities in my inbox, even more so for databricks. Did microsoft and snowflake give out a bunch of free credits or something? The demand is so great, I&amp;#39;m seeing nil from their competitors. &lt;/p&gt;\n\n&lt;p&gt;Anyone else noticed this? What gives?&lt;/p&gt;\n\n&lt;p&gt;Bonus question: Is this trend inspiring any of yall to upskill in azure? I&amp;#39;m overdue myself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bmvtm", "is_robot_indexable": true, "report_reasons": null, "author": "claytonjr", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bmvtm/whats_up_with_all_these_azure_and_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bmvtm/whats_up_with_all_these_azure_and_snowflake/", "subreddit_subscribers": 91169, "created_utc": 1677337003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can anyone point me to resources that teach you how you can take a script and put it into a production environment that allows you to schedule it? Most courses I\u2019ve taken and videos I watch go through the process of pulling data from a source and pushing it into a destination, but I can\u2019t find any resources on how you actually get something into production. Excuse me if this is a trivial question, I\u2019m just genuinely struggling. Thank you in advance.", "author_fullname": "t2_3eirbc33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to put a pipeline into production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c8fjj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677397110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone point me to resources that teach you how you can take a script and put it into a production environment that allows you to schedule it? Most courses I\u2019ve taken and videos I watch go through the process of pulling data from a source and pushing it into a destination, but I can\u2019t find any resources on how you actually get something into production. Excuse me if this is a trivial question, I\u2019m just genuinely struggling. Thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11c8fjj", "is_robot_indexable": true, "report_reasons": null, "author": "pbxmy", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c8fjj/how_to_put_a_pipeline_into_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c8fjj/how_to_put_a_pipeline_into_production/", "subreddit_subscribers": 91169, "created_utc": 1677397110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The best of the best way to pull the Oracle data using AWS Glue in terms of performance for large tables holding 200M records. JDBC is very common. Is JDBC the best way to pull the data out from Oracle? Here we would like pull the data not Oracle team will extract the data and give to us. What is best way to pull the data.", "author_fullname": "t2_3sqs3uub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to pull the data from Oracle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bpnsb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677344163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The best of the best way to pull the Oracle data using AWS Glue in terms of performance for large tables holding 200M records. JDBC is very common. Is JDBC the best way to pull the data out from Oracle? Here we would like pull the data not Oracle team will extract the data and give to us. What is best way to pull the data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bpnsb", "is_robot_indexable": true, "report_reasons": null, "author": "priyasweety1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bpnsb/best_way_to_pull_the_data_from_oracle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bpnsb/best_way_to_pull_the_data_from_oracle/", "subreddit_subscribers": 91169, "created_utc": 1677344163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you structure paths in different data lake zones (bronze, silver, gold)? Do you have everywhere the same paths just different bucket? E.g.\n\nbronze/customer/source=a/2023/02/22/raw.json\n\nbronze/customer/source=b/2023/02/22/raw.json\n\nsilver/customer/source=a/2023/02/22/processed.parquet\n\nsilver/customer/source=b/2023/02/22/processed.parquet\n\nSomething like that?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data lake zones structure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bs3f0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677350611.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677350094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you structure paths in different data lake zones (bronze, silver, gold)? Do you have everywhere the same paths just different bucket? E.g.&lt;/p&gt;\n\n&lt;p&gt;bronze/customer/source=a/2023/02/22/raw.json&lt;/p&gt;\n\n&lt;p&gt;bronze/customer/source=b/2023/02/22/raw.json&lt;/p&gt;\n\n&lt;p&gt;silver/customer/source=a/2023/02/22/processed.parquet&lt;/p&gt;\n\n&lt;p&gt;silver/customer/source=b/2023/02/22/processed.parquet&lt;/p&gt;\n\n&lt;p&gt;Something like that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bs3f0", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bs3f0/data_lake_zones_structure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bs3f0/data_lake_zones_structure/", "subreddit_subscribers": 91169, "created_utc": 1677350094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_170m1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "European Route Planning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bpmfp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1677344066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tech.marksblogg.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tech.marksblogg.com/route-planning-europe-postgresql-pgrouting.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11bpmfp", "is_robot_indexable": true, "report_reasons": null, "author": "marklit", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bpmfp/european_route_planning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tech.marksblogg.com/route-planning-europe-postgresql-pgrouting.html", "subreddit_subscribers": 91169, "created_utc": 1677344066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So the company I work for has this legacy data warehouse and applications that need to be migrated to an Azure data lake. I'm in charge of one of the biggest solutions which is kinda complex: data has several origins and flows from those sources to the data warehouse, the from there it moves to other databases and returns to the warehouse, etc and has fixes and patches all over the place. Basically it's kind of a mess. I'm in charge of not only migrating this, but also simplyfing and redesign a better solution. Has any of you had any experience with this kind of issue? How would you recommend me to prepare or skillset to have for this kind of task?@", "author_fullname": "t2_wah5l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating data models from legacy IPC workflows and Oracle data warehouse to Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bn94e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677337983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So the company I work for has this legacy data warehouse and applications that need to be migrated to an Azure data lake. I&amp;#39;m in charge of one of the biggest solutions which is kinda complex: data has several origins and flows from those sources to the data warehouse, the from there it moves to other databases and returns to the warehouse, etc and has fixes and patches all over the place. Basically it&amp;#39;s kind of a mess. I&amp;#39;m in charge of not only migrating this, but also simplyfing and redesign a better solution. Has any of you had any experience with this kind of issue? How would you recommend me to prepare or skillset to have for this kind of task?@&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bn94e", "is_robot_indexable": true, "report_reasons": null, "author": "reborndu", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bn94e/migrating_data_models_from_legacy_ipc_workflows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bn94e/migrating_data_models_from_legacy_ipc_workflows/", "subreddit_subscribers": 91169, "created_utc": 1677337983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which one is better if I want to find a DE job asap? And which one pays higher?", "author_fullname": "t2_5t56uq7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Spark vs Databricks? Which one should I learn to expect more jobs and higher salaries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11brvxm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677349586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which one is better if I want to find a DE job asap? And which one pays higher?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11brvxm", "is_robot_indexable": true, "report_reasons": null, "author": "Born-Comment3359", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11brvxm/apache_spark_vs_databricks_which_one_should_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11brvxm/apache_spark_vs_databricks_which_one_should_i/", "subreddit_subscribers": 91169, "created_utc": 1677349586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "i have been learning Azure recently and i noticed that Databricks is quite more integrated into Azure more that it is in AWS (i worked with AWS for 3 years in my previous employment). It is even a part of the Azure Data engineering certificate questions. \n\n&amp;#x200B;\n\nis there any advantage to using Databricks on Azure rather than AWS/GCP ?", "author_fullname": "t2_64nmnknh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks on AWS vs Azure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11breh6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677348362.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have been learning Azure recently and i noticed that Databricks is quite more integrated into Azure more that it is in AWS (i worked with AWS for 3 years in my previous employment). It is even a part of the Azure Data engineering certificate questions. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;is there any advantage to using Databricks on Azure rather than AWS/GCP ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11breh6", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDoggos5883", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11breh6/databricks_on_aws_vs_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11breh6/databricks_on_aws_vs_azure/", "subreddit_subscribers": 91169, "created_utc": 1677348362.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a use case where set of containerized workloads send their internal database's state through S3/RESTAPI based on AWS and trying to build an analytics with AWS Glue + Athena for it. I am looking for effective way to capture the changed data (specifically a set of events in the payload) and still make effective use of Glue + Sparks distribution. Here are more details :   \n\n\n1. Devices would be in the numbers of 20K - 30K sending data once/twice a day  \n\n2. The tools in these devices/containers are well written to capture the details of some of its internal database, form a JSON payload and send it. For each device, one example use case payload be like  :   \n{ \"device\\_firmware\": \"val\", \"device\\_name\": \"b\", \"device\\_prop1\": \"\", ... \"all\\_events\": \\[\\] }  \n\n3. As you can see for a particular use case its basically certain properties + all\\_events.  all\\_events is not new events, but all the events that have happened. So day1 for device1 it could be 10, next day 15 (5 new events added). This is because the architecture does not want to load these devices for any computation/diff of what was sent last and write any code to send diff + its possible they may go offiline for days, and once online should sync safely and send their complete state to the server.  \n\n4. Size of these all\\_events is not very large and does not grow a lot everyday but its not small either so expect it'd grow over say few months.  \n\n\n**Questions/comments** :   \n\n\n1. I have experience on Glue + Athena where a new data would land and I'd transform -&gt; parquet and load this into target Glue for Athena consumption, the Spark jobs are simple there.  \n\n2. I understand in above case, I'd have to do the compute/ keep some state of last processed/hash on ids and only load new ones however, I am also okay to fully load the complete state everytime as well and overwrite it. However, it means I'd have to overwrite the Parquet in target and do not know if the Spark workers can scale there as it has to map to that parquet file name when overriding. Want to hear suggestions here..  \n\n3. Hudi/Iceberg could be options here for upserts. If that is the case are there any performance considerations when utilizing large number of workers. E.g. if say I have such data for 20K devices in my S3 bucket and do the upserts, does Spark know how to distribute it in standard spark way where more workers can do this quickly? (each device state is independent so there is no shuffle or joins or anything)   \n\n4. In a traditional warehouses, if we have such use case where source dumps the complete state and not changed data, what is the reading/resources you'd recommend ?", "author_fullname": "t2_qg4yidm6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Data Lake + capturing only changed data from state dumps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bo3cy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677340162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a use case where set of containerized workloads send their internal database&amp;#39;s state through S3/RESTAPI based on AWS and trying to build an analytics with AWS Glue + Athena for it. I am looking for effective way to capture the changed data (specifically a set of events in the payload) and still make effective use of Glue + Sparks distribution. Here are more details :   &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Devices would be in the numbers of 20K - 30K sending data once/twice a day  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The tools in these devices/containers are well written to capture the details of some of its internal database, form a JSON payload and send it. For each device, one example use case payload be like  :&lt;br/&gt;\n{ &amp;quot;device_firmware&amp;quot;: &amp;quot;val&amp;quot;, &amp;quot;device_name&amp;quot;: &amp;quot;b&amp;quot;, &amp;quot;device_prop1&amp;quot;: &amp;quot;&amp;quot;, ... &amp;quot;all_events&amp;quot;: [] }  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;As you can see for a particular use case its basically certain properties + all_events.  all_events is not new events, but all the events that have happened. So day1 for device1 it could be 10, next day 15 (5 new events added). This is because the architecture does not want to load these devices for any computation/diff of what was sent last and write any code to send diff + its possible they may go offiline for days, and once online should sync safely and send their complete state to the server.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Size of these all_events is not very large and does not grow a lot everyday but its not small either so expect it&amp;#39;d grow over say few months.  &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions/comments&lt;/strong&gt; :   &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I have experience on Glue + Athena where a new data would land and I&amp;#39;d transform -&amp;gt; parquet and load this into target Glue for Athena consumption, the Spark jobs are simple there.  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I understand in above case, I&amp;#39;d have to do the compute/ keep some state of last processed/hash on ids and only load new ones however, I am also okay to fully load the complete state everytime as well and overwrite it. However, it means I&amp;#39;d have to overwrite the Parquet in target and do not know if the Spark workers can scale there as it has to map to that parquet file name when overriding. Want to hear suggestions here..  &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Hudi/Iceberg could be options here for upserts. If that is the case are there any performance considerations when utilizing large number of workers. E.g. if say I have such data for 20K devices in my S3 bucket and do the upserts, does Spark know how to distribute it in standard spark way where more workers can do this quickly? (each device state is independent so there is no shuffle or joins or anything)   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;In a traditional warehouses, if we have such use case where source dumps the complete state and not changed data, what is the reading/resources you&amp;#39;d recommend ?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11bo3cy", "is_robot_indexable": true, "report_reasons": null, "author": "Other_Cartoonist7071", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bo3cy/aws_data_lake_capturing_only_changed_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bo3cy/aws_data_lake_capturing_only_changed_data_from/", "subreddit_subscribers": 91169, "created_utc": 1677340162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a PM and we are hiring a data engineer for our team. I would like to \"classify\" different motivational type of candidates.\n\nI imagine that there are the ones which are very technology driven who like to learn and work with different and new technologies.\n\nThen, maybe other who want to have end-to-end responsibility from source to even building DWH or even Dashboards.\n\nDoes this make sense ? What kind of \"types\" exists?", "author_fullname": "t2_e4028dc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What motivates a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ca12v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677403515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a PM and we are hiring a data engineer for our team. I would like to &amp;quot;classify&amp;quot; different motivational type of candidates.&lt;/p&gt;\n\n&lt;p&gt;I imagine that there are the ones which are very technology driven who like to learn and work with different and new technologies.&lt;/p&gt;\n\n&lt;p&gt;Then, maybe other who want to have end-to-end responsibility from source to even building DWH or even Dashboards.&lt;/p&gt;\n\n&lt;p&gt;Does this make sense ? What kind of &amp;quot;types&amp;quot; exists?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11ca12v", "is_robot_indexable": true, "report_reasons": null, "author": "tzt1324", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ca12v/what_motivates_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ca12v/what_motivates_a_data_engineer/", "subreddit_subscribers": 91169, "created_utc": 1677403515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Redditors, \n\n&amp;#x200B;\n\nI am working on a research project, where I will have to play around with Spark Scheduler (basically implementing some scheduling algorithms). I have some basic knowledge of Spark, and I am proficient in Python but never used Scala before (I started learning Scala one month ago). \n\nFurthermore, I was wondering whether I should learn Scala and use Spark with Scala to be able to play around with Spark Scheduler, or is this possible using the python API (PySpark) ? \n\n I have around 3 months timeframe to finish this project, but I also have a few years of experience in software engineering with other programming languages (PHP, JS, Java) so learning some Scala to get started with Spark will not be hard I believe. \n\n&amp;#x200B;\n\nThank you !", "author_fullname": "t2_nq65wse7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use Scala or Python to work on Spark Scheduler", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c07vn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677370554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Redditors, &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am working on a research project, where I will have to play around with Spark Scheduler (basically implementing some scheduling algorithms). I have some basic knowledge of Spark, and I am proficient in Python but never used Scala before (I started learning Scala one month ago). &lt;/p&gt;\n\n&lt;p&gt;Furthermore, I was wondering whether I should learn Scala and use Spark with Scala to be able to play around with Spark Scheduler, or is this possible using the python API (PySpark) ? &lt;/p&gt;\n\n&lt;p&gt;I have around 3 months timeframe to finish this project, but I also have a few years of experience in software engineering with other programming languages (PHP, JS, Java) so learning some Scala to get started with Spark will not be hard I believe. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11c07vn", "is_robot_indexable": true, "report_reasons": null, "author": "lancelot_of_camelot", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c07vn/should_i_use_scala_or_python_to_work_on_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c07vn/should_i_use_scala_or_python_to_work_on_spark/", "subreddit_subscribers": 91169, "created_utc": 1677370554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHi everyone,\n\nI   am fairly new to the tech industry and have been working for a startup   for six months in the support team. My day-to-day tasks involve   identifying and fixing bugs in the company's products. However, I feel   like I am not making much progress in my career in this role and would   like to explore new fields where I can advance and become a senior  professional in a few years as possible as I could.\n\nI   have observed that software engineers are the majority in the field,  and  with more profiles with over five years of experience set to enter  the  job market between now and 2027, I'm concerned that I might not  have a  competitive edge as a software engineer. Therefore, I am  exploring  alternative career paths that are new, in-demand, and have a  high  potential for growth.\n\nI'm   considering pursuing a career in data engineering, DevOps, BI, or   product niche such as SAP. What do you think about these career paths?   Are there any other alternative paths you can suggest? I would   appreciate your advice and insights on this matter.\n\nThank you in advance for your help!", "author_fullname": "t2_d3rgt5sk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you think SWE with 5yeo will still hold an edge as now in 2027 ? Is it better to switch to DE ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bztrq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677369529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I   am fairly new to the tech industry and have been working for a startup   for six months in the support team. My day-to-day tasks involve   identifying and fixing bugs in the company&amp;#39;s products. However, I feel   like I am not making much progress in my career in this role and would   like to explore new fields where I can advance and become a senior  professional in a few years as possible as I could.&lt;/p&gt;\n\n&lt;p&gt;I   have observed that software engineers are the majority in the field,  and  with more profiles with over five years of experience set to enter  the  job market between now and 2027, I&amp;#39;m concerned that I might not  have a  competitive edge as a software engineer. Therefore, I am  exploring  alternative career paths that are new, in-demand, and have a  high  potential for growth.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m   considering pursuing a career in data engineering, DevOps, BI, or   product niche such as SAP. What do you think about these career paths?   Are there any other alternative paths you can suggest? I would   appreciate your advice and insights on this matter.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bztrq", "is_robot_indexable": true, "report_reasons": null, "author": "maguire_SV", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bztrq/do_you_think_swe_with_5yeo_will_still_hold_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bztrq/do_you_think_swe_with_5yeo_will_still_hold_an/", "subreddit_subscribers": 91169, "created_utc": 1677369529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So this year my org is finally taking data governance seriously enough to purchase a data catalog solution. I'm part of the team evaluating solutions, and one of the things I'm hearing constantly is the desire for a good \"out-of-the-box\" experience that will improve adoption among some of our analysts. We'd put together a homebrewed catalog a few years back and had very little adoption among our users, which is why that's now being emphasized.\n\nI'm currently looking at Alation now, but does anybody else have other recommendations? What, in your opinion, counts as a good OoTB experience for an analyst? I'm not an analyst myself and I don't have a ton of experience with what their day-to-day work looks like.", "author_fullname": "t2_jna1cg91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Data Catalog to Help Drive Adoption Among Analysts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bxx64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677364619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So this year my org is finally taking data governance seriously enough to purchase a data catalog solution. I&amp;#39;m part of the team evaluating solutions, and one of the things I&amp;#39;m hearing constantly is the desire for a good &amp;quot;out-of-the-box&amp;quot; experience that will improve adoption among some of our analysts. We&amp;#39;d put together a homebrewed catalog a few years back and had very little adoption among our users, which is why that&amp;#39;s now being emphasized.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently looking at Alation now, but does anybody else have other recommendations? What, in your opinion, counts as a good OoTB experience for an analyst? I&amp;#39;m not an analyst myself and I don&amp;#39;t have a ton of experience with what their day-to-day work looks like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11bxx64", "is_robot_indexable": true, "report_reasons": null, "author": "MaintenanceSad913", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bxx64/best_data_catalog_to_help_drive_adoption_among/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bxx64/best_data_catalog_to_help_drive_adoption_among/", "subreddit_subscribers": 91169, "created_utc": 1677364619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am in Professional Services Division (PSD) at SAS. PSD at SAS is organized by industries.  I began developing pipelines and ETLs at insurance and banking. Then I worked at Law Enforcement/Public Safety/Government industry for 7 years before going back to Finance/Banking/Risk and Insurance for 2 more years. \n\nI have 3 rounds of job interviews in 2 weeks at a company I really like. This company PSD is organized by geography. Meaning PSD in their Austin office serves all customers in the CST region regardless of industry. \n\nIn my prep efforts, I am trying to compile challenges that data engineers face in other industries. IoT is one industry I am completely ignorant. \n\nPlease, post your industry and what real-world challenges you face so I can work on my real world technical answers.  Thanks.\n\nEDIT. I will be interviewed by a staff and two senior level engineers. I am sure their questions will be real world problems and not DE book academic exercises.", "author_fullname": "t2_og9di", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your industry, and what kind if challenges you face with your pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bvifd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677358844.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677358577.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in Professional Services Division (PSD) at SAS. PSD at SAS is organized by industries.  I began developing pipelines and ETLs at insurance and banking. Then I worked at Law Enforcement/Public Safety/Government industry for 7 years before going back to Finance/Banking/Risk and Insurance for 2 more years. &lt;/p&gt;\n\n&lt;p&gt;I have 3 rounds of job interviews in 2 weeks at a company I really like. This company PSD is organized by geography. Meaning PSD in their Austin office serves all customers in the CST region regardless of industry. &lt;/p&gt;\n\n&lt;p&gt;In my prep efforts, I am trying to compile challenges that data engineers face in other industries. IoT is one industry I am completely ignorant. &lt;/p&gt;\n\n&lt;p&gt;Please, post your industry and what real-world challenges you face so I can work on my real world technical answers.  Thanks.&lt;/p&gt;\n\n&lt;p&gt;EDIT. I will be interviewed by a staff and two senior level engineers. I am sure their questions will be real world problems and not DE book academic exercises.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11bvifd", "is_robot_indexable": true, "report_reasons": null, "author": "alfarosalvador", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bvifd/what_is_your_industry_and_what_kind_if_challenges/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bvifd/what_is_your_industry_and_what_kind_if_challenges/", "subreddit_subscribers": 91169, "created_utc": 1677358577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I have some lambdas and in the future some glue jobs which will be generating and moving files between the different zones (bronce, silver, etc). What are the advantages of using lake formation? Is it worth the cost? What I'm missing if I don't use it? I still don't totally get its purpose \ud83d\udc49\ud83d\udc48", "author_fullname": "t2_dpj60sgl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Lake Formation use cases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bp06b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677342525.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some lambdas and in the future some glue jobs which will be generating and moving files between the different zones (bronce, silver, etc). What are the advantages of using lake formation? Is it worth the cost? What I&amp;#39;m missing if I don&amp;#39;t use it? I still don&amp;#39;t totally get its purpose \ud83d\udc49\ud83d\udc48&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bp06b", "is_robot_indexable": true, "report_reasons": null, "author": "_unwin", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bp06b/aws_lake_formation_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bp06b/aws_lake_formation_use_cases/", "subreddit_subscribers": 91169, "created_utc": 1677342525.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,  \n  \nI was curious if anyone is scraping jobs data and what solution is being used.  \n  \nI am looking to pass company name as a parameter to pull jobs data. It does not have to be extensive. This is just tracking the number of open jobs, position title, position description.   \n  \nInitially I was going to build a custom python selenium parser for LinkedIn as I have built a similar parser for freight data previously. Although, my parser was quite slow and after looking into some APIs like SerpAPI I thought maybe there would be a more extensive solution (possibly more sites than LinkedIn) that wouldn't cost too terribly much.  \n  \nThere will likely be 1000-2000 company names that need parsed daily. The plan would be to icrease the velocity of this parsing over time to near-real-time but that is not important in the near future. This is for a personal project so the price is important.    \n  \nThank you all in advance!", "author_fullname": "t2_326jvb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scraping Job Data Solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bmio5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677336000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,  &lt;/p&gt;\n\n&lt;p&gt;I was curious if anyone is scraping jobs data and what solution is being used.  &lt;/p&gt;\n\n&lt;p&gt;I am looking to pass company name as a parameter to pull jobs data. It does not have to be extensive. This is just tracking the number of open jobs, position title, position description.   &lt;/p&gt;\n\n&lt;p&gt;Initially I was going to build a custom python selenium parser for LinkedIn as I have built a similar parser for freight data previously. Although, my parser was quite slow and after looking into some APIs like SerpAPI I thought maybe there would be a more extensive solution (possibly more sites than LinkedIn) that wouldn&amp;#39;t cost too terribly much.  &lt;/p&gt;\n\n&lt;p&gt;There will likely be 1000-2000 company names that need parsed daily. The plan would be to icrease the velocity of this parsing over time to near-real-time but that is not important in the near future. This is for a personal project so the price is important.    &lt;/p&gt;\n\n&lt;p&gt;Thank you all in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bmio5", "is_robot_indexable": true, "report_reasons": null, "author": "ShouldHaveWentBio", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bmio5/scraping_job_data_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bmio5/scraping_job_data_solution/", "subreddit_subscribers": 91169, "created_utc": 1677336000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have the following scenario (lets imagine every step is daily data load):\n\n\nFirstly, I save the parquet file with 3 columns 'a', 'b', 'c'.\n\n    d = {'a':[1], 'b':[2], 'c':[3]}\n    df = pd.DataFrame.from_dict(d)\n    df.to_parquet('schema/schema1.parquet')\n\nThen I save another file with only 2 columns 'a', 'b'\n\n    d = {'a':[1], 'c':[3]}\n    df = pd.DataFrame.from_dict(d)\n    df.to_parquet('schema/schema2.parquet')\n\nThen I add another file with 4 columns 'a', 'b', 'c', 'd'\n\n    d = {'a':[1], 'b':[2], 'c':[3], 'd':[4]}\n    df = pd.DataFrame.from_dict(d)\n    df.to_parquet('schema/schema3.parquet')\n\nNow, the issue is that when I read the parquet files using pandas (\\`pd.read\\_parquet('schema/')\\`), I get 3 rows (correct) but also only 3 columns (wrong) - I would expect getting 4 columns as the last file introduced the new column. Polars cannot even read the files as it complains straight away about a different number of columns.\n\nPossible solutions that come to my mind:\n\n1. Have some python library where all schemas would be defined so I would use this defined schema (python class) and try to parse the input data using the class attributes and in case any attribute is missing put there a None value. But that could be pretty complicated to implement probably. I would probably have to iterate over the files one by one and check schema conformity.\n2. Iterate over the files one by one and then concatenate (union) them. (Not too different from the previous actually)\n3. Any better solution?\n\nHow do you handle such cases?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parquet schema evolution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c9zr5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677403826.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677403358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have the following scenario (lets imagine every step is daily data load):&lt;/p&gt;\n\n&lt;p&gt;Firstly, I save the parquet file with 3 columns &amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;d = {&amp;#39;a&amp;#39;:[1], &amp;#39;b&amp;#39;:[2], &amp;#39;c&amp;#39;:[3]}\ndf = pd.DataFrame.from_dict(d)\ndf.to_parquet(&amp;#39;schema/schema1.parquet&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then I save another file with only 2 columns &amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;d = {&amp;#39;a&amp;#39;:[1], &amp;#39;c&amp;#39;:[3]}\ndf = pd.DataFrame.from_dict(d)\ndf.to_parquet(&amp;#39;schema/schema2.parquet&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then I add another file with 4 columns &amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;d&amp;#39;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;d = {&amp;#39;a&amp;#39;:[1], &amp;#39;b&amp;#39;:[2], &amp;#39;c&amp;#39;:[3], &amp;#39;d&amp;#39;:[4]}\ndf = pd.DataFrame.from_dict(d)\ndf.to_parquet(&amp;#39;schema/schema3.parquet&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Now, the issue is that when I read the parquet files using pandas (`pd.read_parquet(&amp;#39;schema/&amp;#39;)`), I get 3 rows (correct) but also only 3 columns (wrong) - I would expect getting 4 columns as the last file introduced the new column. Polars cannot even read the files as it complains straight away about a different number of columns.&lt;/p&gt;\n\n&lt;p&gt;Possible solutions that come to my mind:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Have some python library where all schemas would be defined so I would use this defined schema (python class) and try to parse the input data using the class attributes and in case any attribute is missing put there a None value. But that could be pretty complicated to implement probably. I would probably have to iterate over the files one by one and check schema conformity.&lt;/li&gt;\n&lt;li&gt;Iterate over the files one by one and then concatenate (union) them. (Not too different from the previous actually)&lt;/li&gt;\n&lt;li&gt;Any better solution?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;How do you handle such cases?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11c9zr5", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c9zr5/parquet_schema_evolution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c9zr5/parquet_schema_evolution/", "subreddit_subscribers": 91169, "created_utc": 1677403358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI've read the book cover to cover. But things change, topics aren't covered to the level they could be, and, it's been some years since I actually built a DV2.0 warehouse. Hoping to have a couple of questions answered by the community.\n\nEasy one first - at what point do you apply business naming conventions to the fields? Is it when you get to the point of the star schema, or do you do it before?\n\nNext one is a bit more complex:\n\nI have a \\`hub\\_customer\\` table. It was built off a Kafka event. The business key is customer\\_id. I have the following columns:\n\n* customer\\_hash\\_key\n* load\\_date\n* record\\_source\n* customer\\_id\n\nAll good so far. \n\nWe now need to ingest customers from Salesforce, where data is maintained across the \\`account\\` and \\`contact\\` tables. My understanding is that this should go into the 'same' hub, with a same-as-link table that creates the relation between the Kafka customer and the Salesforce account/contact.\n\nHow would you suggest adding the Salesforce dataset into the vault? \n\nShould the original \\`hub\\_customer\\` actually have be named \\`hub\\_customer0001\\`, and a new \\`hub\\_customer0002\\` be created that now has the following columns:\n\n* customer\\_hash\\_key\n* load\\_date\n* record\\_source\n* customer\\_id\n* account\\_id\n* contact\\_id\n\nOr would you just add the new columns to the existing table, or would you simply concat the account\\_id and contact\\_id into the customer\\_id column that already exists?\n\nPresumably if you went with the option of a new version number hub, it would be back-populated from a Kafka perspective and the \\`sat\\_customer\\_kafka\\` would then be used against this moving forward, and a new \\`sat\\_account\\_sf\\` and \\`sat\\_contact\\_sf\\` would also be generated that would point back to this same hub?\n\nI hope that makes sense?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Vault modelling questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11c5mf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677386815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read the book cover to cover. But things change, topics aren&amp;#39;t covered to the level they could be, and, it&amp;#39;s been some years since I actually built a DV2.0 warehouse. Hoping to have a couple of questions answered by the community.&lt;/p&gt;\n\n&lt;p&gt;Easy one first - at what point do you apply business naming conventions to the fields? Is it when you get to the point of the star schema, or do you do it before?&lt;/p&gt;\n\n&lt;p&gt;Next one is a bit more complex:&lt;/p&gt;\n\n&lt;p&gt;I have a `hub_customer` table. It was built off a Kafka event. The business key is customer_id. I have the following columns:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;customer_hash_key&lt;/li&gt;\n&lt;li&gt;load_date&lt;/li&gt;\n&lt;li&gt;record_source&lt;/li&gt;\n&lt;li&gt;customer_id&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;All good so far. &lt;/p&gt;\n\n&lt;p&gt;We now need to ingest customers from Salesforce, where data is maintained across the `account` and `contact` tables. My understanding is that this should go into the &amp;#39;same&amp;#39; hub, with a same-as-link table that creates the relation between the Kafka customer and the Salesforce account/contact.&lt;/p&gt;\n\n&lt;p&gt;How would you suggest adding the Salesforce dataset into the vault? &lt;/p&gt;\n\n&lt;p&gt;Should the original `hub_customer` actually have be named `hub_customer0001`, and a new `hub_customer0002` be created that now has the following columns:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;customer_hash_key&lt;/li&gt;\n&lt;li&gt;load_date&lt;/li&gt;\n&lt;li&gt;record_source&lt;/li&gt;\n&lt;li&gt;customer_id&lt;/li&gt;\n&lt;li&gt;account_id&lt;/li&gt;\n&lt;li&gt;contact_id&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Or would you just add the new columns to the existing table, or would you simply concat the account_id and contact_id into the customer_id column that already exists?&lt;/p&gt;\n\n&lt;p&gt;Presumably if you went with the option of a new version number hub, it would be back-populated from a Kafka perspective and the `sat_customer_kafka` would then be used against this moving forward, and a new `sat_account_sf` and `sat_contact_sf` would also be generated that would point back to this same hub?&lt;/p&gt;\n\n&lt;p&gt;I hope that makes sense?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11c5mf7", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11c5mf7/data_vault_modelling_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11c5mf7/data_vault_modelling_questions/", "subreddit_subscribers": 91169, "created_utc": 1677386815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Throwaway account for reasons. Was laid off early Jan (so I can\u2019t ask this on Blind) and am currently interviewing at Databricks as an SA. I\u2019ve had three interviews plus a take home assessment so far. Third interview was awful, but everything else was great + I have some amazing references. Recruiter emailed me on Friday asking to catch up on Monday afternoon. Any idea what this could mean? Currently freaking out since I\u2019ve heard of databricks making rejection calls.\n\n**edited for spelling", "author_fullname": "t2_5yco2o9ii", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks SA interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bwz4z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677362464.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677362241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Throwaway account for reasons. Was laid off early Jan (so I can\u2019t ask this on Blind) and am currently interviewing at Databricks as an SA. I\u2019ve had three interviews plus a take home assessment so far. Third interview was awful, but everything else was great + I have some amazing references. Recruiter emailed me on Friday asking to catch up on Monday afternoon. Any idea what this could mean? Currently freaking out since I\u2019ve heard of databricks making rejection calls.&lt;/p&gt;\n\n&lt;p&gt;**edited for spelling&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11bwz4z", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Employment89", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bwz4z/databricks_sa_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bwz4z/databricks_sa_interview/", "subreddit_subscribers": 91169, "created_utc": 1677362241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there,\n\nI've been working about 10 months in a data engineering consultant role where I've been on client site at a major energy company and briefly at an automotive place. The job unfortunately has been far too passive and I need to get real hard DE experience so I can really rank up my career experience as much as possible.\n\nI want to move out to the States for my next job, but am happy to go in at starting level because my experience so far working simply hasn't been rigorous or challenging enough. I am, however, aware that there are starting salaries around 90-115k, and I'd be looking to get in at that range to make things work out.\n\nI have family over there, but would still need a company to offer me a job online before moving over there so that I can get my working visa for the US.\n\nAny advice you could give me on where to look, what companies / areas I should focus my search on, and what sort of upskilling you think would be most valuable whilst I'm searching, I'd be super grateful!\n\nThank you all in advance", "author_fullname": "t2_vdvtwxn8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hello America, I am looking to move to the states for my next DE job (intra-company lateral move not viable). Any Advice??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bsxmz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677352230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working about 10 months in a data engineering consultant role where I&amp;#39;ve been on client site at a major energy company and briefly at an automotive place. The job unfortunately has been far too passive and I need to get real hard DE experience so I can really rank up my career experience as much as possible.&lt;/p&gt;\n\n&lt;p&gt;I want to move out to the States for my next job, but am happy to go in at starting level because my experience so far working simply hasn&amp;#39;t been rigorous or challenging enough. I am, however, aware that there are starting salaries around 90-115k, and I&amp;#39;d be looking to get in at that range to make things work out.&lt;/p&gt;\n\n&lt;p&gt;I have family over there, but would still need a company to offer me a job online before moving over there so that I can get my working visa for the US.&lt;/p&gt;\n\n&lt;p&gt;Any advice you could give me on where to look, what companies / areas I should focus my search on, and what sort of upskilling you think would be most valuable whilst I&amp;#39;m searching, I&amp;#39;d be super grateful!&lt;/p&gt;\n\n&lt;p&gt;Thank you all in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11bsxmz", "is_robot_indexable": true, "report_reasons": null, "author": "Wide-Holiday-6971", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bsxmz/hello_america_i_am_looking_to_move_to_the_states/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11bsxmz/hello_america_i_am_looking_to_move_to_the_states/", "subreddit_subscribers": 91169, "created_utc": 1677352230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hi all, I work in a data engineering role for a large pharma company and i'm just trying to get an idea of where everyone stands on the whole work from home vs return to office mess that a lot of  us are in. Some of us are strictly at home, others are hybrid and others are full time in the office. Personally, I'm hybrid 3 days a week and its honestly pointless.  I'm stuck in an office that is big, loud and noisy and its hard to concentrate. Worst of all, my team is spread out through the country so nobody in this office is on my team.  its a 45 minute commute with traffic and it sucks. I'm 100x more productive at home. For some of my teammates, they work in big empty offices which I think is even worse. \n\n[View Poll](https://www.reddit.com/poll/11bng86)", "author_fullname": "t2_stdv2q27", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am more productive and happier going into an office as opposed to working remotely from home", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11bng86", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677338492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi all, I work in a data engineering role for a large pharma company and i&amp;#39;m just trying to get an idea of where everyone stands on the whole work from home vs return to office mess that a lot of  us are in. Some of us are strictly at home, others are hybrid and others are full time in the office. Personally, I&amp;#39;m hybrid 3 days a week and its honestly pointless.  I&amp;#39;m stuck in an office that is big, loud and noisy and its hard to concentrate. Worst of all, my team is spread out through the country so nobody in this office is on my team.  its a 45 minute commute with traffic and it sucks. I&amp;#39;m 100x more productive at home. For some of my teammates, they work in big empty offices which I think is even worse. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11bng86\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11bng86", "is_robot_indexable": true, "report_reasons": null, "author": "xrt679", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1677597692935, "options": [{"text": "YES", "id": "21777559"}, {"text": "NO", "id": "21777560"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 183, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11bng86/i_am_more_productive_and_happier_going_into_an/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/11bng86/i_am_more_productive_and_happier_going_into_an/", "subreddit_subscribers": 91169, "created_utc": 1677338492.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}