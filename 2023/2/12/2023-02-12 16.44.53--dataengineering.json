{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am learning lots in terms of general data engineering at my current role but was wondering about the benefits of learning Data Structures and Algorithms on the side to further boost my skills. I have a few questions about this and would be grateful for any answers from those with experience and knowledge.\n\n1) Will bring better at DS&amp;A make me a better data engineer? I feel as though a lot of the skills aren't used directly in DE but please correct me if I'm wrong.\n\n2) How comprehensively would you need to know DS&amp;A for a DE coding exam when applying to new roles? I'd imagine it to be not as intense as a SWE role for example.\n\n3) What is a realistic timeframe to be able to start passing coding exams if I'm allocating around 5 hours a week to learning this?\n\n4) What are some good resources for learning this and is there anything that is a bit more tailored to DE DS&amp;A tests?\n\nThank you in advance for any responses.", "author_fullname": "t2_87ogeeb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Structures and Algorithms as a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11055pg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 45, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 45, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676169978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning lots in terms of general data engineering at my current role but was wondering about the benefits of learning Data Structures and Algorithms on the side to further boost my skills. I have a few questions about this and would be grateful for any answers from those with experience and knowledge.&lt;/p&gt;\n\n&lt;p&gt;1) Will bring better at DS&amp;amp;A make me a better data engineer? I feel as though a lot of the skills aren&amp;#39;t used directly in DE but please correct me if I&amp;#39;m wrong.&lt;/p&gt;\n\n&lt;p&gt;2) How comprehensively would you need to know DS&amp;amp;A for a DE coding exam when applying to new roles? I&amp;#39;d imagine it to be not as intense as a SWE role for example.&lt;/p&gt;\n\n&lt;p&gt;3) What is a realistic timeframe to be able to start passing coding exams if I&amp;#39;m allocating around 5 hours a week to learning this?&lt;/p&gt;\n\n&lt;p&gt;4) What are some good resources for learning this and is there anything that is a bit more tailored to DE DS&amp;amp;A tests?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11055pg", "is_robot_indexable": true, "report_reasons": null, "author": "SendMeYourThoughts", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11055pg/data_structures_and_algorithms_as_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11055pg/data_structures_and_algorithms_as_a_data_engineer/", "subreddit_subscribers": 89337, "created_utc": 1676169978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It\u2019s very early and experimental but it was born out of a desire to fix a lot of issues I had with editing dbt models in neovim. \n\n\nSome features: \n\nRun / test open model, the entire project, or arbitrary selectors\n\nAsync jobs with pop-up command outputs\n\nCustom dbt filetype with better syntax highlighting\n\nDisables accidentally modifying sql files in the target folders\n\nJump to any ref or source model using gf (go-to-file)\n\nTelescope Extension to fuzzy-find models\nAutomatically detect dbt project folder", "author_fullname": "t2_vxxrqrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wrote a dbt plugin for Neovim", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_10zs63w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RX7_91iWzk_OIsyuN9o4DdsGbtQqQ9nowrQ7XlGGHEc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676134628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It\u2019s very early and experimental but it was born out of a desire to fix a lot of issues I had with editing dbt models in neovim. &lt;/p&gt;\n\n&lt;p&gt;Some features: &lt;/p&gt;\n\n&lt;p&gt;Run / test open model, the entire project, or arbitrary selectors&lt;/p&gt;\n\n&lt;p&gt;Async jobs with pop-up command outputs&lt;/p&gt;\n\n&lt;p&gt;Custom dbt filetype with better syntax highlighting&lt;/p&gt;\n\n&lt;p&gt;Disables accidentally modifying sql files in the target folders&lt;/p&gt;\n\n&lt;p&gt;Jump to any ref or source model using gf (go-to-file)&lt;/p&gt;\n\n&lt;p&gt;Telescope Extension to fuzzy-find models\nAutomatically detect dbt project folder&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/PedramNavid/dbtpal", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?auto=webp&amp;v=enabled&amp;s=7e93dee1c3cb4e70bc180a6906e219a74bd6b786", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d72bac527ebde31306886896a0d3a103e4419791", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4eead8e0ac13949d0d9d2668ac28e2121a3f3647", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccb247e412b4d33305bf1a62173b4b92c75a9b29", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44c778939da1818981aa2ece7d26cd78f12ffb21", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bda6c77e215d210ada652b9bf5d7b0012eeec39", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c10d1705e0ea245e67b18f363eee781c019f582", "width": 1080, "height": 540}], "variants": {}, "id": "ajKwdyq3fMifnpDuCfjA1XC5MeSHNnZZqDOyqomfbJM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "10zs63w", "is_robot_indexable": true, "report_reasons": null, "author": "MrMosBiggestFan", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zs63w/i_wrote_a_dbt_plugin_for_neovim/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/PedramNavid/dbtpal", "subreddit_subscribers": 89337, "created_utc": 1676134628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nThe intention of this post is to stimulate discussion on the merits of various approaches to the ingestion of data into a cloud warehouse/lakehouse.\n\nHow do you go about it, and what are your reasons for doing so?\n\nQuestions to get us started:\n- do you land your data in an object store (s3, blob) before loading in to your warehouse? All the time, or just in certain circumstances? What about if you\u2019re ingesting from a SQL source?\n- do you have a preference for off the shelf solutions such as FiveTran/Matillion/ADF, or would you pref to build a framework yourself? Have you built a framework, and if so what language did you use &amp; how robust is it?\n- if you were to start from scratch, greenfield, what would it look like?\n\nAnd I\u2019ll begin by answering my own questions:\n- many of our sources sync directly into Snowflake, including Kafka, Segment and FiveTran. Where we have built a custom pipeline we land the data in S3 as a first hop.\n- my preference as a developer is to build. We have an oop python framework we have developed which is working well. But it\u2019s only used where an off the shelf solutions doesn\u2019t meet our needs. From a build vs buy strategy, we buy the ingestion and build the business transformation. It\u2019s the business logic that holds more value. We use dbt for transform.\n- if I were to go again, it would be a Hudi lakehouse, with a custom pipeline framework. It allows us to remain separated from specific vendor solutions which may lead to lock-in/cost hikes. I\u2019d likely retain dbt-cli, and as much as possible take a mesh/domain separation to the data (noting than business domain and business systems are different things).\n\nI\u2019d also want to do a far better job of making the data \u2018findable\u2019, but that\u2019s not strictly related to the title. We publish dbt docs right now, but have a number of dbt projects, and the information on the sources isn\u2019t contained in here. Planning to investigate OpenMetadata when we have capacity.\n\nKeen on others thoughts.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ingesting Data - workflow best practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1102xw5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676164104.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676163226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;The intention of this post is to stimulate discussion on the merits of various approaches to the ingestion of data into a cloud warehouse/lakehouse.&lt;/p&gt;\n\n&lt;p&gt;How do you go about it, and what are your reasons for doing so?&lt;/p&gt;\n\n&lt;p&gt;Questions to get us started:\n- do you land your data in an object store (s3, blob) before loading in to your warehouse? All the time, or just in certain circumstances? What about if you\u2019re ingesting from a SQL source?\n- do you have a preference for off the shelf solutions such as FiveTran/Matillion/ADF, or would you pref to build a framework yourself? Have you built a framework, and if so what language did you use &amp;amp; how robust is it?\n- if you were to start from scratch, greenfield, what would it look like?&lt;/p&gt;\n\n&lt;p&gt;And I\u2019ll begin by answering my own questions:\n- many of our sources sync directly into Snowflake, including Kafka, Segment and FiveTran. Where we have built a custom pipeline we land the data in S3 as a first hop.\n- my preference as a developer is to build. We have an oop python framework we have developed which is working well. But it\u2019s only used where an off the shelf solutions doesn\u2019t meet our needs. From a build vs buy strategy, we buy the ingestion and build the business transformation. It\u2019s the business logic that holds more value. We use dbt for transform.\n- if I were to go again, it would be a Hudi lakehouse, with a custom pipeline framework. It allows us to remain separated from specific vendor solutions which may lead to lock-in/cost hikes. I\u2019d likely retain dbt-cli, and as much as possible take a mesh/domain separation to the data (noting than business domain and business systems are different things).&lt;/p&gt;\n\n&lt;p&gt;I\u2019d also want to do a far better job of making the data \u2018findable\u2019, but that\u2019s not strictly related to the title. We publish dbt docs right now, but have a number of dbt projects, and the information on the sources isn\u2019t contained in here. Planning to investigate OpenMetadata when we have capacity.&lt;/p&gt;\n\n&lt;p&gt;Keen on others thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1102xw5", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1102xw5/ingesting_data_workflow_best_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1102xw5/ingesting_data_workflow_best_practice/", "subreddit_subscribers": 89337, "created_utc": 1676163226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If so: What is it?", "author_fullname": "t2_6fdt02qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have a side business?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ztssr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676138829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If so: What is it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ztssr", "is_robot_indexable": true, "report_reasons": null, "author": "Insighteous", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ztssr/do_you_have_a_side_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ztssr/do_you_have_a_side_business/", "subreddit_subscribers": 89337, "created_utc": 1676138829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I work as DWH developer for 4 years, I work with Oracle Database, use Oracle Data Integrator and PL/SQL for ETL. My strongest skills are SQL, relational databates, PL/SQL, data modelling (dimensional data model, star schemas, scd...generally everything from kimball's datawarehouse toolkit). \nI've just got offered job as Data Engineer. I'd love to learn how to make DWH and ETL in modern way but I am also scared, to be honest. I have no experience with cloud, I have only basic knowledge of Python. I've never worked with Docker and I know only basics of Linux and git. Should I take that job or should I study cloud, Python etc and then apply for the similar position?", "author_fullname": "t2_kh4jiqla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DWH developer transformation to Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110bvt7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676194728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I work as DWH developer for 4 years, I work with Oracle Database, use Oracle Data Integrator and PL/SQL for ETL. My strongest skills are SQL, relational databates, PL/SQL, data modelling (dimensional data model, star schemas, scd...generally everything from kimball&amp;#39;s datawarehouse toolkit). \nI&amp;#39;ve just got offered job as Data Engineer. I&amp;#39;d love to learn how to make DWH and ETL in modern way but I am also scared, to be honest. I have no experience with cloud, I have only basic knowledge of Python. I&amp;#39;ve never worked with Docker and I know only basics of Linux and git. Should I take that job or should I study cloud, Python etc and then apply for the similar position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110bvt7", "is_robot_indexable": true, "report_reasons": null, "author": "No_Pause7942", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110bvt7/dwh_developer_transformation_to_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110bvt7/dwh_developer_transformation_to_data_engineer/", "subreddit_subscribers": 89337, "created_utc": 1676194728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently I\u2019m a data analyst that specifically works with my company\u2019s inventory. And I\u2019m stalling, I only use excel/power query, all the data I use comes from our CRM or our partners, and is put into excel. It sucks to work with, if I scroll to fast on some sheets they\u2019ll crash because there\u2019s too many rows. \n\nAnyway, working this job I realized I enjoy automating work sheets, and the overall work process more than the analyzation. So I\u2019d like to move into data engineering and want to gear my personal portfolio towards that. I thinking of doing a project where I just make a simple pipeline. I want to use Python and Spotify\u2019s API to extract and transform the data, and load it into a Power BI dashboard. However, I\u2019m not a data engineer, and honestly I\u2019m a pretty low level analyst with an out of date skill set, and I\u2019m not sure if this project is something worthwhile. \n\nIt seems like data engineering is a very wide field in terms of tools used, and I\u2019m not sure if the tools above are what\u2019s desired by employers or atleast shows desirable skills, so any feedback would be greatly appreciated, thanks!", "author_fullname": "t2_49nguj2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to start a data engineering project but not sure if I have the right idea", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11010wf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676157837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I\u2019m a data analyst that specifically works with my company\u2019s inventory. And I\u2019m stalling, I only use excel/power query, all the data I use comes from our CRM or our partners, and is put into excel. It sucks to work with, if I scroll to fast on some sheets they\u2019ll crash because there\u2019s too many rows. &lt;/p&gt;\n\n&lt;p&gt;Anyway, working this job I realized I enjoy automating work sheets, and the overall work process more than the analyzation. So I\u2019d like to move into data engineering and want to gear my personal portfolio towards that. I thinking of doing a project where I just make a simple pipeline. I want to use Python and Spotify\u2019s API to extract and transform the data, and load it into a Power BI dashboard. However, I\u2019m not a data engineer, and honestly I\u2019m a pretty low level analyst with an out of date skill set, and I\u2019m not sure if this project is something worthwhile. &lt;/p&gt;\n\n&lt;p&gt;It seems like data engineering is a very wide field in terms of tools used, and I\u2019m not sure if the tools above are what\u2019s desired by employers or atleast shows desirable skills, so any feedback would be greatly appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11010wf", "is_robot_indexable": true, "report_reasons": null, "author": "Hillsand0", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11010wf/i_want_to_start_a_data_engineering_project_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11010wf/i_want_to_start_a_data_engineering_project_but/", "subreddit_subscribers": 89337, "created_utc": 1676157837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say you have a medallion architecture lakehouse/warehouse. There are facts and dimensions in your gold layer used for analytics.\n\nYou have a request to pull data from one source, provide some cleaning and logic to it and then send it to another system via their API. At this stage, there is no requirement from analysts to see this data in a fact/dim.\n\nDo you build a completely standalone pipeline to cater to the need?\n\nDo you ingest into bronze, bring through to silver to align with all other data in a consistent manner, potentially building that into larger source agnostic tables, and then send it out from there?\n\nDo you do something different?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a minimum level you take your data through a warehouse before showing it to users?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110403g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676166370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you have a medallion architecture lakehouse/warehouse. There are facts and dimensions in your gold layer used for analytics.&lt;/p&gt;\n\n&lt;p&gt;You have a request to pull data from one source, provide some cleaning and logic to it and then send it to another system via their API. At this stage, there is no requirement from analysts to see this data in a fact/dim.&lt;/p&gt;\n\n&lt;p&gt;Do you build a completely standalone pipeline to cater to the need?&lt;/p&gt;\n\n&lt;p&gt;Do you ingest into bronze, bring through to silver to align with all other data in a consistent manner, potentially building that into larger source agnostic tables, and then send it out from there?&lt;/p&gt;\n\n&lt;p&gt;Do you do something different?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110403g", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110403g/is_there_a_minimum_level_you_take_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110403g/is_there_a_minimum_level_you_take_your_data/", "subreddit_subscribers": 89337, "created_utc": 1676166370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Side projects? Reading? Courses?\n\nAs someone with no formal background in SWE/tech, most of my improvement has come from the desire to learn more about things. Not the most structured approach though, just curious to know how everyone else keeps their skills sharp!", "author_fullname": "t2_15ztlh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you personally do to improve as a DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110gth0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676211704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Side projects? Reading? Courses?&lt;/p&gt;\n\n&lt;p&gt;As someone with no formal background in SWE/tech, most of my improvement has come from the desire to learn more about things. Not the most structured approach though, just curious to know how everyone else keeps their skills sharp!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110gth0", "is_robot_indexable": true, "report_reasons": null, "author": "rlyply", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110gth0/what_do_you_personally_do_to_improve_as_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110gth0/what_do_you_personally_do_to_improve_as_a_de/", "subreddit_subscribers": 89337, "created_utc": 1676211704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it still an open and fully interoperable building block? Or can tables in Unity Catalog can only be queried by Databricks' engine?", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If I use Databricks Unity Catalog, can i still use open source Spark or Presto / Trino (or any other SQL engine for that matter) to query tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1108cug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676180881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it still an open and fully interoperable building block? Or can tables in Unity Catalog can only be queried by Databricks&amp;#39; engine?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1108cug", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1108cug/if_i_use_databricks_unity_catalog_can_i_still_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1108cug/if_i_use_databricks_unity_catalog_can_i_still_use/", "subreddit_subscribers": 89337, "created_utc": 1676180881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cqao8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fixing iMessage search with DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_10zya3n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UTDqxp8lwTt7YNzKZRrJ34PKpig1gaF2Vc5DoaB5fhA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676150440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arecadata.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.arecadata.com/analyzing-imessage-data-with-duckdb/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?auto=webp&amp;v=enabled&amp;s=6e8766df6a1f23a768be56b5c70524dea5767092", "width": 2000, "height": 1333}, "resolutions": [{"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f30f04385659e52ff23a1a6c831437c7c4f4aa1", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92ba4aba8c0d7007e9b8c5e4095093e12f1e0d8d", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9c20078b7b68a8d02eae7390db79f4b37aa4bc1", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f9c6a3413d4569149a29505c748629631b59e9e", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3edc94694e982b0d785026c791e785f5662d59b9", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b4ec75131e0c602b635dc4548b717729e9a99dc", "width": 1080, "height": 719}], "variants": {}, "id": "rak11NSlLzYqT7yjd33V5YkXdlq37ptPu7yolvA6Gt8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10zya3n", "is_robot_indexable": true, "report_reasons": null, "author": "dan_the_lion", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zya3n/fixing_imessage_search_with_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arecadata.com/analyzing-imessage-data-with-duckdb/", "subreddit_subscribers": 89337, "created_utc": 1676150440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been using Xplenty to extract data from GBQ and to load into a MySQL DB instance. I think Xplenty uses a framework of Apache to transfer data (I have read the error logs, and it seems like it is an Apache framework). \n\nNow, let\u2019s say if I have to load data (2k rows) using a Python script that is run on my machine. It takes less than a few seconds to extract and load. But, if I do is from Xplenty, it takes minutes to load. \n\nWhat is the reason for ETL tools to be slow when transferring data? I have heard that frameworks like Apache Spark, they are really fast. But why isn\u2019t the speed reflected when I use an ETL tool that is supposed to be running an Apache framework? \n\nI have always thought about this but didn\u2019t find anything helpful for me.", "author_fullname": "t2_emzh9atv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why ETL tools take a lot of time to transfer data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zs7xo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676134759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been using Xplenty to extract data from GBQ and to load into a MySQL DB instance. I think Xplenty uses a framework of Apache to transfer data (I have read the error logs, and it seems like it is an Apache framework). &lt;/p&gt;\n\n&lt;p&gt;Now, let\u2019s say if I have to load data (2k rows) using a Python script that is run on my machine. It takes less than a few seconds to extract and load. But, if I do is from Xplenty, it takes minutes to load. &lt;/p&gt;\n\n&lt;p&gt;What is the reason for ETL tools to be slow when transferring data? I have heard that frameworks like Apache Spark, they are really fast. But why isn\u2019t the speed reflected when I use an ETL tool that is supposed to be running an Apache framework? &lt;/p&gt;\n\n&lt;p&gt;I have always thought about this but didn\u2019t find anything helpful for me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10zs7xo", "is_robot_indexable": true, "report_reasons": null, "author": "MaintenanceSad6825", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zs7xo/why_etl_tools_take_a_lot_of_time_to_transfer_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zs7xo/why_etl_tools_take_a_lot_of_time_to_transfer_data/", "subreddit_subscribers": 89337, "created_utc": 1676134759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Excluding airbnb (major resorts, hotels, etc.)\n\nAt the moment, it seems the industry either builds everything in house or use 3rd party systems for each task (communication, profiling, check-in management, data storage/retrieval, etc.)", "author_fullname": "t2_rt5kovjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data engineers here with experience in building a data platform for the hospitality and travel industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110471e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676166967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Excluding airbnb (major resorts, hotels, etc.)&lt;/p&gt;\n\n&lt;p&gt;At the moment, it seems the industry either builds everything in house or use 3rd party systems for each task (communication, profiling, check-in management, data storage/retrieval, etc.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110471e", "is_robot_indexable": true, "report_reasons": null, "author": "slp_001100", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110471e/any_data_engineers_here_with_experience_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110471e/any_data_engineers_here_with_experience_in/", "subreddit_subscribers": 89337, "created_utc": 1676166967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been reading through O'Reilly's *Data Pipelines Pocket Reference* which has done a really great job of breaking apart the steps of an ELT pipeline into real-world use cases. I like how the extraction step is simplified to reading from a source and writing a CSV to S3; and the examples for ingesting from DBs or APIs make sense.\n\nMy questions are pretty simple, but when I think about how to apply the same logic to sourcing from a filesystem (or S3 path) I have a few more questions...\n\n1. Unlike a DB, files don't have primary keys, but often, the file's parent directory path can be used to uniquely identify the file, would I be right to include the path and any other data to the output CSV in my Extract step? Would this be considered EtLT?\n2. Expanding on the first question, In cases where the directory path is important for uniquely identifying a file, what do I do when I have two or more different file types that I'm interested in under the same parent directory? Should I Extract each separately to it's own CSV? Should I create a single CSV for all the files under that parent directory, joining files together? Something else?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should I be Extracting data files from a filesystem/S3 like I do for DBs &amp; APIs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1103z7u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676166303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been reading through O&amp;#39;Reilly&amp;#39;s &lt;em&gt;Data Pipelines Pocket Reference&lt;/em&gt; which has done a really great job of breaking apart the steps of an ELT pipeline into real-world use cases. I like how the extraction step is simplified to reading from a source and writing a CSV to S3; and the examples for ingesting from DBs or APIs make sense.&lt;/p&gt;\n\n&lt;p&gt;My questions are pretty simple, but when I think about how to apply the same logic to sourcing from a filesystem (or S3 path) I have a few more questions...&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Unlike a DB, files don&amp;#39;t have primary keys, but often, the file&amp;#39;s parent directory path can be used to uniquely identify the file, would I be right to include the path and any other data to the output CSV in my Extract step? Would this be considered EtLT?&lt;/li&gt;\n&lt;li&gt;Expanding on the first question, In cases where the directory path is important for uniquely identifying a file, what do I do when I have two or more different file types that I&amp;#39;m interested in under the same parent directory? Should I Extract each separately to it&amp;#39;s own CSV? Should I create a single CSV for all the files under that parent directory, joining files together? Something else?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1103z7u", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1103z7u/how_should_i_be_extracting_data_files_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1103z7u/how_should_i_be_extracting_data_files_from_a/", "subreddit_subscribers": 89337, "created_utc": 1676166303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Company uses Domo as our data warehouse and BI solution. I run into problems once a month where incorrect manually entered data in systems gets into an important table and I have no way of fixing it unless I reload the data and replace all data in the table. Is anyone else working with Domo and how do you handle cleaning up incorrect inputs?", "author_fullname": "t2_3eirbc33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone use Domo?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1100m81", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676156686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Company uses Domo as our data warehouse and BI solution. I run into problems once a month where incorrect manually entered data in systems gets into an important table and I have no way of fixing it unless I reload the data and replace all data in the table. Is anyone else working with Domo and how do you handle cleaning up incorrect inputs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1100m81", "is_robot_indexable": true, "report_reasons": null, "author": "pbxmy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1100m81/does_anyone_use_domo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1100m81/does_anyone_use_domo/", "subreddit_subscribers": 89337, "created_utc": 1676156686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI have been in data engineering for a long time but pretty much purely in the batch processing / analytics warehouse creation and management space. Airflow, modeling, reporting, SQL etc. The places that I've worked largely haven't had a dire need for stream processing relative to other needs, but I'm trying to move myself and my team members more in that direction. \n\nGiven I don't have a ton of accessible stream-data to experiment with at work, are there good resources available publicly to consume and develop data stream processes? I'm particularly interested in Kinesis because of the AWS infrastructure I deal with at work. \n\nThanks for any help!", "author_fullname": "t2_wxoh8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need to buff up my data streaming skills. Any good resources for toy/demo projects utilizing Kinesis specifically? Sources for free streaming data to work on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zujtf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676140733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I have been in data engineering for a long time but pretty much purely in the batch processing / analytics warehouse creation and management space. Airflow, modeling, reporting, SQL etc. The places that I&amp;#39;ve worked largely haven&amp;#39;t had a dire need for stream processing relative to other needs, but I&amp;#39;m trying to move myself and my team members more in that direction. &lt;/p&gt;\n\n&lt;p&gt;Given I don&amp;#39;t have a ton of accessible stream-data to experiment with at work, are there good resources available publicly to consume and develop data stream processes? I&amp;#39;m particularly interested in Kinesis because of the AWS infrastructure I deal with at work. &lt;/p&gt;\n\n&lt;p&gt;Thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10zujtf", "is_robot_indexable": true, "report_reasons": null, "author": "tylerjaywood", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zujtf/i_need_to_buff_up_my_data_streaming_skills_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zujtf/i_need_to_buff_up_my_data_streaming_skills_any/", "subreddit_subscribers": 89337, "created_utc": 1676140733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, my friend wants to learn SQL what would you recommend as the best way of learning SQL ?", "author_fullname": "t2_3xupopvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL tips", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_110hva6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676214594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, my friend wants to learn SQL what would you recommend as the best way of learning SQL ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "110hva6", "is_robot_indexable": true, "report_reasons": null, "author": "Sulaiman_m97", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110hva6/sql_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110hva6/sql_tips/", "subreddit_subscribers": 89337, "created_utc": 1676214594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI'm new to Data Modelling and I'm currently stumped at a personal project. Allow me to give some context first.\n\nI have been given a preaggregated data set containing preorders at a daily level. Basically everyday I will get a flat file that has the summed up amounts of preorders by day (past, present and future), store, and product category. I don't have customer or product information. \n\nFor example, in the file from yesterday, I would have preorders slated for 13 May 2023 as 13, comprised of any unknown number of customers ordering any number of unknown products. Then when I get today's file, I will see that for 13 May 2023, I now have 5 preorders, meaning either some or all the customers from yesterday's 13 preorders probably cancelled or shifted their preorders to another unknown date. \n\nTo conplicate matters, if for preorder date of 13 May 2023, the amount of preorders went from 13 to 0, I would not get that row with preorder count = 0 in the new file. \n\nThe idea is to have this dataset feed a dashboard so that the end user can track the growth of preorders for any given date and store as time/year progresses.\n\nI looked into SCD2 but I'm not sure if this is the right approach for the task. Because for one, the preorders are facts and it is the facts that are changing, not dimensions, hence I thought slowly changing facts?\n\nAnother reason I think SCD2 is not right because I was told that I shouldn't be using the preorder column as a \"join condition/key\" to check whether or not a record changed (preorder date, store, category as composite keys) from one day's file to another day's file. Otherwise I think I would be doing this with some extra steps in addition to a Merge statement. \n\nSo I'm reaching out for help from all you gurus because I'm getting nowhere despite all the Googling. I'm trying to do this in SQL Server but will eventually move it to Snowflake.\n\nThank you in advance!", "author_fullname": "t2_iv0k1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Data Modelling, how to design for preorders that change as time progresses? Have you done slowly changing \"facts\" in SQL and how would you do it in this case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_110ipjw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676216815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new to Data Modelling and I&amp;#39;m currently stumped at a personal project. Allow me to give some context first.&lt;/p&gt;\n\n&lt;p&gt;I have been given a preaggregated data set containing preorders at a daily level. Basically everyday I will get a flat file that has the summed up amounts of preorders by day (past, present and future), store, and product category. I don&amp;#39;t have customer or product information. &lt;/p&gt;\n\n&lt;p&gt;For example, in the file from yesterday, I would have preorders slated for 13 May 2023 as 13, comprised of any unknown number of customers ordering any number of unknown products. Then when I get today&amp;#39;s file, I will see that for 13 May 2023, I now have 5 preorders, meaning either some or all the customers from yesterday&amp;#39;s 13 preorders probably cancelled or shifted their preorders to another unknown date. &lt;/p&gt;\n\n&lt;p&gt;To conplicate matters, if for preorder date of 13 May 2023, the amount of preorders went from 13 to 0, I would not get that row with preorder count = 0 in the new file. &lt;/p&gt;\n\n&lt;p&gt;The idea is to have this dataset feed a dashboard so that the end user can track the growth of preorders for any given date and store as time/year progresses.&lt;/p&gt;\n\n&lt;p&gt;I looked into SCD2 but I&amp;#39;m not sure if this is the right approach for the task. Because for one, the preorders are facts and it is the facts that are changing, not dimensions, hence I thought slowly changing facts?&lt;/p&gt;\n\n&lt;p&gt;Another reason I think SCD2 is not right because I was told that I shouldn&amp;#39;t be using the preorder column as a &amp;quot;join condition/key&amp;quot; to check whether or not a record changed (preorder date, store, category as composite keys) from one day&amp;#39;s file to another day&amp;#39;s file. Otherwise I think I would be doing this with some extra steps in addition to a Merge statement. &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m reaching out for help from all you gurus because I&amp;#39;m getting nowhere despite all the Googling. I&amp;#39;m trying to do this in SQL Server but will eventually move it to Snowflake.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110ipjw", "is_robot_indexable": true, "report_reasons": null, "author": "RoyalStraightFlush", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110ipjw/new_to_data_modelling_how_to_design_for_preorders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110ipjw/new_to_data_modelling_how_to_design_for_preorders/", "subreddit_subscribers": 89337, "created_utc": 1676216815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Maybe it is because english is not my native language but I don't know what number to fill in in their [cost calculator](https://cost.airbyte.com/?_gl=1*yeje9n*_gcl_aw*R0NMLjE2NjI1MDQ3MTguQ2owS0NRanczOXVZQmhDTEFSSXNBRF9Tek1RRlJISDB2eTFKZzlLRldwRDI4OUl0SngtRzF0X3dOc2VKa1I5MThiTmtPT1g1OXl5cWxNVWFBaUFtRUFMd193Y0I.&amp;_ga=2.266664462.1256404185.1665036128-558301217.1646090235&amp;_gac=1.184557403.1662504717.Cj0KCQjw39uYBhCLARIsAD_SzMQFRHH0vy1Jg9KFWpD289ItJx-G1t_wNseJkR918bNkOOX59yyqlMUaAiAmEALw_wcB).\n\nIt says:  'Data to replicate from your database sources'. Does that mean the size of the database? Or the size of the new rows i want to (incrementally) sync each month?", "author_fullname": "t2_6bgrg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about the Airbyte cost calculator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110h36c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676212460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe it is because english is not my native language but I don&amp;#39;t know what number to fill in in their &lt;a href=\"https://cost.airbyte.com/?_gl=1*yeje9n*_gcl_aw*R0NMLjE2NjI1MDQ3MTguQ2owS0NRanczOXVZQmhDTEFSSXNBRF9Tek1RRlJISDB2eTFKZzlLRldwRDI4OUl0SngtRzF0X3dOc2VKa1I5MThiTmtPT1g1OXl5cWxNVWFBaUFtRUFMd193Y0I.&amp;amp;_ga=2.266664462.1256404185.1665036128-558301217.1646090235&amp;amp;_gac=1.184557403.1662504717.Cj0KCQjw39uYBhCLARIsAD_SzMQFRHH0vy1Jg9KFWpD289ItJx-G1t_wNseJkR918bNkOOX59yyqlMUaAiAmEALw_wcB\"&gt;cost calculator&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It says:  &amp;#39;Data to replicate from your database sources&amp;#39;. Does that mean the size of the database? Or the size of the new rows i want to (incrementally) sync each month?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110h36c", "is_robot_indexable": true, "report_reasons": null, "author": "karaqz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110h36c/question_about_the_airbyte_cost_calculator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110h36c/question_about_the_airbyte_cost_calculator/", "subreddit_subscribers": 89337, "created_utc": 1676212460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings everyone.\n\nI work on a company that builds software solutions for governments. At the data sector, we are processing healthcare data for BI and ML applications. \n\nOur current data pipeline looks something like this: Oracle db (data source) -&gt; PostgreSQL db (intermediate db) -&gt; Power BI. This workflow is orchestrated by AirFlow.\n\nThe main issue we are facing is the control of which person can access which database, and the segmentation of said data.\n\nWe would also like to implement a data governance tool. I have been looking into Delta Lake, but it seems this is a tool for data lake house, and not data governance.\n\nI would like advice on which tools should I look into that can fix the issues mentioned. Also, given our current situation, what would be the next step in order to implement a data governance tool?\n\nThanks in advance!!\n\nEdit: forgot to mention, but this tool also needs to be able to work both on premise and in the cloud.", "author_fullname": "t2_1201f0e5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on data governance tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1104d44", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676167484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings everyone.&lt;/p&gt;\n\n&lt;p&gt;I work on a company that builds software solutions for governments. At the data sector, we are processing healthcare data for BI and ML applications. &lt;/p&gt;\n\n&lt;p&gt;Our current data pipeline looks something like this: Oracle db (data source) -&amp;gt; PostgreSQL db (intermediate db) -&amp;gt; Power BI. This workflow is orchestrated by AirFlow.&lt;/p&gt;\n\n&lt;p&gt;The main issue we are facing is the control of which person can access which database, and the segmentation of said data.&lt;/p&gt;\n\n&lt;p&gt;We would also like to implement a data governance tool. I have been looking into Delta Lake, but it seems this is a tool for data lake house, and not data governance.&lt;/p&gt;\n\n&lt;p&gt;I would like advice on which tools should I look into that can fix the issues mentioned. Also, given our current situation, what would be the next step in order to implement a data governance tool?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!!&lt;/p&gt;\n\n&lt;p&gt;Edit: forgot to mention, but this tool also needs to be able to work both on premise and in the cloud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1104d44", "is_robot_indexable": true, "report_reasons": null, "author": "Alvin0p1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1104d44/advice_on_data_governance_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1104d44/advice_on_data_governance_tools/", "subreddit_subscribers": 89337, "created_utc": 1676167484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bsrs5rj9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ER Model Explained \u2014 DBMS Concepts | Coding Chronicles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "name": "t3_10zw7pw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/F9wR7J8Pb20T_iAGhGrFG83z9WRJGd5AjD4iJX8vAw4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676145031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "codingchronicles.adityakarad.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://codingchronicles.adityakarad.com/er-model-explained-dbms-concepts", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?auto=webp&amp;v=enabled&amp;s=9925d24699375e00b236b6a1509c27134fad055d", "width": 1200, "height": 668}, "resolutions": [{"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0b4b6e152e06179dc46ad1eb612d90271cbb13c", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8132656f5a770400eb93b2ef76ae7a4430931b11", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e96a5e3eff5a65fb8ef92922025eb36a1ec6c64f", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0958febe467583276fd4d2699712693fbeff38a5", "width": 640, "height": 356}, {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9afe5f3a9e026078762c5405c9b2f425acfe8fc2", "width": 960, "height": 534}, {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c120cfb3c8f520b27431bf0d46f4d65341439316", "width": 1080, "height": 601}], "variants": {}, "id": "GcVhT5tkWyK3YaxXoPtCN0yMcF-XtPeKefuMWoUnxUI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10zw7pw", "is_robot_indexable": true, "report_reasons": null, "author": "indian_dev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zw7pw/er_model_explained_dbms_concepts_coding_chronicles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://codingchronicles.adityakarad.com/er-model-explained-dbms-concepts", "subreddit_subscribers": 89337, "created_utc": 1676145031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Using the same data and set of transformations and excluding all other factors, which would be cheaper: A transformation in spark or transformation in a datawarehouse?", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transform in spark or in datawarehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110c0u4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676195268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Using the same data and set of transformations and excluding all other factors, which would be cheaper: A transformation in spark or transformation in a datawarehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110c0u4", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110c0u4/transform_in_spark_or_in_datawarehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110c0u4/transform_in_spark_or_in_datawarehouse/", "subreddit_subscribers": 89337, "created_utc": 1676195268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sorry if this is not the place to ask.\n\nLooking to major in DE but I have been seeing lots of posts and videos talking about how data engineering won't be useful or needed in the future,is this true?\n\n\nIn addition how did you know that DE was the thing for you?", "author_fullname": "t2_tzb9l6f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "will data engineering still be needed in 10+ years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zvyec", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.41, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676144353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this is not the place to ask.&lt;/p&gt;\n\n&lt;p&gt;Looking to major in DE but I have been seeing lots of posts and videos talking about how data engineering won&amp;#39;t be useful or needed in the future,is this true?&lt;/p&gt;\n\n&lt;p&gt;In addition how did you know that DE was the thing for you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10zvyec", "is_robot_indexable": true, "report_reasons": null, "author": "khtoto", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zvyec/will_data_engineering_still_be_needed_in_10_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zvyec/will_data_engineering_still_be_needed_in_10_years/", "subreddit_subscribers": 89337, "created_utc": 1676144353.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}