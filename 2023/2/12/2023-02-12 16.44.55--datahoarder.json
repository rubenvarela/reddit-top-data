{"kind": "Listing", "data": {"after": "t3_110bfkk", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It's been 5 years and two houses. It's a lot quieter now.", "author_fullname": "t2_j4kum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Reminder to stop putting off your server maintenance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"b3nm79zedoha1": {"status": "valid", "e": "Image", "m": "image/jpg", "o": [{"y": 3000, "x": 4000, "u": "https://preview.redd.it/b3nm79zedoha1.jpg?width=1080&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=035741f99f95c0dafb69b3182cc5d42ca6d0ff6d"}], "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/b3nm79zedoha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6d445e1cd577bf7d88f0fc351f0da4206826f478"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/b3nm79zedoha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dff8b1c83abe4a41b7f53ed78aa2bf69c0639e16"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/b3nm79zedoha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=415822021251b89ae6887317bd4b7dac152300d4"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/b3nm79zedoha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b71c08a359826822e0de346ad021c5ac3c72469"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/b3nm79zedoha1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f7f7f428ffbba8b13669eeb0a7637d8018a6023"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/b3nm79zedoha1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b10118b11ebc46c681570f09a5b60253594781a2"}], "s": {"y": 3000, "x": 4000, "u": "https://preview.redd.it/b3nm79zedoha1.jpg?width=4000&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e2d81cb4c150ed7ab2a1d9a5f862e04128664347"}, "id": "b3nm79zedoha1"}, "elccyh5fdoha1": {"status": "valid", "e": "Image", "m": "image/jpg", "o": [{"y": 3276, "x": 2232, "u": "https://preview.redd.it/elccyh5fdoha1.jpg?width=1080&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a5490f520c112c0a53400f492565bfcf967c8740"}], "p": [{"y": 158, "x": 108, "u": "https://preview.redd.it/elccyh5fdoha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=273219855cd06918f9d174731680db9e2f3525a8"}, {"y": 317, "x": 216, "u": "https://preview.redd.it/elccyh5fdoha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d3ce9314f970189cb30318967a27e9037a2b268"}, {"y": 469, "x": 320, "u": "https://preview.redd.it/elccyh5fdoha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=138eb2a4b70302a281fef17a9eb510c9a81a10b3"}, {"y": 939, "x": 640, "u": "https://preview.redd.it/elccyh5fdoha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=faadd0b0eba81b65206fb6452247092a3a2f6361"}, {"y": 1409, "x": 960, "u": "https://preview.redd.it/elccyh5fdoha1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=30ba45dba1d7c602d6e6ffaecf8c93e312b0600c"}, {"y": 1585, "x": 1080, "u": "https://preview.redd.it/elccyh5fdoha1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48788f0460e9e427d93479ca62a66983113b13d9"}], "s": {"y": 3276, "x": 2232, "u": "https://preview.redd.it/elccyh5fdoha1.jpg?width=2232&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8bccfb08a337f329153ff0ec87c07a8ea3d6fa33"}, "id": "elccyh5fdoha1"}, "0h7yei2fdoha1": {"status": "valid", "e": "Image", "m": "image/jpg", "o": [{"y": 4000, "x": 3000, "u": "https://preview.redd.it/0h7yei2fdoha1.jpg?width=1080&amp;blur=40&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=28ab1ffa13fc8321d15d0645d8c9b421f3a91180"}], "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/0h7yei2fdoha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e782ef67d95e3d88222bab250904c4d15ad03fb8"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/0h7yei2fdoha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ef10ab34c11ab4921f39cf3690ddfca3033b0ac"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/0h7yei2fdoha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b492e8746edce59ab028939502aed0d29348b196"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/0h7yei2fdoha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=025885418a1a1b793c7bd4878824b2874970782b"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/0h7yei2fdoha1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34d161849d7a6cbb65967df8b3f458ade0b495b6"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/0h7yei2fdoha1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b379f17e4fb95d295dba27152c7900fd7cb7bfa4"}], "s": {"y": 4000, "x": 3000, "u": "https://preview.redd.it/0h7yei2fdoha1.jpg?width=3000&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=85e8824949e1da789a89456b8bd25d6365aba00b"}, "id": "0h7yei2fdoha1"}}, "name": "t3_1105oii", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 998, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "b3nm79zedoha1", "id": 239712967}, {"media_id": "0h7yei2fdoha1", "id": 239712968}, {"media_id": "elccyh5fdoha1", "id": 239712969}]}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 998, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676171667.0, "link_flair_type": "text", "wls": 3, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s been 5 years and two houses. It&amp;#39;s a lot quieter now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1105oii", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "130TB ZFS", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1105oii", "is_robot_indexable": true, "report_reasons": null, "author": "TheAJGman", "discussion_type": null, "num_comments": 73, "send_replies": true, "whitelist_status": "promo_adult_nsfw", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1105oii/reminder_to_stop_putting_off_your_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1105oii", "subreddit_subscribers": 669542, "created_utc": 1676171667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As we saw with Google Books, all it takes is one protracted lawsuit from a publisher to completely shut down book archiving efforts (GB has over 25 million scanned books they can't share now). IA is in the middle of a similar publisher lawsuit, and they've bowed to DMCAs before even if they're completely bogus because they don't want any heat. Is anyone making efforts to reupload their books? There are scripts for ripping IA, so it's just a matter of automating it.", "author_fullname": "t2_rd3dx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone backing up/reploading Archive.org's scanned books to Libgen, etc.?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zss7h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 165, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 165, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676136202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As we saw with Google Books, all it takes is one protracted lawsuit from a publisher to completely shut down book archiving efforts (GB has over 25 million scanned books they can&amp;#39;t share now). IA is in the middle of a similar publisher lawsuit, and they&amp;#39;ve bowed to DMCAs before even if they&amp;#39;re completely bogus because they don&amp;#39;t want any heat. Is anyone making efforts to reupload their books? There are scripts for ripping IA, so it&amp;#39;s just a matter of automating it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10zss7h", "is_robot_indexable": true, "report_reasons": null, "author": "MangaAnon", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10zss7h/is_anyone_backing_upreploading_archiveorgs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10zss7h/is_anyone_backing_upreploading_archiveorgs/", "subreddit_subscribers": 669542, "created_utc": 1676136202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've automated importing my family photos from CDs, but the process doesn't distinguish between thumbnails and full quality, it just copies jpegs. Some CDs have multiple resolutions of the same image.\n\nIs there a windows tool that lets you find photos that are similar, and delete all but the largest?\n\nI've found a whole myriad of tools to find duplicate photos, but they all either delete the latest dated one, or force you to manually choose between photos. I just want to clean up the worst versions of my photos. Any recommendations?\n\n&amp;#x200B;\n\nEDIT:\n\nCzkawka does what I was looking for. I had tried it before, but couldn't find the option before it was pointed out. Press the \"Select\" button after searching for images, it brings up a dropdown menu that has the option I was looking for.", "author_fullname": "t2_k8lxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delete duplicate photos, only highest resolution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zt2vv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Solved", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676193060.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676136969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve automated importing my family photos from CDs, but the process doesn&amp;#39;t distinguish between thumbnails and full quality, it just copies jpegs. Some CDs have multiple resolutions of the same image.&lt;/p&gt;\n\n&lt;p&gt;Is there a windows tool that lets you find photos that are similar, and delete all but the largest?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found a whole myriad of tools to find duplicate photos, but they all either delete the latest dated one, or force you to manually choose between photos. I just want to clean up the worst versions of my photos. Any recommendations?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;Czkawka does what I was looking for. I had tried it before, but couldn&amp;#39;t find the option before it was pointed out. Press the &amp;quot;Select&amp;quot; button after searching for images, it brings up a dropdown menu that has the option I was looking for.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "10zt2vv", "is_robot_indexable": true, "report_reasons": null, "author": "zeldn", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10zt2vv/delete_duplicate_photos_only_highest_resolution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10zt2vv/delete_duplicate_photos_only_highest_resolution/", "subreddit_subscribers": 669542, "created_utc": 1676136969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_3xunvi1q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheapest I can find a new 16tb - 230$ - anyone know of any lower, new only?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_110638u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/76ILkn4h3HNpkgGNBzTc4rgswwgzSqCcK1OTrOXsx0U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676173001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/y5674vnwypha1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/y5674vnwypha1.jpg?auto=webp&amp;v=enabled&amp;s=2e98c8b57bb3dadf2f9714e90d2f017e2716147b", "width": 1170, "height": 2532}, "resolutions": [{"url": "https://preview.redd.it/y5674vnwypha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4a9251eade3fa7df441f2315e43e609f0538adc4", "width": 108, "height": 216}, {"url": "https://preview.redd.it/y5674vnwypha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eaddab5d2c582b2192cceb918a3c145d0f11e522", "width": 216, "height": 432}, {"url": "https://preview.redd.it/y5674vnwypha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2cc3a960b8d9466f6e9d6644c8483b1fec7e1eb8", "width": 320, "height": 640}, {"url": "https://preview.redd.it/y5674vnwypha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c589322b551732fe933588144c2f03fa5961a29", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/y5674vnwypha1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2ad72ff3c68e2d665e44d72f35c83a3fd3dbcd76", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/y5674vnwypha1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5492541d6d16459c864dbe77e9dcb9c3456eb00", "width": 1080, "height": 2160}], "variants": {}, "id": "16rlTX0wDq6q1VUkoH0pY0cj-rXiA11bvhBCFQzCyvs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "110638u", "is_robot_indexable": true, "report_reasons": null, "author": "PythonsByX", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/110638u/cheapest_i_can_find_a_new_16tb_230_anyone_know_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/y5674vnwypha1.jpg", "subreddit_subscribers": 669542, "created_utc": 1676173001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Specifically, I want to remove dots from all folder names (not necessarily files in folders, but that\u2019d be a plus) within a larger folder\n\nHaving to rename files to fit in with the majority individually is tiring \n\nAny program that can help me do this efficiently?\n\nEdit: To specify, I\u2019m using Windows 10", "author_fullname": "t2_8rjozvgt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to mass rename files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1103kj2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676165694.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676165067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Specifically, I want to remove dots from all folder names (not necessarily files in folders, but that\u2019d be a plus) within a larger folder&lt;/p&gt;\n\n&lt;p&gt;Having to rename files to fit in with the majority individually is tiring &lt;/p&gt;\n\n&lt;p&gt;Any program that can help me do this efficiently?&lt;/p&gt;\n\n&lt;p&gt;Edit: To specify, I\u2019m using Windows 10&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "44TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1103kj2", "is_robot_indexable": true, "report_reasons": null, "author": "IsMathScience_", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1103kj2/looking_to_mass_rename_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1103kj2/looking_to_mass_rename_files/", "subreddit_subscribers": 669542, "created_utc": 1676165067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey !\n\nFor a little while, I've been capturing live shows (Phish shows to be precise) to keep/hoard them after the streaming link is disabled. Here is the method I use and the problems I have with it.\n\nI use OBS to capture, I've had many time a problem of the software being unable to stop recording, typically when the video is more than 1h30 long. I've searched the internet and tried many things to no end so I capture in 2 or 3 parts and stitch them in Premiere, which is a bit annoying but not my top priority problem.\n\nFor now I record in mp4, CBR 3500kbps 1920\\*1080 on high quality settings.\n\nThere are times where I captured in .mkv because it made OBS less upset but then I have to convert the files because Premiere won't take this format, here I use Handbrake. I have no clear method on this I just try to convert in a better bitrate than the source to avoid maximum losses in this second encoding but if you have optimal settings I'd gladly take the advice.\n\nMy biggest problem is with the final encoding once I've stitched my clips. I 'm really unsatisfied with the quality/size ratio. I generally export in H264, VBR 2 pass around 4000kbps and it looks something like this : [https://imgur.com/a/qZM7nwG](https://imgur.com/a/qZM7nwG)\n\nOn some shots it looks decent enough for me but in this low light situations (or for example on the shots with confettis) it's really bad.\n\nHere are screenshots for the same show they uploaded to Youtube (they upload in 4kHDR but i put the settings on 1080p) it looks better to me. [https://imgur.com/a/bxATdz9](https://imgur.com/a/bxATdz9)\n\nThis particular video is 4h long and 6.82GB\n\nI have an archival release that I downloaded from them, and even if it's tape from the 90's so it's not the same thing, it's 4h42min, and 5.30GB with around 2600kbps and it looks better done to me. [https://imgur.com/a/vBrpOAz](https://imgur.com/a/vBrpOAz)\n\nI've also seen movies I (legally of course officer \ud83d\udc6e) downloaded thath were BRrip, some in 4k that looked fabulous for a file size under or just above 1GB. \n\nI've tried H265 and got some marginal improvement on file size, but not really on quality and the format is a bit less compatible with everything than H264 so I don't see it as really worth.\n\nI'm looking for a better method to shrink file size if possible but mostly to improve video quality and minimize compression artefacts, as long as the file is not like twice the size.\n\nAny advice is welcome (I'm ready to change everything, but stay on a free method or something affordable) and thank you very much for your time !", "author_fullname": "t2_tnwcl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a good capture/encoding method for concerts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zt2l7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676136947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey !&lt;/p&gt;\n\n&lt;p&gt;For a little while, I&amp;#39;ve been capturing live shows (Phish shows to be precise) to keep/hoard them after the streaming link is disabled. Here is the method I use and the problems I have with it.&lt;/p&gt;\n\n&lt;p&gt;I use OBS to capture, I&amp;#39;ve had many time a problem of the software being unable to stop recording, typically when the video is more than 1h30 long. I&amp;#39;ve searched the internet and tried many things to no end so I capture in 2 or 3 parts and stitch them in Premiere, which is a bit annoying but not my top priority problem.&lt;/p&gt;\n\n&lt;p&gt;For now I record in mp4, CBR 3500kbps 1920*1080 on high quality settings.&lt;/p&gt;\n\n&lt;p&gt;There are times where I captured in .mkv because it made OBS less upset but then I have to convert the files because Premiere won&amp;#39;t take this format, here I use Handbrake. I have no clear method on this I just try to convert in a better bitrate than the source to avoid maximum losses in this second encoding but if you have optimal settings I&amp;#39;d gladly take the advice.&lt;/p&gt;\n\n&lt;p&gt;My biggest problem is with the final encoding once I&amp;#39;ve stitched my clips. I &amp;#39;m really unsatisfied with the quality/size ratio. I generally export in H264, VBR 2 pass around 4000kbps and it looks something like this : &lt;a href=\"https://imgur.com/a/qZM7nwG\"&gt;https://imgur.com/a/qZM7nwG&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;On some shots it looks decent enough for me but in this low light situations (or for example on the shots with confettis) it&amp;#39;s really bad.&lt;/p&gt;\n\n&lt;p&gt;Here are screenshots for the same show they uploaded to Youtube (they upload in 4kHDR but i put the settings on 1080p) it looks better to me. &lt;a href=\"https://imgur.com/a/bxATdz9\"&gt;https://imgur.com/a/bxATdz9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This particular video is 4h long and 6.82GB&lt;/p&gt;\n\n&lt;p&gt;I have an archival release that I downloaded from them, and even if it&amp;#39;s tape from the 90&amp;#39;s so it&amp;#39;s not the same thing, it&amp;#39;s 4h42min, and 5.30GB with around 2600kbps and it looks better done to me. &lt;a href=\"https://imgur.com/a/vBrpOAz\"&gt;https://imgur.com/a/vBrpOAz&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also seen movies I (legally of course officer \ud83d\udc6e) downloaded thath were BRrip, some in 4k that looked fabulous for a file size under or just above 1GB. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried H265 and got some marginal improvement on file size, but not really on quality and the format is a bit less compatible with everything than H264 so I don&amp;#39;t see it as really worth.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a better method to shrink file size if possible but mostly to improve video quality and minimize compression artefacts, as long as the file is not like twice the size.&lt;/p&gt;\n\n&lt;p&gt;Any advice is welcome (I&amp;#39;m ready to change everything, but stay on a free method or something affordable) and thank you very much for your time !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bZrrVtZJGIGCQPb6TVYZfBGqT-y16wafy_GgYs2j1Lg.jpg?auto=webp&amp;v=enabled&amp;s=2b960717bca180d0d41de8ba238a356624323bb5", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/bZrrVtZJGIGCQPb6TVYZfBGqT-y16wafy_GgYs2j1Lg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ece1c28a3e044e052abb37347375b1bbeacc6626", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/bZrrVtZJGIGCQPb6TVYZfBGqT-y16wafy_GgYs2j1Lg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=023b729e11b3a3aa706202bea512ce9e7f7f707d", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/bZrrVtZJGIGCQPb6TVYZfBGqT-y16wafy_GgYs2j1Lg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61252b3c272ea74f6f24b770f9d7c433ff8ac746", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/bZrrVtZJGIGCQPb6TVYZfBGqT-y16wafy_GgYs2j1Lg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b0642c213bd41e493c3eaeb3e73a0ed0303d85f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/bZrrVtZJGIGCQPb6TVYZfBGqT-y16wafy_GgYs2j1Lg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d9d445e331fc94b7239623e6b8f95b2d1976fb6", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/bZrrVtZJGIGCQPb6TVYZfBGqT-y16wafy_GgYs2j1Lg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d30692856f2d3dd0fa5d735977267c00f6bbaf5", "width": 1080, "height": 607}], "variants": {}, "id": "KxRzu7N-5o-sh22iK9NVsQAJFpEOmBIeL87vcA7sTmY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10zt2l7", "is_robot_indexable": true, "report_reasons": null, "author": "Trve_Kawaii", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10zt2l7/looking_for_a_good_captureencoding_method_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10zt2l7/looking_for_a_good_captureencoding_method_for/", "subreddit_subscribers": 669542, "created_utc": 1676136947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can anybody please identify this port ?", "author_fullname": "t2_d5yz6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Identify these ports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tqloi3dwymha1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 144, "x": 108, "u": "https://preview.redd.it/tqloi3dwymha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=caef221ef8c0da9939757713775a3c2311743bc2"}, {"y": 288, "x": 216, "u": "https://preview.redd.it/tqloi3dwymha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8448bc2e5f131a1360879f83dc7ce1c1ceb1c5f"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/tqloi3dwymha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d6510b90fa241b1d32c22fad28a907a6d078db80"}, {"y": 853, "x": 640, "u": "https://preview.redd.it/tqloi3dwymha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70c40c13290ec26a63f277d2e8a8c9c02c84d148"}, {"y": 1280, "x": 960, "u": "https://preview.redd.it/tqloi3dwymha1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bc5a84d4743ed523d5d564741e1339134bcad3c3"}, {"y": 1440, "x": 1080, "u": "https://preview.redd.it/tqloi3dwymha1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd821fa0983676f30cd259c1760948181d3f3a39"}], "s": {"y": 4032, "x": 3024, "u": "https://preview.redd.it/tqloi3dwymha1.jpg?width=3024&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=83e08dfa861e2a49ffbfb072373522dac00eba36"}, "id": "tqloi3dwymha1"}, "9qerk2dwymha1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 143, "x": 108, "u": "https://preview.redd.it/9qerk2dwymha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de7b24502748e761de8938d46c5f4e49a9a39115"}, {"y": 287, "x": 216, "u": "https://preview.redd.it/9qerk2dwymha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bfbc39ccd62413c907966566621bad003fbe18ae"}, {"y": 426, "x": 320, "u": "https://preview.redd.it/9qerk2dwymha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=888eef9204eca44873465fe60280dd6523309b8c"}, {"y": 852, "x": 640, "u": "https://preview.redd.it/9qerk2dwymha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e483f7d9af1bd392d66c4bdf79ab04139c7caaf6"}, {"y": 1279, "x": 960, "u": "https://preview.redd.it/9qerk2dwymha1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2654185a80b41d2f104338375f987cd292769e61"}, {"y": 1439, "x": 1080, "u": "https://preview.redd.it/9qerk2dwymha1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46e32511e9d2fa1cc17e852312a949fd75b04020"}], "s": {"y": 2180, "x": 1636, "u": "https://preview.redd.it/9qerk2dwymha1.jpg?width=1636&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=f23b4123e0f5370f645a1145a9f2abb716c42bef"}, "id": "9qerk2dwymha1"}}, "name": "t3_10zzvrr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.52, "author_flair_background_color": null, "ups": 1, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "tqloi3dwymha1", "id": 239635569}, {"media_id": "9qerk2dwymha1", "id": 239635570}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fwBOJSJ_qcKW6l1PY6a-1nPjdN_JuB6KJPGoo4oJ7dE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676154677.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anybody please identify this port ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/10zzvrr", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10zzvrr", "is_robot_indexable": true, "report_reasons": null, "author": "vipermo", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10zzvrr/identify_these_ports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/10zzvrr", "subreddit_subscribers": 669542, "created_utc": 1676154677.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A friend gifted me a 5.25 drive recently, and I'm setting up a little data archival setup using a Greaseweazle that will include it.  Given that I won't be using it inside a computer, does anyone know of a good option for keeping the 5.25 drive dust free and protected?  In a perfect world it would be a plastic enclosure that uses the mounting holes with a removable end to expose the data/power connections at the back, but I'm not going to be that picky.", "author_fullname": "t2_n98iv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shell/Enclosure/Case for 5.25 Floppy Drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ztdss", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676137764.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A friend gifted me a 5.25 drive recently, and I&amp;#39;m setting up a little data archival setup using a Greaseweazle that will include it.  Given that I won&amp;#39;t be using it inside a computer, does anyone know of a good option for keeping the 5.25 drive dust free and protected?  In a perfect world it would be a plastic enclosure that uses the mounting holes with a removable end to expose the data/power connections at the back, but I&amp;#39;m not going to be that picky.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10ztdss", "is_robot_indexable": true, "report_reasons": null, "author": "majestic_ubertrout", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10ztdss/shellenclosurecase_for_525_floppy_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10ztdss/shellenclosurecase_for_525_floppy_drive/", "subreddit_subscribers": 669542, "created_utc": 1676137764.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup And Migration Plans", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_110ix4p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_99kth8pk", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "homelab", "selftext": "Hello! I'm mostly a lurker here, but I really appreciate all the information shared and supportive community here! I work in Cyber Security, and I use my lab for testing and proof of concept work, as well as toying around with different tech. I'm hoping I can ask for some advice:\n\nI have a Proxmox server and a TrueNAS server currently, and I'm building a third server for backup of both of these - or ideally to replace them - but I'm not sure how to set this up.\n\n&amp;#x200B;\n\nBackground:\n\nHere is what I have currently:\n\n1. **Proxmox Server (HP Proliant dl380p G8)** \\- 2x Xeon 2620 (24 total threads), 96GB DDR3 ECC, 2.6TB in RAID5 (Hardware), 800GB SAS SSD, 4x 1Gbps NIC\n2. **Primary TrueNAS Server** **(Baremetal)**\\- Core i5 8400 (6 threads), 32GB DDR4, 1x 1TB boot SATA SSD, 1x 32GB Optane NVMe cache drive, 4x 8TB SATA HDD in RAID Z2, 10Gbps NIC\n3. **New Server (Still collecting parts)** \\- Xeon 2660 V4 (28 threads), 64GB DDR4 ECC (with space for 64GB more), 6x 8tb SATA HDD (Used, will be tested), 2x 512GB NVMe SSD for boot (RAID Z1), eventually a 10Gbps NIC, Old Radeon GPU\n\nMy first plan was to just put TrueNAS on the new machine and back both of the other servers up to the new one, but the specs are overkill for that, and I'd like to eliminate the Proliant.\n\nAnother thought I had is to migrate my Proxmox to the new server to run VMs, and act as a back up for my Primary NAS, with the VMs here backed up to the Primary NAS, but I'm worried about the used drives, even if they pass my testing. This would eliminate the Proliant.\n\nMy current plan is to purchase two more new 8TB drives to add to my existing 4x ZFS pool on the primary NAS, and move those into the New Server - then I'd put Proxmox on it and virtualize my Primary NAS, moving the used drives to the i5 machine to backup Proxmox and the primary NAS, again eliminating the Proliant.\n\nThis would result in two machines:\n\n1. **New Proxmox server** hosting my VMs and a virtual TrueNAS instance with 6 new drives\n2. **Old i5 machine** running TrueNAS (or PBS) with the 6 used drives\n\nI'm not sure how I can make that work though, or if messing with my Primary NAS is even a good idea. I've also been warned against virtualizing TrueNAS previously, but I see many people do it and it makes sense. The Proliant doesn't fit into my little rack and it's fairly power hungry, so I'd like to take it out of the picture if possible - it was bought for $150 when I got started with homelabbing, and it has been fantastic, but being restricted to 2.5\" drives has been more limiting than I'd realized. I may relegate it to a test machine that I spin up when needed.\n\nWhat I'm thinking of doing is setting those additional 2 8TB drives as a RAID Z1 pool alongside the Primary NAS pool on the new machine, and that would host all of my Proxmox data, then setting the Primary NAS pool to a TrueNAS VM. Then I would set up the i5 with the 6 used 8TB drives in RAID Z3 and run backups to it. The vast majority of my data could acceptably be lost, but it would take weeks to rebuild it if that happened, so I'd rather avoid it.\n\n&amp;#x200B;\n\n**My questions are:**\n\nIs this the best way to do it? How would you do something like this?\n\nWould it make more sense to migrate my current pool to the used disks, then create a new Z3 pool with the 6 new disks and migrate again?\n\nAm I too worried about the used drives? I'm going to evaluate them with Hard Drive Sentinel.\n\nThe new Proxmox instance will be on ZFS since I won't be using hardware RAID (yay), so I was just planning to do replication for the backup, would that comfortably cover the virtual TrueNAS, or should I do that separately?\n\n&amp;#x200B;\n\ntldr: I'm building a new server and want to move a Proxmox instance and a TrueNAS instance into the same box - how?\n\n&amp;#x200B;\n\nThank you in advance for any input!", "author_fullname": "t2_99kth8pk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup And Migration Plans", "link_flair_richtext": [], "subreddit_name_prefixed": "r/homelab", "hidden": false, "pwls": 6, "link_flair_css_class": "help", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10y24cg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675967387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.homelab", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I&amp;#39;m mostly a lurker here, but I really appreciate all the information shared and supportive community here! I work in Cyber Security, and I use my lab for testing and proof of concept work, as well as toying around with different tech. I&amp;#39;m hoping I can ask for some advice:&lt;/p&gt;\n\n&lt;p&gt;I have a Proxmox server and a TrueNAS server currently, and I&amp;#39;m building a third server for backup of both of these - or ideally to replace them - but I&amp;#39;m not sure how to set this up.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Background:&lt;/p&gt;\n\n&lt;p&gt;Here is what I have currently:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Proxmox Server (HP Proliant dl380p G8)&lt;/strong&gt; - 2x Xeon 2620 (24 total threads), 96GB DDR3 ECC, 2.6TB in RAID5 (Hardware), 800GB SAS SSD, 4x 1Gbps NIC&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Primary TrueNAS Server&lt;/strong&gt; &lt;strong&gt;(Baremetal)&lt;/strong&gt;- Core i5 8400 (6 threads), 32GB DDR4, 1x 1TB boot SATA SSD, 1x 32GB Optane NVMe cache drive, 4x 8TB SATA HDD in RAID Z2, 10Gbps NIC&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;New Server (Still collecting parts)&lt;/strong&gt; - Xeon 2660 V4 (28 threads), 64GB DDR4 ECC (with space for 64GB more), 6x 8tb SATA HDD (Used, will be tested), 2x 512GB NVMe SSD for boot (RAID Z1), eventually a 10Gbps NIC, Old Radeon GPU&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;My first plan was to just put TrueNAS on the new machine and back both of the other servers up to the new one, but the specs are overkill for that, and I&amp;#39;d like to eliminate the Proliant.&lt;/p&gt;\n\n&lt;p&gt;Another thought I had is to migrate my Proxmox to the new server to run VMs, and act as a back up for my Primary NAS, with the VMs here backed up to the Primary NAS, but I&amp;#39;m worried about the used drives, even if they pass my testing. This would eliminate the Proliant.&lt;/p&gt;\n\n&lt;p&gt;My current plan is to purchase two more new 8TB drives to add to my existing 4x ZFS pool on the primary NAS, and move those into the New Server - then I&amp;#39;d put Proxmox on it and virtualize my Primary NAS, moving the used drives to the i5 machine to backup Proxmox and the primary NAS, again eliminating the Proliant.&lt;/p&gt;\n\n&lt;p&gt;This would result in two machines:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;New Proxmox server&lt;/strong&gt; hosting my VMs and a virtual TrueNAS instance with 6 new drives&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Old i5 machine&lt;/strong&gt; running TrueNAS (or PBS) with the 6 used drives&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m not sure how I can make that work though, or if messing with my Primary NAS is even a good idea. I&amp;#39;ve also been warned against virtualizing TrueNAS previously, but I see many people do it and it makes sense. The Proliant doesn&amp;#39;t fit into my little rack and it&amp;#39;s fairly power hungry, so I&amp;#39;d like to take it out of the picture if possible - it was bought for $150 when I got started with homelabbing, and it has been fantastic, but being restricted to 2.5&amp;quot; drives has been more limiting than I&amp;#39;d realized. I may relegate it to a test machine that I spin up when needed.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m thinking of doing is setting those additional 2 8TB drives as a RAID Z1 pool alongside the Primary NAS pool on the new machine, and that would host all of my Proxmox data, then setting the Primary NAS pool to a TrueNAS VM. Then I would set up the i5 with the 6 used 8TB drives in RAID Z3 and run backups to it. The vast majority of my data could acceptably be lost, but it would take weeks to rebuild it if that happened, so I&amp;#39;d rather avoid it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My questions are:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Is this the best way to do it? How would you do something like this?&lt;/p&gt;\n\n&lt;p&gt;Would it make more sense to migrate my current pool to the used disks, then create a new Z3 pool with the 6 new disks and migrate again?&lt;/p&gt;\n\n&lt;p&gt;Am I too worried about the used drives? I&amp;#39;m going to evaluate them with Hard Drive Sentinel.&lt;/p&gt;\n\n&lt;p&gt;The new Proxmox instance will be on ZFS since I won&amp;#39;t be using hardware RAID (yay), so I was just planning to do replication for the backup, would that comfortably cover the virtual TrueNAS, or should I do that separately?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;tldr: I&amp;#39;m building a new server and want to move a Proxmox instance and a TrueNAS instance into the same box - how?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "664a26e4-322a-11e6-80ae-0e0378709321", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2ubz7", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff6347", "id": "10y24cg", "is_robot_indexable": true, "report_reasons": null, "author": "Akura_Awesome", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/homelab/comments/10y24cg/backup_and_migration_plans/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/homelab/comments/10y24cg/backup_and_migration_plans/", "subreddit_subscribers": 551350, "created_utc": 1675967387.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1676217376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.homelab", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/homelab/comments/10y24cg/backup_and_migration_plans/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "110ix4p", "is_robot_indexable": true, "report_reasons": null, "author": "Akura_Awesome", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_10y24cg", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/110ix4p/backup_and_migration_plans/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/homelab/comments/10y24cg/backup_and_migration_plans/", "subreddit_subscribers": 669542, "created_utc": 1676217376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I read about 3-2-1 rule and other posts and wanted to start backing up my family files/photos/videos. This would be on top of each family member's personal google drives and laptops. I would appreciate some advice on whether this is an okay approach.\n\n- Dedicated internal HDD on my desktop for my family to drop files into regularly.\n- USB external hard drive to copy over the HDD (keep it disconnected; backup every couple of months).\n- Backblaze personal once I get \"enough\" photos (currently all files fit in my Google drive, but it won't soon)\n\nShould I add a second HDD on my desktop for redundancy? Would a dedicated NAS be an overkill for couple terabytes of files?", "author_fullname": "t2_6m5kup0n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup approach for family photos/files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110gne8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676211226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read about 3-2-1 rule and other posts and wanted to start backing up my family files/photos/videos. This would be on top of each family member&amp;#39;s personal google drives and laptops. I would appreciate some advice on whether this is an okay approach.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Dedicated internal HDD on my desktop for my family to drop files into regularly.&lt;/li&gt;\n&lt;li&gt;USB external hard drive to copy over the HDD (keep it disconnected; backup every couple of months).&lt;/li&gt;\n&lt;li&gt;Backblaze personal once I get &amp;quot;enough&amp;quot; photos (currently all files fit in my Google drive, but it won&amp;#39;t soon)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Should I add a second HDD on my desktop for redundancy? Would a dedicated NAS be an overkill for couple terabytes of files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "110gne8", "is_robot_indexable": true, "report_reasons": null, "author": "Remarkable_Skin_159", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/110gne8/backup_approach_for_family_photosfiles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/110gne8/backup_approach_for_family_photosfiles/", "subreddit_subscribers": 669542, "created_utc": 1676211226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently have four external hard drives set up in a JBOD array, which I use for my Plex server. I\u2019d like to move them to [something like this](https://www.amazon.com/Syba-Swappable-Drive-External-Enclosure/dp/B07MD2LNYX/ref=sr_1_3?keywords=jbod%2Benclosure&amp;qid=1674884128&amp;sr=8-3&amp;ufe=app_do%3Aamzn1.fos.f5122f16-c3e8-4386-bf32-63e904010ad0&amp;th=1) to save space and to take up fewer outlets. I\u2019m sorry if this is a stupid question, but if I move the drives to this enclosure, will my Mac continue to see them as part of the array?", "author_fullname": "t2_p5abb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shucking external drives to move them to a multiple bay enclosure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110g2pf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676209548.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have four external hard drives set up in a JBOD array, which I use for my Plex server. I\u2019d like to move them to &lt;a href=\"https://www.amazon.com/Syba-Swappable-Drive-External-Enclosure/dp/B07MD2LNYX/ref=sr_1_3?keywords=jbod%2Benclosure&amp;amp;qid=1674884128&amp;amp;sr=8-3&amp;amp;ufe=app_do%3Aamzn1.fos.f5122f16-c3e8-4386-bf32-63e904010ad0&amp;amp;th=1\"&gt;something like this&lt;/a&gt; to save space and to take up fewer outlets. I\u2019m sorry if this is a stupid question, but if I move the drives to this enclosure, will my Mac continue to see them as part of the array?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "110g2pf", "is_robot_indexable": true, "report_reasons": null, "author": "sleepyarmistice", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/110g2pf/shucking_external_drives_to_move_them_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/110g2pf/shucking_external_drives_to_move_them_to_a/", "subreddit_subscribers": 669542, "created_utc": 1676209548.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I found a website where I want to archive it's contents, but the problem is it's not a hosting website it's a linking website. \n\nI used wget ^((wget -m -E -k -K -p https://dl.example.com/ -P \\~/webrips)) to get the entire website, before realizing that it only grabbed content from the dl.example.com site, when what I really wanted was the content that was behind the links stored on the site.\n\nAll links on the main directory site are DDL, the links with the content I want are from oracle's CDN.\n\nAny help would be appreciated, I've been doing some searching and nothing seems to work. \n\n(so far) I've tried:\n\n\\-jdownloader\n\n\\-wget\n\n\\-Idm\n\n\\-Script one download (terminal)", "author_fullname": "t2_cbhs4xvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download all the files from a webpage that hosts direct download links from other websites?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110an92", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676189719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found a website where I want to archive it&amp;#39;s contents, but the problem is it&amp;#39;s not a hosting website it&amp;#39;s a linking website. &lt;/p&gt;\n\n&lt;p&gt;I used wget &lt;sup&gt;(wget -m -E -k -K -p &lt;a href=\"https://dl.example.com/\"&gt;https://dl.example.com/&lt;/a&gt; -P \\&lt;/sup&gt;/webrips)) to get the entire website, before realizing that it only grabbed content from the dl.example.com site, when what I really wanted was the content that was behind the links stored on the site.&lt;/p&gt;\n\n&lt;p&gt;All links on the main directory site are DDL, the links with the content I want are from oracle&amp;#39;s CDN.&lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated, I&amp;#39;ve been doing some searching and nothing seems to work. &lt;/p&gt;\n\n&lt;p&gt;(so far) I&amp;#39;ve tried:&lt;/p&gt;\n\n&lt;p&gt;-jdownloader&lt;/p&gt;\n\n&lt;p&gt;-wget&lt;/p&gt;\n\n&lt;p&gt;-Idm&lt;/p&gt;\n\n&lt;p&gt;-Script one download (terminal)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "RIP enterprisegoogledriveunlimited", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "110an92", "is_robot_indexable": true, "report_reasons": null, "author": "GoryRamsy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/110an92/how_to_download_all_the_files_from_a_webpage_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/110an92/how_to_download_all_the_files_from_a_webpage_that/", "subreddit_subscribers": 669542, "created_utc": 1676189719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Slowly piecing together a server, &amp; am looking to buy \\~3x bay cages (5 HDDs per 3 5.25\" bays). I have had a couple in the past that did not play nice with LSI / ZFS (can't quite remember which of the two was the culprit).  \n\n\nI'm sure someone here is running 5-in-3's with a LSI HBA &amp; ZFS; any recommendations?", "author_fullname": "t2_as0s5xdl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommend me 5-in-3 bay that plays nice with LSI + ZFS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1108av4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676180681.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Slowly piecing together a server, &amp;amp; am looking to buy ~3x bay cages (5 HDDs per 3 5.25&amp;quot; bays). I have had a couple in the past that did not play nice with LSI / ZFS (can&amp;#39;t quite remember which of the two was the culprit).  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure someone here is running 5-in-3&amp;#39;s with a LSI HBA &amp;amp; ZFS; any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "0.145PB, ZFS", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1108av4", "is_robot_indexable": true, "report_reasons": null, "author": "kaheksajalg7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1108av4/recommend_me_5in3_bay_that_plays_nice_with_lsi_zfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1108av4/recommend_me_5in3_bay_that_plays_nice_with_lsi_zfs/", "subreddit_subscribers": 669542, "created_utc": 1676180681.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there! My local city/municipality has created [this awesome portal](https://arch.tnrl.ca/)  (https://arch.tnrl.ca/) of newspapers around my city from the past 100+ years! It's pretty awesome! However I don't love their search feature, and I also would love to archive it all for myself in case, for whatever reason, the site goes away. Any help or tips would be greatly appreciated! Persevere and preserve on (cheesy, I know)!", "author_fullname": "t2_fw1g6oob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would I go about archiving this newspaper archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1101f41", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676158914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there! My local city/municipality has created &lt;a href=\"https://arch.tnrl.ca/\"&gt;this awesome portal&lt;/a&gt;  (&lt;a href=\"https://arch.tnrl.ca/\"&gt;https://arch.tnrl.ca/&lt;/a&gt;) of newspapers around my city from the past 100+ years! It&amp;#39;s pretty awesome! However I don&amp;#39;t love their search feature, and I also would love to archive it all for myself in case, for whatever reason, the site goes away. Any help or tips would be greatly appreciated! Persevere and preserve on (cheesy, I know)!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1101f41", "is_robot_indexable": true, "report_reasons": null, "author": "Dwayne30RockJohnson", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1101f41/how_would_i_go_about_archiving_this_newspaper/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1101f41/how_would_i_go_about_archiving_this_newspaper/", "subreddit_subscribers": 669542, "created_utc": 1676158914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi\n\nNot sure if this the correct subreddit to ask this question, but here it goes.\n\nIs there a doable way to download multiple files from a website that has downloadable links in subpages like this one [https://www.creativefabrica.com/freebies/page/2/?orderby=popularity](https://www.creativefabrica.com/freebies/page/2/?orderby=popularity) or pages that has the link in the same page like this one [https://www.fontspace.com/commercial-fonts](https://www.fontspace.com/commercial-fonts)\n\nSo nothing illegal, just would help a lot to have the option to download all the files from the same page instead of clicking every subpage individually or every save as. Tried some of the google addons, but they seem to only download the page with the link and save it as .download or then the png/jpg from the site.", "author_fullname": "t2_130voj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download multiple files from webpage/website", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zyo62", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676151495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;Not sure if this the correct subreddit to ask this question, but here it goes.&lt;/p&gt;\n\n&lt;p&gt;Is there a doable way to download multiple files from a website that has downloadable links in subpages like this one &lt;a href=\"https://www.creativefabrica.com/freebies/page/2/?orderby=popularity\"&gt;https://www.creativefabrica.com/freebies/page/2/?orderby=popularity&lt;/a&gt; or pages that has the link in the same page like this one &lt;a href=\"https://www.fontspace.com/commercial-fonts\"&gt;https://www.fontspace.com/commercial-fonts&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So nothing illegal, just would help a lot to have the option to download all the files from the same page instead of clicking every subpage individually or every save as. Tried some of the google addons, but they seem to only download the page with the link and save it as .download or then the png/jpg from the site.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KfnazUSf0QXKx_MQpFST5l0pzEfDXj-lpw94VnmOIng.jpg?auto=webp&amp;v=enabled&amp;s=9a080eb956daf7d8db24607813044333cb3f35de", "width": 1920, "height": 760}, "resolutions": [{"url": "https://external-preview.redd.it/KfnazUSf0QXKx_MQpFST5l0pzEfDXj-lpw94VnmOIng.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=526f333f3bfab994104013af0e9d7d62638c2c9a", "width": 108, "height": 42}, {"url": "https://external-preview.redd.it/KfnazUSf0QXKx_MQpFST5l0pzEfDXj-lpw94VnmOIng.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e242bba4b370267b767d1d35dffe854e6571c60e", "width": 216, "height": 85}, {"url": "https://external-preview.redd.it/KfnazUSf0QXKx_MQpFST5l0pzEfDXj-lpw94VnmOIng.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e9e8c227fc1699e7647dcf31d4ddcfcab0004e6", "width": 320, "height": 126}, {"url": "https://external-preview.redd.it/KfnazUSf0QXKx_MQpFST5l0pzEfDXj-lpw94VnmOIng.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=121eee86d77c8fcd2bd0932dfd3fa64be2b46f23", "width": 640, "height": 253}, {"url": "https://external-preview.redd.it/KfnazUSf0QXKx_MQpFST5l0pzEfDXj-lpw94VnmOIng.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73e9bdb39db415acd2cc672eebf6e5f8a7948fe7", "width": 960, "height": 380}, {"url": "https://external-preview.redd.it/KfnazUSf0QXKx_MQpFST5l0pzEfDXj-lpw94VnmOIng.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=52edd1d9238a70a79c46495776680decd4820e2a", "width": 1080, "height": 427}], "variants": {}, "id": "bOtgyGUG1osmRWTL9NoBpDnGLRIx6lZ8QuIKQ6SZMEk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10zyo62", "is_robot_indexable": true, "report_reasons": null, "author": "B3ttor", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10zyo62/download_multiple_files_from_webpagewebsite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10zyo62/download_multiple_files_from_webpagewebsite/", "subreddit_subscribers": 669542, "created_utc": 1676151495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am on a windows device with several external HDDs set up. I recently added a new 18 Tb drive to my last available port, and it looks like something is either wrong with the port or it's an older generation because my disk read/write is maxing out at around 40Mbps. I've tested the drive on another port and got regular speeds for these drives.\n\nI need to expand my storage space, but with quite a few family members and friends using my plex server, I don't love the idea of a drive that can't read more than 40 Mbps.\n\nI am considering a powered USB hub connected to one of my faster ports, but I wanted to ask around before going that route. Is there any concern with doing this? How does this impact the available data through that port? Is each drive essentially allotted 50% of the available speed, or is it all just added up and bottlenecked by the original port's speeds? Thanks.", "author_fullname": "t2_9h44z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any concerns with a powered USB Hub?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zw87f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676145067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am on a windows device with several external HDDs set up. I recently added a new 18 Tb drive to my last available port, and it looks like something is either wrong with the port or it&amp;#39;s an older generation because my disk read/write is maxing out at around 40Mbps. I&amp;#39;ve tested the drive on another port and got regular speeds for these drives.&lt;/p&gt;\n\n&lt;p&gt;I need to expand my storage space, but with quite a few family members and friends using my plex server, I don&amp;#39;t love the idea of a drive that can&amp;#39;t read more than 40 Mbps.&lt;/p&gt;\n\n&lt;p&gt;I am considering a powered USB hub connected to one of my faster ports, but I wanted to ask around before going that route. Is there any concern with doing this? How does this impact the available data through that port? Is each drive essentially allotted 50% of the available speed, or is it all just added up and bottlenecked by the original port&amp;#39;s speeds? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10zw87f", "is_robot_indexable": true, "report_reasons": null, "author": "jayhawk618", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10zw87f/any_concerns_with_a_powered_usb_hub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10zw87f/any_concerns_with_a_powered_usb_hub/", "subreddit_subscribers": 669542, "created_utc": 1676145067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This question may belong elsewhere but i figure someone here knows or uses something similar to what i'm looking for. I want to install this software on an always on machine, preferably via docker, where i can drop a URL in a GUI and it will save that page and the pages of all the links inside it. Bonus points if it can check for changes every so often and grab an updated version to a new location is things are different.", "author_fullname": "t2_ltbzxq19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docker option for something like httrack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zsjot", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676135580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This question may belong elsewhere but i figure someone here knows or uses something similar to what i&amp;#39;m looking for. I want to install this software on an always on machine, preferably via docker, where i can drop a URL in a GUI and it will save that page and the pages of all the links inside it. Bonus points if it can check for changes every so often and grab an updated version to a new location is things are different.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10zsjot", "is_robot_indexable": true, "report_reasons": null, "author": "29Top", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10zsjot/docker_option_for_something_like_httrack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10zsjot/docker_option_for_something_like_httrack/", "subreddit_subscribers": 669542, "created_utc": 1676135580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have noticed the following events with my naked eyes:\n\n\\-when I expel an external hard drive on windows, the OS also tells the internal HDD disk motor to stop spinning (the hard drive also emits a blinking light signal on certain models).\n\n\\-when I expel an external hard drive on GhostBSD, the filesystem is expelled but the internal HDD disk motor still keeps running until I remove the USB cord attached to the USB port.\n\nWhy is that? Should I be concerned about it? \n\n\\-------\n\nIf I ain't not happy about the way FUSE works then Is it possible to replace the stock software interface for running and editing filesystems in userspace with something else? Which other alternatives are available to use so that I can test 'em on my desktop installation to see how well they perform?\n\nWhat are the terminal commands I need to add or replace these sort of programs?", "author_fullname": "t2_68cjgmwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "noob question about FUSE and how it works on GhostBSD as compared to the software interface used in windows.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_110im9r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676216567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have noticed the following events with my naked eyes:&lt;/p&gt;\n\n&lt;p&gt;-when I expel an external hard drive on windows, the OS also tells the internal HDD disk motor to stop spinning (the hard drive also emits a blinking light signal on certain models).&lt;/p&gt;\n\n&lt;p&gt;-when I expel an external hard drive on GhostBSD, the filesystem is expelled but the internal HDD disk motor still keeps running until I remove the USB cord attached to the USB port.&lt;/p&gt;\n\n&lt;p&gt;Why is that? Should I be concerned about it? &lt;/p&gt;\n\n&lt;p&gt;-------&lt;/p&gt;\n\n&lt;p&gt;If I ain&amp;#39;t not happy about the way FUSE works then Is it possible to replace the stock software interface for running and editing filesystems in userspace with something else? Which other alternatives are available to use so that I can test &amp;#39;em on my desktop installation to see how well they perform?&lt;/p&gt;\n\n&lt;p&gt;What are the terminal commands I need to add or replace these sort of programs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "110im9r", "is_robot_indexable": true, "report_reasons": null, "author": "Unique_Lake", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/110im9r/noob_question_about_fuse_and_how_it_works_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/110im9r/noob_question_about_fuse_and_how_it_works_on/", "subreddit_subscribers": 669542, "created_utc": 1676216567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 4 bay Austor nas with 4x 10tb drives but I want to size them up as the budget allows, buying one at a time. With the drives  configured in raid5 am I able to hot swap a larger dive in? Say i buy one 14tb drive then another in a month and so on will the NAS redistribute the raid5 to use the new volume and reflect the available storage as i put one in now then again in a month?", "author_fullname": "t2_ltbzxq19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Noob question about nas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110gyfo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676212107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 4 bay Austor nas with 4x 10tb drives but I want to size them up as the budget allows, buying one at a time. With the drives  configured in raid5 am I able to hot swap a larger dive in? Say i buy one 14tb drive then another in a month and so on will the NAS redistribute the raid5 to use the new volume and reflect the available storage as i put one in now then again in a month?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "110gyfo", "is_robot_indexable": true, "report_reasons": null, "author": "29Top", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/110gyfo/noob_question_about_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/110gyfo/noob_question_about_nas/", "subreddit_subscribers": 669542, "created_utc": 1676212107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've had this 2.5\" 5TB Toshiba drive for almost 2 years. Worked fine until yesterday. When I try to download anything with qBittorrent onto the drive, after a couple seconds I get \"Delayed Write Failed\" errors and the downloads stop. I have backup copy of all files on another drive so that's not really an issue.\n\nI wanted to ask, is this error caused by the hard drive, or something software-related? I can successfully download files onto the drive from my web browser, but with torrent files I get this error every time. I tried changing the destination folder in qBittorrent to other drives, and those drives don't seem to be getting this error.\n\nAnyway I think I'm gonna send this drive to Seagate for RMA. Hopefully they replace it.", "author_fullname": "t2_s2tsrp18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External 2.5\" 5TB HDD \"Delayed Write Failed\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1103t0u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676165760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve had this 2.5&amp;quot; 5TB Toshiba drive for almost 2 years. Worked fine until yesterday. When I try to download anything with qBittorrent onto the drive, after a couple seconds I get &amp;quot;Delayed Write Failed&amp;quot; errors and the downloads stop. I have backup copy of all files on another drive so that&amp;#39;s not really an issue.&lt;/p&gt;\n\n&lt;p&gt;I wanted to ask, is this error caused by the hard drive, or something software-related? I can successfully download files onto the drive from my web browser, but with torrent files I get this error every time. I tried changing the destination folder in qBittorrent to other drives, and those drives don&amp;#39;t seem to be getting this error.&lt;/p&gt;\n\n&lt;p&gt;Anyway I think I&amp;#39;m gonna send this drive to Seagate for RMA. Hopefully they replace it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1103t0u", "is_robot_indexable": true, "report_reasons": null, "author": "jakuri69", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1103t0u/external_25_5tb_hdd_delayed_write_failed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1103t0u/external_25_5tb_hdd_delayed_write_failed/", "subreddit_subscribers": 669542, "created_utc": 1676165760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was commenting in a thread about plex/storage/cloud, and the fellas kept saying 'Unlimited is gone'.  \nI said no, I use it, it isn't a myth, go and purchase it. Then, after some days another redditor made a comment: \"*Signed up and got an email from them saying I\u2019m at 80% of my pooled storage limit and if I exceed the limit my account will go into a \u201cread only\u201d state.*\".\n\nGoogling about I saw evidence that Education (free) accounts are being limited in 100TB shared across entire uni.\n\nBut ours are Business, we are paying. What do you reckon?  Are they not limiting paying customers anytime  soon, or 100TB, or the advertised 5TB and nothing else?", "author_fullname": "t2_kkjbi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Unlimited Shared Drive on Google Workspace going away in 2024?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1101lac", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676159383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was commenting in a thread about plex/storage/cloud, and the fellas kept saying &amp;#39;Unlimited is gone&amp;#39;.&lt;br/&gt;\nI said no, I use it, it isn&amp;#39;t a myth, go and purchase it. Then, after some days another redditor made a comment: &amp;quot;&lt;em&gt;Signed up and got an email from them saying I\u2019m at 80% of my pooled storage limit and if I exceed the limit my account will go into a \u201cread only\u201d state.&lt;/em&gt;&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Googling about I saw evidence that Education (free) accounts are being limited in 100TB shared across entire uni.&lt;/p&gt;\n\n&lt;p&gt;But ours are Business, we are paying. What do you reckon?  Are they not limiting paying customers anytime  soon, or 100TB, or the advertised 5TB and nothing else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "84TB @ GDrive oo", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1101lac", "is_robot_indexable": true, "report_reasons": null, "author": "tecepeipe", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1101lac/is_unlimited_shared_drive_on_google_workspace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1101lac/is_unlimited_shared_drive_on_google_workspace/", "subreddit_subscribers": 669542, "created_utc": 1676159383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know anything about this external HDD on Amazon.  I\u2019m after a 10 or 12TB one.\n\nHelp me decide on this product: Deal: UnionSine 12TB 3.5\" Portable External Hard Drive USB3.2Gen2 type-C HDD Storage Compatible for PC, Desktop, Laptop(Black) HD3510 https://amzn.eu/d/dXj5OwM\n\nI can\u2019t find out much about it other than the reviews on the site (though many are for different size models).  \n\nNot sure whether to go for it or stick with a (dearer) WD or Seagate", "author_fullname": "t2_q4xxlckl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "12TB UnionSine External Hard Drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1101ikx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676159176.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know anything about this external HDD on Amazon.  I\u2019m after a 10 or 12TB one.&lt;/p&gt;\n\n&lt;p&gt;Help me decide on this product: Deal: UnionSine 12TB 3.5&amp;quot; Portable External Hard Drive USB3.2Gen2 type-C HDD Storage Compatible for PC, Desktop, Laptop(Black) HD3510 &lt;a href=\"https://amzn.eu/d/dXj5OwM\"&gt;https://amzn.eu/d/dXj5OwM&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I can\u2019t find out much about it other than the reviews on the site (though many are for different size models).  &lt;/p&gt;\n\n&lt;p&gt;Not sure whether to go for it or stick with a (dearer) WD or Seagate&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1101ikx", "is_robot_indexable": true, "report_reasons": null, "author": "Fit-Adhesiveness-866", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1101ikx/12tb_unionsine_external_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1101ikx/12tb_unionsine_external_hard_drive/", "subreddit_subscribers": 669542, "created_utc": 1676159176.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, All hail the land of Spinny and Non Spinny disks!\n\nOver many years, I have acquired a large amount of hard drives, sadly JBOD, so not suitably primed for raid backups or arrays. I have found myself running out of room in my full tower cases for 3.5\" hard drives and the cost of enclosure boxes for drives has put me off jumping on that wagon.\n\n&amp;#x200B;\n\nOption A\n\nWanting a way of connecting 8 drives, I bought this -  [HP 638836-001 660087-001 SAS9207-8E HBA PCI-E 6GB/s Raid Controller Full Height | eBay](https://www.ebay.com/itm/294842317609)  as a way of cleaning up external cables from my comp to a prospective diy drive enclosure and the original plan was to build said enclosure and mount one of these in it - [https://www.amazon.com/gp/product/B00PRXOQFA](https://www.amazon.com/gp/product/B00PRXOQFA), which would then just need two SFF-8088 cables back to the main comp / raid controller and two SFF-8087 to SATA breakout cables for the internal wiring. I would mount a small PSU in the enclosure also and have the drives powered from that, how much power do 8 SATA drives need?\n\nOption B\n\nI also removed the 4 port SAS/SATA backplanes from my HP DL380 and I DL360 (will edit with second server type / specs) and that led me to wonder if I could just use a pre-existing backplane to connect to either the SAS9207-8E  or a SAS9207-8I card, for the 2.5\" backplanes I can use SATA extenders to get past the width limitation and can either power the backplane with an adapter cable or power the drives directly with regular SATA power cables? Would I be able to use something like this perhaps?\n\n[Dell F313F 8-Port 3.5\\&amp;#034; SAS Hard Drive Backplane for PowerEdge T610 / T710 | eBay](https://www.ebay.com/itm/255864387815)\n\nThanks!", "author_fullname": "t2_nvu5c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DIY Storage Array / NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zv9yu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676142619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, All hail the land of Spinny and Non Spinny disks!&lt;/p&gt;\n\n&lt;p&gt;Over many years, I have acquired a large amount of hard drives, sadly JBOD, so not suitably primed for raid backups or arrays. I have found myself running out of room in my full tower cases for 3.5&amp;quot; hard drives and the cost of enclosure boxes for drives has put me off jumping on that wagon.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Option A&lt;/p&gt;\n\n&lt;p&gt;Wanting a way of connecting 8 drives, I bought this -  &lt;a href=\"https://www.ebay.com/itm/294842317609\"&gt;HP 638836-001 660087-001 SAS9207-8E HBA PCI-E 6GB/s Raid Controller Full Height | eBay&lt;/a&gt;  as a way of cleaning up external cables from my comp to a prospective diy drive enclosure and the original plan was to build said enclosure and mount one of these in it - &lt;a href=\"https://www.amazon.com/gp/product/B00PRXOQFA\"&gt;https://www.amazon.com/gp/product/B00PRXOQFA&lt;/a&gt;, which would then just need two SFF-8088 cables back to the main comp / raid controller and two SFF-8087 to SATA breakout cables for the internal wiring. I would mount a small PSU in the enclosure also and have the drives powered from that, how much power do 8 SATA drives need?&lt;/p&gt;\n\n&lt;p&gt;Option B&lt;/p&gt;\n\n&lt;p&gt;I also removed the 4 port SAS/SATA backplanes from my HP DL380 and I DL360 (will edit with second server type / specs) and that led me to wonder if I could just use a pre-existing backplane to connect to either the SAS9207-8E  or a SAS9207-8I card, for the 2.5&amp;quot; backplanes I can use SATA extenders to get past the width limitation and can either power the backplane with an adapter cable or power the drives directly with regular SATA power cables? Would I be able to use something like this perhaps?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.ebay.com/itm/255864387815\"&gt;Dell F313F 8-Port 3.5&amp;amp;#034; SAS Hard Drive Backplane for PowerEdge T610 / T710 | eBay&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OyA3RvikNy1AbUAdFkvYwhFKQdTbDVFc3g9bUK34vDg.jpg?auto=webp&amp;v=enabled&amp;s=e1e87ccb0a063f526393f6b624f3f33cc9bd031e", "width": 400, "height": 335}, "resolutions": [{"url": "https://external-preview.redd.it/OyA3RvikNy1AbUAdFkvYwhFKQdTbDVFc3g9bUK34vDg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=050427c76118a166b58b70d1e647235e554ac2ab", "width": 108, "height": 90}, {"url": "https://external-preview.redd.it/OyA3RvikNy1AbUAdFkvYwhFKQdTbDVFc3g9bUK34vDg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b06f7c768bd85040f11324cb3559c8907ec7a222", "width": 216, "height": 180}, {"url": "https://external-preview.redd.it/OyA3RvikNy1AbUAdFkvYwhFKQdTbDVFc3g9bUK34vDg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64cceb4054043aca98d033d86237007b55211b78", "width": 320, "height": 268}], "variants": {}, "id": "g_z7U36_zCaBZtX1Wr9x5-DztkhZ8FblTwvqskO_q9g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "10zv9yu", "is_robot_indexable": true, "report_reasons": null, "author": "Marslauncher", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/10zv9yu/diy_storage_array_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/10zv9yu/diy_storage_array_nas/", "subreddit_subscribers": 669542, "created_utc": 1676142619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was wondering if videos on archive.org could potentially have malicious code embedded in them?\nI don\u2019t know if they re-encode uploaded videos, but if so, would it be enough to remove any malicious content? How to know if its a safe video?", "author_fullname": "t2_t0hp325k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Malicious code in videos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_110i5hw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676215345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if videos on archive.org could potentially have malicious code embedded in them?\nI don\u2019t know if they re-encode uploaded videos, but if so, would it be enough to remove any malicious content? How to know if its a safe video?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "110i5hw", "is_robot_indexable": true, "report_reasons": null, "author": "ChaoticAstronomy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/110i5hw/malicious_code_in_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/110i5hw/malicious_code_in_videos/", "subreddit_subscribers": 669542, "created_utc": 1676215345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I remember a while back someone commented in here that they tested their old hard drive &amp; the test showed that it was in good health, but someone else commented, \"nope, thats not true\", because the test the 1st redditor did was a superficial health test, not a complete one. And they said that actually the drive is probably failing quite a bit.   \nSo what programs should I use? I got some old hard drives i need to test, an SSHD, a SSD, USB drives, SD cards.   \n\\-thanks!", "author_fullname": "t2_uodj9nv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need a recommendation for programs that will tell me if a hard drive, SSHD, SSD, USB drive &amp; SD card are bad or failing.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110bfkk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676192971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I remember a while back someone commented in here that they tested their old hard drive &amp;amp; the test showed that it was in good health, but someone else commented, &amp;quot;nope, thats not true&amp;quot;, because the test the 1st redditor did was a superficial health test, not a complete one. And they said that actually the drive is probably failing quite a bit.&lt;br/&gt;\nSo what programs should I use? I got some old hard drives i need to test, an SSHD, a SSD, USB drives, SD cards.&lt;br/&gt;\n-thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "110bfkk", "is_robot_indexable": true, "report_reasons": null, "author": "Username9822", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/110bfkk/i_need_a_recommendation_for_programs_that_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/110bfkk/i_need_a_recommendation_for_programs_that_will/", "subreddit_subscribers": 669542, "created_utc": 1676192971.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}