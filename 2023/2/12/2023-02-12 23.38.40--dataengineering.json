{"kind": "Listing", "data": {"after": "t3_1104d44", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am learning lots in terms of general data engineering at my current role but was wondering about the benefits of learning Data Structures and Algorithms on the side to further boost my skills. I have a few questions about this and would be grateful for any answers from those with experience and knowledge.\n\n1) Will bring better at DS&amp;A make me a better data engineer? I feel as though a lot of the skills aren't used directly in DE but please correct me if I'm wrong.\n\n2) How comprehensively would you need to know DS&amp;A for a DE coding exam when applying to new roles? I'd imagine it to be not as intense as a SWE role for example.\n\n3) What is a realistic timeframe to be able to start passing coding exams if I'm allocating around 5 hours a week to learning this?\n\n4) What are some good resources for learning this and is there anything that is a bit more tailored to DE DS&amp;A tests?\n\nThank you in advance for any responses.", "author_fullname": "t2_87ogeeb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Structures and Algorithms as a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11055pg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 64, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676169978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning lots in terms of general data engineering at my current role but was wondering about the benefits of learning Data Structures and Algorithms on the side to further boost my skills. I have a few questions about this and would be grateful for any answers from those with experience and knowledge.&lt;/p&gt;\n\n&lt;p&gt;1) Will bring better at DS&amp;amp;A make me a better data engineer? I feel as though a lot of the skills aren&amp;#39;t used directly in DE but please correct me if I&amp;#39;m wrong.&lt;/p&gt;\n\n&lt;p&gt;2) How comprehensively would you need to know DS&amp;amp;A for a DE coding exam when applying to new roles? I&amp;#39;d imagine it to be not as intense as a SWE role for example.&lt;/p&gt;\n\n&lt;p&gt;3) What is a realistic timeframe to be able to start passing coding exams if I&amp;#39;m allocating around 5 hours a week to learning this?&lt;/p&gt;\n\n&lt;p&gt;4) What are some good resources for learning this and is there anything that is a bit more tailored to DE DS&amp;amp;A tests?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11055pg", "is_robot_indexable": true, "report_reasons": null, "author": "SendMeYourThoughts", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11055pg/data_structures_and_algorithms_as_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11055pg/data_structures_and_algorithms_as_a_data_engineer/", "subreddit_subscribers": 89383, "created_utc": 1676169978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Side projects? Reading? Courses?\n\nAs someone with no formal background in SWE/tech, most of my improvement has come from the desire to learn more about things. Not the most structured approach though, just curious to know how everyone else keeps their skills sharp!", "author_fullname": "t2_15ztlh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you personally do to improve as a DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110gth0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676211704.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Side projects? Reading? Courses?&lt;/p&gt;\n\n&lt;p&gt;As someone with no formal background in SWE/tech, most of my improvement has come from the desire to learn more about things. Not the most structured approach though, just curious to know how everyone else keeps their skills sharp!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110gth0", "is_robot_indexable": true, "report_reasons": null, "author": "rlyply", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110gth0/what_do_you_personally_do_to_improve_as_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110gth0/what_do_you_personally_do_to_improve_as_a_de/", "subreddit_subscribers": 89383, "created_utc": 1676211704.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nThe intention of this post is to stimulate discussion on the merits of various approaches to the ingestion of data into a cloud warehouse/lakehouse.\n\nHow do you go about it, and what are your reasons for doing so?\n\nQuestions to get us started:\n- do you land your data in an object store (s3, blob) before loading in to your warehouse? All the time, or just in certain circumstances? What about if you\u2019re ingesting from a SQL source?\n- do you have a preference for off the shelf solutions such as FiveTran/Matillion/ADF, or would you pref to build a framework yourself? Have you built a framework, and if so what language did you use &amp; how robust is it?\n- if you were to start from scratch, greenfield, what would it look like?\n\nAnd I\u2019ll begin by answering my own questions:\n- many of our sources sync directly into Snowflake, including Kafka, Segment and FiveTran. Where we have built a custom pipeline we land the data in S3 as a first hop.\n- my preference as a developer is to build. We have an oop python framework we have developed which is working well. But it\u2019s only used where an off the shelf solutions doesn\u2019t meet our needs. From a build vs buy strategy, we buy the ingestion and build the business transformation. It\u2019s the business logic that holds more value. We use dbt for transform.\n- if I were to go again, it would be a Hudi lakehouse, with a custom pipeline framework. It allows us to remain separated from specific vendor solutions which may lead to lock-in/cost hikes. I\u2019d likely retain dbt-cli, and as much as possible take a mesh/domain separation to the data (noting than business domain and business systems are different things).\n\nI\u2019d also want to do a far better job of making the data \u2018findable\u2019, but that\u2019s not strictly related to the title. We publish dbt docs right now, but have a number of dbt projects, and the information on the sources isn\u2019t contained in here. Planning to investigate OpenMetadata when we have capacity.\n\nKeen on others thoughts.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ingesting Data - workflow best practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1102xw5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676164104.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676163226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;The intention of this post is to stimulate discussion on the merits of various approaches to the ingestion of data into a cloud warehouse/lakehouse.&lt;/p&gt;\n\n&lt;p&gt;How do you go about it, and what are your reasons for doing so?&lt;/p&gt;\n\n&lt;p&gt;Questions to get us started:\n- do you land your data in an object store (s3, blob) before loading in to your warehouse? All the time, or just in certain circumstances? What about if you\u2019re ingesting from a SQL source?\n- do you have a preference for off the shelf solutions such as FiveTran/Matillion/ADF, or would you pref to build a framework yourself? Have you built a framework, and if so what language did you use &amp;amp; how robust is it?\n- if you were to start from scratch, greenfield, what would it look like?&lt;/p&gt;\n\n&lt;p&gt;And I\u2019ll begin by answering my own questions:\n- many of our sources sync directly into Snowflake, including Kafka, Segment and FiveTran. Where we have built a custom pipeline we land the data in S3 as a first hop.\n- my preference as a developer is to build. We have an oop python framework we have developed which is working well. But it\u2019s only used where an off the shelf solutions doesn\u2019t meet our needs. From a build vs buy strategy, we buy the ingestion and build the business transformation. It\u2019s the business logic that holds more value. We use dbt for transform.\n- if I were to go again, it would be a Hudi lakehouse, with a custom pipeline framework. It allows us to remain separated from specific vendor solutions which may lead to lock-in/cost hikes. I\u2019d likely retain dbt-cli, and as much as possible take a mesh/domain separation to the data (noting than business domain and business systems are different things).&lt;/p&gt;\n\n&lt;p&gt;I\u2019d also want to do a far better job of making the data \u2018findable\u2019, but that\u2019s not strictly related to the title. We publish dbt docs right now, but have a number of dbt projects, and the information on the sources isn\u2019t contained in here. Planning to investigate OpenMetadata when we have capacity.&lt;/p&gt;\n\n&lt;p&gt;Keen on others thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1102xw5", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1102xw5/ingesting_data_workflow_best_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1102xw5/ingesting_data_workflow_best_practice/", "subreddit_subscribers": 89383, "created_utc": 1676163226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, my friend wants to learn SQL what would you recommend as the best way of learning SQL ?", "author_fullname": "t2_3xupopvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL tips", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110hva6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676214594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, my friend wants to learn SQL what would you recommend as the best way of learning SQL ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "110hva6", "is_robot_indexable": true, "report_reasons": null, "author": "Sulaiman_m97", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110hva6/sql_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110hva6/sql_tips/", "subreddit_subscribers": 89383, "created_utc": 1676214594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I work as DWH developer for 4 years, I work with Oracle Database, use Oracle Data Integrator and PL/SQL for ETL. My strongest skills are SQL, relational databates, PL/SQL, data modelling (dimensional data model, star schemas, scd...generally everything from kimball's datawarehouse toolkit). \nI've just got offered job as Data Engineer. I'd love to learn how to make DWH and ETL in modern way but I am also scared, to be honest. I have no experience with cloud, I have only basic knowledge of Python. I've never worked with Docker and I know only basics of Linux and git. Should I take that job or should I study cloud, Python etc and then apply for the similar position?", "author_fullname": "t2_kh4jiqla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DWH developer transformation to Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110bvt7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676194728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I work as DWH developer for 4 years, I work with Oracle Database, use Oracle Data Integrator and PL/SQL for ETL. My strongest skills are SQL, relational databates, PL/SQL, data modelling (dimensional data model, star schemas, scd...generally everything from kimball&amp;#39;s datawarehouse toolkit). \nI&amp;#39;ve just got offered job as Data Engineer. I&amp;#39;d love to learn how to make DWH and ETL in modern way but I am also scared, to be honest. I have no experience with cloud, I have only basic knowledge of Python. I&amp;#39;ve never worked with Docker and I know only basics of Linux and git. Should I take that job or should I study cloud, Python etc and then apply for the similar position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110bvt7", "is_robot_indexable": true, "report_reasons": null, "author": "No_Pause7942", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110bvt7/dwh_developer_transformation_to_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110bvt7/dwh_developer_transformation_to_data_engineer/", "subreddit_subscribers": 89383, "created_utc": 1676194728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say you have a medallion architecture lakehouse/warehouse. There are facts and dimensions in your gold layer used for analytics.\n\nYou have a request to pull data from one source, provide some cleaning and logic to it and then send it to another system via their API. At this stage, there is no requirement from analysts to see this data in a fact/dim.\n\nDo you build a completely standalone pipeline to cater to the need?\n\nDo you ingest into bronze, bring through to silver to align with all other data in a consistent manner, potentially building that into larger source agnostic tables, and then send it out from there?\n\nDo you do something different?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a minimum level you take your data through a warehouse before showing it to users?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110403g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676166370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you have a medallion architecture lakehouse/warehouse. There are facts and dimensions in your gold layer used for analytics.&lt;/p&gt;\n\n&lt;p&gt;You have a request to pull data from one source, provide some cleaning and logic to it and then send it to another system via their API. At this stage, there is no requirement from analysts to see this data in a fact/dim.&lt;/p&gt;\n\n&lt;p&gt;Do you build a completely standalone pipeline to cater to the need?&lt;/p&gt;\n\n&lt;p&gt;Do you ingest into bronze, bring through to silver to align with all other data in a consistent manner, potentially building that into larger source agnostic tables, and then send it out from there?&lt;/p&gt;\n\n&lt;p&gt;Do you do something different?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110403g", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110403g/is_there_a_minimum_level_you_take_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110403g/is_there_a_minimum_level_you_take_your_data/", "subreddit_subscribers": 89383, "created_utc": 1676166370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently I\u2019m a data analyst that specifically works with my company\u2019s inventory. And I\u2019m stalling, I only use excel/power query, all the data I use comes from our CRM or our partners, and is put into excel. It sucks to work with, if I scroll to fast on some sheets they\u2019ll crash because there\u2019s too many rows. \n\nAnyway, working this job I realized I enjoy automating work sheets, and the overall work process more than the analyzation. So I\u2019d like to move into data engineering and want to gear my personal portfolio towards that. I thinking of doing a project where I just make a simple pipeline. I want to use Python and Spotify\u2019s API to extract and transform the data, and load it into a Power BI dashboard. However, I\u2019m not a data engineer, and honestly I\u2019m a pretty low level analyst with an out of date skill set, and I\u2019m not sure if this project is something worthwhile. \n\nIt seems like data engineering is a very wide field in terms of tools used, and I\u2019m not sure if the tools above are what\u2019s desired by employers or atleast shows desirable skills, so any feedback would be greatly appreciated, thanks!", "author_fullname": "t2_49nguj2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to start a data engineering project but not sure if I have the right idea", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11010wf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676157837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I\u2019m a data analyst that specifically works with my company\u2019s inventory. And I\u2019m stalling, I only use excel/power query, all the data I use comes from our CRM or our partners, and is put into excel. It sucks to work with, if I scroll to fast on some sheets they\u2019ll crash because there\u2019s too many rows. &lt;/p&gt;\n\n&lt;p&gt;Anyway, working this job I realized I enjoy automating work sheets, and the overall work process more than the analyzation. So I\u2019d like to move into data engineering and want to gear my personal portfolio towards that. I thinking of doing a project where I just make a simple pipeline. I want to use Python and Spotify\u2019s API to extract and transform the data, and load it into a Power BI dashboard. However, I\u2019m not a data engineer, and honestly I\u2019m a pretty low level analyst with an out of date skill set, and I\u2019m not sure if this project is something worthwhile. &lt;/p&gt;\n\n&lt;p&gt;It seems like data engineering is a very wide field in terms of tools used, and I\u2019m not sure if the tools above are what\u2019s desired by employers or atleast shows desirable skills, so any feedback would be greatly appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11010wf", "is_robot_indexable": true, "report_reasons": null, "author": "Hillsand0", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11010wf/i_want_to_start_a_data_engineering_project_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11010wf/i_want_to_start_a_data_engineering_project_but/", "subreddit_subscribers": 89383, "created_utc": 1676157837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it still an open and fully interoperable building block? Or can tables in Unity Catalog can only be queried by Databricks' engine?", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If I use Databricks Unity Catalog, can i still use open source Spark or Presto / Trino (or any other SQL engine for that matter) to query tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1108cug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676180881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it still an open and fully interoperable building block? Or can tables in Unity Catalog can only be queried by Databricks&amp;#39; engine?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1108cug", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1108cug/if_i_use_databricks_unity_catalog_can_i_still_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1108cug/if_i_use_databricks_unity_catalog_can_i_still_use/", "subreddit_subscribers": 89383, "created_utc": 1676180881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Folks,   \nWhat are some of the best CDC options available? How schema changes are handled in CDC?  \nDo we need to dedup data once data is written at S3? How deletes are handled?", "author_fullname": "t2_sr3rc27q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CDC Implementation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110jbvv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676218401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Folks,&lt;br/&gt;\nWhat are some of the best CDC options available? How schema changes are handled in CDC?&lt;br/&gt;\nDo we need to dedup data once data is written at S3? How deletes are handled?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110jbvv", "is_robot_indexable": true, "report_reasons": null, "author": "honey12123", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/110jbvv/cdc_implementation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110jbvv/cdc_implementation/", "subreddit_subscribers": 89383, "created_utc": 1676218401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Excluding airbnb (major resorts, hotels, etc.)\n\nAt the moment, it seems the industry either builds everything in house or use 3rd party systems for each task (communication, profiling, check-in management, data storage/retrieval, etc.)", "author_fullname": "t2_rt5kovjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data engineers here with experience in building a data platform for the hospitality and travel industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110471e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676166967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Excluding airbnb (major resorts, hotels, etc.)&lt;/p&gt;\n\n&lt;p&gt;At the moment, it seems the industry either builds everything in house or use 3rd party systems for each task (communication, profiling, check-in management, data storage/retrieval, etc.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110471e", "is_robot_indexable": true, "report_reasons": null, "author": "slp_001100", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110471e/any_data_engineers_here_with_experience_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110471e/any_data_engineers_here_with_experience_in/", "subreddit_subscribers": 89383, "created_utc": 1676166967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been reading through O'Reilly's *Data Pipelines Pocket Reference* which has done a really great job of breaking apart the steps of an ELT pipeline into real-world use cases. I like how the extraction step is simplified to reading from a source and writing a CSV to S3; and the examples for ingesting from DBs or APIs make sense.\n\nMy questions are pretty simple, but when I think about how to apply the same logic to sourcing from a filesystem (or S3 path) I have a few more questions...\n\n1. Unlike a DB, files don't have primary keys, but often, the file's parent directory path can be used to uniquely identify the file, would I be right to include the path and any other data to the output CSV in my Extract step? Would this be considered EtLT?\n2. Expanding on the first question, In cases where the directory path is important for uniquely identifying a file, what do I do when I have two or more different file types that I'm interested in under the same parent directory? Should I Extract each separately to it's own CSV? Should I create a single CSV for all the files under that parent directory, joining files together? Something else?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should I be Extracting data files from a filesystem/S3 like I do for DBs &amp; APIs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1103z7u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676166303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been reading through O&amp;#39;Reilly&amp;#39;s &lt;em&gt;Data Pipelines Pocket Reference&lt;/em&gt; which has done a really great job of breaking apart the steps of an ELT pipeline into real-world use cases. I like how the extraction step is simplified to reading from a source and writing a CSV to S3; and the examples for ingesting from DBs or APIs make sense.&lt;/p&gt;\n\n&lt;p&gt;My questions are pretty simple, but when I think about how to apply the same logic to sourcing from a filesystem (or S3 path) I have a few more questions...&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Unlike a DB, files don&amp;#39;t have primary keys, but often, the file&amp;#39;s parent directory path can be used to uniquely identify the file, would I be right to include the path and any other data to the output CSV in my Extract step? Would this be considered EtLT?&lt;/li&gt;\n&lt;li&gt;Expanding on the first question, In cases where the directory path is important for uniquely identifying a file, what do I do when I have two or more different file types that I&amp;#39;m interested in under the same parent directory? Should I Extract each separately to it&amp;#39;s own CSV? Should I create a single CSV for all the files under that parent directory, joining files together? Something else?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1103z7u", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1103z7u/how_should_i_be_extracting_data_files_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1103z7u/how_should_i_be_extracting_data_files_from_a/", "subreddit_subscribers": 89383, "created_utc": 1676166303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Company uses Domo as our data warehouse and BI solution. I run into problems once a month where incorrect manually entered data in systems gets into an important table and I have no way of fixing it unless I reload the data and replace all data in the table. Is anyone else working with Domo and how do you handle cleaning up incorrect inputs?", "author_fullname": "t2_3eirbc33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone use Domo?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1100m81", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676156686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Company uses Domo as our data warehouse and BI solution. I run into problems once a month where incorrect manually entered data in systems gets into an important table and I have no way of fixing it unless I reload the data and replace all data in the table. Is anyone else working with Domo and how do you handle cleaning up incorrect inputs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1100m81", "is_robot_indexable": true, "report_reasons": null, "author": "pbxmy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1100m81/does_anyone_use_domo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1100m81/does_anyone_use_domo/", "subreddit_subscribers": 89383, "created_utc": 1676156686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I\u2019ve been working with my company as a data engineer in our business intelligence department for the last 3 years. Over the last 3 years our team has been severely neglected by our leadership causing many people in my team to move to new opportunities. This has lead to my team being over worked and underpaid (making $81k in austin) I can never find time to work on projects as I\u2019m constantly being pulled into fire drills due to bad data in Salesforce. \n\nOur current infrastructure is SSMS enterprise data warehouse using SSIS and SSAS cubes. There are plans for our team to move to the cloud but with my current leadership, I don\u2019t see the move to cloud happening anytime soon. I\u2019ve also build data pipelines using python and pulling data from source system apis\n\nI really would like to move to a new company but in job listings I feel like everyone is only looking for DEs that work with different cloud technologies.\n\nI was wondering if anyone could give me advice on ways I can make myself more appealing to employers. Any recommendations are helpful from courses to certifications would be greatly appreciated.", "author_fullname": "t2_2jf9pj50", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help moving to a cloud base DE role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110pk9f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676234132.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019ve been working with my company as a data engineer in our business intelligence department for the last 3 years. Over the last 3 years our team has been severely neglected by our leadership causing many people in my team to move to new opportunities. This has lead to my team being over worked and underpaid (making $81k in austin) I can never find time to work on projects as I\u2019m constantly being pulled into fire drills due to bad data in Salesforce. &lt;/p&gt;\n\n&lt;p&gt;Our current infrastructure is SSMS enterprise data warehouse using SSIS and SSAS cubes. There are plans for our team to move to the cloud but with my current leadership, I don\u2019t see the move to cloud happening anytime soon. I\u2019ve also build data pipelines using python and pulling data from source system apis&lt;/p&gt;\n\n&lt;p&gt;I really would like to move to a new company but in job listings I feel like everyone is only looking for DEs that work with different cloud technologies.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone could give me advice on ways I can make myself more appealing to employers. Any recommendations are helpful from courses to certifications would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110pk9f", "is_robot_indexable": true, "report_reasons": null, "author": "DankBoyardee", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110pk9f/help_moving_to_a_cloud_base_de_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110pk9f/help_moving_to_a_cloud_base_de_role/", "subreddit_subscribers": 89383, "created_utc": 1676234132.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to build a project portfolio but not sure where to commit. Thank you for the suggestions in advance.", "author_fullname": "t2_m9qt65bk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling to find practice projects. Is Leetcode good enough?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110o9s2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676230848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to build a project portfolio but not sure where to commit. Thank you for the suggestions in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110o9s2", "is_robot_indexable": true, "report_reasons": null, "author": "beakyblindar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110o9s2/struggling_to_find_practice_projects_is_leetcode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110o9s2/struggling_to_find_practice_projects_is_leetcode/", "subreddit_subscribers": 89383, "created_utc": 1676230848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am 6 year experienced data engineer have worked over last few years on \\[MSBI, tableau , oracle, spark, CDH, various vendor specific pipeline, ES , kibana and little bit on API side as well, but haven't got a chance to work on streaming problems much except few learning POC's and neither in future there is any scope of it. Can you guys please tell how much important it is to know various streaming at scale in production ?, is it that people with hands on streaming problem statements are paid more and preferred in interview ? . I belong from very poor family and have made only limited savings yet, so job safety and money are important to me currently.", "author_fullname": "t2_fftrw7s7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "knowledge of Streaming system for data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110lel5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676223610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am 6 year experienced data engineer have worked over last few years on [MSBI, tableau , oracle, spark, CDH, various vendor specific pipeline, ES , kibana and little bit on API side as well, but haven&amp;#39;t got a chance to work on streaming problems much except few learning POC&amp;#39;s and neither in future there is any scope of it. Can you guys please tell how much important it is to know various streaming at scale in production ?, is it that people with hands on streaming problem statements are paid more and preferred in interview ? . I belong from very poor family and have made only limited savings yet, so job safety and money are important to me currently.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "110lel5", "is_robot_indexable": true, "report_reasons": null, "author": "No-Position1673", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110lel5/knowledge_of_streaming_system_for_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110lel5/knowledge_of_streaming_system_for_data_engineer/", "subreddit_subscribers": 89383, "created_utc": 1676223610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI am a fairly new working professional in Software Engineering, who was recently laid off. I am currently in the final interview stages of 2 companies for 2 different roles - data scientist and data engineer. The thing is - I have some experience working within both the domains, and also have a couple of publications in NLP. \n\nWhile I completely understand that the final decision is going to be upto me, I had a few questions for people here - especially for the people who have made a switch from data science to data engineering. \n\n1. How easy was it for you to switch?\n2. Why did you make the switch?\n3. What is something that you really love and really hate about the 2 domains?\n\nThis would help me gain better insight and make an even more informed decision.\n\nThanks!", "author_fullname": "t2_tp3j7tir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Insight from data engineers - especially ex data scientists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_110scdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676241330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a fairly new working professional in Software Engineering, who was recently laid off. I am currently in the final interview stages of 2 companies for 2 different roles - data scientist and data engineer. The thing is - I have some experience working within both the domains, and also have a couple of publications in NLP. &lt;/p&gt;\n\n&lt;p&gt;While I completely understand that the final decision is going to be upto me, I had a few questions for people here - especially for the people who have made a switch from data science to data engineering. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How easy was it for you to switch?&lt;/li&gt;\n&lt;li&gt;Why did you make the switch?&lt;/li&gt;\n&lt;li&gt;What is something that you really love and really hate about the 2 domains?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This would help me gain better insight and make an even more informed decision.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110scdj", "is_robot_indexable": true, "report_reasons": null, "author": "djavulsk-perkele", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110scdj/insight_from_data_engineers_especially_ex_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110scdj/insight_from_data_engineers_especially_ex_data/", "subreddit_subscribers": 89383, "created_utc": 1676241330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm just running some labs with Azure Synapse and Databricks on Azure and I wanted someone to validate whether this would be a solid pipeline.  The source is a Postgres db.\n\nExtract: Synapse Pipelines Copy Activity to Azure Data Lake Gen 2 Storage\n\nTransformation: Azure Databricks notebook triggered by Synapse Pipelines. Databricks notebook would be written in PySpark.\n\nLoad: Databricks notebook loads transformed data into Synapse dedicated SQL pool\n\n&amp;#x200B;\n\nAm I missing any steps here? Can Databricks directly load transformed data into a Synapse Dedicated SQL pool?", "author_fullname": "t2_nhdew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Validate my Azure Synapse/Databricks pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_110rr24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676239793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m just running some labs with Azure Synapse and Databricks on Azure and I wanted someone to validate whether this would be a solid pipeline.  The source is a Postgres db.&lt;/p&gt;\n\n&lt;p&gt;Extract: Synapse Pipelines Copy Activity to Azure Data Lake Gen 2 Storage&lt;/p&gt;\n\n&lt;p&gt;Transformation: Azure Databricks notebook triggered by Synapse Pipelines. Databricks notebook would be written in PySpark.&lt;/p&gt;\n\n&lt;p&gt;Load: Databricks notebook loads transformed data into Synapse dedicated SQL pool&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Am I missing any steps here? Can Databricks directly load transformed data into a Synapse Dedicated SQL pool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110rr24", "is_robot_indexable": true, "report_reasons": null, "author": "MonkeyMaster64", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110rr24/validate_my_azure_synapsedatabricks_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110rr24/validate_my_azure_synapsedatabricks_pipeline/", "subreddit_subscribers": 89383, "created_utc": 1676239793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in a Manager position at my company and work at a client. I work mostly on the requirements side as a Business Analyst for Data Analytics products (Management Dashboards).\n\nI have two people who report to me and lead a team for ensuring we build what the client asked for.\n\nI do not enjoy it for the sole reason that I do not own any portion of the product. Even requirements are pre-gathered by the client and I make sure on feasibility and looking for gaps. \n\nMy tech skills stop at SQL and how dashboards are built (data views, calcs, and design). But I am an expert in understanding business needs and getting teams to build it. \n\nI make ~120K outside of a HCOL area. 6 YOE. \n\nWith my deep analytics experience, and basic SQL, money wise is it worth it to go the DE route? Would I have to start at the Entry level spot? Or ride the management path and never do the actual building of anything?", "author_fullname": "t2_9630n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition to Data Engineer from a Data Analytics/Business Analyst manager position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_110rbqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676239190.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676238661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in a Manager position at my company and work at a client. I work mostly on the requirements side as a Business Analyst for Data Analytics products (Management Dashboards).&lt;/p&gt;\n\n&lt;p&gt;I have two people who report to me and lead a team for ensuring we build what the client asked for.&lt;/p&gt;\n\n&lt;p&gt;I do not enjoy it for the sole reason that I do not own any portion of the product. Even requirements are pre-gathered by the client and I make sure on feasibility and looking for gaps. &lt;/p&gt;\n\n&lt;p&gt;My tech skills stop at SQL and how dashboards are built (data views, calcs, and design). But I am an expert in understanding business needs and getting teams to build it. &lt;/p&gt;\n\n&lt;p&gt;I make ~120K outside of a HCOL area. 6 YOE. &lt;/p&gt;\n\n&lt;p&gt;With my deep analytics experience, and basic SQL, money wise is it worth it to go the DE route? Would I have to start at the Entry level spot? Or ride the management path and never do the actual building of anything?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "110rbqx", "is_robot_indexable": true, "report_reasons": null, "author": "Amanlikeyou", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110rbqx/transition_to_data_engineer_from_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110rbqx/transition_to_data_engineer_from_a_data/", "subreddit_subscribers": 89383, "created_utc": 1676238661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "From reading through this sub and articles like [this](https://medium.com/bluecore-engineering/were-all-using-airflow-wrong-and-how-to-fix-it-a56f14cb0753), there's definitely arguments for containerizing all Airflow tasks to separate execution logic from orchestration logic. Whether it's easier onboarding of new devs, package conflicts between tasks, simpler debugging, etc., it all sounds great in theory. But I'm curious how many teams actually build their DAGs like this and whether it's worth it?\n\n[View Poll](https://www.reddit.com/poll/110qo3h)", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you execute all Airflow tasks in containers to separate execution logic from orchestration logic?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110qo3h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676236961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From reading through this sub and articles like &lt;a href=\"https://medium.com/bluecore-engineering/were-all-using-airflow-wrong-and-how-to-fix-it-a56f14cb0753\"&gt;this&lt;/a&gt;, there&amp;#39;s definitely arguments for containerizing all Airflow tasks to separate execution logic from orchestration logic. Whether it&amp;#39;s easier onboarding of new devs, package conflicts between tasks, simpler debugging, etc., it all sounds great in theory. But I&amp;#39;m curious how many teams actually build their DAGs like this and whether it&amp;#39;s worth it?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/110qo3h\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?auto=webp&amp;v=enabled&amp;s=c4c33040015af6b9b895354919a038471d8ebd2d", "width": 752, "height": 427}, "resolutions": [{"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00c7c68e97652e6b3530ab5eba5ea327b38a8942", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=943e5fa8fa60e636733f063d1d720572ccbc59a4", "width": 216, "height": 122}, {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=040eb5e59874649b8347f423c89e973bd8cc13e8", "width": 320, "height": 181}, {"url": "https://external-preview.redd.it/DMBUJ8maay7dbF1RPYVGDGEVZerwKQW2ENndmdY4BvA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=daa1a474f8dfc6b5bb91f396ddd49601bc8a0a8c", "width": 640, "height": 363}], "variants": {}, "id": "sf2SA2a5dF3sFQeNi3Z_FOLTkemkNklRDj4S8DgYVz0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110qo3h", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1676668961870, "options": [{"text": "Yes we containerize and it's worth it", "id": "21568710"}, {"text": "Yes we containerize but it's not worth it", "id": "21568711"}, {"text": "No we don't containerize but we're interested", "id": "21568712"}, {"text": "No we don't containerize and we're not interested", "id": "21568713"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 32, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110qo3h/do_you_execute_all_airflow_tasks_in_containers_to/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/110qo3h/do_you_execute_all_airflow_tasks_in_containers_to/", "subreddit_subscribers": 89383, "created_utc": 1676236961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would someone kindly let me know whether they have experience working in the supply chain as a data engineer? If so, what is their daily work look like! \nWhat kind of tool you are using and for which purpose!", "author_fullname": "t2_m6lk62t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Role of a Data engineer in a supply chain org !", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110nqwv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676229502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would someone kindly let me know whether they have experience working in the supply chain as a data engineer? If so, what is their daily work look like! \nWhat kind of tool you are using and for which purpose!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "110nqwv", "is_robot_indexable": true, "report_reasons": null, "author": "TelevisionDue5491", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110nqwv/role_of_a_data_engineer_in_a_supply_chain_org/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110nqwv/role_of_a_data_engineer_in_a_supply_chain_org/", "subreddit_subscribers": 89383, "created_utc": 1676229502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nJust wanted to ask for some advice on an upcoming technical task for an interview I have coming up. \n\nI've never done one before and the details of the task are very vague and when I asked for more details the recruiter just replied with \"it will be a generic problem\" which to me, sounded like a leet style question. However, if it's a paired programming task, maybe it will be more complicated than a generic leet style question and i'll be helping designing a pipeline/bit of software using OOP etc.\n\n* Has anybody on this space done a technical task where it's pair programming?\n* What sort of questions were you asked?\n* Any suggestions on preparing for this (despite the recruiter suggesting no prep was needed)", "author_fullname": "t2_1drdwjiw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview - Technical Task (paired programming exercise) preperation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110ljl9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676223950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Just wanted to ask for some advice on an upcoming technical task for an interview I have coming up. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve never done one before and the details of the task are very vague and when I asked for more details the recruiter just replied with &amp;quot;it will be a generic problem&amp;quot; which to me, sounded like a leet style question. However, if it&amp;#39;s a paired programming task, maybe it will be more complicated than a generic leet style question and i&amp;#39;ll be helping designing a pipeline/bit of software using OOP etc.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Has anybody on this space done a technical task where it&amp;#39;s pair programming?&lt;/li&gt;\n&lt;li&gt;What sort of questions were you asked?&lt;/li&gt;\n&lt;li&gt;Any suggestions on preparing for this (despite the recruiter suggesting no prep was needed)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "110ljl9", "is_robot_indexable": true, "report_reasons": null, "author": "yorkshireSpud12", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110ljl9/interview_technical_task_paired_programming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110ljl9/interview_technical_task_paired_programming/", "subreddit_subscribers": 89383, "created_utc": 1676223950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say you have an ELT pipeline that moves data from a source system with CDC to a DWH (e.g. BigQuery), and for some tables you use slowly changing dimension type 2.\n\nTherefore, for these tables, your DWH would have both the latest snapshot as well as all the history of the changes.\n\nOne day you decide to ditch BigQuery to move to a different platform, say Snowflake.\n\nHow do you seamlessly migrate your pipeline AND data to the new platform, while making sure to maintain the changes history?", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you migrate tables with SCD type 2 from one system to another?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110k9rf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676220799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you have an ELT pipeline that moves data from a source system with CDC to a DWH (e.g. BigQuery), and for some tables you use slowly changing dimension type 2.&lt;/p&gt;\n\n&lt;p&gt;Therefore, for these tables, your DWH would have both the latest snapshot as well as all the history of the changes.&lt;/p&gt;\n\n&lt;p&gt;One day you decide to ditch BigQuery to move to a different platform, say Snowflake.&lt;/p&gt;\n\n&lt;p&gt;How do you seamlessly migrate your pipeline AND data to the new platform, while making sure to maintain the changes history?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110k9rf", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110k9rf/how_do_you_migrate_tables_with_scd_type_2_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110k9rf/how_do_you_migrate_tables_with_scd_type_2_from/", "subreddit_subscribers": 89383, "created_utc": 1676220799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all,\n\nI'm new to Data Modelling and I'm currently stumped at a personal project. Allow me to give some context first.\n\nI have been given a preaggregated data set containing preorders at a daily level. Basically everyday I will get a flat file that has the summed up amounts of preorders by day (past, present and future), store, and product category. I don't have customer or product information. \n\nFor example, in the file from yesterday, I would have preorders slated for 13 May 2023 as 13, comprised of any unknown number of customers ordering any number of unknown products. Then when I get today's file, I will see that for 13 May 2023, I now have 5 preorders, meaning either some or all the customers from yesterday's 13 preorders probably cancelled or shifted their preorders to another unknown date. \n\nTo conplicate matters, if for preorder date of 13 May 2023, the amount of preorders went from 13 to 0, I would not get that row with preorder count = 0 in the new file. \n\nThe idea is to have this dataset feed a dashboard so that the end user can track the growth of preorders for any given date and store as time/year progresses.\n\nI looked into SCD2 but I'm not sure if this is the right approach for the task. Because for one, the preorders are facts and it is the facts that are changing, not dimensions, hence I thought slowly changing facts?\n\nAnother reason I think SCD2 is not right because I was told that I shouldn't be using the preorder column as a \"join condition/key\" to check whether or not a record changed (preorder date, store, category as composite keys) from one day's file to another day's file. Otherwise I think I would be doing this with some extra steps in addition to a Merge statement. \n\nSo I'm reaching out for help from all you gurus because I'm getting nowhere despite all the Googling. I'm trying to do this in SQL Server but will eventually move it to Snowflake.\n\nThank you in advance!", "author_fullname": "t2_iv0k1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Data Modelling, how to design for preorders that change as time progresses? Have you done slowly changing \"facts\" in SQL and how would you do it in this case?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110ipjw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676216815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new to Data Modelling and I&amp;#39;m currently stumped at a personal project. Allow me to give some context first.&lt;/p&gt;\n\n&lt;p&gt;I have been given a preaggregated data set containing preorders at a daily level. Basically everyday I will get a flat file that has the summed up amounts of preorders by day (past, present and future), store, and product category. I don&amp;#39;t have customer or product information. &lt;/p&gt;\n\n&lt;p&gt;For example, in the file from yesterday, I would have preorders slated for 13 May 2023 as 13, comprised of any unknown number of customers ordering any number of unknown products. Then when I get today&amp;#39;s file, I will see that for 13 May 2023, I now have 5 preorders, meaning either some or all the customers from yesterday&amp;#39;s 13 preorders probably cancelled or shifted their preorders to another unknown date. &lt;/p&gt;\n\n&lt;p&gt;To conplicate matters, if for preorder date of 13 May 2023, the amount of preorders went from 13 to 0, I would not get that row with preorder count = 0 in the new file. &lt;/p&gt;\n\n&lt;p&gt;The idea is to have this dataset feed a dashboard so that the end user can track the growth of preorders for any given date and store as time/year progresses.&lt;/p&gt;\n\n&lt;p&gt;I looked into SCD2 but I&amp;#39;m not sure if this is the right approach for the task. Because for one, the preorders are facts and it is the facts that are changing, not dimensions, hence I thought slowly changing facts?&lt;/p&gt;\n\n&lt;p&gt;Another reason I think SCD2 is not right because I was told that I shouldn&amp;#39;t be using the preorder column as a &amp;quot;join condition/key&amp;quot; to check whether or not a record changed (preorder date, store, category as composite keys) from one day&amp;#39;s file to another day&amp;#39;s file. Otherwise I think I would be doing this with some extra steps in addition to a Merge statement. &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m reaching out for help from all you gurus because I&amp;#39;m getting nowhere despite all the Googling. I&amp;#39;m trying to do this in SQL Server but will eventually move it to Snowflake.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110ipjw", "is_robot_indexable": true, "report_reasons": null, "author": "RoyalStraightFlush", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110ipjw/new_to_data_modelling_how_to_design_for_preorders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110ipjw/new_to_data_modelling_how_to_design_for_preorders/", "subreddit_subscribers": 89383, "created_utc": 1676216815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Maybe it is because english is not my native language but I don't know what number to fill in in their [cost calculator](https://cost.airbyte.com/?_gl=1*yeje9n*_gcl_aw*R0NMLjE2NjI1MDQ3MTguQ2owS0NRanczOXVZQmhDTEFSSXNBRF9Tek1RRlJISDB2eTFKZzlLRldwRDI4OUl0SngtRzF0X3dOc2VKa1I5MThiTmtPT1g1OXl5cWxNVWFBaUFtRUFMd193Y0I.&amp;_ga=2.266664462.1256404185.1665036128-558301217.1646090235&amp;_gac=1.184557403.1662504717.Cj0KCQjw39uYBhCLARIsAD_SzMQFRHH0vy1Jg9KFWpD289ItJx-G1t_wNseJkR918bNkOOX59yyqlMUaAiAmEALw_wcB).\n\nIt says:  'Data to replicate from your database sources'. Does that mean the size of the database? Or the size of the new rows i want to (incrementally) sync each month?", "author_fullname": "t2_6bgrg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about the Airbyte cost calculator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110h36c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676212460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe it is because english is not my native language but I don&amp;#39;t know what number to fill in in their &lt;a href=\"https://cost.airbyte.com/?_gl=1*yeje9n*_gcl_aw*R0NMLjE2NjI1MDQ3MTguQ2owS0NRanczOXVZQmhDTEFSSXNBRF9Tek1RRlJISDB2eTFKZzlLRldwRDI4OUl0SngtRzF0X3dOc2VKa1I5MThiTmtPT1g1OXl5cWxNVWFBaUFtRUFMd193Y0I.&amp;amp;_ga=2.266664462.1256404185.1665036128-558301217.1646090235&amp;amp;_gac=1.184557403.1662504717.Cj0KCQjw39uYBhCLARIsAD_SzMQFRHH0vy1Jg9KFWpD289ItJx-G1t_wNseJkR918bNkOOX59yyqlMUaAiAmEALw_wcB\"&gt;cost calculator&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It says:  &amp;#39;Data to replicate from your database sources&amp;#39;. Does that mean the size of the database? Or the size of the new rows i want to (incrementally) sync each month?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110h36c", "is_robot_indexable": true, "report_reasons": null, "author": "karaqz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110h36c/question_about_the_airbyte_cost_calculator/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110h36c/question_about_the_airbyte_cost_calculator/", "subreddit_subscribers": 89383, "created_utc": 1676212460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings everyone.\n\nI work on a company that builds software solutions for governments. At the data sector, we are processing healthcare data for BI and ML applications. \n\nOur current data pipeline looks something like this: Oracle db (data source) -&gt; PostgreSQL db (intermediate db) -&gt; Power BI. This workflow is orchestrated by AirFlow.\n\nThe main issue we are facing is the control of which person can access which database, and the segmentation of said data.\n\nWe would also like to implement a data governance tool. I have been looking into Delta Lake, but it seems this is a tool for data lake house, and not data governance.\n\nI would like advice on which tools should I look into that can fix the issues mentioned. Also, given our current situation, what would be the next step in order to implement a data governance tool?\n\nThanks in advance!!\n\nEdit: forgot to mention, but this tool also needs to be able to work both on premise and in the cloud.", "author_fullname": "t2_1201f0e5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on data governance tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1104d44", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676167484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings everyone.&lt;/p&gt;\n\n&lt;p&gt;I work on a company that builds software solutions for governments. At the data sector, we are processing healthcare data for BI and ML applications. &lt;/p&gt;\n\n&lt;p&gt;Our current data pipeline looks something like this: Oracle db (data source) -&amp;gt; PostgreSQL db (intermediate db) -&amp;gt; Power BI. This workflow is orchestrated by AirFlow.&lt;/p&gt;\n\n&lt;p&gt;The main issue we are facing is the control of which person can access which database, and the segmentation of said data.&lt;/p&gt;\n\n&lt;p&gt;We would also like to implement a data governance tool. I have been looking into Delta Lake, but it seems this is a tool for data lake house, and not data governance.&lt;/p&gt;\n\n&lt;p&gt;I would like advice on which tools should I look into that can fix the issues mentioned. Also, given our current situation, what would be the next step in order to implement a data governance tool?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!!&lt;/p&gt;\n\n&lt;p&gt;Edit: forgot to mention, but this tool also needs to be able to work both on premise and in the cloud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1104d44", "is_robot_indexable": true, "report_reasons": null, "author": "Alvin0p1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1104d44/advice_on_data_governance_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1104d44/advice_on_data_governance_tools/", "subreddit_subscribers": 89383, "created_utc": 1676167484.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}