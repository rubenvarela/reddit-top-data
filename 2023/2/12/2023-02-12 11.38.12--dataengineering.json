{"kind": "Listing", "data": {"after": "t3_10zvyec", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It\u2019s very early and experimental but it was born out of a desire to fix a lot of issues I had with editing dbt models in neovim. \n\n\nSome features: \n\nRun / test open model, the entire project, or arbitrary selectors\n\nAsync jobs with pop-up command outputs\n\nCustom dbt filetype with better syntax highlighting\n\nDisables accidentally modifying sql files in the target folders\n\nJump to any ref or source model using gf (go-to-file)\n\nTelescope Extension to fuzzy-find models\nAutomatically detect dbt project folder", "author_fullname": "t2_vxxrqrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I wrote a dbt plugin for Neovim", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_10zs63w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/RX7_91iWzk_OIsyuN9o4DdsGbtQqQ9nowrQ7XlGGHEc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676134628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It\u2019s very early and experimental but it was born out of a desire to fix a lot of issues I had with editing dbt models in neovim. &lt;/p&gt;\n\n&lt;p&gt;Some features: &lt;/p&gt;\n\n&lt;p&gt;Run / test open model, the entire project, or arbitrary selectors&lt;/p&gt;\n\n&lt;p&gt;Async jobs with pop-up command outputs&lt;/p&gt;\n\n&lt;p&gt;Custom dbt filetype with better syntax highlighting&lt;/p&gt;\n\n&lt;p&gt;Disables accidentally modifying sql files in the target folders&lt;/p&gt;\n\n&lt;p&gt;Jump to any ref or source model using gf (go-to-file)&lt;/p&gt;\n\n&lt;p&gt;Telescope Extension to fuzzy-find models\nAutomatically detect dbt project folder&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/PedramNavid/dbtpal", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?auto=webp&amp;v=enabled&amp;s=7e93dee1c3cb4e70bc180a6906e219a74bd6b786", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d72bac527ebde31306886896a0d3a103e4419791", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4eead8e0ac13949d0d9d2668ac28e2121a3f3647", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccb247e412b4d33305bf1a62173b4b92c75a9b29", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44c778939da1818981aa2ece7d26cd78f12ffb21", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bda6c77e215d210ada652b9bf5d7b0012eeec39", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/AykCyi1oKCJWocsASUXE3CLaPGAed2n_pDTs6Z29iwU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c10d1705e0ea245e67b18f363eee781c019f582", "width": 1080, "height": 540}], "variants": {}, "id": "ajKwdyq3fMifnpDuCfjA1XC5MeSHNnZZqDOyqomfbJM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "10zs63w", "is_robot_indexable": true, "report_reasons": null, "author": "MrMosBiggestFan", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zs63w/i_wrote_a_dbt_plugin_for_neovim/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/PedramNavid/dbtpal", "subreddit_subscribers": 89301, "created_utc": 1676134628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am learning lots in terms of general data engineering at my current role but was wondering about the benefits of learning Data Structures and Algorithms on the side to further boost my skills. I have a few questions about this and would be grateful for any answers from those with experience and knowledge.\n\n1) Will bring better at DS&amp;A make me a better data engineer? I feel as though a lot of the skills aren't used directly in DE but please correct me if I'm wrong.\n\n2) How comprehensively would you need to know DS&amp;A for a DE coding exam when applying to new roles? I'd imagine it to be not as intense as a SWE role for example.\n\n3) What is a realistic timeframe to be able to start passing coding exams if I'm allocating around 5 hours a week to learning this?\n\n4) What are some good resources for learning this and is there anything that is a bit more tailored to DE DS&amp;A tests?\n\nThank you in advance for any responses.", "author_fullname": "t2_87ogeeb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Structures and Algorithms as a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11055pg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676169978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning lots in terms of general data engineering at my current role but was wondering about the benefits of learning Data Structures and Algorithms on the side to further boost my skills. I have a few questions about this and would be grateful for any answers from those with experience and knowledge.&lt;/p&gt;\n\n&lt;p&gt;1) Will bring better at DS&amp;amp;A make me a better data engineer? I feel as though a lot of the skills aren&amp;#39;t used directly in DE but please correct me if I&amp;#39;m wrong.&lt;/p&gt;\n\n&lt;p&gt;2) How comprehensively would you need to know DS&amp;amp;A for a DE coding exam when applying to new roles? I&amp;#39;d imagine it to be not as intense as a SWE role for example.&lt;/p&gt;\n\n&lt;p&gt;3) What is a realistic timeframe to be able to start passing coding exams if I&amp;#39;m allocating around 5 hours a week to learning this?&lt;/p&gt;\n\n&lt;p&gt;4) What are some good resources for learning this and is there anything that is a bit more tailored to DE DS&amp;amp;A tests?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for any responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11055pg", "is_robot_indexable": true, "report_reasons": null, "author": "SendMeYourThoughts", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11055pg/data_structures_and_algorithms_as_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11055pg/data_structures_and_algorithms_as_a_data_engineer/", "subreddit_subscribers": 89301, "created_utc": 1676169978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nThe intention of this post is to stimulate discussion on the merits of various approaches to the ingestion of data into a cloud warehouse/lakehouse.\n\nHow do you go about it, and what are your reasons for doing so?\n\nQuestions to get us started:\n- do you land your data in an object store (s3, blob) before loading in to your warehouse? All the time, or just in certain circumstances? What about if you\u2019re ingesting from a SQL source?\n- do you have a preference for off the shelf solutions such as FiveTran/Matillion/ADF, or would you pref to build a framework yourself? Have you built a framework, and if so what language did you use &amp; how robust is it?\n- if you were to start from scratch, greenfield, what would it look like?\n\nAnd I\u2019ll begin by answering my own questions:\n- many of our sources sync directly into Snowflake, including Kafka, Segment and FiveTran. Where we have built a custom pipeline we land the data in S3 as a first hop.\n- my preference as a developer is to build. We have an oop python framework we have developed which is working well. But it\u2019s only used where an off the shelf solutions doesn\u2019t meet our needs. From a build vs buy strategy, we buy the ingestion and build the business transformation. It\u2019s the business logic that holds more value. We use dbt for transform.\n- if I were to go again, it would be a Hudi lakehouse, with a custom pipeline framework. It allows us to remain separated from specific vendor solutions which may lead to lock-in/cost hikes. I\u2019d likely retain dbt-cli, and as much as possible take a mesh/domain separation to the data (noting than business domain and business systems are different things).\n\nI\u2019d also want to do a far better job of making the data \u2018findable\u2019, but that\u2019s not strictly related to the title. We publish dbt docs right now, but have a number of dbt projects, and the information on the sources isn\u2019t contained in here. Planning to investigate OpenMetadata when we have capacity.\n\nKeen on others thoughts.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ingesting Data - workflow best practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1102xw5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676164104.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676163226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;The intention of this post is to stimulate discussion on the merits of various approaches to the ingestion of data into a cloud warehouse/lakehouse.&lt;/p&gt;\n\n&lt;p&gt;How do you go about it, and what are your reasons for doing so?&lt;/p&gt;\n\n&lt;p&gt;Questions to get us started:\n- do you land your data in an object store (s3, blob) before loading in to your warehouse? All the time, or just in certain circumstances? What about if you\u2019re ingesting from a SQL source?\n- do you have a preference for off the shelf solutions such as FiveTran/Matillion/ADF, or would you pref to build a framework yourself? Have you built a framework, and if so what language did you use &amp;amp; how robust is it?\n- if you were to start from scratch, greenfield, what would it look like?&lt;/p&gt;\n\n&lt;p&gt;And I\u2019ll begin by answering my own questions:\n- many of our sources sync directly into Snowflake, including Kafka, Segment and FiveTran. Where we have built a custom pipeline we land the data in S3 as a first hop.\n- my preference as a developer is to build. We have an oop python framework we have developed which is working well. But it\u2019s only used where an off the shelf solutions doesn\u2019t meet our needs. From a build vs buy strategy, we buy the ingestion and build the business transformation. It\u2019s the business logic that holds more value. We use dbt for transform.\n- if I were to go again, it would be a Hudi lakehouse, with a custom pipeline framework. It allows us to remain separated from specific vendor solutions which may lead to lock-in/cost hikes. I\u2019d likely retain dbt-cli, and as much as possible take a mesh/domain separation to the data (noting than business domain and business systems are different things).&lt;/p&gt;\n\n&lt;p&gt;I\u2019d also want to do a far better job of making the data \u2018findable\u2019, but that\u2019s not strictly related to the title. We publish dbt docs right now, but have a number of dbt projects, and the information on the sources isn\u2019t contained in here. Planning to investigate OpenMetadata when we have capacity.&lt;/p&gt;\n\n&lt;p&gt;Keen on others thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1102xw5", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1102xw5/ingesting_data_workflow_best_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1102xw5/ingesting_data_workflow_best_practice/", "subreddit_subscribers": 89301, "created_utc": 1676163226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If so: What is it?", "author_fullname": "t2_6fdt02qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have a side business?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ztssr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676138829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If so: What is it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10ztssr", "is_robot_indexable": true, "report_reasons": null, "author": "Insighteous", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ztssr/do_you_have_a_side_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ztssr/do_you_have_a_side_business/", "subreddit_subscribers": 89301, "created_utc": 1676138829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say you have a medallion architecture lakehouse/warehouse. There are facts and dimensions in your gold layer used for analytics.\n\nYou have a request to pull data from one source, provide some cleaning and logic to it and then send it to another system via their API. At this stage, there is no requirement from analysts to see this data in a fact/dim.\n\nDo you build a completely standalone pipeline to cater to the need?\n\nDo you ingest into bronze, bring through to silver to align with all other data in a consistent manner, potentially building that into larger source agnostic tables, and then send it out from there?\n\nDo you do something different?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a minimum level you take your data through a warehouse before showing it to users?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110403g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676166370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you have a medallion architecture lakehouse/warehouse. There are facts and dimensions in your gold layer used for analytics.&lt;/p&gt;\n\n&lt;p&gt;You have a request to pull data from one source, provide some cleaning and logic to it and then send it to another system via their API. At this stage, there is no requirement from analysts to see this data in a fact/dim.&lt;/p&gt;\n\n&lt;p&gt;Do you build a completely standalone pipeline to cater to the need?&lt;/p&gt;\n\n&lt;p&gt;Do you ingest into bronze, bring through to silver to align with all other data in a consistent manner, potentially building that into larger source agnostic tables, and then send it out from there?&lt;/p&gt;\n\n&lt;p&gt;Do you do something different?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110403g", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110403g/is_there_a_minimum_level_you_take_your_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110403g/is_there_a_minimum_level_you_take_your_data/", "subreddit_subscribers": 89301, "created_utc": 1676166370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I joined a company as the only data engineer, my first task is to make an overall presentation of the best practices to use the Azure data engineering stack to make a data warehouse for our business analysts. I was curious what people in other organizations are using?\n\nOur data sources include some legacy applications, APIs, SaaS applications etc. I was thinking of using synapse pipelines or data factory to extract all the data in a data lake, then use either Azure functions or SQL scripts in synapse to do any transformations and push it to a dedicated sql pool, and use it as the delivery platform for our BI analysts.\n\nAlthough I really want to use databricks since coding my solutions makes more sense to me, but from a pricing and 'low-code' standpoint from my management, I am stuck to keeping my solutions low code as possible and only use when it's necessary.\n\nAny advices on best practices to how others are using Azure are welcome.", "author_fullname": "t2_l35gwhuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practices For Data Engineering on Azure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zqt7n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676131236.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I joined a company as the only data engineer, my first task is to make an overall presentation of the best practices to use the Azure data engineering stack to make a data warehouse for our business analysts. I was curious what people in other organizations are using?&lt;/p&gt;\n\n&lt;p&gt;Our data sources include some legacy applications, APIs, SaaS applications etc. I was thinking of using synapse pipelines or data factory to extract all the data in a data lake, then use either Azure functions or SQL scripts in synapse to do any transformations and push it to a dedicated sql pool, and use it as the delivery platform for our BI analysts.&lt;/p&gt;\n\n&lt;p&gt;Although I really want to use databricks since coding my solutions makes more sense to me, but from a pricing and &amp;#39;low-code&amp;#39; standpoint from my management, I am stuck to keeping my solutions low code as possible and only use when it&amp;#39;s necessary.&lt;/p&gt;\n\n&lt;p&gt;Any advices on best practices to how others are using Azure are welcome.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10zqt7n", "is_robot_indexable": true, "report_reasons": null, "author": "Senior_Anteater4688", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zqt7n/best_practices_for_data_engineering_on_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zqt7n/best_practices_for_data_engineering_on_azure/", "subreddit_subscribers": 89301, "created_utc": 1676131236.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm clearly searching wrong because I cant find the answer even in their documentation. I assume the limit depends on the size of the cluster, but I'm struggling to find the number...", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many concurrent queries does Databricks SQL Compute warehouses support? I need this to decide the minimum number of clusters that need to be active to meet a set concurrency level and SLA. in order to Cant find anyway to set this in the cluster config.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zq7t2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676130045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m clearly searching wrong because I cant find the answer even in their documentation. I assume the limit depends on the size of the cluster, but I&amp;#39;m struggling to find the number...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10zq7t2", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zq7t2/how_many_concurrent_queries_does_databricks_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zq7t2/how_many_concurrent_queries_does_databricks_sql/", "subreddit_subscribers": 89301, "created_utc": 1676130045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently I\u2019m a data analyst that specifically works with my company\u2019s inventory. And I\u2019m stalling, I only use excel/power query, all the data I use comes from our CRM or our partners, and is put into excel. It sucks to work with, if I scroll to fast on some sheets they\u2019ll crash because there\u2019s too many rows. \n\nAnyway, working this job I realized I enjoy automating work sheets, and the overall work process more than the analyzation. So I\u2019d like to move into data engineering and want to gear my personal portfolio towards that. I thinking of doing a project where I just make a simple pipeline. I want to use Python and Spotify\u2019s API to extract and transform the data, and load it into a Power BI dashboard. However, I\u2019m not a data engineer, and honestly I\u2019m a pretty low level analyst with an out of date skill set, and I\u2019m not sure if this project is something worthwhile. \n\nIt seems like data engineering is a very wide field in terms of tools used, and I\u2019m not sure if the tools above are what\u2019s desired by employers or atleast shows desirable skills, so any feedback would be greatly appreciated, thanks!", "author_fullname": "t2_49nguj2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to start a data engineering project but not sure if I have the right idea", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11010wf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676157837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I\u2019m a data analyst that specifically works with my company\u2019s inventory. And I\u2019m stalling, I only use excel/power query, all the data I use comes from our CRM or our partners, and is put into excel. It sucks to work with, if I scroll to fast on some sheets they\u2019ll crash because there\u2019s too many rows. &lt;/p&gt;\n\n&lt;p&gt;Anyway, working this job I realized I enjoy automating work sheets, and the overall work process more than the analyzation. So I\u2019d like to move into data engineering and want to gear my personal portfolio towards that. I thinking of doing a project where I just make a simple pipeline. I want to use Python and Spotify\u2019s API to extract and transform the data, and load it into a Power BI dashboard. However, I\u2019m not a data engineer, and honestly I\u2019m a pretty low level analyst with an out of date skill set, and I\u2019m not sure if this project is something worthwhile. &lt;/p&gt;\n\n&lt;p&gt;It seems like data engineering is a very wide field in terms of tools used, and I\u2019m not sure if the tools above are what\u2019s desired by employers or atleast shows desirable skills, so any feedback would be greatly appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11010wf", "is_robot_indexable": true, "report_reasons": null, "author": "Hillsand0", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11010wf/i_want_to_start_a_data_engineering_project_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11010wf/i_want_to_start_a_data_engineering_project_but/", "subreddit_subscribers": 89301, "created_utc": 1676157837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cqao8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fixing iMessage search with DuckDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_10zya3n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UTDqxp8lwTt7YNzKZRrJ34PKpig1gaF2Vc5DoaB5fhA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676150440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "arecadata.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.arecadata.com/analyzing-imessage-data-with-duckdb/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?auto=webp&amp;v=enabled&amp;s=6e8766df6a1f23a768be56b5c70524dea5767092", "width": 2000, "height": 1333}, "resolutions": [{"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f30f04385659e52ff23a1a6c831437c7c4f4aa1", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=92ba4aba8c0d7007e9b8c5e4095093e12f1e0d8d", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9c20078b7b68a8d02eae7390db79f4b37aa4bc1", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f9c6a3413d4569149a29505c748629631b59e9e", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3edc94694e982b0d785026c791e785f5662d59b9", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/QYjXeW44_v_G-i3tyLTYFj1k6pqQtsZG00MIagsucPo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b4ec75131e0c602b635dc4548b717729e9a99dc", "width": 1080, "height": 719}], "variants": {}, "id": "rak11NSlLzYqT7yjd33V5YkXdlq37ptPu7yolvA6Gt8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10zya3n", "is_robot_indexable": true, "report_reasons": null, "author": "dan_the_lion", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zya3n/fixing_imessage_search_with_duckdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.arecadata.com/analyzing-imessage-data-with-duckdb/", "subreddit_subscribers": 89301, "created_utc": 1676150440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to create Databricks cluster, jobs in my workspace \n\nApart from Terraform(due to client policies), please suggest steps to create databricks cluster, job etc in azure devops cicd process", "author_fullname": "t2_6iqir5tk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks \u00d7 Azure Devops", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zokyk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676124842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to create Databricks cluster, jobs in my workspace &lt;/p&gt;\n\n&lt;p&gt;Apart from Terraform(due to client policies), please suggest steps to create databricks cluster, job etc in azure devops cicd process&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10zokyk", "is_robot_indexable": true, "report_reasons": null, "author": "pinky_07", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zokyk/databricks_azure_devops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zokyk/databricks_azure_devops/", "subreddit_subscribers": 89301, "created_utc": 1676124842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it still an open and fully interoperable building block? Or can tables in Unity Catalog can only be queried by Databricks' engine?", "author_fullname": "t2_7spandv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If I use Databricks Unity Catalog, can i still use open source Spark or Presto / Trino (or any other SQL engine for that matter) to query tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1108cug", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676180881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it still an open and fully interoperable building block? Or can tables in Unity Catalog can only be queried by Databricks&amp;#39; engine?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1108cug", "is_robot_indexable": true, "report_reasons": null, "author": "brrdprrsn", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1108cug/if_i_use_databricks_unity_catalog_can_i_still_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1108cug/if_i_use_databricks_unity_catalog_can_i_still_use/", "subreddit_subscribers": 89301, "created_utc": 1676180881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Excluding airbnb (major resorts, hotels, etc.)\n\nAt the moment, it seems the industry either builds everything in house or use 3rd party systems for each task (communication, profiling, check-in management, data storage/retrieval, etc.)", "author_fullname": "t2_rt5kovjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data engineers here with experience in building a data platform for the hospitality and travel industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110471e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676166967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Excluding airbnb (major resorts, hotels, etc.)&lt;/p&gt;\n\n&lt;p&gt;At the moment, it seems the industry either builds everything in house or use 3rd party systems for each task (communication, profiling, check-in management, data storage/retrieval, etc.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110471e", "is_robot_indexable": true, "report_reasons": null, "author": "slp_001100", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110471e/any_data_engineers_here_with_experience_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110471e/any_data_engineers_here_with_experience_in/", "subreddit_subscribers": 89301, "created_utc": 1676166967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Company uses Domo as our data warehouse and BI solution. I run into problems once a month where incorrect manually entered data in systems gets into an important table and I have no way of fixing it unless I reload the data and replace all data in the table. Is anyone else working with Domo and how do you handle cleaning up incorrect inputs?", "author_fullname": "t2_3eirbc33", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone use Domo?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1100m81", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676156686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Company uses Domo as our data warehouse and BI solution. I run into problems once a month where incorrect manually entered data in systems gets into an important table and I have no way of fixing it unless I reload the data and replace all data in the table. Is anyone else working with Domo and how do you handle cleaning up incorrect inputs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1100m81", "is_robot_indexable": true, "report_reasons": null, "author": "pbxmy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1100m81/does_anyone_use_domo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1100m81/does_anyone_use_domo/", "subreddit_subscribers": 89301, "created_utc": 1676156686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been using Xplenty to extract data from GBQ and to load into a MySQL DB instance. I think Xplenty uses a framework of Apache to transfer data (I have read the error logs, and it seems like it is an Apache framework). \n\nNow, let\u2019s say if I have to load data (2k rows) using a Python script that is run on my machine. It takes less than a few seconds to extract and load. But, if I do is from Xplenty, it takes minutes to load. \n\nWhat is the reason for ETL tools to be slow when transferring data? I have heard that frameworks like Apache Spark, they are really fast. But why isn\u2019t the speed reflected when I use an ETL tool that is supposed to be running an Apache framework? \n\nI have always thought about this but didn\u2019t find anything helpful for me.", "author_fullname": "t2_emzh9atv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why ETL tools take a lot of time to transfer data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zs7xo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676134759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been using Xplenty to extract data from GBQ and to load into a MySQL DB instance. I think Xplenty uses a framework of Apache to transfer data (I have read the error logs, and it seems like it is an Apache framework). &lt;/p&gt;\n\n&lt;p&gt;Now, let\u2019s say if I have to load data (2k rows) using a Python script that is run on my machine. It takes less than a few seconds to extract and load. But, if I do is from Xplenty, it takes minutes to load. &lt;/p&gt;\n\n&lt;p&gt;What is the reason for ETL tools to be slow when transferring data? I have heard that frameworks like Apache Spark, they are really fast. But why isn\u2019t the speed reflected when I use an ETL tool that is supposed to be running an Apache framework? &lt;/p&gt;\n\n&lt;p&gt;I have always thought about this but didn\u2019t find anything helpful for me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10zs7xo", "is_robot_indexable": true, "report_reasons": null, "author": "MaintenanceSad6825", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zs7xo/why_etl_tools_take_a_lot_of_time_to_transfer_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zs7xo/why_etl_tools_take_a_lot_of_time_to_transfer_data/", "subreddit_subscribers": 89301, "created_utc": 1676134759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been reading through O'Reilly's *Data Pipelines Pocket Reference* which has done a really great job of breaking apart the steps of an ELT pipeline into real-world use cases. I like how the extraction step is simplified to reading from a source and writing a CSV to S3; and the examples for ingesting from DBs or APIs make sense.\n\nMy questions are pretty simple, but when I think about how to apply the same logic to sourcing from a filesystem (or S3 path) I have a few more questions...\n\n1. Unlike a DB, files don't have primary keys, but often, the file's parent directory path can be used to uniquely identify the file, would I be right to include the path and any other data to the output CSV in my Extract step? Would this be considered EtLT?\n2. Expanding on the first question, In cases where the directory path is important for uniquely identifying a file, what do I do when I have two or more different file types that I'm interested in under the same parent directory? Should I Extract each separately to it's own CSV? Should I create a single CSV for all the files under that parent directory, joining files together? Something else?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should I be Extracting data files from a filesystem/S3 like I do for DBs &amp; APIs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1103z7u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676166303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been reading through O&amp;#39;Reilly&amp;#39;s &lt;em&gt;Data Pipelines Pocket Reference&lt;/em&gt; which has done a really great job of breaking apart the steps of an ELT pipeline into real-world use cases. I like how the extraction step is simplified to reading from a source and writing a CSV to S3; and the examples for ingesting from DBs or APIs make sense.&lt;/p&gt;\n\n&lt;p&gt;My questions are pretty simple, but when I think about how to apply the same logic to sourcing from a filesystem (or S3 path) I have a few more questions...&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Unlike a DB, files don&amp;#39;t have primary keys, but often, the file&amp;#39;s parent directory path can be used to uniquely identify the file, would I be right to include the path and any other data to the output CSV in my Extract step? Would this be considered EtLT?&lt;/li&gt;\n&lt;li&gt;Expanding on the first question, In cases where the directory path is important for uniquely identifying a file, what do I do when I have two or more different file types that I&amp;#39;m interested in under the same parent directory? Should I Extract each separately to it&amp;#39;s own CSV? Should I create a single CSV for all the files under that parent directory, joining files together? Something else?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1103z7u", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1103z7u/how_should_i_be_extracting_data_files_from_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1103z7u/how_should_i_be_extracting_data_files_from_a/", "subreddit_subscribers": 89301, "created_utc": 1676166303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nI have been in data engineering for a long time but pretty much purely in the batch processing / analytics warehouse creation and management space. Airflow, modeling, reporting, SQL etc. The places that I've worked largely haven't had a dire need for stream processing relative to other needs, but I'm trying to move myself and my team members more in that direction. \n\nGiven I don't have a ton of accessible stream-data to experiment with at work, are there good resources available publicly to consume and develop data stream processes? I'm particularly interested in Kinesis because of the AWS infrastructure I deal with at work. \n\nThanks for any help!", "author_fullname": "t2_wxoh8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need to buff up my data streaming skills. Any good resources for toy/demo projects utilizing Kinesis specifically? Sources for free streaming data to work on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zujtf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676140733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I have been in data engineering for a long time but pretty much purely in the batch processing / analytics warehouse creation and management space. Airflow, modeling, reporting, SQL etc. The places that I&amp;#39;ve worked largely haven&amp;#39;t had a dire need for stream processing relative to other needs, but I&amp;#39;m trying to move myself and my team members more in that direction. &lt;/p&gt;\n\n&lt;p&gt;Given I don&amp;#39;t have a ton of accessible stream-data to experiment with at work, are there good resources available publicly to consume and develop data stream processes? I&amp;#39;m particularly interested in Kinesis because of the AWS infrastructure I deal with at work. &lt;/p&gt;\n\n&lt;p&gt;Thanks for any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10zujtf", "is_robot_indexable": true, "report_reasons": null, "author": "tylerjaywood", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zujtf/i_need_to_buff_up_my_data_streaming_skills_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zujtf/i_need_to_buff_up_my_data_streaming_skills_any/", "subreddit_subscribers": 89301, "created_utc": 1676140733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am currently starting to use AWS for a project. However I am unsure how to treat access to services. F.e I have Airflow deployed on an ec2 instance and it runs a Python script which pushes data in S3 etc. To load the files in S3 I need Access Keys, for which I have created a new user. I have stored them in Secrets Manager. To access the keys in secrets Manager from my script, I again need Access Keys (aka a new user). F.e for using various other aws operators in airflow, one also has to attach access keys.\n\nI now have created new users for the services which have the minimal needed policy attached. But it seems a bit wrong to use users for that.  Having one user with enough access rights to run everything seems to be wrong too. And I am roles don't provide me keys which I can use. \n\nWhat is best practice to solve this?", "author_fullname": "t2_v219tksh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle access to different aws services with access keys?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zpsp2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676129440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am currently starting to use AWS for a project. However I am unsure how to treat access to services. F.e I have Airflow deployed on an ec2 instance and it runs a Python script which pushes data in S3 etc. To load the files in S3 I need Access Keys, for which I have created a new user. I have stored them in Secrets Manager. To access the keys in secrets Manager from my script, I again need Access Keys (aka a new user). F.e for using various other aws operators in airflow, one also has to attach access keys.&lt;/p&gt;\n\n&lt;p&gt;I now have created new users for the services which have the minimal needed policy attached. But it seems a bit wrong to use users for that.  Having one user with enough access rights to run everything seems to be wrong too. And I am roles don&amp;#39;t provide me keys which I can use. &lt;/p&gt;\n\n&lt;p&gt;What is best practice to solve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10zpsp2", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Hand-577", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zpsp2/how_to_handle_access_to_different_aws_services/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zpsp2/how_to_handle_access_to_different_aws_services/", "subreddit_subscribers": 89301, "created_utc": 1676129440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Starting out in Data Engineering: Seeking guidance and resources\n\nHello everyone,\n\nI am interested in a data engineering role. I was hoping if any experienced data engineers could help me with some guidance on what I should focus on first.\n\nI have a good understanding of Python and SQL, but I am not sure where to start with data engineering specifically. I would appreciate any advice or resources you can provide.\n\nThank you in advance for your help!", "author_fullname": "t2_m6lk62t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting out in Data Engineering: Seeking guidance and resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_110cath", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676196325.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Starting out in Data Engineering: Seeking guidance and resources&lt;/p&gt;\n\n&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am interested in a data engineering role. I was hoping if any experienced data engineers could help me with some guidance on what I should focus on first.&lt;/p&gt;\n\n&lt;p&gt;I have a good understanding of Python and SQL, but I am not sure where to start with data engineering specifically. I would appreciate any advice or resources you can provide.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110cath", "is_robot_indexable": true, "report_reasons": null, "author": "TelevisionDue5491", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110cath/starting_out_in_data_engineering_seeking_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110cath/starting_out_in_data_engineering_seeking_guidance/", "subreddit_subscribers": 89301, "created_utc": 1676196325.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Using the same data and set of transformations and excluding all other factors, which would be cheaper: A transformation in spark or transformation in a datawarehouse?", "author_fullname": "t2_6jogidac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transform in spark or in datawarehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_110c0u4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676195268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Using the same data and set of transformations and excluding all other factors, which would be cheaper: A transformation in spark or transformation in a datawarehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "110c0u4", "is_robot_indexable": true, "report_reasons": null, "author": "_barnuts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110c0u4/transform_in_spark_or_in_datawarehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110c0u4/transform_in_spark_or_in_datawarehouse/", "subreddit_subscribers": 89301, "created_utc": 1676195268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I work as DWH developer for 4 years, I work with Oracle Database, use Oracle Data Integrator and PL/SQL for ETL. My strongest skills are SQL, relational databates, PL/SQL, data modelling (dimensional data model, star schemas, scd...generally everything from kimball's datawarehouse toolkit). \nI've just got offered job as Data Engineer. I'd love to learn how to make DWH and ETL in modern way but I am also scared, to be honest. I have no experience with cloud, I have only basic knowledge of Python. I've never worked with Docker and I know only basics of Linux and git. Should I take that job or should I study cloud, Python etc and then apply for the similar position?", "author_fullname": "t2_kh4jiqla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DWH developer transformation to Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_110bvt7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676194728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I work as DWH developer for 4 years, I work with Oracle Database, use Oracle Data Integrator and PL/SQL for ETL. My strongest skills are SQL, relational databates, PL/SQL, data modelling (dimensional data model, star schemas, scd...generally everything from kimball&amp;#39;s datawarehouse toolkit). \nI&amp;#39;ve just got offered job as Data Engineer. I&amp;#39;d love to learn how to make DWH and ETL in modern way but I am also scared, to be honest. I have no experience with cloud, I have only basic knowledge of Python. I&amp;#39;ve never worked with Docker and I know only basics of Linux and git. Should I take that job or should I study cloud, Python etc and then apply for the similar position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "110bvt7", "is_robot_indexable": true, "report_reasons": null, "author": "No_Pause7942", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/110bvt7/dwh_developer_transformation_to_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/110bvt7/dwh_developer_transformation_to_data_engineer/", "subreddit_subscribers": 89301, "created_utc": 1676194728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings everyone.\n\nI work on a company that builds software solutions for governments. At the data sector, we are processing healthcare data for BI and ML applications. \n\nOur current data pipeline looks something like this: Oracle db (data source) -&gt; PostgreSQL db (intermediate db) -&gt; Power BI. This workflow is orchestrated by AirFlow.\n\nThe main issue we are facing is the control of which person can access which database, and the segmentation of said data.\n\nWe would also like to implement a data governance tool. I have been looking into Delta Lake, but it seems this is a tool for data lake house, and not data governance.\n\nI would like advice on which tools should I look into that can fix the issues mentioned. Also, given our current situation, what would be the next step in order to implement a data governance tool?\n\nThanks in advance!!\n\nEdit: forgot to mention, but this tool also needs to be able to work both on premise and in the cloud.", "author_fullname": "t2_1201f0e5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on data governance tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1104d44", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676167484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings everyone.&lt;/p&gt;\n\n&lt;p&gt;I work on a company that builds software solutions for governments. At the data sector, we are processing healthcare data for BI and ML applications. &lt;/p&gt;\n\n&lt;p&gt;Our current data pipeline looks something like this: Oracle db (data source) -&amp;gt; PostgreSQL db (intermediate db) -&amp;gt; Power BI. This workflow is orchestrated by AirFlow.&lt;/p&gt;\n\n&lt;p&gt;The main issue we are facing is the control of which person can access which database, and the segmentation of said data.&lt;/p&gt;\n\n&lt;p&gt;We would also like to implement a data governance tool. I have been looking into Delta Lake, but it seems this is a tool for data lake house, and not data governance.&lt;/p&gt;\n\n&lt;p&gt;I would like advice on which tools should I look into that can fix the issues mentioned. Also, given our current situation, what would be the next step in order to implement a data governance tool?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!!&lt;/p&gt;\n\n&lt;p&gt;Edit: forgot to mention, but this tool also needs to be able to work both on premise and in the cloud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1104d44", "is_robot_indexable": true, "report_reasons": null, "author": "Alvin0p1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1104d44/advice_on_data_governance_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1104d44/advice_on_data_governance_tools/", "subreddit_subscribers": 89301, "created_utc": 1676167484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bsrs5rj9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ER Model Explained \u2014 DBMS Concepts | Coding Chronicles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "name": "t3_10zw7pw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/F9wR7J8Pb20T_iAGhGrFG83z9WRJGd5AjD4iJX8vAw4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676145031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "codingchronicles.adityakarad.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://codingchronicles.adityakarad.com/er-model-explained-dbms-concepts", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?auto=webp&amp;v=enabled&amp;s=9925d24699375e00b236b6a1509c27134fad055d", "width": 1200, "height": 668}, "resolutions": [{"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0b4b6e152e06179dc46ad1eb612d90271cbb13c", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8132656f5a770400eb93b2ef76ae7a4430931b11", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e96a5e3eff5a65fb8ef92922025eb36a1ec6c64f", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0958febe467583276fd4d2699712693fbeff38a5", "width": 640, "height": 356}, {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9afe5f3a9e026078762c5405c9b2f425acfe8fc2", "width": 960, "height": 534}, {"url": "https://external-preview.redd.it/oSbt12VvsPV7cmw5UvIs8HXoj2mqhHCl_ic3VQQ0bSc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c120cfb3c8f520b27431bf0d46f4d65341439316", "width": 1080, "height": 601}], "variants": {}, "id": "GcVhT5tkWyK3YaxXoPtCN0yMcF-XtPeKefuMWoUnxUI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10zw7pw", "is_robot_indexable": true, "report_reasons": null, "author": "indian_dev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zw7pw/er_model_explained_dbms_concepts_coding_chronicles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://codingchronicles.adityakarad.com/er-model-explained-dbms-concepts", "subreddit_subscribers": 89301, "created_utc": 1676145031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\nI am trying to find an efficient and collaborative way to insert relational data records into an RDBMS. \n\nIt will have to do foreign key lookups to help data population by suggesting the foreign key lookup. \n\nI can build a custom html web app to do this but couldn\u2019t find and framework/tool that does this. \n\nThank you.", "author_fullname": "t2_vnxs1lvy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RDBMS data entry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zqtg3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676131251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\nI am trying to find an efficient and collaborative way to insert relational data records into an RDBMS. &lt;/p&gt;\n\n&lt;p&gt;It will have to do foreign key lookups to help data population by suggesting the foreign key lookup. &lt;/p&gt;\n\n&lt;p&gt;I can build a custom html web app to do this but couldn\u2019t find and framework/tool that does this. &lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10zqtg3", "is_robot_indexable": true, "report_reasons": null, "author": "sumosumo234", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zqtg3/rdbms_data_entry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zqtg3/rdbms_data_entry/", "subreddit_subscribers": 89301, "created_utc": 1676131251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am currently starting to use AWS for a project. However I am unsure how to treat access to services. F.e I have Airflow deployed on an ec2 instance and it runs a Python script which pushes data in S3 etc. To load the files in S3 I need Access Keys, for which I have created a new user. I have stored them in Secrets Manager. To access the keys in secrets Manager from my script, I again need Access Keys (aka a new user). F.e for using various other aws operators in airflow, one also has to attach access keys.\n\nI now have created new users for the services which have the minimal needed policy attached. But it seems a bit wrong to use users for that.  Having one user with enough access rights to run everything seems to be wrong too. And I am roles don't provide me keys which I can use. \n\nWhat is best practice to solve this?", "author_fullname": "t2_v219tksh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle access to different aws services with access keys?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zpf3i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676128021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am currently starting to use AWS for a project. However I am unsure how to treat access to services. F.e I have Airflow deployed on an ec2 instance and it runs a Python script which pushes data in S3 etc. To load the files in S3 I need Access Keys, for which I have created a new user. I have stored them in Secrets Manager. To access the keys in secrets Manager from my script, I again need Access Keys (aka a new user). F.e for using various other aws operators in airflow, one also has to attach access keys.&lt;/p&gt;\n\n&lt;p&gt;I now have created new users for the services which have the minimal needed policy attached. But it seems a bit wrong to use users for that.  Having one user with enough access rights to run everything seems to be wrong too. And I am roles don&amp;#39;t provide me keys which I can use. &lt;/p&gt;\n\n&lt;p&gt;What is best practice to solve this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10zpf3i", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive-Hand-577", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zpf3i/how_to_handle_access_to_different_aws_services/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zpf3i/how_to_handle_access_to_different_aws_services/", "subreddit_subscribers": 89301, "created_utc": 1676128021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sorry if this is not the place to ask.\n\nLooking to major in DE but I have been seeing lots of posts and videos talking about how data engineering won't be useful or needed in the future,is this true?\n\n\nIn addition how did you know that DE was the thing for you?", "author_fullname": "t2_tzb9l6f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "will data engineering still be needed in 10+ years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10zvyec", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.41, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676144353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this is not the place to ask.&lt;/p&gt;\n\n&lt;p&gt;Looking to major in DE but I have been seeing lots of posts and videos talking about how data engineering won&amp;#39;t be useful or needed in the future,is this true?&lt;/p&gt;\n\n&lt;p&gt;In addition how did you know that DE was the thing for you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10zvyec", "is_robot_indexable": true, "report_reasons": null, "author": "khtoto", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10zvyec/will_data_engineering_still_be_needed_in_10_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10zvyec/will_data_engineering_still_be_needed_in_10_years/", "subreddit_subscribers": 89301, "created_utc": 1676144353.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}