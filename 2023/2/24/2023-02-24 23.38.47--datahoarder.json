{"kind": "Listing", "data": {"after": "t3_11afilz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5ruh5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My 72TB Unraid NAS build", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11adt8k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 1064, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 1064, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ENFh7AV9lq0_bm_ouA_cnv2nmRu0gAiKJM0HbhFVMlA.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677199214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.imgur.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.imgur.com/XGuHPOg.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eutOglK3SU76o6D8XF8Ss5CHODVwLhhD7nHqeY7LURI.jpg?auto=webp&amp;v=enabled&amp;s=2178ea0f3de76592c78efde7fbf0e45d04dfdfbe", "width": 4032, "height": 3024}, "resolutions": [{"url": "https://external-preview.redd.it/eutOglK3SU76o6D8XF8Ss5CHODVwLhhD7nHqeY7LURI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e86dad73896c02126236d87fce536d80d4b1de32", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/eutOglK3SU76o6D8XF8Ss5CHODVwLhhD7nHqeY7LURI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d90b110c3785c608a14fd7e2a58146c3d85cc03d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/eutOglK3SU76o6D8XF8Ss5CHODVwLhhD7nHqeY7LURI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=960e7797f4805be34b1f8275e9c9a036e2201bab", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/eutOglK3SU76o6D8XF8Ss5CHODVwLhhD7nHqeY7LURI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c65ba318c93ac387fec83ec5850f73e179ca14a", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/eutOglK3SU76o6D8XF8Ss5CHODVwLhhD7nHqeY7LURI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be54d12348a94e10ecfe5df68b90b09fb2c6f3ca", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/eutOglK3SU76o6D8XF8Ss5CHODVwLhhD7nHqeY7LURI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3ffd98680631615802bb5cf6da1d68c188babc6a", "width": 1080, "height": 810}], "variants": {}, "id": "kx02vcX0ErtW6Lm2yz7spacWvkSS2K7f5BXcrcysUTk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "~93 TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11adt8k", "is_robot_indexable": true, "report_reasons": null, "author": "dmn002", "discussion_type": null, "num_comments": 122, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11adt8k/my_72tb_unraid_nas_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.imgur.com/XGuHPOg.jpg", "subreddit_subscribers": 671148, "created_utc": 1677199214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_8dxkdy1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anon loses 8 terabytes of data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "name": "t3_11b2tkr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 238, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 238, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/muuIeUDZrOAFmfIIrzVgFH8XUjrW9s8fSEdq-r9EJb0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677274559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/e2ntykkey8ka1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/e2ntykkey8ka1.jpg?auto=webp&amp;v=enabled&amp;s=784f5b98a08f6920fede9b514539d1c72b8426b9", "width": 750, "height": 364}, "resolutions": [{"url": "https://preview.redd.it/e2ntykkey8ka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e508f212edecddc1d4ad96079fe5da3762cd5578", "width": 108, "height": 52}, {"url": "https://preview.redd.it/e2ntykkey8ka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0186b90a768a8dee6d6be99274bdc5a736b0e3c5", "width": 216, "height": 104}, {"url": "https://preview.redd.it/e2ntykkey8ka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=586f27eff46baab138590040452bc3b454f0cb89", "width": 320, "height": 155}, {"url": "https://preview.redd.it/e2ntykkey8ka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b074e177aa2d9191a67b0008801fde16a261962e", "width": 640, "height": 310}], "variants": {}, "id": "IOCx6E11r7MTm3EOFDXg9MVEb2SzaHzBTzLv9J_RkL8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b2tkr", "is_robot_indexable": true, "report_reasons": null, "author": "Epoxhy", "discussion_type": null, "num_comments": 70, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b2tkr/anon_loses_8_terabytes_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/e2ntykkey8ka1.jpg", "subreddit_subscribers": 671148, "created_utc": 1677274559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_foufd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I rip this documentary? I\u2019ll gladly pay for it but I want to cut up small clips of it for personal use.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 106, "top_awarded_type": null, "hide_score": false, "name": "t3_11acvpw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/D-rcL0z_rT01ZMdo_IyNbEIngTKerKyy6r0Q-6c2mag.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677196719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/hwmqbr2yi2ka1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/hwmqbr2yi2ka1.jpg?auto=webp&amp;v=enabled&amp;s=4864aa957471141f3ca255bebd9c6a09902e1f48", "width": 694, "height": 527}, "resolutions": [{"url": "https://preview.redd.it/hwmqbr2yi2ka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c6ce93be62b8082df9249de618d1f16961bfe23", "width": 108, "height": 82}, {"url": "https://preview.redd.it/hwmqbr2yi2ka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c80b2aa3b5f53b118f3f39c91fc7b31275429327", "width": 216, "height": 164}, {"url": "https://preview.redd.it/hwmqbr2yi2ka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55cd2c2b376dab574f916ba5b8317a8fa0effd36", "width": 320, "height": 242}, {"url": "https://preview.redd.it/hwmqbr2yi2ka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c2bbbddc7b81f5e1a4b182736e663bc658b3477", "width": 640, "height": 485}], "variants": {}, "id": "o1jqkfC6Cp8hqJVCLOsNPmoCgRosGpBKLDLyOFsbaxY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11acvpw", "is_robot_indexable": true, "report_reasons": null, "author": "PureCohencidence", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11acvpw/how_can_i_rip_this_documentary_ill_gladly_pay_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/hwmqbr2yi2ka1.jpg", "subreddit_subscribers": 671148, "created_utc": 1677196719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am having trouble sending a 101GB file to someone. I have tried Google Drive but the recipient has been getting a \"bandwidth quota exceeded\" message from google about this file. What would be the best way to get this file to them?", "author_fullname": "t2_cdfdsbku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to send a 101GB file to someone else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11atddz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677250770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am having trouble sending a 101GB file to someone. I have tried Google Drive but the recipient has been getting a &amp;quot;bandwidth quota exceeded&amp;quot; message from google about this file. What would be the best way to get this file to them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11atddz", "is_robot_indexable": true, "report_reasons": null, "author": "Dramatic_Law_4239", "discussion_type": null, "num_comments": 78, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11atddz/how_to_send_a_101gb_file_to_someone_else/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11atddz/how_to_send_a_101gb_file_to_someone_else/", "subreddit_subscribers": 671148, "created_utc": 1677250770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4x3kx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "saveShop: a scraper for collecting metadata &amp; media files from the 3DS and Wii U eShop", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 106, "top_awarded_type": null, "hide_score": false, "name": "t3_11aebas", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 22, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;The 3DS eShop is closing down on March 27, but there&amp;#39;s a way to save it!&lt;br&gt;Today, we&amp;#39;re releasing saveShop, a tool for creating your own personal eShop archive \ud83d\ude4c &lt;a href=\"https://t.co/kGzPWhdtXy\"&gt;pic.twitter.com/kGzPWhdtXy&lt;/a&gt;&lt;/p&gt;&amp;mdash; Mikage (@MikageEmu) &lt;a href=\"https://twitter.com/MikageEmu/status/1628460351435014148?ref_src=twsrc%5Etfw\"&gt;February 22, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/MikageEmu/status/1628460351435014148", "author_name": "Mikage", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;The 3DS eShop is closing down on March 27, but there&amp;#39;s a way to save it!&lt;br&gt;Today, we&amp;#39;re releasing saveShop, a tool for creating your own personal eShop archive \ud83d\ude4c &lt;a href=\"https://t.co/kGzPWhdtXy\"&gt;pic.twitter.com/kGzPWhdtXy&lt;/a&gt;&lt;/p&gt;&amp;mdash; Mikage (@MikageEmu) &lt;a href=\"https://twitter.com/MikageEmu/status/1628460351435014148?ref_src=twsrc%5Etfw\"&gt;February 22, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/MikageEmu", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;The 3DS eShop is closing down on March 27, but there&amp;#39;s a way to save it!&lt;br&gt;Today, we&amp;#39;re releasing saveShop, a tool for creating your own personal eShop archive \ud83d\ude4c &lt;a href=\"https://t.co/kGzPWhdtXy\"&gt;pic.twitter.com/kGzPWhdtXy&lt;/a&gt;&lt;/p&gt;&amp;mdash; Mikage (@MikageEmu) &lt;a href=\"https://twitter.com/MikageEmu/status/1628460351435014148?ref_src=twsrc%5Etfw\"&gt;February 22, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/11aebas", "height": 200}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/SPwOHmU_u4AWRIoo9uFJ_XLcwe0QP1Gea2TxUfinEc4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677200634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/i/status/1628460351435014148", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d4z-3yakd1UACywy8mptZiIRd94N3Kg_RKjFa8T71Vo.jpg?auto=webp&amp;v=enabled&amp;s=0cc8154cb01673a1406daef16d87b84ce9e9b6a6", "width": 140, "height": 106}, "resolutions": [{"url": "https://external-preview.redd.it/d4z-3yakd1UACywy8mptZiIRd94N3Kg_RKjFa8T71Vo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=737b8580caa96f3987d4502e7c38d78471c5ce61", "width": 108, "height": 81}], "variants": {}, "id": "pH982tPSNEU-HvasPDIy9x8ZIeOx0HCzSwzPOTrMXN0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11aebas", "is_robot_indexable": true, "report_reasons": null, "author": "Shados", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11aebas/saveshop_a_scraper_for_collecting_metadata_media/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/i/status/1628460351435014148", "subreddit_subscribers": 671148, "created_utc": 1677200634.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/MikageEmu/status/1628460351435014148", "author_name": "Mikage", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;The 3DS eShop is closing down on March 27, but there&amp;#39;s a way to save it!&lt;br&gt;Today, we&amp;#39;re releasing saveShop, a tool for creating your own personal eShop archive \ud83d\ude4c &lt;a href=\"https://t.co/kGzPWhdtXy\"&gt;pic.twitter.com/kGzPWhdtXy&lt;/a&gt;&lt;/p&gt;&amp;mdash; Mikage (@MikageEmu) &lt;a href=\"https://twitter.com/MikageEmu/status/1628460351435014148?ref_src=twsrc%5Etfw\"&gt;February 22, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/MikageEmu", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a NetGear ReadyNAS 2304 4 Bay NAS that has served me well, it's got 4 10TB drives into for a bit over 26TB of storage in RAID 5. I originally though that when I got it by the time I was running out of space I would be able to get a bigger unit so the problem of transferring the data would be easy. Well that time has come and I definitely am not in a place to drop a few grand on a Storinator (I could maybe swing starting with a chassis and my own hardware, but that's a different story). So I was wondering how I could upgrade the existing array without having a full backup of the data and just making a new one.\n\nMost of the data on there is my Plex server and related files. I keep the raw and processed files on there (with the Raw files being slowly processed through) so it would suck to lose it, but not unrecoverable. I have my critical files backed up and could find a spare drive to back up some more harder to reacquire stuff.\n\nSo is there a way to upgrade the array and keep the data without having a spare 30TB of storage to back it up first? Could I just swap out one drive at a time for a larger one and let the array rebuild? How much would it cost to get set up with tape to back the whole thing up? It's something I want to get to eventually and this would be a great reason to start, but if getting set up with that much capacity would cost more than a bit over $1k then I can't swing it right now.", "author_fullname": "t2_in93e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to migrate a 20+ TB NAS to bigger drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ahyre", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677211396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a NetGear ReadyNAS 2304 4 Bay NAS that has served me well, it&amp;#39;s got 4 10TB drives into for a bit over 26TB of storage in RAID 5. I originally though that when I got it by the time I was running out of space I would be able to get a bigger unit so the problem of transferring the data would be easy. Well that time has come and I definitely am not in a place to drop a few grand on a Storinator (I could maybe swing starting with a chassis and my own hardware, but that&amp;#39;s a different story). So I was wondering how I could upgrade the existing array without having a full backup of the data and just making a new one.&lt;/p&gt;\n\n&lt;p&gt;Most of the data on there is my Plex server and related files. I keep the raw and processed files on there (with the Raw files being slowly processed through) so it would suck to lose it, but not unrecoverable. I have my critical files backed up and could find a spare drive to back up some more harder to reacquire stuff.&lt;/p&gt;\n\n&lt;p&gt;So is there a way to upgrade the array and keep the data without having a spare 30TB of storage to back it up first? Could I just swap out one drive at a time for a larger one and let the array rebuild? How much would it cost to get set up with tape to back the whole thing up? It&amp;#39;s something I want to get to eventually and this would be a great reason to start, but if getting set up with that much capacity would cost more than a bit over $1k then I can&amp;#39;t swing it right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "26TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ahyre", "is_robot_indexable": true, "report_reasons": null, "author": "Saint_The_Stig", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11ahyre/how_to_migrate_a_20_tb_nas_to_bigger_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ahyre/how_to_migrate_a_20_tb_nas_to_bigger_drives/", "subreddit_subscribers": 671148, "created_utc": 1677211396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As per title. My parents first PC, I want to image it to then run it through recovery software to recover old photos (have already run a soft Recuva on the PC to confirm that there are a lot of deleted photos that I\u2019d like to recover).\n\nI\u2019ve used OSForensics\u2019 built in HDD imager (which makes .img files), does anyone know if this works on an old ass Winxp machine or what alternatives there are?\n\nThanks", "author_fullname": "t2_u1k87", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easiest way to system image an old Windows XP PC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ahugo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677211034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As per title. My parents first PC, I want to image it to then run it through recovery software to recover old photos (have already run a soft Recuva on the PC to confirm that there are a lot of deleted photos that I\u2019d like to recover).&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve used OSForensics\u2019 built in HDD imager (which makes .img files), does anyone know if this works on an old ass Winxp machine or what alternatives there are?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ahugo", "is_robot_indexable": true, "report_reasons": null, "author": "MurmurOfTheCine", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ahugo/easiest_way_to_system_image_an_old_windows_xp_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ahugo/easiest_way_to_system_image_an_old_windows_xp_pc/", "subreddit_subscribers": 671148, "created_utc": 1677211034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Talk about general topics in our Discussion Thread!\n\n* Try out new software that you liked/hated? \n* Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n* Come show us how much data you lost since you didn't have backups!\n\nTotally not an attempt to build community rapport.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataHoarder Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b2oaq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Bi-Weekly Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677274212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Talk about general topics in our Discussion Thread!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Try out new software that you liked/hated? &lt;/li&gt;\n&lt;li&gt;Tell us about that $40 2TB MicroSD card from Amazon that&amp;#39;s totally not a scam&lt;/li&gt;\n&lt;li&gt;Come show us how much data you lost since you didn&amp;#39;t have backups!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Totally not an attempt to build community rapport.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11b2oaq", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b2oaq/datahoarder_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/11b2oaq/datahoarder_discussion/", "subreddit_subscribers": 671148, "created_utc": 1677274212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just got a new WD Red Pro 12tb and prior to putting it into service I decided to run an extended SMART test.  It's been running for about 30 hours now and still shows 90% remaining.  Given that I haven't written anything to the disk yet, I assume it's probably writing over the disk, but how long should I expect it to take?  The recommended poll time is about 18 hours.  The SMART stats show no errors at the moment.  \n\nThere is nothing else on the system using the disk.  I've seen people complain about the time taken for an extended SMART test, so perhaps I must be more patient.  Might I gain insight from anybody else's experience?", "author_fullname": "t2_1etf5co5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long should a SMART extended test take on a new (unused) 12TB drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b09u0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677268239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just got a new WD Red Pro 12tb and prior to putting it into service I decided to run an extended SMART test.  It&amp;#39;s been running for about 30 hours now and still shows 90% remaining.  Given that I haven&amp;#39;t written anything to the disk yet, I assume it&amp;#39;s probably writing over the disk, but how long should I expect it to take?  The recommended poll time is about 18 hours.  The SMART stats show no errors at the moment.  &lt;/p&gt;\n\n&lt;p&gt;There is nothing else on the system using the disk.  I&amp;#39;ve seen people complain about the time taken for an extended SMART test, so perhaps I must be more patient.  Might I gain insight from anybody else&amp;#39;s experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b09u0", "is_robot_indexable": true, "report_reasons": null, "author": "tsr_timmy", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b09u0/how_long_should_a_smart_extended_test_take_on_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11b09u0/how_long_should_a_smart_extended_test_take_on_a/", "subreddit_subscribers": 671148, "created_utc": 1677268239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "r/DataHoarder/comments/nvehy1/\n\nI made this post almost 2 years ago. Right now, I'm at around 5-5.5TB of files including backups (that I want to backup physically anyways). \n\nShould I simply buy an 8TB+ drive, or is it time to move to something like a Raid 10 or ZFS1/2 setup? Or any other recommendations? \n\nIf either can saturate a 2.5Gbe link, I could move to doing some things directly off a NAS, so wondering, although it would be very expensive", "author_fullname": "t2_1mv7lrj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Buy a single drive or move to something larger ?(8TB+)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11amhaw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677227426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"/r/DataHoarder/comments/nvehy1/\"&gt;r/DataHoarder/comments/nvehy1/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I made this post almost 2 years ago. Right now, I&amp;#39;m at around 5-5.5TB of files including backups (that I want to backup physically anyways). &lt;/p&gt;\n\n&lt;p&gt;Should I simply buy an 8TB+ drive, or is it time to move to something like a Raid 10 or ZFS1/2 setup? Or any other recommendations? &lt;/p&gt;\n\n&lt;p&gt;If either can saturate a 2.5Gbe link, I could move to doing some things directly off a NAS, so wondering, although it would be very expensive&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11amhaw", "is_robot_indexable": true, "report_reasons": null, "author": "DangerousChoice42", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11amhaw/buy_a_single_drive_or_move_to_something_larger_8tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11amhaw/buy_a_single_drive_or_move_to_something_larger_8tb/", "subreddit_subscribers": 671148, "created_utc": 1677227426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Should i do that by port forwarding and static ip or is it a bad idea?(ie. just stick with some cloud service)", "author_fullname": "t2_d338cejp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it a good idea to set up nas to work over the internet?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11anwhm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677233115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Should i do that by port forwarding and static ip or is it a bad idea?(ie. just stick with some cloud service)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11anwhm", "is_robot_indexable": true, "report_reasons": null, "author": "Ihsan3498", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11anwhm/is_it_a_good_idea_to_set_up_nas_to_work_over_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11anwhm/is_it_a_good_idea_to_set_up_nas_to_work_over_the/", "subreddit_subscribers": 671148, "created_utc": 1677233115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I'm new to setting up a NAS but I have some questions...\n\n&amp;#x200B;\n\nI'm currently hoping to set up a RAID 1 NAS with about 4tb or 5tb of capacity (so x2 4tb or 5tb hdds), and I was wondering if it would be worth investing the money into a synology nas? From my research, it seems to be more plug and play than a DIY setup obviously, but has a lot of downsides such as the higher price and being walled into the synology ecosystem. While I'm not really too worried about running into problems setting up a DIY setup with a pi, I don't have too much time to dedicate to this at the moment, which is why I'm considering synology.\n\n&amp;#x200B;\n\nAlso a very unrelated question - in regards to an off site backup, would it be a good idea to get a used LTO-4 or LTO-5 tape drive on ebay and a few tape cartridges and run a backup every few months?\n\n&amp;#x200B;\n\nI'm just getting into researching everything, so I apologize if any questions are kinda bad.", "author_fullname": "t2_ncm4a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synology vs. DILY with a pi?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ai1hn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677211636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m new to setting up a NAS but I have some questions...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently hoping to set up a RAID 1 NAS with about 4tb or 5tb of capacity (so x2 4tb or 5tb hdds), and I was wondering if it would be worth investing the money into a synology nas? From my research, it seems to be more plug and play than a DIY setup obviously, but has a lot of downsides such as the higher price and being walled into the synology ecosystem. While I&amp;#39;m not really too worried about running into problems setting up a DIY setup with a pi, I don&amp;#39;t have too much time to dedicate to this at the moment, which is why I&amp;#39;m considering synology.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also a very unrelated question - in regards to an off site backup, would it be a good idea to get a used LTO-4 or LTO-5 tape drive on ebay and a few tape cartridges and run a backup every few months?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just getting into researching everything, so I apologize if any questions are kinda bad.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ai1hn", "is_robot_indexable": true, "report_reasons": null, "author": "crazedturtle77", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ai1hn/synology_vs_dily_with_a_pi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ai1hn/synology_vs_dily_with_a_pi/", "subreddit_subscribers": 671148, "created_utc": 1677211636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "And now it wont start up. It beeps a few times then stops beeping. It still spins. Desperately opened it to see if theres stuck heads and there weren't. Its a 10tb harddrive. I have years of data on it.\n\nCan anyone recommend a discrete mail in place that can possibly repair it? \n\nI was also wondering how private these places generally are? Will they look at the data because theres lots of private things i wish noone would see. Nothing illegal.", "author_fullname": "t2_b4bc83dd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So I dropped my harddrive..", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11b4fc4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677278608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And now it wont start up. It beeps a few times then stops beeping. It still spins. Desperately opened it to see if theres stuck heads and there weren&amp;#39;t. Its a 10tb harddrive. I have years of data on it.&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend a discrete mail in place that can possibly repair it? &lt;/p&gt;\n\n&lt;p&gt;I was also wondering how private these places generally are? Will they look at the data because theres lots of private things i wish noone would see. Nothing illegal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b4fc4", "is_robot_indexable": true, "report_reasons": null, "author": "hiheythereu", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b4fc4/so_i_dropped_my_harddrive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11b4fc4/so_i_dropped_my_harddrive/", "subreddit_subscribers": 671148, "created_utc": 1677278608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi friends, I have the task to save as many files of various image formats as possible, so I decided to ask you for advice. What parsing tools do you use?", "author_fullname": "t2_k1badclf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parse image formats", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b1wjm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677272330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends, I have the task to save as many files of various image formats as possible, so I decided to ask you for advice. What parsing tools do you use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b1wjm", "is_robot_indexable": true, "report_reasons": null, "author": "mountname1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b1wjm/parse_image_formats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11b1wjm/parse_image_formats/", "subreddit_subscribers": 671148, "created_utc": 1677272330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, in mi iPhone I can see the date hen photos were taken, and they photos are ordered by it, but when I airdrop them to my iMac the \u201cdate created\u201d it the moment I transfer the file. The same happens if I download them from iCloud. I\u2019ve tried in options send as/ automatic - individual photo /// all photo data\u2026 non of this works. I need help.", "author_fullname": "t2_qi4lzz55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Date and metadata on iPhone photos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11axfko", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677261123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, in mi iPhone I can see the date hen photos were taken, and they photos are ordered by it, but when I airdrop them to my iMac the \u201cdate created\u201d it the moment I transfer the file. The same happens if I download them from iCloud. I\u2019ve tried in options send as/ automatic - individual photo /// all photo data\u2026 non of this works. I need help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11axfko", "is_robot_indexable": true, "report_reasons": null, "author": "Disastrous-Win-3656", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11axfko/date_and_metadata_on_iphone_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11axfko/date_and_metadata_on_iphone_photos/", "subreddit_subscribers": 671148, "created_utc": 1677261123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After an upgrade, I am thinking about selling my smaller NAS (iX4-300D with 4x3TB RED) on Facebook. It works without issues, just needed \"more bigger better\"  \nWhat is the best way to show that the system and drives are error free and working, in a way that a novice would understand too? Is there a \"Diskinfo\" for RAID?", "author_fullname": "t2_5ai3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Specs/Stats for selling a NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11atlxf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677251383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After an upgrade, I am thinking about selling my smaller NAS (iX4-300D with 4x3TB RED) on Facebook. It works without issues, just needed &amp;quot;more bigger better&amp;quot;&lt;br/&gt;\nWhat is the best way to show that the system and drives are error free and working, in a way that a novice would understand too? Is there a &amp;quot;Diskinfo&amp;quot; for RAID?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11atlxf", "is_robot_indexable": true, "report_reasons": null, "author": "saldridge", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11atlxf/specsstats_for_selling_a_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11atlxf/specsstats_for_selling_a_nas/", "subreddit_subscribers": 671148, "created_utc": 1677251383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First of all, I do not have much in-depth knowledge of filesystems. We can say that this is a novice question. I am still primarily a Windows user. All of my data resides in NTFS single partition drives. Previously I have used FAT and FAT16 and remember having problems with them. Since Windows switched primarily to NTFS (in XP I think) I moved to NTFS and never ever had file system consistency problems (except a few on boot disks on power loss). \n\nSoon I'll move to some new drives and that should be the right time to move data to some Linux FS so I can build a Linux server. I would want to avoid BTRFS and ZFS. The redundancy is planned to be handled by Snapraid and the disks are planned to be independent. The idea of spanning a file system over multiple physical drives does not appeal to me. The question is XFS vs EXT4. \n\nSnapraid says if the disk size is below 16TB there are no limitations, if above 16TB the parity drive has to be XFS because the parity is a single file and EXT4 has a file size limit of 16TB. Various internet sources suggest that XFS is faster and better, but taking into account that they also suggest that EXT4 is faster than NTFS and I use NTFS as starting baseline, they are both better. If the need arises to have to mount the drive on a Windows machine, EXT4 can be read with additional utilities, but XFS cannot afaik. \n\nI do not really understand if I should be concerned by a scenario of running out of inodes in EXT4. I have read that some had that problem and that it is problem that is unsolvable without format. I have looked through my current files and the disks with the most files have no more than a million files per 4TB disk. \n\nI have also read that XFS is twice processor intensive vs EXT4. Taking into account that the server will be based on a lower-end processor, is that something a home server user has to concern himself with, or is it more a data center issue?\n\nNow, when I concentrated all my findings in one place, the question comes down to: \n\nIs there a reason why someone in my situation should not use EXT4?", "author_fullname": "t2_14qhf2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Linux filesystems EXT4 vs XFS, what to choose, what is better", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ar65f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677244626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all, I do not have much in-depth knowledge of filesystems. We can say that this is a novice question. I am still primarily a Windows user. All of my data resides in NTFS single partition drives. Previously I have used FAT and FAT16 and remember having problems with them. Since Windows switched primarily to NTFS (in XP I think) I moved to NTFS and never ever had file system consistency problems (except a few on boot disks on power loss). &lt;/p&gt;\n\n&lt;p&gt;Soon I&amp;#39;ll move to some new drives and that should be the right time to move data to some Linux FS so I can build a Linux server. I would want to avoid BTRFS and ZFS. The redundancy is planned to be handled by Snapraid and the disks are planned to be independent. The idea of spanning a file system over multiple physical drives does not appeal to me. The question is XFS vs EXT4. &lt;/p&gt;\n\n&lt;p&gt;Snapraid says if the disk size is below 16TB there are no limitations, if above 16TB the parity drive has to be XFS because the parity is a single file and EXT4 has a file size limit of 16TB. Various internet sources suggest that XFS is faster and better, but taking into account that they also suggest that EXT4 is faster than NTFS and I use NTFS as starting baseline, they are both better. If the need arises to have to mount the drive on a Windows machine, EXT4 can be read with additional utilities, but XFS cannot afaik. &lt;/p&gt;\n\n&lt;p&gt;I do not really understand if I should be concerned by a scenario of running out of inodes in EXT4. I have read that some had that problem and that it is problem that is unsolvable without format. I have looked through my current files and the disks with the most files have no more than a million files per 4TB disk. &lt;/p&gt;\n\n&lt;p&gt;I have also read that XFS is twice processor intensive vs EXT4. Taking into account that the server will be based on a lower-end processor, is that something a home server user has to concern himself with, or is it more a data center issue?&lt;/p&gt;\n\n&lt;p&gt;Now, when I concentrated all my findings in one place, the question comes down to: &lt;/p&gt;\n\n&lt;p&gt;Is there a reason why someone in my situation should not use EXT4?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ar65f", "is_robot_indexable": true, "report_reasons": null, "author": "SaleB81", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ar65f/linux_filesystems_ext4_vs_xfs_what_to_choose_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ar65f/linux_filesystems_ext4_vs_xfs_what_to_choose_what/", "subreddit_subscribers": 671148, "created_utc": 1677244626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Answer seems to be \"no\", but I thought I'd double check. Was looking at my biggest files to free up space and noticed that some of the files were taking up double the storage space because of a previous file version which wasn't auto-deleted after 30 days *or* excluded from the storage quota.\n\nAnd when generally browsing Drive contents the view only lists File Size, not Storage Size, so there doesn't even seem to be a way to check without looking at the Details panel for each file individually?", "author_fullname": "t2_311xe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any way to specifically find files with multiple versions on Google Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11aqprf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677243231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Answer seems to be &amp;quot;no&amp;quot;, but I thought I&amp;#39;d double check. Was looking at my biggest files to free up space and noticed that some of the files were taking up double the storage space because of a previous file version which wasn&amp;#39;t auto-deleted after 30 days &lt;em&gt;or&lt;/em&gt; excluded from the storage quota.&lt;/p&gt;\n\n&lt;p&gt;And when generally browsing Drive contents the view only lists File Size, not Storage Size, so there doesn&amp;#39;t even seem to be a way to check without looking at the Details panel for each file individually?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11aqprf", "is_robot_indexable": true, "report_reasons": null, "author": "ChunkyLaFunga", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11aqprf/is_there_any_way_to_specifically_find_files_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11aqprf/is_there_any_way_to_specifically_find_files_with/", "subreddit_subscribers": 671148, "created_utc": 1677243231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I installed a new Seagate ironwolf NAS drive, and since install, I notice a thump that sounds like it would come from my sub. Is that normal or do I have a faulty drive? I have a WD drive that I would hear spin up but never something like this. Both the PC and the sub are on the floor, but I have definitely tracked this back to the drive itself. Thanks!", "author_fullname": "t2_nuc2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New hard drive, more thump", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11aqp2y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677243172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I installed a new Seagate ironwolf NAS drive, and since install, I notice a thump that sounds like it would come from my sub. Is that normal or do I have a faulty drive? I have a WD drive that I would hear spin up but never something like this. Both the PC and the sub are on the floor, but I have definitely tracked this back to the drive itself. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11aqp2y", "is_robot_indexable": true, "report_reasons": null, "author": "TonyMaxwell", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11aqp2y/new_hard_drive_more_thump/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11aqp2y/new_hard_drive_more_thump/", "subreddit_subscribers": 671148, "created_utc": 1677243172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!  \n\n\nI have bought CarbonCopyCloner, but got very sad about how complex it seem to clone the firevault protected macbook ssd to a external drive and keep it encrypted with filevault?  \n\n\nMy setup is: Macbook PRO mid 2014 (High Sierra) with ssd internal disk.  \nI want to be protected against if the 8 year old internal ssd-disk dies. And be able to just change the SSD.  \n\n\nI have read this:  \n[https://bombich.com/kb/ccc5/working-filevault-encryption](https://bombich.com/kb/ccc5/working-filevault-encryption)  \n\n\nAnd what I have understand is to  \n1. Format the external 5400rpm drive as ATFS (non-encrypted).  \n2. Clone the internal MacOS (filevault activated) to the external drive using CCC5.  \n3. Boot from the external drive.  \n4. Acivate Filevault while booted from the external drive.  \n5. Wait for the encryption progress to finish.  \n6. Done.  \n\n\nIs this correct? Any better easy way to do this?  \nI mean this takes about a 6 hours to complete.  \n\n\nWhat about the next time I want to sync the internal drive to the external? Start over from 1.?  \n\n\nThank you very much.", "author_fullname": "t2_1addx075", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CCC5: Clone MacOS systemdisk to encrypted external drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11aq4s7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677241308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!  &lt;/p&gt;\n\n&lt;p&gt;I have bought CarbonCopyCloner, but got very sad about how complex it seem to clone the firevault protected macbook ssd to a external drive and keep it encrypted with filevault?  &lt;/p&gt;\n\n&lt;p&gt;My setup is: Macbook PRO mid 2014 (High Sierra) with ssd internal disk.&lt;br/&gt;\nI want to be protected against if the 8 year old internal ssd-disk dies. And be able to just change the SSD.  &lt;/p&gt;\n\n&lt;p&gt;I have read this:&lt;br/&gt;\n&lt;a href=\"https://bombich.com/kb/ccc5/working-filevault-encryption\"&gt;https://bombich.com/kb/ccc5/working-filevault-encryption&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;And what I have understand is to&lt;br/&gt;\n1. Format the external 5400rpm drive as ATFS (non-encrypted).&lt;br/&gt;\n2. Clone the internal MacOS (filevault activated) to the external drive using CCC5.&lt;br/&gt;\n3. Boot from the external drive.&lt;br/&gt;\n4. Acivate Filevault while booted from the external drive.&lt;br/&gt;\n5. Wait for the encryption progress to finish.&lt;br/&gt;\n6. Done.  &lt;/p&gt;\n\n&lt;p&gt;Is this correct? Any better easy way to do this?&lt;br/&gt;\nI mean this takes about a 6 hours to complete.  &lt;/p&gt;\n\n&lt;p&gt;What about the next time I want to sync the internal drive to the external? Start over from 1.?  &lt;/p&gt;\n\n&lt;p&gt;Thank you very much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11aq4s7", "is_robot_indexable": true, "report_reasons": null, "author": "raynoralpha123", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11aq4s7/ccc5_clone_macos_systemdisk_to_encrypted_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11aq4s7/ccc5_clone_macos_systemdisk_to_encrypted_external/", "subreddit_subscribers": 671148, "created_utc": 1677241308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If you utilize NVMe RAID on new motherboard chipsets, do you have an utility to upgrade firmware on SSD disks?   \nSamsung Magician does not support VMD (yet).", "author_fullname": "t2_u2h4zflt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upgrade disk firmware under VMD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11almb2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677224113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you utilize NVMe RAID on new motherboard chipsets, do you have an utility to upgrade firmware on SSD disks?&lt;br/&gt;\nSamsung Magician does not support VMD (yet).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11almb2", "is_robot_indexable": true, "report_reasons": null, "author": "mrmh1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11almb2/upgrade_disk_firmware_under_vmd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11almb2/upgrade_disk_firmware_under_vmd/", "subreddit_subscribers": 671148, "created_utc": 1677224113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a software solution that backs up say, a large volume... 50 or 100TB to several smaller hard drives?   Looking at my situation and trying to apply 3-2-1 principles...  I'm kind of surprised something like this doesn't exist. \n\nPremise:\n\nI don't know about you, but over there years I've managed to collect a lot of hard drives as I've built and decommissioned arrays.   At the moment I have two Dell R510's that mirror each other.. One loaded with 12x4TB disks and one that is **cold** loaded with 12x2TB disks plus an attached MD1000 that is also cold loaded with 15x1TB disks.  Additionally I have a pretty disgusting collection of spare 2TB and 1TB disks, plus several... and I mean several USB external drives that are 2.5\" size.   A lot of this is because I was lucky enough work for a company that e-wasted a lot of this shit. \n\nRight now I am looking to pick up maybe 6 to 10 12TB disks, then the 4TB disks will move to the cold R510 and all the 2TB disks will max out the MD1000... and I'll have a shit load of 1TB disks, externals, and still have spare 2TB disks.\n\nSoo lets put all these disks to use!\n\nA rough set of user Requirements:\n\n*  As stated software to automate 50+TB to many smaller disks.   This is seriously not a thing?\n*  3-2-1 here... No special formats.  I want like StableBit or Drivebender type setup where the files are just there. \n*  I don't care about encryption... plus I have like nearly 20 external drives with physical keys that are removable or they have keypads.   Everyone has their own preferences anyway. \n* Software keeps track of what files went to which drive so you can search and get a drive ID (you would label your drive)\n* Software could do verification if you grabbed a drive from storage and plugged it in.\n\n\nIf I can't find something like that, I've been seriously thinking about writing this in .Net for a while.  I'd adopt drives, track everything in a master database, plus write a database and maybe an XML file to the adopted drive plus whatever files. Maybe add file versioning and the ability to specify which files and folders would get backed up more than once.", "author_fullname": "t2_98lln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Large Volume to Multi Drive Back up?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ak06q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677218175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a software solution that backs up say, a large volume... 50 or 100TB to several smaller hard drives?   Looking at my situation and trying to apply 3-2-1 principles...  I&amp;#39;m kind of surprised something like this doesn&amp;#39;t exist. &lt;/p&gt;\n\n&lt;p&gt;Premise:&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know about you, but over there years I&amp;#39;ve managed to collect a lot of hard drives as I&amp;#39;ve built and decommissioned arrays.   At the moment I have two Dell R510&amp;#39;s that mirror each other.. One loaded with 12x4TB disks and one that is &lt;strong&gt;cold&lt;/strong&gt; loaded with 12x2TB disks plus an attached MD1000 that is also cold loaded with 15x1TB disks.  Additionally I have a pretty disgusting collection of spare 2TB and 1TB disks, plus several... and I mean several USB external drives that are 2.5&amp;quot; size.   A lot of this is because I was lucky enough work for a company that e-wasted a lot of this shit. &lt;/p&gt;\n\n&lt;p&gt;Right now I am looking to pick up maybe 6 to 10 12TB disks, then the 4TB disks will move to the cold R510 and all the 2TB disks will max out the MD1000... and I&amp;#39;ll have a shit load of 1TB disks, externals, and still have spare 2TB disks.&lt;/p&gt;\n\n&lt;p&gt;Soo lets put all these disks to use!&lt;/p&gt;\n\n&lt;p&gt;A rough set of user Requirements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt; As stated software to automate 50+TB to many smaller disks.   This is seriously not a thing?&lt;/li&gt;\n&lt;li&gt; 3-2-1 here... No special formats.  I want like StableBit or Drivebender type setup where the files are just there. &lt;/li&gt;\n&lt;li&gt; I don&amp;#39;t care about encryption... plus I have like nearly 20 external drives with physical keys that are removable or they have keypads.   Everyone has their own preferences anyway. &lt;/li&gt;\n&lt;li&gt;Software keeps track of what files went to which drive so you can search and get a drive ID (you would label your drive)&lt;/li&gt;\n&lt;li&gt;Software could do verification if you grabbed a drive from storage and plugged it in.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If I can&amp;#39;t find something like that, I&amp;#39;ve been seriously thinking about writing this in .Net for a while.  I&amp;#39;d adopt drives, track everything in a master database, plus write a database and maybe an XML file to the adopted drive plus whatever files. Maybe add file versioning and the ability to specify which files and folders would get backed up more than once.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "80TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ak06q", "is_robot_indexable": true, "report_reasons": null, "author": "phantom_eight", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11ak06q/large_volume_to_multi_drive_back_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ak06q/large_volume_to_multi_drive_back_up/", "subreddit_subscribers": 671148, "created_utc": 1677218175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm using rsync to copy 7TB of data from an 8TB Seagate drive to a 12TB Hitachi drive and i'm only getting speeds of 112 megabytes /second according to rsync.\n\nThe drives are connected to a 5 port sata controller that is x4 PCIe.\n\nMy system load during the operation is 2.87, which is not bad for a quad core system I don't think?\n\nThis is an Ubuntu file server with Snapraid and Samba for the file shares.\n\nCould I be running into a SMR issue? I expected sata to sata transfers to be quicker than gigabit ethernet speeds.\n\nThanks for any info. Like I said, I'm new to dealing with this much data.\n\n&amp;#x200B;\n\nEdit: I'm going from EXT4 to ExFAT using exfat-fuse.", "author_fullname": "t2_42q6llun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to data hoarding...is it normal for big SATA drives to be this slow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ajrxi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677217371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using rsync to copy 7TB of data from an 8TB Seagate drive to a 12TB Hitachi drive and i&amp;#39;m only getting speeds of 112 megabytes /second according to rsync.&lt;/p&gt;\n\n&lt;p&gt;The drives are connected to a 5 port sata controller that is x4 PCIe.&lt;/p&gt;\n\n&lt;p&gt;My system load during the operation is 2.87, which is not bad for a quad core system I don&amp;#39;t think?&lt;/p&gt;\n\n&lt;p&gt;This is an Ubuntu file server with Snapraid and Samba for the file shares.&lt;/p&gt;\n\n&lt;p&gt;Could I be running into a SMR issue? I expected sata to sata transfers to be quicker than gigabit ethernet speeds.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any info. Like I said, I&amp;#39;m new to dealing with this much data.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;m going from EXT4 to ExFAT using exfat-fuse.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ajrxi", "is_robot_indexable": true, "report_reasons": null, "author": "slughugzzz", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ajrxi/new_to_data_hoardingis_it_normal_for_big_sata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ajrxi/new_to_data_hoardingis_it_normal_for_big_sata/", "subreddit_subscribers": 671148, "created_utc": 1677217371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm running a [Rock 5B](https://wiki.radxa.com/Rock5/hardware/5b) server and am looking to expand its storage and set up back ups. The OS ([Armbian Ubuntu Jammy](https://www.armbian.com/rock-5b/)) is installed on a 200gb partition of a 2 TB NVMe stick and I'm adding two 12 TB WD HDDs for additional storage. How I set these additions drives up has kept me going back and forth.\n\nAll the applications are run through Docker containers, and presently all of the application data (database, file storage, etc) are stored on the 1.8 TB partition of the 2 TB NVMe drive. The main ones are\n\n* Immich\n* Nextcloud\n* Jellyfin\n\nWhat are the different ways that I could configure this using both the 1.8 TB partition on the SSD and the 12 TB HDD? I'd like to get some benefit out of the SSD's speeds, and would also like some sort of backup/redundancy in place. Best I can think of is to rsync the SSD to the 1st HDD, then rsync all of HDD 1 to HDD2.\n\nI'm happy to do some reading, if you have links to write ups/articles that may be helpful. I've just been staring at this for long enough that I'm going cross-eyed.\n\nDisclaimer: Because of the Rockchip kernel, ZFS is out.", "author_fullname": "t2_3l394", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a multifunctional NAS but unsure about configuring storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ajakk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677215748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m running a &lt;a href=\"https://wiki.radxa.com/Rock5/hardware/5b\"&gt;Rock 5B&lt;/a&gt; server and am looking to expand its storage and set up back ups. The OS (&lt;a href=\"https://www.armbian.com/rock-5b/\"&gt;Armbian Ubuntu Jammy&lt;/a&gt;) is installed on a 200gb partition of a 2 TB NVMe stick and I&amp;#39;m adding two 12 TB WD HDDs for additional storage. How I set these additions drives up has kept me going back and forth.&lt;/p&gt;\n\n&lt;p&gt;All the applications are run through Docker containers, and presently all of the application data (database, file storage, etc) are stored on the 1.8 TB partition of the 2 TB NVMe drive. The main ones are&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Immich&lt;/li&gt;\n&lt;li&gt;Nextcloud&lt;/li&gt;\n&lt;li&gt;Jellyfin&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What are the different ways that I could configure this using both the 1.8 TB partition on the SSD and the 12 TB HDD? I&amp;#39;d like to get some benefit out of the SSD&amp;#39;s speeds, and would also like some sort of backup/redundancy in place. Best I can think of is to rsync the SSD to the 1st HDD, then rsync all of HDD 1 to HDD2.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m happy to do some reading, if you have links to write ups/articles that may be helpful. I&amp;#39;ve just been staring at this for long enough that I&amp;#39;m going cross-eyed.&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: Because of the Rockchip kernel, ZFS is out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ajakk", "is_robot_indexable": true, "report_reasons": null, "author": "uninvitedguest", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ajakk/building_a_multifunctional_nas_but_unsure_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ajakk/building_a_multifunctional_nas_but_unsure_about/", "subreddit_subscribers": 671148, "created_utc": 1677215748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi hope this type of post is not against subreddit policy. I recently started backing up my DVD library and now twice I\u2019ve encountered my SSD wiping while I\u2019m transferring files. For the second time Ill have to back up all 4TBs of content I had on one :( \n\nI\u2019m not sure if it\u2019s just one of my two SSDs is having this issue or if it\u2019s something experienced with these drives in general, and wanted to ask the group what options might be better suited for my long term storage needs. \n\nIn case it helps I\u2019m using MakeMKV on a 2018 MacBook to backup my collection and moving directly onto the SSDs for watching on my tablet. Maybe I pay too much attention to reviews but I chose this drive because I wanted something that can take some abuse so I don\u2019t have to worry about losing content over damage or water spills.", "author_fullname": "t2_154ith", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External hard drive recommendation. Having issues with Sandisk Extreme Portable SSD 4TB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11afilz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1677204322.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677204050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi hope this type of post is not against subreddit policy. I recently started backing up my DVD library and now twice I\u2019ve encountered my SSD wiping while I\u2019m transferring files. For the second time Ill have to back up all 4TBs of content I had on one :( &lt;/p&gt;\n\n&lt;p&gt;I\u2019m not sure if it\u2019s just one of my two SSDs is having this issue or if it\u2019s something experienced with these drives in general, and wanted to ask the group what options might be better suited for my long term storage needs. &lt;/p&gt;\n\n&lt;p&gt;In case it helps I\u2019m using MakeMKV on a 2018 MacBook to backup my collection and moving directly onto the SSDs for watching on my tablet. Maybe I pay too much attention to reviews but I chose this drive because I wanted something that can take some abuse so I don\u2019t have to worry about losing content over damage or water spills.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11afilz", "is_robot_indexable": true, "report_reasons": null, "author": "MalloryWasHere", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11afilz/external_hard_drive_recommendation_having_issues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11afilz/external_hard_drive_recommendation_having_issues/", "subreddit_subscribers": 671148, "created_utc": 1677204050.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}