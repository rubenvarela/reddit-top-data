{"kind": "Listing", "data": {"after": "t3_1134zhk", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on \"Databricks \u2764\ufe0f IDEs\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_112l0h5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 106, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 106, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/SOrJwgEmcji99qBB7f8cs3zClfI4s7tDtiqx1eSlcEw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676421566.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "databricks.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.databricks.com/blog/2023/02/14/announcing-a-native-visual-studio-code-experience-for-databricks.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lRXw7aSkwr2vDc87Jertcty43PF6Vt5WQZNJVGJpTTM.jpg?auto=webp&amp;v=enabled&amp;s=542ffe72699f182145030ab57fceb0690e556eae", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/lRXw7aSkwr2vDc87Jertcty43PF6Vt5WQZNJVGJpTTM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ce9048c75face835b64732dc192c4e59b1a1b4ea", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/lRXw7aSkwr2vDc87Jertcty43PF6Vt5WQZNJVGJpTTM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ef884a4cb10bb33fd097dd0207db4e0e56368e3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/lRXw7aSkwr2vDc87Jertcty43PF6Vt5WQZNJVGJpTTM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=99ee41eb1c1482daac0735c971f8c1a20d8506c4", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/lRXw7aSkwr2vDc87Jertcty43PF6Vt5WQZNJVGJpTTM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7f569924f0a22439680dbf1be5e394df5ab2027", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/lRXw7aSkwr2vDc87Jertcty43PF6Vt5WQZNJVGJpTTM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b42ac75475681132a1c658a834f6d449b4ed4c16", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/lRXw7aSkwr2vDc87Jertcty43PF6Vt5WQZNJVGJpTTM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=143fe5376bacaa2bf617398cfa8585d1b2ea2773", "width": 1080, "height": 565}], "variants": {}, "id": "GtRADiMcQfJdZjMrWJwz2KJVAao1Bb5LSMuNacp0rVI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "112l0h5", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/112l0h5/thoughts_on_databricks_ides/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.databricks.com/blog/2023/02/14/announcing-a-native-visual-studio-code-experience-for-databricks.html", "subreddit_subscribers": 89701, "created_utc": 1676421566.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9e7m1qmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finnhub streaming data pipeline using Spark, Kafka, Kubernetes and more - Github repo &amp; more info in the comments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 48, "top_awarded_type": null, "hide_score": false, "name": "t3_1131jqq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 67, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 67, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CbifdmwD18eb4V2QhY84xODBLIeFazHoVdEaSRnHDXc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676477425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/44en1od0kdia1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/44en1od0kdia1.png?auto=webp&amp;v=enabled&amp;s=bd40c6eb7926721714742b3fcf5941eb50684aaa", "width": 2381, "height": 822}, "resolutions": [{"url": "https://preview.redd.it/44en1od0kdia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4f89886f46480a09c1ee666186e1da9f60a55824", "width": 108, "height": 37}, {"url": "https://preview.redd.it/44en1od0kdia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7a93b4d80d6a39cba158604636da7593cee15584", "width": 216, "height": 74}, {"url": "https://preview.redd.it/44en1od0kdia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=230b2497b9dd9fada4a17d96681c94e94bdf070a", "width": 320, "height": 110}, {"url": "https://preview.redd.it/44en1od0kdia1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69a45be536958efc184054cd2e95a21ad8e44e08", "width": 640, "height": 220}, {"url": "https://preview.redd.it/44en1od0kdia1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adafa2f6b140f6fa94fb9a6c57e913b627d1f7af", "width": 960, "height": 331}, {"url": "https://preview.redd.it/44en1od0kdia1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=50dea1dddc719945eaf5df33b056b8db300da24b", "width": 1080, "height": 372}], "variants": {}, "id": "WBRfH8NzSNCYSGKZg1qxfeT9pcEhMHoSqNpwBZvqY6o"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1131jqq", "is_robot_indexable": true, "report_reasons": null, "author": "LewWariat", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1131jqq/finnhub_streaming_data_pipeline_using_spark_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/44en1od0kdia1.png", "subreddit_subscribers": 89701, "created_utc": 1676477425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "It's been quite a while since I dealt with managing a type 2 SCD so I wanted to get confirmation on what the typical strategies are. I've done hash columns that will hash all of the columns of a dimension table and compare that to the hash column of the incoming data. This worked pretty well but I remember hearing that there's always a chance that hash values will be the same. Is that concern still valid, and how often does that happen? \n\nWhat are other strategies/data models/queries that will identify a changed row in a type 2 SCD? I came across [this Stackoverflow answer](https://stackoverflow.com/a/35171620/1175788) for essentially the same question but the query is pretty obtuse. I want to avoid a query where it's doing comparisons across all the columns like: `WHERE source.id = incoming.id AND (source.quantity &lt;&gt; incoming.quantity OR source.date &lt;&gt; incoming.date)` because that's obviously terribly inefficient", "author_fullname": "t2_2pyy4c8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Type 2 slowly changing dimension. What are the common SQL queries to identify updated rows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1130zot", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676475958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s been quite a while since I dealt with managing a type 2 SCD so I wanted to get confirmation on what the typical strategies are. I&amp;#39;ve done hash columns that will hash all of the columns of a dimension table and compare that to the hash column of the incoming data. This worked pretty well but I remember hearing that there&amp;#39;s always a chance that hash values will be the same. Is that concern still valid, and how often does that happen? &lt;/p&gt;\n\n&lt;p&gt;What are other strategies/data models/queries that will identify a changed row in a type 2 SCD? I came across &lt;a href=\"https://stackoverflow.com/a/35171620/1175788\"&gt;this Stackoverflow answer&lt;/a&gt; for essentially the same question but the query is pretty obtuse. I want to avoid a query where it&amp;#39;s doing comparisons across all the columns like: &lt;code&gt;WHERE source.id = incoming.id AND (source.quantity &amp;lt;&amp;gt; incoming.quantity OR source.date &amp;lt;&amp;gt; incoming.date)&lt;/code&gt; because that&amp;#39;s obviously terribly inefficient&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;v=enabled&amp;s=19b4a59f036ea2f314ff2033c11e54cdc240f8d8", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d93e783257998ff2ed865c359d9a00312a5412d7", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90216f7dc897a869ee852791bafa1e00667cdf07", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1130zot", "is_robot_indexable": true, "report_reasons": null, "author": "opabm", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1130zot/type_2_slowly_changing_dimension_what_are_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1130zot/type_2_slowly_changing_dimension_what_are_the/", "subreddit_subscribers": 89701, "created_utc": 1676475958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, question to all of you working in MS ecosystem - are you using only PowerShell in your job or is it a mix of bash/PS?\n\nI'm asking because working rn with Hadoop stack, I decided to get more proficient with linux/bash and am finding it pretty horrible ([this rant](http://xahlee.info/comp/why_bash_sucks.html) sounds about right), I'm not a linux noob but I still have to google hard to do anything beyond very basic. I heard good things about PS and from cursory research it seems much more well thought-out, unlike bash with its decades of hacky baggage.\n\nIf you think that I'm misguided and bash is awesome, please let me know, however my main point is: can one as DE with Azure avoid bash completely or you still need to interact with Linux, which I suppose to be the case? And how much will limiting myself to MS ecosystem limit my career options?\n\nThanks!", "author_fullname": "t2_470sg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE with 100% Windows/Powershell possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112uq66", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676455985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, question to all of you working in MS ecosystem - are you using only PowerShell in your job or is it a mix of bash/PS?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m asking because working rn with Hadoop stack, I decided to get more proficient with linux/bash and am finding it pretty horrible (&lt;a href=\"http://xahlee.info/comp/why_bash_sucks.html\"&gt;this rant&lt;/a&gt; sounds about right), I&amp;#39;m not a linux noob but I still have to google hard to do anything beyond very basic. I heard good things about PS and from cursory research it seems much more well thought-out, unlike bash with its decades of hacky baggage.&lt;/p&gt;\n\n&lt;p&gt;If you think that I&amp;#39;m misguided and bash is awesome, please let me know, however my main point is: can one as DE with Azure avoid bash completely or you still need to interact with Linux, which I suppose to be the case? And how much will limiting myself to MS ecosystem limit my career options?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "112uq66", "is_robot_indexable": true, "report_reasons": null, "author": "Zosimas", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/112uq66/de_with_100_windowspowershell_possible/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/112uq66/de_with_100_windowspowershell_possible/", "subreddit_subscribers": 89701, "created_utc": 1676455985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you mask the data? Have full access rights? Follow just guidance? How does it work where you are?", "author_fullname": "t2_xt5zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does your data engineering team handle ingesting PII and classified data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1130z35", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676475915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you mask the data? Have full access rights? Follow just guidance? How does it work where you are?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1130z35", "is_robot_indexable": true, "report_reasons": null, "author": "mister_patience", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1130z35/how_does_your_data_engineering_team_handle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1130z35/how_does_your_data_engineering_team_handle/", "subreddit_subscribers": 89701, "created_utc": 1676475915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently I am trying to stand up a self managed DataHub instance for my organization. I believe for a data catalog to truly provide business value, the respective business teams need to \"buy in\" and document their domain knowledge into the Data Catalog. One of my fears is that after putting in a ton of work standing up a self managed DataHub platform is that it will be dead in the water due to lack of adoption by  business teams and their users. To people who have implemented a Data Catalog solution before my question is this - how did you gain \"buy in\" from the business and what data catalog features were important to provide actual business value to the end users (i.e. data lineage, business glossary, data profiling, etc.)?", "author_fullname": "t2_6fq4a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get business user buy in for a Data Catalog?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112pxwi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676437150.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I am trying to stand up a self managed DataHub instance for my organization. I believe for a data catalog to truly provide business value, the respective business teams need to &amp;quot;buy in&amp;quot; and document their domain knowledge into the Data Catalog. One of my fears is that after putting in a ton of work standing up a self managed DataHub platform is that it will be dead in the water due to lack of adoption by  business teams and their users. To people who have implemented a Data Catalog solution before my question is this - how did you gain &amp;quot;buy in&amp;quot; from the business and what data catalog features were important to provide actual business value to the end users (i.e. data lineage, business glossary, data profiling, etc.)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "112pxwi", "is_robot_indexable": true, "report_reasons": null, "author": "Ghostflake", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/112pxwi/how_to_get_business_user_buy_in_for_a_data_catalog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/112pxwi/how_to_get_business_user_buy_in_for_a_data_catalog/", "subreddit_subscribers": 89701, "created_utc": 1676437150.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just to give some context, I started this week at a new job working for about a 100 person startup. I was brought on as the first data hire, however, my boss (the cto) had already build out a MySQL database functioning as a data warehouse, being fed by a custom rails platform. As it is now, there is very little structure or documentation and I can\u2019t access the db directly bc of the firewall. I guess the assumption was that I could explore the data and build out dashboards using the metbase platform that was in place. He also told me he can ingest new data sources like hubspot directly into MySQL through the rails platform. \n\nMy questions are vague:\n\n-Does any of this seem like bad practice?\n\n-Is it possible that no additional modeling would need to be done and I could rely on say, the initial sql in tableau to bring the data together?\n\n-Are there any general indications to look out for that necessitate modeling beyond what is currently in place?\n\n-Is using MySQL in this fashion kosher or could it be problematic beyond just for performance issues (The tables are all under 1 mill rows but growing steadily)?\n\n\n\nI was told that the top priority is to start establishing metrics to calculate ROI but this seems like it could be a bit premature before confirming we have everything in place from a data perspective. Perhaps throwing together some quick wins in the beginning with dashboards is the best approach.\n\nThanks for any advice here! Just looking for some guidance from more seasoned folks.", "author_fullname": "t2_dkfbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Could use some advice for my new job.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112ro91", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676443898.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676443556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just to give some context, I started this week at a new job working for about a 100 person startup. I was brought on as the first data hire, however, my boss (the cto) had already build out a MySQL database functioning as a data warehouse, being fed by a custom rails platform. As it is now, there is very little structure or documentation and I can\u2019t access the db directly bc of the firewall. I guess the assumption was that I could explore the data and build out dashboards using the metbase platform that was in place. He also told me he can ingest new data sources like hubspot directly into MySQL through the rails platform. &lt;/p&gt;\n\n&lt;p&gt;My questions are vague:&lt;/p&gt;\n\n&lt;p&gt;-Does any of this seem like bad practice?&lt;/p&gt;\n\n&lt;p&gt;-Is it possible that no additional modeling would need to be done and I could rely on say, the initial sql in tableau to bring the data together?&lt;/p&gt;\n\n&lt;p&gt;-Are there any general indications to look out for that necessitate modeling beyond what is currently in place?&lt;/p&gt;\n\n&lt;p&gt;-Is using MySQL in this fashion kosher or could it be problematic beyond just for performance issues (The tables are all under 1 mill rows but growing steadily)?&lt;/p&gt;\n\n&lt;p&gt;I was told that the top priority is to start establishing metrics to calculate ROI but this seems like it could be a bit premature before confirming we have everything in place from a data perspective. Perhaps throwing together some quick wins in the beginning with dashboards is the best approach.&lt;/p&gt;\n\n&lt;p&gt;Thanks for any advice here! Just looking for some guidance from more seasoned folks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "112ro91", "is_robot_indexable": true, "report_reasons": null, "author": "biga410", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/112ro91/could_use_some_advice_for_my_new_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/112ro91/could_use_some_advice_for_my_new_job/", "subreddit_subscribers": 89701, "created_utc": 1676443556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In this post [https://www.reddit.com/r/dataengineering/comments/y8wbh0/looking\\_for\\_data\\_analytics\\_engine\\_for\\_lowlatency/](https://www.reddit.com/r/dataengineering/comments/y8wbh0/looking_for_data_analytics_engine_for_lowlatency/) I was guided towards Headless BI, specifically [Cube.dev](https://Cube.dev).\n\nWe looked into it, seemed to work for us and went with it. Nice!\n\nExcept... we've run into various edge cases where we're now questioning our choice heavily.\n\nBrowsing around, I've found Cube to be somewhat inspired by Looker and Looker being, seemingly, more powerful, but was thinking, maybe there are other tools on the block?\n\nAnd while at it, how a tool like that would be actually called? Headless BI doesn't turn up too much results. Semantic Layer? Maybe something else?", "author_fullname": "t2_4gt5e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any alternatives to Looker/LookML &amp; Cube.dev?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1131e3a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676477013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In this post &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/y8wbh0/looking_for_data_analytics_engine_for_lowlatency/\"&gt;https://www.reddit.com/r/dataengineering/comments/y8wbh0/looking_for_data_analytics_engine_for_lowlatency/&lt;/a&gt; I was guided towards Headless BI, specifically &lt;a href=\"https://Cube.dev\"&gt;Cube.dev&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;We looked into it, seemed to work for us and went with it. Nice!&lt;/p&gt;\n\n&lt;p&gt;Except... we&amp;#39;ve run into various edge cases where we&amp;#39;re now questioning our choice heavily.&lt;/p&gt;\n\n&lt;p&gt;Browsing around, I&amp;#39;ve found Cube to be somewhat inspired by Looker and Looker being, seemingly, more powerful, but was thinking, maybe there are other tools on the block?&lt;/p&gt;\n\n&lt;p&gt;And while at it, how a tool like that would be actually called? Headless BI doesn&amp;#39;t turn up too much results. Semantic Layer? Maybe something else?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IkJBfNtzRzAGnHrD5WSLeOv32EOc9aOFFmrkE780nb8.jpg?auto=webp&amp;v=enabled&amp;s=4c2ee9ced32cf7f44c9acfadaf0fc6138d934235", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/IkJBfNtzRzAGnHrD5WSLeOv32EOc9aOFFmrkE780nb8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39fc2899acfe1fd7fec2ad6a9c6a16ed630cc31d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/IkJBfNtzRzAGnHrD5WSLeOv32EOc9aOFFmrkE780nb8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bb8a7f81c9f0c3327863c615505b600bdd32ead4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/IkJBfNtzRzAGnHrD5WSLeOv32EOc9aOFFmrkE780nb8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0747c7e295fa50f4a169ff2c77b4e38dfe3c70c5", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/IkJBfNtzRzAGnHrD5WSLeOv32EOc9aOFFmrkE780nb8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44ddb5bc88a05e68b02981b71d6f63b8130ecb7a", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/IkJBfNtzRzAGnHrD5WSLeOv32EOc9aOFFmrkE780nb8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd7a3df58c7294394cdfee68c359fedcde4abc6f", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/IkJBfNtzRzAGnHrD5WSLeOv32EOc9aOFFmrkE780nb8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=450ad0a42363c74fd12f5edf265b485734b70be3", "width": 1080, "height": 567}], "variants": {}, "id": "CYFlWqFefFx0WAlgFZvtSzIVYhX58H2hKywSvmvXXxw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1131e3a", "is_robot_indexable": true, "report_reasons": null, "author": "psycketom", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1131e3a/any_alternatives_to_lookerlookml_cubedev/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1131e3a/any_alternatives_to_lookerlookml_cubedev/", "subreddit_subscribers": 89701, "created_utc": 1676477013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am trying to work on some personal projects to supplement my learning as I take the Data Talks Data Engineer camp.\n\nRecently, I've received my extended streams data from Spotify. As a way to have an extra layer to my project I've created a separate dataset with Unique Spotify tracks with metadata\n\nTable One: Extended Steaming Data. All my listens from Spotify between three years\nTable Two: Dimension table. Has metadata for each unique track.\n \nThese two tables are related through a Track URI ID.\n\nMy next step is to push these two tables to Google Cloud Services where I can create some views to query off if and visualize with Big Query.\n\nThis is really one first time pushing a dataset for my own personal project to the cloud. I guess I just wanted to post to see if there was any advice or suggestions.", "author_fullname": "t2_z321026", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Personal Project: Beginner seeking advice for Spotify streams project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112ok1b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676432433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am trying to work on some personal projects to supplement my learning as I take the Data Talks Data Engineer camp.&lt;/p&gt;\n\n&lt;p&gt;Recently, I&amp;#39;ve received my extended streams data from Spotify. As a way to have an extra layer to my project I&amp;#39;ve created a separate dataset with Unique Spotify tracks with metadata&lt;/p&gt;\n\n&lt;p&gt;Table One: Extended Steaming Data. All my listens from Spotify between three years\nTable Two: Dimension table. Has metadata for each unique track.&lt;/p&gt;\n\n&lt;p&gt;These two tables are related through a Track URI ID.&lt;/p&gt;\n\n&lt;p&gt;My next step is to push these two tables to Google Cloud Services where I can create some views to query off if and visualize with Big Query.&lt;/p&gt;\n\n&lt;p&gt;This is really one first time pushing a dataset for my own personal project to the cloud. I guess I just wanted to post to see if there was any advice or suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "112ok1b", "is_robot_indexable": true, "report_reasons": null, "author": "raz_the_kid0901", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/112ok1b/personal_project_beginner_seeking_advice_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/112ok1b/personal_project_beginner_seeking_advice_for/", "subreddit_subscribers": 89701, "created_utc": 1676432433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I am exploring some ideas in the data space and wonder what are some of the pain points that current solutions don't solve for you? I am assuming ETL(fivetran) + Warehouse(snowflake) + Modeling(DBT) + RETL(Hightouch/Census) is the usual setup at organizations when they are revamping their modern data stack. Am I missing something?", "author_fullname": "t2_3tiq5c7i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's missing in the modern data stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11388la", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676494377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I am exploring some ideas in the data space and wonder what are some of the pain points that current solutions don&amp;#39;t solve for you? I am assuming ETL(fivetran) + Warehouse(snowflake) + Modeling(DBT) + RETL(Hightouch/Census) is the usual setup at organizations when they are revamping their modern data stack. Am I missing something?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11388la", "is_robot_indexable": true, "report_reasons": null, "author": "ownubie", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11388la/whats_missing_in_the_modern_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11388la/whats_missing_in_the_modern_data_stack/", "subreddit_subscribers": 89701, "created_utc": 1676494377.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm using Snowflake to store all of our data and while I'm investigating issues, I notice certain columns haven't been updated for weeks which I'd like to flag and triage. \n\nI use dbt and unsure if dbt can help with this easily. I use dbt tests and can program a macro across certain columns to catch if data isn't populating as I'd expect....but I was curious...\n\n**What approaches or tools have made your lives easier with data profiling and catching data issues?**", "author_fullname": "t2_j1vd6s00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data profiling tools / approaches?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1130jx5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676474767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using Snowflake to store all of our data and while I&amp;#39;m investigating issues, I notice certain columns haven&amp;#39;t been updated for weeks which I&amp;#39;d like to flag and triage. &lt;/p&gt;\n\n&lt;p&gt;I use dbt and unsure if dbt can help with this easily. I use dbt tests and can program a macro across certain columns to catch if data isn&amp;#39;t populating as I&amp;#39;d expect....but I was curious...&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What approaches or tools have made your lives easier with data profiling and catching data issues?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1130jx5", "is_robot_indexable": true, "report_reasons": null, "author": "crhumble", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1130jx5/data_profiling_tools_approaches/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1130jx5/data_profiling_tools_approaches/", "subreddit_subscribers": 89701, "created_utc": 1676474767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This article has a useful *very* high level summary tl;dr of Fundamentals of Data Engineering\n\n[https://siliconangle.com/2023/02/10/evolving-role-data-engineer/](https://siliconangle.com/2023/02/10/evolving-role-data-engineer/)\n\n&amp;#x200B;\n\n(although the cover image overlaid with some python code for 3D rendering instead of DE loses it some geek points ;)", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A useful summary/overview of FoDE: The evolving role of the data engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112vn1i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676459535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This article has a useful &lt;em&gt;very&lt;/em&gt; high level summary tl;dr of Fundamentals of Data Engineering&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://siliconangle.com/2023/02/10/evolving-role-data-engineer/\"&gt;https://siliconangle.com/2023/02/10/evolving-role-data-engineer/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(although the cover image overlaid with some python code for 3D rendering instead of DE loses it some geek points ;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/H9O296jDd5ja0wrDNbARLYfxkPUiPLwhif6aKR3sY9o.jpg?auto=webp&amp;v=enabled&amp;s=f6151291d14854b67add19949d5e08b2a632bcc9", "width": 1920, "height": 1281}, "resolutions": [{"url": "https://external-preview.redd.it/H9O296jDd5ja0wrDNbARLYfxkPUiPLwhif6aKR3sY9o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e97b9d6fcf855ca862789412fcc89068b09ba8d", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/H9O296jDd5ja0wrDNbARLYfxkPUiPLwhif6aKR3sY9o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac22a21d79279d31bbdbc673ca391c002b2b0279", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/H9O296jDd5ja0wrDNbARLYfxkPUiPLwhif6aKR3sY9o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=829ba013e1977ce0c4e2b902689ab893e1238b45", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/H9O296jDd5ja0wrDNbARLYfxkPUiPLwhif6aKR3sY9o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=59226715d7bf94bed8a70fd87e1f5b3a4b885fcb", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/H9O296jDd5ja0wrDNbARLYfxkPUiPLwhif6aKR3sY9o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd4c98658f09df2ffc40dcdd9a369fd6bbb40b1b", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/H9O296jDd5ja0wrDNbARLYfxkPUiPLwhif6aKR3sY9o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=65eb2be5ade82bbb5cc4ac84394ccf65315ee3c0", "width": 1080, "height": 720}], "variants": {}, "id": "RtziY08pvnHZqgYEZJKNNk3sCzE45Sd9eIPgowb1wP8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "112vn1i", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/112vn1i/a_useful_summaryoverview_of_fode_the_evolving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/112vn1i/a_useful_summaryoverview_of_fode_the_evolving/", "subreddit_subscribers": 89701, "created_utc": 1676459535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I am looking for a tool (open source preferably) which can help me in data cataloging, lineage and governance along with a UI for data preparation ( a front end from which business team can search for fields based on keywords picked from the catalog and choose those fields to prepare reports) the backend has to be data warehouse ( snowflake in my case). Are there such tools available in market?", "author_fullname": "t2_eb80kwgd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Governance, Catalogue, Lineage tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112uts1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676456396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I am looking for a tool (open source preferably) which can help me in data cataloging, lineage and governance along with a UI for data preparation ( a front end from which business team can search for fields based on keywords picked from the catalog and choose those fields to prepare reports) the backend has to be data warehouse ( snowflake in my case). Are there such tools available in market?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "112uts1", "is_robot_indexable": true, "report_reasons": null, "author": "No-Caregiver-1204", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/112uts1/data_governance_catalogue_lineage_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/112uts1/data_governance_catalogue_lineage_tool/", "subreddit_subscribers": 89701, "created_utc": 1676456396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve hosted a few rounds of a data book club, and it\u2019s been a fantastic way to me and 100+ data professional actually read (not just passively skim \ud83e\udd23) many books on our lists.\n\nNext month, we\u2019re reading [*Data Teams: A Unified Management Model for Successful Data-Focused Teams*](https://www.amazon.com/Data-Teams-Management-Successful-Data-Focused/dp/1484262271/ref=sr_1_1?crid=12ST07D9VZNUB&amp;keywords=Data+Teams%3A+A+Unified+Management+Model+for+Successful+Data-Focused+Teams&amp;qid=1676346037&amp;sprefix=data+teams+a+unified+management+model+for+successful+data-focused+teams%2Caps%2C198&amp;sr=8-1) by [Jesse Anderson](https://www.linkedin.com/in/jessetanderson/).\n\nI\u2019m not being paid to promote this book in any way, and I have no affiliation with the author. It's a book I wanna read!\n\n**Here\u2019s how the book club works:** All participants read the book independently, and then we meet bi-weekly for 30 mins to discuss key takeaways, questions, hot takes, etc.\n\n**Here\u2019s the schedule:**\n\n* March 17th: Discuss pt. 1 &amp; pt. 2\n* March 31st: Discuss pt. 3\n* April 5th: AMA w/ Author, [Jesse Anderson](https://www.linkedin.com/in/jessetanderson/)\n* April 14th: Discuss pt. 4\n\nWe currently have dozens signed up! If you\u2019d like to join, book it [**here**](https://www.operationalanalytics.club/events/titlecase-book-club-data-teams-a-unified-management-model-for-successful-data-focused-teams)**.**", "author_fullname": "t2_nkrhcqia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Club - Data Teams: A Unified Management Model for Successful Data-Focused Teams by Jesse Anderson", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1139l8l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676498263.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676497889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve hosted a few rounds of a data book club, and it\u2019s been a fantastic way to me and 100+ data professional actually read (not just passively skim \ud83e\udd23) many books on our lists.&lt;/p&gt;\n\n&lt;p&gt;Next month, we\u2019re reading &lt;a href=\"https://www.amazon.com/Data-Teams-Management-Successful-Data-Focused/dp/1484262271/ref=sr_1_1?crid=12ST07D9VZNUB&amp;amp;keywords=Data+Teams%3A+A+Unified+Management+Model+for+Successful+Data-Focused+Teams&amp;amp;qid=1676346037&amp;amp;sprefix=data+teams+a+unified+management+model+for+successful+data-focused+teams%2Caps%2C198&amp;amp;sr=8-1\"&gt;&lt;em&gt;Data Teams: A Unified Management Model for Successful Data-Focused Teams&lt;/em&gt;&lt;/a&gt; by &lt;a href=\"https://www.linkedin.com/in/jessetanderson/\"&gt;Jesse Anderson&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m not being paid to promote this book in any way, and I have no affiliation with the author. It&amp;#39;s a book I wanna read!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here\u2019s how the book club works:&lt;/strong&gt; All participants read the book independently, and then we meet bi-weekly for 30 mins to discuss key takeaways, questions, hot takes, etc.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here\u2019s the schedule:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;March 17th: Discuss pt. 1 &amp;amp; pt. 2&lt;/li&gt;\n&lt;li&gt;March 31st: Discuss pt. 3&lt;/li&gt;\n&lt;li&gt;April 5th: AMA w/ Author, &lt;a href=\"https://www.linkedin.com/in/jessetanderson/\"&gt;Jesse Anderson&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;April 14th: Discuss pt. 4&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We currently have dozens signed up! If you\u2019d like to join, book it &lt;a href=\"https://www.operationalanalytics.club/events/titlecase-book-club-data-teams-a-unified-management-model-for-successful-data-focused-teams\"&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1139l8l", "is_robot_indexable": true, "report_reasons": null, "author": "JParkerRogers", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1139l8l/book_club_data_teams_a_unified_management_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1139l8l/book_club_data_teams_a_unified_management_model/", "subreddit_subscribers": 89701, "created_utc": 1676497889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_d0gtdepx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake CHANGE DATE FEED \u2014 How to read CDC without using Delta Log", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 57, "top_awarded_type": null, "hide_score": false, "name": "t3_1130wj8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gcQT_X76jiYTXNkvzEX7-zIUUj14WcY6xa5Jb9So8io.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676475716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@joydeep.roy/change-date-feed-how-to-read-cdc-without-using-delta-log-17e0ceb99a8e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FQh0qHIqWY4sZK_iDxisWEBeDlYXpY_A-QEaD6nwoS4.jpg?auto=webp&amp;v=enabled&amp;s=f97d42dbbd8e27dc2b44056b321fe4b91e3d7d9d", "width": 1002, "height": 414}, "resolutions": [{"url": "https://external-preview.redd.it/FQh0qHIqWY4sZK_iDxisWEBeDlYXpY_A-QEaD6nwoS4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=716712296ffbdb9044c829dcc7a73014376063e1", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/FQh0qHIqWY4sZK_iDxisWEBeDlYXpY_A-QEaD6nwoS4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63f7f69089c1f264df96a662f8ec1bb1f6c1fe40", "width": 216, "height": 89}, {"url": "https://external-preview.redd.it/FQh0qHIqWY4sZK_iDxisWEBeDlYXpY_A-QEaD6nwoS4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=294b02119766f1b2ecd4dacada768322d17868d1", "width": 320, "height": 132}, {"url": "https://external-preview.redd.it/FQh0qHIqWY4sZK_iDxisWEBeDlYXpY_A-QEaD6nwoS4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32d70acf82831566b93ab0124a35cd18d16ad1fb", "width": 640, "height": 264}, {"url": "https://external-preview.redd.it/FQh0qHIqWY4sZK_iDxisWEBeDlYXpY_A-QEaD6nwoS4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef28f0508c14093813f44b172a31b8a160ca28b4", "width": 960, "height": 396}], "variants": {}, "id": "gVVkQGOOB1Nv48mh-zEITYt_WkTJdgoTJ9edGrmyA_I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1130wj8", "is_robot_indexable": true, "report_reasons": null, "author": "JBR_Codepen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1130wj8/delta_lake_change_date_feed_how_to_read_cdc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@joydeep.roy/change-date-feed-how-to-read-cdc-without-using-delta-log-17e0ceb99a8e", "subreddit_subscribers": 89701, "created_utc": 1676475716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, it seems you cannot create a view over a federated datasource?\n\nthats a great shame :(\n\nWe use Superset to access our datalake, and it's nice to push query complexity into Athena rather than doing it in Superset!  (In fact, i'm not even sure superset sees the federated sources)\n\nHas anyone seen if this restriction is documented?\n\nIt's not terrible tho to use a virtual dataset, just inconsistent in the architecture we have right now.", "author_fullname": "t2_30v538jt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Athena - no views over federated data sources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112v475", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676458421.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676457513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, it seems you cannot create a view over a federated datasource?&lt;/p&gt;\n\n&lt;p&gt;thats a great shame :(&lt;/p&gt;\n\n&lt;p&gt;We use Superset to access our datalake, and it&amp;#39;s nice to push query complexity into Athena rather than doing it in Superset!  (In fact, i&amp;#39;m not even sure superset sees the federated sources)&lt;/p&gt;\n\n&lt;p&gt;Has anyone seen if this restriction is documented?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not terrible tho to use a virtual dataset, just inconsistent in the architecture we have right now.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "112v475", "is_robot_indexable": true, "report_reasons": null, "author": "codek1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/112v475/athena_no_views_over_federated_data_sources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/112v475/athena_no_views_over_federated_data_sources/", "subreddit_subscribers": 89701, "created_utc": 1676457513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \nI wanted to ask about any experience with SAS Viya in terms of ease of learning and functionality. \n\nI have around a bit above 3 years experience working with AWS and I wanted to know, is my knowledge is actually transferable to work with SAS cloud. \n\nI am applying to a job and discovered that they run a multi cloud platform, partially with AWS and partially with SAS and that\u2019s why I am asking. \n\nCheers", "author_fullname": "t2_64nmnknh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience with SAS Viya", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112uv40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "spoiler", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676456540.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, \nI wanted to ask about any experience with SAS Viya in terms of ease of learning and functionality. &lt;/p&gt;\n\n&lt;p&gt;I have around a bit above 3 years experience working with AWS and I wanted to know, is my knowledge is actually transferable to work with SAS cloud. &lt;/p&gt;\n\n&lt;p&gt;I am applying to a job and discovered that they run a multi cloud platform, partially with AWS and partially with SAS and that\u2019s why I am asking. &lt;/p&gt;\n\n&lt;p&gt;Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": true, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "112uv40", "is_robot_indexable": true, "report_reasons": null, "author": "SnooDoggos5883", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/112uv40/experience_with_sas_viya/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/112uv40/experience_with_sas_viya/", "subreddit_subscribers": 89701, "created_utc": 1676456540.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to figure out what the role of a \u201ccontent manager\u201d is at Google.  I\u2019m not sure I even have the right title. But essentially the role sits in the business and knows a lot about the data.  They work as a conduit between data engineering and the business. \n\nWhere I work we are called data managers. We typically have domain expertise and have usually worked in the business before.  They will also be fluent in data so they can help to build out requirements for the DEs.  It\u2019s similar to a BA but the big difference is they understand how the data is used. \n\nDo other people have this role in their company? I\u2019m really looking for tech industry examples. \n\nContext: my company is non-tech and wants to be tech and I\u2019m trying to figure out how to talk to leadership in terms they understand.", "author_fullname": "t2_7ge1tylx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Content Manager? at Google", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_113anoe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676500594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to figure out what the role of a \u201ccontent manager\u201d is at Google.  I\u2019m not sure I even have the right title. But essentially the role sits in the business and knows a lot about the data.  They work as a conduit between data engineering and the business. &lt;/p&gt;\n\n&lt;p&gt;Where I work we are called data managers. We typically have domain expertise and have usually worked in the business before.  They will also be fluent in data so they can help to build out requirements for the DEs.  It\u2019s similar to a BA but the big difference is they understand how the data is used. &lt;/p&gt;\n\n&lt;p&gt;Do other people have this role in their company? I\u2019m really looking for tech industry examples. &lt;/p&gt;\n\n&lt;p&gt;Context: my company is non-tech and wants to be tech and I\u2019m trying to figure out how to talk to leadership in terms they understand.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "113anoe", "is_robot_indexable": true, "report_reasons": null, "author": "fannypackbringitback", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113anoe/content_manager_at_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113anoe/content_manager_at_google/", "subreddit_subscribers": 89701, "created_utc": 1676500594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I got a flow which I want to automate in Azure. For now we're running a python script on prem, but the server needs to get phased out.\n\n&amp;#x200B;\n\n\\- Everyday I get emails in Office 365 from client.\n\n\\- Every email holds a single Excel file with data on a single (the 2nd) row. The format is always the same.\n\n&amp;#x200B;\n\nMy question is how can I get that data from Excel, so I can enrich and manipulate it and process it to another system.\n\n&amp;#x200B;\n\nI don't know which approach is best for this... Synapse, Power Automate, Functions... something else.", "author_fullname": "t2_ig8s88dn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automate Excel data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1139rhi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676498341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I got a flow which I want to automate in Azure. For now we&amp;#39;re running a python script on prem, but the server needs to get phased out.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;- Everyday I get emails in Office 365 from client.&lt;/p&gt;\n\n&lt;p&gt;- Every email holds a single Excel file with data on a single (the 2nd) row. The format is always the same.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question is how can I get that data from Excel, so I can enrich and manipulate it and process it to another system.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know which approach is best for this... Synapse, Power Automate, Functions... something else.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1139rhi", "is_robot_indexable": true, "report_reasons": null, "author": "Hs82H", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1139rhi/automate_excel_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1139rhi/automate_excel_data/", "subreddit_subscribers": 89701, "created_utc": 1676498341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I would like to ask few questions regarding setting up a free data server. Right now I work in a tech company but my department does not have any data server that I can use to extract data. This is extremely uncomfortable and make my work process very inefficient. Since they said they do not have a budget to get up a data server (I think the upper management level is just lazy). I got a permission to make my own data server on my local environment just so I can use it to do my work. Is it possible to do that using free SQL server? I have access to the raw data from a 3rd party website (csv and excel format). Would it be possible to manually load those data to the sql server and update when there is new data ?", "author_fullname": "t2_5uvrlw9s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up a local data server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1139kdv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676497830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I would like to ask few questions regarding setting up a free data server. Right now I work in a tech company but my department does not have any data server that I can use to extract data. This is extremely uncomfortable and make my work process very inefficient. Since they said they do not have a budget to get up a data server (I think the upper management level is just lazy). I got a permission to make my own data server on my local environment just so I can use it to do my work. Is it possible to do that using free SQL server? I have access to the raw data from a 3rd party website (csv and excel format). Would it be possible to manually load those data to the sql server and update when there is new data ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1139kdv", "is_robot_indexable": true, "report_reasons": null, "author": "Professional_Ball_58", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1139kdv/setting_up_a_local_data_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1139kdv/setting_up_a_local_data_server/", "subreddit_subscribers": 89701, "created_utc": 1676497830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If this is more of a devops question my apologies.\n\nMy supervisor gave me the go ahead to set up a managed redis service for use as a caching layer on top of some of our db products. \n\nI haven't done this before and it's not something we have a lot of experience with at my company and I was just wondering what are some pain points, pitfalls, or gotchas to look out for.\n\nThe machine doesn't need a lot of compute but will likely need a lot of memory. Idk if elasticache handles this out of the box or not.\n\nWe generally use AWS secrets for managing credentials; what are best practice's for syncing a redis user's credentials with like rolling credentials in secrets manager?\n\nEdit: We're a python shop and I generally use aws_cdk for python for deployments\n\nThanks.", "author_fullname": "t2_utq2123m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up ElastiCache service in AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1138cr6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676494923.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676494695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If this is more of a devops question my apologies.&lt;/p&gt;\n\n&lt;p&gt;My supervisor gave me the go ahead to set up a managed redis service for use as a caching layer on top of some of our db products. &lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t done this before and it&amp;#39;s not something we have a lot of experience with at my company and I was just wondering what are some pain points, pitfalls, or gotchas to look out for.&lt;/p&gt;\n\n&lt;p&gt;The machine doesn&amp;#39;t need a lot of compute but will likely need a lot of memory. Idk if elasticache handles this out of the box or not.&lt;/p&gt;\n\n&lt;p&gt;We generally use AWS secrets for managing credentials; what are best practice&amp;#39;s for syncing a redis user&amp;#39;s credentials with like rolling credentials in secrets manager?&lt;/p&gt;\n\n&lt;p&gt;Edit: We&amp;#39;re a python shop and I generally use aws_cdk for python for deployments&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1138cr6", "is_robot_indexable": true, "report_reasons": null, "author": "1UStasis", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1138cr6/setting_up_elasticache_service_in_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1138cr6/setting_up_elasticache_service_in_aws/", "subreddit_subscribers": 89701, "created_utc": 1676494695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team is pretty strict about using config files to store a variety of credentials tied to our data pipelines - especially variables making up the connection string for our DW. Is this a common thing or do other teams use other methods such as .env files?", "author_fullname": "t2_bwp6e1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your team\u2019s method for storing credentials for your pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1137p0i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676492961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team is pretty strict about using config files to store a variety of credentials tied to our data pipelines - especially variables making up the connection string for our DW. Is this a common thing or do other teams use other methods such as .env files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1137p0i", "is_robot_indexable": true, "report_reasons": null, "author": "wild_bill34", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1137p0i/what_is_your_teams_method_for_storing_credentials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1137p0i/what_is_your_teams_method_for_storing_credentials/", "subreddit_subscribers": 89701, "created_utc": 1676492961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The first version of SQL, SQL-86, was released in 1986 by the American National Standards Institute (ANSI) and the International Organization for Standardization (ISO). Since then, there have been several updates to the standard, including SQL-92, SQL-99, and SQL-2003.\n\nIf you're interested in learning about the evolution of SQL over years and how it got to its current place, please check my article published in Level Up Coding publication. In this article, I am going to take a look at the SQL Standard, as well as popular implementations of SQL such as MySQL, PostgreSQL, MS SQL Server, Oracle, and SQLite. I will explore the features and capabilities of each, as well as any limitations or drawbacks.\n\n[https://levelup.gitconnected.com/the-evolution-of-sql-a-look-at-the-past-present-and-future-of-sql-standards-2326cddf7a45](https://levelup.gitconnected.com/the-evolution-of-sql-a-look-at-the-past-present-and-future-of-sql-standards-2326cddf7a45)\n\nhttps://preview.redd.it/w953o0sukeia1.jpg?width=3136&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7faa01ad856bb983564cc05c649d755d9d07bc5d", "author_fullname": "t2_vacizcrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Evolution of SQL: A Look at the Past, Present, and Future of SQL Standards", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"w953o0sukeia1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/w953o0sukeia1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7a69ed3036aa697781bff8a8ca53307ec3a7284"}, {"y": 108, "x": 216, "u": "https://preview.redd.it/w953o0sukeia1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4455daad9ff1a72855a158605f2f80698db2e93b"}, {"y": 160, "x": 320, "u": "https://preview.redd.it/w953o0sukeia1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5302bd6af2f3bc780c0acc47297d5a9bc0dd33e0"}, {"y": 320, "x": 640, "u": "https://preview.redd.it/w953o0sukeia1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f948110d61eae32aac5e59c64ded82abe3aa7f44"}, {"y": 480, "x": 960, "u": "https://preview.redd.it/w953o0sukeia1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d3ebb0d7356cd5701a6e04f5e6e6d02845d03936"}, {"y": 540, "x": 1080, "u": "https://preview.redd.it/w953o0sukeia1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf45919883bd7338cebc0ca4337986789b6e4553"}], "s": {"y": 1568, "x": 3136, "u": "https://preview.redd.it/w953o0sukeia1.jpg?width=3136&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7faa01ad856bb983564cc05c649d755d9d07bc5d"}, "id": "w953o0sukeia1"}}, "name": "t3_11365yo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/bC5Cu5pGGZi2AOMbTc7_wH3X0LYw6z7ehQMCnXEtS80.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676488958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The first version of SQL, SQL-86, was released in 1986 by the American National Standards Institute (ANSI) and the International Organization for Standardization (ISO). Since then, there have been several updates to the standard, including SQL-92, SQL-99, and SQL-2003.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested in learning about the evolution of SQL over years and how it got to its current place, please check my article published in Level Up Coding publication. In this article, I am going to take a look at the SQL Standard, as well as popular implementations of SQL such as MySQL, PostgreSQL, MS SQL Server, Oracle, and SQLite. I will explore the features and capabilities of each, as well as any limitations or drawbacks.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://levelup.gitconnected.com/the-evolution-of-sql-a-look-at-the-past-present-and-future-of-sql-standards-2326cddf7a45\"&gt;https://levelup.gitconnected.com/the-evolution-of-sql-a-look-at-the-past-present-and-future-of-sql-standards-2326cddf7a45&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/w953o0sukeia1.jpg?width=3136&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7faa01ad856bb983564cc05c649d755d9d07bc5d\"&gt;https://preview.redd.it/w953o0sukeia1.jpg?width=3136&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7faa01ad856bb983564cc05c649d755d9d07bc5d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11365yo", "is_robot_indexable": true, "report_reasons": null, "author": "sdmohajer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11365yo/the_evolution_of_sql_a_look_at_the_past_present/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11365yo/the_evolution_of_sql_a_look_at_the_past_present/", "subreddit_subscribers": 89701, "created_utc": 1676488958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Not a data engineer and am looking for some advice. Currently at my work we create R applications pulling directly from a vendor database. The queries for our current applications aren't that large so we query the DB directly but I would like to try and speed things up. I am looking to optimize our workflow and am thinking of trying the following:\n\n- Copy the db tables into our data warehouse nightly\n- Create custom tables for our applications that run nightly in a \"data mart\"\n\nThis would allow our applications to hit the data mart tables instead of running the entire queries which would significantly speed up load times. Does this approach seem correct? Is there a better way of handling this?", "author_fullname": "t2_10g3u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on best practices for ETL process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1135fwu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676487064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not a data engineer and am looking for some advice. Currently at my work we create R applications pulling directly from a vendor database. The queries for our current applications aren&amp;#39;t that large so we query the DB directly but I would like to try and speed things up. I am looking to optimize our workflow and am thinking of trying the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Copy the db tables into our data warehouse nightly&lt;/li&gt;\n&lt;li&gt;Create custom tables for our applications that run nightly in a &amp;quot;data mart&amp;quot;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This would allow our applications to hit the data mart tables instead of running the entire queries which would significantly speed up load times. Does this approach seem correct? Is there a better way of handling this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1135fwu", "is_robot_indexable": true, "report_reasons": null, "author": "pf903", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1135fwu/question_on_best_practices_for_etl_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1135fwu/question_on_best_practices_for_etl_process/", "subreddit_subscribers": 89701, "created_utc": 1676487064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm learning DE and sincerely am kinda lost in the tools, so i'm struggling to start a new solo project (watched two Darshil Parmar's projects). So i asked ChatGPT a recommendation and it gives me the following:\n\n1. **Data source:** kaggle dataset\n2. **Storage:** PostgreSQL\n3. **Data modeling**\n4. **Process Data with Spark**\n\n&amp;#x200B;\n\nOk, but too simple (?) i would like to improve this project by ingesting data to a modern dw/data lake/data lakehouse, I also want to use AWS, so i'll use EC2 instance to postgre.\n\nI recently had an overview on AWS Redshift, but would it be better using snowflake or any other technology? \n\nCould you improve the idea of this project? if possible, recommend me good kaggle datasets or an API for the data source, anyway, i'll be very grateful for any suggestion you have. I'm trying to learn in an efficient way.", "author_fullname": "t2_9fkl3gdn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ChatGPT recommended me a first project and I want your opinion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1134zhk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676485917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m learning DE and sincerely am kinda lost in the tools, so i&amp;#39;m struggling to start a new solo project (watched two Darshil Parmar&amp;#39;s projects). So i asked ChatGPT a recommendation and it gives me the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Data source:&lt;/strong&gt; kaggle dataset&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Storage:&lt;/strong&gt; PostgreSQL&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data modeling&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Process Data with Spark&lt;/strong&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Ok, but too simple (?) i would like to improve this project by ingesting data to a modern dw/data lake/data lakehouse, I also want to use AWS, so i&amp;#39;ll use EC2 instance to postgre.&lt;/p&gt;\n\n&lt;p&gt;I recently had an overview on AWS Redshift, but would it be better using snowflake or any other technology? &lt;/p&gt;\n\n&lt;p&gt;Could you improve the idea of this project? if possible, recommend me good kaggle datasets or an API for the data source, anyway, i&amp;#39;ll be very grateful for any suggestion you have. I&amp;#39;m trying to learn in an efficient way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1134zhk", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished_Emu9409", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1134zhk/chatgpt_recommended_me_a_first_project_and_i_want/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1134zhk/chatgpt_recommended_me_a_first_project_and_i_want/", "subreddit_subscribers": 89701, "created_utc": 1676485917.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}