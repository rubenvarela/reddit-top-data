{"kind": "Listing", "data": {"after": null, "dist": 18, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2tv9i42n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "8 Key Data Structures That Power Modern Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_10uhjfg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": "#46d160", "ups": 65, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W_v05d_2RTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"8 Key Data Structures That Power Modern Databases\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "8 Key Data Structures That Power Modern Databases", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W_v05d_2RTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"8 Key Data Structures That Power Modern Databases\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W_v05d_2RTo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W_v05d_2RTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"8 Key Data Structures That Power Modern Databases\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/10uhjfg", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 65, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zY0b9zsXDpbRf4m_tPBmFKYlKJ6MSVOij3Tfm06fdVg.jpg", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675616973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/W_v05d_2RTo", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dbJ3NYIMGPA-tUGeY-cL9GBgtPbMOSoYKQMC4g828uY.jpg?auto=webp&amp;v=enabled&amp;s=36fd6f07ef58b45a2cd4c607c0259c4f3146866a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/dbJ3NYIMGPA-tUGeY-cL9GBgtPbMOSoYKQMC4g828uY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8078f2ad7b737b1dad91897dd3e9d27f557a65be", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/dbJ3NYIMGPA-tUGeY-cL9GBgtPbMOSoYKQMC4g828uY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33b49517a2ffaa921a06edeb42cb716b26c90f96", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/dbJ3NYIMGPA-tUGeY-cL9GBgtPbMOSoYKQMC4g828uY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=abdfd844cefa928050fbb186669a1f488e1e5895", "width": 320, "height": 240}], "variants": {}, "id": "YlNv470TRLtro5y24MpTmp3uzYVNCkTm5WFEoIAKU44"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod | Sr. Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10uhjfg", "is_robot_indexable": true, "report_reasons": null, "author": "theporterhaus", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/10uhjfg/8_key_data_structures_that_power_modern_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/W_v05d_2RTo", "subreddit_subscribers": 88621, "created_utc": 1675616973.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "8 Key Data Structures That Power Modern Databases", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W_v05d_2RTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"8 Key Data Structures That Power Modern Databases\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W_v05d_2RTo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in the job market for a Full Time role as a Sr. Data Engineer. I'm currently consulting for two companies and want a role with benefits at the moment. I absolutely bombed a hackerrank test from one company. I hadn't touched any practice problems since March of last year when I interviewed for Meta. They gave me 24 hours to complete the assessment, so it went as expected.\n\nI got asked by another company to complete a CodeSignal assessment. I spend about 10 hours today going through EASY practice problems on all of the sites in the subject line and couldn't complete a single question without help. I'm sure with time it would get better, but working 10-12 hours a day does not offer that kind of time for me.\n\nPeople here will say that a Data Engineer unable to complete these problems is not an engineer. Maybe, maybe not. I have a degree in Business Administration and taught myself everything I know, so I'd be quick to admit I'm not an engineer through studies. Mentorship has been essentially non-existent since starting my data career in 2015, so I'm certainly not a refined programmer. Can you throw just about any database, data streaming, or AWS problem at me to solve? Sure, if it has a practical business outcome.\n\nI was feeling really depressed (and actually questioning my entire career) after spinning my wheels all day today with these weird problems until I realized that these companies are looking for a Software Engineer with experience in databases AND cloud technologies. That's a pretty specific set of candidates IMO.\n\nI'm writing the above to encourage anyone who has the time (still in school, in a bootcamp, or plenty of free time) to grind out whatever you need to on these sites for a really well paying job. However, if you're feeling discouraged, know that this stuff is insanely hard even with on the job experience under your belt. Practice obviously is key to succeeding in this interviewing world we're in. For those of us with experience who are feeling discouraged, like myself, my advice would be to turn down these interviews. I just did. It's dehumanizing and these questions have no real-world application as a DE as far as I can see. Companies can see 8 years of SQL, Python, and Machine Learning experience on my resume; but, because I have no clue how to write an algorithm to convert roman numerals to integers, they couldn't care less about me. \n\nI'm boycotting these assessments for the time being. I'm not a great student, not great with theory, and definitely not book smart, so this is like asking a fish to climb a tree. I enjoy all aspects of the \"practical\" database world and enjoy solving a business problem with python, but I do not enjoy finding patterns in algo questions and learning how to repeat that just to get through an interview.", "author_fullname": "t2_52terfle", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leetcode/Hackerrank/CodeSignal Opinion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u15l8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_3": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675571086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the job market for a Full Time role as a Sr. Data Engineer. I&amp;#39;m currently consulting for two companies and want a role with benefits at the moment. I absolutely bombed a hackerrank test from one company. I hadn&amp;#39;t touched any practice problems since March of last year when I interviewed for Meta. They gave me 24 hours to complete the assessment, so it went as expected.&lt;/p&gt;\n\n&lt;p&gt;I got asked by another company to complete a CodeSignal assessment. I spend about 10 hours today going through EASY practice problems on all of the sites in the subject line and couldn&amp;#39;t complete a single question without help. I&amp;#39;m sure with time it would get better, but working 10-12 hours a day does not offer that kind of time for me.&lt;/p&gt;\n\n&lt;p&gt;People here will say that a Data Engineer unable to complete these problems is not an engineer. Maybe, maybe not. I have a degree in Business Administration and taught myself everything I know, so I&amp;#39;d be quick to admit I&amp;#39;m not an engineer through studies. Mentorship has been essentially non-existent since starting my data career in 2015, so I&amp;#39;m certainly not a refined programmer. Can you throw just about any database, data streaming, or AWS problem at me to solve? Sure, if it has a practical business outcome.&lt;/p&gt;\n\n&lt;p&gt;I was feeling really depressed (and actually questioning my entire career) after spinning my wheels all day today with these weird problems until I realized that these companies are looking for a Software Engineer with experience in databases AND cloud technologies. That&amp;#39;s a pretty specific set of candidates IMO.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m writing the above to encourage anyone who has the time (still in school, in a bootcamp, or plenty of free time) to grind out whatever you need to on these sites for a really well paying job. However, if you&amp;#39;re feeling discouraged, know that this stuff is insanely hard even with on the job experience under your belt. Practice obviously is key to succeeding in this interviewing world we&amp;#39;re in. For those of us with experience who are feeling discouraged, like myself, my advice would be to turn down these interviews. I just did. It&amp;#39;s dehumanizing and these questions have no real-world application as a DE as far as I can see. Companies can see 8 years of SQL, Python, and Machine Learning experience on my resume; but, because I have no clue how to write an algorithm to convert roman numerals to integers, they couldn&amp;#39;t care less about me. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m boycotting these assessments for the time being. I&amp;#39;m not a great student, not great with theory, and definitely not book smart, so this is like asking a fish to climb a tree. I enjoy all aspects of the &amp;quot;practical&amp;quot; database world and enjoy solving a business problem with python, but I do not enjoy finding patterns in algo questions and learning how to repeat that just to get through an interview.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": 31, "coin_price": 1800, "id": "gid_3", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/platinum_512.png", "days_of_premium": 31, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/platinum_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 700 Reddit Coins and a month of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Platinum", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/platinum_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/platinum_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10u15l8", "is_robot_indexable": true, "report_reasons": null, "author": "figgidius", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10u15l8/leetcodehackerrankcodesignal_opinion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10u15l8/leetcodehackerrankcodesignal_opinion/", "subreddit_subscribers": 88621, "created_utc": 1675571086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, what's the situation with the job market right now? Have any of you received callbacks for job interviews? How many job applications have you submitted and how many interviews did you get? I feel like the job market is really dry right now. I have been applying for jobs but haven't heard back.\nDo you think one should utilise this time to prep for the interviews and keep improving skills till the job market gets stable or continue applying?", "author_fullname": "t2_7m65ddby", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current Job Market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10udqar", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675607289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, what&amp;#39;s the situation with the job market right now? Have any of you received callbacks for job interviews? How many job applications have you submitted and how many interviews did you get? I feel like the job market is really dry right now. I have been applying for jobs but haven&amp;#39;t heard back.\nDo you think one should utilise this time to prep for the interviews and keep improving skills till the job market gets stable or continue applying?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10udqar", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Ball_965", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10udqar/current_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10udqar/current_job_market/", "subreddit_subscribers": 88621, "created_utc": 1675607289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Made it through to the second round of interviews for an entry level Data Engineering role. First interview was all SQL, which I\u2019m mostly comfortable with since as current Business Analyst, I use it in my day to day. Within one problem I had to demo Joins, aggregate functions, CASE statements, CTE and Window Functions. \n\nI was notified that for the second interview it will be Python which I have a very general, very basic understanding of. What in your opinion should I expect for the Python interview? I\u2019m looking to determine which areas of Python I should spend my time studying and practicing before the interview. Please note that this is an Entry level role, and the hiring manager did mention that the person hired would spend most of the time working with SQL. I\u2019m not sure what to expect, so not sure where I should spend my time on. What in your opinion are the Python foundations for DE?", "author_fullname": "t2_ry76f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10um7h4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675628098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Made it through to the second round of interviews for an entry level Data Engineering role. First interview was all SQL, which I\u2019m mostly comfortable with since as current Business Analyst, I use it in my day to day. Within one problem I had to demo Joins, aggregate functions, CASE statements, CTE and Window Functions. &lt;/p&gt;\n\n&lt;p&gt;I was notified that for the second interview it will be Python which I have a very general, very basic understanding of. What in your opinion should I expect for the Python interview? I\u2019m looking to determine which areas of Python I should spend my time studying and practicing before the interview. Please note that this is an Entry level role, and the hiring manager did mention that the person hired would spend most of the time working with SQL. I\u2019m not sure what to expect, so not sure where I should spend my time on. What in your opinion are the Python foundations for DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10um7h4", "is_robot_indexable": true, "report_reasons": null, "author": "CosmicNightmare", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10um7h4/python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10um7h4/python/", "subreddit_subscribers": 88621, "created_utc": 1675628098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you structure (and name) your Airflow dags? \n\nFor example, we have a dag that runs an ingestion from all different sources at EOD. Then there is another dag that (creates some data aggregates) has an external sensor and when the first dag is finished, this starts its run. \n\nThe problem I have with it is when I need to reload only few parts of ingestion dag and then following parts of the aggregates dag, it is too slow, manual work and not error prone (or I would have to rerun entire dags). I am thinking of building a \u201chorizontal\u201d dag instead of this \u201cvertical\u201d one, meaning one dag would have one source and all its dependencies. Or another way would be to have one gigantic dag (probably not good option).\n\nHow do you structure your dags? Also do you name it like e.g. \u201clanding layer\u201d/ingestion/raw/data lake/L0 and then \u201ccurated\u201d/silver/warehouse/L1?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow dags - structure and naming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u8b6g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675587947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you structure (and name) your Airflow dags? &lt;/p&gt;\n\n&lt;p&gt;For example, we have a dag that runs an ingestion from all different sources at EOD. Then there is another dag that (creates some data aggregates) has an external sensor and when the first dag is finished, this starts its run. &lt;/p&gt;\n\n&lt;p&gt;The problem I have with it is when I need to reload only few parts of ingestion dag and then following parts of the aggregates dag, it is too slow, manual work and not error prone (or I would have to rerun entire dags). I am thinking of building a \u201chorizontal\u201d dag instead of this \u201cvertical\u201d one, meaning one dag would have one source and all its dependencies. Or another way would be to have one gigantic dag (probably not good option).&lt;/p&gt;\n\n&lt;p&gt;How do you structure your dags? Also do you name it like e.g. \u201clanding layer\u201d/ingestion/raw/data lake/L0 and then \u201ccurated\u201d/silver/warehouse/L1?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10u8b6g", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10u8b6g/airflow_dags_structure_and_naming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10u8b6g/airflow_dags_structure_and_naming/", "subreddit_subscribers": 88621, "created_utc": 1675587947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've looked in the wiki. There's a nice brief but I'm looking for a more in depth write up, video, book, etc regarding setting up a data lake. Any pointers to some? Or any personal anecdotes and lessons learned?", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have a pointer to a more technical reference for creating a data lake from scratch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ufwvb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675612935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve looked in the wiki. There&amp;#39;s a nice brief but I&amp;#39;m looking for a more in depth write up, video, book, etc regarding setting up a data lake. Any pointers to some? Or any personal anecdotes and lessons learned?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ufwvb", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ufwvb/anyone_have_a_pointer_to_a_more_technical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ufwvb/anyone_have_a_pointer_to_a_more_technical/", "subreddit_subscribers": 88621, "created_utc": 1675612935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I\u2019m currently a senior data analyst and I\u2019m looking to make the move to the DE side. My day to day deals with SQL, Power BI and some python for the manipulation of datasets. Started being involved with some DE projects and it seemed very interesting. Can you guys recommend the best books or material for me to learn the basics of DE?", "author_fullname": "t2_202bqogr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best books or material to learn the basics of data engineering.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uu1j4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675647494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I\u2019m currently a senior data analyst and I\u2019m looking to make the move to the DE side. My day to day deals with SQL, Power BI and some python for the manipulation of datasets. Started being involved with some DE projects and it seemed very interesting. Can you guys recommend the best books or material for me to learn the basics of DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uu1j4", "is_robot_indexable": true, "report_reasons": null, "author": "lramirez27", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uu1j4/best_books_or_material_to_learn_the_basics_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uu1j4/best_books_or_material_to_learn_the_basics_of/", "subreddit_subscribers": 88621, "created_utc": 1675647494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\\[Databricks newbie here\\] Hello, I need to download lots (a few tens of thousands) of datasets from Databricks (I need to train a ML model), and I am looking for a way to make it fast. Does anyone have suggestions on how to proceed?\n\nAt the moment my procedure is the following:\n\n1. Retrieve dataframe using \\`spark.sql\\`\n2. Select the dataframe column which we want to consider\n3. Display dataframe and save result\n\nI also tried using \\`df1.coalesce(1, shuffle = true).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"dbfs:/FileStore/user/me/output.csv\")\\` but it's unbearably slow.\n\nWhat is the recommended way to retrieve data and export it fast? Thank you.", "author_fullname": "t2_c75nc3n7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a fast way to get lots of data from Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10udui5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675613529.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675607602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[Databricks newbie here] Hello, I need to download lots (a few tens of thousands) of datasets from Databricks (I need to train a ML model), and I am looking for a way to make it fast. Does anyone have suggestions on how to proceed?&lt;/p&gt;\n\n&lt;p&gt;At the moment my procedure is the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Retrieve dataframe using `spark.sql`&lt;/li&gt;\n&lt;li&gt;Select the dataframe column which we want to consider&lt;/li&gt;\n&lt;li&gt;Display dataframe and save result&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I also tried using `df1.coalesce(1, shuffle = true).write.format(&amp;quot;com.databricks.spark.csv&amp;quot;).option(&amp;quot;header&amp;quot;, &amp;quot;true&amp;quot;).save(&amp;quot;dbfs:/FileStore/user/me/output.csv&amp;quot;)` but it&amp;#39;s unbearably slow.&lt;/p&gt;\n\n&lt;p&gt;What is the recommended way to retrieve data and export it fast? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10udui5", "is_robot_indexable": true, "report_reasons": null, "author": "BackgroundPass2082", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10udui5/looking_for_a_fast_way_to_get_lots_of_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10udui5/looking_for_a_fast_way_to_get_lots_of_data_from/", "subreddit_subscribers": 88621, "created_utc": 1675607602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I've been lucky enough to have received 3 data engineering internship offers for this summer which are giving me a tough time making a decision. Any advice would be appreciated.\n\nAbout me: SWE student with 2 C++ internships under my belt. While I do know basic data engineering concepts (Data lake/warehouse, ETL, APIs, data pipeline, etc.), I don't really have experience using any data tools and technologies. I'm really just looking for the option that will give me the best start towards the data engineer path.\n\n&amp;#x200B;\n\nCompany A: Medium-sized company specializing in wealth management solutions.\n\n\\- Tech stack: Python, SQL, Airflow, Db2, TFS\n\n\\- Pay: 22$/h\n\n\\- Remote\n\n\\- Small team of 2 data engineers, 1 tech lead and 1 manager. \n\n&amp;#x200B;\n\nCompany B: small-sized consulting company specializing in delivering AI solutions to businesses.\n\n\\- Tech stack: depends on the client's needs but the team said it is often Python, Spark, Databricks, Azure, Git, Kedro\n\n\\- Pay: 25$/h\n\n\\- Remote\n\n\\- Small team of 1 data engineer, 2 data scientists and 1 manager. \n\n&amp;#x200B;\n\nCompany C: large-sized company specializing in conversational AI solutions.\n\n\\- Tech stack: Java, Spark, Azure Databricks, Delta Lake, Git, Kafka, Spring\n\n\\- Pay: 25$/h\n\n\\- Remote\n\n\\- Team size: 9-10", "author_fullname": "t2_58yrswvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for choosing between internship offers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uke9m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675623752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve been lucky enough to have received 3 data engineering internship offers for this summer which are giving me a tough time making a decision. Any advice would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;About me: SWE student with 2 C++ internships under my belt. While I do know basic data engineering concepts (Data lake/warehouse, ETL, APIs, data pipeline, etc.), I don&amp;#39;t really have experience using any data tools and technologies. I&amp;#39;m really just looking for the option that will give me the best start towards the data engineer path.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Company A: Medium-sized company specializing in wealth management solutions.&lt;/p&gt;\n\n&lt;p&gt;- Tech stack: Python, SQL, Airflow, Db2, TFS&lt;/p&gt;\n\n&lt;p&gt;- Pay: 22$/h&lt;/p&gt;\n\n&lt;p&gt;- Remote&lt;/p&gt;\n\n&lt;p&gt;- Small team of 2 data engineers, 1 tech lead and 1 manager. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Company B: small-sized consulting company specializing in delivering AI solutions to businesses.&lt;/p&gt;\n\n&lt;p&gt;- Tech stack: depends on the client&amp;#39;s needs but the team said it is often Python, Spark, Databricks, Azure, Git, Kedro&lt;/p&gt;\n\n&lt;p&gt;- Pay: 25$/h&lt;/p&gt;\n\n&lt;p&gt;- Remote&lt;/p&gt;\n\n&lt;p&gt;- Small team of 1 data engineer, 2 data scientists and 1 manager. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Company C: large-sized company specializing in conversational AI solutions.&lt;/p&gt;\n\n&lt;p&gt;- Tech stack: Java, Spark, Azure Databricks, Delta Lake, Git, Kafka, Spring&lt;/p&gt;\n\n&lt;p&gt;- Pay: 25$/h&lt;/p&gt;\n\n&lt;p&gt;- Remote&lt;/p&gt;\n\n&lt;p&gt;- Team size: 9-10&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10uke9m", "is_robot_indexable": true, "report_reasons": null, "author": "Promettre", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uke9m/advice_for_choosing_between_internship_offers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uke9m/advice_for_choosing_between_internship_offers/", "subreddit_subscribers": 88621, "created_utc": 1675623752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm quite new to data engineering but I'm doing more of it at work (started out as a data analyst but the role involves more and more engineering stuff). We use AWS - most of our pipeline is made up of a bunch of python Lambdas and a script that runs in an EC2 instance, and it's orchestrated using Step Functions.\n\nI'm aware that Airflow is a standard tool for organising data pipelines but I'm confused about when I should be thinking about using it. Given I'm using  AWS Step Functions, what exactly would I get out of using Airflow? And given that most companies are using cloud platforms that presumably have similar services, why is Airflow still used? Is it that it is more transferrable if we choose to migrate to GCP or Azure or whatever?  I feel like I'm missing something here.", "author_fullname": "t2_1znkakv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow vs AWS Step Functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ujaxk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675621188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m quite new to data engineering but I&amp;#39;m doing more of it at work (started out as a data analyst but the role involves more and more engineering stuff). We use AWS - most of our pipeline is made up of a bunch of python Lambdas and a script that runs in an EC2 instance, and it&amp;#39;s orchestrated using Step Functions.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that Airflow is a standard tool for organising data pipelines but I&amp;#39;m confused about when I should be thinking about using it. Given I&amp;#39;m using  AWS Step Functions, what exactly would I get out of using Airflow? And given that most companies are using cloud platforms that presumably have similar services, why is Airflow still used? Is it that it is more transferrable if we choose to migrate to GCP or Azure or whatever?  I feel like I&amp;#39;m missing something here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ujaxk", "is_robot_indexable": true, "report_reasons": null, "author": "Psychological-Suit-5", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ujaxk/airflow_vs_aws_step_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ujaxk/airflow_vs_aws_step_functions/", "subreddit_subscribers": 88621, "created_utc": 1675621188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!  \nI'm looking for a managed service/tool that can call an API and ingest it into a datawarehouse(Snowflake).  \n\n\nHope that anyone can help me in the right direction \ud83e\udd1e", "author_fullname": "t2_oeiyrmpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managed service for API calls", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uhri4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675617506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;br/&gt;\nI&amp;#39;m looking for a managed service/tool that can call an API and ingest it into a datawarehouse(Snowflake).  &lt;/p&gt;\n\n&lt;p&gt;Hope that anyone can help me in the right direction \ud83e\udd1e&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uhri4", "is_robot_indexable": true, "report_reasons": null, "author": "formaldehyden", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uhri4/managed_service_for_api_calls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uhri4/managed_service_for_api_calls/", "subreddit_subscribers": 88621, "created_utc": 1675617506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a cross-post from \"r/learnpython\", but I thought this community might have more relevant experience and insights. I just started learning Python, and am trying to simulate some scenarios I might encounter in my job as a Data Engineer (mostly ETL-related). I'm ready to try to set up my first official \"Project\" for reading a certain category of flat files and loading them to a DB. Does anyone have any advice or good articles on how to structure things properly for Prod / Non-Prod activities?\n\nFor example, I'm going to build a separate module to create my SQL Alchemy engine objects that can be reused for multiple sources / targets / environments. What might be a good way to specify if I want a Dev or a Prod connection back? Do you pass a parameter into the module? Use configuration files and have the module figure out which environment it is running in? Or maybe something like different virtual environments for Dev and Prod? Any advice or insight would be greatly appreciated!", "author_fullname": "t2_14wbya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Prod / Non-Prod Configuration Advice for Python ETL Jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ucw8n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675604990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a cross-post from &amp;quot;&lt;a href=\"/r/learnpython\"&gt;r/learnpython&lt;/a&gt;&amp;quot;, but I thought this community might have more relevant experience and insights. I just started learning Python, and am trying to simulate some scenarios I might encounter in my job as a Data Engineer (mostly ETL-related). I&amp;#39;m ready to try to set up my first official &amp;quot;Project&amp;quot; for reading a certain category of flat files and loading them to a DB. Does anyone have any advice or good articles on how to structure things properly for Prod / Non-Prod activities?&lt;/p&gt;\n\n&lt;p&gt;For example, I&amp;#39;m going to build a separate module to create my SQL Alchemy engine objects that can be reused for multiple sources / targets / environments. What might be a good way to specify if I want a Dev or a Prod connection back? Do you pass a parameter into the module? Use configuration files and have the module figure out which environment it is running in? Or maybe something like different virtual environments for Dev and Prod? Any advice or insight would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ucw8n", "is_robot_indexable": true, "report_reasons": null, "author": "phobia42", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ucw8n/seeking_prod_nonprod_configuration_advice_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ucw8n/seeking_prod_nonprod_configuration_advice_for/", "subreddit_subscribers": 88621, "created_utc": 1675604990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, I am extremely new to dagster and I couldn't find any information about the questions I have. Basically I want to know 2 things:  \n\n\n1. Can you trigger a dagster pipeline via an api call? Can I integrate this with other API libraries like FastAPI or Django REST?\n2. Can I pass data via path- or get-params in the api call to the asset functions themselves?\n\nMore info in this [stackoverflow post I made](https://stackoverflow.com/questions/75350111/dagster-can-you-trigger-a-job-to-run-via-an-api), but basically I have a pipeline that is written in pure python, that receives a player's username via an api call, and then runs the entire pipeline to get all the data for *that particular player only.* I want to know if this is possible, or if dagster is only good for data that doesn't require pre-defined parameters\n\nAny help is greatly appreciated, thanks!", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to trigger a dagster pipeline from an api endpoint, and also pass metadata/data via get params to some of the assets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uok0y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675633671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I am extremely new to dagster and I couldn&amp;#39;t find any information about the questions I have. Basically I want to know 2 things:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can you trigger a dagster pipeline via an api call? Can I integrate this with other API libraries like FastAPI or Django REST?&lt;/li&gt;\n&lt;li&gt;Can I pass data via path- or get-params in the api call to the asset functions themselves?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;More info in this &lt;a href=\"https://stackoverflow.com/questions/75350111/dagster-can-you-trigger-a-job-to-run-via-an-api\"&gt;stackoverflow post I made&lt;/a&gt;, but basically I have a pipeline that is written in pure python, that receives a player&amp;#39;s username via an api call, and then runs the entire pipeline to get all the data for &lt;em&gt;that particular player only.&lt;/em&gt; I want to know if this is possible, or if dagster is only good for data that doesn&amp;#39;t require pre-defined parameters&lt;/p&gt;\n\n&lt;p&gt;Any help is greatly appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;v=enabled&amp;s=19b4a59f036ea2f314ff2033c11e54cdc240f8d8", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d93e783257998ff2ed865c359d9a00312a5412d7", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90216f7dc897a869ee852791bafa1e00667cdf07", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uok0y", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uok0y/is_there_a_way_to_trigger_a_dagster_pipeline_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uok0y/is_there_a_way_to_trigger_a_dagster_pipeline_from/", "subreddit_subscribers": 88621, "created_utc": 1675633671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For a data analysis job I need a OLAP database. I\u2018m considering Druid because it\u2019s scalable, real-time and can use mini.io as deep storage. Because we use min.io, this is a nice feature. \n\nDo you have any experiences with the challenges Druid puts onto you team or good advices for alternatives? From what I see, managing the cluster could be a bigger effort.", "author_fullname": "t2_s3omzbn3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your OLAP Database recommendation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ulbai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675625954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a data analysis job I need a OLAP database. I\u2018m considering Druid because it\u2019s scalable, real-time and can use mini.io as deep storage. Because we use min.io, this is a nice feature. &lt;/p&gt;\n\n&lt;p&gt;Do you have any experiences with the challenges Druid puts onto you team or good advices for alternatives? From what I see, managing the cluster could be a bigger effort.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ulbai", "is_robot_indexable": true, "report_reasons": null, "author": "ZenCoding", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ulbai/whats_your_olap_database_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ulbai/whats_your_olap_database_recommendation/", "subreddit_subscribers": 88621, "created_utc": 1675625954.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Everybody,\n\nNeeded input on how best to transfer almost 2 TBs of data from an on-prem Teradata server to Bigquery, on a daily basis.\n\nHere are some considerations:\n\n1. The data should be transferred in a secure manner\n2. The process should have the ability to do both full and delta loads\n3. As inexpensive as possible\n\nAll feedback and comments welcome :)", "author_fullname": "t2_pxuosxo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On-prem Teradata to BQ Data Transfer pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10uvf5r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675651351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Everybody,&lt;/p&gt;\n\n&lt;p&gt;Needed input on how best to transfer almost 2 TBs of data from an on-prem Teradata server to Bigquery, on a daily basis.&lt;/p&gt;\n\n&lt;p&gt;Here are some considerations:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The data should be transferred in a secure manner&lt;/li&gt;\n&lt;li&gt;The process should have the ability to do both full and delta loads&lt;/li&gt;\n&lt;li&gt;As inexpensive as possible&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;All feedback and comments welcome :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10uvf5r", "is_robot_indexable": true, "report_reasons": null, "author": "deezelmunky", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uvf5r/onprem_teradata_to_bq_data_transfer_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uvf5r/onprem_teradata_to_bq_data_transfer_pipeline/", "subreddit_subscribers": 88621, "created_utc": 1675651351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, \nI'm looking for an open-source data lineage app (e.g. [tokern](https://open-metadata.org/), [datahubproject](https://datahubproject.io/), [openmetadata](https://open-metadata.org/)).  \n\nThe key issue is that in addition to automatic ingestion  connectors or deriving schemas from queries, **the tool should also have a friendly way of adding objects and their relationships from something like a csv or json file.**\n\nContext: company has been documenting all its data objects manually and has a large csv explicitly showing each data object and its predescessor/s. These aren't just the standard  database/workflow/dashboard objects; these include things like power automate scripts.  I'm just looking for a good way to show everything in a map, visualize them, and navigate through their connections properly)\n\nAt this point, I'll even be happy with a pure visualization engine, like for instance if I can repurpose [kedro-viz](https://github.com/kedro-org/kedro-viz) or [dbt's](https://docs.getdbt.com/docs/build/python-models) lineage visualizer so that it can take a csv or json of object relationships as an input.   Or even a custom power BI visualization or python graph frontend would be fine, but I can't seem to see one that works.  I'd also be happy if any of the aforementioned lineage tools I mentioned above have this functionality and I just missed it.\n\nThanks everyone!", "author_fullname": "t2_4xg4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for an open-source data lineage app, where objects and connections can be manually defined (not just automatically ingested)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10usa5i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675643058.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675642860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, \nI&amp;#39;m looking for an open-source data lineage app (e.g. &lt;a href=\"https://open-metadata.org/\"&gt;tokern&lt;/a&gt;, &lt;a href=\"https://datahubproject.io/\"&gt;datahubproject&lt;/a&gt;, &lt;a href=\"https://open-metadata.org/\"&gt;openmetadata&lt;/a&gt;).  &lt;/p&gt;\n\n&lt;p&gt;The key issue is that in addition to automatic ingestion  connectors or deriving schemas from queries, &lt;strong&gt;the tool should also have a friendly way of adding objects and their relationships from something like a csv or json file.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Context: company has been documenting all its data objects manually and has a large csv explicitly showing each data object and its predescessor/s. These aren&amp;#39;t just the standard  database/workflow/dashboard objects; these include things like power automate scripts.  I&amp;#39;m just looking for a good way to show everything in a map, visualize them, and navigate through their connections properly)&lt;/p&gt;\n\n&lt;p&gt;At this point, I&amp;#39;ll even be happy with a pure visualization engine, like for instance if I can repurpose &lt;a href=\"https://github.com/kedro-org/kedro-viz\"&gt;kedro-viz&lt;/a&gt; or &lt;a href=\"https://docs.getdbt.com/docs/build/python-models\"&gt;dbt&amp;#39;s&lt;/a&gt; lineage visualizer so that it can take a csv or json of object relationships as an input.   Or even a custom power BI visualization or python graph frontend would be fine, but I can&amp;#39;t seem to see one that works.  I&amp;#39;d also be happy if any of the aforementioned lineage tools I mentioned above have this functionality and I just missed it.&lt;/p&gt;\n\n&lt;p&gt;Thanks everyone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ntYU6Ou1ez-oMJPwzMpA2muqo-5TYgKpQ1CdS81RNfs.jpg?auto=webp&amp;v=enabled&amp;s=9948f8addaa2e47ee79511ae45cff1d9245dc66a", "width": 310, "height": 310}, "resolutions": [{"url": "https://external-preview.redd.it/ntYU6Ou1ez-oMJPwzMpA2muqo-5TYgKpQ1CdS81RNfs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e33b566892d18b692a63009505235b2706b86fd6", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ntYU6Ou1ez-oMJPwzMpA2muqo-5TYgKpQ1CdS81RNfs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc7224a6096e18b8bfa81e39e73c18df5bc11a3c", "width": 216, "height": 216}], "variants": {}, "id": "HAPFDFRRMoP2a9fJFsIVmEt8sTvE02WcjtCO87LuE3s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10usa5i", "is_robot_indexable": true, "report_reasons": null, "author": "efofecks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10usa5i/looking_for_an_opensource_data_lineage_app_where/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10usa5i/looking_for_an_opensource_data_lineage_app_where/", "subreddit_subscribers": 88621, "created_utc": 1675642860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Context: I am a somewhat experienced (9 years) generalist engineer, working on a data engineering project centering around the usage of Apache Hudi. My problem does not lend itself to partitioning, and I am having trouble getting my solution to perform adequately with a non-partitioned table using SIMPLE indexing. I am considering implementing my own index that is optimized for my use case. I am hesitant, because this is not an area of expertise of mine, and I doubt that I will be able to implement a satisfactory solution.\n\nMy question -- to anyone who has done such an implementation or knows what it entails -- is whether this seems like a path I should even proceed, given that I am by no means an expert in big data or data engineering. I'm definitely more fluent and experienced than your average engineer, but far from knowing enough about the internals of Hudi to consider contributing to their source or anything like that.\n\nFurther, if anyone has any resources at all on what this effort looks like, and/or any guidance, that would be greatly appreciated. I've found nothing online except for the API I need to implement, provided on the Hudi website.", "author_fullname": "t2_55zctcl1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feasibility of a novice building a custom Hudi indexing implementation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uqctm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675638040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I am a somewhat experienced (9 years) generalist engineer, working on a data engineering project centering around the usage of Apache Hudi. My problem does not lend itself to partitioning, and I am having trouble getting my solution to perform adequately with a non-partitioned table using SIMPLE indexing. I am considering implementing my own index that is optimized for my use case. I am hesitant, because this is not an area of expertise of mine, and I doubt that I will be able to implement a satisfactory solution.&lt;/p&gt;\n\n&lt;p&gt;My question -- to anyone who has done such an implementation or knows what it entails -- is whether this seems like a path I should even proceed, given that I am by no means an expert in big data or data engineering. I&amp;#39;m definitely more fluent and experienced than your average engineer, but far from knowing enough about the internals of Hudi to consider contributing to their source or anything like that.&lt;/p&gt;\n\n&lt;p&gt;Further, if anyone has any resources at all on what this effort looks like, and/or any guidance, that would be greatly appreciated. I&amp;#39;ve found nothing online except for the API I need to implement, provided on the Hudi website.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uqctm", "is_robot_indexable": true, "report_reasons": null, "author": "aiminghire", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uqctm/feasibility_of_a_novice_building_a_custom_hudi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uqctm/feasibility_of_a_novice_building_a_custom_hudi/", "subreddit_subscribers": 88621, "created_utc": 1675638040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you feel about your job? I'm just bringing this long lasting debate from software engineering and softwafe craftship. I feel the way it is approached could help on defining guidelines in terms of mentorship, good practices, etc\n\n[View Poll](https://www.reddit.com/poll/10uc8da)", "author_fullname": "t2_v3ifff74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Craftship or actual Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uc8da", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675603014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you feel about your job? I&amp;#39;m just bringing this long lasting debate from software engineering and softwafe craftship. I feel the way it is approached could help on defining guidelines in terms of mentorship, good practices, etc&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10uc8da\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10uc8da", "is_robot_indexable": true, "report_reasons": null, "author": "kaismd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1675775814615, "options": [{"text": "Craftship", "id": "21439441"}, {"text": "Engineering", "id": "21439442"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 57, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uc8da/craftship_or_actual_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10uc8da/craftship_or_actual_engineering/", "subreddit_subscribers": 88621, "created_utc": 1675603014.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}