{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2tv9i42n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "8 Key Data Structures That Power Modern Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_10uhjfg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "#46d160", "ups": 72, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W_v05d_2RTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"8 Key Data Structures That Power Modern Databases\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "8 Key Data Structures That Power Modern Databases", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W_v05d_2RTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"8 Key Data Structures That Power Modern Databases\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W_v05d_2RTo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W_v05d_2RTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"8 Key Data Structures That Power Modern Databases\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/10uhjfg", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zY0b9zsXDpbRf4m_tPBmFKYlKJ6MSVOij3Tfm06fdVg.jpg", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675616973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/W_v05d_2RTo", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dbJ3NYIMGPA-tUGeY-cL9GBgtPbMOSoYKQMC4g828uY.jpg?auto=webp&amp;v=enabled&amp;s=36fd6f07ef58b45a2cd4c607c0259c4f3146866a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/dbJ3NYIMGPA-tUGeY-cL9GBgtPbMOSoYKQMC4g828uY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8078f2ad7b737b1dad91897dd3e9d27f557a65be", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/dbJ3NYIMGPA-tUGeY-cL9GBgtPbMOSoYKQMC4g828uY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33b49517a2ffaa921a06edeb42cb716b26c90f96", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/dbJ3NYIMGPA-tUGeY-cL9GBgtPbMOSoYKQMC4g828uY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=abdfd844cefa928050fbb186669a1f488e1e5895", "width": 320, "height": 240}], "variants": {}, "id": "YlNv470TRLtro5y24MpTmp3uzYVNCkTm5WFEoIAKU44"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod | Sr. Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10uhjfg", "is_robot_indexable": true, "report_reasons": null, "author": "theporterhaus", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/10uhjfg/8_key_data_structures_that_power_modern_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/W_v05d_2RTo", "subreddit_subscribers": 88641, "created_utc": 1675616973.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "8 Key Data Structures That Power Modern Databases", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/W_v05d_2RTo?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"8 Key Data Structures That Power Modern Databases\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/W_v05d_2RTo/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, what's the situation with the job market right now? Have any of you received callbacks for job interviews? How many job applications have you submitted and how many interviews did you get? I feel like the job market is really dry right now. I have been applying for jobs but haven't heard back.\nDo you think one should utilise this time to prep for the interviews and keep improving skills till the job market gets stable or continue applying?", "author_fullname": "t2_7m65ddby", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current Job Market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10udqar", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675607289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, what&amp;#39;s the situation with the job market right now? Have any of you received callbacks for job interviews? How many job applications have you submitted and how many interviews did you get? I feel like the job market is really dry right now. I have been applying for jobs but haven&amp;#39;t heard back.\nDo you think one should utilise this time to prep for the interviews and keep improving skills till the job market gets stable or continue applying?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10udqar", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Ball_965", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10udqar/current_job_market/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10udqar/current_job_market/", "subreddit_subscribers": 88641, "created_utc": 1675607289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Over the past while I've been battling with some local pyspark and docker-compose setups to have better tests for CI/CD.   \nTo path to solve this problem was to try get the same level of depth of environment that runs in production in the company I work at (databricks, AWS EMR, S3, etc.) as locally  \n\n\nFigured I'd share out some of wrapped up knowledge of battling with specific Jars and hive-metastore (which you don't actually need, just a SQL database set up in certain way!) \n\nThe repo has the following features in it  \n \n\n* Quick and Easy setup for local testing and development environment and abstracting the complexity of configuring up a pyspark environment in this way\n* Full Pyspark Implementation\n* Full S3 like implementation with Minio\n* Read and write data to S3 and access them as tables and databases in Spark through metastore\n* Ability to run pytest on the pyspark container\n* Read and write with delta format\n* Example of testing pyspark code with either unittest or pytest\n* Consistent environment for testing and development with docker-compose and poetry\n* Ability to run tests on push with github actions  \n\n\nIf I've missed anything please feel free to let me know! Hope a few of you find this useful\n\n[https://github.com/emmc15/pyspark-testing-env](https://github.com/emmc15/pyspark-testing-env)", "author_fullname": "t2_1luxgh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "End to End Pyspark Testing CI/CD Example Repo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uw3rn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675653318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Over the past while I&amp;#39;ve been battling with some local pyspark and docker-compose setups to have better tests for CI/CD.&lt;br/&gt;\nTo path to solve this problem was to try get the same level of depth of environment that runs in production in the company I work at (databricks, AWS EMR, S3, etc.) as locally  &lt;/p&gt;\n\n&lt;p&gt;Figured I&amp;#39;d share out some of wrapped up knowledge of battling with specific Jars and hive-metastore (which you don&amp;#39;t actually need, just a SQL database set up in certain way!) &lt;/p&gt;\n\n&lt;p&gt;The repo has the following features in it  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Quick and Easy setup for local testing and development environment and abstracting the complexity of configuring up a pyspark environment in this way&lt;/li&gt;\n&lt;li&gt;Full Pyspark Implementation&lt;/li&gt;\n&lt;li&gt;Full S3 like implementation with Minio&lt;/li&gt;\n&lt;li&gt;Read and write data to S3 and access them as tables and databases in Spark through metastore&lt;/li&gt;\n&lt;li&gt;Ability to run pytest on the pyspark container&lt;/li&gt;\n&lt;li&gt;Read and write with delta format&lt;/li&gt;\n&lt;li&gt;Example of testing pyspark code with either unittest or pytest&lt;/li&gt;\n&lt;li&gt;Consistent environment for testing and development with docker-compose and poetry&lt;/li&gt;\n&lt;li&gt;Ability to run tests on push with github actions&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If I&amp;#39;ve missed anything please feel free to let me know! Hope a few of you find this useful&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/emmc15/pyspark-testing-env\"&gt;https://github.com/emmc15/pyspark-testing-env&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZfAr6jI2jlrWEnHJDFKxQAp9zQbUfDMITmW6A9qaMbg.jpg?auto=webp&amp;v=enabled&amp;s=c2358ececabd505f63105d6d13d81226571e3796", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ZfAr6jI2jlrWEnHJDFKxQAp9zQbUfDMITmW6A9qaMbg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80ea760474f8bab8cbd7883eef62ec51edbd2b9f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ZfAr6jI2jlrWEnHJDFKxQAp9zQbUfDMITmW6A9qaMbg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa6274870102f08fe20b60ed21e0238487e1966b", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ZfAr6jI2jlrWEnHJDFKxQAp9zQbUfDMITmW6A9qaMbg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3362beccb909ec923ced39673009cefd8833238", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ZfAr6jI2jlrWEnHJDFKxQAp9zQbUfDMITmW6A9qaMbg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a17aeb24075702d4cde11f0e06420134c0530494", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ZfAr6jI2jlrWEnHJDFKxQAp9zQbUfDMITmW6A9qaMbg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=810dd44d12ade2c5af041892f8a333a808d30b19", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ZfAr6jI2jlrWEnHJDFKxQAp9zQbUfDMITmW6A9qaMbg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f69ae4ae95c021e6da3a3a1a44dfd61ef1b55fbf", "width": 1080, "height": 540}], "variants": {}, "id": "bBB2SnUsapw54XjP727vA3nYYJUF_fkOqSnGxZn2yiU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "10uw3rn", "is_robot_indexable": true, "report_reasons": null, "author": "Oct8-Danger", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uw3rn/end_to_end_pyspark_testing_cicd_example_repo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uw3rn/end_to_end_pyspark_testing_cicd_example_repo/", "subreddit_subscribers": 88641, "created_utc": 1675653318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Made it through to the second round of interviews for an entry level Data Engineering role. First interview was all SQL, which I\u2019m mostly comfortable with since as current Business Analyst, I use it in my day to day. Within one problem I had to demo Joins, aggregate functions, CASE statements, CTE and Window Functions. \n\nI was notified that for the second interview it will be Python which I have a very general, very basic understanding of. What in your opinion should I expect for the Python interview? I\u2019m looking to determine which areas of Python I should spend my time studying and practicing before the interview. Please note that this is an Entry level role, and the hiring manager did mention that the person hired would spend most of the time working with SQL. I\u2019m not sure what to expect, so not sure where I should spend my time on. What in your opinion are the Python foundations for DE?", "author_fullname": "t2_ry76f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10um7h4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675628098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Made it through to the second round of interviews for an entry level Data Engineering role. First interview was all SQL, which I\u2019m mostly comfortable with since as current Business Analyst, I use it in my day to day. Within one problem I had to demo Joins, aggregate functions, CASE statements, CTE and Window Functions. &lt;/p&gt;\n\n&lt;p&gt;I was notified that for the second interview it will be Python which I have a very general, very basic understanding of. What in your opinion should I expect for the Python interview? I\u2019m looking to determine which areas of Python I should spend my time studying and practicing before the interview. Please note that this is an Entry level role, and the hiring manager did mention that the person hired would spend most of the time working with SQL. I\u2019m not sure what to expect, so not sure where I should spend my time on. What in your opinion are the Python foundations for DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10um7h4", "is_robot_indexable": true, "report_reasons": null, "author": "CosmicNightmare", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10um7h4/python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10um7h4/python/", "subreddit_subscribers": 88641, "created_utc": 1675628098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I\u2019m currently a senior data analyst and I\u2019m looking to make the move to the DE side. My day to day deals with SQL, Power BI and some python for the manipulation of datasets. Started being involved with some DE projects and it seemed very interesting. Can you guys recommend the best books or material for me to learn the basics of DE?", "author_fullname": "t2_202bqogr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best books or material to learn the basics of data engineering.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uu1j4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675647494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I\u2019m currently a senior data analyst and I\u2019m looking to make the move to the DE side. My day to day deals with SQL, Power BI and some python for the manipulation of datasets. Started being involved with some DE projects and it seemed very interesting. Can you guys recommend the best books or material for me to learn the basics of DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uu1j4", "is_robot_indexable": true, "report_reasons": null, "author": "lramirez27", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uu1j4/best_books_or_material_to_learn_the_basics_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uu1j4/best_books_or_material_to_learn_the_basics_of/", "subreddit_subscribers": 88641, "created_utc": 1675647494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you structure (and name) your Airflow dags? \n\nFor example, we have a dag that runs an ingestion from all different sources at EOD. Then there is another dag that (creates some data aggregates) has an external sensor and when the first dag is finished, this starts its run. \n\nThe problem I have with it is when I need to reload only few parts of ingestion dag and then following parts of the aggregates dag, it is too slow, manual work and not error prone (or I would have to rerun entire dags). I am thinking of building a \u201chorizontal\u201d dag instead of this \u201cvertical\u201d one, meaning one dag would have one source and all its dependencies. Or another way would be to have one gigantic dag (probably not good option).\n\nHow do you structure your dags? Also do you name it like e.g. \u201clanding layer\u201d/ingestion/raw/data lake/L0 and then \u201ccurated\u201d/silver/warehouse/L1?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow dags - structure and naming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u8b6g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675587947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you structure (and name) your Airflow dags? &lt;/p&gt;\n\n&lt;p&gt;For example, we have a dag that runs an ingestion from all different sources at EOD. Then there is another dag that (creates some data aggregates) has an external sensor and when the first dag is finished, this starts its run. &lt;/p&gt;\n\n&lt;p&gt;The problem I have with it is when I need to reload only few parts of ingestion dag and then following parts of the aggregates dag, it is too slow, manual work and not error prone (or I would have to rerun entire dags). I am thinking of building a \u201chorizontal\u201d dag instead of this \u201cvertical\u201d one, meaning one dag would have one source and all its dependencies. Or another way would be to have one gigantic dag (probably not good option).&lt;/p&gt;\n\n&lt;p&gt;How do you structure your dags? Also do you name it like e.g. \u201clanding layer\u201d/ingestion/raw/data lake/L0 and then \u201ccurated\u201d/silver/warehouse/L1?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10u8b6g", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10u8b6g/airflow_dags_structure_and_naming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10u8b6g/airflow_dags_structure_and_naming/", "subreddit_subscribers": 88641, "created_utc": 1675587947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, \nI'm looking for an open-source data lineage app (e.g. [tokern](https://open-metadata.org/), [datahubproject](https://datahubproject.io/), [openmetadata](https://open-metadata.org/)).  \n\nThe key issue is that in addition to automatic ingestion  connectors or deriving schemas from queries, **the tool should also have a friendly way of adding objects and their relationships from something like a csv or json file.**\n\nContext: company has been documenting all its data objects manually and has a large csv explicitly showing each data object and its predescessor/s. These aren't just the standard  database/workflow/dashboard objects; these include things like power automate scripts.  I'm just looking for a good way to show everything in a map, visualize them, and navigate through their connections properly)\n\nAt this point, I'll even be happy with a pure visualization engine, like for instance if I can repurpose [kedro-viz](https://github.com/kedro-org/kedro-viz) or [dbt's](https://docs.getdbt.com/docs/build/python-models) lineage visualizer so that it can take a csv or json of object relationships as an input.   Or even a custom power BI visualization or python graph frontend would be fine, but I can't seem to see one that works.  I'd also be happy if any of the aforementioned lineage tools I mentioned above have this functionality and I just missed it.\n\nThanks everyone!", "author_fullname": "t2_4xg4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for an open-source data lineage app, where objects and connections can be manually defined (not just automatically ingested)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10usa5i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675643058.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675642860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, \nI&amp;#39;m looking for an open-source data lineage app (e.g. &lt;a href=\"https://open-metadata.org/\"&gt;tokern&lt;/a&gt;, &lt;a href=\"https://datahubproject.io/\"&gt;datahubproject&lt;/a&gt;, &lt;a href=\"https://open-metadata.org/\"&gt;openmetadata&lt;/a&gt;).  &lt;/p&gt;\n\n&lt;p&gt;The key issue is that in addition to automatic ingestion  connectors or deriving schemas from queries, &lt;strong&gt;the tool should also have a friendly way of adding objects and their relationships from something like a csv or json file.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Context: company has been documenting all its data objects manually and has a large csv explicitly showing each data object and its predescessor/s. These aren&amp;#39;t just the standard  database/workflow/dashboard objects; these include things like power automate scripts.  I&amp;#39;m just looking for a good way to show everything in a map, visualize them, and navigate through their connections properly)&lt;/p&gt;\n\n&lt;p&gt;At this point, I&amp;#39;ll even be happy with a pure visualization engine, like for instance if I can repurpose &lt;a href=\"https://github.com/kedro-org/kedro-viz\"&gt;kedro-viz&lt;/a&gt; or &lt;a href=\"https://docs.getdbt.com/docs/build/python-models\"&gt;dbt&amp;#39;s&lt;/a&gt; lineage visualizer so that it can take a csv or json of object relationships as an input.   Or even a custom power BI visualization or python graph frontend would be fine, but I can&amp;#39;t seem to see one that works.  I&amp;#39;d also be happy if any of the aforementioned lineage tools I mentioned above have this functionality and I just missed it.&lt;/p&gt;\n\n&lt;p&gt;Thanks everyone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ntYU6Ou1ez-oMJPwzMpA2muqo-5TYgKpQ1CdS81RNfs.jpg?auto=webp&amp;v=enabled&amp;s=9948f8addaa2e47ee79511ae45cff1d9245dc66a", "width": 310, "height": 310}, "resolutions": [{"url": "https://external-preview.redd.it/ntYU6Ou1ez-oMJPwzMpA2muqo-5TYgKpQ1CdS81RNfs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e33b566892d18b692a63009505235b2706b86fd6", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ntYU6Ou1ez-oMJPwzMpA2muqo-5TYgKpQ1CdS81RNfs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cc7224a6096e18b8bfa81e39e73c18df5bc11a3c", "width": 216, "height": 216}], "variants": {}, "id": "HAPFDFRRMoP2a9fJFsIVmEt8sTvE02WcjtCO87LuE3s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10usa5i", "is_robot_indexable": true, "report_reasons": null, "author": "efofecks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10usa5i/looking_for_an_opensource_data_lineage_app_where/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10usa5i/looking_for_an_opensource_data_lineage_app_where/", "subreddit_subscribers": 88641, "created_utc": 1675642860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've looked in the wiki. There's a nice brief but I'm looking for a more in depth write up, video, book, etc regarding setting up a data lake. Any pointers to some? Or any personal anecdotes and lessons learned?", "author_fullname": "t2_ut20i32q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have a pointer to a more technical reference for creating a data lake from scratch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ufwvb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675612935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve looked in the wiki. There&amp;#39;s a nice brief but I&amp;#39;m looking for a more in depth write up, video, book, etc regarding setting up a data lake. Any pointers to some? Or any personal anecdotes and lessons learned?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ufwvb", "is_robot_indexable": true, "report_reasons": null, "author": "alex_o_h", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ufwvb/anyone_have_a_pointer_to_a_more_technical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ufwvb/anyone_have_a_pointer_to_a_more_technical/", "subreddit_subscribers": 88641, "created_utc": 1675612935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\\[Databricks newbie here\\] Hello, I need to download lots (a few tens of thousands) of datasets from Databricks (I need to train a ML model), and I am looking for a way to make it fast. Does anyone have suggestions on how to proceed?\n\nAt the moment my procedure is the following:\n\n1. Retrieve dataframe using \\`spark.sql\\`\n2. Select the dataframe column which we want to consider\n3. Display dataframe and save result\n\nI also tried using \\`df1.coalesce(1, shuffle = true).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"dbfs:/FileStore/user/me/output.csv\")\\` but it's unbearably slow.\n\nWhat is the recommended way to retrieve data and export it fast? Thank you.", "author_fullname": "t2_c75nc3n7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a fast way to get lots of data from Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10udui5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675613529.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675607602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[Databricks newbie here] Hello, I need to download lots (a few tens of thousands) of datasets from Databricks (I need to train a ML model), and I am looking for a way to make it fast. Does anyone have suggestions on how to proceed?&lt;/p&gt;\n\n&lt;p&gt;At the moment my procedure is the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Retrieve dataframe using `spark.sql`&lt;/li&gt;\n&lt;li&gt;Select the dataframe column which we want to consider&lt;/li&gt;\n&lt;li&gt;Display dataframe and save result&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I also tried using `df1.coalesce(1, shuffle = true).write.format(&amp;quot;com.databricks.spark.csv&amp;quot;).option(&amp;quot;header&amp;quot;, &amp;quot;true&amp;quot;).save(&amp;quot;dbfs:/FileStore/user/me/output.csv&amp;quot;)` but it&amp;#39;s unbearably slow.&lt;/p&gt;\n\n&lt;p&gt;What is the recommended way to retrieve data and export it fast? Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10udui5", "is_robot_indexable": true, "report_reasons": null, "author": "BackgroundPass2082", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10udui5/looking_for_a_fast_way_to_get_lots_of_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10udui5/looking_for_a_fast_way_to_get_lots_of_data_from/", "subreddit_subscribers": 88641, "created_utc": 1675607602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I've been lucky enough to have received 3 data engineering internship offers for this summer which are giving me a tough time making a decision. Any advice would be appreciated.\n\nAbout me: SWE student with 2 C++ internships under my belt. While I do know basic data engineering concepts (Data lake/warehouse, ETL, APIs, data pipeline, etc.), I don't really have experience using any data tools and technologies. I'm really just looking for the option that will give me the best start towards the data engineer path.\n\n&amp;#x200B;\n\nCompany A: Medium-sized company specializing in wealth management solutions.\n\n\\- Tech stack: Python, SQL, Airflow, Db2, TFS\n\n\\- Pay: 22$/h\n\n\\- Remote\n\n\\- Small team of 2 data engineers, 1 tech lead and 1 manager. \n\n&amp;#x200B;\n\nCompany B: small-sized consulting company specializing in delivering AI solutions to businesses.\n\n\\- Tech stack: depends on the client's needs but the team said it is often Python, Spark, Databricks, Azure, Git, Kedro\n\n\\- Pay: 25$/h\n\n\\- Remote\n\n\\- Small team of 1 data engineer, 2 data scientists and 1 manager. \n\n&amp;#x200B;\n\nCompany C: large-sized company specializing in conversational AI solutions.\n\n\\- Tech stack: Java, Spark, Azure Databricks, Delta Lake, Git, Kafka, Spring\n\n\\- Pay: 25$/h\n\n\\- Remote\n\n\\- Team size: 9-10", "author_fullname": "t2_58yrswvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for choosing between internship offers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uke9m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675623752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve been lucky enough to have received 3 data engineering internship offers for this summer which are giving me a tough time making a decision. Any advice would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;About me: SWE student with 2 C++ internships under my belt. While I do know basic data engineering concepts (Data lake/warehouse, ETL, APIs, data pipeline, etc.), I don&amp;#39;t really have experience using any data tools and technologies. I&amp;#39;m really just looking for the option that will give me the best start towards the data engineer path.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Company A: Medium-sized company specializing in wealth management solutions.&lt;/p&gt;\n\n&lt;p&gt;- Tech stack: Python, SQL, Airflow, Db2, TFS&lt;/p&gt;\n\n&lt;p&gt;- Pay: 22$/h&lt;/p&gt;\n\n&lt;p&gt;- Remote&lt;/p&gt;\n\n&lt;p&gt;- Small team of 2 data engineers, 1 tech lead and 1 manager. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Company B: small-sized consulting company specializing in delivering AI solutions to businesses.&lt;/p&gt;\n\n&lt;p&gt;- Tech stack: depends on the client&amp;#39;s needs but the team said it is often Python, Spark, Databricks, Azure, Git, Kedro&lt;/p&gt;\n\n&lt;p&gt;- Pay: 25$/h&lt;/p&gt;\n\n&lt;p&gt;- Remote&lt;/p&gt;\n\n&lt;p&gt;- Small team of 1 data engineer, 2 data scientists and 1 manager. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Company C: large-sized company specializing in conversational AI solutions.&lt;/p&gt;\n\n&lt;p&gt;- Tech stack: Java, Spark, Azure Databricks, Delta Lake, Git, Kafka, Spring&lt;/p&gt;\n\n&lt;p&gt;- Pay: 25$/h&lt;/p&gt;\n\n&lt;p&gt;- Remote&lt;/p&gt;\n\n&lt;p&gt;- Team size: 9-10&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10uke9m", "is_robot_indexable": true, "report_reasons": null, "author": "Promettre", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uke9m/advice_for_choosing_between_internship_offers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uke9m/advice_for_choosing_between_internship_offers/", "subreddit_subscribers": 88641, "created_utc": 1675623752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a cross-post from \"r/learnpython\", but I thought this community might have more relevant experience and insights. I just started learning Python, and am trying to simulate some scenarios I might encounter in my job as a Data Engineer (mostly ETL-related). I'm ready to try to set up my first official \"Project\" for reading a certain category of flat files and loading them to a DB. Does anyone have any advice or good articles on how to structure things properly for Prod / Non-Prod activities?\n\nFor example, I'm going to build a separate module to create my SQL Alchemy engine objects that can be reused for multiple sources / targets / environments. What might be a good way to specify if I want a Dev or a Prod connection back? Do you pass a parameter into the module? Use configuration files and have the module figure out which environment it is running in? Or maybe something like different virtual environments for Dev and Prod? Any advice or insight would be greatly appreciated!", "author_fullname": "t2_14wbya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Prod / Non-Prod Configuration Advice for Python ETL Jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ucw8n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675604990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a cross-post from &amp;quot;&lt;a href=\"/r/learnpython\"&gt;r/learnpython&lt;/a&gt;&amp;quot;, but I thought this community might have more relevant experience and insights. I just started learning Python, and am trying to simulate some scenarios I might encounter in my job as a Data Engineer (mostly ETL-related). I&amp;#39;m ready to try to set up my first official &amp;quot;Project&amp;quot; for reading a certain category of flat files and loading them to a DB. Does anyone have any advice or good articles on how to structure things properly for Prod / Non-Prod activities?&lt;/p&gt;\n\n&lt;p&gt;For example, I&amp;#39;m going to build a separate module to create my SQL Alchemy engine objects that can be reused for multiple sources / targets / environments. What might be a good way to specify if I want a Dev or a Prod connection back? Do you pass a parameter into the module? Use configuration files and have the module figure out which environment it is running in? Or maybe something like different virtual environments for Dev and Prod? Any advice or insight would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ucw8n", "is_robot_indexable": true, "report_reasons": null, "author": "phobia42", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ucw8n/seeking_prod_nonprod_configuration_advice_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ucw8n/seeking_prod_nonprod_configuration_advice_for/", "subreddit_subscribers": 88641, "created_utc": 1675604990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm quite new to data engineering but I'm doing more of it at work (started out as a data analyst but the role involves more and more engineering stuff). We use AWS - most of our pipeline is made up of a bunch of python Lambdas and a script that runs in an EC2 instance, and it's orchestrated using Step Functions.\n\nI'm aware that Airflow is a standard tool for organising data pipelines but I'm confused about when I should be thinking about using it. Given I'm using  AWS Step Functions, what exactly would I get out of using Airflow? And given that most companies are using cloud platforms that presumably have similar services, why is Airflow still used? Is it that it is more transferrable if we choose to migrate to GCP or Azure or whatever?  I feel like I'm missing something here.", "author_fullname": "t2_1znkakv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow vs AWS Step Functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ujaxk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675621188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m quite new to data engineering but I&amp;#39;m doing more of it at work (started out as a data analyst but the role involves more and more engineering stuff). We use AWS - most of our pipeline is made up of a bunch of python Lambdas and a script that runs in an EC2 instance, and it&amp;#39;s orchestrated using Step Functions.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that Airflow is a standard tool for organising data pipelines but I&amp;#39;m confused about when I should be thinking about using it. Given I&amp;#39;m using  AWS Step Functions, what exactly would I get out of using Airflow? And given that most companies are using cloud platforms that presumably have similar services, why is Airflow still used? Is it that it is more transferrable if we choose to migrate to GCP or Azure or whatever?  I feel like I&amp;#39;m missing something here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ujaxk", "is_robot_indexable": true, "report_reasons": null, "author": "Psychological-Suit-5", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ujaxk/airflow_vs_aws_step_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ujaxk/airflow_vs_aws_step_functions/", "subreddit_subscribers": 88641, "created_utc": 1675621188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!  \nI'm looking for a managed service/tool that can call an API and ingest it into a datawarehouse(Snowflake).  \n\n\nHope that anyone can help me in the right direction \ud83e\udd1e", "author_fullname": "t2_oeiyrmpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managed service for API calls", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uhri4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675617506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;br/&gt;\nI&amp;#39;m looking for a managed service/tool that can call an API and ingest it into a datawarehouse(Snowflake).  &lt;/p&gt;\n\n&lt;p&gt;Hope that anyone can help me in the right direction \ud83e\udd1e&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uhri4", "is_robot_indexable": true, "report_reasons": null, "author": "formaldehyden", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uhri4/managed_service_for_api_calls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uhri4/managed_service_for_api_calls/", "subreddit_subscribers": 88641, "created_utc": 1675617506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For a data analysis job I need a OLAP database. I\u2018m considering Druid because it\u2019s scalable, real-time and can use mini.io as deep storage. Because we use min.io, this is a nice feature. \n\nDo you have any experiences with the challenges Druid puts onto you team or good advices for alternatives? From what I see, managing the cluster could be a bigger effort.", "author_fullname": "t2_s3omzbn3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s your OLAP Database recommendation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ulbai", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675625954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a data analysis job I need a OLAP database. I\u2018m considering Druid because it\u2019s scalable, real-time and can use mini.io as deep storage. Because we use min.io, this is a nice feature. &lt;/p&gt;\n\n&lt;p&gt;Do you have any experiences with the challenges Druid puts onto you team or good advices for alternatives? From what I see, managing the cluster could be a bigger effort.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ulbai", "is_robot_indexable": true, "report_reasons": null, "author": "ZenCoding", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ulbai/whats_your_olap_database_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ulbai/whats_your_olap_database_recommendation/", "subreddit_subscribers": 88641, "created_utc": 1675625954.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Everybody,\n\nNeeded input on how best to transfer almost 2 TBs of data from an on-prem Teradata server to Bigquery, on a daily basis.\n\nHere are some considerations:\n\n1. The data should be transferred in a secure manner\n2. The process should have the ability to do both full and delta loads\n3. As inexpensive as possible\n\nAll feedback and comments welcome :)", "author_fullname": "t2_pxuosxo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On-prem Teradata to BQ Data Transfer pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uvf5r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675651351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Everybody,&lt;/p&gt;\n\n&lt;p&gt;Needed input on how best to transfer almost 2 TBs of data from an on-prem Teradata server to Bigquery, on a daily basis.&lt;/p&gt;\n\n&lt;p&gt;Here are some considerations:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The data should be transferred in a secure manner&lt;/li&gt;\n&lt;li&gt;The process should have the ability to do both full and delta loads&lt;/li&gt;\n&lt;li&gt;As inexpensive as possible&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;All feedback and comments welcome :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10uvf5r", "is_robot_indexable": true, "report_reasons": null, "author": "deezelmunky", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uvf5r/onprem_teradata_to_bq_data_transfer_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uvf5r/onprem_teradata_to_bq_data_transfer_pipeline/", "subreddit_subscribers": 88641, "created_utc": 1675651351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, I am extremely new to dagster and I couldn't find any information about the questions I have. Basically I want to know 2 things:  \n\n\n1. Can you trigger a dagster pipeline via an api call? Can I integrate this with other API libraries like FastAPI or Django REST?\n2. Can I pass data via path- or get-params in the api call to the asset functions themselves?\n\nMore info in this [stackoverflow post I made](https://stackoverflow.com/questions/75350111/dagster-can-you-trigger-a-job-to-run-via-an-api), but basically I have a pipeline that is written in pure python, that receives a player's username via an api call, and then runs the entire pipeline to get all the data for *that particular player only.* I want to know if this is possible, or if dagster is only good for data that doesn't require pre-defined parameters\n\nAny help is greatly appreciated, thanks!", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to trigger a dagster pipeline from an api endpoint, and also pass metadata/data via get params to some of the assets?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uok0y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675633671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I am extremely new to dagster and I couldn&amp;#39;t find any information about the questions I have. Basically I want to know 2 things:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can you trigger a dagster pipeline via an api call? Can I integrate this with other API libraries like FastAPI or Django REST?&lt;/li&gt;\n&lt;li&gt;Can I pass data via path- or get-params in the api call to the asset functions themselves?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;More info in this &lt;a href=\"https://stackoverflow.com/questions/75350111/dagster-can-you-trigger-a-job-to-run-via-an-api\"&gt;stackoverflow post I made&lt;/a&gt;, but basically I have a pipeline that is written in pure python, that receives a player&amp;#39;s username via an api call, and then runs the entire pipeline to get all the data for &lt;em&gt;that particular player only.&lt;/em&gt; I want to know if this is possible, or if dagster is only good for data that doesn&amp;#39;t require pre-defined parameters&lt;/p&gt;\n\n&lt;p&gt;Any help is greatly appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?auto=webp&amp;v=enabled&amp;s=19b4a59f036ea2f314ff2033c11e54cdc240f8d8", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d93e783257998ff2ed865c359d9a00312a5412d7", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/QgPvRTknlY3rMNDqH1k4I37XGiq9tZF_FsygC_Xht4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90216f7dc897a869ee852791bafa1e00667cdf07", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uok0y", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uok0y/is_there_a_way_to_trigger_a_dagster_pipeline_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uok0y/is_there_a_way_to_trigger_a_dagster_pipeline_from/", "subreddit_subscribers": 88641, "created_utc": 1675633671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have any favorite resources for reviewing common spark interview questions? Things like optimization, scaling, and such. Thanks!", "author_fullname": "t2_2vuapfhl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Interview Prep Resources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ux96m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675656794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any favorite resources for reviewing common spark interview questions? Things like optimization, scaling, and such. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ux96m", "is_robot_indexable": true, "report_reasons": null, "author": "TheShitStorms92", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ux96m/spark_interview_prep_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ux96m/spark_interview_prep_resources/", "subreddit_subscribers": 88641, "created_utc": 1675656794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\nI am currently working as a Senior Data Engineer at a tech start up. The work is really good and I am learning a lot.\n\nWill adding ML to my tech stack help me?", "author_fullname": "t2_tyw12rnx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some feedback on ML in DE tech stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10uz8mg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675663245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,\nI am currently working as a Senior Data Engineer at a tech start up. The work is really good and I am learning a lot.&lt;/p&gt;\n\n&lt;p&gt;Will adding ML to my tech stack help me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uz8mg", "is_robot_indexable": true, "report_reasons": null, "author": "technophilius89", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uz8mg/need_some_feedback_on_ml_in_de_tech_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uz8mg/need_some_feedback_on_ml_in_de_tech_stack/", "subreddit_subscribers": 88641, "created_utc": 1675663245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm looking to switch into a career in data engineering, but I know myself well enough to know that self-study is not effective for me.\n\n* I will definitely constantly doubt whether I am studying the most optimal thing\n\n* When I get frustrated/confused, I will constantly wish I just had an experienced human being to answer my questions, instead of googling and drowning in terminology and opinions\n\n* I think I will become a generic data engineer, instead of becoming really really good at a single hyper-specific tech stack.\n\n* I personally get motivated 100x more when I have 1-on-1 accountability, whether it be fitness, study, religion, a hobby, really anything.\n\nSo I am looking for a senior-level data engineer who can give me advice. **I want someone who will essentially teach me how to become a clone of themselves.** I want someone who will tell me the exact steps to get a job similar to theirs.\n\nFor structure, I was thinking maybe 1 hour per week on Zoom to critique my weekly study progress, and maybe 3-5 text messages per week for quick questions. We can discuss money privately, but I am definitely willing to compensate you fairly for your time!", "author_fullname": "t2_fq68u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking to Hire a Mentor \ud83d\ude4f", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10uz4c4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675668012.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675662873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m looking to switch into a career in data engineering, but I know myself well enough to know that self-study is not effective for me.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;I will definitely constantly doubt whether I am studying the most optimal thing&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;When I get frustrated/confused, I will constantly wish I just had an experienced human being to answer my questions, instead of googling and drowning in terminology and opinions&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I think I will become a generic data engineer, instead of becoming really really good at a single hyper-specific tech stack.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I personally get motivated 100x more when I have 1-on-1 accountability, whether it be fitness, study, religion, a hobby, really anything.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So I am looking for a senior-level data engineer who can give me advice. &lt;strong&gt;I want someone who will essentially teach me how to become a clone of themselves.&lt;/strong&gt; I want someone who will tell me the exact steps to get a job similar to theirs.&lt;/p&gt;\n\n&lt;p&gt;For structure, I was thinking maybe 1 hour per week on Zoom to critique my weekly study progress, and maybe 3-5 text messages per week for quick questions. We can discuss money privately, but I am definitely willing to compensate you fairly for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10uz4c4", "is_robot_indexable": true, "report_reasons": null, "author": "KimchiFitness", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uz4c4/looking_to_hire_a_mentor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uz4c4/looking_to_hire_a_mentor/", "subreddit_subscribers": 88641, "created_utc": 1675662873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wanted to do a POC on edgeDB. Can anyone share resources or insights throwing light on proper use cases for utilizing edgeDB over other data warehouses?", "author_fullname": "t2_eb80kwgd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use case for using edgeDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uyrwk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675661696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wanted to do a POC on edgeDB. Can anyone share resources or insights throwing light on proper use cases for utilizing edgeDB over other data warehouses?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uyrwk", "is_robot_indexable": true, "report_reasons": null, "author": "No-Caregiver-1204", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uyrwk/use_case_for_using_edgedb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uyrwk/use_case_for_using_edgedb/", "subreddit_subscribers": 88641, "created_utc": 1675661696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Context: I am a somewhat experienced (9 years) generalist engineer, working on a data engineering project centering around the usage of Apache Hudi. My problem does not lend itself to partitioning, and I am having trouble getting my solution to perform adequately with a non-partitioned table using SIMPLE indexing. I am considering implementing my own index that is optimized for my use case. I am hesitant, because this is not an area of expertise of mine, and I doubt that I will be able to implement a satisfactory solution.\n\nMy question -- to anyone who has done such an implementation or knows what it entails -- is whether this seems like a path I should even proceed, given that I am by no means an expert in big data or data engineering. I'm definitely more fluent and experienced than your average engineer, but far from knowing enough about the internals of Hudi to consider contributing to their source or anything like that.\n\nFurther, if anyone has any resources at all on what this effort looks like, and/or any guidance, that would be greatly appreciated. I've found nothing online except for the API I need to implement, provided on the Hudi website.", "author_fullname": "t2_55zctcl1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feasibility of a novice building a custom Hudi indexing implementation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uqctm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675638040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I am a somewhat experienced (9 years) generalist engineer, working on a data engineering project centering around the usage of Apache Hudi. My problem does not lend itself to partitioning, and I am having trouble getting my solution to perform adequately with a non-partitioned table using SIMPLE indexing. I am considering implementing my own index that is optimized for my use case. I am hesitant, because this is not an area of expertise of mine, and I doubt that I will be able to implement a satisfactory solution.&lt;/p&gt;\n\n&lt;p&gt;My question -- to anyone who has done such an implementation or knows what it entails -- is whether this seems like a path I should even proceed, given that I am by no means an expert in big data or data engineering. I&amp;#39;m definitely more fluent and experienced than your average engineer, but far from knowing enough about the internals of Hudi to consider contributing to their source or anything like that.&lt;/p&gt;\n\n&lt;p&gt;Further, if anyone has any resources at all on what this effort looks like, and/or any guidance, that would be greatly appreciated. I&amp;#39;ve found nothing online except for the API I need to implement, provided on the Hudi website.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uqctm", "is_robot_indexable": true, "report_reasons": null, "author": "aiminghire", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uqctm/feasibility_of_a_novice_building_a_custom_hudi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uqctm/feasibility_of_a_novice_building_a_custom_hudi/", "subreddit_subscribers": 88641, "created_utc": 1675638040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you feel about your job? I'm just bringing this long lasting debate from software engineering and softwafe craftship. I feel the way it is approached could help on defining guidelines in terms of mentorship, good practices, etc\n\n[View Poll](https://www.reddit.com/poll/10uc8da)", "author_fullname": "t2_v3ifff74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Craftship or actual Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uc8da", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675603014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you feel about your job? I&amp;#39;m just bringing this long lasting debate from software engineering and softwafe craftship. I feel the way it is approached could help on defining guidelines in terms of mentorship, good practices, etc&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10uc8da\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10uc8da", "is_robot_indexable": true, "report_reasons": null, "author": "kaismd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1675775814615, "options": [{"text": "Craftship", "id": "21439441"}, {"text": "Engineering", "id": "21439442"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 60, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uc8da/craftship_or_actual_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10uc8da/craftship_or_actual_engineering/", "subreddit_subscribers": 88641, "created_utc": 1675603014.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}