{"kind": "Listing", "data": {"after": null, "dist": 8, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Made it through to the second round of interviews for an entry level Data Engineering role. First interview was all SQL, which I\u2019m mostly comfortable with since as current Business Analyst, I use it in my day to day. Within one problem I had to demo Joins, aggregate functions, CASE statements, CTE and Window Functions. \n\nI was notified that for the second interview it will be Python which I have a very general, very basic understanding of. What in your opinion should I expect for the Python interview? I\u2019m looking to determine which areas of Python I should spend my time studying and practicing before the interview. Please note that this is an Entry level role, and the hiring manager did mention that the person hired would spend most of the time working with SQL. I\u2019m not sure what to expect, so not sure where I should spend my time on. What in your opinion are the Python foundations for DE?", "author_fullname": "t2_ry76f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10um7h4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675628098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Made it through to the second round of interviews for an entry level Data Engineering role. First interview was all SQL, which I\u2019m mostly comfortable with since as current Business Analyst, I use it in my day to day. Within one problem I had to demo Joins, aggregate functions, CASE statements, CTE and Window Functions. &lt;/p&gt;\n\n&lt;p&gt;I was notified that for the second interview it will be Python which I have a very general, very basic understanding of. What in your opinion should I expect for the Python interview? I\u2019m looking to determine which areas of Python I should spend my time studying and practicing before the interview. Please note that this is an Entry level role, and the hiring manager did mention that the person hired would spend most of the time working with SQL. I\u2019m not sure what to expect, so not sure where I should spend my time on. What in your opinion are the Python foundations for DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10um7h4", "is_robot_indexable": true, "report_reasons": null, "author": "CosmicNightmare", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10um7h4/python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10um7h4/python/", "subreddit_subscribers": 88655, "created_utc": 1675628098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a cross-post from \"r/learnpython\", but I thought this community might have more relevant experience and insights. I just started learning Python, and am trying to simulate some scenarios I might encounter in my job as a Data Engineer (mostly ETL-related). I'm ready to try to set up my first official \"Project\" for reading a certain category of flat files and loading them to a DB. Does anyone have any advice or good articles on how to structure things properly for Prod / Non-Prod activities?\n\nFor example, I'm going to build a separate module to create my SQL Alchemy engine objects that can be reused for multiple sources / targets / environments. What might be a good way to specify if I want a Dev or a Prod connection back? Do you pass a parameter into the module? Use configuration files and have the module figure out which environment it is running in? Or maybe something like different virtual environments for Dev and Prod? Any advice or insight would be greatly appreciated!", "author_fullname": "t2_14wbya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Prod / Non-Prod Configuration Advice for Python ETL Jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ucw8n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675604990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a cross-post from &amp;quot;&lt;a href=\"/r/learnpython\"&gt;r/learnpython&lt;/a&gt;&amp;quot;, but I thought this community might have more relevant experience and insights. I just started learning Python, and am trying to simulate some scenarios I might encounter in my job as a Data Engineer (mostly ETL-related). I&amp;#39;m ready to try to set up my first official &amp;quot;Project&amp;quot; for reading a certain category of flat files and loading them to a DB. Does anyone have any advice or good articles on how to structure things properly for Prod / Non-Prod activities?&lt;/p&gt;\n\n&lt;p&gt;For example, I&amp;#39;m going to build a separate module to create my SQL Alchemy engine objects that can be reused for multiple sources / targets / environments. What might be a good way to specify if I want a Dev or a Prod connection back? Do you pass a parameter into the module? Use configuration files and have the module figure out which environment it is running in? Or maybe something like different virtual environments for Dev and Prod? Any advice or insight would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ucw8n", "is_robot_indexable": true, "report_reasons": null, "author": "phobia42", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ucw8n/seeking_prod_nonprod_configuration_advice_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ucw8n/seeking_prod_nonprod_configuration_advice_for/", "subreddit_subscribers": 88655, "created_utc": 1675604990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I've been lucky enough to have received 3 data engineering internship offers for this summer which are giving me a tough time making a decision. Any advice would be appreciated.\n\nAbout me: SWE student with 2 C++ internships under my belt. While I do know basic data engineering concepts (Data lake/warehouse, ETL, APIs, data pipeline, etc.), I don't really have experience using any data tools and technologies. I'm really just looking for the option that will give me the best start towards the data engineer path.\n\n&amp;#x200B;\n\nCompany A: Medium-sized company specializing in wealth management solutions.\n\n\\- Tech stack: Python, SQL, Airflow, Db2, TFS\n\n\\- Pay: 22$/h\n\n\\- Remote\n\n\\- Small team of 2 data engineers, 1 tech lead and 1 manager. \n\n&amp;#x200B;\n\nCompany B: small-sized consulting company specializing in delivering AI solutions to businesses.\n\n\\- Tech stack: depends on the client's needs but the team said it is often Python, Spark, Databricks, Azure, Git, Kedro\n\n\\- Pay: 25$/h\n\n\\- Remote\n\n\\- Small team of 1 data engineer, 2 data scientists and 1 manager. \n\n&amp;#x200B;\n\nCompany C: large-sized company specializing in conversational AI solutions.\n\n\\- Tech stack: Java, Spark, Azure Databricks, Delta Lake, Git, Kafka, Spring\n\n\\- Pay: 25$/h\n\n\\- Remote\n\n\\- Team size: 9-10", "author_fullname": "t2_58yrswvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for choosing between internship offers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uke9m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675623752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve been lucky enough to have received 3 data engineering internship offers for this summer which are giving me a tough time making a decision. Any advice would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;About me: SWE student with 2 C++ internships under my belt. While I do know basic data engineering concepts (Data lake/warehouse, ETL, APIs, data pipeline, etc.), I don&amp;#39;t really have experience using any data tools and technologies. I&amp;#39;m really just looking for the option that will give me the best start towards the data engineer path.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Company A: Medium-sized company specializing in wealth management solutions.&lt;/p&gt;\n\n&lt;p&gt;- Tech stack: Python, SQL, Airflow, Db2, TFS&lt;/p&gt;\n\n&lt;p&gt;- Pay: 22$/h&lt;/p&gt;\n\n&lt;p&gt;- Remote&lt;/p&gt;\n\n&lt;p&gt;- Small team of 2 data engineers, 1 tech lead and 1 manager. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Company B: small-sized consulting company specializing in delivering AI solutions to businesses.&lt;/p&gt;\n\n&lt;p&gt;- Tech stack: depends on the client&amp;#39;s needs but the team said it is often Python, Spark, Databricks, Azure, Git, Kedro&lt;/p&gt;\n\n&lt;p&gt;- Pay: 25$/h&lt;/p&gt;\n\n&lt;p&gt;- Remote&lt;/p&gt;\n\n&lt;p&gt;- Small team of 1 data engineer, 2 data scientists and 1 manager. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Company C: large-sized company specializing in conversational AI solutions.&lt;/p&gt;\n\n&lt;p&gt;- Tech stack: Java, Spark, Azure Databricks, Delta Lake, Git, Kafka, Spring&lt;/p&gt;\n\n&lt;p&gt;- Pay: 25$/h&lt;/p&gt;\n\n&lt;p&gt;- Remote&lt;/p&gt;\n\n&lt;p&gt;- Team size: 9-10&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10uke9m", "is_robot_indexable": true, "report_reasons": null, "author": "Promettre", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uke9m/advice_for_choosing_between_internship_offers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uke9m/advice_for_choosing_between_internship_offers/", "subreddit_subscribers": 88655, "created_utc": 1675623752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm quite new to data engineering but I'm doing more of it at work (started out as a data analyst but the role involves more and more engineering stuff). We use AWS - most of our pipeline is made up of a bunch of python Lambdas and a script that runs in an EC2 instance, and it's orchestrated using Step Functions.\n\nI'm aware that Airflow is a standard tool for organising data pipelines but I'm confused about when I should be thinking about using it. Given I'm using  AWS Step Functions, what exactly would I get out of using Airflow? And given that most companies are using cloud platforms that presumably have similar services, why is Airflow still used? Is it that it is more transferrable if we choose to migrate to GCP or Azure or whatever?  I feel like I'm missing something here.", "author_fullname": "t2_1znkakv1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow vs AWS Step Functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ujaxk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675621188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m quite new to data engineering but I&amp;#39;m doing more of it at work (started out as a data analyst but the role involves more and more engineering stuff). We use AWS - most of our pipeline is made up of a bunch of python Lambdas and a script that runs in an EC2 instance, and it&amp;#39;s orchestrated using Step Functions.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m aware that Airflow is a standard tool for organising data pipelines but I&amp;#39;m confused about when I should be thinking about using it. Given I&amp;#39;m using  AWS Step Functions, what exactly would I get out of using Airflow? And given that most companies are using cloud platforms that presumably have similar services, why is Airflow still used? Is it that it is more transferrable if we choose to migrate to GCP or Azure or whatever?  I feel like I&amp;#39;m missing something here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ujaxk", "is_robot_indexable": true, "report_reasons": null, "author": "Psychological-Suit-5", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ujaxk/airflow_vs_aws_step_functions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ujaxk/airflow_vs_aws_step_functions/", "subreddit_subscribers": 88655, "created_utc": 1675621188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!  \nI'm looking for a managed service/tool that can call an API and ingest it into a datawarehouse(Snowflake).  \n\n\nHope that anyone can help me in the right direction \ud83e\udd1e", "author_fullname": "t2_oeiyrmpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managed service for API calls", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uhri4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675617506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;br/&gt;\nI&amp;#39;m looking for a managed service/tool that can call an API and ingest it into a datawarehouse(Snowflake).  &lt;/p&gt;\n\n&lt;p&gt;Hope that anyone can help me in the right direction \ud83e\udd1e&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uhri4", "is_robot_indexable": true, "report_reasons": null, "author": "formaldehyden", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uhri4/managed_service_for_api_calls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uhri4/managed_service_for_api_calls/", "subreddit_subscribers": 88655, "created_utc": 1675617506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have any favorite resources for reviewing common spark interview questions? Things like optimization, scaling, and such. Thanks!", "author_fullname": "t2_2vuapfhl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Interview Prep Resources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ux96m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675656794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any favorite resources for reviewing common spark interview questions? Things like optimization, scaling, and such. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10ux96m", "is_robot_indexable": true, "report_reasons": null, "author": "TheShitStorms92", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10ux96m/spark_interview_prep_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10ux96m/spark_interview_prep_resources/", "subreddit_subscribers": 88655, "created_utc": 1675656794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently working on a data pipeline that is extracting data from a web API. The data is then loaded into Google Cloud Storage as JSON Line delimited files. From there I would like to ingest the data into BigQuery. Unfortunately some field types across the many files are not constant, and BigQuery returns an error when I try loading in many files, implying that a field type does not match the schema. I would really appreciate it if someone can give me an indication of the industry best practices when it comes to processing and validating the data to ensure consistency across the different files. Would I have to create a beam pipeline that coerces all the values to fit the schema, or are there any frameworks such as great expectations to do this? If so where should I integrate great expectations or another framework within the pipeline. Thank you for your time.", "author_fullname": "t2_7s8l0yk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data validation and field type coercion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10v2u7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675677217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working on a data pipeline that is extracting data from a web API. The data is then loaded into Google Cloud Storage as JSON Line delimited files. From there I would like to ingest the data into BigQuery. Unfortunately some field types across the many files are not constant, and BigQuery returns an error when I try loading in many files, implying that a field type does not match the schema. I would really appreciate it if someone can give me an indication of the industry best practices when it comes to processing and validating the data to ensure consistency across the different files. Would I have to create a beam pipeline that coerces all the values to fit the schema, or are there any frameworks such as great expectations to do this? If so where should I integrate great expectations or another framework within the pipeline. Thank you for your time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10v2u7v", "is_robot_indexable": true, "report_reasons": null, "author": "manfromthetaleb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10v2u7v/data_validation_and_field_type_coercion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10v2u7v/data_validation_and_field_type_coercion/", "subreddit_subscribers": 88655, "created_utc": 1675677217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Context: I am a somewhat experienced (9 years) generalist engineer, working on a data engineering project centering around the usage of Apache Hudi. My problem does not lend itself to partitioning, and I am having trouble getting my solution to perform adequately with a non-partitioned table using SIMPLE indexing. I am considering implementing my own index that is optimized for my use case. I am hesitant, because this is not an area of expertise of mine, and I doubt that I will be able to implement a satisfactory solution.\n\nMy question -- to anyone who has done such an implementation or knows what it entails -- is whether this seems like a path I should even proceed, given that I am by no means an expert in big data or data engineering. I'm definitely more fluent and experienced than your average engineer, but far from knowing enough about the internals of Hudi to consider contributing to their source or anything like that.\n\nFurther, if anyone has any resources at all on what this effort looks like, and/or any guidance, that would be greatly appreciated. I've found nothing online except for the API I need to implement, provided on the Hudi website.", "author_fullname": "t2_55zctcl1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feasibility of a novice building a custom Hudi indexing implementation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uqctm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675638040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I am a somewhat experienced (9 years) generalist engineer, working on a data engineering project centering around the usage of Apache Hudi. My problem does not lend itself to partitioning, and I am having trouble getting my solution to perform adequately with a non-partitioned table using SIMPLE indexing. I am considering implementing my own index that is optimized for my use case. I am hesitant, because this is not an area of expertise of mine, and I doubt that I will be able to implement a satisfactory solution.&lt;/p&gt;\n\n&lt;p&gt;My question -- to anyone who has done such an implementation or knows what it entails -- is whether this seems like a path I should even proceed, given that I am by no means an expert in big data or data engineering. I&amp;#39;m definitely more fluent and experienced than your average engineer, but far from knowing enough about the internals of Hudi to consider contributing to their source or anything like that.&lt;/p&gt;\n\n&lt;p&gt;Further, if anyone has any resources at all on what this effort looks like, and/or any guidance, that would be greatly appreciated. I&amp;#39;ve found nothing online except for the API I need to implement, provided on the Hudi website.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10uqctm", "is_robot_indexable": true, "report_reasons": null, "author": "aiminghire", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10uqctm/feasibility_of_a_novice_building_a_custom_hudi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10uqctm/feasibility_of_a_novice_building_a_custom_hudi/", "subreddit_subscribers": 88655, "created_utc": 1675638040.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}