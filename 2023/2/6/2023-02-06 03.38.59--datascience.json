{"kind": "Listing", "data": {"after": "t3_10uho9q", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_cdrji8bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "isn't this just too much for a take home assignment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 128, "top_awarded_type": null, "hide_score": false, "name": "t3_10ueevu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 270, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 270, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XnRi7AnPeriE520osDIV_l4HSuSyW6V4Pqmgzwssu3U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675609107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/jdtrxsz2efga1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?auto=webp&amp;v=enabled&amp;s=0985c44cfb4efe1d0d8d1b2de411f169d1397444", "width": 1080, "height": 988}, "resolutions": [{"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9778e6b16ef078d8351f11b5bc596c767f347c61", "width": 108, "height": 98}, {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e324d275de5af34fb37faf87ebba87c31511359e", "width": 216, "height": 197}, {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=877115ce24bf001cacfab00f83aa24e614986e24", "width": 320, "height": 292}, {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c83730ae4f0e3084cc0fd0199364a1152fbdba7a", "width": 640, "height": 585}, {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=796a00f9173ceee148da202d9b210376e44d156d", "width": 960, "height": 878}, {"url": "https://preview.redd.it/jdtrxsz2efga1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=66778d27c72b94c31cc1cf62b358cfa6a6060739", "width": 1080, "height": 988}], "variants": {}, "id": "E6xrcS-8woaqKln1AI0fuEzDUlz5ZTUf60J2TsPbvy4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ueevu", "is_robot_indexable": true, "report_reasons": null, "author": "questionaboutpsy", "discussion_type": null, "num_comments": 225, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ueevu/isnt_this_just_too_much_for_a_take_home_assignment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/jdtrxsz2efga1.jpg", "subreddit_subscribers": 845036, "created_utc": 1675609107.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for a small engineering firm. I have been tasked by my CEO to train an AI to solve what is essentially a regression problem (although he doesn't know that, he just wants it to \"make predictions.\" AI/ML is not his expertise). There are only 4 features (all numerical) to this dataset, but unfortunately there are also only 25 samples. Collecting test samples for this application is expensive, and no relevant public data exists. In a few months, we should be able to collect 25-30 more samples. There will not be another chance after that to collect more data before the contract ends. It also doesn't help that I'm not even sure we can trust that the data we do have was collected properly (there are some serious anomalies) but that's besides the point I guess.\n\nI've tried explaining to my CEO why this is extremely difficult to work with and why it is hard to trust the predictions of the model. He says that we get paid to do the impossible. I cannot seem to convince him or get him to understand how absurdly small 25 samples is for training an AI model. He originally wanted us to use a deep neural net. Right now I'm trying a simple ANN (mostly to placate him) and also a support vector machine. \n\nAny advice on how to handle this, whether technically or professionally? Are there better models or any standard practices for when working with such limited data? Any way I can explain to my boss when this inevitably fails why it's not my fault?", "author_fullname": "t2_ll6fgzm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working with extremely limited data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u61v7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 77, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 77, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675579221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a small engineering firm. I have been tasked by my CEO to train an AI to solve what is essentially a regression problem (although he doesn&amp;#39;t know that, he just wants it to &amp;quot;make predictions.&amp;quot; AI/ML is not his expertise). There are only 4 features (all numerical) to this dataset, but unfortunately there are also only 25 samples. Collecting test samples for this application is expensive, and no relevant public data exists. In a few months, we should be able to collect 25-30 more samples. There will not be another chance after that to collect more data before the contract ends. It also doesn&amp;#39;t help that I&amp;#39;m not even sure we can trust that the data we do have was collected properly (there are some serious anomalies) but that&amp;#39;s besides the point I guess.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried explaining to my CEO why this is extremely difficult to work with and why it is hard to trust the predictions of the model. He says that we get paid to do the impossible. I cannot seem to convince him or get him to understand how absurdly small 25 samples is for training an AI model. He originally wanted us to use a deep neural net. Right now I&amp;#39;m trying a simple ANN (mostly to placate him) and also a support vector machine. &lt;/p&gt;\n\n&lt;p&gt;Any advice on how to handle this, whether technically or professionally? Are there better models or any standard practices for when working with such limited data? Any way I can explain to my boss when this inevitably fails why it&amp;#39;s not my fault?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10u61v7", "is_robot_indexable": true, "report_reasons": null, "author": "CyanDean", "discussion_type": null, "num_comments": 57, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10u61v7/working_with_extremely_limited_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10u61v7/working_with_extremely_limited_data/", "subreddit_subscribers": 845036, "created_utc": 1675579221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3op9qx89", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science managers, what core skills (and to what depth of knowledge) are you looking for in a Data Scientist hire in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ul9n4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675625837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ul9n4", "is_robot_indexable": true, "report_reasons": null, "author": "LatterConcentrate6", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ul9n4/data_science_managers_what_core_skills_and_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ul9n4/data_science_managers_what_core_skills_and_to/", "subreddit_subscribers": 845036, "created_utc": 1675625837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHi,\n\nFor those who struggle with all the GitLab/GitHub commands in the Internet, this article will give you nearly all you need in your daily work. The targeted audience is Data Scientist/Data Engineer, with no experience or medium experience with Git.\n\n[8 minutes to cover 99 of your Git needs](https://medium.com/towards-data-science/8-minutes-to-cover-99-of-your-git-needs-2c904c43590a)", "author_fullname": "t2_ssf8k2ti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GitLab/GitHub survival kit for noobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ufcxo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675611526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;For those who struggle with all the GitLab/GitHub commands in the Internet, this article will give you nearly all you need in your daily work. The targeted audience is Data Scientist/Data Engineer, with no experience or medium experience with Git.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/towards-data-science/8-minutes-to-cover-99-of-your-git-needs-2c904c43590a\"&gt;8 minutes to cover 99 of your Git needs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?auto=webp&amp;v=enabled&amp;s=fcbe6260658080408ba0815f24355835547f5bd4", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=55326b67339827aa92eb4223a65f3bc6dadb7ce6", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0a57870679304b43b391df0e2f9caf42a85f78d3", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bafbd70fa4e880ec0728502774b9910a1246b1d0", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d31d0d812d7c54e8ca75cb2f8e6c2a7742a53ba0", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0077063957792017bd30a97c21d426f0159ca9d9", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/ubJjN3_lqL4cFgahIxbYTxhTRa5k-3P8tns20b0OvUY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc084837e71f56f02dadfb772cf01269e6f5b1f6", "width": 1080, "height": 720}], "variants": {}, "id": "Lvsd3i4VAfg5ik6r83gGp6xjxoSWoyC3D9SdzOS1CqQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ufcxo", "is_robot_indexable": true, "report_reasons": null, "author": "Arli84", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ufcxo/gitlabgithub_survival_kit_for_noobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ufcxo/gitlabgithub_survival_kit_for_noobs/", "subreddit_subscribers": 845036, "created_utc": 1675611526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to see which house prices in my dataset are outliers based on other feature columns like sqft, waterfront or year built. \n\nSome of these are more important and play significant role on deciding if a data point is an outlier. \n\nWhat is the logic/literature behind this? How can I go about building this code?", "author_fullname": "t2_m826ekr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multivariate Outlier Detection in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u7wfw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675586319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to see which house prices in my dataset are outliers based on other feature columns like sqft, waterfront or year built. &lt;/p&gt;\n\n&lt;p&gt;Some of these are more important and play significant role on deciding if a data point is an outlier. &lt;/p&gt;\n\n&lt;p&gt;What is the logic/literature behind this? How can I go about building this code?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10u7wfw", "is_robot_indexable": true, "report_reasons": null, "author": "Utterizi", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10u7wfw/multivariate_outlier_detection_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10u7wfw/multivariate_outlier_detection_in_python/", "subreddit_subscribers": 845036, "created_utc": 1675586319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm curious because in my \"small\" experience of +4 years last friday I did an interview for a small company, when they asked me about using git or control version somehow I was totally honest and said something a long the lines \"look I know what it is and how it works but because I like to learn but in these bigs companies in my resume at the end of the day they care more about having results as soon as possible with nothing or very little documentation rather than doing things properly, so I did as they ask\".\nThey started laughing like some joke saying \"oh wow I cant imagine working like that what a mess\" I dont think they really care since as they also said is something you should get used to easily (plus I'm gonna reject them). \n\nSo I'm just curious how many of you really work using git? \nPS: My profile is data scientist/analyst using Python.\n\nUpdate: \nAs Im reading all of you I see that I need to change that because for me and the company so... this week I'll start to use it 100%.\nAlso I'm giving some more info about why I think I didnt really work with it in the past:\n- No production deployment (\"if you can run it locally why waste money?\")\n- Really small teams where normally very few projects where really done by more than the person itself.\n- When I tried to bring it in the past It was kind of a mess for me without anybody helping, and It was hard for me to defend why since I really didnt know either.\n- Normally when I tried to learn something new I used to focus on new libreries, best techniques/coding practices and my next step was about docker and production deployment but before that Im focus on the git.\n\nI want to thank all of you for your thoughts, I'll keep replying later.", "author_fullname": "t2_x2mp516", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many of you really work using control version like git rather than local files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uf7ws", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675620348.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675611169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious because in my &amp;quot;small&amp;quot; experience of +4 years last friday I did an interview for a small company, when they asked me about using git or control version somehow I was totally honest and said something a long the lines &amp;quot;look I know what it is and how it works but because I like to learn but in these bigs companies in my resume at the end of the day they care more about having results as soon as possible with nothing or very little documentation rather than doing things properly, so I did as they ask&amp;quot;.\nThey started laughing like some joke saying &amp;quot;oh wow I cant imagine working like that what a mess&amp;quot; I dont think they really care since as they also said is something you should get used to easily (plus I&amp;#39;m gonna reject them). &lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m just curious how many of you really work using git? \nPS: My profile is data scientist/analyst using Python.&lt;/p&gt;\n\n&lt;p&gt;Update: \nAs Im reading all of you I see that I need to change that because for me and the company so... this week I&amp;#39;ll start to use it 100%.\nAlso I&amp;#39;m giving some more info about why I think I didnt really work with it in the past:\n- No production deployment (&amp;quot;if you can run it locally why waste money?&amp;quot;)\n- Really small teams where normally very few projects where really done by more than the person itself.\n- When I tried to bring it in the past It was kind of a mess for me without anybody helping, and It was hard for me to defend why since I really didnt know either.\n- Normally when I tried to learn something new I used to focus on new libreries, best techniques/coding practices and my next step was about docker and production deployment but before that Im focus on the git.&lt;/p&gt;\n\n&lt;p&gt;I want to thank all of you for your thoughts, I&amp;#39;ll keep replying later.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uf7ws", "is_robot_indexable": true, "report_reasons": null, "author": "KingdomXander", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uf7ws/how_many_of_you_really_work_using_control_version/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uf7ws/how_many_of_you_really_work_using_control_version/", "subreddit_subscribers": 845036, "created_utc": 1675611169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I read before on Reddit as well as on blog posts about data science professionals landing a job and thinking that they finally get to apply their skills to do something cool, when they had to instead do analysis on excel. \n\nAlso data scientists in some companies who aren\u2019t sure what goal they are hired to achieve. Or they don\u2019t even have the right data to work on. Or their work never makes it to production because of some reason or another. And they get disillusioned.\n\nRecently I came across this post on data science in finance. And the description looks pretty interesting. \n\nhttps://careerfoundry.com/en/blog/data-analytics/data-science-in-finance/\n\nAre any current Data science professionals who are in the financial industry. Who can shed some light on this? \n\nIs the work really as described? Or is it better? \n\nDo you get interesting problems to work on? \n\nDo you feel you get an opportunity to make an impact with your work? \n\nDo your models make it to production?", "author_fullname": "t2_kxuu98cn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do data scientists in the financial industry really get to do this cool stuff?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u8jio", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675588918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read before on Reddit as well as on blog posts about data science professionals landing a job and thinking that they finally get to apply their skills to do something cool, when they had to instead do analysis on excel. &lt;/p&gt;\n\n&lt;p&gt;Also data scientists in some companies who aren\u2019t sure what goal they are hired to achieve. Or they don\u2019t even have the right data to work on. Or their work never makes it to production because of some reason or another. And they get disillusioned.&lt;/p&gt;\n\n&lt;p&gt;Recently I came across this post on data science in finance. And the description looks pretty interesting. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://careerfoundry.com/en/blog/data-analytics/data-science-in-finance/\"&gt;https://careerfoundry.com/en/blog/data-analytics/data-science-in-finance/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Are any current Data science professionals who are in the financial industry. Who can shed some light on this? &lt;/p&gt;\n\n&lt;p&gt;Is the work really as described? Or is it better? &lt;/p&gt;\n\n&lt;p&gt;Do you get interesting problems to work on? &lt;/p&gt;\n\n&lt;p&gt;Do you feel you get an opportunity to make an impact with your work? &lt;/p&gt;\n\n&lt;p&gt;Do your models make it to production?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?auto=webp&amp;v=enabled&amp;s=b1f342a687094de675f38a3e1341bf42c650e76d", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4727ec8b4b2e5fc969314fc8266ea394739d8b72", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=308b97f9105b3d61c1643e7574f2d47ab264a8f8", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63f7f446d229be98f5fe796d53520d6fee17a829", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=893f0a3204b4464fd58384ebee7bc9c1412a49ab", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90b27af958090d65f4f044916ece584e64c0d794", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/0UoHBT4PuSsR_Vm260X6fpPbhrlkDLmvfR0c6vik5YY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb3198f892353fe206a82b36e271cb6653aff306", "width": 1080, "height": 540}], "variants": {}, "id": "pxpxKEZtpLgEYvmWS0rEj_u-yqmAkUOclPNab-nMANI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10u8jio", "is_robot_indexable": true, "report_reasons": null, "author": "lnfrarad", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10u8jio/do_data_scientists_in_the_financial_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10u8jio/do_data_scientists_in_the_financial_industry/", "subreddit_subscribers": 845036, "created_utc": 1675588918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, I recently screwed up a couple of interviews because of not doing as well as I should have on ML System Design/Case Study type questions where interviewers generally give very vague broad questions. I would love to know the kind of framework people follow for it and any material you used to prep for that? Any good articles/books/youtube channels with good content around this would be appreciated. thanks!", "author_fullname": "t2_5xrvr0ca", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ML System Design/Case Study Preparation material", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uu1fc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675647486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I recently screwed up a couple of interviews because of not doing as well as I should have on ML System Design/Case Study type questions where interviewers generally give very vague broad questions. I would love to know the kind of framework people follow for it and any material you used to prep for that? Any good articles/books/youtube channels with good content around this would be appreciated. thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uu1fc", "is_robot_indexable": true, "report_reasons": null, "author": "saum7800", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uu1fc/ml_system_designcase_study_preparation_material/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uu1fc/ml_system_designcase_study_preparation_material/", "subreddit_subscribers": 845036, "created_utc": 1675647486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have debated buying a domain and posting a bunch of projects I\u2019ve worked on. Does anyone have any experience doing this, and have any recommendations or tips?", "author_fullname": "t2_pgh062fv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Personal Website to publish projects/portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10upfd2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675635779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have debated buying a domain and posting a bunch of projects I\u2019ve worked on. Does anyone have any experience doing this, and have any recommendations or tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10upfd2", "is_robot_indexable": true, "report_reasons": null, "author": "cornballdata", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10upfd2/personal_website_to_publish_projectsportfolio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10upfd2/personal_website_to_publish_projectsportfolio/", "subreddit_subscribers": 845036, "created_utc": 1675635779.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In most data sci jobs, are people typically able to figure out what to do? Or is it common to go to a job and not know what to do, and not be able to figure it out, especially if you don\u2019t have help from coworkers? \n\nI know some type of work may be standardized across the field, but others custom to the company. To what extent is each?", "author_fullname": "t2_8oao8a3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you ever been in a job where you didn\u2019t know/couldn\u2019t figure out what to do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10urwyd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675641937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In most data sci jobs, are people typically able to figure out what to do? Or is it common to go to a job and not know what to do, and not be able to figure it out, especially if you don\u2019t have help from coworkers? &lt;/p&gt;\n\n&lt;p&gt;I know some type of work may be standardized across the field, but others custom to the company. To what extent is each?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10urwyd", "is_robot_indexable": true, "report_reasons": null, "author": "Midnight_Spell", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10urwyd/have_you_ever_been_in_a_job_where_you_didnt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10urwyd/have_you_ever_been_in_a_job_where_you_didnt/", "subreddit_subscribers": 845036, "created_utc": 1675641937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Newer to DS work and am looking for some direction on approaches. \n\nI'm trying to estimate the impact of an event upon a customer satisfaction metric, for both the general population and specific segments. The event is assumed to have heterogeneous effects due to the nature of the customer base (impacted customers in some regions more than others) and was not part of an experimental study.\n\nI've tried: Using Arima time series modeling based upon the metric, fitting on the time period prior to the event, predicting after the event, and comparing the predicted values to the actual ones. However, Arima doesn't appear to be appropriate due to limited data. There appears to be monthly seasonality, as well as seasonality related to the day of the week. \n\nSince the customer satisfaction metric is an aggregation from scores provided by individuals, I've also tried using individual scores pre-event as training and using individual scores given post-event as test, fitting traditional classification models to the training set and making predictions on the test set. To estimate the difference between the expected versus actual customer metric, I've taken the training scores and predicted test scores and calculated the aggregated metric for those records as the expected aggregate value and separately calculated the aggregated metric over the training scores and actual test values for the actual aggregate value. However, this method gives me a larger than actual estimated impact - regardless of whether or not I balance the classes during training, this modeling approach tends to predict one customer rating more frequently than the others.\n\nI've also done some reading into causality libraries/modeling approaches, like econml DML, but I'm not sure how helpful CATE would be here, since my metric of interest is an aggregation. Any suggestions?", "author_fullname": "t2_fmsekv8p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Techniques for estimating the impact of an event upon user satisfaction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10unjik", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675631230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Newer to DS work and am looking for some direction on approaches. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to estimate the impact of an event upon a customer satisfaction metric, for both the general population and specific segments. The event is assumed to have heterogeneous effects due to the nature of the customer base (impacted customers in some regions more than others) and was not part of an experimental study.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried: Using Arima time series modeling based upon the metric, fitting on the time period prior to the event, predicting after the event, and comparing the predicted values to the actual ones. However, Arima doesn&amp;#39;t appear to be appropriate due to limited data. There appears to be monthly seasonality, as well as seasonality related to the day of the week. &lt;/p&gt;\n\n&lt;p&gt;Since the customer satisfaction metric is an aggregation from scores provided by individuals, I&amp;#39;ve also tried using individual scores pre-event as training and using individual scores given post-event as test, fitting traditional classification models to the training set and making predictions on the test set. To estimate the difference between the expected versus actual customer metric, I&amp;#39;ve taken the training scores and predicted test scores and calculated the aggregated metric for those records as the expected aggregate value and separately calculated the aggregated metric over the training scores and actual test values for the actual aggregate value. However, this method gives me a larger than actual estimated impact - regardless of whether or not I balance the classes during training, this modeling approach tends to predict one customer rating more frequently than the others.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also done some reading into causality libraries/modeling approaches, like econml DML, but I&amp;#39;m not sure how helpful CATE would be here, since my metric of interest is an aggregation. Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10unjik", "is_robot_indexable": true, "report_reasons": null, "author": "Translate_pro", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10unjik/techniques_for_estimating_the_impact_of_an_event/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10unjik/techniques_for_estimating_the_impact_of_an_event/", "subreddit_subscribers": 845036, "created_utc": 1675631230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently we're just using google sheets to document stuff and while its working, it's been a hassle keeping it up. A miss in the updates can break the whole thing, which can be frustrating rather than focusing on my tests. Also it becomes tedious too when someone checks up on it and it takes a long time to backtrack on everything.\n\nWe've tried using the timeline feature or tasking in Asana but its quite tedious as well to track and keep tickets or are we just doing it wrong? Lately we've been planning on trying out to setup like a kanban thing but just wondering if there are any best practices for this?", "author_fullname": "t2_7u37sy3v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What practices/tools/platforms are best on documenting undergoing tests (AB tests, and etc.) and strategies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u9kkw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675593106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently we&amp;#39;re just using google sheets to document stuff and while its working, it&amp;#39;s been a hassle keeping it up. A miss in the updates can break the whole thing, which can be frustrating rather than focusing on my tests. Also it becomes tedious too when someone checks up on it and it takes a long time to backtrack on everything.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve tried using the timeline feature or tasking in Asana but its quite tedious as well to track and keep tickets or are we just doing it wrong? Lately we&amp;#39;ve been planning on trying out to setup like a kanban thing but just wondering if there are any best practices for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10u9kkw", "is_robot_indexable": true, "report_reasons": null, "author": "Aggressive-Pup-28", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10u9kkw/what_practicestoolsplatforms_are_best_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10u9kkw/what_practicestoolsplatforms_are_best_on/", "subreddit_subscribers": 845036, "created_utc": 1675593106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I live in Brazil and have been working as a DA for two years now, I'm now working for a big 4 consulting firm. I got kinda jealous of other people in tech (mainly web/mobile devs) getting all these remote jobs that pay in dollars, and make probably more than 5 times what I make, so I decided I would try to do it too.\n\nGranted, I haven't applied to many jobs yet, but  I wanted some inputs from you guys, if it's something that's worth pursuing, or if I should just change careers and start developing.", "author_fullname": "t2_alhkg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do US based companies hire Data/Business analysts overseas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10uv2ls", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675650350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I live in Brazil and have been working as a DA for two years now, I&amp;#39;m now working for a big 4 consulting firm. I got kinda jealous of other people in tech (mainly web/mobile devs) getting all these remote jobs that pay in dollars, and make probably more than 5 times what I make, so I decided I would try to do it too.&lt;/p&gt;\n\n&lt;p&gt;Granted, I haven&amp;#39;t applied to many jobs yet, but  I wanted some inputs from you guys, if it&amp;#39;s something that&amp;#39;s worth pursuing, or if I should just change careers and start developing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uv2ls", "is_robot_indexable": true, "report_reasons": null, "author": "Kyomeii", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uv2ls/do_us_based_companies_hire_databusiness_analysts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uv2ls/do_us_based_companies_hire_databusiness_analysts/", "subreddit_subscribers": 845036, "created_utc": 1675650350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey folks, working on a research project right now doing a binary classification on text data. Essentially, I have a ton of text data that I'm looking over and labeling each datapoint (composed of text + a couple of other less useful features) as \"yes\" or \"no\" if the text looks like it fits a condition (I apologize for the vagueness). The unfortunate part is that I'm only hitting \"yes\" a very low % of the time, which is completely expected, but it's resulted in me only having \\~100 positive examples. Ideally, I'd have wayyy more. So this brings me to my question, what methods exist to find positive examples more efficiently while limiting how much bias is going into the process?\n\nI have a couple of thoughts. I was considering doing an unsupervised clustering, maybe K-means, and see if my positive samples fit snuggly into a cluster, and look at the other examples in that cluster. This might work but seems a little inefficient. \n\nI've also considered building a classifier based on the positive samples I have right now, which might get me something, but I worry a lot about overfitting, perhaps there is a classification technique you could recommend to me in this case that works well with small amounts of data? I've considered simple models like logistic regression, but bayesian methods have also caught my eye. I'm also considering using some sort of tree-based method and increasing the depth of the tree incrementally until I start to see something that I want.\n\nLastly, I've tried to use some domain knowledge to generate a candidate list of samples. Basically, I've looked at the positive examples so far and applied what I know to be (somewhat) true about this particular problem to limit the samples a bit more with keyword matching. None of these have been quite as successful as I'd like, so I'd like to consult your wisdom and see if you have any advice for me :) Thank you for your help.", "author_fullname": "t2_16io5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I safely identify more positive examples in a text dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10urvpy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675641851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, working on a research project right now doing a binary classification on text data. Essentially, I have a ton of text data that I&amp;#39;m looking over and labeling each datapoint (composed of text + a couple of other less useful features) as &amp;quot;yes&amp;quot; or &amp;quot;no&amp;quot; if the text looks like it fits a condition (I apologize for the vagueness). The unfortunate part is that I&amp;#39;m only hitting &amp;quot;yes&amp;quot; a very low % of the time, which is completely expected, but it&amp;#39;s resulted in me only having ~100 positive examples. Ideally, I&amp;#39;d have wayyy more. So this brings me to my question, what methods exist to find positive examples more efficiently while limiting how much bias is going into the process?&lt;/p&gt;\n\n&lt;p&gt;I have a couple of thoughts. I was considering doing an unsupervised clustering, maybe K-means, and see if my positive samples fit snuggly into a cluster, and look at the other examples in that cluster. This might work but seems a little inefficient. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also considered building a classifier based on the positive samples I have right now, which might get me something, but I worry a lot about overfitting, perhaps there is a classification technique you could recommend to me in this case that works well with small amounts of data? I&amp;#39;ve considered simple models like logistic regression, but bayesian methods have also caught my eye. I&amp;#39;m also considering using some sort of tree-based method and increasing the depth of the tree incrementally until I start to see something that I want.&lt;/p&gt;\n\n&lt;p&gt;Lastly, I&amp;#39;ve tried to use some domain knowledge to generate a candidate list of samples. Basically, I&amp;#39;ve looked at the positive examples so far and applied what I know to be (somewhat) true about this particular problem to limit the samples a bit more with keyword matching. None of these have been quite as successful as I&amp;#39;d like, so I&amp;#39;d like to consult your wisdom and see if you have any advice for me :) Thank you for your help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10urvpy", "is_robot_indexable": true, "report_reasons": null, "author": "Doubles76", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10urvpy/how_can_i_safely_identify_more_positive_examples/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10urvpy/how_can_i_safely_identify_more_positive_examples/", "subreddit_subscribers": 845036, "created_utc": 1675641851.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys,\n\nI'm a junior in an undergrad BS Data Science program at a small Christian university in the Midwest. I've been searching for a summer internship in Data Science/Data Analytics since September and have had no luck. I've reached out to people in my network and those of my family and professors wherever possible, and I've visited my university's career center several times for resume revisions and have adopted the various strategies they have suggested. I've submitted somewhere in the ballpark of 200 applications in the last 6 months, and I've been ghosted by most recruiters. Of the 200 applications, I received 4 callbacks for interviews, and of those 4, only 1 resulted in a follow-up interview. For this last position, I was well-prepared and felt that I performed well in both interviews, but alas, I finally received yet another rejection letter last week.\n\nI'm frustrated and disappointed, to say the least. I understand that these numbers are pretty typical in the current tech job market, and other Redditors frequently call it a \"numbers game.\" While merely continuing a barrage of new applications may work for new graduates and recently laid-off junior positions, I'm fighting against time since I'm looking for a summer internship that ends before I resume classes in the fall. At this current rate, I'd have to submit another 50 applications to get a chance of even one more interview, which is incredibly time-consuming. The job search process wore me out months ago - I'm discouraged and exhausted - and it takes valuable time away from actually practicing my skills and learning new topics. On top of that, it already feels too late. My academic advisor told me in October to try to have something figured out by the end of December since many internship positions would already be filled beyond that point. It's now February. If my odds were bad 6 months ago, it's only going to get worse.\n\nI'm kind of at my wits' end. I also am approaching the point where I need to have some concrete summer plans so I can coordinate schedules with family and friends, not just \"I'm looking for an internship\" because that doesn't seem to be panning out. Here are a few of my options:\n\n1. Go back to the summer camp where I worked for the last two years.\n   1. Pros: I already have friends there and I'm 99% guaranteed a job if I apply. I'll also be on the West Coast, which is where I want to be.\n   2. Cons: The pay is little more than a volunteer stipend. I won't have much opportunity to develop tech skills or otherwise advance my career.\n2. Stay at home for the summer. I could split my time between learning through online MOOCs and potentially look for a low-skill job such as administrative assistant or data entry. Or a gig like Doordash. \n   1. Pros: I can live with my family for free. I'll also be on the West Coast and will have the flexibility to pursue my outdoor hobbies while working on tech skills. The wage floor is also pretty high in my state.\n   2. Cons: There's no guarantee that I can find a job, especially for something that only lasts the summer when employers may be wanting something more permanent. It also feels kind of humiliating that I failed to find a job in my industry?\n3. Look for internships in adjacent fields that involve data. I've seen this suggested to people looking to make a career switch but I'm not sure if these exist or if they will work for me. I also won't have the mentorship in DS/DA that I'm specifically looking for. \n\nWhat factors should I take into consideration when I look at my options for this summer? Is there anything else as far as career development that I should also think about? \n\nI'm also wondering if the current scarcity of tech positions is homogeneous across the industry. DS doesn't seem as attractive as it was a few years ago, and now I feel unsure about all of my career/academic choices to date.\n\nFirst, I feel like DS was hyped up to more than it was when I first started college as a freshman, and now it seems that a lot of people on the internet also think that it's now on the decline. It also seems to be the consensus that the best path into DS is through a more established undergrad program in CS, Math, or Stats, rather than a DS degree because they tend to be so broad in nature that you learn a little bit about many topics but nothing sufficiently in-depth to be useful. Unfortunately, that seems to be my experience - I don't feel like I'm learning anything in classes so I'm taking time outside of class to work on Kaggle Learn courses and the Andrew Ng Coursera ML course. If I could go back in time, I would have gone into CS and started at a different university. I'm not particularly fond of my university or the Midwest (I long to be back on the West Coast) and it's a long story of how I ended up here, but suffice it to say that the reason I'm still here is because I'm on a full-tuition scholarship which I'd lose if I transferred elsewhere. But I can't go back in time. I'm a junior and should be graduating in two more semesters after this semester, so I had been OK with sticking it out under the assumption that I could get a decent job when I graduate and move back to the West Coast. But I'm at the point where I question if any of that is true. \n\nSecond, I'm not even sure anymore if this is really what I want to do. In my senior year of high school I became really interested in finance, and DS seemed like the perfect way to join my long standing interest in tech with what a growing interest in math (which, sidenote, may have died after I took Intro to Linear Algebra. I like to think it was just a bad professor) and my new interest in business topics. In the last semester or so, I've clarified my long-term goals and want to break into the ML field and eventually become an MLE. However, in working with scikit-learn and other ML frameworks in Kaggle Learn courses, it feels dull and I'm just doing it because I have gaps in my knowledge. I don't really find myself loving it. Is this normal? I know it's preferable to work on my own projects rather than repetitive activities, but I still don't feel that I know enough skills to work on my own projects. I often wonder if I'd be better off in a more standard CS track towards become an SWE or backend web dev. But there's huge gaps in my knowledge there as well. And if I switch majors, I'll probably have to take an extra semester or two because my current DS requirements don't include any of the dev, networking, or security classes. \n\nI guess to summarize, I went into this degree track with certain expectations and everything has turned out to be a disappointment. I'm not sure what to do anymore because although I'm willing to work hard, it's difficult to maintain the motivation to do so when I'm not sure if everything I'm doing is mere futility. Thanks for taking the time to read through all this and I appreciate any advice/feedback you may have.", "author_fullname": "t2_s15825ic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Failed internship search in a difficult job market: Bad timing or is DS a bubble?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10ulcdc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675626029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a junior in an undergrad BS Data Science program at a small Christian university in the Midwest. I&amp;#39;ve been searching for a summer internship in Data Science/Data Analytics since September and have had no luck. I&amp;#39;ve reached out to people in my network and those of my family and professors wherever possible, and I&amp;#39;ve visited my university&amp;#39;s career center several times for resume revisions and have adopted the various strategies they have suggested. I&amp;#39;ve submitted somewhere in the ballpark of 200 applications in the last 6 months, and I&amp;#39;ve been ghosted by most recruiters. Of the 200 applications, I received 4 callbacks for interviews, and of those 4, only 1 resulted in a follow-up interview. For this last position, I was well-prepared and felt that I performed well in both interviews, but alas, I finally received yet another rejection letter last week.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m frustrated and disappointed, to say the least. I understand that these numbers are pretty typical in the current tech job market, and other Redditors frequently call it a &amp;quot;numbers game.&amp;quot; While merely continuing a barrage of new applications may work for new graduates and recently laid-off junior positions, I&amp;#39;m fighting against time since I&amp;#39;m looking for a summer internship that ends before I resume classes in the fall. At this current rate, I&amp;#39;d have to submit another 50 applications to get a chance of even one more interview, which is incredibly time-consuming. The job search process wore me out months ago - I&amp;#39;m discouraged and exhausted - and it takes valuable time away from actually practicing my skills and learning new topics. On top of that, it already feels too late. My academic advisor told me in October to try to have something figured out by the end of December since many internship positions would already be filled beyond that point. It&amp;#39;s now February. If my odds were bad 6 months ago, it&amp;#39;s only going to get worse.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m kind of at my wits&amp;#39; end. I also am approaching the point where I need to have some concrete summer plans so I can coordinate schedules with family and friends, not just &amp;quot;I&amp;#39;m looking for an internship&amp;quot; because that doesn&amp;#39;t seem to be panning out. Here are a few of my options:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Go back to the summer camp where I worked for the last two years.\n\n&lt;ol&gt;\n&lt;li&gt;Pros: I already have friends there and I&amp;#39;m 99% guaranteed a job if I apply. I&amp;#39;ll also be on the West Coast, which is where I want to be.&lt;/li&gt;\n&lt;li&gt;Cons: The pay is little more than a volunteer stipend. I won&amp;#39;t have much opportunity to develop tech skills or otherwise advance my career.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Stay at home for the summer. I could split my time between learning through online MOOCs and potentially look for a low-skill job such as administrative assistant or data entry. Or a gig like Doordash. \n\n&lt;ol&gt;\n&lt;li&gt;Pros: I can live with my family for free. I&amp;#39;ll also be on the West Coast and will have the flexibility to pursue my outdoor hobbies while working on tech skills. The wage floor is also pretty high in my state.&lt;/li&gt;\n&lt;li&gt;Cons: There&amp;#39;s no guarantee that I can find a job, especially for something that only lasts the summer when employers may be wanting something more permanent. It also feels kind of humiliating that I failed to find a job in my industry?&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Look for internships in adjacent fields that involve data. I&amp;#39;ve seen this suggested to people looking to make a career switch but I&amp;#39;m not sure if these exist or if they will work for me. I also won&amp;#39;t have the mentorship in DS/DA that I&amp;#39;m specifically looking for. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What factors should I take into consideration when I look at my options for this summer? Is there anything else as far as career development that I should also think about? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also wondering if the current scarcity of tech positions is homogeneous across the industry. DS doesn&amp;#39;t seem as attractive as it was a few years ago, and now I feel unsure about all of my career/academic choices to date.&lt;/p&gt;\n\n&lt;p&gt;First, I feel like DS was hyped up to more than it was when I first started college as a freshman, and now it seems that a lot of people on the internet also think that it&amp;#39;s now on the decline. It also seems to be the consensus that the best path into DS is through a more established undergrad program in CS, Math, or Stats, rather than a DS degree because they tend to be so broad in nature that you learn a little bit about many topics but nothing sufficiently in-depth to be useful. Unfortunately, that seems to be my experience - I don&amp;#39;t feel like I&amp;#39;m learning anything in classes so I&amp;#39;m taking time outside of class to work on Kaggle Learn courses and the Andrew Ng Coursera ML course. If I could go back in time, I would have gone into CS and started at a different university. I&amp;#39;m not particularly fond of my university or the Midwest (I long to be back on the West Coast) and it&amp;#39;s a long story of how I ended up here, but suffice it to say that the reason I&amp;#39;m still here is because I&amp;#39;m on a full-tuition scholarship which I&amp;#39;d lose if I transferred elsewhere. But I can&amp;#39;t go back in time. I&amp;#39;m a junior and should be graduating in two more semesters after this semester, so I had been OK with sticking it out under the assumption that I could get a decent job when I graduate and move back to the West Coast. But I&amp;#39;m at the point where I question if any of that is true. &lt;/p&gt;\n\n&lt;p&gt;Second, I&amp;#39;m not even sure anymore if this is really what I want to do. In my senior year of high school I became really interested in finance, and DS seemed like the perfect way to join my long standing interest in tech with what a growing interest in math (which, sidenote, may have died after I took Intro to Linear Algebra. I like to think it was just a bad professor) and my new interest in business topics. In the last semester or so, I&amp;#39;ve clarified my long-term goals and want to break into the ML field and eventually become an MLE. However, in working with scikit-learn and other ML frameworks in Kaggle Learn courses, it feels dull and I&amp;#39;m just doing it because I have gaps in my knowledge. I don&amp;#39;t really find myself loving it. Is this normal? I know it&amp;#39;s preferable to work on my own projects rather than repetitive activities, but I still don&amp;#39;t feel that I know enough skills to work on my own projects. I often wonder if I&amp;#39;d be better off in a more standard CS track towards become an SWE or backend web dev. But there&amp;#39;s huge gaps in my knowledge there as well. And if I switch majors, I&amp;#39;ll probably have to take an extra semester or two because my current DS requirements don&amp;#39;t include any of the dev, networking, or security classes. &lt;/p&gt;\n\n&lt;p&gt;I guess to summarize, I went into this degree track with certain expectations and everything has turned out to be a disappointment. I&amp;#39;m not sure what to do anymore because although I&amp;#39;m willing to work hard, it&amp;#39;s difficult to maintain the motivation to do so when I&amp;#39;m not sure if everything I&amp;#39;m doing is mere futility. Thanks for taking the time to read through all this and I appreciate any advice/feedback you may have.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ulcdc", "is_robot_indexable": true, "report_reasons": null, "author": "mountainstarpenguin", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ulcdc/failed_internship_search_in_a_difficult_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ulcdc/failed_internship_search_in_a_difficult_job/", "subreddit_subscribers": 845036, "created_utc": 1675626029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m looking for data collection tool suggestions. We periodically need to collect data from teams via drop downs and free fields and Excel is proving difficult to manage (people keep deleting things, changing formulas, etc). Does anyone have any experience with another data collection tool?\n\nIdeally this tool would save the question results and the team could go back and see what the entered originally and make changes when we repeat the exercise, which we plan on doing a few times a year.", "author_fullname": "t2_qnn4s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Collection Tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uk3la", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675625519.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675623074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for data collection tool suggestions. We periodically need to collect data from teams via drop downs and free fields and Excel is proving difficult to manage (people keep deleting things, changing formulas, etc). Does anyone have any experience with another data collection tool?&lt;/p&gt;\n\n&lt;p&gt;Ideally this tool would save the question results and the team could go back and see what the entered originally and make changes when we repeat the exercise, which we plan on doing a few times a year.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uk3la", "is_robot_indexable": true, "report_reasons": null, "author": "Aoiumi1234", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uk3la/data_collection_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uk3la/data_collection_tool/", "subreddit_subscribers": 845036, "created_utc": 1675623074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to come up with a feature/set of features, and getting a bit stuck. For the purpose of this question lets say its the ratio of number of times a person clicks on an ad (abbreviated ac) on a website/ time they are on the website.  Here is an example of what I'm thinking about:\n\nsubject 1:  3 hrs on reddit, 2 ac.  One hour on facebook, 5 ac\n\nsubject 2: 1 hour on reddit, 0 ac, three hours on twitter, 2 ac\n\nsubject 3:  5 hours on live journal, 1 ac.\n\nIn this example I would create 4 features:  ac/hour reddit, ac/hour facebook, ac/hour twitter, and ac/hour livejournal.   I'm having trouble with the fact that these four features will have a lot of missing data.  In this particular example, pretend that I've collapsed the webiste categories as much as possible.   What are some other options of dealing with the data?  How does one use data like this in a model without imputing the missing values? I'm open to not using a ratio for this feature set - but I do want exposure to the website to be included somehow.\n\nThanks!\n\nEdited to add, the missingness comes from the situation when someone has 0 hours on the website, its 0 clicks/0 hours so its undefined. This is a different situation than a zero someone who is on the webiste for 5 hours but never clicked on an ad.", "author_fullname": "t2_14fn4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stuck on a feature engineering problem with missing data.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uiv7r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675621876.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675620151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to come up with a feature/set of features, and getting a bit stuck. For the purpose of this question lets say its the ratio of number of times a person clicks on an ad (abbreviated ac) on a website/ time they are on the website.  Here is an example of what I&amp;#39;m thinking about:&lt;/p&gt;\n\n&lt;p&gt;subject 1:  3 hrs on reddit, 2 ac.  One hour on facebook, 5 ac&lt;/p&gt;\n\n&lt;p&gt;subject 2: 1 hour on reddit, 0 ac, three hours on twitter, 2 ac&lt;/p&gt;\n\n&lt;p&gt;subject 3:  5 hours on live journal, 1 ac.&lt;/p&gt;\n\n&lt;p&gt;In this example I would create 4 features:  ac/hour reddit, ac/hour facebook, ac/hour twitter, and ac/hour livejournal.   I&amp;#39;m having trouble with the fact that these four features will have a lot of missing data.  In this particular example, pretend that I&amp;#39;ve collapsed the webiste categories as much as possible.   What are some other options of dealing with the data?  How does one use data like this in a model without imputing the missing values? I&amp;#39;m open to not using a ratio for this feature set - but I do want exposure to the website to be included somehow.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;Edited to add, the missingness comes from the situation when someone has 0 hours on the website, its 0 clicks/0 hours so its undefined. This is a different situation than a zero someone who is on the webiste for 5 hours but never clicked on an ad.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uiv7r", "is_robot_indexable": true, "report_reasons": null, "author": "Ohio_Bean", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uiv7r/stuck_on_a_feature_engineering_problem_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uiv7r/stuck_on_a_feature_engineering_problem_with/", "subreddit_subscribers": 845036, "created_utc": 1675620151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A while back, my close colleague at work had an interview with Sr. Director of Analytics (or maybe just a Director, I forgot), for data related opening. \n\nHe was asked to describe what would he do with 3 data points, representing 3 months, say month of January through March.\n\nI confirmed with my colleague that it was not 3-month (or 90 days data), it was just literally 3 data points, for example sales revenue for those 3 months.\n\nMy hunch at that time was, either the person smoked something, or he blew the interview on purpose, as the recruiter told him the very next day as they decided to \u201cpromote\u201d from within.\n\nI did try to think a variety of ways to derive meaningful reference based on 3 numbers, but eventually I told my colleague that most likely the interview was fake.\n\nI guess I want to know from different perspective, whether you can actually use 3 data points in a meaningful way, for business.\n\nAny taker?\n\nUpdate: as suggested, the company he interviewed with was F100, big in Telco.", "author_fullname": "t2_ul5y0kdu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What can you do with 3 data points?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uh0at", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675620628.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675615684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A while back, my close colleague at work had an interview with Sr. Director of Analytics (or maybe just a Director, I forgot), for data related opening. &lt;/p&gt;\n\n&lt;p&gt;He was asked to describe what would he do with 3 data points, representing 3 months, say month of January through March.&lt;/p&gt;\n\n&lt;p&gt;I confirmed with my colleague that it was not 3-month (or 90 days data), it was just literally 3 data points, for example sales revenue for those 3 months.&lt;/p&gt;\n\n&lt;p&gt;My hunch at that time was, either the person smoked something, or he blew the interview on purpose, as the recruiter told him the very next day as they decided to \u201cpromote\u201d from within.&lt;/p&gt;\n\n&lt;p&gt;I did try to think a variety of ways to derive meaningful reference based on 3 numbers, but eventually I told my colleague that most likely the interview was fake.&lt;/p&gt;\n\n&lt;p&gt;I guess I want to know from different perspective, whether you can actually use 3 data points in a meaningful way, for business.&lt;/p&gt;\n\n&lt;p&gt;Any taker?&lt;/p&gt;\n\n&lt;p&gt;Update: as suggested, the company he interviewed with was F100, big in Telco.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uh0at", "is_robot_indexable": true, "report_reasons": null, "author": "kyleireddit", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uh0at/what_can_you_do_with_3_data_points/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uh0at/what_can_you_do_with_3_data_points/", "subreddit_subscribers": 845036, "created_utc": 1675615684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am learning to use SQL server. I am trying to create a catalog but get the following highlighted error. Have tried searching for the solution couldn't solve it. Please HELP.\n\nhttps://preview.redd.it/4muv1k1brcga1.png?width=1689&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c4fe922dea4efa6fe772f498751deda348c86755", "author_fullname": "t2_7d59jl16", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with MS SQL Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4muv1k1brcga1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef1f77a3df412e367407909de948c593ce004d7f"}, {"y": 94, "x": 216, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=897522d4750e603fa0e99ee04c22facaf1fc2b53"}, {"y": 140, "x": 320, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0e31d574314b709a63102eb4d6ee8977c62b2e4"}, {"y": 281, "x": 640, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1767a0cec2de7ffd4b9437c9b5315b66d8e0fb5c"}, {"y": 421, "x": 960, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8da764bbfe7f013436d7e79c101aab3e907f112f"}, {"y": 474, "x": 1080, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ac1815401aa272a9385ae472ff1b93775b3acc9"}], "s": {"y": 742, "x": 1689, "u": "https://preview.redd.it/4muv1k1brcga1.png?width=1689&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c4fe922dea4efa6fe772f498751deda348c86755"}, "id": "4muv1k1brcga1"}}, "name": "t3_10ua3yf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WvJ-7fpbXA6W6HNNu2RWjt0i9hzdATaA0DJOPllYGhU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675595270.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am learning to use SQL server. I am trying to create a catalog but get the following highlighted error. Have tried searching for the solution couldn&amp;#39;t solve it. Please HELP.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4muv1k1brcga1.png?width=1689&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c4fe922dea4efa6fe772f498751deda348c86755\"&gt;https://preview.redd.it/4muv1k1brcga1.png?width=1689&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=c4fe922dea4efa6fe772f498751deda348c86755&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10ua3yf", "is_robot_indexable": true, "report_reasons": null, "author": "yujshr", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10ua3yf/need_help_with_ms_sql_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10ua3yf/need_help_with_ms_sql_server/", "subreddit_subscribers": 845036, "created_utc": 1675595270.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I'm 14 years old, I really liked the data science area, I've always liked computers (I've been using them since I was 3 years old), but researching about it, I saw on a website that you need to be able to communicate well with other people. I want to know if it is really necessary, because I will have to train this part a lot.\n\nI can be good at coming up with ideas and delivering them, but is good communication necessary? (here we call it \"sales talk\").", "author_fullname": "t2_pf53e81a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "you need to be able to communicate well with other people?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10urnyk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675641352.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m 14 years old, I really liked the data science area, I&amp;#39;ve always liked computers (I&amp;#39;ve been using them since I was 3 years old), but researching about it, I saw on a website that you need to be able to communicate well with other people. I want to know if it is really necessary, because I will have to train this part a lot.&lt;/p&gt;\n\n&lt;p&gt;I can be good at coming up with ideas and delivering them, but is good communication necessary? (here we call it &amp;quot;sales talk&amp;quot;).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10urnyk", "is_robot_indexable": true, "report_reasons": null, "author": "iwdxd", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10urnyk/you_need_to_be_able_to_communicate_well_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10urnyk/you_need_to_be_able_to_communicate_well_with/", "subreddit_subscribers": 845036, "created_utc": 1675641352.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019d like to start a data science degree but I already have a metric crap ton of student loans and cannot afford to pay graduate or even undergraduate tuition out of pocket. \n\nI\u2019ve found some classes on edx by Harvard and an online tutorial website called data camp that will supposedly allow me to learn the needed skills. \n\nAre these viable ways to earn certification, build a portfolio and start a career?", "author_fullname": "t2_mxouy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I start a data career without another degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10un4bt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675630248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019d like to start a data science degree but I already have a metric crap ton of student loans and cannot afford to pay graduate or even undergraduate tuition out of pocket. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve found some classes on edx by Harvard and an online tutorial website called data camp that will supposedly allow me to learn the needed skills. &lt;/p&gt;\n\n&lt;p&gt;Are these viable ways to earn certification, build a portfolio and start a career?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10un4bt", "is_robot_indexable": true, "report_reasons": null, "author": "agawl81", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10un4bt/can_i_start_a_data_career_without_another_degree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10un4bt/can_i_start_a_data_career_without_another_degree/", "subreddit_subscribers": 845036, "created_utc": 1675630248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello people! I hope my question is appropriate for this community. I have the following plot (figure), and I would like to show that in the central region there is a linear pattern, and find the correct line with linear regression (I know how to do linear regression). \n\nThe problem here is how do I decide to exclude the data that stands on a line parallel to y axis or x axis? Is there any statistical test to do that?\n\nThe data is the measure of two continuous variables, so there is not an \"a priori\" method to exclude some of them. \n\nThank you in advance!", "author_fullname": "t2_nuspi80u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to distinguish between 3 linear regressions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uieee", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675619013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello people! I hope my question is appropriate for this community. I have the following plot (figure), and I would like to show that in the central region there is a linear pattern, and find the correct line with linear regression (I know how to do linear regression). &lt;/p&gt;\n\n&lt;p&gt;The problem here is how do I decide to exclude the data that stands on a line parallel to y axis or x axis? Is there any statistical test to do that?&lt;/p&gt;\n\n&lt;p&gt;The data is the measure of two continuous variables, so there is not an &amp;quot;a priori&amp;quot; method to exclude some of them. &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uieee", "is_robot_indexable": true, "report_reasons": null, "author": "Trattopino", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uieee/how_to_distinguish_between_3_linear_regressions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uieee/how_to_distinguish_between_3_linear_regressions/", "subreddit_subscribers": 845036, "created_utc": 1675619013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello there, I am trying to detect a fraud detection model which outputs risk as Low Medium or High, I have a customers id in one data frame and in another data frame i have their data that from which customer (source) id to which (target) how much money 'emt' is being transferred. Now I want to drop customer id from the initial data frame and add a new column containing a series of transaction for both sources and targets. How do i do this and is there a better way to do this?", "author_fullname": "t2_amimzgo5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to process additional data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10u69ua", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675580037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there, I am trying to detect a fraud detection model which outputs risk as Low Medium or High, I have a customers id in one data frame and in another data frame i have their data that from which customer (source) id to which (target) how much money &amp;#39;emt&amp;#39; is being transferred. Now I want to drop customer id from the initial data frame and add a new column containing a series of transaction for both sources and targets. How do i do this and is there a better way to do this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10u69ua", "is_robot_indexable": true, "report_reasons": null, "author": "Old_Stick_9560", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10u69ua/how_to_process_additional_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10u69ua/how_to_process_additional_data/", "subreddit_subscribers": 845036, "created_utc": 1675580037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_n9tfb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No reply unfortunately", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_10uuyn8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1bm8rUyeJL3RWrc7vsyp8-kTLBO-T2a4ejrUF1C2Zsw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675650026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/eoyhlrytriga1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/eoyhlrytriga1.jpg?auto=webp&amp;v=enabled&amp;s=13ecfc163c5a030c01ff3284780cb63133210ed5", "width": 1270, "height": 2469}, "resolutions": [{"url": "https://preview.redd.it/eoyhlrytriga1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26ad30c871e0323d17b12031253b7d63fddb331a", "width": 108, "height": 209}, {"url": "https://preview.redd.it/eoyhlrytriga1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c76603e1da2d5361ede5cb1a38ec5224e23bb4e6", "width": 216, "height": 419}, {"url": "https://preview.redd.it/eoyhlrytriga1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e2e03e1a29217b4a67db5933d4abe8f46e91b1f", "width": 320, "height": 622}, {"url": "https://preview.redd.it/eoyhlrytriga1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ceca0e3c8cf37e668a26aaeb8ff238c2fb330b3a", "width": 640, "height": 1244}, {"url": "https://preview.redd.it/eoyhlrytriga1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1f1134bb77b66212afb204f7bebda6d98678512d", "width": 960, "height": 1866}, {"url": "https://preview.redd.it/eoyhlrytriga1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70338691e17eacfbb8cd814c49442632043cba8b", "width": 1080, "height": 2099}], "variants": {}, "id": "O3TfpKHdUftIi74cxGK0tQTqQ5Dp0D1HwsK8E5EI0uw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uuyn8", "is_robot_indexable": true, "report_reasons": null, "author": "xliang23", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uuyn8/no_reply_unfortunately/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/eoyhlrytriga1.jpg", "subreddit_subscribers": 845036, "created_utc": 1675650026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2hocwgkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What product or service could be sold by data science professionals at scale?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10uho9q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675617289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "10uho9q", "is_robot_indexable": true, "report_reasons": null, "author": "Mark_Collins", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/10uho9q/what_product_or_service_could_be_sold_by_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/10uho9q/what_product_or_service_could_be_sold_by_data/", "subreddit_subscribers": 845036, "created_utc": 1675617289.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}