{"kind": "Listing", "data": {"after": "t3_11aq4s7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_8dxkdy1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anon loses 8 terabytes of data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "name": "t3_11b2tkr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 1008, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 1008, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/muuIeUDZrOAFmfIIrzVgFH8XUjrW9s8fSEdq-r9EJb0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677274559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/e2ntykkey8ka1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/e2ntykkey8ka1.jpg?auto=webp&amp;v=enabled&amp;s=784f5b98a08f6920fede9b514539d1c72b8426b9", "width": 750, "height": 364}, "resolutions": [{"url": "https://preview.redd.it/e2ntykkey8ka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e508f212edecddc1d4ad96079fe5da3762cd5578", "width": 108, "height": 52}, {"url": "https://preview.redd.it/e2ntykkey8ka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0186b90a768a8dee6d6be99274bdc5a736b0e3c5", "width": 216, "height": 104}, {"url": "https://preview.redd.it/e2ntykkey8ka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=586f27eff46baab138590040452bc3b454f0cb89", "width": 320, "height": 155}, {"url": "https://preview.redd.it/e2ntykkey8ka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b074e177aa2d9191a67b0008801fde16a261962e", "width": 640, "height": 310}], "variants": {}, "id": "IOCx6E11r7MTm3EOFDXg9MVEb2SzaHzBTzLv9J_RkL8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b2tkr", "is_robot_indexable": true, "report_reasons": null, "author": "Epoxhy", "discussion_type": null, "num_comments": 185, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b2tkr/anon_loses_8_terabytes_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/e2ntykkey8ka1.jpg", "subreddit_subscribers": 671169, "created_utc": 1677274559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am having trouble sending a 101GB file to someone. I have tried Google Drive but the recipient has been getting a \"bandwidth quota exceeded\" message from google about this file. What would be the best way to get this file to them?", "author_fullname": "t2_cdfdsbku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to send a 101GB file to someone else?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11atddz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677250770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am having trouble sending a 101GB file to someone. I have tried Google Drive but the recipient has been getting a &amp;quot;bandwidth quota exceeded&amp;quot; message from google about this file. What would be the best way to get this file to them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11atddz", "is_robot_indexable": true, "report_reasons": null, "author": "Dramatic_Law_4239", "discussion_type": null, "num_comments": 100, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11atddz/how_to_send_a_101gb_file_to_someone_else/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11atddz/how_to_send_a_101gb_file_to_someone_else/", "subreddit_subscribers": 671169, "created_utc": 1677250770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello r/DataHoarder I do a lot of sweeping rips of images and videos here on reddit - but there's a problem this often results in a lot of dupliactes (same image - different file name) do you guys know of any better ways to manage those as opposed to deleting them by hand?", "author_fullname": "t2_65xhtvia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to manage duplicates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b5jm0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677281434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello &lt;a href=\"/r/DataHoarder\"&gt;r/DataHoarder&lt;/a&gt; I do a lot of sweeping rips of images and videos here on reddit - but there&amp;#39;s a problem this often results in a lot of dupliactes (same image - different file name) do you guys know of any better ways to manage those as opposed to deleting them by hand?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b5jm0", "is_robot_indexable": true, "report_reasons": null, "author": "AstronautPale4588", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b5jm0/how_to_manage_duplicates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11b5jm0/how_to_manage_duplicates/", "subreddit_subscribers": 671169, "created_utc": 1677281434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_fs0ww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PrivTracker is an open-source service that allows to share torrent files just with your friends and nobody else. It shares peers only within a group which is using the same randomized private Announce URL generated for you by this site.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b4zg6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1677280003.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "privtracker.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://privtracker.com/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b4zg6", "is_robot_indexable": true, "report_reasons": null, "author": "foundfootagefan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b4zg6/privtracker_is_an_opensource_service_that_allows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://privtracker.com/", "subreddit_subscribers": 671169, "created_utc": 1677280003.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just got a new WD Red Pro 12tb and prior to putting it into service I decided to run an extended SMART test.  It's been running for about 30 hours now and still shows 90% remaining.  Given that I haven't written anything to the disk yet, I assume it's probably writing over the disk, but how long should I expect it to take?  The recommended poll time is about 18 hours.  The SMART stats show no errors at the moment.  \n\nThere is nothing else on the system using the disk.  I've seen people complain about the time taken for an extended SMART test, so perhaps I must be more patient.  Might I gain insight from anybody else's experience?", "author_fullname": "t2_1etf5co5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long should a SMART extended test take on a new (unused) 12TB drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b09u0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677268239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just got a new WD Red Pro 12tb and prior to putting it into service I decided to run an extended SMART test.  It&amp;#39;s been running for about 30 hours now and still shows 90% remaining.  Given that I haven&amp;#39;t written anything to the disk yet, I assume it&amp;#39;s probably writing over the disk, but how long should I expect it to take?  The recommended poll time is about 18 hours.  The SMART stats show no errors at the moment.  &lt;/p&gt;\n\n&lt;p&gt;There is nothing else on the system using the disk.  I&amp;#39;ve seen people complain about the time taken for an extended SMART test, so perhaps I must be more patient.  Might I gain insight from anybody else&amp;#39;s experience?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b09u0", "is_robot_indexable": true, "report_reasons": null, "author": "tsr_timmy", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b09u0/how_long_should_a_smart_extended_test_take_on_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11b09u0/how_long_should_a_smart_extended_test_take_on_a/", "subreddit_subscribers": 671169, "created_utc": 1677268239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Talk about general topics in our Discussion Thread!\n\n* Try out new software that you liked/hated? \n* Tell us about that $40 2TB MicroSD card from Amazon that's totally not a scam\n* Come show us how much data you lost since you didn't have backups!\n\nTotally not an attempt to build community rapport.", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataHoarder Discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b2oaq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Bi-Weekly Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677274212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Talk about general topics in our Discussion Thread!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Try out new software that you liked/hated? &lt;/li&gt;\n&lt;li&gt;Tell us about that $40 2TB MicroSD card from Amazon that&amp;#39;s totally not a scam&lt;/li&gt;\n&lt;li&gt;Come show us how much data you lost since you didn&amp;#39;t have backups!&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Totally not an attempt to build community rapport.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11b2oaq", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b2oaq/datahoarder_discussion/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/11b2oaq/datahoarder_discussion/", "subreddit_subscribers": 671169, "created_utc": 1677274212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Something is about to happen to your main storage. You know about it, but it's too late to prevent it. You look around and find this. What do you save on it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11b63u1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_n70s2tw8", "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-q8tl6X75rvigyuICcTNF-tZa3ZAoY8qqM4ZSdvjdtU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "gaming", "selftext": "", "author_fullname": "t2_8s416y93", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Found my 8mb memory card for the PS2 :)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/gaming", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_11aqx9z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 927, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 927, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-q8tl6X75rvigyuICcTNF-tZa3ZAoY8qqM4ZSdvjdtU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "mod_note": null, "created": 1677243853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dvknwg41f6ka1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?auto=webp&amp;v=enabled&amp;s=b0c64b1c60ffa96867e11e48e6c36790800b1226", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67921772929adc98cdefd714ac84b48f6ba9cfae", "width": 108, "height": 144}, {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b35c01d2c265bacc80a65669120267c8f95d9081", "width": 216, "height": 288}, {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=903decb605763e3cacecf6b467c742845e1e1bfb", "width": 320, "height": 426}, {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d43891f36ed2bb2d4505a4e43a589e2b1d3a62d9", "width": 640, "height": 853}, {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad142ef264e29c2a81fd617273da6b0eddb7095a", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b225d811009b7f1464d18f792850a4ea2dd3bb06", "width": 1080, "height": 1440}], "variants": {}, "id": "k5RKNy_Jhnxb_22gWZV70raWcoA-TBt-91VHwDdTMsA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh03", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11aqx9z", "is_robot_indexable": true, "report_reasons": null, "author": "Sam_Dragonborn1", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/gaming/comments/11aqx9z/found_my_8mb_memory_card_for_the_ps2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dvknwg41f6ka1.jpg", "subreddit_subscribers": 36303889, "created_utc": 1677243853.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1677282878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dvknwg41f6ka1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?auto=webp&amp;v=enabled&amp;s=b0c64b1c60ffa96867e11e48e6c36790800b1226", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=67921772929adc98cdefd714ac84b48f6ba9cfae", "width": 108, "height": 144}, {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b35c01d2c265bacc80a65669120267c8f95d9081", "width": 216, "height": 288}, {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=903decb605763e3cacecf6b467c742845e1e1bfb", "width": 320, "height": 426}, {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d43891f36ed2bb2d4505a4e43a589e2b1d3a62d9", "width": 640, "height": 853}, {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad142ef264e29c2a81fd617273da6b0eddb7095a", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/dvknwg41f6ka1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b225d811009b7f1464d18f792850a4ea2dd3bb06", "width": 1080, "height": 1440}], "variants": {}, "id": "k5RKNy_Jhnxb_22gWZV70raWcoA-TBt-91VHwDdTMsA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11b63u1", "is_robot_indexable": true, "report_reasons": null, "author": "PickledPhallus", "discussion_type": null, "num_comments": 6, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_11aqx9z", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b63u1/something_is_about_to_happen_to_your_main_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dvknwg41f6ka1.jpg", "subreddit_subscribers": 671169, "created_utc": 1677282878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My friend is deploying overseas soon and decided to depart from two of his Dell PowerVaults. One is full of 2TB enterprise drives, the other only has 3. \nHave been wanting to run a plexus server for a while now, as well as general data backup. Any have recommendations for how I should configure the raid?", "author_fullname": "t2_5796qdbk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Was gifted a DAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11ba185", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677293537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My friend is deploying overseas soon and decided to depart from two of his Dell PowerVaults. One is full of 2TB enterprise drives, the other only has 3. \nHave been wanting to run a plexus server for a while now, as well as general data backup. Any have recommendations for how I should configure the raid?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ba185", "is_robot_indexable": true, "report_reasons": null, "author": "rotsquid", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ba185/was_gifted_a_das/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ba185/was_gifted_a_das/", "subreddit_subscribers": 671169, "created_utc": 1677293537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently purchased a USB 18TB drive to use as an extra backup. Every two weeks I attach it to my NAS and run Hyperbackup so it has a copy of everything. I was planning to store it at my mom's house to have an off-site backup. Then I realized I could just attach the drive to my PC and use Backblaze personal. Besides the extra monthly cost of Backblaze personal (more because I have to pay them to keep the data permanently even while the drive is disconnected), are there any downsides? It might even be cheaper if I factor in the gas/time for driving to my mom's. Who else does it this way?\n\nAll of my most important data is backed up nightly to Backblaze B2 directly from the NAS, but that's all under 1TB. The rest of these files are more archival and because they total over 13TB I can't afford to do it directly through B2.", "author_fullname": "t2_65csv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any downsides to using Backblaze personal from an external HD vs just keeping the drive off-site?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b6b0q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677283373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently purchased a USB 18TB drive to use as an extra backup. Every two weeks I attach it to my NAS and run Hyperbackup so it has a copy of everything. I was planning to store it at my mom&amp;#39;s house to have an off-site backup. Then I realized I could just attach the drive to my PC and use Backblaze personal. Besides the extra monthly cost of Backblaze personal (more because I have to pay them to keep the data permanently even while the drive is disconnected), are there any downsides? It might even be cheaper if I factor in the gas/time for driving to my mom&amp;#39;s. Who else does it this way?&lt;/p&gt;\n\n&lt;p&gt;All of my most important data is backed up nightly to Backblaze B2 directly from the NAS, but that&amp;#39;s all under 1TB. The rest of these files are more archival and because they total over 13TB I can&amp;#39;t afford to do it directly through B2.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "13TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b6b0q", "is_robot_indexable": true, "report_reasons": null, "author": "Pikmeir", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11b6b0q/any_downsides_to_using_backblaze_personal_from_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11b6b0q/any_downsides_to_using_backblaze_personal_from_an/", "subreddit_subscribers": 671169, "created_utc": 1677283373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Should i do that by port forwarding and static ip or is it a bad idea?(ie. just stick with some cloud service)", "author_fullname": "t2_d338cejp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it a good idea to set up nas to work over the internet?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11anwhm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677233115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Should i do that by port forwarding and static ip or is it a bad idea?(ie. just stick with some cloud service)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11anwhm", "is_robot_indexable": true, "report_reasons": null, "author": "Ihsan3498", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11anwhm/is_it_a_good_idea_to_set_up_nas_to_work_over_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11anwhm/is_it_a_good_idea_to_set_up_nas_to_work_over_the/", "subreddit_subscribers": 671169, "created_utc": 1677233115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "r/DataHoarder/comments/nvehy1/\n\nI made this post almost 2 years ago. Right now, I'm at around 5-5.5TB of files including backups (that I want to backup physically anyways). \n\nShould I simply buy an 8TB+ drive, or is it time to move to something like a Raid 10 or ZFS1/2 setup? Or any other recommendations? \n\nIf either can saturate a 2.5Gbe link, I could move to doing some things directly off a NAS, so wondering, although it would be very expensive", "author_fullname": "t2_1mv7lrj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Buy a single drive or move to something larger ?(8TB+)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11amhaw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677227426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"/r/DataHoarder/comments/nvehy1/\"&gt;r/DataHoarder/comments/nvehy1/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I made this post almost 2 years ago. Right now, I&amp;#39;m at around 5-5.5TB of files including backups (that I want to backup physically anyways). &lt;/p&gt;\n\n&lt;p&gt;Should I simply buy an 8TB+ drive, or is it time to move to something like a Raid 10 or ZFS1/2 setup? Or any other recommendations? &lt;/p&gt;\n\n&lt;p&gt;If either can saturate a 2.5Gbe link, I could move to doing some things directly off a NAS, so wondering, although it would be very expensive&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11amhaw", "is_robot_indexable": true, "report_reasons": null, "author": "DangerousChoice42", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11amhaw/buy_a_single_drive_or_move_to_something_larger_8tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11amhaw/buy_a_single_drive_or_move_to_something_larger_8tb/", "subreddit_subscribers": 671169, "created_utc": 1677227426.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I'm new to setting up a NAS but I have some questions...\n\n&amp;#x200B;\n\nI'm currently hoping to set up a RAID 1 NAS with about 4tb or 5tb of capacity (so x2 4tb or 5tb hdds), and I was wondering if it would be worth investing the money into a synology nas? From my research, it seems to be more plug and play than a DIY setup obviously, but has a lot of downsides such as the higher price and being walled into the synology ecosystem. While I'm not really too worried about running into problems setting up a DIY setup with a pi, I don't have too much time to dedicate to this at the moment, which is why I'm considering synology.\n\n&amp;#x200B;\n\nAlso a very unrelated question - in regards to an off site backup, would it be a good idea to get a used LTO-4 or LTO-5 tape drive on ebay and a few tape cartridges and run a backup every few months?\n\n&amp;#x200B;\n\nI'm just getting into researching everything, so I apologize if any questions are kinda bad.", "author_fullname": "t2_ncm4a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Synology vs. DILY with a pi?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ai1hn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677211636.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;m new to setting up a NAS but I have some questions...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently hoping to set up a RAID 1 NAS with about 4tb or 5tb of capacity (so x2 4tb or 5tb hdds), and I was wondering if it would be worth investing the money into a synology nas? From my research, it seems to be more plug and play than a DIY setup obviously, but has a lot of downsides such as the higher price and being walled into the synology ecosystem. While I&amp;#39;m not really too worried about running into problems setting up a DIY setup with a pi, I don&amp;#39;t have too much time to dedicate to this at the moment, which is why I&amp;#39;m considering synology.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also a very unrelated question - in regards to an off site backup, would it be a good idea to get a used LTO-4 or LTO-5 tape drive on ebay and a few tape cartridges and run a backup every few months?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just getting into researching everything, so I apologize if any questions are kinda bad.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ai1hn", "is_robot_indexable": true, "report_reasons": null, "author": "crazedturtle77", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ai1hn/synology_vs_dily_with_a_pi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ai1hn/synology_vs_dily_with_a_pi/", "subreddit_subscribers": 671169, "created_utc": 1677211636.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there. I don\u2019t have any experience with downloading anything but a singular html file every once in a while, and even that didn\u2019t work out for this particular website\n\nThis site contains lore about a game, it\u2019s characters, locations, events, interactions, wars, religions and so on, all divided into various short stories so it\u2019s very important that all text from each link is downloaded properly \n\nI own IDM but have never successfully downloaded a site in this manner before. I read much about datahoarders talking about writing scripts but I am not familiar with this process\n\nHow can I use IDM, or any other program, to download every short story written on this website, without ending up with thousands of copies and unreadable minka? Detailed answers would be particularly appreifatws\n\nThe site in question is this;\n\nhttps://universe.leagueoflegends.com/en_US/\n\nThis link should be able to lead to every other link,through enough sub links", "author_fullname": "t2_8rjozvgt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m looking for help on how to archive a website with many layers of sub-links", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11ba3gj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677293719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there. I don\u2019t have any experience with downloading anything but a singular html file every once in a while, and even that didn\u2019t work out for this particular website&lt;/p&gt;\n\n&lt;p&gt;This site contains lore about a game, it\u2019s characters, locations, events, interactions, wars, religions and so on, all divided into various short stories so it\u2019s very important that all text from each link is downloaded properly &lt;/p&gt;\n\n&lt;p&gt;I own IDM but have never successfully downloaded a site in this manner before. I read much about datahoarders talking about writing scripts but I am not familiar with this process&lt;/p&gt;\n\n&lt;p&gt;How can I use IDM, or any other program, to download every short story written on this website, without ending up with thousands of copies and unreadable minka? Detailed answers would be particularly appreifatws&lt;/p&gt;\n\n&lt;p&gt;The site in question is this;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://universe.leagueoflegends.com/en_US/\"&gt;https://universe.leagueoflegends.com/en_US/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This link should be able to lead to every other link,through enough sub links&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j7B5XOPyTfR_uJ9-i3b2LSEqOTHEofdpzJvy0QgTzZM.jpg?auto=webp&amp;v=enabled&amp;s=e06712973ec645cc9421777148f3c24354964b1c", "width": 1920, "height": 946}, "resolutions": [{"url": "https://external-preview.redd.it/j7B5XOPyTfR_uJ9-i3b2LSEqOTHEofdpzJvy0QgTzZM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=444fffbd353e0d607a768e0e3abea15b66039d2a", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/j7B5XOPyTfR_uJ9-i3b2LSEqOTHEofdpzJvy0QgTzZM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bdd6149a012c4b760c671297648e49aa4f8c523c", "width": 216, "height": 106}, {"url": "https://external-preview.redd.it/j7B5XOPyTfR_uJ9-i3b2LSEqOTHEofdpzJvy0QgTzZM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7740b495037235b749784d67f152541bf554c89e", "width": 320, "height": 157}, {"url": "https://external-preview.redd.it/j7B5XOPyTfR_uJ9-i3b2LSEqOTHEofdpzJvy0QgTzZM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae79397298bc3457c453ed8eff801c210c444490", "width": 640, "height": 315}, {"url": "https://external-preview.redd.it/j7B5XOPyTfR_uJ9-i3b2LSEqOTHEofdpzJvy0QgTzZM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80db129ed24a2b1e398eb01c844d7f6866a1b65b", "width": 960, "height": 473}, {"url": "https://external-preview.redd.it/j7B5XOPyTfR_uJ9-i3b2LSEqOTHEofdpzJvy0QgTzZM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c80bfc9d613944272fced2460c7e8548b36e9b9", "width": 1080, "height": 532}], "variants": {}, "id": "hULVSvrAoNJ1PIpZGm-lxJlAz8ka5pB1ABbjWnHz7ls"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "44TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ba3gj", "is_robot_indexable": true, "report_reasons": null, "author": "IsMathScience_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/11ba3gj/im_looking_for_help_on_how_to_archive_a_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ba3gj/im_looking_for_help_on_how_to_archive_a_website/", "subreddit_subscribers": 671169, "created_utc": 1677293719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If you have a 5 x 10 tb raid-z2 vdev and you incrementally replace each drive, one at a time with 20 tb drives, once all are upgraded is there a way to then increase the overall vdev size to a total 5 x 20 tb size or do you have to hose the vdev and start over?", "author_fullname": "t2_pi19ro", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ZFS vdev size increase question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b7r5x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677287152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you have a 5 x 10 tb raid-z2 vdev and you incrementally replace each drive, one at a time with 20 tb drives, once all are upgraded is there a way to then increase the overall vdev size to a total 5 x 20 tb size or do you have to hose the vdev and start over?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b7r5x", "is_robot_indexable": true, "report_reasons": null, "author": "dootsie5times", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b7r5x/zfs_vdev_size_increase_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11b7r5x/zfs_vdev_size_increase_question/", "subreddit_subscribers": 671169, "created_utc": 1677287152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello\n\n(Please bare in mind that im new to this NAS topic)\n\ni want to get me an NAS Server and use it as an media server to watch 4k movies of it. So could be every NAS used as an media server? What do I need to pay attention for when buying a NAS for creating a media server? My budget is 600\u20ac which would be around 635$. I heard 4k movies are around 22GB large so i could need a lot of space.\n\nAlso could anyone explaine me what unraid means?", "author_fullname": "t2_9i27ujyu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be the best NAS Server for a Plex media server that can run 4k movies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b7ayr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677285967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;(Please bare in mind that im new to this NAS topic)&lt;/p&gt;\n\n&lt;p&gt;i want to get me an NAS Server and use it as an media server to watch 4k movies of it. So could be every NAS used as an media server? What do I need to pay attention for when buying a NAS for creating a media server? My budget is 600\u20ac which would be around 635$. I heard 4k movies are around 22GB large so i could need a lot of space.&lt;/p&gt;\n\n&lt;p&gt;Also could anyone explaine me what unraid means?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b7ayr", "is_robot_indexable": true, "report_reasons": null, "author": "Aggressive_Access316", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b7ayr/what_would_be_the_best_nas_server_for_a_plex/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11b7ayr/what_would_be_the_best_nas_server_for_a_plex/", "subreddit_subscribers": 671169, "created_utc": 1677285967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " Hi all,\n\nI am in the process of setting up a NAS to use as a backup target for my Synology, and I'm trying to decide what type of hard drives to buy. I have come across \"NEW\" enterprise HDDs being sold on eBay, particularly HGST, which I thought was defunct since 2018? I am unsure if they're new old stock or one of those scummy wiped SMART data drives being sold as new situation, but the prices are very attractive, and I could save some money by purchasing those over brand new drives. Has anyone been in a similar situation and could offer some insights or recommendations?\n\nThe two options:\n\n1. Use multiple \"new\" drives in RAID 6 or RAID 10\n2. Use fewer large capacity drives from an authorized dealer and put them in RAID 5\n\nI'm open to suggestions any advice or recommendations would be helpful!", "author_fullname": "t2_5syv6rhp8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice on NAS storage setup - \"new\" old hard drives from eBay", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b5ohs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677281770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am in the process of setting up a NAS to use as a backup target for my Synology, and I&amp;#39;m trying to decide what type of hard drives to buy. I have come across &amp;quot;NEW&amp;quot; enterprise HDDs being sold on eBay, particularly HGST, which I thought was defunct since 2018? I am unsure if they&amp;#39;re new old stock or one of those scummy wiped SMART data drives being sold as new situation, but the prices are very attractive, and I could save some money by purchasing those over brand new drives. Has anyone been in a similar situation and could offer some insights or recommendations?&lt;/p&gt;\n\n&lt;p&gt;The two options:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use multiple &amp;quot;new&amp;quot; drives in RAID 6 or RAID 10&lt;/li&gt;\n&lt;li&gt;Use fewer large capacity drives from an authorized dealer and put them in RAID 5&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m open to suggestions any advice or recommendations would be helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b5ohs", "is_robot_indexable": true, "report_reasons": null, "author": "OceanicOracle", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b5ohs/seeking_advice_on_nas_storage_setup_new_old_hard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11b5ohs/seeking_advice_on_nas_storage_setup_new_old_hard/", "subreddit_subscribers": 671169, "created_utc": 1677281770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know some people have built entire PCs that are submerged in mineral oil including the drives if they were SSDs but not if they were the old air filled drives because the oil would seep in and destroy them but helium drives are sealed so they should be safe to submerge, right? Has anyone tried that?", "author_fullname": "t2_vtl8mp58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone experimented cooling their helium drives with mineral oil?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b5ami", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677280798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know some people have built entire PCs that are submerged in mineral oil including the drives if they were SSDs but not if they were the old air filled drives because the oil would seep in and destroy them but helium drives are sealed so they should be safe to submerge, right? Has anyone tried that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11b5ami", "is_robot_indexable": true, "report_reasons": null, "author": "Phantom_Poops", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b5ami/has_anyone_experimented_cooling_their_helium/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11b5ami/has_anyone_experimented_cooling_their_helium/", "subreddit_subscribers": 671169, "created_utc": 1677280798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi friends, I have the task to save as many files of various image formats as possible, so I decided to ask you for advice. What parsing tools do you use?", "author_fullname": "t2_k1badclf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parse image formats", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b1wjm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677272330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends, I have the task to save as many files of various image formats as possible, so I decided to ask you for advice. What parsing tools do you use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11b1wjm", "is_robot_indexable": true, "report_reasons": null, "author": "mountname1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11b1wjm/parse_image_formats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11b1wjm/parse_image_formats/", "subreddit_subscribers": 671169, "created_utc": 1677272330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, in mi iPhone I can see the date hen photos were taken, and they photos are ordered by it, but when I airdrop them to my iMac the \u201cdate created\u201d it the moment I transfer the file. The same happens if I download them from iCloud. I\u2019ve tried in options send as/ automatic - individual photo /// all photo data\u2026 non of this works. I need help.", "author_fullname": "t2_qi4lzz55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Date and metadata on iPhone photos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11axfko", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677261123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, in mi iPhone I can see the date hen photos were taken, and they photos are ordered by it, but when I airdrop them to my iMac the \u201cdate created\u201d it the moment I transfer the file. The same happens if I download them from iCloud. I\u2019ve tried in options send as/ automatic - individual photo /// all photo data\u2026 non of this works. I need help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11axfko", "is_robot_indexable": true, "report_reasons": null, "author": "Disastrous-Win-3656", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11axfko/date_and_metadata_on_iphone_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11axfko/date_and_metadata_on_iphone_photos/", "subreddit_subscribers": 671169, "created_utc": 1677261123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "VirusTotal keeps \\*everything\\* uploaded to it. There are lost files that don't exist anywhere on the planet except locked up on a VirusTotal server somewhere. I did a search on this subreddit, and I'm surprised nobody's talking about this. \n\nI think certain partners are allowed to download these, but I doubt that we'll ever get access to them. I guess it makes sense, some of these files could contain private or copyrighted data. It still makes me wonder what an incredible resource VT could be if only I could download those files.", "author_fullname": "t2_jwdxd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "There are files that only exist on VirusTotal.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11auq83", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677254328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;VirusTotal keeps *everything* uploaded to it. There are lost files that don&amp;#39;t exist anywhere on the planet except locked up on a VirusTotal server somewhere. I did a search on this subreddit, and I&amp;#39;m surprised nobody&amp;#39;s talking about this. &lt;/p&gt;\n\n&lt;p&gt;I think certain partners are allowed to download these, but I doubt that we&amp;#39;ll ever get access to them. I guess it makes sense, some of these files could contain private or copyrighted data. It still makes me wonder what an incredible resource VT could be if only I could download those files.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "11auq83", "is_robot_indexable": true, "report_reasons": null, "author": "supersonicbrick", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11auq83/there_are_files_that_only_exist_on_virustotal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11auq83/there_are_files_that_only_exist_on_virustotal/", "subreddit_subscribers": 671169, "created_utc": 1677254328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After an upgrade, I am thinking about selling my smaller NAS (iX4-300D with 4x3TB RED) on Facebook. It works without issues, just needed \"more bigger better\"  \nWhat is the best way to show that the system and drives are error free and working, in a way that a novice would understand too? Is there a \"Diskinfo\" for RAID?", "author_fullname": "t2_5ai3u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Specs/Stats for selling a NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11atlxf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677251383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After an upgrade, I am thinking about selling my smaller NAS (iX4-300D with 4x3TB RED) on Facebook. It works without issues, just needed &amp;quot;more bigger better&amp;quot;&lt;br/&gt;\nWhat is the best way to show that the system and drives are error free and working, in a way that a novice would understand too? Is there a &amp;quot;Diskinfo&amp;quot; for RAID?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11atlxf", "is_robot_indexable": true, "report_reasons": null, "author": "saldridge", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11atlxf/specsstats_for_selling_a_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11atlxf/specsstats_for_selling_a_nas/", "subreddit_subscribers": 671169, "created_utc": 1677251383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First of all, I do not have much in-depth knowledge of filesystems. We can say that this is a novice question. I am still primarily a Windows user. All of my data resides in NTFS single partition drives. Previously I have used FAT and FAT16 and remember having problems with them. Since Windows switched primarily to NTFS (in XP I think) I moved to NTFS and never ever had file system consistency problems (except a few on boot disks on power loss). \n\nSoon I'll move to some new drives and that should be the right time to move data to some Linux FS so I can build a Linux server. I would want to avoid BTRFS and ZFS. The redundancy is planned to be handled by Snapraid and the disks are planned to be independent. The idea of spanning a file system over multiple physical drives does not appeal to me. The question is XFS vs EXT4. \n\nSnapraid says if the disk size is below 16TB there are no limitations, if above 16TB the parity drive has to be XFS because the parity is a single file and EXT4 has a file size limit of 16TB. Various internet sources suggest that XFS is faster and better, but taking into account that they also suggest that EXT4 is faster than NTFS and I use NTFS as starting baseline, they are both better. If the need arises to have to mount the drive on a Windows machine, EXT4 can be read with additional utilities, but XFS cannot afaik. \n\nI do not really understand if I should be concerned by a scenario of running out of inodes in EXT4. I have read that some had that problem and that it is problem that is unsolvable without format. I have looked through my current files and the disks with the most files have no more than a million files per 4TB disk. \n\nI have also read that XFS is twice processor intensive vs EXT4. Taking into account that the server will be based on a lower-end processor, is that something a home server user has to concern himself with, or is it more a data center issue?\n\nNow, when I concentrated all my findings in one place, the question comes down to: \n\nIs there a reason why someone in my situation should not use EXT4?", "author_fullname": "t2_14qhf2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Linux filesystems EXT4 vs XFS, what to choose, what is better", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ar65f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677244626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all, I do not have much in-depth knowledge of filesystems. We can say that this is a novice question. I am still primarily a Windows user. All of my data resides in NTFS single partition drives. Previously I have used FAT and FAT16 and remember having problems with them. Since Windows switched primarily to NTFS (in XP I think) I moved to NTFS and never ever had file system consistency problems (except a few on boot disks on power loss). &lt;/p&gt;\n\n&lt;p&gt;Soon I&amp;#39;ll move to some new drives and that should be the right time to move data to some Linux FS so I can build a Linux server. I would want to avoid BTRFS and ZFS. The redundancy is planned to be handled by Snapraid and the disks are planned to be independent. The idea of spanning a file system over multiple physical drives does not appeal to me. The question is XFS vs EXT4. &lt;/p&gt;\n\n&lt;p&gt;Snapraid says if the disk size is below 16TB there are no limitations, if above 16TB the parity drive has to be XFS because the parity is a single file and EXT4 has a file size limit of 16TB. Various internet sources suggest that XFS is faster and better, but taking into account that they also suggest that EXT4 is faster than NTFS and I use NTFS as starting baseline, they are both better. If the need arises to have to mount the drive on a Windows machine, EXT4 can be read with additional utilities, but XFS cannot afaik. &lt;/p&gt;\n\n&lt;p&gt;I do not really understand if I should be concerned by a scenario of running out of inodes in EXT4. I have read that some had that problem and that it is problem that is unsolvable without format. I have looked through my current files and the disks with the most files have no more than a million files per 4TB disk. &lt;/p&gt;\n\n&lt;p&gt;I have also read that XFS is twice processor intensive vs EXT4. Taking into account that the server will be based on a lower-end processor, is that something a home server user has to concern himself with, or is it more a data center issue?&lt;/p&gt;\n\n&lt;p&gt;Now, when I concentrated all my findings in one place, the question comes down to: &lt;/p&gt;\n\n&lt;p&gt;Is there a reason why someone in my situation should not use EXT4?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11ar65f", "is_robot_indexable": true, "report_reasons": null, "author": "SaleB81", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11ar65f/linux_filesystems_ext4_vs_xfs_what_to_choose_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11ar65f/linux_filesystems_ext4_vs_xfs_what_to_choose_what/", "subreddit_subscribers": 671169, "created_utc": 1677244626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Answer seems to be \"no\", but I thought I'd double check. Was looking at my biggest files to free up space and noticed that some of the files were taking up double the storage space because of a previous file version which wasn't auto-deleted after 30 days *or* excluded from the storage quota.\n\nAnd when generally browsing Drive contents the view only lists File Size, not Storage Size, so there doesn't even seem to be a way to check without looking at the Details panel for each file individually?", "author_fullname": "t2_311xe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any way to specifically find files with multiple versions on Google Drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11aqprf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677243231.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Answer seems to be &amp;quot;no&amp;quot;, but I thought I&amp;#39;d double check. Was looking at my biggest files to free up space and noticed that some of the files were taking up double the storage space because of a previous file version which wasn&amp;#39;t auto-deleted after 30 days &lt;em&gt;or&lt;/em&gt; excluded from the storage quota.&lt;/p&gt;\n\n&lt;p&gt;And when generally browsing Drive contents the view only lists File Size, not Storage Size, so there doesn&amp;#39;t even seem to be a way to check without looking at the Details panel for each file individually?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11aqprf", "is_robot_indexable": true, "report_reasons": null, "author": "ChunkyLaFunga", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11aqprf/is_there_any_way_to_specifically_find_files_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11aqprf/is_there_any_way_to_specifically_find_files_with/", "subreddit_subscribers": 671169, "created_utc": 1677243231.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I installed a new Seagate ironwolf NAS drive, and since install, I notice a thump that sounds like it would come from my sub. Is that normal or do I have a faulty drive? I have a WD drive that I would hear spin up but never something like this. Both the PC and the sub are on the floor, but I have definitely tracked this back to the drive itself. Thanks!", "author_fullname": "t2_nuc2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New hard drive, more thump", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11aqp2y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677243172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I installed a new Seagate ironwolf NAS drive, and since install, I notice a thump that sounds like it would come from my sub. Is that normal or do I have a faulty drive? I have a WD drive that I would hear spin up but never something like this. Both the PC and the sub are on the floor, but I have definitely tracked this back to the drive itself. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11aqp2y", "is_robot_indexable": true, "report_reasons": null, "author": "TonyMaxwell", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11aqp2y/new_hard_drive_more_thump/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11aqp2y/new_hard_drive_more_thump/", "subreddit_subscribers": 671169, "created_utc": 1677243172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!  \n\n\nI have bought CarbonCopyCloner, but got very sad about how complex it seem to clone the firevault protected macbook ssd to a external drive and keep it encrypted with filevault?  \n\n\nMy setup is: Macbook PRO mid 2014 (High Sierra) with ssd internal disk.  \nI want to be protected against if the 8 year old internal ssd-disk dies. And be able to just change the SSD.  \n\n\nI have read this:  \n[https://bombich.com/kb/ccc5/working-filevault-encryption](https://bombich.com/kb/ccc5/working-filevault-encryption)  \n\n\nAnd what I have understand is to  \n1. Format the external 5400rpm drive as ATFS (non-encrypted).  \n2. Clone the internal MacOS (filevault activated) to the external drive using CCC5.  \n3. Boot from the external drive.  \n4. Acivate Filevault while booted from the external drive.  \n5. Wait for the encryption progress to finish.  \n6. Done.  \n\n\nIs this correct? Any better easy way to do this?  \nI mean this takes about a 6 hours to complete.  \n\n\nWhat about the next time I want to sync the internal drive to the external? Start over from 1.?  \n\n\nThank you very much.", "author_fullname": "t2_1addx075", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CCC5: Clone MacOS systemdisk to encrypted external drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11aq4s7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677241308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!  &lt;/p&gt;\n\n&lt;p&gt;I have bought CarbonCopyCloner, but got very sad about how complex it seem to clone the firevault protected macbook ssd to a external drive and keep it encrypted with filevault?  &lt;/p&gt;\n\n&lt;p&gt;My setup is: Macbook PRO mid 2014 (High Sierra) with ssd internal disk.&lt;br/&gt;\nI want to be protected against if the 8 year old internal ssd-disk dies. And be able to just change the SSD.  &lt;/p&gt;\n\n&lt;p&gt;I have read this:&lt;br/&gt;\n&lt;a href=\"https://bombich.com/kb/ccc5/working-filevault-encryption\"&gt;https://bombich.com/kb/ccc5/working-filevault-encryption&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;And what I have understand is to&lt;br/&gt;\n1. Format the external 5400rpm drive as ATFS (non-encrypted).&lt;br/&gt;\n2. Clone the internal MacOS (filevault activated) to the external drive using CCC5.&lt;br/&gt;\n3. Boot from the external drive.&lt;br/&gt;\n4. Acivate Filevault while booted from the external drive.&lt;br/&gt;\n5. Wait for the encryption progress to finish.&lt;br/&gt;\n6. Done.  &lt;/p&gt;\n\n&lt;p&gt;Is this correct? Any better easy way to do this?&lt;br/&gt;\nI mean this takes about a 6 hours to complete.  &lt;/p&gt;\n\n&lt;p&gt;What about the next time I want to sync the internal drive to the external? Start over from 1.?  &lt;/p&gt;\n\n&lt;p&gt;Thank you very much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "11aq4s7", "is_robot_indexable": true, "report_reasons": null, "author": "raynoralpha123", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/11aq4s7/ccc5_clone_macos_systemdisk_to_encrypted_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/11aq4s7/ccc5_clone_macos_systemdisk_to_encrypted_external/", "subreddit_subscribers": 671169, "created_utc": 1677241308.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}