{"kind": "Listing", "data": {"after": "t3_11ax15b", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a senior business systems analyst at fortune 500 with SQL and big query stack. Either I go up into something like data engineering, or I find a new branch career. We have lots of other analyst jobs and many data engineer jobs.\n\n\nWhat's your typical day? What tools do you use? Do I need to know hardcore python programming or something? Don't want to jump into something and then realize I'm drowning cause it's so complex I can't keep up.", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does a data engineer do every day? How do I know if I'm good enough to do that?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11amg63", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677265626.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677227305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a senior business systems analyst at fortune 500 with SQL and big query stack. Either I go up into something like data engineering, or I find a new branch career. We have lots of other analyst jobs and many data engineer jobs.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your typical day? What tools do you use? Do I need to know hardcore python programming or something? Don&amp;#39;t want to jump into something and then realize I&amp;#39;m drowning cause it&amp;#39;s so complex I can&amp;#39;t keep up.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11amg63", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11amg63/what_does_a_data_engineer_do_every_day_how_do_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11amg63/what_does_a_data_engineer_do_every_day_how_do_i/", "subreddit_subscribers": 91002, "created_utc": 1677227305.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_y15lw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "4 ways to build dbt Python models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11awcne", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ynjDHdVsg0X3Oo_lCwH45EGss1uZvmBFeWuW9r1rE-0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677258417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datafold.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.datafold.com/blog/dbt-python", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dYCGaXKKaGsH5P092NQZ3pIC4XIJu9nrayvmEJrZnfI.jpg?auto=webp&amp;v=enabled&amp;s=03aee5abbd9db5e52d344c939e5442500746c6e3", "width": 1920, "height": 1081}, "resolutions": [{"url": "https://external-preview.redd.it/dYCGaXKKaGsH5P092NQZ3pIC4XIJu9nrayvmEJrZnfI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f2c21159b63ab2c364a83dfb7ac6c113f2d48e6", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/dYCGaXKKaGsH5P092NQZ3pIC4XIJu9nrayvmEJrZnfI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e04bdcb313a79198461f83c2cb4f80d99477dccd", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/dYCGaXKKaGsH5P092NQZ3pIC4XIJu9nrayvmEJrZnfI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7883781904e302a1cee8ed081e1f091eab59a805", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/dYCGaXKKaGsH5P092NQZ3pIC4XIJu9nrayvmEJrZnfI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ff0953ccd82b2db9a4cc9d22aaac670b576e790", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/dYCGaXKKaGsH5P092NQZ3pIC4XIJu9nrayvmEJrZnfI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=38ec2abb4df9311394968c3c4ea93cad5f3b7886", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/dYCGaXKKaGsH5P092NQZ3pIC4XIJu9nrayvmEJrZnfI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1179db66a2f8768ca94ac079dc8d053a21a1b9aa", "width": 1080, "height": 608}], "variants": {}, "id": "nPlCs849bn22ZnA2XvOziYJ0AZmmtYWsIi_Zsj6c2xA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11awcne", "is_robot_indexable": true, "report_reasons": null, "author": "gorkemyurt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11awcne/4_ways_to_build_dbt_python_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datafold.com/blog/dbt-python", "subreddit_subscribers": 91002, "created_utc": 1677258417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,I hope this question is suitable around here. I am in the early stages of my career and I have finished in January a 1.5 year contract as a Data Analyst for a company. Right now, I have had interviews with another company and I have successfully received a Data Engineer position with starting date on the 1st of April.My question is, given my background (Python, R, SQL, Postgres, all upper intermediate level), Bachelors in Data Science and ongoing Masters in Data Science, what would be the best way to gain a lot of knowledge in the Data Engineering field? I have just finished the O'Reilly \"Fundamentals of Data Engineering\", but my open to any suggestions (books, courses, YT channels, etc.). To be more specific, I am oriented towards Google Cloud Platform exclusively. Many thanks in advance!", "author_fullname": "t2_2g94ru12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From Analyst to Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11argsz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677245720.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677245507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,I hope this question is suitable around here. I am in the early stages of my career and I have finished in January a 1.5 year contract as a Data Analyst for a company. Right now, I have had interviews with another company and I have successfully received a Data Engineer position with starting date on the 1st of April.My question is, given my background (Python, R, SQL, Postgres, all upper intermediate level), Bachelors in Data Science and ongoing Masters in Data Science, what would be the best way to gain a lot of knowledge in the Data Engineering field? I have just finished the O&amp;#39;Reilly &amp;quot;Fundamentals of Data Engineering&amp;quot;, but my open to any suggestions (books, courses, YT channels, etc.). To be more specific, I am oriented towards Google Cloud Platform exclusively. Many thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11argsz", "is_robot_indexable": true, "report_reasons": null, "author": "BubuGly18", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11argsz/from_analyst_to_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11argsz/from_analyst_to_engineer/", "subreddit_subscribers": 91002, "created_utc": 1677245507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_lnwagoki", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Video: Demonstration of Trying out Apache Iceberg in Spark Locally using a single Docker Image", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11avnyf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/6dtfvo7nz5ka1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/6dtfvo7nz5ka1/DASH_96.mp4", "dash_url": "https://v.redd.it/6dtfvo7nz5ka1/DASHPlaylist.mpd?a=1679892164%2CZmI2OTYyMGU0NjgyMjM3ZGYwMTM3MTc5YWZjNTdjZDY1NDY5YzE1ODJmNWNhNTllYzRhMzU1MmJmMTBhMDcyZQ%3D%3D&amp;v=1&amp;f=sd", "duration": 899, "hls_url": "https://v.redd.it/6dtfvo7nz5ka1/HLSPlaylist.m3u8?a=1679892164%2CMmZlODQ0ODJmOWM1YjI1N2M2ODgwZGExM2VjOTMxODA3NDIwMzBhY2M4ZDZhNWY1YzFiNzM1MzYwYTNhNjA3Zg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AEGCdZLAciaiQCae5diXVPdR-B8dEeupVzeyhWXFP9A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677256697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/6dtfvo7nz5ka1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Ccw2QiF9jcm6qSun6XwA5N7Bqh3TQ232byLReeYnzOg.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=00479251a89a675a148d7df12bd18c9267a64c46", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/Ccw2QiF9jcm6qSun6XwA5N7Bqh3TQ232byLReeYnzOg.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e2cabe9766586ee7d5461e7bb23ea03c8ce949ff", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Ccw2QiF9jcm6qSun6XwA5N7Bqh3TQ232byLReeYnzOg.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=933cbc9ead92bf8d80dda203569ef3b3c92478a0", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/Ccw2QiF9jcm6qSun6XwA5N7Bqh3TQ232byLReeYnzOg.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=625bffe483eda9f054adcbd81b53e347561c88dc", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/Ccw2QiF9jcm6qSun6XwA5N7Bqh3TQ232byLReeYnzOg.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=b1f951764f8edfc44e5ec4f2010f4bfb71a6f564", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/Ccw2QiF9jcm6qSun6XwA5N7Bqh3TQ232byLReeYnzOg.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=08b67eca962347dcd2546a1597c5d18173cb6aca", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/Ccw2QiF9jcm6qSun6XwA5N7Bqh3TQ232byLReeYnzOg.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7db6b4ff69fbd5d29532cf817cbe3c8b7cd74ac3", "width": 1080, "height": 607}], "variants": {}, "id": "d8muqGO0greRfC0uhiqc91xBpkQLi7AkX5uw8j29uRE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11avnyf", "is_robot_indexable": true, "report_reasons": null, "author": "AMDataLake", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11avnyf/video_demonstration_of_trying_out_apache_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/6dtfvo7nz5ka1", "subreddit_subscribers": 91002, "created_utc": 1677256697.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/6dtfvo7nz5ka1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/6dtfvo7nz5ka1/DASH_96.mp4", "dash_url": "https://v.redd.it/6dtfvo7nz5ka1/DASHPlaylist.mpd?a=1679892164%2CZmI2OTYyMGU0NjgyMjM3ZGYwMTM3MTc5YWZjNTdjZDY1NDY5YzE1ODJmNWNhNTllYzRhMzU1MmJmMTBhMDcyZQ%3D%3D&amp;v=1&amp;f=sd", "duration": 899, "hls_url": "https://v.redd.it/6dtfvo7nz5ka1/HLSPlaylist.m3u8?a=1679892164%2CMmZlODQ0ODJmOWM1YjI1N2M2ODgwZGExM2VjOTMxODA3NDIwMzBhY2M4ZDZhNWY1YzFiNzM1MzYwYTNhNjA3Zg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2rku02rf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Techniques You Should Know as a Kafka Streams Developer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11al0xa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/BFrngw6jOK9dADX8e-L5TlbuBGJlcGfbzA1Ili3TGIg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677221851.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kestra.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kestra.io/blogs/2023-02-23-techniques-kafka-streams-developer.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LVv1k2CZxucbMP1zL6tyQf6Hm_YTJah_aV9lKX2hUps.jpg?auto=webp&amp;v=enabled&amp;s=ddf81e77be4d6b79c49db7779725f5235ec9771d", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/LVv1k2CZxucbMP1zL6tyQf6Hm_YTJah_aV9lKX2hUps.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfc0cab571adc9ba69d078c698cd351f8631c9ba", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/LVv1k2CZxucbMP1zL6tyQf6Hm_YTJah_aV9lKX2hUps.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c27156262e4d20ef542d9d7bd7e0b10c3e58dd03", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/LVv1k2CZxucbMP1zL6tyQf6Hm_YTJah_aV9lKX2hUps.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7287209d8ee2c4db4e3fbb60ab42031dd788f63c", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/LVv1k2CZxucbMP1zL6tyQf6Hm_YTJah_aV9lKX2hUps.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bef29cd382b91822c871aa448b00d3c2215efc22", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/LVv1k2CZxucbMP1zL6tyQf6Hm_YTJah_aV9lKX2hUps.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff52541263d0b94d4959bce5922b72f6e7f12bab", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/LVv1k2CZxucbMP1zL6tyQf6Hm_YTJah_aV9lKX2hUps.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7f391870b5d7d874b3ab0d2ddcc1c69a2437e2c", "width": 1080, "height": 607}], "variants": {}, "id": "jfTPXGQiNOKhMii9w6fkPVeGpyxL1ZT1lqC_p0_TZTY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11al0xa", "is_robot_indexable": true, "report_reasons": null, "author": "tchiotludo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11al0xa/techniques_you_should_know_as_a_kafka_streams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kestra.io/blogs/2023-02-23-techniques-kafka-streams-developer.html", "subreddit_subscribers": 91002, "created_utc": 1677221851.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am wondering what exact steps do you take in the \"Load\" stage when doing ELT data architecture?\n\nBy Extract I am thinking of simply downloading data from sources and dumping them as is to some object storage. Then the load stage? You take this raw data and without any transformations/validations/cleaning just load it into some RDBMS? Well, I guess at least e.g. schema flattening and data type casting has to be done in this step - but nothing else? No aggregations, derived columns, joins etc? Then aggregations, joins, derived columns in the Transform phase? Also, what if this table loaded in the \"Load\" stage does not require any more transformations? You just copy it 1:1 to different database schema?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What steps do you apply in the \"L\" when doing ELT?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11awvyp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677259741.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering what exact steps do you take in the &amp;quot;Load&amp;quot; stage when doing ELT data architecture?&lt;/p&gt;\n\n&lt;p&gt;By Extract I am thinking of simply downloading data from sources and dumping them as is to some object storage. Then the load stage? You take this raw data and without any transformations/validations/cleaning just load it into some RDBMS? Well, I guess at least e.g. schema flattening and data type casting has to be done in this step - but nothing else? No aggregations, derived columns, joins etc? Then aggregations, joins, derived columns in the Transform phase? Also, what if this table loaded in the &amp;quot;Load&amp;quot; stage does not require any more transformations? You just copy it 1:1 to different database schema?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11awvyp", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11awvyp/what_steps_do_you_apply_in_the_l_when_doing_elt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11awvyp/what_steps_do_you_apply_in_the_l_when_doing_elt/", "subreddit_subscribers": 91002, "created_utc": 1677259741.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to be a data engineer in a coding-heavy role. Like, I don\u2019t want to be a DE that uses tools and SQL only. I have worked as a database developer for ~4 years writing SQL and PLSQL only for ETL reasons. I wanted to do more than that. I am currently working as a software engineer for the past 7 months. Should I stay a software engineer for the next few years so I understand software engineering practices before I jump into a data engineering role that is code heavy? Or, should I just jump into a data engineering role that is code-heavy right now? Assume I have both options.", "author_fullname": "t2_jpjpdkcf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I wait to get into data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b7g0l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677286327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to be a data engineer in a coding-heavy role. Like, I don\u2019t want to be a DE that uses tools and SQL only. I have worked as a database developer for ~4 years writing SQL and PLSQL only for ETL reasons. I wanted to do more than that. I am currently working as a software engineer for the past 7 months. Should I stay a software engineer for the next few years so I understand software engineering practices before I jump into a data engineering role that is code heavy? Or, should I just jump into a data engineering role that is code-heavy right now? Assume I have both options.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11b7g0l", "is_robot_indexable": true, "report_reasons": null, "author": "iemback", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11b7g0l/should_i_wait_to_get_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11b7g0l/should_i_wait_to_get_into_data_engineering/", "subreddit_subscribers": 91002, "created_utc": 1677286327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, we are using Databricks Repos with Azure DevOps. For some reason, whenever someone makes changes on their branch, these changes are populated to all branches; kind of defeating the point of a branching strategy to begin with.\n\nHas anybody ever experienced this? I could not figure out, what would be wrong in our setup and haven't found people online with a similar problem.\n\nDoes anybody have some insights on this that they can share with me?", "author_fullname": "t2_6kh3i5kp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Confusion in Databricks Repos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11apkwt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677239450.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, we are using Databricks Repos with Azure DevOps. For some reason, whenever someone makes changes on their branch, these changes are populated to all branches; kind of defeating the point of a branching strategy to begin with.&lt;/p&gt;\n\n&lt;p&gt;Has anybody ever experienced this? I could not figure out, what would be wrong in our setup and haven&amp;#39;t found people online with a similar problem.&lt;/p&gt;\n\n&lt;p&gt;Does anybody have some insights on this that they can share with me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11apkwt", "is_robot_indexable": true, "report_reasons": null, "author": "SolvingGames", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11apkwt/confusion_in_databricks_repos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11apkwt/confusion_in_databricks_repos/", "subreddit_subscribers": 91002, "created_utc": 1677239450.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of my DE experience is in batch ETL with Python or AWS Kinesis + Lambda. Now that I am getting exposed to the world of data streaming with Kafka, most processing apps from what I've seen so far are built in either Java or Scala, whether its Kafka Streams or Flink app. My colleagues have different preferences and I'm not sure which route I want to take. I know it will be a steep learning curve but I am itching to get this hands on experience. Which route seems to be more fun?", "author_fullname": "t2_991xsmvf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka Stream Processing in Java or Scala", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11aypfk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677264314.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of my DE experience is in batch ETL with Python or AWS Kinesis + Lambda. Now that I am getting exposed to the world of data streaming with Kafka, most processing apps from what I&amp;#39;ve seen so far are built in either Java or Scala, whether its Kafka Streams or Flink app. My colleagues have different preferences and I&amp;#39;m not sure which route I want to take. I know it will be a steep learning curve but I am itching to get this hands on experience. Which route seems to be more fun?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11aypfk", "is_robot_indexable": true, "report_reasons": null, "author": "twadftw10", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11aypfk/kafka_stream_processing_in_java_or_scala/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11aypfk/kafka_stream_processing_in_java_or_scala/", "subreddit_subscribers": 91002, "created_utc": 1677264314.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm about to be 2 years at my current company as a senior day to analyst, and I'm honestly really not enjoying it because of how bad leaders in the industry are at understanding data, or what goes into it. Boss thinks better data sources like BigQuery and Oracle are unreliable even though half the company uses it, So we use Excel exclusively with 500k rows and just send the same workbook back and forth. I spend most days working 7:00 a.m. to 7:00 p.m., incompetent leaders at my current job and my previous jobs. I'm not sure if I'm extremely unlucky, or if this is just how data analytics is but I'm pretty much just exhausted from it....\n\n\nSo my three options are Data engineering, project management, and cybersecurity. My company is a great company and has all three, it's just a matter of which one to go into. \n\n\n\nMy concerns for data engineering specifically are that while I do possess a lot of technical knowledge, and I can get things done if needed to, I suffer sometimes from being a non-technical person. In the past I've just consulted with the engineering team in order to get databases created in SQL or to have a query created or optimized. I feel like data engineering could be a good career, but a huge leap, and the possibility of drowning in how much there is to learn and being overwhelmed by it. Plus I don't know how bad bosses are or how stakeholder management is. \n\n\n\nCybersecurity seems extremely fun, and there are several cyber security one or two analysts, and then I could even become a cybersecurity project manager later on. I have a degree in information systems and I did take a Linux ethical hacking course, as well as a cybersecurity course. I thought it was awesome. But I don't know how far I could get into it because again, non-technical person so I don't know if I would even be able to advance to an engineer position in security. I also have some skill in Python, but I'm not really a fan of programming at all\n\n\nThen there's project management. I started my career as a project analyst, and I thought it was a blast. It was at an organization using waterfall instead of agile, which kind of sucked, But just getting to be involved in so many projects, change requests, the whole project management life cycle was awesome. The only thing I dislike is the work life balance can be extreme sometimes, and whenever there's extra work to be done, they say screw it, just throw it onto the project analyst. So I'm not sure how a senior project analyst would do, but I've seen senior project analyst positions, and project analyst lead positions lately. \n\n\nAny advice you might have about any of these industries that you have or have not worked on would be great", "author_fullname": "t2_dmawn6hx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "for anyone who has experience in data engineering, project management, or cybersecurity, which one have you enjoyed the most? I need help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11arg8c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677245463.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m about to be 2 years at my current company as a senior day to analyst, and I&amp;#39;m honestly really not enjoying it because of how bad leaders in the industry are at understanding data, or what goes into it. Boss thinks better data sources like BigQuery and Oracle are unreliable even though half the company uses it, So we use Excel exclusively with 500k rows and just send the same workbook back and forth. I spend most days working 7:00 a.m. to 7:00 p.m., incompetent leaders at my current job and my previous jobs. I&amp;#39;m not sure if I&amp;#39;m extremely unlucky, or if this is just how data analytics is but I&amp;#39;m pretty much just exhausted from it....&lt;/p&gt;\n\n&lt;p&gt;So my three options are Data engineering, project management, and cybersecurity. My company is a great company and has all three, it&amp;#39;s just a matter of which one to go into. &lt;/p&gt;\n\n&lt;p&gt;My concerns for data engineering specifically are that while I do possess a lot of technical knowledge, and I can get things done if needed to, I suffer sometimes from being a non-technical person. In the past I&amp;#39;ve just consulted with the engineering team in order to get databases created in SQL or to have a query created or optimized. I feel like data engineering could be a good career, but a huge leap, and the possibility of drowning in how much there is to learn and being overwhelmed by it. Plus I don&amp;#39;t know how bad bosses are or how stakeholder management is. &lt;/p&gt;\n\n&lt;p&gt;Cybersecurity seems extremely fun, and there are several cyber security one or two analysts, and then I could even become a cybersecurity project manager later on. I have a degree in information systems and I did take a Linux ethical hacking course, as well as a cybersecurity course. I thought it was awesome. But I don&amp;#39;t know how far I could get into it because again, non-technical person so I don&amp;#39;t know if I would even be able to advance to an engineer position in security. I also have some skill in Python, but I&amp;#39;m not really a fan of programming at all&lt;/p&gt;\n\n&lt;p&gt;Then there&amp;#39;s project management. I started my career as a project analyst, and I thought it was a blast. It was at an organization using waterfall instead of agile, which kind of sucked, But just getting to be involved in so many projects, change requests, the whole project management life cycle was awesome. The only thing I dislike is the work life balance can be extreme sometimes, and whenever there&amp;#39;s extra work to be done, they say screw it, just throw it onto the project analyst. So I&amp;#39;m not sure how a senior project analyst would do, but I&amp;#39;ve seen senior project analyst positions, and project analyst lead positions lately. &lt;/p&gt;\n\n&lt;p&gt;Any advice you might have about any of these industries that you have or have not worked on would be great&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11arg8c", "is_robot_indexable": true, "report_reasons": null, "author": "InevitableTraining69", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11arg8c/for_anyone_who_has_experience_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11arg8c/for_anyone_who_has_experience_in_data_engineering/", "subreddit_subscribers": 91002, "created_utc": 1677245463.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As an analyst.. I have deep knowledge on writing SQL queries.. my queries could range to thousand lines of code.. I am also good with python for data analysis and running machine learning.. what do I need to know to transition to data engineering. \nThis year I started understanding how dbt and fivetran works. I was able to develop a python script that loads data from an RDS instance to S3 bucket then to snowflake. I also executed with fivetran in moving the data\u2026. Even with all these I feel I know nothing", "author_fullname": "t2_c1lb6wq0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for beginner in DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11arcj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677245148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As an analyst.. I have deep knowledge on writing SQL queries.. my queries could range to thousand lines of code.. I am also good with python for data analysis and running machine learning.. what do I need to know to transition to data engineering. \nThis year I started understanding how dbt and fivetran works. I was able to develop a python script that loads data from an RDS instance to S3 bucket then to snowflake. I also executed with fivetran in moving the data\u2026. Even with all these I feel I know nothing&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11arcj4", "is_robot_indexable": true, "report_reasons": null, "author": "ejiod2021", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11arcj4/advice_for_beginner_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11arcj4/advice_for_beginner_in_de/", "subreddit_subscribers": 91002, "created_utc": 1677245148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I followed some resources in other to build a docker image of my app and the push it to Azure Container Registry. I followed a tutorial in order to deploy it with a Web App, but I am not sure how to set up and magage the \"runs\" of my app.\n\nWhat I want to do is to be able to set up timed tasks that use the hosted dockerized image and calls docker run with a customized startup command. For instance I would like that:\n\n* Every Y minutes, the docker image is runned with command CMD1\n* Every X minutes, the same docker image is runned with a different command CMD2\n\nHow can I accomplish that?", "author_fullname": "t2_vlk568vv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to set and manage timers to run a dockerized app hosted in ACR?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11aodbm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677234938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I followed some resources in other to build a docker image of my app and the push it to Azure Container Registry. I followed a tutorial in order to deploy it with a Web App, but I am not sure how to set up and magage the &amp;quot;runs&amp;quot; of my app.&lt;/p&gt;\n\n&lt;p&gt;What I want to do is to be able to set up timed tasks that use the hosted dockerized image and calls docker run with a customized startup command. For instance I would like that:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Every Y minutes, the docker image is runned with command CMD1&lt;/li&gt;\n&lt;li&gt;Every X minutes, the same docker image is runned with a different command CMD2&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;How can I accomplish that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11aodbm", "is_robot_indexable": true, "report_reasons": null, "author": "Plenty-Button8465", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11aodbm/how_to_set_and_manage_timers_to_run_a_dockerized/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11aodbm/how_to_set_and_manage_timers_to_run_a_dockerized/", "subreddit_subscribers": 91002, "created_utc": 1677234938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any repos you all would recommend to see how DAGs are put together?  \n\nReason I ask is we're migrating our jobs to airflow and right now I have several custom python scripts to execute. Reading up on best practices and saw you use the @task decorator and functions to execute which is fine, but I also read you don't want lots of processing logic in your dags so figured I could use the bash operator to call the python scripts with lots of logic but how does that work with @task?   \n\nI'm reading a bunch but not sure which is the best way. Can you mix and match @task with other operators (ie bash?) in the same DAG? Should I just store everything in functions under the task decorator? Is there anything wrong about a single large DAG to run my stuff?  \n\nThanks!", "author_fullname": "t2_szv0ygic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow 2.0 examples and tips?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11arrno", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677246394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any repos you all would recommend to see how DAGs are put together?  &lt;/p&gt;\n\n&lt;p&gt;Reason I ask is we&amp;#39;re migrating our jobs to airflow and right now I have several custom python scripts to execute. Reading up on best practices and saw you use the @task decorator and functions to execute which is fine, but I also read you don&amp;#39;t want lots of processing logic in your dags so figured I could use the bash operator to call the python scripts with lots of logic but how does that work with @task?   &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reading a bunch but not sure which is the best way. Can you mix and match @task with other operators (ie bash?) in the same DAG? Should I just store everything in functions under the task decorator? Is there anything wrong about a single large DAG to run my stuff?  &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11arrno", "is_robot_indexable": true, "report_reasons": null, "author": "Hippodick666420", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11arrno/airflow_20_examples_and_tips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11arrno/airflow_20_examples_and_tips/", "subreddit_subscribers": 91002, "created_utc": 1677246394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "dear team. just need an advice on how to go about my career.\n\nI used to be a very good oracle dba 10 years ago then shifted to technical project management which i hate. i started studying snowflake and got snowpro core cert and currently studying dbt. i want your advice on what is next or what the path i should follow to find a job in data engineering world. \n\nsnowflak then dbt then what. any recommendations is highly apprciated i am doing that on my own with no guidance", "author_fullname": "t2_dbndze4d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "snowflake dbt ...etc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b3rom", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677276923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;dear team. just need an advice on how to go about my career.&lt;/p&gt;\n\n&lt;p&gt;I used to be a very good oracle dba 10 years ago then shifted to technical project management which i hate. i started studying snowflake and got snowpro core cert and currently studying dbt. i want your advice on what is next or what the path i should follow to find a job in data engineering world. &lt;/p&gt;\n\n&lt;p&gt;snowflak then dbt then what. any recommendations is highly apprciated i am doing that on my own with no guidance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11b3rom", "is_robot_indexable": true, "report_reasons": null, "author": "Secure_Chipmunk991", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11b3rom/snowflake_dbt_etc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11b3rom/snowflake_dbt_etc/", "subreddit_subscribers": 91002, "created_utc": 1677276923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for some approach how to get parquet data from S3 into Postgres. Obviously one can use python but I would like to simplify and standardize the process as much as possible. I thought of using dbt python models but it apparently supports only Snowflake and BigQuery which we do not have so I thought of using DuckDB + dbt to load the parquets, do the transformations (I know this is possible) but how to output it then efficiently to Postgres?\n\nPS. The intended data path is raw -&gt; parquet -&gt; postgres", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parquet through dbt+DuckDB into postgres?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11awcol", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677258420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for some approach how to get parquet data from S3 into Postgres. Obviously one can use python but I would like to simplify and standardize the process as much as possible. I thought of using dbt python models but it apparently supports only Snowflake and BigQuery which we do not have so I thought of using DuckDB + dbt to load the parquets, do the transformations (I know this is possible) but how to output it then efficiently to Postgres?&lt;/p&gt;\n\n&lt;p&gt;PS. The intended data path is raw -&amp;gt; parquet -&amp;gt; postgres&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11awcol", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11awcol/parquet_through_dbtduckdb_into_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11awcol/parquet_through_dbtduckdb_into_postgres/", "subreddit_subscribers": 91002, "created_utc": 1677258420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nWe use debezium connector as a source with confluent kafka in my org. We use debezium for both MySQL and SQL Server. In MySQL, debezium seems to run fine for the most part, but in SQL Server, there are some limitations which greatly increase the manual work.\n\n1) In MySQL, if CDC is disabled for some reason &amp; re-enabled, debezium automatically detects it and triggers a full snapshot. The same is not true for SQL Server where it's left for the users to figure out and snapshot manually.\n\n2) Unlike MySQL, DDL operations are not straightforward. There are a series of steps to follow, both offline and online methods are available. My org doesn't prefer taking DB down for DDL operations, that only leaves the online method. [That] (https://debezium.io/documentation/reference/stable/connectors/sqlserver.html#online-schema-updates) has a limitation that values of the new column will be missed after new column is added &amp; before new CDC instance is created.\n\nAll of this adds lot of manual work. For reasons beyond our control, we cannot absolutely guarentee that such steps will always be followed by the DB team nor that CDC is never taken down. (If CDC is enabled, some operations like TRUNCATE on the main table are blocked, not sure if other operations are too.)\n\nThus, we are looking for alternatives to get near real time data (i.e. gap of 15 mins atmost). Does anyone know of an alternative that doesn't have all the above limitations and has automations built in to mostly take care of itself?", "author_fullname": "t2_14bzgy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative to debezium for SQL Server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11auhii", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677253696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;We use debezium connector as a source with confluent kafka in my org. We use debezium for both MySQL and SQL Server. In MySQL, debezium seems to run fine for the most part, but in SQL Server, there are some limitations which greatly increase the manual work.&lt;/p&gt;\n\n&lt;p&gt;1) In MySQL, if CDC is disabled for some reason &amp;amp; re-enabled, debezium automatically detects it and triggers a full snapshot. The same is not true for SQL Server where it&amp;#39;s left for the users to figure out and snapshot manually.&lt;/p&gt;\n\n&lt;p&gt;2) Unlike MySQL, DDL operations are not straightforward. There are a series of steps to follow, both offline and online methods are available. My org doesn&amp;#39;t prefer taking DB down for DDL operations, that only leaves the online method. &lt;a href=\"https://debezium.io/documentation/reference/stable/connectors/sqlserver.html#online-schema-updates\"&gt;That&lt;/a&gt; has a limitation that values of the new column will be missed after new column is added &amp;amp; before new CDC instance is created.&lt;/p&gt;\n\n&lt;p&gt;All of this adds lot of manual work. For reasons beyond our control, we cannot absolutely guarentee that such steps will always be followed by the DB team nor that CDC is never taken down. (If CDC is enabled, some operations like TRUNCATE on the main table are blocked, not sure if other operations are too.)&lt;/p&gt;\n\n&lt;p&gt;Thus, we are looking for alternatives to get near real time data (i.e. gap of 15 mins atmost). Does anyone know of an alternative that doesn&amp;#39;t have all the above limitations and has automations built in to mostly take care of itself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11auhii", "is_robot_indexable": true, "report_reasons": null, "author": "downloaderfan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11auhii/alternative_to_debezium_for_sql_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11auhii/alternative_to_debezium_for_sql_server/", "subreddit_subscribers": 91002, "created_utc": 1677253696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! \n\nDoes anyone used Benthos in their orgs? What experiences did you have with it?\n\n - Link:  https://github.com/benthosdev/benthos\n\nI'm currently developing a PoC with it, and for really simple tasks is quite good, but while trying more advanced stuff like time window processing, I'm not really liking it. \n\nWhat are your thoughts about it?", "author_fullname": "t2_16enpq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experiences with Benthos", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11arseq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677246456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! &lt;/p&gt;\n\n&lt;p&gt;Does anyone used Benthos in their orgs? What experiences did you have with it?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Link:  &lt;a href=\"https://github.com/benthosdev/benthos\"&gt;https://github.com/benthosdev/benthos&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m currently developing a PoC with it, and for really simple tasks is quite good, but while trying more advanced stuff like time window processing, I&amp;#39;m not really liking it. &lt;/p&gt;\n\n&lt;p&gt;What are your thoughts about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dsopK-ZJQ3pol4Z4JCg43-ShlNbAtwyU0Bp5mHQD_fE.jpg?auto=webp&amp;v=enabled&amp;s=63b3dd26530f54ead3722e992dcc0da0e5220c40", "width": 1280, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/dsopK-ZJQ3pol4Z4JCg43-ShlNbAtwyU0Bp5mHQD_fE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0f640bbccaa5585b3daf9c7385eb2392635d237", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/dsopK-ZJQ3pol4Z4JCg43-ShlNbAtwyU0Bp5mHQD_fE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0babdf7ba6068e6ba5eb5fd5e0978f9306931e4", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/dsopK-ZJQ3pol4Z4JCg43-ShlNbAtwyU0Bp5mHQD_fE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fcbd668d6eaec7d90f2bed19cbd66eb8e0e71378", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/dsopK-ZJQ3pol4Z4JCg43-ShlNbAtwyU0Bp5mHQD_fE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f94bedfbc834c51cfe0ab99e959bd55a6d9533c4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/dsopK-ZJQ3pol4Z4JCg43-ShlNbAtwyU0Bp5mHQD_fE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01ddc43fc25b448df758eaeecc3a3d8967dd85a5", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/dsopK-ZJQ3pol4Z4JCg43-ShlNbAtwyU0Bp5mHQD_fE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8575e4e6076161dbea7257e8351136bf128adc88", "width": 1080, "height": 540}], "variants": {}, "id": "okpWdrrKp9xiusC64h2Oe4WuQNjwswZrA8pgQOUQE1o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11arseq", "is_robot_indexable": true, "report_reasons": null, "author": "naxmtz91", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11arseq/experiences_with_benthos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11arseq/experiences_with_benthos/", "subreddit_subscribers": 91002, "created_utc": 1677246456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hopefully this doesn't breake any rules (let me know if that's the case). \n\n Join us on **March 7, 2023 at 11AM (EST)**, for our online event to learn what remarkable results these companies achieved with Keboola and how they did it. Plus, find out how *you* can use Keboola too.  \n \n\nIn-depth talks and interactive workshops for 500 everyday data heroes. Hosted by Keboola. Workshops for dbt beginners and experts, customer stories and a list of technical walkthroughs.   \n\n\n[https://lp.keboola.com/empower-online-by-keboola?utm\\_source=signature&amp;utm\\_medium=email&amp;utm\\_campaign=empower&amp;utm\\_content=lundberg](https://lp.keboola.com/empower-online-by-keboola?utm_source=signature&amp;utm_medium=email&amp;utm_campaign=empower&amp;utm_content=lundberg)", "author_fullname": "t2_opyjpm1x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Online Event: Keboola, dbt and success stories .", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11apnqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677239731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hopefully this doesn&amp;#39;t breake any rules (let me know if that&amp;#39;s the case). &lt;/p&gt;\n\n&lt;p&gt;Join us on &lt;strong&gt;March 7, 2023 at 11AM (EST)&lt;/strong&gt;, for our online event to learn what remarkable results these companies achieved with Keboola and how they did it. Plus, find out how &lt;em&gt;you&lt;/em&gt; can use Keboola too.  &lt;/p&gt;\n\n&lt;p&gt;In-depth talks and interactive workshops for 500 everyday data heroes. Hosted by Keboola. Workshops for dbt beginners and experts, customer stories and a list of technical walkthroughs.   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://lp.keboola.com/empower-online-by-keboola?utm_source=signature&amp;amp;utm_medium=email&amp;amp;utm_campaign=empower&amp;amp;utm_content=lundberg\"&gt;https://lp.keboola.com/empower-online-by-keboola?utm_source=signature&amp;amp;utm_medium=email&amp;amp;utm_campaign=empower&amp;amp;utm_content=lundberg&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fbRPC2dKGy1MUv1uqEinXygCSKdMz7mK1DF7qaDGYeQ.jpg?auto=webp&amp;v=enabled&amp;s=c91a5fe1ed907329ca23d6a20adb77e577179861", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/fbRPC2dKGy1MUv1uqEinXygCSKdMz7mK1DF7qaDGYeQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=502c7bc44df3463ca12c95beb0f4a081a9f86a2d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fbRPC2dKGy1MUv1uqEinXygCSKdMz7mK1DF7qaDGYeQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32b038df2825aba42506cf875cf9ac92d1937cdb", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/fbRPC2dKGy1MUv1uqEinXygCSKdMz7mK1DF7qaDGYeQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d1811d17684fb93cd372ebc176b28c7b6c97856", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/fbRPC2dKGy1MUv1uqEinXygCSKdMz7mK1DF7qaDGYeQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d9896bb7daf3cc8ff02872b55bb4f62a138f02b", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/fbRPC2dKGy1MUv1uqEinXygCSKdMz7mK1DF7qaDGYeQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad37f074251353993113d53278948b47635ed536", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/fbRPC2dKGy1MUv1uqEinXygCSKdMz7mK1DF7qaDGYeQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bbe064ac89ca6965ac32d4728fbbc62ee003bdc7", "width": 1080, "height": 567}], "variants": {}, "id": "piUl_p41XfGk4PLiT4H02atNTQF75mjNyXzv8y6izPY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11apnqn", "is_robot_indexable": true, "report_reasons": null, "author": "CalleKeboola", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11apnqn/online_event_keboola_dbt_and_success_stories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11apnqn/online_event_keboola_dbt_and_success_stories/", "subreddit_subscribers": 91002, "created_utc": 1677239731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team's data processing / cleanup involves creating an exclusion field where we track all exclusions that apply to each line in a concatenated string. Then, we have a single \"inclusion\" field which assigns a final value based on a pre-defined hierarchy of the applicable exclusion codes. \n\nThis was set up with each exclusion being represented by a single letter, and the final inclusion code is based on the left-most character (they're applied in the hierarchical order). For example, if a line is missing some information (exclusion code M) and the record was submitted incorrectly (S), it'll have the exclusion code 'MS', and the 'M' will go into the 'Data Quality' bucket. If, however, a different line was only submitted incorrectly, it'll have an exclusion code 'S' and go into the \"Submission Issues\" bucket.\n\n&amp;#x200B;\n\nThis worked fine at first because we only had 15 exclusions. However, we've grown to 34 exclusions, meaning we've gone through all the letters of the alphabet and we'll soon run out of single-digit numbers. \n\n&amp;#x200B;\n\n**Does anyone have a suggestion on a more robust way to handle this**, so that we can continue to track all exclusions that apply to any particular line and be able to boil it down to a single field for users?\n\n&amp;#x200B;\n\nI thought about expanding to 2 digits, but I'd like something that's easier to scale if we end up adding a ton of exclusions down the road. I also worry about if we did 2 digits then a user might erroneously think exclusions '02' applies to a line when really it was '10' and '23' with the string '0142**1*****02*****3**94'. I'm not really sure about the file size implications of keeping this in a single field vs tracking all of these exclusions in their own single character field, but I think they switched from the latter to the former before I got here so I'm guessing a concatenated field is preferrable.", "author_fullname": "t2_avuzo09", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's a good, robust option for tracking all applicable flags on a dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b4cu9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677278427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team&amp;#39;s data processing / cleanup involves creating an exclusion field where we track all exclusions that apply to each line in a concatenated string. Then, we have a single &amp;quot;inclusion&amp;quot; field which assigns a final value based on a pre-defined hierarchy of the applicable exclusion codes. &lt;/p&gt;\n\n&lt;p&gt;This was set up with each exclusion being represented by a single letter, and the final inclusion code is based on the left-most character (they&amp;#39;re applied in the hierarchical order). For example, if a line is missing some information (exclusion code M) and the record was submitted incorrectly (S), it&amp;#39;ll have the exclusion code &amp;#39;MS&amp;#39;, and the &amp;#39;M&amp;#39; will go into the &amp;#39;Data Quality&amp;#39; bucket. If, however, a different line was only submitted incorrectly, it&amp;#39;ll have an exclusion code &amp;#39;S&amp;#39; and go into the &amp;quot;Submission Issues&amp;quot; bucket.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This worked fine at first because we only had 15 exclusions. However, we&amp;#39;ve grown to 34 exclusions, meaning we&amp;#39;ve gone through all the letters of the alphabet and we&amp;#39;ll soon run out of single-digit numbers. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Does anyone have a suggestion on a more robust way to handle this&lt;/strong&gt;, so that we can continue to track all exclusions that apply to any particular line and be able to boil it down to a single field for users?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I thought about expanding to 2 digits, but I&amp;#39;d like something that&amp;#39;s easier to scale if we end up adding a ton of exclusions down the road. I also worry about if we did 2 digits then a user might erroneously think exclusions &amp;#39;02&amp;#39; applies to a line when really it was &amp;#39;10&amp;#39; and &amp;#39;23&amp;#39; with the string &amp;#39;0142&lt;strong&gt;1&lt;/strong&gt;&lt;strong&gt;&lt;em&gt;02&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;3&lt;/strong&gt;94&amp;#39;. I&amp;#39;m not really sure about the file size implications of keeping this in a single field vs tracking all of these exclusions in their own single character field, but I think they switched from the latter to the former before I got here so I&amp;#39;m guessing a concatenated field is preferrable.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11b4cu9", "is_robot_indexable": true, "report_reasons": null, "author": "Burton_Gustice", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11b4cu9/whats_a_good_robust_option_for_tracking_all/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11b4cu9/whats_a_good_robust_option_for_tracking_all/", "subreddit_subscribers": 91002, "created_utc": 1677278427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm evaluating couchbase for a new startup, it meets my needs, unfortunately the community edition is pretty stripped/limited in comparison, and the enterprise licensing needs to go through sales (fucking hell!!!!). Has anyone worked with enterprise on your own infrastructure? What's the pricing like? Was it worth it? I really don't feel like waiting on a sales call to make a decision whether i proceed with cb or go another db.\n\nOr i use the CE, and hope once i hit the scaling limits, the price makes sense, but I despise vendor lock in...\n\nNote: couchbase if you ever see this, your sales tactics, lack of transparency make a great way to loose developers.", "author_fullname": "t2_p1007ct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Couchbase enterprise licensing and costs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11b1923", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677270947.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677270706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m evaluating couchbase for a new startup, it meets my needs, unfortunately the community edition is pretty stripped/limited in comparison, and the enterprise licensing needs to go through sales (fucking hell!!!!). Has anyone worked with enterprise on your own infrastructure? What&amp;#39;s the pricing like? Was it worth it? I really don&amp;#39;t feel like waiting on a sales call to make a decision whether i proceed with cb or go another db.&lt;/p&gt;\n\n&lt;p&gt;Or i use the CE, and hope once i hit the scaling limits, the price makes sense, but I despise vendor lock in...&lt;/p&gt;\n\n&lt;p&gt;Note: couchbase if you ever see this, your sales tactics, lack of transparency make a great way to loose developers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11b1923", "is_robot_indexable": true, "report_reasons": null, "author": "wind_dude", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11b1923/couchbase_enterprise_licensing_and_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11b1923/couchbase_enterprise_licensing_and_costs/", "subreddit_subscribers": 91002, "created_utc": 1677270706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nContext: I've got to accept a list of IDs and then, *for each one,* process their data and send it somewhere.\n\nQuestion: When relying on Lambda for parallelizing such a task, how best to organize/parition it? Possible considerations are...\n\n... 1 Lambda worker per ID\n\n... Organize small batches of IDs, and have 1 worker for each batch\n\n... Maybe Lambda knows how to do this for me and I shouldn't worry about it.\n\nWould love your advice, please and thank you.", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Parallelizing with AWS Lambda", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ayy66", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677264918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Context: I&amp;#39;ve got to accept a list of IDs and then, &lt;em&gt;for each one,&lt;/em&gt; process their data and send it somewhere.&lt;/p&gt;\n\n&lt;p&gt;Question: When relying on Lambda for parallelizing such a task, how best to organize/parition it? Possible considerations are...&lt;/p&gt;\n\n&lt;p&gt;... 1 Lambda worker per ID&lt;/p&gt;\n\n&lt;p&gt;... Organize small batches of IDs, and have 1 worker for each batch&lt;/p&gt;\n\n&lt;p&gt;... Maybe Lambda knows how to do this for me and I shouldn&amp;#39;t worry about it.&lt;/p&gt;\n\n&lt;p&gt;Would love your advice, please and thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ayy66", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ayy66/parallelizing_with_aws_lambda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ayy66/parallelizing_with_aws_lambda/", "subreddit_subscribers": 91002, "created_utc": 1677264918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am based in Europe and have been offered two different positions, and I am not sure which one to choose. I am hoping to get some advice from the community here.\n\nThe first position is a long-term contract as a MLops engineer. The second position is a freelance contract for 2 years as a cloud data/ops engineer on Azure. While the data engineer position is better paid, I am not sure which one would be better for my career in the long term.\n\nI have some experience in both areas, but I am not an expert. I am looking for a position that will allow me to learn and grow in my career.\n\nI would appreciate any advice or insight that you could offer. Have any of you been in a similar situation? Which position would you choose, and why?\n\nThanks in advance for your help!", "author_fullname": "t2_8nkhucjj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice: Long-term MLops vs Cloud Data/Ops Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11axnzr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677261702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am based in Europe and have been offered two different positions, and I am not sure which one to choose. I am hoping to get some advice from the community here.&lt;/p&gt;\n\n&lt;p&gt;The first position is a long-term contract as a MLops engineer. The second position is a freelance contract for 2 years as a cloud data/ops engineer on Azure. While the data engineer position is better paid, I am not sure which one would be better for my career in the long term.&lt;/p&gt;\n\n&lt;p&gt;I have some experience in both areas, but I am not an expert. I am looking for a position that will allow me to learn and grow in my career.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate any advice or insight that you could offer. Have any of you been in a similar situation? Which position would you choose, and why?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11axnzr", "is_robot_indexable": true, "report_reasons": null, "author": "MLBets", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11axnzr/need_advice_longterm_mlops_vs_cloud_dataops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11axnzr/need_advice_longterm_mlops_vs_cloud_dataops/", "subreddit_subscribers": 91002, "created_utc": 1677261702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello: \n\nI have been using DataFunsion in GCP and for the most part was working perfectly, the Pineline is very simple, its gets a Saleforce Table (Data Extention) and put it into a table in GCP, two days ago was working with no issues But know I\u00b4m getting this error \u201c**Preview runner container killed possibly because of out of memory. Please try running preview again**.\u201d Don\u00b4t know why it didn\u00b4t appear before and don\u00b4t know how to get rid of it.\n\nAny help will be welcome, Thank You.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/ewkjja1yc6ka1.jpg?width=666&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e41d72c104f1c0c763dae5010d1695337875b161", "author_fullname": "t2_m2kvp34t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DATAFUSION: out of memory issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ewkjja1yc6ka1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 118, "x": 108, "u": "https://preview.redd.it/ewkjja1yc6ka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08d933e7df2cff6348fe9d767f2133ec90a8ed45"}, {"y": 236, "x": 216, "u": "https://preview.redd.it/ewkjja1yc6ka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25413f6eb892c8d0bcaea45c8ac9027695578194"}, {"y": 350, "x": 320, "u": "https://preview.redd.it/ewkjja1yc6ka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed9a0c516b721d38cfb20fe1c54eba58d1f19552"}, {"y": 700, "x": 640, "u": "https://preview.redd.it/ewkjja1yc6ka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9db7818b96ac89caf13ed56c8d19d52d5bdeea54"}], "s": {"y": 729, "x": 666, "u": "https://preview.redd.it/ewkjja1yc6ka1.jpg?width=666&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e41d72c104f1c0c763dae5010d1695337875b161"}, "id": "ewkjja1yc6ka1"}}, "name": "t3_11axfsl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FS8647CSveu4J4BxBRiIe2sLzMc8EVdyzXOxBPd936U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677261139.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello: &lt;/p&gt;\n\n&lt;p&gt;I have been using DataFunsion in GCP and for the most part was working perfectly, the Pineline is very simple, its gets a Saleforce Table (Data Extention) and put it into a table in GCP, two days ago was working with no issues But know I\u00b4m getting this error \u201c&lt;strong&gt;Preview runner container killed possibly because of out of memory. Please try running preview again&lt;/strong&gt;.\u201d Don\u00b4t know why it didn\u00b4t appear before and don\u00b4t know how to get rid of it.&lt;/p&gt;\n\n&lt;p&gt;Any help will be welcome, Thank You.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ewkjja1yc6ka1.jpg?width=666&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=e41d72c104f1c0c763dae5010d1695337875b161\"&gt;https://preview.redd.it/ewkjja1yc6ka1.jpg?width=666&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=e41d72c104f1c0c763dae5010d1695337875b161&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11axfsl", "is_robot_indexable": true, "report_reasons": null, "author": "neromerob", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11axfsl/datafusion_out_of_memory_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11axfsl/datafusion_out_of_memory_issue/", "subreddit_subscribers": 91002, "created_utc": 1677261139.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking for a database for storing primarily time-series data while being suitable for the \"Transform\" phase in the ELT process. We need to preserve time-series functions such as time bucketing, getting last values etc.\n\nIs TimescaleDB suitable for ELT architecture? Meaning is it efficient to do the heavy \"Transform\" steps? Would some distributed OLAP DB like Pinot or Druid be better maybe? Or any other suggestions?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TimescaleDB - suitability for heavy Transformations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11axa3r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677260729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a database for storing primarily time-series data while being suitable for the &amp;quot;Transform&amp;quot; phase in the ELT process. We need to preserve time-series functions such as time bucketing, getting last values etc.&lt;/p&gt;\n\n&lt;p&gt;Is TimescaleDB suitable for ELT architecture? Meaning is it efficient to do the heavy &amp;quot;Transform&amp;quot; steps? Would some distributed OLAP DB like Pinot or Druid be better maybe? Or any other suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11axa3r", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11axa3r/timescaledb_suitability_for_heavy_transformations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11axa3r/timescaledb_suitability_for_heavy_transformations/", "subreddit_subscribers": 91002, "created_utc": 1677260729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you have spark workloads that consume Kafka data you might like to know that there is a way for you to monitor Kafka consumption in your monitoring UI of choice. Since Spark doesn't expose any Kafka metrics by default I've decided to write a blog post about it. As the number of jobs grows, their visibility decreases so it's very important to be able to monitor them or even implement alarms when something is not as expected.\n\nIf you'd like to implement it in your Structured Streaming jobs or are just curious about custom metrics and the new Prometheus endpoint, make sure to check the post!\n\n[https://medium.com/towards-data-science/custom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1](https://medium.com/towards-data-science/custom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1)\n\nFeel free to comment if you have any doubts or even any suggestions on what Spark topic I should cover next", "author_fullname": "t2_jxqw29xi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Custom Kafka metrics using Apache Spark PrometheusServlet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ax15b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677260084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you have spark workloads that consume Kafka data you might like to know that there is a way for you to monitor Kafka consumption in your monitoring UI of choice. Since Spark doesn&amp;#39;t expose any Kafka metrics by default I&amp;#39;ve decided to write a blog post about it. As the number of jobs grows, their visibility decreases so it&amp;#39;s very important to be able to monitor them or even implement alarms when something is not as expected.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;d like to implement it in your Structured Streaming jobs or are just curious about custom metrics and the new Prometheus endpoint, make sure to check the post!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/towards-data-science/custom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1\"&gt;https://medium.com/towards-data-science/custom-kafka-streaming-metrics-using-apache-spark-prometheus-sink-9c04cf2ddaf1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Feel free to comment if you have any doubts or even any suggestions on what Spark topic I should cover next&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uxSBGzgk_OoOH5kaNBulfCQiaEIycjzLj6KJVhv_vvI.jpg?auto=webp&amp;v=enabled&amp;s=7bda75f9e4032d18d4094a729411f308aa97f7cc", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/uxSBGzgk_OoOH5kaNBulfCQiaEIycjzLj6KJVhv_vvI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bdeb41fea6d53d3891744fcc911398d576d68941", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/uxSBGzgk_OoOH5kaNBulfCQiaEIycjzLj6KJVhv_vvI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc894a4ee0c894b20d756b59b57466770a14a526", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/uxSBGzgk_OoOH5kaNBulfCQiaEIycjzLj6KJVhv_vvI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6ee4fac5eff3cf8c72020de52634ae2fc9b75067", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/uxSBGzgk_OoOH5kaNBulfCQiaEIycjzLj6KJVhv_vvI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33a17f9ea7af78b746decdd18cd6d6d8c67fbbc3", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/uxSBGzgk_OoOH5kaNBulfCQiaEIycjzLj6KJVhv_vvI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b338c6e2fbb7205e706880ea670426362f6b4e6", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/uxSBGzgk_OoOH5kaNBulfCQiaEIycjzLj6KJVhv_vvI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f69f9ae86953297bdc03b39d5c273d7d6544db1b", "width": 1080, "height": 720}], "variants": {}, "id": "o15iOZCwQF2h6w29QPZsFgid0C0GLtTUcRQfTpijgmQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11ax15b", "is_robot_indexable": true, "report_reasons": null, "author": "orpheuz24", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ax15b/custom_kafka_metrics_using_apache_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ax15b/custom_kafka_metrics_using_apache_spark/", "subreddit_subscribers": 91002, "created_utc": 1677260084.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}