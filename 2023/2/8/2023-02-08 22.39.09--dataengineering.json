{"kind": "Listing", "data": {"after": "t3_10wfqvn", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_71htpegt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would this job fall under data engineering or data analyst?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10wwzag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8S8N4XQaxECI8wuHKQFjlqmuwCXmoxXkwQ8mNJ2mcvc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675863697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/b8g2l2p4f0ha1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/b8g2l2p4f0ha1.jpg?auto=webp&amp;v=enabled&amp;s=38dea63530954c5ed8ce074ac4403b72011e7613", "width": 1179, "height": 1697}, "resolutions": [{"url": "https://preview.redd.it/b8g2l2p4f0ha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9879664806dad4faee9d91170090e00b57ae66d7", "width": 108, "height": 155}, {"url": "https://preview.redd.it/b8g2l2p4f0ha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0807e82dc9553727f29032f41e7e6c2d103b600", "width": 216, "height": 310}, {"url": "https://preview.redd.it/b8g2l2p4f0ha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d603b70aaa599b4879654967c0662aba28904f1", "width": 320, "height": 460}, {"url": "https://preview.redd.it/b8g2l2p4f0ha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b563ae2024d8513eb1620aeb381f39a937ebb1d1", "width": 640, "height": 921}, {"url": "https://preview.redd.it/b8g2l2p4f0ha1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=16291c56c2f89bb8de54a9d99092e385dd8c1e0e", "width": 960, "height": 1381}, {"url": "https://preview.redd.it/b8g2l2p4f0ha1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d38add370c65a31aa4a5ed432cb5f7923835ae1b", "width": 1080, "height": 1554}], "variants": {}, "id": "6TewrJcJltrqxUjN8TvlHA2hkWpQzn-bpQ_CCLWMghI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10wwzag", "is_robot_indexable": true, "report_reasons": null, "author": "YTthrowawsy", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wwzag/would_this_job_fall_under_data_engineering_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/b8g2l2p4f0ha1.jpg", "subreddit_subscribers": 88894, "created_utc": 1675863697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2tv9i42n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Labs to acquire Transform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_10x1n11", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "#46d160", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/53xRo1Rmn8V_yqkH6RC13B_emrp0REe-eWjMVqqCj0w.jpg", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675871398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getdbt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getdbt.com/blog/dbt-acquisition-transform/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iLGctQE3L1g279W1cv2OtoqCujUouTjEgvE2mOJdMcY.jpg?auto=webp&amp;v=enabled&amp;s=361aa3d45804afd6eb14a48b76c6a3bacbe8cf33", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/iLGctQE3L1g279W1cv2OtoqCujUouTjEgvE2mOJdMcY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3fef7426177672dc29b1468840ec7d315a062660", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/iLGctQE3L1g279W1cv2OtoqCujUouTjEgvE2mOJdMcY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=701cfac9ecde266a1028dd7f27b9432782f33294", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/iLGctQE3L1g279W1cv2OtoqCujUouTjEgvE2mOJdMcY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8716195cdbd1d217783ac2c487480492d483660", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/iLGctQE3L1g279W1cv2OtoqCujUouTjEgvE2mOJdMcY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1d9cf818b5b1307921dc1ab304c2ecc32b97197e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/iLGctQE3L1g279W1cv2OtoqCujUouTjEgvE2mOJdMcY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d759b482c03b08280d015b84e9d6138e477c51c3", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/iLGctQE3L1g279W1cv2OtoqCujUouTjEgvE2mOJdMcY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0950854ac88e70f55bd3453e9f20b4e84a3d2356", "width": 1080, "height": 607}], "variants": {}, "id": "oWSXMYG-HC-dmBhiXAikz7t6X2pdhTO-fGTkj_cFha4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod | Sr. Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10x1n11", "is_robot_indexable": true, "report_reasons": null, "author": "theporterhaus", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/10x1n11/dbt_labs_to_acquire_transform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getdbt.com/blog/dbt-acquisition-transform/", "subreddit_subscribers": 88894, "created_utc": 1675871398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering who has the best data orchestration tool at the moment?\n\nI am currently using prefect on a virtual machine to handle all of my flows that primarily execute dbt. I have also looked into dagster and mage, but prefect seems to be the most comprehensive? Are there any other orchestration tools that have a valid integration with dbt that are more useful?", "author_fullname": "t2_3h5wixaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Orchestration Tool to run dbt projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x4n7n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675875782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering who has the best data orchestration tool at the moment?&lt;/p&gt;\n\n&lt;p&gt;I am currently using prefect on a virtual machine to handle all of my flows that primarily execute dbt. I have also looked into dagster and mage, but prefect seems to be the most comprehensive? Are there any other orchestration tools that have a valid integration with dbt that are more useful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10x4n7n", "is_robot_indexable": true, "report_reasons": null, "author": "J0hnDutt00n", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x4n7n/best_orchestration_tool_to_run_dbt_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x4n7n/best_orchestration_tool_to_run_dbt_projects/", "subreddit_subscribers": 88894, "created_utc": 1675875782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!  \n\n\nThis is a DBT-related question.\n\nI'm searching for a solution that can help me clean up my warehouse of old and deprecated models automatically.\n\nMy challenge is that I'm using custom schemas in my deployment environment, which means that mart models are deployed their own schemas and staging data into a staging schema. I want the cleaning to be done every schema.\n\nI stumbled upon this one: [https://discourse.getdbt.com/t/clean-your-warehouse-of-old-and-deprecated-models/1547/1](https://discourse.getdbt.com/t/clean-your-warehouse-of-old-and-deprecated-models/1547/1)  \n\n\n... but the suggested macro(s) can not solve the challenge with custom schemas  \n\n\nDoes anyone of you have a solution for cleaning up a warehouse with DBT custom schemas? \ud83d\ude47\u200d\u2642\ufe0f", "author_fullname": "t2_oeiyrmpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT: Clean your warehouse of old and deprecated models featuring custom schemas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wrlve", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675845421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!  &lt;/p&gt;\n\n&lt;p&gt;This is a DBT-related question.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m searching for a solution that can help me clean up my warehouse of old and deprecated models automatically.&lt;/p&gt;\n\n&lt;p&gt;My challenge is that I&amp;#39;m using custom schemas in my deployment environment, which means that mart models are deployed their own schemas and staging data into a staging schema. I want the cleaning to be done every schema.&lt;/p&gt;\n\n&lt;p&gt;I stumbled upon this one: &lt;a href=\"https://discourse.getdbt.com/t/clean-your-warehouse-of-old-and-deprecated-models/1547/1\"&gt;https://discourse.getdbt.com/t/clean-your-warehouse-of-old-and-deprecated-models/1547/1&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;... but the suggested macro(s) can not solve the challenge with custom schemas  &lt;/p&gt;\n\n&lt;p&gt;Does anyone of you have a solution for cleaning up a warehouse with DBT custom schemas? \ud83d\ude47\u200d\u2642\ufe0f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?auto=webp&amp;v=enabled&amp;s=d4169652ab7f36209622ee244f310aefe0cf8ce2", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd185c71f8fd75a33c0c79555ab7aa66ff94f024", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10e2c53de9b2969366504c9ded514bbe1e2eb4d1", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7634b43f18facd6b7a0eaa901c2b135c2c9f47cf", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=487560d27ca62339efe41270d29a0644753c4362", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43637abd63f6c913d8d643f155a22cfee21ab4eb", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7eff2686e5c425ddf4ad53b33e6ccec820db7c7", "width": 1080, "height": 567}], "variants": {}, "id": "7Z_t_HsXt2-BEolo1xeZUv0TRH4nZTtHHcogXhY8TFI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10wrlve", "is_robot_indexable": true, "report_reasons": null, "author": "formaldehyden", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wrlve/dbt_clean_your_warehouse_of_old_and_deprecated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wrlve/dbt_clean_your_warehouse_of_old_and_deprecated/", "subreddit_subscribers": 88894, "created_utc": 1675845421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_40ihn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Airflow DAGs on Dagster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10x7ixs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xj-OOmT7UPCIw2j_Lx_3S8AHW76__BIAQrEKjDXV9zg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675882755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/dagster-airflow-migration", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?auto=webp&amp;v=enabled&amp;s=c77b3d2e139b81d19d91fb093a86fe06147f0df0", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45e3a502f6f0c45e678d1e3a816b67206bdd859a", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5aba134ef347285f14a6c5d66c07d140a3cf23e3", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=532ff18bf5f7f538f7d0ca18f882c7c899b321d6", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8e963ae3df8798a882ecf920c3aa3f3b63ddc03", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=549d4c7458892fb76b4988dcccb5061b27094060", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ubfrirg3vqTJpzBBXxtnTiqGrrZE00LTVOLFrF26Hmo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a0137b5793ef5b51c305bfb024e7e5991eff28cf", "width": 1080, "height": 567}], "variants": {}, "id": "qrMeQRAkw-xrrf9moY8jwZFpUX5vOWb6xdHFQo2DDJg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10x7ixs", "is_robot_indexable": true, "report_reasons": null, "author": "floydophone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x7ixs/running_airflow_dags_on_dagster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/dagster-airflow-migration", "subreddit_subscribers": 88894, "created_utc": 1675882755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all,\n\nRecently I saw someone post asking about a mentor. I'm looking for the same, or at the very least someone who can help validate or improve my plan for the next \\~6 months.\n\nA bit of context: I'm a lead Data Scientist at a startup. When I joined, I was an intern and we were 3 people. I grew quickly into the role and became the lead, managing a team of 6 in a company of 35 people.\n\nWhile my title is Lead Data Scientist, we do a lot of data cleaning &amp; data validation, build ETL pipelines...our tool stack consists predominantly of python, django, pandas, airflow, GCP. We do statistical analysis but no machine learning, very little predictive algorightms...\n\nI actually feel more like an Analytics Engineer/borderline Data Engineer depsite my title. However, I still have a lot to learn. For example, we use pandas far more than SQL (so I have basic sql querying experience but can improve), and I've never used Spark or Hadoop...\n\nI've loved the company and helping it grow, but we're based in Paris, France, and believe it or not I miss a lot about America (I'm originally from California). So a while ago I discussed with our CTO and have let them know that I'll no longer work for them starting April 2022, so I can focus on moving my family to the states.\n\nI'd like to transition into a role as a full-fledged Data Engineer, as I think it's very interesting and has the best future. I plan on moving to the states by January 2024 at the latest.\n\nSo essentially from April - December 2023 I'm saved enough to be able to focus on personal projects and developing data engineering skills in addition to networking and applying to places later in the year.\n\nIf someone could mentor me, I would love to chat! If not, here's my plan for these months:\n\n* Do the entire DataEngineeringClup Zoomcamp 2023 (despite not being able to start with the rest of the students this past January)\n* Reading: Fundamentals of Data Engineering- Housley and Reis, Designing Data Intensive Applications - Kleppmann, Data Warehouse Toolkit - Kimball\n* Maybe giving Data Engineering with Python a go?\n\n&amp;#x200B;\n\nThis is a huge personal project that'll change my life as well as my family's. I wanna set us up as nicely as possible, so I'm taking a shot in the dark here and asking for any help I can get! **If you read to here, thank you**", "author_fullname": "t2_gcq3x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a mentor or someone to help validate my plan to transition into Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x4ir5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675875514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;Recently I saw someone post asking about a mentor. I&amp;#39;m looking for the same, or at the very least someone who can help validate or improve my plan for the next ~6 months.&lt;/p&gt;\n\n&lt;p&gt;A bit of context: I&amp;#39;m a lead Data Scientist at a startup. When I joined, I was an intern and we were 3 people. I grew quickly into the role and became the lead, managing a team of 6 in a company of 35 people.&lt;/p&gt;\n\n&lt;p&gt;While my title is Lead Data Scientist, we do a lot of data cleaning &amp;amp; data validation, build ETL pipelines...our tool stack consists predominantly of python, django, pandas, airflow, GCP. We do statistical analysis but no machine learning, very little predictive algorightms...&lt;/p&gt;\n\n&lt;p&gt;I actually feel more like an Analytics Engineer/borderline Data Engineer depsite my title. However, I still have a lot to learn. For example, we use pandas far more than SQL (so I have basic sql querying experience but can improve), and I&amp;#39;ve never used Spark or Hadoop...&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve loved the company and helping it grow, but we&amp;#39;re based in Paris, France, and believe it or not I miss a lot about America (I&amp;#39;m originally from California). So a while ago I discussed with our CTO and have let them know that I&amp;#39;ll no longer work for them starting April 2022, so I can focus on moving my family to the states.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to transition into a role as a full-fledged Data Engineer, as I think it&amp;#39;s very interesting and has the best future. I plan on moving to the states by January 2024 at the latest.&lt;/p&gt;\n\n&lt;p&gt;So essentially from April - December 2023 I&amp;#39;m saved enough to be able to focus on personal projects and developing data engineering skills in addition to networking and applying to places later in the year.&lt;/p&gt;\n\n&lt;p&gt;If someone could mentor me, I would love to chat! If not, here&amp;#39;s my plan for these months:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Do the entire DataEngineeringClup Zoomcamp 2023 (despite not being able to start with the rest of the students this past January)&lt;/li&gt;\n&lt;li&gt;Reading: Fundamentals of Data Engineering- Housley and Reis, Designing Data Intensive Applications - Kleppmann, Data Warehouse Toolkit - Kimball&lt;/li&gt;\n&lt;li&gt;Maybe giving Data Engineering with Python a go?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is a huge personal project that&amp;#39;ll change my life as well as my family&amp;#39;s. I wanna set us up as nicely as possible, so I&amp;#39;m taking a shot in the dark here and asking for any help I can get! &lt;strong&gt;If you read to here, thank you&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10x4ir5", "is_robot_indexable": true, "report_reasons": null, "author": "johnsonfrusciante", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x4ir5/looking_for_a_mentor_or_someone_to_help_validate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x4ir5/looking_for_a_mentor_or_someone_to_help_validate/", "subreddit_subscribers": 88894, "created_utc": 1675875514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all. I'm not a data engineer or analytics engineer so sorry if this is a misguided question. \n\nI hear parquet files are far more light weight and speedier for analytics than csv. Therefore is it possible to use parquet files in place of csv files for dbt to load via dbt seed? If not, why not? Thanks!", "author_fullname": "t2_2gzsok4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dbt: csv/parquet seed files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wwjg4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675862486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all. I&amp;#39;m not a data engineer or analytics engineer so sorry if this is a misguided question. &lt;/p&gt;\n\n&lt;p&gt;I hear parquet files are far more light weight and speedier for analytics than csv. Therefore is it possible to use parquet files in place of csv files for dbt to load via dbt seed? If not, why not? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10wwjg4", "is_robot_indexable": true, "report_reasons": null, "author": "ciarandeceol1", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wwjg4/dbt_csvparquet_seed_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wwjg4/dbt_csvparquet_seed_files/", "subreddit_subscribers": 88894, "created_utc": 1675862486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm wondering on the best way to collect data from users and allow them to review those data. What are you using there for ?\n\nWe are currently using Google Sheets. The first stage of our data pipeline ingest those sheets. The issue with GS is that users can change inputs from others users as well. There is no input validation and versioning is quite bad.\n\nI have already seen custom interface where you can see what your user is allowed to and request review/change by email for a specific row of table to a specific user. But I supposed that it has been developped internally...\n\nWhat are you using there for ?", "author_fullname": "t2_120jir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to collect data from users and allow them to validate those data ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wtxv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675854464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering on the best way to collect data from users and allow them to review those data. What are you using there for ?&lt;/p&gt;\n\n&lt;p&gt;We are currently using Google Sheets. The first stage of our data pipeline ingest those sheets. The issue with GS is that users can change inputs from others users as well. There is no input validation and versioning is quite bad.&lt;/p&gt;\n\n&lt;p&gt;I have already seen custom interface where you can see what your user is allowed to and request review/change by email for a specific row of table to a specific user. But I supposed that it has been developped internally...&lt;/p&gt;\n\n&lt;p&gt;What are you using there for ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10wtxv5", "is_robot_indexable": true, "report_reasons": null, "author": "tgilon", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wtxv5/how_to_collect_data_from_users_and_allow_them_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wtxv5/how_to_collect_data_from_users_and_allow_them_to/", "subreddit_subscribers": 88894, "created_utc": 1675854464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Help! I accidentally deleted a table from Postgres database in Dbeaver. Its an important one and ik I'm an idiot to not have a backup. \n\nAnyway I can recover it?\n\nEdit: this is on my local database and not on the cloud. This is 2021 data which is no longer available on systems. I'm guessing where it goes once I delete it... Not recycle bin for sure.", "author_fullname": "t2_803noo26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deleted a table accidentally!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wuzsn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675870508.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675857936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Help! I accidentally deleted a table from Postgres database in Dbeaver. Its an important one and ik I&amp;#39;m an idiot to not have a backup. &lt;/p&gt;\n\n&lt;p&gt;Anyway I can recover it?&lt;/p&gt;\n\n&lt;p&gt;Edit: this is on my local database and not on the cloud. This is 2021 data which is no longer available on systems. I&amp;#39;m guessing where it goes once I delete it... Not recycle bin for sure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10wuzsn", "is_robot_indexable": true, "report_reasons": null, "author": "Dosawithchutney", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wuzsn/deleted_a_table_accidentally/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wuzsn/deleted_a_table_accidentally/", "subreddit_subscribers": 88894, "created_utc": 1675857936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have you switched to any Airflow alternative? I would love to hear the reasons.\n\n[View Poll](https://www.reddit.com/poll/10x8qj1)", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have you switched to any Airflow alternative? Please comment why yes/no", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x8qj1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675885633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have you switched to any Airflow alternative? I would love to hear the reasons.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10x8qj1\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10x8qj1", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1676231233706, "options": [{"text": "Dagster", "id": "21501894"}, {"text": "Prefect", "id": "21501895"}, {"text": "Mage", "id": "21501896"}, {"text": "Other (please comment what)", "id": "21501897"}, {"text": "Still Airflow", "id": "21501898"}, {"text": "Show me the results", "id": "21501899"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 116, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x8qj1/have_you_switched_to_any_airflow_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10x8qj1/have_you_switched_to_any_airflow_alternative/", "subreddit_subscribers": 88894, "created_utc": 1675885633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " **Context:**  \nI'm the only data scientist/analyst/guy at my company. I mainly do some query and data manipulation using R or Python, present results and my company finds me absolutely amazing and indispensable.\n\n**Present:**  \nMy company acquired shares of another company which doesn't have any data guys whatsoever, and offered them me to do some data work for them, to help them get started.\n\n**The work to be done:**  \nThis company is more of a group of companies which is has data from many sources (data from insurance, banking, health care, etc.). They want to create a data warehouse using these numerous databases, and start using their data. Some databases are cloud, other on prem, will have to use API for another, etc. It will be very small data, like 5000 clients. A girl at that company pull all the data manually and put it in excel for example but still..\n\n**The problem:**  \nI have no idea how to do a data warehouse and keep it updated. I told this to my superiors but they're not worried and said \"meh anything is fine, it's very small data, don't worry. Anything you do will be a great help already\". I know if I just pull data, put it in an excel, do this daily automatically, it will be fine. But there's also talks of having the data warehouse \"live\", as in, with all the data replicated live. And they want to build a \"customer hub\" on top of it, something that a user can access and input data if needed  \nThere's a guy at my company who will setup a SQL Server locally, but after that it will be all me.\n\n**My question:**  \nCan someone point me to some resources to help me with the situation? I was *absolutely freaking out* in the meeting this was decided. I was brought to this meeting without knowing what they were going to say and then they tell them \"sure this guy will do it for you\". I have no idea how to tackle this.", "author_fullname": "t2_3msnawl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Urgent Help Needed] Create data warehouse - disfunctional company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x4qav", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675875984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt;&lt;br/&gt;\nI&amp;#39;m the only data scientist/analyst/guy at my company. I mainly do some query and data manipulation using R or Python, present results and my company finds me absolutely amazing and indispensable.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Present:&lt;/strong&gt;&lt;br/&gt;\nMy company acquired shares of another company which doesn&amp;#39;t have any data guys whatsoever, and offered them me to do some data work for them, to help them get started.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The work to be done:&lt;/strong&gt;&lt;br/&gt;\nThis company is more of a group of companies which is has data from many sources (data from insurance, banking, health care, etc.). They want to create a data warehouse using these numerous databases, and start using their data. Some databases are cloud, other on prem, will have to use API for another, etc. It will be very small data, like 5000 clients. A girl at that company pull all the data manually and put it in excel for example but still..&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The problem:&lt;/strong&gt;&lt;br/&gt;\nI have no idea how to do a data warehouse and keep it updated. I told this to my superiors but they&amp;#39;re not worried and said &amp;quot;meh anything is fine, it&amp;#39;s very small data, don&amp;#39;t worry. Anything you do will be a great help already&amp;quot;. I know if I just pull data, put it in an excel, do this daily automatically, it will be fine. But there&amp;#39;s also talks of having the data warehouse &amp;quot;live&amp;quot;, as in, with all the data replicated live. And they want to build a &amp;quot;customer hub&amp;quot; on top of it, something that a user can access and input data if needed&lt;br/&gt;\nThere&amp;#39;s a guy at my company who will setup a SQL Server locally, but after that it will be all me.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My question:&lt;/strong&gt;&lt;br/&gt;\nCan someone point me to some resources to help me with the situation? I was &lt;em&gt;absolutely freaking out&lt;/em&gt; in the meeting this was decided. I was brought to this meeting without knowing what they were going to say and then they tell them &amp;quot;sure this guy will do it for you&amp;quot;. I have no idea how to tackle this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10x4qav", "is_robot_indexable": true, "report_reasons": null, "author": "Prettywaffleman", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x4qav/urgent_help_needed_create_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x4qav/urgent_help_needed_create_data_warehouse/", "subreddit_subscribers": 88894, "created_utc": 1675875984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got a technical screen coming up about Python and SQL and while I do have experience in both, I was hoping to read or watch (Udemy) resources regarding best practices. For instance, I imagine I'll have to answer questions similar to \"Walk me through how you'd remove duplicates in a dataset\" for SQL or \"Tell me how you'd de-dupe a list\" for Python which - while I have done both before - I'm unsure if the way I go about this aligns with best practice.\n\nFor SQL, I read through some posts and saw the following resources recommended:\n\n* T-SQL Fundamentals by Itzik Ben-Gan\n* T-SQL Querying by Itzik Ben-Gan\n* Learning SQL by O'Reilly publisher\n\nHowever, I'm unsure if those books only talk about the basics (e.g., \"Here's how to query filtered data\") or if they go into advanced topics regarding best practices and whatnot. Does anyone have insight here?\n\nAs for Python, I wouldn't even know where to start looking for such.\n\nAny insight or feedback would be greatly appreciate as I've largely gone through my data engineering career without much mentorship.\n\n*Additional context: they specifically said it's not \"Leetcode-like\".*", "author_fullname": "t2_hwg7lsz6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for SQL and Python Best Practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x4i50", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675875474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a technical screen coming up about Python and SQL and while I do have experience in both, I was hoping to read or watch (Udemy) resources regarding best practices. For instance, I imagine I&amp;#39;ll have to answer questions similar to &amp;quot;Walk me through how you&amp;#39;d remove duplicates in a dataset&amp;quot; for SQL or &amp;quot;Tell me how you&amp;#39;d de-dupe a list&amp;quot; for Python which - while I have done both before - I&amp;#39;m unsure if the way I go about this aligns with best practice.&lt;/p&gt;\n\n&lt;p&gt;For SQL, I read through some posts and saw the following resources recommended:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;T-SQL Fundamentals by Itzik Ben-Gan&lt;/li&gt;\n&lt;li&gt;T-SQL Querying by Itzik Ben-Gan&lt;/li&gt;\n&lt;li&gt;Learning SQL by O&amp;#39;Reilly publisher&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;However, I&amp;#39;m unsure if those books only talk about the basics (e.g., &amp;quot;Here&amp;#39;s how to query filtered data&amp;quot;) or if they go into advanced topics regarding best practices and whatnot. Does anyone have insight here?&lt;/p&gt;\n\n&lt;p&gt;As for Python, I wouldn&amp;#39;t even know where to start looking for such.&lt;/p&gt;\n\n&lt;p&gt;Any insight or feedback would be greatly appreciate as I&amp;#39;ve largely gone through my data engineering career without much mentorship.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Additional context: they specifically said it&amp;#39;s not &amp;quot;Leetcode-like&amp;quot;.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10x4i50", "is_robot_indexable": true, "report_reasons": null, "author": "spicy_pierogi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10x4i50/resources_for_sql_and_python_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x4i50/resources_for_sql_and_python_best_practices/", "subreddit_subscribers": 88894, "created_utc": 1675875474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am trying to run ELT jobs using DBT with Databricks as the warehouse.\n\nI have created an incremental model that uses sources and the incremental strategy is set to 'merge'. I have also configured the unique key, but whenever I run the model, only the 'append' activity works where the new values are incrementally added but the updated rows in the source table are not updated in table created when I run this model\n\nCould anyone explain why is this happening?", "author_fullname": "t2_9d4i4lxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I implement incremental models with 'merge' strategy in DBT ( Data Build Tool) using Databricks as the warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wrph1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675845834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am trying to run ELT jobs using DBT with Databricks as the warehouse.&lt;/p&gt;\n\n&lt;p&gt;I have created an incremental model that uses sources and the incremental strategy is set to &amp;#39;merge&amp;#39;. I have also configured the unique key, but whenever I run the model, only the &amp;#39;append&amp;#39; activity works where the new values are incrementally added but the updated rows in the source table are not updated in table created when I run this model&lt;/p&gt;\n\n&lt;p&gt;Could anyone explain why is this happening?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10wrph1", "is_robot_indexable": true, "report_reasons": null, "author": "New_Introduction_154", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wrph1/how_do_i_implement_incremental_models_with_merge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wrph1/how_do_i_implement_incremental_models_with_merge/", "subreddit_subscribers": 88894, "created_utc": 1675845834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rethinking Stream Processing and Streaming Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_10x5uwh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JTZl3_bfA5KMAGrk_C5fQcEFrOewP0X7RCml78nbIWw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675878668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "risingwave-labs.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.risingwave-labs.com/blog/Rethinking_stream_processing_and_streaming_databases/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?auto=webp&amp;v=enabled&amp;s=5840241cc2d9a277f350dbf7130265842eb394b4", "width": 1365, "height": 767}, "resolutions": [{"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1d26575d826dc84ec92247cbbfcc2c2fb2a855a", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a1353be1e737d336024d2e5f47264f8827d85215", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=990050d6d47fab5e5fa82f0fab5dc98a55d2fa27", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2f233e718a694a52ce5f56ff81057dc200b65df", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96ad0358d7447cd21305d06736139f5e0315cc2b", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/7vwsx8aivp_pRUc0TEpUDKEKyeqm0VzSWfyiIJmi8_g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2aa49201f3cb9ba460e2c4ba6ae51b4e0ba2f5b", "width": 1080, "height": 606}], "variants": {}, "id": "QqxYaazblEVaBxyQJDXb4w-J1BYZ2l_cfoLGuvtUy3c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10x5uwh", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x5uwh/rethinking_stream_processing_and_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.risingwave-labs.com/blog/Rethinking_stream_processing_and_streaming_databases/", "subreddit_subscribers": 88894, "created_utc": 1675878668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi.  I am looking for resources that show how to effectively utilize dask within python.  Books with the recipe approach are ideal.  Or if you can point me at some open GitHub repos that used dask that would be great.  I am specifically looking for ones that use a cluster.\n\nThanks", "author_fullname": "t2_l04by", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dask Recipes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10whjin", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675814646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.  I am looking for resources that show how to effectively utilize dask within python.  Books with the recipe approach are ideal.  Or if you can point me at some open GitHub repos that used dask that would be great.  I am specifically looking for ones that use a cluster.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10whjin", "is_robot_indexable": true, "report_reasons": null, "author": "kentmaxwell", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10whjin/dask_recipes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10whjin/dask_recipes/", "subreddit_subscribers": 88894, "created_utc": 1675814646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our startup is &lt;50 people and our stack is: fivetran, dbt, snowflake and preset. \n\nWe have some use cases where people in the company need access to user email addresses for research purposes. How do your teams think about PII (emails specifically) &amp; exposing that in your BI tool?", "author_fullname": "t2_j1vd6s00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PII in Business Intelligence tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x7kvn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675882868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our startup is &amp;lt;50 people and our stack is: fivetran, dbt, snowflake and preset. &lt;/p&gt;\n\n&lt;p&gt;We have some use cases where people in the company need access to user email addresses for research purposes. How do your teams think about PII (emails specifically) &amp;amp; exposing that in your BI tool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10x7kvn", "is_robot_indexable": true, "report_reasons": null, "author": "crhumble", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x7kvn/pii_in_business_intelligence_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x7kvn/pii_in_business_intelligence_tool/", "subreddit_subscribers": 88894, "created_utc": 1675882868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for an ETL tool that will allow OAuth2 grant type client\\_credentials, im looking for a simple no-code tool such as Hevo that can help accomplish this open to any suggestions. I'm new to APIs and ETL tools and my work is asking for data from an API for a recruitment system that we have just acquired.\n\n&amp;#x200B;\n\nany help is greatly appreciated thank you in advance.", "author_fullname": "t2_37taeo1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL Tool suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x1d82", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675871122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for an ETL tool that will allow OAuth2 grant type client_credentials, im looking for a simple no-code tool such as Hevo that can help accomplish this open to any suggestions. I&amp;#39;m new to APIs and ETL tools and my work is asking for data from an API for a recruitment system that we have just acquired.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;any help is greatly appreciated thank you in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10x1d82", "is_robot_indexable": true, "report_reasons": null, "author": "MathematicianOne3790", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x1d82/etl_tool_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x1d82/etl_tool_suggestions/", "subreddit_subscribers": 88894, "created_utc": 1675871122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New here, what would be the best one to learn and why? \n\nPrefect or Airflow?\n\nI seen Zoomcamp changed their tool from Airflow to Prefect for the 2023 cohort and I was just wondering what would be the tool of choice in 2023 for you guys.", "author_fullname": "t2_j68xrjb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Orchestration tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x9uq0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675888218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New here, what would be the best one to learn and why? &lt;/p&gt;\n\n&lt;p&gt;Prefect or Airflow?&lt;/p&gt;\n\n&lt;p&gt;I seen Zoomcamp changed their tool from Airflow to Prefect for the 2023 cohort and I was just wondering what would be the tool of choice in 2023 for you guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10x9uq0", "is_robot_indexable": true, "report_reasons": null, "author": "Yimmy_90", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x9uq0/orchestration_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x9uq0/orchestration_tools/", "subreddit_subscribers": 88894, "created_utc": 1675888218.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I recently graduated with a degree in Mechanical Engineering. Being that it was the middle of a pandemic I took what I could get which was a Data Engineering/Analyst role. I have worked at this company for almost 2 years now developing my skills in Python, Databricks, SQL, SSIS and many other data engineering programs. I decided to go back into Mechanical Engineering as an Engineer II, so I could use my degree and work with physical things. \n\nAre there any job opportunities that combine both skillsets? I know where I accepted has a data science team that will use machine learning to spot defects and iterate through on mechanical designs. Are there more jobs out there similar to this or is this a niche field?", "author_fullname": "t2_dx6y9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mechanical &amp; Data Engineering Opportunities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x9df5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675887118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I recently graduated with a degree in Mechanical Engineering. Being that it was the middle of a pandemic I took what I could get which was a Data Engineering/Analyst role. I have worked at this company for almost 2 years now developing my skills in Python, Databricks, SQL, SSIS and many other data engineering programs. I decided to go back into Mechanical Engineering as an Engineer II, so I could use my degree and work with physical things. &lt;/p&gt;\n\n&lt;p&gt;Are there any job opportunities that combine both skillsets? I know where I accepted has a data science team that will use machine learning to spot defects and iterate through on mechanical designs. Are there more jobs out there similar to this or is this a niche field?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10x9df5", "is_robot_indexable": true, "report_reasons": null, "author": "cdl723", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x9df5/mechanical_data_engineering_opportunities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x9df5/mechanical_data_engineering_opportunities/", "subreddit_subscribers": 88894, "created_utc": 1675887118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team is considering both options but wanted to understand what your teams find a bit more useful. \n\nSegment keeps pushing their CDP but I only care about event tracking + collection.   \nSnowplow seems decent but looks infra heavy. \n\nThoughts?", "author_fullname": "t2_j1vd6s00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Segment or Snowplow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10x7j7k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675882774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team is considering both options but wanted to understand what your teams find a bit more useful. &lt;/p&gt;\n\n&lt;p&gt;Segment keeps pushing their CDP but I only care about event tracking + collection.&lt;br/&gt;\nSnowplow seems decent but looks infra heavy. &lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10x7j7k", "is_robot_indexable": true, "report_reasons": null, "author": "crhumble", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x7j7k/segment_or_snowplow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x7j7k/segment_or_snowplow/", "subreddit_subscribers": 88894, "created_utc": 1675882774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n[Read Raster Data From Postgis Using Python](https://preview.redd.it/3vjp0t4yzzga1.png?width=597&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=56fdd37c413af378ff444bf929ec79ae4b82a15e)\n\n[Read Raster Data From Postgis Using Python](https://spatial-dev.guru/2023/02/04/read-raster-data-from-postgis-using-python/)", "author_fullname": "t2_avt84u4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Read Raster Data From Postgis Using Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"3vjp0t4yzzga1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 56, "x": 108, "u": "https://preview.redd.it/3vjp0t4yzzga1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60cb9c81810919cf094ea6060531e5fc2bc37e42"}, {"y": 113, "x": 216, "u": "https://preview.redd.it/3vjp0t4yzzga1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2de9cdfd7aeda3d4be6563924ee5b64ca3021f83"}, {"y": 168, "x": 320, "u": "https://preview.redd.it/3vjp0t4yzzga1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6560f9772a7feb511d1339c98369320ef051f1ee"}], "s": {"y": 314, "x": 597, "u": "https://preview.redd.it/3vjp0t4yzzga1.png?width=597&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=56fdd37c413af378ff444bf929ec79ae4b82a15e"}, "id": "3vjp0t4yzzga1"}}, "name": "t3_10x4ziw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jjOq3MTN5HCfwKGJUv9kmQ76JpDyh4yQUvrsNaC3M0o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675876590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3vjp0t4yzzga1.png?width=597&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=56fdd37c413af378ff444bf929ec79ae4b82a15e\"&gt;Read Raster Data From Postgis Using Python&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://spatial-dev.guru/2023/02/04/read-raster-data-from-postgis-using-python/\"&gt;Read Raster Data From Postgis Using Python&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10x4ziw", "is_robot_indexable": true, "report_reasons": null, "author": "iamgeoknight", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x4ziw/read_raster_data_from_postgis_using_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10x4ziw/read_raster_data_from_postgis_using_python/", "subreddit_subscribers": 88894, "created_utc": 1675876590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_24uok5oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Aiven for Apache Flink\u00ae is now generally available: Fully managed Flink service based on Apache Flink SQL for streaming analytics.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10x1tv7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9qABl1S31MOQdNEuC1y7qVoI-FQNCRza8_Q1Hm95flA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675871589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "aiven.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://aiven.io/blog/aiven-for-apache-flink-generally-available?utm_source=reddit&amp;utm_medium=organic&amp;utm_campaign=flink_ga_global_2023", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pw7Fj8LkMjK_gwp3JzEEL5bvDqgpb8HrnaPYrIYICeE.jpg?auto=webp&amp;v=enabled&amp;s=3f64eb5d8e2f34aa04e1c2827d0db4670c16c475", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/pw7Fj8LkMjK_gwp3JzEEL5bvDqgpb8HrnaPYrIYICeE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b46c2ab71d7fa2007988845a31fcba4b2eeb5b01", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/pw7Fj8LkMjK_gwp3JzEEL5bvDqgpb8HrnaPYrIYICeE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f040d331c665548e54d1b8fb20808598b59b7bb", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/pw7Fj8LkMjK_gwp3JzEEL5bvDqgpb8HrnaPYrIYICeE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bde21d9e887d8d876bd5868f354fc024d018c06a", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/pw7Fj8LkMjK_gwp3JzEEL5bvDqgpb8HrnaPYrIYICeE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3f70d37f934d7989f8a21db72fab48dc202f309", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/pw7Fj8LkMjK_gwp3JzEEL5bvDqgpb8HrnaPYrIYICeE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=685454fe51c531c367b5694b3627b35f29c5258a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/pw7Fj8LkMjK_gwp3JzEEL5bvDqgpb8HrnaPYrIYICeE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7061bdbe24bd398640da874e532c2a83b4c41ea7", "width": 1080, "height": 567}], "variants": {}, "id": "Om_AQH4XaUhBqYdtXQKH3HciWr7jcDjhzNNwogvuxwY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10x1tv7", "is_robot_indexable": true, "report_reasons": null, "author": "Marksfik", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10x1tv7/aiven_for_apache_flink_is_now_generally_available/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://aiven.io/blog/aiven-for-apache-flink-generally-available?utm_source=reddit&amp;utm_medium=organic&amp;utm_campaign=flink_ga_global_2023", "subreddit_subscribers": 88894, "created_utc": 1675871589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm in finance, there's hundreds of data providers, and so many of them provide flat files, databases, or api's to share their data, however it arrives at all different times, and I'm wondering where do people put metadata about the data they purchase / subscribe to? \n\nLet's say I buy data from MSCI, they're an index data provider, if they provide me with file X and it's contractually obligated to arrive at 3:01am every day, but they also provide file Y which arrives at 1:10am, where do you stash this information inside of your organization? Like are you using Amundsen for this? Seems very specific, but thought someone might have the same problem as me out there.", "author_fullname": "t2_116kc1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How you manage metadata about data you purchase / subscribe to?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wu15i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675854789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in finance, there&amp;#39;s hundreds of data providers, and so many of them provide flat files, databases, or api&amp;#39;s to share their data, however it arrives at all different times, and I&amp;#39;m wondering where do people put metadata about the data they purchase / subscribe to? &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I buy data from MSCI, they&amp;#39;re an index data provider, if they provide me with file X and it&amp;#39;s contractually obligated to arrive at 3:01am every day, but they also provide file Y which arrives at 1:10am, where do you stash this information inside of your organization? Like are you using Amundsen for this? Seems very specific, but thought someone might have the same problem as me out there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10wu15i", "is_robot_indexable": true, "report_reasons": null, "author": "daeisfresh", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wu15i/how_you_manage_metadata_about_data_you_purchase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wu15i/how_you_manage_metadata_about_data_you_purchase/", "subreddit_subscribers": 88894, "created_utc": 1675854789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cf7te0cf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dockerizing Spark Structured Streaming with Kafka And LocalStack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": false, "name": "t3_10wqx10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/o51ygZzFQacPN3B01RutOsoFr5Z84WEQrr7K4CH2UVw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675842832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/riskified-technology/dockerizing-spark-structured-streaming-with-kafka-and-localstack-5409a34e1dfc", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?auto=webp&amp;v=enabled&amp;s=da2dbd6392b12da27c0b1c6780b3a2a77999acdd", "width": 1200, "height": 637}, "resolutions": [{"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f42a70f7cba57379720b0c9a917bfcab1ebfd89e", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ad3643ca336979d0c228194569bf8b6a5bef82a", "width": 216, "height": 114}, {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=828969329c950b28949159c6e8ec505263ca5fe1", "width": 320, "height": 169}, {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ec44953d372b3898ac188ce6b4f3af4635b0259", "width": 640, "height": 339}, {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46171e3653da657fd4c995a092fb99f561743ec0", "width": 960, "height": 509}, {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=836ccab8dae16c480f207af7ce8ea202124e37e7", "width": 1080, "height": 573}], "variants": {}, "id": "XbYMa6xB0_zYWuc7QraYxrT74UnWf2pivt68uGK0ZrM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10wqx10", "is_robot_indexable": true, "report_reasons": null, "author": "ori___tal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wqx10/dockerizing_spark_structured_streaming_with_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/riskified-technology/dockerizing-spark-structured-streaming-with-kafka-and-localstack-5409a34e1dfc", "subreddit_subscribers": 88894, "created_utc": 1675842832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI have been working as a DE for around 3 years, I mostly work on integrations, centralized Data marts, event-driven pipelines, and some streaming pipelines ( &lt; TB/day). Currently working on building a monitoring framework (Heavily 3rd party patched up, Databricks, Snowflake Logs, External Libraries for Data shift etc)\n\nI want to work towards more Data Engineering System Design roles. I have a Masters, if that matters.\n\nI want to work for a Snowflake, Databricks,  Segment, Mixpanel instead of just using these at work.\n\nHere is what I want to work towards within next year.\n\nAny suggestions on how I can work my way towards these roles will be helpful. I am willing to explore lower-hanging fruit like Azure/LinkedIn (Integrations) / AWS :( if that leads me to land more system design focussed roles later.  I am also open to Startups Airbyte, Amplitude etc, but they must be willing to hire me based on my current experience.\n\nHow can I work towards getting these pre-requisites??\n\n&amp;#x200B;\n\n1. *Query Optimization* : **Pre-requisite:** Significant background in database internals or building core components (query language, query compilation, query execution, storage engines, transaction processing) for large-scale data processing systems (e.g. Hadoop, Spark, Presto, etc.)\n2. *Core Distributed System*: **Pre-requisite:** 3+ years of experience in distributed systems and multi-threaded code\n3. *Database Connectors*: **Pre-requisites:** Building these connectors will require you to go deep into each database and understand its approach to write-ahead logging and information schema management.\n4. *Profiling and Tuning at scale*:   **Pre-requisites:** Experience in profiling and optimizing high performance applications", "author_fullname": "t2_h9t47ksa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer --&gt; Distributed Systems (Data Engineering)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wfqvn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675810155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I have been working as a DE for around 3 years, I mostly work on integrations, centralized Data marts, event-driven pipelines, and some streaming pipelines ( &amp;lt; TB/day). Currently working on building a monitoring framework (Heavily 3rd party patched up, Databricks, Snowflake Logs, External Libraries for Data shift etc)&lt;/p&gt;\n\n&lt;p&gt;I want to work towards more Data Engineering System Design roles. I have a Masters, if that matters.&lt;/p&gt;\n\n&lt;p&gt;I want to work for a Snowflake, Databricks,  Segment, Mixpanel instead of just using these at work.&lt;/p&gt;\n\n&lt;p&gt;Here is what I want to work towards within next year.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions on how I can work my way towards these roles will be helpful. I am willing to explore lower-hanging fruit like Azure/LinkedIn (Integrations) / AWS :( if that leads me to land more system design focussed roles later.  I am also open to Startups Airbyte, Amplitude etc, but they must be willing to hire me based on my current experience.&lt;/p&gt;\n\n&lt;p&gt;How can I work towards getting these pre-requisites??&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;em&gt;Query Optimization&lt;/em&gt; : &lt;strong&gt;Pre-requisite:&lt;/strong&gt; Significant background in database internals or building core components (query language, query compilation, query execution, storage engines, transaction processing) for large-scale data processing systems (e.g. Hadoop, Spark, Presto, etc.)&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Core Distributed System&lt;/em&gt;: &lt;strong&gt;Pre-requisite:&lt;/strong&gt; 3+ years of experience in distributed systems and multi-threaded code&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Database Connectors&lt;/em&gt;: &lt;strong&gt;Pre-requisites:&lt;/strong&gt; Building these connectors will require you to go deep into each database and understand its approach to write-ahead logging and information schema management.&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Profiling and Tuning at scale&lt;/em&gt;:   &lt;strong&gt;Pre-requisites:&lt;/strong&gt; Experience in profiling and optimizing high performance applications&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10wfqvn", "is_robot_indexable": true, "report_reasons": null, "author": "Mother_Importance956", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wfqvn/data_engineer_distributed_systems_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wfqvn/data_engineer_distributed_systems_data_engineering/", "subreddit_subscribers": 88894, "created_utc": 1675810155.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}