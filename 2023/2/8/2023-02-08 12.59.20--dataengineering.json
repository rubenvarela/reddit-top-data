{"kind": "Listing", "data": {"after": "t3_10vzi9w", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When we have moved to data lakes and data lake house based architecture, why should I care about an OLAP DB? At this point in the data eco system?\n\nI seem to have missed the memo on this one lol", "author_fullname": "t2_8r6amwln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the hype around duckDB that I don\u2019t seem to understand?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wd2e0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675803783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When we have moved to data lakes and data lake house based architecture, why should I care about an OLAP DB? At this point in the data eco system?&lt;/p&gt;\n\n&lt;p&gt;I seem to have missed the memo on this one lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10wd2e0", "is_robot_indexable": true, "report_reasons": null, "author": "money_noob_007", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wd2e0/what_is_the_hype_around_duckdb_that_i_dont_seem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wd2e0/what_is_the_hype_around_duckdb_that_i_dont_seem/", "subreddit_subscribers": 88850, "created_utc": 1675803783.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_56wplwbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leetcode for Spark and PySpark at Zillacode.com", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "name": "t3_10wcbp7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ao4w9JGVdp2rI7G1xb6NkdN7OlJNnc_BPwj9OXAfCkE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675802047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/h3tyyo81utga1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/h3tyyo81utga1.png?auto=webp&amp;v=enabled&amp;s=9f7ae19bd2829bb8df24ae5038eff8174126749b", "width": 1910, "height": 993}, "resolutions": [{"url": "https://preview.redd.it/h3tyyo81utga1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5acca28af069631bd9eb329ea2ce6eb59725c987", "width": 108, "height": 56}, {"url": "https://preview.redd.it/h3tyyo81utga1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82790f88d488c87e571a5d472ebcff9896b43ac2", "width": 216, "height": 112}, {"url": "https://preview.redd.it/h3tyyo81utga1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6812515f318859e5a3981a9acc32ad3464ebd541", "width": 320, "height": 166}, {"url": "https://preview.redd.it/h3tyyo81utga1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f99f2d3044a940c9bf978972eef94c421ee9e670", "width": 640, "height": 332}, {"url": "https://preview.redd.it/h3tyyo81utga1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7537395a8412a0bd18acf625d61ab359bc53f9e", "width": 960, "height": 499}, {"url": "https://preview.redd.it/h3tyyo81utga1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e8fc48c7d60b7eeb508e8ffd9bfb20acc0001cc1", "width": 1080, "height": 561}], "variants": {}, "id": "zsyHuvSkKoisFm-ANFVa3Ouz7LC-86kghjkF5Iq9QtQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10wcbp7", "is_robot_indexable": true, "report_reasons": null, "author": "dmage5000", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wcbp7/leetcode_for_spark_and_pyspark_at_zillacodecom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/h3tyyo81utga1.png", "subreddit_subscribers": 88850, "created_utc": 1675802047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(**Disclaimer**:  I'm not a data engineer and my impression may  be far away fro truth.  You can laugh at me, and please also give constructive answers) \n\nData migration, also called data moving, data replication or data integration, involves copying pre-existing data and synching incremental data.  It doesn't involve \"data processing\" per se,  like data aggregations such as \\`count()\\` .  It's the basis for system integration and data pipeline building. \n\n**I think it's underestimated because the community don't talk enough about its best practices**. \n\n* If you read a book about data pipeline, it may be focusing on data processing and be talking about map/reduce, spark, stateful processing etc. \n* If you do data migration as a software engineer,  chances are you may not even notice there is a concept called \"data pipeline\" and you just implement everything manually.  For example, my previous company implemented pre-existing one-time data migration using some Java code, and implemented data sync using another piece of code.  We didn't know that there is stream-based solution that can do both. \n\n**In short, data engineers don't pay much attention about its patterns (best practices), and software engineers don't even realize that there are patterns for it.**  If you try to search a book called \"data migration patterns\", you can't even find one. \n\n**But I think it deserves a book**.  I've joined a few data migration projects, and I think there are a few **common problems** to handle:\n\n* As I mentioned before, how to do pre-existing data  migration and afterwards data sync using a single solution ?   How to limit down time caused by write lock when generation a snapshot?  When to do a cut off? \n* If \"update\" event reaches the consumer before the \"insert\" event, how do you handle it?  Is \"timestamp\" trustable? \n* If you need to sync data in both ways between 2 systems, how do you avoid  infinite loop of data change propagation? \n* What if Order creation event arrives before its Item creation event ? \n* How to handle event consumption errors?  What if dead letter queue is also not reachable?\n* What are the reconciliation tools for you to verify that you migration result is correct? \n* ... \n\nI think you may finally find all the answers by searching, asking and so on.   But **it would be nice if there is a book addressing all these problems in a comprehensive way**. \n\n**Is there such a book**?  If not,  why doesn't anybody write one?", "author_fullname": "t2_10j5re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "May I say \"data migration\" is underestimated and can you recommend me a book about its patterns?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10w76tz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675789963.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(&lt;strong&gt;Disclaimer&lt;/strong&gt;:  I&amp;#39;m not a data engineer and my impression may  be far away fro truth.  You can laugh at me, and please also give constructive answers) &lt;/p&gt;\n\n&lt;p&gt;Data migration, also called data moving, data replication or data integration, involves copying pre-existing data and synching incremental data.  It doesn&amp;#39;t involve &amp;quot;data processing&amp;quot; per se,  like data aggregations such as `count()` .  It&amp;#39;s the basis for system integration and data pipeline building. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I think it&amp;#39;s underestimated because the community don&amp;#39;t talk enough about its best practices&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;If you read a book about data pipeline, it may be focusing on data processing and be talking about map/reduce, spark, stateful processing etc. &lt;/li&gt;\n&lt;li&gt;If you do data migration as a software engineer,  chances are you may not even notice there is a concept called &amp;quot;data pipeline&amp;quot; and you just implement everything manually.  For example, my previous company implemented pre-existing one-time data migration using some Java code, and implemented data sync using another piece of code.  We didn&amp;#39;t know that there is stream-based solution that can do both. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;In short, data engineers don&amp;#39;t pay much attention about its patterns (best practices), and software engineers don&amp;#39;t even realize that there are patterns for it.&lt;/strong&gt;  If you try to search a book called &amp;quot;data migration patterns&amp;quot;, you can&amp;#39;t even find one. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;But I think it deserves a book&lt;/strong&gt;.  I&amp;#39;ve joined a few data migration projects, and I think there are a few &lt;strong&gt;common problems&lt;/strong&gt; to handle:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;As I mentioned before, how to do pre-existing data  migration and afterwards data sync using a single solution ?   How to limit down time caused by write lock when generation a snapshot?  When to do a cut off? &lt;/li&gt;\n&lt;li&gt;If &amp;quot;update&amp;quot; event reaches the consumer before the &amp;quot;insert&amp;quot; event, how do you handle it?  Is &amp;quot;timestamp&amp;quot; trustable? &lt;/li&gt;\n&lt;li&gt;If you need to sync data in both ways between 2 systems, how do you avoid  infinite loop of data change propagation? &lt;/li&gt;\n&lt;li&gt;What if Order creation event arrives before its Item creation event ? &lt;/li&gt;\n&lt;li&gt;How to handle event consumption errors?  What if dead letter queue is also not reachable?&lt;/li&gt;\n&lt;li&gt;What are the reconciliation tools for you to verify that you migration result is correct? &lt;/li&gt;\n&lt;li&gt;... &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I think you may finally find all the answers by searching, asking and so on.   But &lt;strong&gt;it would be nice if there is a book addressing all these problems in a comprehensive way&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is there such a book&lt;/strong&gt;?  If not,  why doesn&amp;#39;t anybody write one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10w76tz", "is_robot_indexable": true, "report_reasons": null, "author": "shaunyip", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10w76tz/may_i_say_data_migration_is_underestimated_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10w76tz/may_i_say_data_migration_is_underestimated_and/", "subreddit_subscribers": 88850, "created_utc": 1675789963.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I personally don't like that there are so many career related questions in this sub recently. Specifically, because these questions often confuse having a title with having an interesting job as an endgoal. However, wo am I to decide over the content of the sub? So, here I am and have such a question:\n\nWould you consider becoming a pure Azure dev that basically manages the data infrastructure solely by the means of Azure a lateral move onto an inescapable Azure path from a kind of ETL-developer role that was hard coding *everything*?\n\nI don't have any hands-on experience with cloud technology, so you could argue that it could serve me as an accelerator to becoming a good data engineer in the long run (/next job) and also open me up to cloud heavy jobs and devops opportunities. However, I fear to lose contact to scripting (or software engineering to be precise) and hence won't be considered for code heavy roles in the future anymore. Particularly, because I only have little more than one year of work experience.", "author_fullname": "t2_uktyi3l0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is setting up infrastructure completely on Azure a dead end?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10w2fg3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675779593.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675778163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I personally don&amp;#39;t like that there are so many career related questions in this sub recently. Specifically, because these questions often confuse having a title with having an interesting job as an endgoal. However, wo am I to decide over the content of the sub? So, here I am and have such a question:&lt;/p&gt;\n\n&lt;p&gt;Would you consider becoming a pure Azure dev that basically manages the data infrastructure solely by the means of Azure a lateral move onto an inescapable Azure path from a kind of ETL-developer role that was hard coding &lt;em&gt;everything&lt;/em&gt;?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have any hands-on experience with cloud technology, so you could argue that it could serve me as an accelerator to becoming a good data engineer in the long run (/next job) and also open me up to cloud heavy jobs and devops opportunities. However, I fear to lose contact to scripting (or software engineering to be precise) and hence won&amp;#39;t be considered for code heavy roles in the future anymore. Particularly, because I only have little more than one year of work experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10w2fg3", "is_robot_indexable": true, "report_reasons": null, "author": "Sensitive_Doctor_796", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10w2fg3/is_setting_up_infrastructure_completely_on_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10w2fg3/is_setting_up_infrastructure_completely_on_azure/", "subreddit_subscribers": 88850, "created_utc": 1675778163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I understand (or at least I think so) role of surrogate keys on dimensional tables, however, not really sure about usefulness of surrogate keys on fact tables. \nDoes it make sense to use surrogate keys on fact tables? Why yes/no?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Surrogate keys on fact tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wbtdj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675800853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand (or at least I think so) role of surrogate keys on dimensional tables, however, not really sure about usefulness of surrogate keys on fact tables. \nDoes it make sense to use surrogate keys on fact tables? Why yes/no?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10wbtdj", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wbtdj/surrogate_keys_on_fact_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wbtdj/surrogate_keys_on_fact_tables/", "subreddit_subscribers": 88850, "created_utc": 1675800853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, through repeated experiences of varying success when working with inhouse backend teams and them applying changes to the application, I was wondering how others have solved that problem?\n\nIt always took a frustrating amount of talking and pleading, to make CPOs, CTOs and Backend Leads understand that what they're doing has downstream effects and while a semi-automated alerting was the outcome in several projects, I was never able to find a satisfying technological solution to the issue. \n\nI'd love to read about other experiences to the issue of changing BE data structures.", "author_fullname": "t2_w2y7e99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle source app changes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10w0i1e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675772576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, through repeated experiences of varying success when working with inhouse backend teams and them applying changes to the application, I was wondering how others have solved that problem?&lt;/p&gt;\n\n&lt;p&gt;It always took a frustrating amount of talking and pleading, to make CPOs, CTOs and Backend Leads understand that what they&amp;#39;re doing has downstream effects and while a semi-automated alerting was the outcome in several projects, I was never able to find a satisfying technological solution to the issue. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to read about other experiences to the issue of changing BE data structures.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10w0i1e", "is_robot_indexable": true, "report_reasons": null, "author": "whichalps", "discussion_type": null, "num_comments": 12, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10w0i1e/how_do_you_handle_source_app_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10w0i1e/how_do_you_handle_source_app_changes/", "subreddit_subscribers": 88850, "created_utc": 1675772576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Comment any particular likes/dislikes\n\n[View Poll](https://www.reddit.com/poll/10wblmw)", "author_fullname": "t2_kdj5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What cloud platform does your company primarily use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wblmw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675800344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Comment any particular likes/dislikes&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10wblmw\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10wblmw", "is_robot_indexable": true, "report_reasons": null, "author": "Touvejs", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1675973144854, "options": [{"text": "AWS", "id": "21483635"}, {"text": "GCP", "id": "21483636"}, {"text": "Azure", "id": "21483637"}, {"text": "Other (e.g. IBM, Alibaba Cloud, Oracle)", "id": "21483638"}, {"text": "Don't use any cloud platforms", "id": "21483639"}, {"text": "See results", "id": "21483640"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 497, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wblmw/what_cloud_platform_does_your_company_primarily/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10wblmw/what_cloud_platform_does_your_company_primarily/", "subreddit_subscribers": 88850, "created_utc": 1675800344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First, I would like to thank this sub for providing good book recommendations. Looking to transition from swe. I have started off with Fundamentals of Data Engineering (Reis &amp; Housley) and it has been fantastic so far! \n\nCall me superfluous, but I have went ahead and purchased 3 other recommendations from this sub and I would love to know what order everyone would recommend I proceed. I thought of a few different orders but thought it would be best just to ask. The list is as follows:\n\n- Designing Data Intensive Applications (Kleppmann)\n\n- Data Pipelines Pocket Reference (Densmore)\n\n- The Data Warehouse Toolkit (Kimball &amp; Ross)\n\nTL;DR: Please, order the above books in such a way you would recommend best for a beginner.", "author_fullname": "t2_13rmpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book Order for Beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10w8kb1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "287cf772-ac9d-11eb-aa84-0ead36cb44af", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675793148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First, I would like to thank this sub for providing good book recommendations. Looking to transition from swe. I have started off with Fundamentals of Data Engineering (Reis &amp;amp; Housley) and it has been fantastic so far! &lt;/p&gt;\n\n&lt;p&gt;Call me superfluous, but I have went ahead and purchased 3 other recommendations from this sub and I would love to know what order everyone would recommend I proceed. I thought of a few different orders but thought it would be best just to ask. The list is as follows:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Designing Data Intensive Applications (Kleppmann)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data Pipelines Pocket Reference (Densmore)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The Data Warehouse Toolkit (Kimball &amp;amp; Ross)&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;TL;DR: Please, order the above books in such a way you would recommend best for a beginner.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Software Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10w8kb1", "is_robot_indexable": true, "report_reasons": null, "author": "OVOtoonami", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10w8kb1/book_order_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10w8kb1/book_order_for_beginners/", "subreddit_subscribers": 88850, "created_utc": 1675793148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!  \n\n\nThis is a DBT-related question.\n\nI'm searching for a solution that can help me clean up my warehouse of old and deprecated models automatically.\n\nMy challenge is that I'm using custom schemas in my deployment environment, which means that mart models are deployed their own schemas and staging data into a staging schema. I want the cleaning to be done every schema.\n\nI stumbled upon this one: [https://discourse.getdbt.com/t/clean-your-warehouse-of-old-and-deprecated-models/1547/1](https://discourse.getdbt.com/t/clean-your-warehouse-of-old-and-deprecated-models/1547/1)  \n\n\n... but the suggested macro(s) can not solve the challenge with custom schemas  \n\n\nDoes anyone of you have a solution for cleaning up a warehouse with DBT custom schemas? \ud83d\ude47\u200d\u2642\ufe0f", "author_fullname": "t2_oeiyrmpr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT: Clean your warehouse of old and deprecated models featuring custom schemas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wrlve", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675845421.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!  &lt;/p&gt;\n\n&lt;p&gt;This is a DBT-related question.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m searching for a solution that can help me clean up my warehouse of old and deprecated models automatically.&lt;/p&gt;\n\n&lt;p&gt;My challenge is that I&amp;#39;m using custom schemas in my deployment environment, which means that mart models are deployed their own schemas and staging data into a staging schema. I want the cleaning to be done every schema.&lt;/p&gt;\n\n&lt;p&gt;I stumbled upon this one: &lt;a href=\"https://discourse.getdbt.com/t/clean-your-warehouse-of-old-and-deprecated-models/1547/1\"&gt;https://discourse.getdbt.com/t/clean-your-warehouse-of-old-and-deprecated-models/1547/1&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;... but the suggested macro(s) can not solve the challenge with custom schemas  &lt;/p&gt;\n\n&lt;p&gt;Does anyone of you have a solution for cleaning up a warehouse with DBT custom schemas? \ud83d\ude47\u200d\u2642\ufe0f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?auto=webp&amp;v=enabled&amp;s=d4169652ab7f36209622ee244f310aefe0cf8ce2", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd185c71f8fd75a33c0c79555ab7aa66ff94f024", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10e2c53de9b2969366504c9ded514bbe1e2eb4d1", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7634b43f18facd6b7a0eaa901c2b135c2c9f47cf", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=487560d27ca62339efe41270d29a0644753c4362", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43637abd63f6c913d8d643f155a22cfee21ab4eb", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/PJCj8tgzdxpdMf_mbE9zWO1dQfyK3Jf3irVTvz8-RF0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7eff2686e5c425ddf4ad53b33e6ccec820db7c7", "width": 1080, "height": 567}], "variants": {}, "id": "7Z_t_HsXt2-BEolo1xeZUv0TRH4nZTtHHcogXhY8TFI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10wrlve", "is_robot_indexable": true, "report_reasons": null, "author": "formaldehyden", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wrlve/dbt_clean_your_warehouse_of_old_and_deprecated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wrlve/dbt_clean_your_warehouse_of_old_and_deprecated/", "subreddit_subscribers": 88850, "created_utc": 1675845421.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi.  I am looking for resources that show how to effectively utilize dask within python.  Books with the recipe approach are ideal.  Or if you can point me at some open GitHub repos that used dask that would be great.  I am specifically looking for ones that use a cluster.\n\nThanks", "author_fullname": "t2_l04by", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dask Recipes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10whjin", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675814646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.  I am looking for resources that show how to effectively utilize dask within python.  Books with the recipe approach are ideal.  Or if you can point me at some open GitHub repos that used dask that would be great.  I am specifically looking for ones that use a cluster.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10whjin", "is_robot_indexable": true, "report_reasons": null, "author": "kentmaxwell", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10whjin/dask_recipes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10whjin/dask_recipes/", "subreddit_subscribers": 88850, "created_utc": 1675814646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's a realistic cost estimate for earning this cert? I'd like to get a good amount of hands on practice with the tools while studying for it. I'm assuming AWS Free Tier is not sufficient.", "author_fullname": "t2_4i8pl31g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost of AWS Certified Big Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wbaz7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675799643.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s a realistic cost estimate for earning this cert? I&amp;#39;d like to get a good amount of hands on practice with the tools while studying for it. I&amp;#39;m assuming AWS Free Tier is not sufficient.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10wbaz7", "is_robot_indexable": true, "report_reasons": null, "author": "knowledgebass", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wbaz7/cost_of_aws_certified_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wbaz7/cost_of_aws_certified_big_data/", "subreddit_subscribers": 88850, "created_utc": 1675799643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working for the past 3 yrs with a local consulting firm. They assign us to projects for their clients. Most of these projects are on premise with tools like Informatica, SSIS, MSSQLServer, Tidal etc. I am pretty well versed in these. But I am now looking for a new job and it seems like everyone is constantly looking for a candidate who knows ALL cloud platforms. No recruiters are interested further because I have no cloud experience. I have the AWS cloud practitioner certificate and I have begun to watch and read documentation for working in Azure. But since I have not worked with it in a professional capacity, I'm not landing any new jobs.\n\nAny tips on how to overcome this slump? Just more certifications? Thanks in advance", "author_fullname": "t2_ej6rfpuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I upskill myself to get a new job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10w8z7h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675794114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working for the past 3 yrs with a local consulting firm. They assign us to projects for their clients. Most of these projects are on premise with tools like Informatica, SSIS, MSSQLServer, Tidal etc. I am pretty well versed in these. But I am now looking for a new job and it seems like everyone is constantly looking for a candidate who knows ALL cloud platforms. No recruiters are interested further because I have no cloud experience. I have the AWS cloud practitioner certificate and I have begun to watch and read documentation for working in Azure. But since I have not worked with it in a professional capacity, I&amp;#39;m not landing any new jobs.&lt;/p&gt;\n\n&lt;p&gt;Any tips on how to overcome this slump? Just more certifications? Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10w8z7h", "is_robot_indexable": true, "report_reasons": null, "author": "AppointmentFit5600", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10w8z7h/how_do_i_upskill_myself_to_get_a_new_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10w8z7h/how_do_i_upskill_myself_to_get_a_new_job/", "subreddit_subscribers": 88850, "created_utc": 1675794114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team uses data vault modeling to arrange source data into hubs/satellites/links from which we build traditional dim/fact tables for our users. We get a number of satellites for different entities that end up representing the same thing. For example, address data shared across three separate entities. Should satellite tables ever be shared? Or should there be three separate satellite tables corresponding to address data?", "author_fullname": "t2_5e0ue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Vault modeling question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10w6wtw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675789308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team uses data vault modeling to arrange source data into hubs/satellites/links from which we build traditional dim/fact tables for our users. We get a number of satellites for different entities that end up representing the same thing. For example, address data shared across three separate entities. Should satellite tables ever be shared? Or should there be three separate satellite tables corresponding to address data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10w6wtw", "is_robot_indexable": true, "report_reasons": null, "author": "harrytrumanprimate", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10w6wtw/data_vault_modeling_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10w6wtw/data_vault_modeling_question/", "subreddit_subscribers": 88850, "created_utc": 1675789308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nRelatively new to the DE field, and I've been handed a confidential .txt file to troubleshoot. It's missing data needed for the portal we upload it to, so I'm hoping to add it in.   \n\n\nIt looks like the first row has one set of fixed-width length requirements, row 2 has another set of character length requirements, and rows 3 &amp; 4 each have their own length requirements, with every pair after that repeating.  \n\n\nAny advice? I'm trying to open it in Excel, but right now my mindset is:\n\n1. Manually separate the data based on what fixed-width requirements it has\n2. Open each in Excel, painstakingly set the fixed-width requirements to match what the portal is requesting\n3. See what's missing, and try to add the missing field (I know of one, just not where it needs to go)\n4. Then combine all data files back into one .txt file again\n\nSeems tedious as hell...I'm a complete noob; is there a more spreamlined or even programmatic way to go about this? This is one of my first big assignments at work, and I'm hoping to solve the problem for them.\n\nThanks in advance!", "author_fullname": "t2_zhui6d5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help with fixed-width txt file I'm struggling with", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10w6trg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675789129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Relatively new to the DE field, and I&amp;#39;ve been handed a confidential .txt file to troubleshoot. It&amp;#39;s missing data needed for the portal we upload it to, so I&amp;#39;m hoping to add it in.   &lt;/p&gt;\n\n&lt;p&gt;It looks like the first row has one set of fixed-width length requirements, row 2 has another set of character length requirements, and rows 3 &amp;amp; 4 each have their own length requirements, with every pair after that repeating.  &lt;/p&gt;\n\n&lt;p&gt;Any advice? I&amp;#39;m trying to open it in Excel, but right now my mindset is:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Manually separate the data based on what fixed-width requirements it has&lt;/li&gt;\n&lt;li&gt;Open each in Excel, painstakingly set the fixed-width requirements to match what the portal is requesting&lt;/li&gt;\n&lt;li&gt;See what&amp;#39;s missing, and try to add the missing field (I know of one, just not where it needs to go)&lt;/li&gt;\n&lt;li&gt;Then combine all data files back into one .txt file again&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Seems tedious as hell...I&amp;#39;m a complete noob; is there a more spreamlined or even programmatic way to go about this? This is one of my first big assignments at work, and I&amp;#39;m hoping to solve the problem for them.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10w6trg", "is_robot_indexable": true, "report_reasons": null, "author": "Savagecvnt", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10w6trg/help_with_fixedwidth_txt_file_im_struggling_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10w6trg/help_with_fixedwidth_txt_file_im_struggling_with/", "subreddit_subscribers": 88850, "created_utc": 1675789129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A deep dive on the cost/performance impact of driver sizing in Databricks with the TPC-DS 1TB benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_10w4dsm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JDL8QyvkYZ4wWFWR55z84yQr2UO1GlMY5xWjOpLTTTY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675783175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/sync-computing/databricks-driver-sizing-impact-on-cost-and-performance-3b93aa2e3b9a", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dav6aLUhAa77nUEMDUjXwiQXs-Vxuv1n8dcbFu5sc5Q.jpg?auto=webp&amp;v=enabled&amp;s=f3f409125e3c06bdcbd3f33be8b19dee2c02a8ad", "width": 1200, "height": 799}, "resolutions": [{"url": "https://external-preview.redd.it/dav6aLUhAa77nUEMDUjXwiQXs-Vxuv1n8dcbFu5sc5Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cd05e3a96b065db5873da1939a5e748b1da4e2a0", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/dav6aLUhAa77nUEMDUjXwiQXs-Vxuv1n8dcbFu5sc5Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=921a7787bee542fa32ac250caf1ec7b978ccc8f5", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/dav6aLUhAa77nUEMDUjXwiQXs-Vxuv1n8dcbFu5sc5Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e9ee1dc95ef59b67e1d762d8d48d7fc23c8e767", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/dav6aLUhAa77nUEMDUjXwiQXs-Vxuv1n8dcbFu5sc5Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e214cf63cd0f1f5adbbc0ec5085a4e05059a5757", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/dav6aLUhAa77nUEMDUjXwiQXs-Vxuv1n8dcbFu5sc5Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83eb138c3a702bfa9240edbd11e80407cff6bda0", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/dav6aLUhAa77nUEMDUjXwiQXs-Vxuv1n8dcbFu5sc5Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58e97a02a85f2ef3e98b37bb7910aac368a659fe", "width": 1080, "height": 719}], "variants": {}, "id": "mvEKM_OGy5Q350p3hPKKhlpJeSBVmpAY1tZocF_s41M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10w4dsm", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10w4dsm/a_deep_dive_on_the_costperformance_impact_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/sync-computing/databricks-driver-sizing-impact-on-cost-and-performance-3b93aa2e3b9a", "subreddit_subscribers": 88850, "created_utc": 1675783175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello\n\nI'm running some experiments to deploy Apache Superset on Kubernetes (GCP). I have some difficulties on sizing my clusters and estimating the costs. Can you share some of your experiences regarding the subject ?  \n\n\nThanks in advance", "author_fullname": "t2_98269xyy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploying Apache Superset on GKE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10vzxbp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675770593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m running some experiments to deploy Apache Superset on Kubernetes (GCP). I have some difficulties on sizing my clusters and estimating the costs. Can you share some of your experiences regarding the subject ?  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10vzxbp", "is_robot_indexable": true, "report_reasons": null, "author": "Electronic-Mountain9", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10vzxbp/deploying_apache_superset_on_gke/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10vzxbp/deploying_apache_superset_on_gke/", "subreddit_subscribers": 88850, "created_utc": 1675770593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resolving Late Arriving Dimensions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10vzpjd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LgSBr3SZ8ioj2TjZtOZtBDZlaN_Oxw7B1pFAbtF_rBE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675769795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/dataseries/resolving-late-arriving-dimensions-c0ebc9f818c3", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RcOclc9_YanKWuAv1unaRoNvYI2F8ylFSihm_5vRWFY.jpg?auto=webp&amp;v=enabled&amp;s=745aa70329f3d259d0db87ef40fb08e578d8a563", "width": 284, "height": 284}, "resolutions": [{"url": "https://external-preview.redd.it/RcOclc9_YanKWuAv1unaRoNvYI2F8ylFSihm_5vRWFY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb100d02c742d280cd0240778ed42850486b56e3", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/RcOclc9_YanKWuAv1unaRoNvYI2F8ylFSihm_5vRWFY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b583598c6a806f5ba42dd0b012a9b4c5d651db7", "width": 216, "height": 216}], "variants": {}, "id": "gt0r6DUbr0VcooIwWMNSHy2xrWW6deLxcQgo-9BgBz0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10vzpjd", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10vzpjd/resolving_late_arriving_dimensions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/dataseries/resolving-late-arriving-dimensions-c0ebc9f818c3", "subreddit_subscribers": 88850, "created_utc": 1675769795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dpzgk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction to Machine Learning and Unsupervised Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_10wsa3t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LpES66N1GG5xOeA7VO7FK9S7T_Ovl-xfNPIOQIA6uFA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675848122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "eventbrite.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.eventbrite.com/e/introduction-to-machine-learning-and-unsupervised-learning-tickets-538397841437?aff=Reddit", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Qak-VzPl3pH3EVpDo9Y7R_-ZQUV6_IfJT9_Y15SRwew.jpg?auto=webp&amp;v=enabled&amp;s=3521b3a8872ccb4e3650b594045acb25b9c1b476", "width": 1000, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/Qak-VzPl3pH3EVpDo9Y7R_-ZQUV6_IfJT9_Y15SRwew.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=431e15b1876147a732c05f08e09f90fbf71a00ce", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Qak-VzPl3pH3EVpDo9Y7R_-ZQUV6_IfJT9_Y15SRwew.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aeb1b63b858ffa261e313cae5fea867120451f7a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Qak-VzPl3pH3EVpDo9Y7R_-ZQUV6_IfJT9_Y15SRwew.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b06ca80fa61bb15871b9902cfc6820f4e837bfd3", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Qak-VzPl3pH3EVpDo9Y7R_-ZQUV6_IfJT9_Y15SRwew.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60ee323018ac45192095517c6bb863c0d3a3712b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Qak-VzPl3pH3EVpDo9Y7R_-ZQUV6_IfJT9_Y15SRwew.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e28c64118e65c3c1720e49934c733efb3df265a3", "width": 960, "height": 480}], "variants": {}, "id": "aD_PFBXkx2_ToJuG95rMcNwpsNwJrR1W4HkATLQw67k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10wsa3t", "is_robot_indexable": true, "report_reasons": null, "author": "Reginald_Martin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wsa3t/introduction_to_machine_learning_and_unsupervised/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.eventbrite.com/e/introduction-to-machine-learning-and-unsupervised-learning-tickets-538397841437?aff=Reddit", "subreddit_subscribers": 88850, "created_utc": 1675848122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am trying to run ELT jobs using DBT with Databricks as the warehouse.\n\nI have created an incremental model that uses sources and the incremental strategy is set to 'merge'. I have also configured the unique key, but whenever I run the model, only the 'append' activity works where the new values are incrementally added but the updated rows in the source table are not updated in table created when I run this model\n\nCould anyone explain why is this happening?", "author_fullname": "t2_9d4i4lxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I implement incremental models with 'merge' strategy in DBT ( Data Build Tool) using Databricks as the warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wrph1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675845834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am trying to run ELT jobs using DBT with Databricks as the warehouse.&lt;/p&gt;\n\n&lt;p&gt;I have created an incremental model that uses sources and the incremental strategy is set to &amp;#39;merge&amp;#39;. I have also configured the unique key, but whenever I run the model, only the &amp;#39;append&amp;#39; activity works where the new values are incrementally added but the updated rows in the source table are not updated in table created when I run this model&lt;/p&gt;\n\n&lt;p&gt;Could anyone explain why is this happening?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10wrph1", "is_robot_indexable": true, "report_reasons": null, "author": "New_Introduction_154", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wrph1/how_do_i_implement_incremental_models_with_merge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wrph1/how_do_i_implement_incremental_models_with_merge/", "subreddit_subscribers": 88850, "created_utc": 1675845834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cf7te0cf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dockerizing Spark Structured Streaming with Kafka And LocalStack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": false, "name": "t3_10wqx10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/o51ygZzFQacPN3B01RutOsoFr5Z84WEQrr7K4CH2UVw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675842832.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/riskified-technology/dockerizing-spark-structured-streaming-with-kafka-and-localstack-5409a34e1dfc", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?auto=webp&amp;v=enabled&amp;s=da2dbd6392b12da27c0b1c6780b3a2a77999acdd", "width": 1200, "height": 637}, "resolutions": [{"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f42a70f7cba57379720b0c9a917bfcab1ebfd89e", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ad3643ca336979d0c228194569bf8b6a5bef82a", "width": 216, "height": 114}, {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=828969329c950b28949159c6e8ec505263ca5fe1", "width": 320, "height": 169}, {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ec44953d372b3898ac188ce6b4f3af4635b0259", "width": 640, "height": 339}, {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46171e3653da657fd4c995a092fb99f561743ec0", "width": 960, "height": 509}, {"url": "https://external-preview.redd.it/Bq9ubKDy_RRJk6RrqPIf5vYH0znFeLpWyA6aL5feGI8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=836ccab8dae16c480f207af7ce8ea202124e37e7", "width": 1080, "height": 573}], "variants": {}, "id": "XbYMa6xB0_zYWuc7QraYxrT74UnWf2pivt68uGK0ZrM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10wqx10", "is_robot_indexable": true, "report_reasons": null, "author": "ori___tal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wqx10/dockerizing_spark_structured_streaming_with_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/riskified-technology/dockerizing-spark-structured-streaming-with-kafka-and-localstack-5409a34e1dfc", "subreddit_subscribers": 88850, "created_utc": 1675842832.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tested, versioned and robust ELT - building extract &amp; load processes that don't break", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_10w1o0m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kmcE_p2Z81_Q_7-ES2s95tE-Y9Acb1AvUk8-5MZxG1I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675776065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "meltano.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://meltano.com/blog/why-our-el-processes-never-break-tested-versioned-and-robust-elt/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Qpy5HQ-FwLSFdziEc6rbD3Stc-Wgsp1gEIH3jM6QvZM.jpg?auto=webp&amp;v=enabled&amp;s=c8504bcc6a097d996eb206bb20fc65e2acbcf5b2", "width": 1024, "height": 683}, "resolutions": [{"url": "https://external-preview.redd.it/Qpy5HQ-FwLSFdziEc6rbD3Stc-Wgsp1gEIH3jM6QvZM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bfd70046e09c6b7d23e9a166df4dd8ddf46dfd8", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/Qpy5HQ-FwLSFdziEc6rbD3Stc-Wgsp1gEIH3jM6QvZM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2e9fae7e3fe6332e23de3f96355e5195c70644f0", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/Qpy5HQ-FwLSFdziEc6rbD3Stc-Wgsp1gEIH3jM6QvZM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83267278e7a58ace6e532dc2181e2c91e8a05fe7", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/Qpy5HQ-FwLSFdziEc6rbD3Stc-Wgsp1gEIH3jM6QvZM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9befa40d67ef6011f7f934444724b20030247c8", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/Qpy5HQ-FwLSFdziEc6rbD3Stc-Wgsp1gEIH3jM6QvZM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b8e5ef8b3e78c2fe67f8efddac82a6658853c8d", "width": 960, "height": 640}], "variants": {}, "id": "7Z09yx6aSEVdWq6umh2dGNQlNgUiY-9cP6HTecB66rU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10w1o0m", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10w1o0m/tested_versioned_and_robust_elt_building_extract/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://meltano.com/blog/why-our-el-processes-never-break-tested-versioned-and-robust-elt/", "subreddit_subscribers": 88850, "created_utc": 1675776065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_b57xklsy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Article - Configure Kafka for High Throughput", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10wop9z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TW9Zn2PNXtuc17I0JmeSOjVM8HZDLemwhQdCEn_cKr0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675835100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "krishnakrmahto.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://krishnakrmahto.com/configure-kafka-for-high-throughput", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j7XE4FoiZPCNPwLcA_1hLnhen7bJWaBfcTJbQ3RIC_4.jpg?auto=webp&amp;v=enabled&amp;s=35bea2af9143849e7eab9a5837c8816f56bd92d6", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/j7XE4FoiZPCNPwLcA_1hLnhen7bJWaBfcTJbQ3RIC_4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e417bbc221ec700683a83e84920c1ace88267d84", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/j7XE4FoiZPCNPwLcA_1hLnhen7bJWaBfcTJbQ3RIC_4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=131c362479425dade1cbd97d266610b9d2a44676", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/j7XE4FoiZPCNPwLcA_1hLnhen7bJWaBfcTJbQ3RIC_4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d298674417df411eb9f85879a8ad218a6ae7732", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/j7XE4FoiZPCNPwLcA_1hLnhen7bJWaBfcTJbQ3RIC_4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a6d91dfb45ca3b4ea4c7b30dc0c0d43b80abd84", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/j7XE4FoiZPCNPwLcA_1hLnhen7bJWaBfcTJbQ3RIC_4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aaedf37dc72cf340da2bbed9b96d751bf195f8cd", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/j7XE4FoiZPCNPwLcA_1hLnhen7bJWaBfcTJbQ3RIC_4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9be7676361c863b1d2fc8ff25923790133f62bb0", "width": 1080, "height": 567}], "variants": {}, "id": "eXryIAQu9tArUSy_ggdrGMAZBcnzpVDrDJhUeE7_ZxY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10wop9z", "is_robot_indexable": true, "report_reasons": null, "author": "krishnakrmahto", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wop9z/article_configure_kafka_for_high_throughput/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://krishnakrmahto.com/configure-kafka-for-high-throughput", "subreddit_subscribers": 88850, "created_utc": 1675835100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nI have been working as a DE for around 3 years, I mostly work on integrations, centralized Data marts, event-driven pipelines, and some streaming pipelines ( &lt; TB/day). Currently working on building a monitoring framework (Heavily 3rd party patched up, Databricks, Snowflake Logs, External Libraries for Data shift etc)\n\nI want to work towards more Data Engineering System Design roles. I have a Masters, if that matters.\n\nI want to work for a Snowflake, Databricks,  Segment, Mixpanel instead of just using these at work.\n\nHere is what I want to work towards within next year.\n\nAny suggestions on how I can work my way towards these roles will be helpful. I am willing to explore lower-hanging fruit like Azure/LinkedIn (Integrations) / AWS :( if that leads me to land more system design focussed roles later.  I am also open to Startups Airbyte, Amplitude etc, but they must be willing to hire me based on my current experience.\n\nHow can I work towards getting these pre-requisites??\n\n&amp;#x200B;\n\n1. *Query Optimization* : **Pre-requisite:** Significant background in database internals or building core components (query language, query compilation, query execution, storage engines, transaction processing) for large-scale data processing systems (e.g. Hadoop, Spark, Presto, etc.)\n2. *Core Distributed System*: **Pre-requisite:** 3+ years of experience in distributed systems and multi-threaded code\n3. *Database Connectors*: **Pre-requisites:** Building these connectors will require you to go deep into each database and understand its approach to write-ahead logging and information schema management.\n4. *Profiling and Tuning at scale*:   **Pre-requisites:** Experience in profiling and optimizing high performance applications", "author_fullname": "t2_h9t47ksa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer --&gt; Distributed Systems (Data Engineering)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wfqvn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675810155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;I have been working as a DE for around 3 years, I mostly work on integrations, centralized Data marts, event-driven pipelines, and some streaming pipelines ( &amp;lt; TB/day). Currently working on building a monitoring framework (Heavily 3rd party patched up, Databricks, Snowflake Logs, External Libraries for Data shift etc)&lt;/p&gt;\n\n&lt;p&gt;I want to work towards more Data Engineering System Design roles. I have a Masters, if that matters.&lt;/p&gt;\n\n&lt;p&gt;I want to work for a Snowflake, Databricks,  Segment, Mixpanel instead of just using these at work.&lt;/p&gt;\n\n&lt;p&gt;Here is what I want to work towards within next year.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions on how I can work my way towards these roles will be helpful. I am willing to explore lower-hanging fruit like Azure/LinkedIn (Integrations) / AWS :( if that leads me to land more system design focussed roles later.  I am also open to Startups Airbyte, Amplitude etc, but they must be willing to hire me based on my current experience.&lt;/p&gt;\n\n&lt;p&gt;How can I work towards getting these pre-requisites??&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;em&gt;Query Optimization&lt;/em&gt; : &lt;strong&gt;Pre-requisite:&lt;/strong&gt; Significant background in database internals or building core components (query language, query compilation, query execution, storage engines, transaction processing) for large-scale data processing systems (e.g. Hadoop, Spark, Presto, etc.)&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Core Distributed System&lt;/em&gt;: &lt;strong&gt;Pre-requisite:&lt;/strong&gt; 3+ years of experience in distributed systems and multi-threaded code&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Database Connectors&lt;/em&gt;: &lt;strong&gt;Pre-requisites:&lt;/strong&gt; Building these connectors will require you to go deep into each database and understand its approach to write-ahead logging and information schema management.&lt;/li&gt;\n&lt;li&gt;&lt;em&gt;Profiling and Tuning at scale&lt;/em&gt;:   &lt;strong&gt;Pre-requisites:&lt;/strong&gt; Experience in profiling and optimizing high performance applications&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10wfqvn", "is_robot_indexable": true, "report_reasons": null, "author": "Mother_Importance956", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wfqvn/data_engineer_distributed_systems_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wfqvn/data_engineer_distributed_systems_data_engineering/", "subreddit_subscribers": 88850, "created_utc": 1675810155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a multiple dimension cube as a source file. ( Given 4 different unique sources)\n\nI am planning to have a lakehouse ( Dimensional Model) and datawarehouse ( ER model )\n\nWhat's your take on the modelling ?", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When Cubes are source for ETL, do we need to think of re-modelling into star schema or ER Model ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10wdadf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675804303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a multiple dimension cube as a source file. ( Given 4 different unique sources)&lt;/p&gt;\n\n&lt;p&gt;I am planning to have a lakehouse ( Dimensional Model) and datawarehouse ( ER model )&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your take on the modelling ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10wdadf", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10wdadf/when_cubes_are_source_for_etl_do_we_need_to_think/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10wdadf/when_cubes_are_source_for_etl_do_we_need_to_think/", "subreddit_subscribers": 88850, "created_utc": 1675804303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a1z6eog1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How will ChatGPT and generative AI change data analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_10vzi9w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/vU9fbPj5esTI5pGqMiNowEG-HOCKdT8kdXVrpu0g1-8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675769082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "makingmeaning.info", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.makingmeaning.info/post/generative-ai-including-chatgpt-and-data-analytics", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hfeF4-Lw0qoLgNPxrXlOE7pXTGOwOQntIa5MgJ8Ws-4.jpg?auto=webp&amp;v=enabled&amp;s=00559c86d5785301e156792fa7cb94876b8c68ff", "width": 567, "height": 567}, "resolutions": [{"url": "https://external-preview.redd.it/hfeF4-Lw0qoLgNPxrXlOE7pXTGOwOQntIa5MgJ8Ws-4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe651d0284bbcaec948c8e59b7d56a81dbbbdafd", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/hfeF4-Lw0qoLgNPxrXlOE7pXTGOwOQntIa5MgJ8Ws-4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f554022b0fef7f5c4a7b8c96116349ad0960afe0", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/hfeF4-Lw0qoLgNPxrXlOE7pXTGOwOQntIa5MgJ8Ws-4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21eb62063f15dc57e2c996b65fc41d2e502dee8c", "width": 320, "height": 320}], "variants": {}, "id": "sJ-IyBfTW5HCkXlnSgURbyCGaSqGdgq7O5xyuX84DZs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10vzi9w", "is_robot_indexable": true, "report_reasons": null, "author": "DataAnalyticsDude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10vzi9w/how_will_chatgpt_and_generative_ai_change_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.makingmeaning.info/post/generative-ai-including-chatgpt-and-data-analytics", "subreddit_subscribers": 88850, "created_utc": 1675769082.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}