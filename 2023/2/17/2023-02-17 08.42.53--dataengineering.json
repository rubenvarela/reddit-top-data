{"kind": "Listing", "data": {"after": "t3_11401cr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Inspired by this [post](https://www.reddit.com/r/dataengineering/comments/11349lf/is_there_anything_like_kaggle_for_data_engineering/) and this [comment](https://www.reddit.com/r/dataengineering/comments/11349lf/comment/j8spjrg/), would r/dataengineering be interested in a project based competition? (mainly for learning purposes)\n\nTo keep things simple, we could use reddit polls to host it. We can decide on the project (and the winner) using votes.\n\nWe can hash out the details if there's enough interest, but I'd be willing to chip in the first $500 to the winning pot. My personal preference is to donate the winnings but will also defer this decision to a poll.\n\n**Open questions:**\n\n1. What should the scope of the project be? Data Engineering is a very broad field.\n2. Do you see any downside to deciding the project using a reddit poll?\n3. Do you see any downside to deciding the winner using a reddit poll?\n4. How long should the competition run? 4 weeks should be max for building a production-ready project on the side (to account for DEs with full time jobs and give new DEs time to learn)\n\nLet me know what you think :)", "author_fullname": "t2_vri7kka6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Competition!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113x4cb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 82, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 82, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676580212.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676571379.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Inspired by this &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/11349lf/is_there_anything_like_kaggle_for_data_engineering/\"&gt;post&lt;/a&gt; and this &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/11349lf/comment/j8spjrg/\"&gt;comment&lt;/a&gt;, would &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; be interested in a project based competition? (mainly for learning purposes)&lt;/p&gt;\n\n&lt;p&gt;To keep things simple, we could use reddit polls to host it. We can decide on the project (and the winner) using votes.&lt;/p&gt;\n\n&lt;p&gt;We can hash out the details if there&amp;#39;s enough interest, but I&amp;#39;d be willing to chip in the first $500 to the winning pot. My personal preference is to donate the winnings but will also defer this decision to a poll.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Open questions:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What should the scope of the project be? Data Engineering is a very broad field.&lt;/li&gt;\n&lt;li&gt;Do you see any downside to deciding the project using a reddit poll?&lt;/li&gt;\n&lt;li&gt;Do you see any downside to deciding the winner using a reddit poll?&lt;/li&gt;\n&lt;li&gt;How long should the competition run? 4 weeks should be max for building a production-ready project on the side (to account for DEs with full time jobs and give new DEs time to learn)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Let me know what you think :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "113x4cb", "is_robot_indexable": true, "report_reasons": null, "author": "datain30", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113x4cb/data_engineering_competition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113x4cb/data_engineering_competition/", "subreddit_subscribers": 89854, "created_utc": 1676571379.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Price Data is gathered from eBay using a Python web scraper called Beautiful Soup, transformed to remove outliers, and averages of the data are loaded onto a Postgres database. \n\nThe goal of this project is to get a snapshot for the value of used graphics cards (GPUs) today, and at some point in the future, compare how the prices have been fluctuating and how they compare to newer GPUs.\n\nThis entire process is hosted on the cloud through the use of an AWS EC2 instance and AWS RDS for the Postgres database. It runs fully independently on the cloud to automate the process of data extraction, transformation, and loading, every day so that a price history for the Nvidia GPUs can be collected.\n\nOnce enough data has been collected and stored, it can start to give a picture on the price performance of used graphics cards in the (UK) market, especially after the crypto mining boom and crash during and after the COVID-19 pandemic.\n\nThe data is shown on Looker Studio's free service. \n\n**Links:** \n\n[GitHub](https://github.com/sachinlim/ebay_airflow)\n\n[Looker Studio](https://lookerstudio.google.com/u/0/reporting/47f510fa-6d05-4839-a984-9c3f9f790bab/page/tDaFD) \n\nIt is pretty much a flat line right now, as there is not a lot of price movements. However, looking back on a monthly/weekly scale with 12-24 months worth of data, it would paint a very interesting picture.\n\n*** \n\nTo do the project, I used an older eBay script I had made and adapted it for this project. \n\nI think Airflow for a basic task like this is overkill but I got the chance to play around with Airflow (dynamic dag), AWS EC2, RDS (Postgres) and Looker Studio, so it's a win for me, regardless. I was actually surprised that Looker Studio updates every day to show the changes. \n\nAfter seeing an older [Reddit ETL Pipeline](https://www.reddit.com/r/dataengineering/comments/vkfs57/i_created_a_pipeline_extracting_reddit_data_using/) post, there's definitely a lot more ways to improve this. The code I've written is perhaps a bit basic, not sure how scalable the script is, if it's clean, and there's SQL injection possible with the `INSERT` statement, though the function to get the price averages won't run for anything other than numbers.\n\nI'm using an t2.medium instance because the t2.small instance would crash the website, but that was when I was playing around with more GPUs being searched. I was thinking of trying the t2.small instance again but decided to leave it as it is, and look for ways to learn about other services to deploy a pipeline like this, especially a free one so I can keep this project running for people to use, like on /r/HardwareSwapUK.", "author_fullname": "t2_v49pkl1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow Pipeline for eBay Data Extraction - Simple project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113roc9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676557141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Price Data is gathered from eBay using a Python web scraper called Beautiful Soup, transformed to remove outliers, and averages of the data are loaded onto a Postgres database. &lt;/p&gt;\n\n&lt;p&gt;The goal of this project is to get a snapshot for the value of used graphics cards (GPUs) today, and at some point in the future, compare how the prices have been fluctuating and how they compare to newer GPUs.&lt;/p&gt;\n\n&lt;p&gt;This entire process is hosted on the cloud through the use of an AWS EC2 instance and AWS RDS for the Postgres database. It runs fully independently on the cloud to automate the process of data extraction, transformation, and loading, every day so that a price history for the Nvidia GPUs can be collected.&lt;/p&gt;\n\n&lt;p&gt;Once enough data has been collected and stored, it can start to give a picture on the price performance of used graphics cards in the (UK) market, especially after the crypto mining boom and crash during and after the COVID-19 pandemic.&lt;/p&gt;\n\n&lt;p&gt;The data is shown on Looker Studio&amp;#39;s free service. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Links:&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/sachinlim/ebay_airflow\"&gt;GitHub&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://lookerstudio.google.com/u/0/reporting/47f510fa-6d05-4839-a984-9c3f9f790bab/page/tDaFD\"&gt;Looker Studio&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;It is pretty much a flat line right now, as there is not a lot of price movements. However, looking back on a monthly/weekly scale with 12-24 months worth of data, it would paint a very interesting picture.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;To do the project, I used an older eBay script I had made and adapted it for this project. &lt;/p&gt;\n\n&lt;p&gt;I think Airflow for a basic task like this is overkill but I got the chance to play around with Airflow (dynamic dag), AWS EC2, RDS (Postgres) and Looker Studio, so it&amp;#39;s a win for me, regardless. I was actually surprised that Looker Studio updates every day to show the changes. &lt;/p&gt;\n\n&lt;p&gt;After seeing an older &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/vkfs57/i_created_a_pipeline_extracting_reddit_data_using/\"&gt;Reddit ETL Pipeline&lt;/a&gt; post, there&amp;#39;s definitely a lot more ways to improve this. The code I&amp;#39;ve written is perhaps a bit basic, not sure how scalable the script is, if it&amp;#39;s clean, and there&amp;#39;s SQL injection possible with the &lt;code&gt;INSERT&lt;/code&gt; statement, though the function to get the price averages won&amp;#39;t run for anything other than numbers.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using an t2.medium instance because the t2.small instance would crash the website, but that was when I was playing around with more GPUs being searched. I was thinking of trying the t2.small instance again but decided to leave it as it is, and look for ways to learn about other services to deploy a pipeline like this, especially a free one so I can keep this project running for people to use, like on &lt;a href=\"/r/HardwareSwapUK\"&gt;/r/HardwareSwapUK&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9AyPvNJ3xAXs6VAX_YnVkXE-zEnDvnmqmzNSwirzauY.jpg?auto=webp&amp;v=enabled&amp;s=2af9600bd4aa992f39d564819271899a1ab7fe0e", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/9AyPvNJ3xAXs6VAX_YnVkXE-zEnDvnmqmzNSwirzauY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3026bad95d2fd621dadaa0bdfc4fce3cef771be7", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/9AyPvNJ3xAXs6VAX_YnVkXE-zEnDvnmqmzNSwirzauY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64cf19660c70d1617f460ff07ecf3bfa7b330151", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/9AyPvNJ3xAXs6VAX_YnVkXE-zEnDvnmqmzNSwirzauY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35f2eecb197804bddcec656085545e631b9d3436", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/9AyPvNJ3xAXs6VAX_YnVkXE-zEnDvnmqmzNSwirzauY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=77273085d988cf74ed3eb98bdde92c801a2e7a26", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/9AyPvNJ3xAXs6VAX_YnVkXE-zEnDvnmqmzNSwirzauY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d649cec23ed95938f033b634800c1129c1283dfe", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/9AyPvNJ3xAXs6VAX_YnVkXE-zEnDvnmqmzNSwirzauY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=acd5ce8b4111c182753abc04a0a76eefb510c852", "width": 1080, "height": 540}], "variants": {}, "id": "2lf3IYLRtQAxbb7CToJK_65KH5OHqQF9YhUq4E9VuTo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "CS Graduate", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "113roc9", "is_robot_indexable": true, "report_reasons": null, "author": "Mapleess", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/113roc9/airflow_pipeline_for_ebay_data_extraction_simple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113roc9/airflow_pipeline_for_ebay_data_extraction_simple/", "subreddit_subscribers": 89854, "created_utc": 1676557141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are them, really?", "author_fullname": "t2_82dwrpz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the advantages of data lakes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113qu1r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676554725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are them, really?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "113qu1r", "is_robot_indexable": true, "report_reasons": null, "author": "Upstairs-Ad-8440", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113qu1r/what_are_the_advantages_of_data_lakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113qu1r/what_are_the_advantages_of_data_lakes/", "subreddit_subscribers": 89854, "created_utc": 1676554725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_puwuw2q2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My project: A focused, personalized observability report for every PR. GitHub Actions: Would you find this useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_113pg54", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b2L8gjGr2xKg0WKG-hT1Xv3tNDNk5E0rte_0BRFIMWE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676550430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/8lpmzrednjia1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/8lpmzrednjia1.png?auto=webp&amp;v=enabled&amp;s=ba5c47aeac347b8fbbb153a3f7f2093ee537698c", "width": 618, "height": 1203}, "resolutions": [{"url": "https://preview.redd.it/8lpmzrednjia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b046a88be133029b6970105b7fdbf8f46602f554", "width": 108, "height": 210}, {"url": "https://preview.redd.it/8lpmzrednjia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5a7699ecf679e7ee2d2a3b7600630ac4768ea9c8", "width": 216, "height": 420}, {"url": "https://preview.redd.it/8lpmzrednjia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1607a7c854fdfce57ebaaa2506b150e5638977a4", "width": 320, "height": 622}], "variants": {}, "id": "JPevZe8OIe_HvE94bD2wlM2BYu4RPMzjNqzycgXcTzU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "113pg54", "is_robot_indexable": true, "report_reasons": null, "author": "observability_geek", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113pg54/my_project_a_focused_personalized_observability/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/8lpmzrednjia1.png", "subreddit_subscribers": 89854, "created_utc": 1676550430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1jx9xua", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A data mesh for the rest of us", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_113rmqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Vo04I-HUxNZxvPo113vbsqEnkeWusBIcQjdmO-x6GK8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676557012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tech.loveholidays.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tech.loveholidays.com/a-data-mesh-for-the-rest-of-us-12e2c10ac128", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CLu9V6SZJ8LyL1Dr6EP6CguToTYYV9yKnx9bT4NB0Wk.jpg?auto=webp&amp;v=enabled&amp;s=f96a74cf96d249f64343eef34991ad1ccdc98edd", "width": 1162, "height": 1392}, "resolutions": [{"url": "https://external-preview.redd.it/CLu9V6SZJ8LyL1Dr6EP6CguToTYYV9yKnx9bT4NB0Wk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb8aa1511981b78405cf1f97c5ed2765d873b593", "width": 108, "height": 129}, {"url": "https://external-preview.redd.it/CLu9V6SZJ8LyL1Dr6EP6CguToTYYV9yKnx9bT4NB0Wk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8894b210a20989a52cb1b49459f6e71cb47c53f", "width": 216, "height": 258}, {"url": "https://external-preview.redd.it/CLu9V6SZJ8LyL1Dr6EP6CguToTYYV9yKnx9bT4NB0Wk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=194b8dcd3f979379f00d3a88fbddacea92bc678e", "width": 320, "height": 383}, {"url": "https://external-preview.redd.it/CLu9V6SZJ8LyL1Dr6EP6CguToTYYV9yKnx9bT4NB0Wk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ac07d5030bfb285211a5f90534038ab699918d2", "width": 640, "height": 766}, {"url": "https://external-preview.redd.it/CLu9V6SZJ8LyL1Dr6EP6CguToTYYV9yKnx9bT4NB0Wk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5df9a8d6b0e8e771972df2a9382722402b34104b", "width": 960, "height": 1150}, {"url": "https://external-preview.redd.it/CLu9V6SZJ8LyL1Dr6EP6CguToTYYV9yKnx9bT4NB0Wk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8dba3097170bf0efd23e8fd9432e786ea92c34bc", "width": 1080, "height": 1293}], "variants": {}, "id": "c5kxXpUajNxYr31sXoHyDiM2CcPGkWrkU4iZDryDntI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "113rmqn", "is_robot_indexable": true, "report_reasons": null, "author": "dropber", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113rmqn/a_data_mesh_for_the_rest_of_us/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tech.loveholidays.com/a-data-mesh-for-the-rest-of-us-12e2c10ac128", "subreddit_subscribers": 89854, "created_utc": 1676557012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm currently using the Databricks platform to build out our Lakehouse infrastructure and have been advised to use Delta Live Tables. \n\nThere are lots of common processes to be run for each of our 300+ silver tables, one of these is to ensure the DateTime format is in 'YYYY-MM-DDTHH:MM:SS format.\n\nIn a typical Python environment I would define that function once and then call it from various scripts, meaning if I ever needed to change that function I would only do so in one place. \n\nHow can I modularise my delta live tables so I can point a notebook to this function, rather than defining it at the top of every single notebook? I've looked into UDFs but they aren't recommended - so i'm stumped here!\n\nThanks,", "author_fullname": "t2_ocur3kkm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to modularise Delta Live Tables using Pyspark in Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113mxlk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676540959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently using the Databricks platform to build out our Lakehouse infrastructure and have been advised to use Delta Live Tables. &lt;/p&gt;\n\n&lt;p&gt;There are lots of common processes to be run for each of our 300+ silver tables, one of these is to ensure the DateTime format is in &amp;#39;YYYY-MM-DDTHH:MM:SS format.&lt;/p&gt;\n\n&lt;p&gt;In a typical Python environment I would define that function once and then call it from various scripts, meaning if I ever needed to change that function I would only do so in one place. &lt;/p&gt;\n\n&lt;p&gt;How can I modularise my delta live tables so I can point a notebook to this function, rather than defining it at the top of every single notebook? I&amp;#39;ve looked into UDFs but they aren&amp;#39;t recommended - so i&amp;#39;m stumped here!&lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "113mxlk", "is_robot_indexable": true, "report_reasons": null, "author": "OutlandishnessOdd695", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113mxlk/how_to_modularise_delta_live_tables_using_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113mxlk/how_to_modularise_delta_live_tables_using_pyspark/", "subreddit_subscribers": 89854, "created_utc": 1676540959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I\u2019m in the biotech industry, and scientists are inseparable from their XLSX sheets. They use them to record experiment data and annotate instrument data metadata.\n\nMy challenge is to build reliable ELT pipelines around these unreliable data sources.\n\nThrough now, the rough workflow is: \n\n1. Design XLSX template w/ each page relating to a backend table in a 1-1 relationship\n2. Host XLSX template in SharePoint site, give access to select scientist to update\n3. Schedule extract task to read XLSX into memory, write each sheet as separate CSV to data lake\n4. Load each CSV into RedShift tables, truncating and loading fully\n\nThis sort of works, but I'm not entirely happy with it, and I'm not sure why. Part of me guesses that I should build smaller webapps to take in this data so that I can validate data in the application layer &amp; read the validated data from the backend DB. But this seems overengineered. Right now validation happens in the Data Warehouse.\n\nAny advice is appreciated, interested what other groups are doing here!", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should I ingest manually created XLSX files into my data warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113slfq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676559672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m in the biotech industry, and scientists are inseparable from their XLSX sheets. They use them to record experiment data and annotate instrument data metadata.&lt;/p&gt;\n\n&lt;p&gt;My challenge is to build reliable ELT pipelines around these unreliable data sources.&lt;/p&gt;\n\n&lt;p&gt;Through now, the rough workflow is: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Design XLSX template w/ each page relating to a backend table in a 1-1 relationship&lt;/li&gt;\n&lt;li&gt;Host XLSX template in SharePoint site, give access to select scientist to update&lt;/li&gt;\n&lt;li&gt;Schedule extract task to read XLSX into memory, write each sheet as separate CSV to data lake&lt;/li&gt;\n&lt;li&gt;Load each CSV into RedShift tables, truncating and loading fully&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This sort of works, but I&amp;#39;m not entirely happy with it, and I&amp;#39;m not sure why. Part of me guesses that I should build smaller webapps to take in this data so that I can validate data in the application layer &amp;amp; read the validated data from the backend DB. But this seems overengineered. Right now validation happens in the Data Warehouse.&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated, interested what other groups are doing here!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "113slfq", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113slfq/how_should_i_ingest_manually_created_xlsx_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113slfq/how_should_i_ingest_manually_created_xlsx_files/", "subreddit_subscribers": 89854, "created_utc": 1676559672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I run a BI team and handle most of the SQL modeling, post-ETL (we have a Data Engineering team that gets stuff into our warehouse). Think building views and datasets, which are then either turned into dashboards and reports by myself or my analysts. It is by far my favorite aspect of my job and it comes very naturally to me.\n\nThis has led me to get more interested in pursuing data engineering in my career. What I do seems to be considered \"analytics engineering\" in the space now, but what I would love to hear from the community here is where \"analytics engineering\" ends and where data engineering begins, as well as the skills that are needed for the latter but not necessarily the former. I write SQL on a daily basis, but my scripting knowledge is limited because it just hasn't been directly relevant for my career yet. For the (simple, small-data) data pipelines I create, I use a software tool that handles all of the ETL for me.\n\nAny and all help is greatly appreciated!", "author_fullname": "t2_i2gus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does analytics engineering end, and data engineering begin?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113uttu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676565486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I run a BI team and handle most of the SQL modeling, post-ETL (we have a Data Engineering team that gets stuff into our warehouse). Think building views and datasets, which are then either turned into dashboards and reports by myself or my analysts. It is by far my favorite aspect of my job and it comes very naturally to me.&lt;/p&gt;\n\n&lt;p&gt;This has led me to get more interested in pursuing data engineering in my career. What I do seems to be considered &amp;quot;analytics engineering&amp;quot; in the space now, but what I would love to hear from the community here is where &amp;quot;analytics engineering&amp;quot; ends and where data engineering begins, as well as the skills that are needed for the latter but not necessarily the former. I write SQL on a daily basis, but my scripting knowledge is limited because it just hasn&amp;#39;t been directly relevant for my career yet. For the (simple, small-data) data pipelines I create, I use a software tool that handles all of the ETL for me.&lt;/p&gt;\n\n&lt;p&gt;Any and all help is greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "113uttu", "is_robot_indexable": true, "report_reasons": null, "author": "SteezeWhiz", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113uttu/where_does_analytics_engineering_end_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113uttu/where_does_analytics_engineering_end_and_data/", "subreddit_subscribers": 89854, "created_utc": 1676565486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm testing airbyte locally. I've deployed my first connection and I noticed that AirByte has cron option for syncing data. I see that Airflow supports AirByte using airbyte operators. Can you guys  give me an example why I should use airflow together with airbyte?", "author_fullname": "t2_ei3tpd4w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why use Airbyte + Airflow since Airbyte has a cron scheduler?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113zt9b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676578265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m testing airbyte locally. I&amp;#39;ve deployed my first connection and I noticed that AirByte has cron option for syncing data. I see that Airflow supports AirByte using airbyte operators. Can you guys  give me an example why I should use airflow together with airbyte?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "113zt9b", "is_robot_indexable": true, "report_reasons": null, "author": "OdiumPura", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113zt9b/why_use_airbyte_airflow_since_airbyte_has_a_cron/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113zt9b/why_use_airbyte_airflow_since_airbyte_has_a_cron/", "subreddit_subscribers": 89854, "created_utc": 1676578265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently a data analyst with a smaller analytics consulting agency in the US and have been using DBT cloud since I started in the data field 7 months ago. I'm looking to apply for data engineering roles after 1.5 - 2yrs of experience in my current role. \n\n\\- If you have taken the exam, what're you thoughts on the exam itself and has it been beneficial with any job searching or in everyday work?\n\n\\- In your opinion, would you prioritize this exam over an AWS associate level cert like the solutions architect or developer?\n\nAny thoughts/feedback is appreciated!", "author_fullname": "t2_71weyfry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the DBT Analytics Engineering Certification worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113wjwy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676569903.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently a data analyst with a smaller analytics consulting agency in the US and have been using DBT cloud since I started in the data field 7 months ago. I&amp;#39;m looking to apply for data engineering roles after 1.5 - 2yrs of experience in my current role. &lt;/p&gt;\n\n&lt;p&gt;- If you have taken the exam, what&amp;#39;re you thoughts on the exam itself and has it been beneficial with any job searching or in everyday work?&lt;/p&gt;\n\n&lt;p&gt;- In your opinion, would you prioritize this exam over an AWS associate level cert like the solutions architect or developer?&lt;/p&gt;\n\n&lt;p&gt;Any thoughts/feedback is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "113wjwy", "is_robot_indexable": true, "report_reasons": null, "author": "DrunkenWhaler136", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113wjwy/is_the_dbt_analytics_engineering_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113wjwy/is_the_dbt_analytics_engineering_certification/", "subreddit_subscribers": 89854, "created_utc": 1676569903.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ok, so I had an old collegue reach out to see if I was interested in doing some consulting for them. He works in accounting, high level controller. My initial meeting with him is tomorrow to go over the problem they want done. I would like some advice or good questions to ask him from you more experienced people. \n\nWhat I know of the job:\n\nHe works in private equity, and he has 12 entities (from aquistions) each has their own chart of accounts. The goal is to consolidite all of them into 1 chart of accounts. Right now its a manual process just using excel workbooks and takes them 3 days to do if they are lucky. \n\nI know this might not be \"data engineering\" but its automation and we do a lot of that in data engineering. I think I can write up some python to essentially consolidate them all. Obviously there will be some caviates I find during the meeting tomorrow. But what types of things should I look for? What should I ask? Thanks for your help guys!", "author_fullname": "t2_1afmkbx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Landed my first consulting job. Looking for advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113zq7m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676578049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok, so I had an old collegue reach out to see if I was interested in doing some consulting for them. He works in accounting, high level controller. My initial meeting with him is tomorrow to go over the problem they want done. I would like some advice or good questions to ask him from you more experienced people. &lt;/p&gt;\n\n&lt;p&gt;What I know of the job:&lt;/p&gt;\n\n&lt;p&gt;He works in private equity, and he has 12 entities (from aquistions) each has their own chart of accounts. The goal is to consolidite all of them into 1 chart of accounts. Right now its a manual process just using excel workbooks and takes them 3 days to do if they are lucky. &lt;/p&gt;\n\n&lt;p&gt;I know this might not be &amp;quot;data engineering&amp;quot; but its automation and we do a lot of that in data engineering. I think I can write up some python to essentially consolidate them all. Obviously there will be some caviates I find during the meeting tomorrow. But what types of things should I look for? What should I ask? Thanks for your help guys!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "113zq7m", "is_robot_indexable": true, "report_reasons": null, "author": "w_savage", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113zq7m/landed_my_first_consulting_job_looking_for_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113zq7m/landed_my_first_consulting_job_looking_for_advice/", "subreddit_subscribers": 89854, "created_utc": 1676578049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm out of a job, and going over DE postings on LinkedIn, I (of course) see some requiring experience with - in this case - Spark, Airflow, DBT, Snowflake. Most of my experience is with Hadoop, Python, SQL/MySQL, with some AWS and Azure Data Factory, so although it'd be **nice** to say I have experience with those things, it's not really true.\n\nWould it be sufficient to do some projects that involve these technologies, or is something more needed?", "author_fullname": "t2_1663zr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get more experience with...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11400wf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676578822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m out of a job, and going over DE postings on LinkedIn, I (of course) see some requiring experience with - in this case - Spark, Airflow, DBT, Snowflake. Most of my experience is with Hadoop, Python, SQL/MySQL, with some AWS and Azure Data Factory, so although it&amp;#39;d be &lt;strong&gt;nice&lt;/strong&gt; to say I have experience with those things, it&amp;#39;s not really true.&lt;/p&gt;\n\n&lt;p&gt;Would it be sufficient to do some projects that involve these technologies, or is something more needed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11400wf", "is_robot_indexable": true, "report_reasons": null, "author": "lengthy_preamble", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11400wf/how_to_get_more_experience_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11400wf/how_to_get_more_experience_with/", "subreddit_subscribers": 89854, "created_utc": 1676578822.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "You\u2019ve been given free reign by your boss to plan and implement any single change in your environment you\u2019d like. No matter large or small, easy or complex.\n\nWhat would you change and why is it your priority #1?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you change in your environment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_114de9d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676618114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You\u2019ve been given free reign by your boss to plan and implement any single change in your environment you\u2019d like. No matter large or small, easy or complex.&lt;/p&gt;\n\n&lt;p&gt;What would you change and why is it your priority #1?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "114de9d", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114de9d/what_would_you_change_in_your_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114de9d/what_would_you_change_in_your_environment/", "subreddit_subscribers": 89854, "created_utc": 1676618114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is a question for performance.\n\nI've just joined a team that's doing ETL with pandas into Postgres. We pull from a series of internal APIs and load a simple docker image that runs the all our py file pipelines. \n\nNow, as it's just not feasible to keep business logic entirely housed in the pandas transforms, the design is such that we have the initial de-normalized table in postgres built from pandas, this generates the base table. Then aggregates are built on top via postgres materialized views (SQL) for specific dashboarding use cases.   \n\n\n1 py file will pulling the data, apply transforms with pandas, and then refreshing any of the mvs. \n\nRule of thumb has been to have one MV for each dashboard, such that there should never be a need to create an additional base table. All the ETL jobs should be processing in under 30 minutes as well.   \n\n\nQuestion is if this is the best method for performance tuning? Why do we need to have a de-normalized table here first of all, and second of all what are we gaining by having materialized views versus tables in postgres. I come from the snowflake world where the MVs would consistently be auto-refreshed, but where performance drops significantly over having a table instead of a view.", "author_fullname": "t2_10wjqv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Performance tuning PostGres", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1148v5q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676602667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a question for performance.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just joined a team that&amp;#39;s doing ETL with pandas into Postgres. We pull from a series of internal APIs and load a simple docker image that runs the all our py file pipelines. &lt;/p&gt;\n\n&lt;p&gt;Now, as it&amp;#39;s just not feasible to keep business logic entirely housed in the pandas transforms, the design is such that we have the initial de-normalized table in postgres built from pandas, this generates the base table. Then aggregates are built on top via postgres materialized views (SQL) for specific dashboarding use cases.   &lt;/p&gt;\n\n&lt;p&gt;1 py file will pulling the data, apply transforms with pandas, and then refreshing any of the mvs. &lt;/p&gt;\n\n&lt;p&gt;Rule of thumb has been to have one MV for each dashboard, such that there should never be a need to create an additional base table. All the ETL jobs should be processing in under 30 minutes as well.   &lt;/p&gt;\n\n&lt;p&gt;Question is if this is the best method for performance tuning? Why do we need to have a de-normalized table here first of all, and second of all what are we gaining by having materialized views versus tables in postgres. I come from the snowflake world where the MVs would consistently be auto-refreshed, but where performance drops significantly over having a table instead of a view.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1148v5q", "is_robot_indexable": true, "report_reasons": null, "author": "branllywd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1148v5q/performance_tuning_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1148v5q/performance_tuning_postgres/", "subreddit_subscribers": 89854, "created_utc": 1676602667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Best practice is a bit of a misnomer. There is no single best practice. It\u2019s what works best for the company.\n\nIs it appropriate to define best practice as \u2018the largest combination of good practices that can be implemented given the operating environment\u2019?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practice Definition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1140gfv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676579943.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Best practice is a bit of a misnomer. There is no single best practice. It\u2019s what works best for the company.&lt;/p&gt;\n\n&lt;p&gt;Is it appropriate to define best practice as \u2018the largest combination of good practices that can be implemented given the operating environment\u2019?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1140gfv", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1140gfv/best_practice_definition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1140gfv/best_practice_definition/", "subreddit_subscribers": 89854, "created_utc": 1676579943.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all  \nI have data engineer interview coming up with [Booking.com](https://Booking.com). I want advice if somebody has already gone through the hoops on how to prepare, I think they have 2 rounds technically coding and system desgin.   \nHow should I prepare for them, from what I have searched online they have streaming coding round for coding round and system round is general system design and data modeling round on a give scenario. I am not sure what is streaming coding round. Also how do people prepare for system design round as data engineer, there are a lot of sources for SWE positions but I haven't found anything like that for data engineering, would appreciate if somebody can share any resources for preparation on these.", "author_fullname": "t2_cu6opso3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Booking.com Data Engineer Interview Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113que5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676554753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all&lt;br/&gt;\nI have data engineer interview coming up with &lt;a href=\"https://Booking.com\"&gt;Booking.com&lt;/a&gt;. I want advice if somebody has already gone through the hoops on how to prepare, I think they have 2 rounds technically coding and system desgin.&lt;br/&gt;\nHow should I prepare for them, from what I have searched online they have streaming coding round for coding round and system round is general system design and data modeling round on a give scenario. I am not sure what is streaming coding round. Also how do people prepare for system design round as data engineer, there are a lot of sources for SWE positions but I haven&amp;#39;t found anything like that for data engineering, would appreciate if somebody can share any resources for preparation on these.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JScxGhJAtnCffNUMMsG-IHXgofOOGPYqUHUx0ieSAf8.jpg?auto=webp&amp;v=enabled&amp;s=e78c7f7b5ef8df799c5ab7819ad21ae28e0bf405", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/JScxGhJAtnCffNUMMsG-IHXgofOOGPYqUHUx0ieSAf8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=128d0c5e050d4fd44731c14d3596b793d77b0906", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/JScxGhJAtnCffNUMMsG-IHXgofOOGPYqUHUx0ieSAf8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c59c9ba9d4b265735403cbfede7112bd6a258057", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/JScxGhJAtnCffNUMMsG-IHXgofOOGPYqUHUx0ieSAf8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=379c22da3c6f868cf8b47f65272c52642a9b8cc1", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/JScxGhJAtnCffNUMMsG-IHXgofOOGPYqUHUx0ieSAf8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1246f60c367c5e32f870ccbc849b81646f382184", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/JScxGhJAtnCffNUMMsG-IHXgofOOGPYqUHUx0ieSAf8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd246c83391f10392953e4abed795482897eca67", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/JScxGhJAtnCffNUMMsG-IHXgofOOGPYqUHUx0ieSAf8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=448a7d6b2100cd5eef4217e155caab07496d166c", "width": 1080, "height": 567}], "variants": {}, "id": "pOxqQ-Hg2p6yWf-XnRr9X7KZJkKYq4zbh2GbSAcQcJM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "113que5", "is_robot_indexable": true, "report_reasons": null, "author": "bha159", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113que5/bookingcom_data_engineer_interview_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113que5/bookingcom_data_engineer_interview_advice/", "subreddit_subscribers": 89854, "created_utc": 1676554753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my manager asked me to find some tools for ETL which stores Metadata also because data factory is not so good and coding make Metadata get lost in between. And in his words \"it should be normal as expensive as IBM datastage\".\n\nAnd I am a beginner,  I don't know what that means.\n\nWe have databricks and dtaafactory for etl.\n\nSo my question is\n\nWhat are such tools? (I found atlan paid and apache atals open source)\nHow Metadata get lost if etl is done via coding?\n\nAnd lastly how Metadata helps?", "author_fullname": "t2_tyxztucf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Metadata management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114bhfp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676611120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my manager asked me to find some tools for ETL which stores Metadata also because data factory is not so good and coding make Metadata get lost in between. And in his words &amp;quot;it should be normal as expensive as IBM datastage&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;And I am a beginner,  I don&amp;#39;t know what that means.&lt;/p&gt;\n\n&lt;p&gt;We have databricks and dtaafactory for etl.&lt;/p&gt;\n\n&lt;p&gt;So my question is&lt;/p&gt;\n\n&lt;p&gt;What are such tools? (I found atlan paid and apache atals open source)\nHow Metadata get lost if etl is done via coding?&lt;/p&gt;\n\n&lt;p&gt;And lastly how Metadata helps?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "114bhfp", "is_robot_indexable": true, "report_reasons": null, "author": "someone_nerdy123", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114bhfp/metadata_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114bhfp/metadata_management/", "subreddit_subscribers": 89854, "created_utc": 1676611120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Stack:\n\nAzure SQL databases\n\n.net app\n\nEverything on Azure\n\nADO git version control/ CI-CD for the app\n\n[View Poll](https://www.reddit.com/poll/1146dol)", "author_fullname": "t2_4c8v1gfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Straw Poll - Which for DB versioning? Stack details in body", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1146dol", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676595293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Stack:&lt;/p&gt;\n\n&lt;p&gt;Azure SQL databases&lt;/p&gt;\n\n&lt;p&gt;.net app&lt;/p&gt;\n\n&lt;p&gt;Everything on Azure&lt;/p&gt;\n\n&lt;p&gt;ADO git version control/ CI-CD for the app&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/1146dol\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1146dol", "is_robot_indexable": true, "report_reasons": null, "author": "ATastefulCrossJoin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1676854493286, "options": [{"text": "Redgate Flyway", "id": "21637301"}, {"text": "SSDT/dacpac", "id": "21637302"}, {"text": "Show me results", "id": "21637303"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 31, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1146dol/straw_poll_which_for_db_versioning_stack_details/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/1146dol/straw_poll_which_for_db_versioning_stack_details/", "subreddit_subscribers": 89854, "created_utc": 1676595293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I am a junior who switched to CS recently (from an applied data science field). I am ultimately interested in either a SWE or data engineering/science role.\n\nI am (incredibly lucky and grateful to be) deciding between two internships and was hoping for some input on what would better set me up for a career in SWE or data engineering:\n\n1. Security automation engineering at a lesser known F100 company: in person (which doesn't bother me) in a smaller city that I'm not super interested in (but relocation/housing are covered which is nice), $23/hour (considering negotiating higher if possible - would hope for $26/27). I don't know much about the field, but am interested in automation and pipeline development (though long-term likely not in a security field).\n2. Reporting/Data analytics at a large healthcare company (worked there last summer too, but different team), fully remote, $27/hour (might try to negotiate to $28/29 but unlikely to get that). This field is very similar to my previous major which I'm still somewhat interested in, but I was hoping to break more into a tech/CS/math-heavy area of data if possible and don't want to pigeonhole myself in healthcare analytics too early on.\n\nAny and all thoughts are much appreciated!", "author_fullname": "t2_4tk5wclk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internship: Security Automation Engineering or Reporting/Data Analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1143ns0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676587976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I am a junior who switched to CS recently (from an applied data science field). I am ultimately interested in either a SWE or data engineering/science role.&lt;/p&gt;\n\n&lt;p&gt;I am (incredibly lucky and grateful to be) deciding between two internships and was hoping for some input on what would better set me up for a career in SWE or data engineering:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Security automation engineering at a lesser known F100 company: in person (which doesn&amp;#39;t bother me) in a smaller city that I&amp;#39;m not super interested in (but relocation/housing are covered which is nice), $23/hour (considering negotiating higher if possible - would hope for $26/27). I don&amp;#39;t know much about the field, but am interested in automation and pipeline development (though long-term likely not in a security field).&lt;/li&gt;\n&lt;li&gt;Reporting/Data analytics at a large healthcare company (worked there last summer too, but different team), fully remote, $27/hour (might try to negotiate to $28/29 but unlikely to get that). This field is very similar to my previous major which I&amp;#39;m still somewhat interested in, but I was hoping to break more into a tech/CS/math-heavy area of data if possible and don&amp;#39;t want to pigeonhole myself in healthcare analytics too early on.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any and all thoughts are much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1143ns0", "is_robot_indexable": true, "report_reasons": null, "author": "lexi_dances_2020", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1143ns0/internship_security_automation_engineering_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1143ns0/internship_security_automation_engineering_or/", "subreddit_subscribers": 89854, "created_utc": 1676587976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Quick summary on my position and structure of company: \n\nI work in an Analytics department, and we provide most reporting and analysis for the company. IT handles some of the static reports and is works on data warehousing. We have read access to most OnPrem SQL Server DBs. Right now most of our job is creating Normalized Databases in Access and creating reports from there.  We use Access for its ability to link to the SQL Server Tables. It is extremely inefficient and I really don't want to write VBA to automate things. I am pretty good at SQL and know a good amount of Python.\n\nOur current setup:\n\n\\-2 Analyst with our own SQL Server where we want to load all of our data. We cannot have access to linked tables from other servers in our environment. \n\n\\-A shared virtual machine where we use our credentials to log in to. I was hoping an orchestration tool could run on this machine.\n\n\\-We use Windows\n\nGoals:\n\nData comes in very randomly, because we work with a lot of third parties. I would like to have a script that runs maybe every hour to check if new data sources are in and then run processes from there. Most of the processes are to extract the data and load into our SQL Server where I run some stored procedures.\n\nMy issue:\n\nI want to use Airflow to automate things, but we have even been denied access to IIS in the past. My Manager doesn't really care about using new tools, and would rather just use VBA to do this. I have used Pandas to transfer data between servers before, but issues around data types have come up. I used SQLAlchemy Create Table to make sure I get the correct table structure and then load the pandas data into the newly created table, but its just not easily usable. I've looked at DBT, but from the little I know using this with SQL Server is not as easy.\n\nI probably missed some important information, but I am looking for some guidance on tools I can implement myself to get my goals done. I cannot download Airflow myself because it requires Docker which requires WSL on windows and I have to get IT to allow this ability.", "author_fullname": "t2_704n3yha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on process workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113t82f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676561355.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Quick summary on my position and structure of company: &lt;/p&gt;\n\n&lt;p&gt;I work in an Analytics department, and we provide most reporting and analysis for the company. IT handles some of the static reports and is works on data warehousing. We have read access to most OnPrem SQL Server DBs. Right now most of our job is creating Normalized Databases in Access and creating reports from there.  We use Access for its ability to link to the SQL Server Tables. It is extremely inefficient and I really don&amp;#39;t want to write VBA to automate things. I am pretty good at SQL and know a good amount of Python.&lt;/p&gt;\n\n&lt;p&gt;Our current setup:&lt;/p&gt;\n\n&lt;p&gt;-2 Analyst with our own SQL Server where we want to load all of our data. We cannot have access to linked tables from other servers in our environment. &lt;/p&gt;\n\n&lt;p&gt;-A shared virtual machine where we use our credentials to log in to. I was hoping an orchestration tool could run on this machine.&lt;/p&gt;\n\n&lt;p&gt;-We use Windows&lt;/p&gt;\n\n&lt;p&gt;Goals:&lt;/p&gt;\n\n&lt;p&gt;Data comes in very randomly, because we work with a lot of third parties. I would like to have a script that runs maybe every hour to check if new data sources are in and then run processes from there. Most of the processes are to extract the data and load into our SQL Server where I run some stored procedures.&lt;/p&gt;\n\n&lt;p&gt;My issue:&lt;/p&gt;\n\n&lt;p&gt;I want to use Airflow to automate things, but we have even been denied access to IIS in the past. My Manager doesn&amp;#39;t really care about using new tools, and would rather just use VBA to do this. I have used Pandas to transfer data between servers before, but issues around data types have come up. I used SQLAlchemy Create Table to make sure I get the correct table structure and then load the pandas data into the newly created table, but its just not easily usable. I&amp;#39;ve looked at DBT, but from the little I know using this with SQL Server is not as easy.&lt;/p&gt;\n\n&lt;p&gt;I probably missed some important information, but I am looking for some guidance on tools I can implement myself to get my goals done. I cannot download Airflow myself because it requires Docker which requires WSL on windows and I have to get IT to allow this ability.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "113t82f", "is_robot_indexable": true, "report_reasons": null, "author": "gloverb2016", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113t82f/advice_on_process_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113t82f/advice_on_process_workflow/", "subreddit_subscribers": 89854, "created_utc": 1676561355.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, i'm a newly hired data engineering intern at a company which i'll later work for, my internship project is to create an ETL pipeline with a GUI based ETL tool.\n\nMy manager conducted me to do some research on who's better for future use between Talend or Pentaho, now i know this is a biased question, but if anyone has done some benchmark testing or worked with both to get some conslusions on things such as ( Performence speed, Scalability, Data integration, easy-to-use, more documentation ...).\n\n&amp;#x200B;\n\nPS: I know you guys really hate this GUI based tools haha (me too), but the manager doesn't require a technical guy for this, thanks!", "author_fullname": "t2_bfls8zod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Talend or Pentaho ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_113sb1g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676558884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, i&amp;#39;m a newly hired data engineering intern at a company which i&amp;#39;ll later work for, my internship project is to create an ETL pipeline with a GUI based ETL tool.&lt;/p&gt;\n\n&lt;p&gt;My manager conducted me to do some research on who&amp;#39;s better for future use between Talend or Pentaho, now i know this is a biased question, but if anyone has done some benchmark testing or worked with both to get some conslusions on things such as ( Performence speed, Scalability, Data integration, easy-to-use, more documentation ...).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;PS: I know you guys really hate this GUI based tools haha (me too), but the manager doesn&amp;#39;t require a technical guy for this, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "113sb1g", "is_robot_indexable": true, "report_reasons": null, "author": "infiiniterotation", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/113sb1g/talend_or_pentaho/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/113sb1g/talend_or_pentaho/", "subreddit_subscribers": 89854, "created_utc": 1676558884.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Heya I have been looking at DE as a career and would like some help. \nI am a fresher and a DA what should I do or learn to get started with DE ?", "author_fullname": "t2_vg4gj092", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hello people Guide me please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114clii", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676615116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Heya I have been looking at DE as a career and would like some help. \nI am a fresher and a DA what should I do or learn to get started with DE ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "114clii", "is_robot_indexable": true, "report_reasons": null, "author": "txjxs_nxsxr", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114clii/hello_people_guide_me_please/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114clii/hello_people_guide_me_please/", "subreddit_subscribers": 89854, "created_utc": 1676615116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have an MSSQL server and one table in the database has nearly 1.1 million records. Now I have to copy these records to snowflake periodically.\n\nThe process I'm following is as follows.\n\nRead data from MSSQL server,\nStore rows in dataframe,\nUse df.to_sql() method to bulk insert into snowflake.\nAnd I have to create a CSV from the df and store it in AWS S3 bucket for future reference.\n\nNow, the problem with this is, that I'm getting a Negsignal.SIGKILL\n\nWith a little bit of research, I have found that we cannot use Airflow to process such huge data.\n\n\nWe also have many such tables that should be moved periodically to snowflake.\n\nWe can use AWS DMS but it is only, limited, we have complex queries where we join multiple tables for data. Our company does not allow us to create views for these queries on the MSSQL database.\n\nHow do I go about solving this issue?\n\nShould I use a kubernets pod or an ec2 server to create a http server that does all these jobs when triggered by Airflow?\n\nI'm pretty new to airflow, any help would be appreciated. Thanks.", "author_fullname": "t2_rznge7zw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I use Airflow to process dataframe with millions of rows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114cexc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676614439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have an MSSQL server and one table in the database has nearly 1.1 million records. Now I have to copy these records to snowflake periodically.&lt;/p&gt;\n\n&lt;p&gt;The process I&amp;#39;m following is as follows.&lt;/p&gt;\n\n&lt;p&gt;Read data from MSSQL server,\nStore rows in dataframe,\nUse df.to_sql() method to bulk insert into snowflake.\nAnd I have to create a CSV from the df and store it in AWS S3 bucket for future reference.&lt;/p&gt;\n\n&lt;p&gt;Now, the problem with this is, that I&amp;#39;m getting a Negsignal.SIGKILL&lt;/p&gt;\n\n&lt;p&gt;With a little bit of research, I have found that we cannot use Airflow to process such huge data.&lt;/p&gt;\n\n&lt;p&gt;We also have many such tables that should be moved periodically to snowflake.&lt;/p&gt;\n\n&lt;p&gt;We can use AWS DMS but it is only, limited, we have complex queries where we join multiple tables for data. Our company does not allow us to create views for these queries on the MSSQL database.&lt;/p&gt;\n\n&lt;p&gt;How do I go about solving this issue?&lt;/p&gt;\n\n&lt;p&gt;Should I use a kubernets pod or an ec2 server to create a http server that does all these jobs when triggered by Airflow?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m pretty new to airflow, any help would be appreciated. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "114cexc", "is_robot_indexable": true, "report_reasons": null, "author": "likessiberianvodka", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114cexc/can_i_use_airflow_to_process_dataframe_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114cexc/can_i_use_airflow_to_process_dataframe_with/", "subreddit_subscribers": 89854, "created_utc": 1676614439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qibzf64", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Desktop vs Cloud Data Modeling Tools: Benefits, Inconveniences, and How to Choose", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1141eao", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/W2ED19EA8pGa452UYAwLUDpBOJZ9EdFcZA3HtUJWNUg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676582328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@kevin_r2020/desktop-vs-cloud-data-modeling-tools-benefits-inconveniences-and-how-to-choose-2f7bc5f51cb0", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sKDTcbwSpPrvkB0MWE0AkQz474yuMG6K3lON514yIXo.jpg?auto=webp&amp;v=enabled&amp;s=845dd7e047d2a2e5526c974955e80b07a59a798d", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/sKDTcbwSpPrvkB0MWE0AkQz474yuMG6K3lON514yIXo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e08e91ba83890b85ae38a1ac67f0d5b974ebe42", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/sKDTcbwSpPrvkB0MWE0AkQz474yuMG6K3lON514yIXo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5ec71393df122165e1bd5f1dc974b21e2e9a8c30", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/sKDTcbwSpPrvkB0MWE0AkQz474yuMG6K3lON514yIXo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45e2b92d2482175af689966c181b138d88bce71f", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/sKDTcbwSpPrvkB0MWE0AkQz474yuMG6K3lON514yIXo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2224f491de76c1ba43a4584aaebcd099eaeb744b", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/sKDTcbwSpPrvkB0MWE0AkQz474yuMG6K3lON514yIXo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09f1acf3a87d133ac83873dfc433c1d8ecf73f9d", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/sKDTcbwSpPrvkB0MWE0AkQz474yuMG6K3lON514yIXo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=154b2602caf127f143d152d9b43104367f4e519e", "width": 1080, "height": 720}], "variants": {}, "id": "lRwKZggbBkySW-dBUPsIuG2eftIiOIj3K-DA_7VLbNQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1141eao", "is_robot_indexable": true, "report_reasons": null, "author": "FunBig7887", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1141eao/desktop_vs_cloud_data_modeling_tools_benefits/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@kevin_r2020/desktop-vs-cloud-data-modeling-tools-benefits-inconveniences-and-how-to-choose-2f7bc5f51cb0", "subreddit_subscribers": 89854, "created_utc": 1676582328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database-like ops benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11401cr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1676578856.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "h2oai.github.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://h2oai.github.io/db-benchmark/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "11401cr", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11401cr/databaselike_ops_benchmark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://h2oai.github.io/db-benchmark/", "subreddit_subscribers": 89854, "created_utc": 1676578856.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}