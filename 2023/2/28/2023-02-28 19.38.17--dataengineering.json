{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve got a monolith AWS lambda function that needs to reach out to and query Athena and also do some writes to various s3 buckets after processing what it got from Athena. \n\nTrying to set up pytest and moto but getting stuck because I\u2019m also using awswrangler. \n\nNot even sure where to start finding info about building unit tests here and want to avoid deploying to AWS just to test minor code changes. \n\nDoes anyone have any good resources in where to start?", "author_fullname": "t2_d5gr1nxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for resources for building unit testing for boto3 code and mocking AWS services in pytest", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11drsam", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677544195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve got a monolith AWS lambda function that needs to reach out to and query Athena and also do some writes to various s3 buckets after processing what it got from Athena. &lt;/p&gt;\n\n&lt;p&gt;Trying to set up pytest and moto but getting stuck because I\u2019m also using awswrangler. &lt;/p&gt;\n\n&lt;p&gt;Not even sure where to start finding info about building unit tests here and want to avoid deploying to AWS just to test minor code changes. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any good resources in where to start?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11drsam", "is_robot_indexable": true, "report_reasons": null, "author": "renok_archnmy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11drsam/looking_for_resources_for_building_unit_testing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11drsam/looking_for_resources_for_building_unit_testing/", "subreddit_subscribers": 91423, "created_utc": 1677544195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_d45r1", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "Last weekend I made a Google Sheets plugin that uses GPT to categorize items, classify cells, reformat data, and more (link in comments)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_11efw6m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 32, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/egf6k3ui2zka1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/egf6k3ui2zka1/DASH_96.mp4", "dash_url": "https://v.redd.it/egf6k3ui2zka1/DASHPlaylist.mpd?a=1680205096%2CZDA1MTc2MTNjZGNjY2VhNDY5NThjYTIzYzIzMDE3ZjU4MTk0MDk4ODEzYWRmOWIzYzI5NzYxNGE3YjExMzY3OQ%3D%3D&amp;v=1&amp;f=sd", "duration": 49, "hls_url": "https://v.redd.it/egf6k3ui2zka1/HLSPlaylist.m3u8?a=1680205096%2CNWI5OWU0ZmUxZjIxMzllMGE3NzVlMzI2ZTBjMzcyZTljYzRhY2YxZmRkZmY2M2NlNDlkNWU0NmVlNTY1NGVlNg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/Cwy_5-meRnsAU4MmrkCss3O8DsQaJFKi5k7dR1sa_OA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677608839.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/egf6k3ui2zka1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vaxkRxfKn4hJZWNyXAAtI2M0yQWUkE3Yv7X8NEFunN0.png?format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7e070d075cc34b5704a40102344b34bce987fffa", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/vaxkRxfKn4hJZWNyXAAtI2M0yQWUkE3Yv7X8NEFunN0.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d83068f0e5850c623fc2b70cfdb4095ed9314a08", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/vaxkRxfKn4hJZWNyXAAtI2M0yQWUkE3Yv7X8NEFunN0.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=66c7b56dae9e4625db75a1bad3a42ca254869637", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/vaxkRxfKn4hJZWNyXAAtI2M0yQWUkE3Yv7X8NEFunN0.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=21607396fcbcb445d53a69e5eb009bb9233b40d1", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/vaxkRxfKn4hJZWNyXAAtI2M0yQWUkE3Yv7X8NEFunN0.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=754c32915adbf96cf4203af02f054bcb5f7bfa5d", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/vaxkRxfKn4hJZWNyXAAtI2M0yQWUkE3Yv7X8NEFunN0.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=80f392608377f01807a1c117ab7c40afb5994a4a", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/vaxkRxfKn4hJZWNyXAAtI2M0yQWUkE3Yv7X8NEFunN0.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2b3eec8551755913cd95f93fccc5713582716add", "width": 1080, "height": 607}], "variants": {}, "id": "bCwsIYYtl5OJFOIAkK-7L1e0K9k3Pnzeo5sECoHwlxk"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11efw6m", "is_robot_indexable": true, "report_reasons": null, "author": "rtwalz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11efw6m/last_weekend_i_made_a_google_sheets_plugin_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/egf6k3ui2zka1", "subreddit_subscribers": 91423, "created_utc": 1677608839.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 4800, "fallback_url": "https://v.redd.it/egf6k3ui2zka1/DASH_1080.mp4?source=fallback", "height": 1080, "width": 1920, "scrubber_media_url": "https://v.redd.it/egf6k3ui2zka1/DASH_96.mp4", "dash_url": "https://v.redd.it/egf6k3ui2zka1/DASHPlaylist.mpd?a=1680205096%2CZDA1MTc2MTNjZGNjY2VhNDY5NThjYTIzYzIzMDE3ZjU4MTk0MDk4ODEzYWRmOWIzYzI5NzYxNGE3YjExMzY3OQ%3D%3D&amp;v=1&amp;f=sd", "duration": 49, "hls_url": "https://v.redd.it/egf6k3ui2zka1/HLSPlaylist.m3u8?a=1680205096%2CNWI5OWU0ZmUxZjIxMzllMGE3NzVlMzI2ZTBjMzcyZTljYzRhY2YxZmRkZmY2M2NlNDlkNWU0NmVlNTY1NGVlNg%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples](https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples)\n\nHi, I wrote a longer blog that you can use to explain to your data engineering team why Streamlit is an excellent choice for example replacing spreadsheets and/or visualizing your ML models. The examples are simple in terms that it shows how easy it's for example to write data back into Snowflake or to visualize a map data. \n\nHope you enjoy and had as much fun reading as I had writing this.   \n\n\nhttps://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5", "author_fullname": "t2_sxd6cnuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introduction to Streamlit and Data applications on Snowflake with Winter Sports examples", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "media_metadata": {"sgnvh0116xka1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 49, "x": 108, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aba633b89ce8a4ad4b6ad478e398b87b98701892"}, {"y": 98, "x": 216, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7168ad79cf7bc0e89f737d02fd9a5da08b2685d0"}, {"y": 145, "x": 320, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=250dd2fc5d66dbfa5d6541df378d5147b21972a0"}, {"y": 291, "x": 640, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f7318e143a74a678c35b71e4407a6c9cf62567db"}, {"y": 437, "x": 960, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3b41d90f5e2d93b3cbc91ff19c3544c59d6fc2a"}, {"y": 492, "x": 1080, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b6f7e1c23ca1a7cb5902486f4bb8b88f334e3da"}], "s": {"y": 875, "x": 1920, "u": "https://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5"}, "id": "sgnvh0116xka1"}}, "name": "t3_11e4bv4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WNUlYBzmq5_xjOvDF9FNroXOFVBeHFjCtdrFBVGl18g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677585694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples\"&gt;https://www.recordlydata.com/blog/introduction-to-streamlit-and-data-applications-on-snowflake-with-winter-sports-examples&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hi, I wrote a longer blog that you can use to explain to your data engineering team why Streamlit is an excellent choice for example replacing spreadsheets and/or visualizing your ML models. The examples are simple in terms that it shows how easy it&amp;#39;s for example to write data back into Snowflake or to visualize a map data. &lt;/p&gt;\n\n&lt;p&gt;Hope you enjoy and had as much fun reading as I had writing this.   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5\"&gt;https://preview.redd.it/sgnvh0116xka1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2305e0a3080a28066343d0cb236af6ac587f38c5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11e4bv4", "is_robot_indexable": true, "report_reasons": null, "author": "Recordly_MHeino", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11e4bv4/introduction_to_streamlit_and_data_applications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11e4bv4/introduction_to_streamlit_and_data_applications/", "subreddit_subscribers": 91423, "created_utc": 1677585694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you structure your pandas ETL jobs? Do you have some predefined template/structure how do you apply steps to your dataframes? Do you apply the transformations on the dataframes right away or you create a separate functions for each transforming step? Do you use some micro-frameworks like for example [Hamilton](https://github.com/dagworks-inc/hamilton)?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas workflow template", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11dlu99", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677529508.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you structure your pandas ETL jobs? Do you have some predefined template/structure how do you apply steps to your dataframes? Do you apply the transformations on the dataframes right away or you create a separate functions for each transforming step? Do you use some micro-frameworks like for example &lt;a href=\"https://github.com/dagworks-inc/hamilton\"&gt;Hamilton&lt;/a&gt;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7lCtm758KvYl3NoNGokuMhmoEhM7aWXWDgVd5kqhPpE.jpg?auto=webp&amp;v=enabled&amp;s=7e647c2fe032b2efe1c8e86fadcd33540ed3318a", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/7lCtm758KvYl3NoNGokuMhmoEhM7aWXWDgVd5kqhPpE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9023c5cd1aa30963e66aa3d8c30ca94545f9d93", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/7lCtm758KvYl3NoNGokuMhmoEhM7aWXWDgVd5kqhPpE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d747f449845b4276445506cd5f33dcceda89bb6d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/7lCtm758KvYl3NoNGokuMhmoEhM7aWXWDgVd5kqhPpE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=861ecaa2e1b8b03513b7ed62e1839b6fe9743295", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/7lCtm758KvYl3NoNGokuMhmoEhM7aWXWDgVd5kqhPpE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fcca2b33479e11f211dda359a9b7538ae447662", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/7lCtm758KvYl3NoNGokuMhmoEhM7aWXWDgVd5kqhPpE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75561d3b421a585f0947c8a260caaf7142f15f08", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/7lCtm758KvYl3NoNGokuMhmoEhM7aWXWDgVd5kqhPpE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0a1b54ba8e8e0434783d28301591bb3e7f2aadd", "width": 1080, "height": 540}], "variants": {}, "id": "3YR5ZTzaTkBoH-5mexRRNuUftSAaFay-5D83JdeOsTM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11dlu99", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11dlu99/pandas_workflow_template/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11dlu99/pandas_workflow_template/", "subreddit_subscribers": 91423, "created_utc": 1677529508.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any benefit on using this technology nowadays? Is it still worth investing into? If not, which compelling arguments could i use to convince my managers to finally adopt cloud technologies?\nClient's management is considering to migrate hadoop jobs to kudu reason being it's a mess to manage updates in hdfs.\nI strongly feel like it could be a big mistake to invest in such niche and unpolular technologies. Considering possible time and effort required for the migration could be big, in my client's interest i would like to suggest a more future-proof and why not, more pleasant to work with technologies to accomplish our requirements (basically NRT reads from a kafka topic via apache spark and NRT updates of master data tables in a data store, currently done in full batch on hive tables over hdfs).\n\nThanks in advance", "author_fullname": "t2_3xvidrz9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone use Apache Kudu?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11do3cw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677534898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any benefit on using this technology nowadays? Is it still worth investing into? If not, which compelling arguments could i use to convince my managers to finally adopt cloud technologies?\nClient&amp;#39;s management is considering to migrate hadoop jobs to kudu reason being it&amp;#39;s a mess to manage updates in hdfs.\nI strongly feel like it could be a big mistake to invest in such niche and unpolular technologies. Considering possible time and effort required for the migration could be big, in my client&amp;#39;s interest i would like to suggest a more future-proof and why not, more pleasant to work with technologies to accomplish our requirements (basically NRT reads from a kafka topic via apache spark and NRT updates of master data tables in a data store, currently done in full batch on hive tables over hdfs).&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11do3cw", "is_robot_indexable": true, "report_reasons": null, "author": "RAT-000", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11do3cw/does_anyone_use_apache_kudu/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11do3cw/does_anyone_use_apache_kudu/", "subreddit_subscribers": 91423, "created_utc": 1677534898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Online it says the english version of the exam changed as of Feb 2023 and I\u2019ve been studying with some old materials along with the updated exam objectives. I\u2019m wondering if anyone has taken the new version and if it\u2019s drastically changed in any way.", "author_fullname": "t2_55onda91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone taken the updated version of DP-203?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11edx4t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677604040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Online it says the english version of the exam changed as of Feb 2023 and I\u2019ve been studying with some old materials along with the updated exam objectives. I\u2019m wondering if anyone has taken the new version and if it\u2019s drastically changed in any way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11edx4t", "is_robot_indexable": true, "report_reasons": null, "author": "bingbongpeepee", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11edx4t/has_anyone_taken_the_updated_version_of_dp203/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11edx4t/has_anyone_taken_the_updated_version_of_dp203/", "subreddit_subscribers": 91423, "created_utc": 1677604040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "## Or how to build a light weight data platform for a small organization from scratch? \n\nWe are an organization with a scale of around 300 people, and our administrative team wants to establish a data platform for aggregating, analyzing, and displaying some internal operational data. Our data volume is not large, so we do not need heavyweight distributed technologies. From the hardware requirements perspective, a bare metal server may be sufficient.\n\nHowever, on the other hand, we need the ability to extract, store, and ultimately present data from multiple sources on a reporting platform.  What I want to know is whether a lakehouse solution like Delta Lake is an ideal choice.\n\nWe do not have relevant implementation experience and hope to get some advice or recommended reference materials to help us better understand the relevant technologies.\n\n\n### Update\nI try to draw out a potential solution based on the discussion and knowledge we have.\n\n| Domain | Solution | Note |\n|-|-|-|\n| Data Warehouse | Clickhouse or PgSql | Lakehouse is overkill |\n| BI / Data App | SuperSet and Dash |  |\n| ETL | AirByte | Any suggestions? |", "author_fullname": "t2_m0cc1w3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to deploy a lakehouse solution on a bare metal server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ea84j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677604352.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677596960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h2&gt;Or how to build a light weight data platform for a small organization from scratch?&lt;/h2&gt;\n\n&lt;p&gt;We are an organization with a scale of around 300 people, and our administrative team wants to establish a data platform for aggregating, analyzing, and displaying some internal operational data. Our data volume is not large, so we do not need heavyweight distributed technologies. From the hardware requirements perspective, a bare metal server may be sufficient.&lt;/p&gt;\n\n&lt;p&gt;However, on the other hand, we need the ability to extract, store, and ultimately present data from multiple sources on a reporting platform.  What I want to know is whether a lakehouse solution like Delta Lake is an ideal choice.&lt;/p&gt;\n\n&lt;p&gt;We do not have relevant implementation experience and hope to get some advice or recommended reference materials to help us better understand the relevant technologies.&lt;/p&gt;\n\n&lt;h3&gt;Update&lt;/h3&gt;\n\n&lt;p&gt;I try to draw out a potential solution based on the discussion and knowledge we have.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Domain&lt;/th&gt;\n&lt;th&gt;Solution&lt;/th&gt;\n&lt;th&gt;Note&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;Data Warehouse&lt;/td&gt;\n&lt;td&gt;Clickhouse or PgSql&lt;/td&gt;\n&lt;td&gt;Lakehouse is overkill&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;BI / Data App&lt;/td&gt;\n&lt;td&gt;SuperSet and Dash&lt;/td&gt;\n&lt;td&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;ETL&lt;/td&gt;\n&lt;td&gt;AirByte&lt;/td&gt;\n&lt;td&gt;Any suggestions?&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11ea84j", "is_robot_indexable": true, "report_reasons": null, "author": "_link89_", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ea84j/is_it_possible_to_deploy_a_lakehouse_solution_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ea84j/is_it_possible_to_deploy_a_lakehouse_solution_on/", "subreddit_subscribers": 91423, "created_utc": 1677596960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am looking at docs and it is saying that mounting external cloud storage isn\u2019t best practice? If that\u2019s the case how do you guys work daily? I am new to databricks and not sure where notebooks, data should be stored and best practice working with cloud storage.\n\n1. If you have data in a data lake like s3/adls to u connect and pull it in or work with remotely?\n1a. If processing that data where do you write it? Back to s3 or dbfs?\n2. Purpose of dbfs if they say not to put data in it?\n3. Do you just mount your external cloud storage anyways?", "author_fullname": "t2_fqm3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practice with storage and databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ec67v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677599940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking at docs and it is saying that mounting external cloud storage isn\u2019t best practice? If that\u2019s the case how do you guys work daily? I am new to databricks and not sure where notebooks, data should be stored and best practice working with cloud storage.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;If you have data in a data lake like s3/adls to u connect and pull it in or work with remotely?\n1a. If processing that data where do you write it? Back to s3 or dbfs?&lt;/li&gt;\n&lt;li&gt;Purpose of dbfs if they say not to put data in it?&lt;/li&gt;\n&lt;li&gt;Do you just mount your external cloud storage anyways?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ec67v", "is_robot_indexable": true, "report_reasons": null, "author": "Bigchip01", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ec67v/best_practice_with_storage_and_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ec67v/best_practice_with_storage_and_databricks/", "subreddit_subscribers": 91423, "created_utc": 1677599940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, everyone.  \n\n\nI make a lot of diagrams to help visualize data pipelines, software architecture, and more.\n\nMy way-to-go tool in the past year and a half is [Whimiscal](https://whimsical.com/). It is by far one of the best tools I've used to make architectural diagrams. The main reason is that the end result is beautiful by default. They nailed the UI. I am an engineer with bad graphical design skills, but the result makes people think I invested a lot of time polishing the design of my visualizations, choosing the right color tone, aligning boxes, etc, which I didn't. The tool just helped me. Big win! :)   \n\n\nHowever, the free version has a limitation of 500 items. I am not sure I understand how they count items, but anyways, after a year and a half, I got close to the 500 items threshold. Actually, I got to the limit and had to delete some architectural diagrams I made, which I dislike doing.   \n\n\nI am considering some alternatives since I am not that heavy a user to consider paying for a graphing tool.  \n1. [Draw.io](https://Draw.io) \\-  It's forever free, but it is not pretty. My diagrams won't be as beautiful as the Whimsical ones. My architectural diagrams will seem like everyone else's and won't stand out in the crowd.\n\n2. [https://miro.com/](https://miro.com/) \\- Seems also a tool that nailed the UI and will help make beautiful diagrams without major efforts. But, also has a limit. By their pricing table, I couldn't really understand what it is. Maybe someone has used it and can throw some light.\n\n3. [https://www.taskade.com/](https://www.taskade.com/) \\- They say the free version has no limits. I wanted to try it out, but they force me to give my email, which I am not sure about. The tool is new and I didn't hear anyone using it, so I am not sure I can trust them. Moreover, looking at the website, without trying the tool itself, feels more like a mind-map tool. I need a diagramming tool for software architectural visualization. If someone has used it, I will appreciate some light as well.   \n\n\n4. Other alternatives?  \n\n\nThank you all. :)\n\n&amp;#x200B;\n\nSide note: Just to give an example, that's a whimsical example. Not mine. It is public for all users to see. My diagrams using the tool aren't that far from it. Isn't it beautiful? \n\n \n\nhttps://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41", "author_fullname": "t2_vd6ewwka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best free diagram tool alternative in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 99, "top_awarded_type": null, "hide_score": true, "media_metadata": {"21q1xw9gxyka1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0c1d4410700e9800eceb539e795806fdbc885705"}, {"y": 153, "x": 216, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fec057f9e1bef58cab753de0a440fe4b093d11d"}, {"y": 227, "x": 320, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9277b0e953f020ec4be8ccd27df9b7125ea8c475"}, {"y": 455, "x": 640, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=90eef4c9806596308eec1ef7e701721d80e996af"}, {"y": 683, "x": 960, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1be8e7f9ac22e597a2f3630321100972c82ac90a"}, {"y": 768, "x": 1080, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e725ee97909069fcef083679d7f78e4b397a693d"}], "s": {"y": 1154, "x": 1622, "u": "https://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41"}, "id": "21q1xw9gxyka1"}}, "name": "t3_11ef7lk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/9qqFweX1KyxDHUvJqEgNJvexAHar6Vut1z4OlW5Kep4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1677607178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, everyone.  &lt;/p&gt;\n\n&lt;p&gt;I make a lot of diagrams to help visualize data pipelines, software architecture, and more.&lt;/p&gt;\n\n&lt;p&gt;My way-to-go tool in the past year and a half is &lt;a href=\"https://whimsical.com/\"&gt;Whimiscal&lt;/a&gt;. It is by far one of the best tools I&amp;#39;ve used to make architectural diagrams. The main reason is that the end result is beautiful by default. They nailed the UI. I am an engineer with bad graphical design skills, but the result makes people think I invested a lot of time polishing the design of my visualizations, choosing the right color tone, aligning boxes, etc, which I didn&amp;#39;t. The tool just helped me. Big win! :)   &lt;/p&gt;\n\n&lt;p&gt;However, the free version has a limitation of 500 items. I am not sure I understand how they count items, but anyways, after a year and a half, I got close to the 500 items threshold. Actually, I got to the limit and had to delete some architectural diagrams I made, which I dislike doing.   &lt;/p&gt;\n\n&lt;p&gt;I am considering some alternatives since I am not that heavy a user to consider paying for a graphing tool.&lt;br/&gt;\n1. &lt;a href=\"https://Draw.io\"&gt;Draw.io&lt;/a&gt; -  It&amp;#39;s forever free, but it is not pretty. My diagrams won&amp;#39;t be as beautiful as the Whimsical ones. My architectural diagrams will seem like everyone else&amp;#39;s and won&amp;#39;t stand out in the crowd.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"https://miro.com/\"&gt;https://miro.com/&lt;/a&gt; - Seems also a tool that nailed the UI and will help make beautiful diagrams without major efforts. But, also has a limit. By their pricing table, I couldn&amp;#39;t really understand what it is. Maybe someone has used it and can throw some light.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;a href=\"https://www.taskade.com/\"&gt;https://www.taskade.com/&lt;/a&gt; - They say the free version has no limits. I wanted to try it out, but they force me to give my email, which I am not sure about. The tool is new and I didn&amp;#39;t hear anyone using it, so I am not sure I can trust them. Moreover, looking at the website, without trying the tool itself, feels more like a mind-map tool. I need a diagramming tool for software architectural visualization. If someone has used it, I will appreciate some light as well.   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Other alternatives?  &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you all. :)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Side note: Just to give an example, that&amp;#39;s a whimsical example. Not mine. It is public for all users to see. My diagrams using the tool aren&amp;#39;t that far from it. Isn&amp;#39;t it beautiful? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41\"&gt;https://preview.redd.it/21q1xw9gxyka1.png?width=1622&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=38d1fb208b45ad8e2c592883b9aaacc03cd7ee41&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?auto=webp&amp;v=enabled&amp;s=a9f6dad99adbc9a7fb64ea6f090216c19a9215b8", "width": 1744, "height": 912}, "resolutions": [{"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c5489caee9a35f72de0c4f2e0775f6eb01afb065", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8529c221c0d7aa4845c78526a5fc7357a5afa044", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7ab9417914f9d18499d85c65b7753c564ce2fbaa", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=917d95a02dd55147c6aff31f43b8bf8ed053ba78", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b218d1bb6fc94247a758630de5617148d71300d", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/Wsaen1JEdKQ8VEf04S7X3Q5wuJQlDObVj_0S646cDi4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70aba50d6cb83c288b36dc32148531496695af79", "width": 1080, "height": 564}], "variants": {}, "id": "k3XoPhRiwTJWBB72DdNhIHIqhF-cNikHtNW8qfA63mc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ef7lk", "is_robot_indexable": true, "report_reasons": null, "author": "yfeltz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ef7lk/best_free_diagram_tool_alternative_in_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ef7lk/best_free_diagram_tool_alternative_in_2023/", "subreddit_subscribers": 91423, "created_utc": 1677607178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w2y7e99", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Brace yourselves... \"professional\" Data Mesh developer job ads incoming!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_11eezyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7Fg-OCdcmezq19GoguvtGJK4781V_M-QvPVyOOof7-w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677606641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/u0xw0g77wyka1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?auto=webp&amp;v=enabled&amp;s=99eb928deaafeb0b6d3e137e8dc78d94286e08ed", "width": 1300, "height": 1583}, "resolutions": [{"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=64c0f173fca9655222e716d0e23c56aa440e8a97", "width": 108, "height": 131}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ec87f23838b5919a0744c3062abfa641a13b1f7", "width": 216, "height": 263}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c566574e632b461ca970f1e9fee8c7fa8cf7b314", "width": 320, "height": 389}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff9e57499592a22b228e11acce182fbde04bb1c0", "width": 640, "height": 779}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b2aa657a7b5a3b068cc69499f312ae26e285c94", "width": 960, "height": 1168}, {"url": "https://preview.redd.it/u0xw0g77wyka1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=694a1ba988e661acc0d902399b7decce6e4fb234", "width": 1080, "height": 1315}], "variants": {}, "id": "qwTGK3kHziyl0N7qLQfANNJvHWA3yaYv--CIWLyF-_g"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11eezyq", "is_robot_indexable": true, "report_reasons": null, "author": "whichalps", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eezyq/brace_yourselves_professional_data_mesh_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/u0xw0g77wyka1.jpg", "subreddit_subscribers": 91423, "created_utc": 1677606641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone i applied recently to a data engineering job but got rejected after passing technical interview and getting \u2248 80% on codility test,\n\nMy current job is python developer/data engineer basically where i am they had a project for about a year and a half and its done. \n\nI feel down and last time i practiced what i did as a data engineer was about 8 months ago, idk how to find a data engineering job anymore and more importantly how to practice what i know or need to know to actually land a job. \n\nI hope you help me find my way out of this", "author_fullname": "t2_i62lmiqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help getting on track", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11dlisz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677528739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone i applied recently to a data engineering job but got rejected after passing technical interview and getting \u2248 80% on codility test,&lt;/p&gt;\n\n&lt;p&gt;My current job is python developer/data engineer basically where i am they had a project for about a year and a half and its done. &lt;/p&gt;\n\n&lt;p&gt;I feel down and last time i practiced what i did as a data engineer was about 8 months ago, idk how to find a data engineering job anymore and more importantly how to practice what i know or need to know to actually land a job. &lt;/p&gt;\n\n&lt;p&gt;I hope you help me find my way out of this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11dlisz", "is_robot_indexable": true, "report_reasons": null, "author": "Fun-Resolution-1025", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11dlisz/help_getting_on_track/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11dlisz/help_getting_on_track/", "subreddit_subscribers": 91423, "created_utc": 1677528739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_66icy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Podcast: Real-Time Data Transformation and Analytics with dbtLabs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_11eem3t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jmFBCQFkX7o?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Real-Time Data Transformation and Analytics with dbt Labs\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Real-Time Data Transformation and Analytics with dbt Labs", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jmFBCQFkX7o?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Real-Time Data Transformation and Analytics with dbt Labs\"&gt;&lt;/iframe&gt;", "author_name": "Confluent", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/jmFBCQFkX7o/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Confluent"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jmFBCQFkX7o?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Real-Time Data Transformation and Analytics with dbt Labs\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/11eem3t", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WEHqDA4HP8d9TenEunduLXKz_pUso-fPBlbv-iM52JM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677605699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/jmFBCQFkX7o", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M3AO8mLqPD7qDTmVJFwpALqaVqxbFe-109Ol0nyNw2U.jpg?auto=webp&amp;v=enabled&amp;s=8b994133c91036f595dc275a79fe2920619b786d", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/M3AO8mLqPD7qDTmVJFwpALqaVqxbFe-109Ol0nyNw2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a696499e3d86e245a43ce3c9e77e430a81d8280", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/M3AO8mLqPD7qDTmVJFwpALqaVqxbFe-109Ol0nyNw2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a4babf2628c86e06215080ac78036c0c90d8339", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/M3AO8mLqPD7qDTmVJFwpALqaVqxbFe-109Ol0nyNw2U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fe583da01bdd051d7423d43822c4cc29f443fa02", "width": 320, "height": 240}], "variants": {}, "id": "-3kHx9E4aGvBSvGbdC7kc0J8XoJMcL-eVH8emK8RsWs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11eem3t", "is_robot_indexable": true, "report_reasons": null, "author": "krisajenkins", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eem3t/podcast_realtime_data_transformation_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/jmFBCQFkX7o", "subreddit_subscribers": 91423, "created_utc": 1677605699.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Real-Time Data Transformation and Analytics with dbt Labs", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/jmFBCQFkX7o?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Real-Time Data Transformation and Analytics with dbt Labs\"&gt;&lt;/iframe&gt;", "author_name": "Confluent", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/jmFBCQFkX7o/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@Confluent"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I have an upcoming interview for a mid-level data engineer role at a data consultancy in London. I have to do a multiple choice SQL test that runs against time, it does not involve coding. I looked online for mock tests but I don't know which one would be the equivalent in terms of difficulty. I browsed through the w3 schools quiz but its entry-level stuff. Any advice or links to a good mock test?", "author_fullname": "t2_r7bmwiee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11edtlt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677603806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have an upcoming interview for a mid-level data engineer role at a data consultancy in London. I have to do a multiple choice SQL test that runs against time, it does not involve coding. I looked online for mock tests but I don&amp;#39;t know which one would be the equivalent in terms of difficulty. I browsed through the w3 schools quiz but its entry-level stuff. Any advice or links to a good mock test?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11edtlt", "is_robot_indexable": true, "report_reasons": null, "author": "va1kyrja-kara", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11edtlt/interview_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11edtlt/interview_test/", "subreddit_subscribers": 91423, "created_utc": 1677603806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_975og", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evaluating dbt Cloud features vs dbt Core", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_11eemdf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UttijFwPZ1u1g62F5EWUoF-Orec7p60mkwvkxfwi3hQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677605717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datafold.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.datafold.com/blog/dbt-cloud", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?auto=webp&amp;v=enabled&amp;s=b59b8e8aa8edaf7fadc5fe1db0607dd6d67ec577", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a79fb773196462b6916386c7a151e69abeb90303", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b02290a513a8edf0bdc9df0ac3c21f0e8cb111c", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bada74c988b2d861be6e0fd2400f5912e7441398", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3702aaf99eb824c0065b4aff34a71f2547209299", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=080da950935f79bbc84fa9edb6f083ef22c84951", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/wFY89WUdaT4mT19l2eMljf5IV-p9BdvRrDW7P--pKGg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f59d1d35204b73984a1c663ac477c9bf84423df", "width": 1080, "height": 607}], "variants": {}, "id": "KmumNgjtFU6jMZRKV2HhNcHPL2ZZ2wK8w-aZVdTRkaQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11eemdf", "is_robot_indexable": true, "report_reasons": null, "author": "arimbr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11eemdf/evaluating_dbt_cloud_features_vs_dbt_core/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.datafold.com/blog/dbt-cloud", "subreddit_subscribers": 91423, "created_utc": 1677605717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I have just started tiny Data Analytics consulting firm. Currently I am the only employee, working full-time  at one client but planning to provide end to end service of Staff Aug as well complete Data Engineering project implementation service. Recently I came across Data conference [https://www.datacouncil.ai/austin](https://www.datacouncil.ai/austin). I have never been to this type of event in individual capacity. I think it should be great learning but do you know if this can be helpful get some connection to get client in future ? How should I use events like these ? If anyone has such experience and advice, that will be of great help.", "author_fullname": "t2_1u2bikk0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Conference", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11edhmg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677603024.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have just started tiny Data Analytics consulting firm. Currently I am the only employee, working full-time  at one client but planning to provide end to end service of Staff Aug as well complete Data Engineering project implementation service. Recently I came across Data conference &lt;a href=\"https://www.datacouncil.ai/austin\"&gt;https://www.datacouncil.ai/austin&lt;/a&gt;. I have never been to this type of event in individual capacity. I think it should be great learning but do you know if this can be helpful get some connection to get client in future ? How should I use events like these ? If anyone has such experience and advice, that will be of great help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?auto=webp&amp;v=enabled&amp;s=54e72a190e3a4e0e3e7412697d111a1d4164245f", "width": 1434, "height": 1434}, "resolutions": [{"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=712b54f3ba3432e501cc4ba9fba72776b722543a", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9eeb54f2d3f0388636f0b6c30d23acaaf892ab9d", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4724ad2f2c8c22bcf6f3d29edf73f5975a527d96", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e46045182cf4ea2bd1725215182a69ceafaf3ba7", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=652c5d744d177eabea48e38193f0a9985d19e198", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/_F5GUrm7PGzf7vLlLgeDXrjMiY-EMTAdHljTEzGNgEg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=18c77681ac295cf1d6523ab0a3856cb09db838ca", "width": 1080, "height": 1080}], "variants": {}, "id": "Fc1fxjSKNc0AhT9MqwkoW1xP4i7uEi4B67sxKyjzJl8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11edhmg", "is_robot_indexable": true, "report_reasons": null, "author": "ks4701", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11edhmg/data_conference/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11edhmg/data_conference/", "subreddit_subscribers": 91423, "created_utc": 1677603024.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I would very appreciate your help here, an important question about architecture modification.  \nWe use the ETL process to fetch data from external services (for example, Github).\n\n1. Extract the data (e.g. issues and PRs) and create raw\\_data objects\n2. Transform the data to our unique objects - let's call them assets.\n3. Load the assets as JSONs (jsonb field) to postgres DB (general assets table).\n\nWe have a few problems with this approach and now we are considering to change our pipeline.\n\n* **Bidirectional asset connection:** our assets have a direct relationship between them, for example, every user has groups, and every group has users.Currently we manually fill the data from one of the sides again and again (before loading the data to Postgres). We manage this in-memory (scale has entered the meeting)\n* **Very slow analysis:** we need the ability to present the whole JSON, but we also need to make an analysis between all of the assets.The problem is that if we have a lot of assets (a lot of JSONs inside of the assets table), the analysis is very slow. For example, 'find all issues that are related to the pull request', in this case we need to iterate over all of the internal JSONs and search with regex on a specific field.\n\nWhat would you recommend in this case?Suggestions:\n\n1. Manage it in Postgres, use functions to convert JSONs into tables, and create triggers to fill the Bidirectional relation.\n2. Data warehouse? I lack knowledge on the subject, but in general not sure it will be ideal, first of all because of OLAP vs OLTP, we need to make analysis but also the possibility to present the whole rows. And how would we fill the bidirectional connection?\n3. GraphDB? Sounds ideal for the bidirectional asset, but not sure about scaling problems.\n\nWhat do you think guys? What would you do in this case?", "author_fullname": "t2_64lh2w2sq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data pipeline modification - JSONs and graphs driven", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11ebv7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677599291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I would very appreciate your help here, an important question about architecture modification.&lt;br/&gt;\nWe use the ETL process to fetch data from external services (for example, Github).&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Extract the data (e.g. issues and PRs) and create raw_data objects&lt;/li&gt;\n&lt;li&gt;Transform the data to our unique objects - let&amp;#39;s call them assets.&lt;/li&gt;\n&lt;li&gt;Load the assets as JSONs (jsonb field) to postgres DB (general assets table).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We have a few problems with this approach and now we are considering to change our pipeline.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Bidirectional asset connection:&lt;/strong&gt; our assets have a direct relationship between them, for example, every user has groups, and every group has users.Currently we manually fill the data from one of the sides again and again (before loading the data to Postgres). We manage this in-memory (scale has entered the meeting)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Very slow analysis:&lt;/strong&gt; we need the ability to present the whole JSON, but we also need to make an analysis between all of the assets.The problem is that if we have a lot of assets (a lot of JSONs inside of the assets table), the analysis is very slow. For example, &amp;#39;find all issues that are related to the pull request&amp;#39;, in this case we need to iterate over all of the internal JSONs and search with regex on a specific field.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What would you recommend in this case?Suggestions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Manage it in Postgres, use functions to convert JSONs into tables, and create triggers to fill the Bidirectional relation.&lt;/li&gt;\n&lt;li&gt;Data warehouse? I lack knowledge on the subject, but in general not sure it will be ideal, first of all because of OLAP vs OLTP, we need to make analysis but also the possibility to present the whole rows. And how would we fill the bidirectional connection?&lt;/li&gt;\n&lt;li&gt;GraphDB? Sounds ideal for the bidirectional asset, but not sure about scaling problems.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;What do you think guys? What would you do in this case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11ebv7v", "is_robot_indexable": true, "report_reasons": null, "author": "ewenField", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11ebv7v/data_pipeline_modification_jsons_and_graphs_driven/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11ebv7v/data_pipeline_modification_jsons_and_graphs_driven/", "subreddit_subscribers": 91423, "created_utc": 1677599291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've been working with full files for quite some time now and was wondering what if the each file contain only a subset of total data, how can someone handle a situation where records are duplicated in 2 different files.", "author_fullname": "t2_t1rd5ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handling delta files in data lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11e3wgn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677584262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been working with full files for quite some time now and was wondering what if the each file contain only a subset of total data, how can someone handle a situation where records are duplicated in 2 different files.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11e3wgn", "is_robot_indexable": true, "report_reasons": null, "author": "PR0K1NG", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11e3wgn/handling_delta_files_in_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11e3wgn/handling_delta_files_in_data_lake/", "subreddit_subscribers": 91423, "created_utc": 1677584262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm storing metrics table in delta lake.   \nIs there any way to ingest this data through databricks (or any other tool) to sharepoint.  \nAnd then use it to visualize reports.  \n\n\nI don't want to go with power BI or other pricing tool. Is there any free way directly in sharepoint ?", "author_fullname": "t2_anqnfg2m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sharepoint as Reporting tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11dx0tg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677559185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m storing metrics table in delta lake.&lt;br/&gt;\nIs there any way to ingest this data through databricks (or any other tool) to sharepoint.&lt;br/&gt;\nAnd then use it to visualize reports.  &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to go with power BI or other pricing tool. Is there any free way directly in sharepoint ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11dx0tg", "is_robot_indexable": true, "report_reasons": null, "author": "saurrb", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11dx0tg/sharepoint_as_reporting_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11dx0tg/sharepoint_as_reporting_tool/", "subreddit_subscribers": 91423, "created_utc": 1677559185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is chaos engineering applicable to data pipelines? Yeah, nay, meh? \n\n[https://towardsdatascience.com/the-chaos-data-engineering-manifesto-5dc09a182e85?source=friends\\_link&amp;sk=05d2a17c0e1a736853cffd5f4a4d9482](https://towardsdatascience.com/the-chaos-data-engineering-manifesto-5dc09a182e85?source=friends_link&amp;sk=05d2a17c0e1a736853cffd5f4a4d9482)", "author_fullname": "t2_a49okn69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Chaos Data Engineering Manifesto", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11doz9v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677537066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is chaos engineering applicable to data pipelines? Yeah, nay, meh? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://towardsdatascience.com/the-chaos-data-engineering-manifesto-5dc09a182e85?source=friends_link&amp;amp;sk=05d2a17c0e1a736853cffd5f4a4d9482\"&gt;https://towardsdatascience.com/the-chaos-data-engineering-manifesto-5dc09a182e85?source=friends_link&amp;amp;sk=05d2a17c0e1a736853cffd5f4a4d9482&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/H_xuLJefUXCliZPNQK1-HuyCK9o5cNmhOVhICJGHBSM.jpg?auto=webp&amp;v=enabled&amp;s=9766b1150f219f0b8162d974d8e88030977b44fe", "width": 1200, "height": 799}, "resolutions": [{"url": "https://external-preview.redd.it/H_xuLJefUXCliZPNQK1-HuyCK9o5cNmhOVhICJGHBSM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b2f27f4fc40dee189afc186bb197f342e473a042", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/H_xuLJefUXCliZPNQK1-HuyCK9o5cNmhOVhICJGHBSM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01ed1779226a29b9442ebd68a2510e20c364a8cd", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/H_xuLJefUXCliZPNQK1-HuyCK9o5cNmhOVhICJGHBSM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d99aa18e186bead7c4f836457c61547b49a8cd3", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/H_xuLJefUXCliZPNQK1-HuyCK9o5cNmhOVhICJGHBSM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e66fdd19c7a5dc72646964ad2e33657f9895157", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/H_xuLJefUXCliZPNQK1-HuyCK9o5cNmhOVhICJGHBSM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09fe81c9ecf434ff4dd4ef6d8ceac9bae59708af", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/H_xuLJefUXCliZPNQK1-HuyCK9o5cNmhOVhICJGHBSM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aa8bdf5c1ed093a70ac7d2418f5d8d586a02cf0d", "width": 1080, "height": 719}], "variants": {}, "id": "kOfxTDZ_6hCNb8d7op6kp8aMstwvUTHmmqWb0nuDz8M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "11doz9v", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Substance2185", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11doz9v/chaos_data_engineering_manifesto/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11doz9v/chaos_data_engineering_manifesto/", "subreddit_subscribers": 91423, "created_utc": 1677537066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it true that relational databases are not good for reads of a lot of sequential data? I mean e.g. transaction logs consisting only of updates = you need to read all the transactions in the order? Is it too \u201cdifficult\u201d for the database? If technology is needed I mean for example TimescaleDB.\n\nAnd if that is the case - what would be the best way to read such data? Only reading pure files like parquet/avro?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RDBMS sequential reads", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11dk5is", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677525422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it true that relational databases are not good for reads of a lot of sequential data? I mean e.g. transaction logs consisting only of updates = you need to read all the transactions in the order? Is it too \u201cdifficult\u201d for the database? If technology is needed I mean for example TimescaleDB.&lt;/p&gt;\n\n&lt;p&gt;And if that is the case - what would be the best way to read such data? Only reading pure files like parquet/avro?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11dk5is", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11dk5is/rdbms_sequential_reads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11dk5is/rdbms_sequential_reads/", "subreddit_subscribers": 91423, "created_utc": 1677525422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "ETL (Extract, Transform, Load) and ELT (Extract, Load, Transform) are two different approaches for data integration in data warehousing.\n\nIn ETL, data is extracted from various sources, transformed to fit the target schema, and then loaded into the data warehouse. In contrast, ELT loads the raw data into the data warehouse and then applies transformations as needed.\n\nThe main advantage of ETL is that it can handle complex transformations and can be more efficient when dealing with large datasets. ELT, on the other hand, allows for faster loading of data and greater flexibility in performing transformations.\n\nUltimately, the choice between ETL and ELT will depend on the specific requirements and constraints of each data integration project.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/tm49toucpwka1.png?width=1466&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=509c3a4dc6d555f22a7f7927ff2c2d694ab34267", "author_fullname": "t2_jtca4f0z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL vs ELT: Check out the major differences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tm49toucpwka1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/tm49toucpwka1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5cf11bffa252465348ae77cc9d8c374833cb0c6b"}, {"y": 159, "x": 216, "u": "https://preview.redd.it/tm49toucpwka1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be57ca76fbb1ce14ca71284a043e314bbebcce90"}, {"y": 236, "x": 320, "u": "https://preview.redd.it/tm49toucpwka1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd79d4fcd69c61adcec4d0967f6d76d5ae712075"}, {"y": 473, "x": 640, "u": "https://preview.redd.it/tm49toucpwka1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f92c26b5ced72a5faa9f41bc174c393160780ea8"}, {"y": 709, "x": 960, "u": "https://preview.redd.it/tm49toucpwka1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f76e46536971112ff37adc4ca668a3b58d8a4cf"}, {"y": 798, "x": 1080, "u": "https://preview.redd.it/tm49toucpwka1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49c565df9a45a5d2662b67bb8c6b11e7e87733c4"}], "s": {"y": 1084, "x": 1466, "u": "https://preview.redd.it/tm49toucpwka1.png?width=1466&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=509c3a4dc6d555f22a7f7927ff2c2d694ab34267"}, "id": "tm49toucpwka1"}}, "name": "t3_11e2rqj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.42, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VmyF4Cx_rlvpJp8Ola9mFsLJW0SprwZA1cVkc6gHQgk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677580103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;ETL (Extract, Transform, Load) and ELT (Extract, Load, Transform) are two different approaches for data integration in data warehousing.&lt;/p&gt;\n\n&lt;p&gt;In ETL, data is extracted from various sources, transformed to fit the target schema, and then loaded into the data warehouse. In contrast, ELT loads the raw data into the data warehouse and then applies transformations as needed.&lt;/p&gt;\n\n&lt;p&gt;The main advantage of ETL is that it can handle complex transformations and can be more efficient when dealing with large datasets. ELT, on the other hand, allows for faster loading of data and greater flexibility in performing transformations.&lt;/p&gt;\n\n&lt;p&gt;Ultimately, the choice between ETL and ELT will depend on the specific requirements and constraints of each data integration project.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tm49toucpwka1.png?width=1466&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=509c3a4dc6d555f22a7f7927ff2c2d694ab34267\"&gt;https://preview.redd.it/tm49toucpwka1.png?width=1466&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=509c3a4dc6d555f22a7f7927ff2c2d694ab34267&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11e2rqj", "is_robot_indexable": true, "report_reasons": null, "author": "hardik-s", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11e2rqj/etl_vs_elt_check_out_the_major_differences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11e2rqj/etl_vs_elt_check_out_the_major_differences/", "subreddit_subscribers": 91423, "created_utc": 1677580103.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}