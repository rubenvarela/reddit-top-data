{"kind": "Listing", "data": {"after": "t3_111qiz7", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Should job posting with mentions of these tools be ignored or are they useful for a data scientists?", "author_fullname": "t2_17yq29", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What role does Tableau and Power BI play in your analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111lroh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676330349.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676326649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Should job posting with mentions of these tools be ignored or are they useful for a data scientists?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111lroh", "is_robot_indexable": true, "report_reasons": null, "author": "shastaslacker", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111lroh/what_role_does_tableau_and_power_bi_play_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111lroh/what_role_does_tableau_and_power_bi_play_in_your/", "subreddit_subscribers": 847789, "created_utc": 1676326649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I knew that I wanted to do something data-related (or computer science-based) for a long time, but unfortunately my undergrad major was completely unrelated to DS. I self-taught myself Python/R while working a marketing job and was suuper fortunate to get into a DS/DA Master\u2019s Program at one of the Ivy League schools. I worked 24/7 to learn a ton about best data practices/tools, had 2 DS co-ops, generated a ton of material for my GitHub, etc.\n\nObviously, just finishing a Master\u2019s program isn\u2019t enough to enter DS, so my career counselor recommended me to \u201ctake a data analyst job at a low-maturity company, use your skills to upgrade the way they use data, become a data rockstar and you\u2019ll get all kinds of doors opened in no time.\u201d **Spoiler** \\- *I did not become a data rockstar*.\n\nI landed a marketing analyst position at a large insurance company, and, long story short, this job is just a mess. My boss is a lifer that recently celebrated 20 years in the same position at the same company and got promoted to manager right as I joined. 30% of my work is shuffling around Excel sheets/making ugly (because the style is regulated) PowerPoints, another 30% is attending useless meetings that she sets up for me to \u201chear what conversations are happening around here\u201d; 20% is making sense of the broken SPSS code that someone wrote for her 15 years ago; the rest of the time is allocated to using Power BI, SQL and R to pull data from various sources and create reports for the internal stakeholders.\n\nNothing at my job is Googlable because all of the processes are either created by someone from 20 years ago or my manager herself; each process can require up to 100 little steps of moving data between million Excel spreadsheets populated with billion formulas making it impossible to comprehend or even load. The documentation she provides me with is always incorrect/incomplete, forcing me to ask for her help, as it would take me many hours to figure this out myself. When I try to do things my way, she gets clearly upset and sometimes starts micromanaging me, making us miss a ton of deadlines just for the sake of making everything look perfect according to the internal standards.\u00a0\n\nI spend a ton of time outside of work hours (the last one to leave the office every single day) trying to make time for extra DS projects but the amount of \u201chigh-priority\u201d tasks I get assigned is too overwhelming. The most technical thing I've done is used VDI to automate an R script that imports a bunch of files, anti-joins them and outputs certain distributions into an Excel doc, but that was a one-time project. I told my manager that I enjoy coding the most and she promised to land me a \u201ccoding-heavy\u201d project with the DS team. However, I followed up 3 times throughout a month and she ended up telling me that the person who asked for help decided to leave the company (jeez I wonder why.)\u00a0\n\nI get so much stress from a seemingly \u201ceasy\u201d job (no one seems to care that everything is 2+ weeks past due or indefinitely undelivered) because I\u2019m trying so hard to get a chance to make an impact and have at least something I can use when applying for DS roles after hitting that 1-year mark. I\u2019m afraid that the advanced skills I acquired are slowly fading away and I\u2019m learning a lot of bad habits from my manager.\n\nWhat would you recommend in my situation to stay on the right track? I usually work through my lunch breaks too (I know, I know), but I had an idea of maybe using that time to read a stats book or something DS-related - any suggestions? Any advice is appreciated :)\n\nEdit: the reason I put \"Ivy League School\" is because, a couple of months ago, my manager gave me an impossible task; I asked for a suggestion on how to better approach this task, and she responded with \"well, I'm not the one with the Master's Degree from the Ivy Leagues.\" I got so butthurt from this because I haven't brought it up once since joining the company lol.\n\nTLDR: want to break into DS through low-maturity analytics job but feeling like it has a negative effect on my career potential - tips?\u00a0", "author_fullname": "t2_6kb6g3y1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it a mistake to enter DS through low-maturity Data Analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111wcmt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676358583.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676357925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I knew that I wanted to do something data-related (or computer science-based) for a long time, but unfortunately my undergrad major was completely unrelated to DS. I self-taught myself Python/R while working a marketing job and was suuper fortunate to get into a DS/DA Master\u2019s Program at one of the Ivy League schools. I worked 24/7 to learn a ton about best data practices/tools, had 2 DS co-ops, generated a ton of material for my GitHub, etc.&lt;/p&gt;\n\n&lt;p&gt;Obviously, just finishing a Master\u2019s program isn\u2019t enough to enter DS, so my career counselor recommended me to \u201ctake a data analyst job at a low-maturity company, use your skills to upgrade the way they use data, become a data rockstar and you\u2019ll get all kinds of doors opened in no time.\u201d &lt;strong&gt;Spoiler&lt;/strong&gt; - &lt;em&gt;I did not become a data rockstar&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;I landed a marketing analyst position at a large insurance company, and, long story short, this job is just a mess. My boss is a lifer that recently celebrated 20 years in the same position at the same company and got promoted to manager right as I joined. 30% of my work is shuffling around Excel sheets/making ugly (because the style is regulated) PowerPoints, another 30% is attending useless meetings that she sets up for me to \u201chear what conversations are happening around here\u201d; 20% is making sense of the broken SPSS code that someone wrote for her 15 years ago; the rest of the time is allocated to using Power BI, SQL and R to pull data from various sources and create reports for the internal stakeholders.&lt;/p&gt;\n\n&lt;p&gt;Nothing at my job is Googlable because all of the processes are either created by someone from 20 years ago or my manager herself; each process can require up to 100 little steps of moving data between million Excel spreadsheets populated with billion formulas making it impossible to comprehend or even load. The documentation she provides me with is always incorrect/incomplete, forcing me to ask for her help, as it would take me many hours to figure this out myself. When I try to do things my way, she gets clearly upset and sometimes starts micromanaging me, making us miss a ton of deadlines just for the sake of making everything look perfect according to the internal standards.\u00a0&lt;/p&gt;\n\n&lt;p&gt;I spend a ton of time outside of work hours (the last one to leave the office every single day) trying to make time for extra DS projects but the amount of \u201chigh-priority\u201d tasks I get assigned is too overwhelming. The most technical thing I&amp;#39;ve done is used VDI to automate an R script that imports a bunch of files, anti-joins them and outputs certain distributions into an Excel doc, but that was a one-time project. I told my manager that I enjoy coding the most and she promised to land me a \u201ccoding-heavy\u201d project with the DS team. However, I followed up 3 times throughout a month and she ended up telling me that the person who asked for help decided to leave the company (jeez I wonder why.)\u00a0&lt;/p&gt;\n\n&lt;p&gt;I get so much stress from a seemingly \u201ceasy\u201d job (no one seems to care that everything is 2+ weeks past due or indefinitely undelivered) because I\u2019m trying so hard to get a chance to make an impact and have at least something I can use when applying for DS roles after hitting that 1-year mark. I\u2019m afraid that the advanced skills I acquired are slowly fading away and I\u2019m learning a lot of bad habits from my manager.&lt;/p&gt;\n\n&lt;p&gt;What would you recommend in my situation to stay on the right track? I usually work through my lunch breaks too (I know, I know), but I had an idea of maybe using that time to read a stats book or something DS-related - any suggestions? Any advice is appreciated :)&lt;/p&gt;\n\n&lt;p&gt;Edit: the reason I put &amp;quot;Ivy League School&amp;quot; is because, a couple of months ago, my manager gave me an impossible task; I asked for a suggestion on how to better approach this task, and she responded with &amp;quot;well, I&amp;#39;m not the one with the Master&amp;#39;s Degree from the Ivy Leagues.&amp;quot; I got so butthurt from this because I haven&amp;#39;t brought it up once since joining the company lol.&lt;/p&gt;\n\n&lt;p&gt;TLDR: want to break into DS through low-maturity analytics job but feeling like it has a negative effect on my career potential - tips?\u00a0&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111wcmt", "is_robot_indexable": true, "report_reasons": null, "author": "busy_bee_movie", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111wcmt/is_it_a_mistake_to_enter_ds_through_lowmaturity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111wcmt/is_it_a_mistake_to_enter_ds_through_lowmaturity/", "subreddit_subscribers": 847789, "created_utc": 1676357925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in my second semester of a data science masters and I'm trying to look for internships but also have no interest in working at a FAANG company. Whenever I try to search for internships it's mostly those giant companies with all the results. Does anyone have a way to search for internships at lesser known companies?", "author_fullname": "t2_vruv52hj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find internships/jobs at smaller companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1126jck", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676384526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in my second semester of a data science masters and I&amp;#39;m trying to look for internships but also have no interest in working at a FAANG company. Whenever I try to search for internships it&amp;#39;s mostly those giant companies with all the results. Does anyone have a way to search for internships at lesser known companies?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1126jck", "is_robot_indexable": true, "report_reasons": null, "author": "sdgso666", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1126jck/how_to_find_internshipsjobs_at_smaller_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1126jck/how_to_find_internshipsjobs_at_smaller_companies/", "subreddit_subscribers": 847789, "created_utc": 1676384526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hey, im currently a 3rd year data science student looking to improve my DSA skills. I have some knowledge about DSA in C++ but i find C++ quite hard. i came across [this](https://www.udemy.com/course/data-structures-and-algorithms-bootcamp-in-python/) course which is DSA using python. Seem to cover most of the topics and has coding exercises and a few projects as well.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/dzyq3sdbn4ia1.png?width=1919&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2b77018ed3f7b99efadc2097c62725ed58034df1\n\nCan anyone share their experience if they have taken this course? is it worth it? Thanks!", "author_fullname": "t2_ch7655b2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is this a good DSA course?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dzyq3sdbn4ia1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 52, "x": 108, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d3c0d1cce45ff648fb146d272beaefd9c7e10e1"}, {"y": 104, "x": 216, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b676f578fdf5a625c710ef785b1ab8c267569fb"}, {"y": 154, "x": 320, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e0d7a9ef89c17f958cd48d6c4e4a8b03a4f8d52"}, {"y": 309, "x": 640, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afe34c3669233fcbd077da6638565b3029784ea4"}, {"y": 464, "x": 960, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=18cabdd4be6c73373bf306a9d99e3fd40f4c3acf"}, {"y": 522, "x": 1080, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e0e44fa17cf89e757cb762f774cec8a89626c50"}], "s": {"y": 929, "x": 1919, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=1919&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2b77018ed3f7b99efadc2097c62725ed58034df1"}, "id": "dzyq3sdbn4ia1"}}, "name": "t3_1120x9u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LdZ5dXEqoN07EJIBk_dOsRGeSgGydtxuY3fmEbQKC-o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1676369188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey, im currently a 3rd year data science student looking to improve my DSA skills. I have some knowledge about DSA in C++ but i find C++ quite hard. i came across &lt;a href=\"https://www.udemy.com/course/data-structures-and-algorithms-bootcamp-in-python/\"&gt;this&lt;/a&gt; course which is DSA using python. Seem to cover most of the topics and has coding exercises and a few projects as well.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dzyq3sdbn4ia1.png?width=1919&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2b77018ed3f7b99efadc2097c62725ed58034df1\"&gt;https://preview.redd.it/dzyq3sdbn4ia1.png?width=1919&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2b77018ed3f7b99efadc2097c62725ed58034df1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Can anyone share their experience if they have taken this course? is it worth it? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1UyxmMpDV4aOgzMDSsaH07C7J3ugsS2_rvR_fbJwOLs.jpg?auto=webp&amp;v=enabled&amp;s=2b6c15109bf537458fe84f654f0878e99a414666", "width": 480, "height": 270}, "resolutions": [{"url": "https://external-preview.redd.it/1UyxmMpDV4aOgzMDSsaH07C7J3ugsS2_rvR_fbJwOLs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e376fe87d706de37aa9fb69329a5b250391e04bf", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/1UyxmMpDV4aOgzMDSsaH07C7J3ugsS2_rvR_fbJwOLs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b1199fcd770c83cc79cbf0acd3e44aaaa9b2575", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/1UyxmMpDV4aOgzMDSsaH07C7J3ugsS2_rvR_fbJwOLs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e3cf345702747971dcdeeb972e10179defed76a", "width": 320, "height": 180}], "variants": {}, "id": "wTDgQS8KR6GH3dRBl51MiRq4yzRC5eYjErPu00M2_Vc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1120x9u", "is_robot_indexable": true, "report_reasons": null, "author": "swift__7", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1120x9u/is_this_a_good_dsa_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1120x9u/is_this_a_good_dsa_course/", "subreddit_subscribers": 847789, "created_utc": 1676369188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I'm currently in my 6 month journey learning DS( I come from a mechanical engineering background), and I was wondering what tools/topics should I focus on if I want to get an entry level job in data science in the field of cancer research? \nIf anyone had an idea about this topic I would really appreciate your insight. Thank you!", "author_fullname": "t2_8773zq8m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going into cancer research in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111m24k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676327352.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m currently in my 6 month journey learning DS( I come from a mechanical engineering background), and I was wondering what tools/topics should I focus on if I want to get an entry level job in data science in the field of cancer research? \nIf anyone had an idea about this topic I would really appreciate your insight. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111m24k", "is_robot_indexable": true, "report_reasons": null, "author": "baydati", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111m24k/going_into_cancer_research_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111m24k/going_into_cancer_research_in_data_science/", "subreddit_subscribers": 847789, "created_utc": 1676327352.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'd love some clarification on these dimensionality reduction methods. I see PCA/PCR recommended as the go-to method for this type of task and almost never see people talk about using PLS to get principal components. It's my understanding that the key difference is that PLS considers the target when making components. \n\nIntuitively, I feel like this would make PLS stronger in many datasets, as it uses more of the available information to better inform the creation of components. I'm not an expert here and don't actually have a ton of expertise with how either of these methods work on a deep level, so any feedback from more experienced data scientists would be much appreciated. Thanks in advance for any thoughts or opinions here!", "author_fullname": "t2_vj9xwd07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is PCR recommended much more often than PLS for dimension reduction?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111kw8i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676324549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;d love some clarification on these dimensionality reduction methods. I see PCA/PCR recommended as the go-to method for this type of task and almost never see people talk about using PLS to get principal components. It&amp;#39;s my understanding that the key difference is that PLS considers the target when making components. &lt;/p&gt;\n\n&lt;p&gt;Intuitively, I feel like this would make PLS stronger in many datasets, as it uses more of the available information to better inform the creation of components. I&amp;#39;m not an expert here and don&amp;#39;t actually have a ton of expertise with how either of these methods work on a deep level, so any feedback from more experienced data scientists would be much appreciated. Thanks in advance for any thoughts or opinions here!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111kw8i", "is_robot_indexable": true, "report_reasons": null, "author": "NDVGuy", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111kw8i/why_is_pcr_recommended_much_more_often_than_pls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111kw8i/why_is_pcr_recommended_much_more_often_than_pls/", "subreddit_subscribers": 847789, "created_utc": 1676324549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I want to start my first projects for my portfolio. Do the data need to be somewhat new or collected by me either from polls or whatever or with APIS? Also has the code have to be unique than others? Because I am not thaaat good(still a student) to code something great or whatever and I feel like my effort will be something no one will see because it\u2019ll be something an experienced data science could manage In 30 minutes and I\u2019m getting disheartened.", "author_fullname": "t2_3jeruvyp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First data projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_112e7s1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676403831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I want to start my first projects for my portfolio. Do the data need to be somewhat new or collected by me either from polls or whatever or with APIS? Also has the code have to be unique than others? Because I am not thaaat good(still a student) to code something great or whatever and I feel like my effort will be something no one will see because it\u2019ll be something an experienced data science could manage In 30 minutes and I\u2019m getting disheartened.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "112e7s1", "is_robot_indexable": true, "report_reasons": null, "author": "Pataouga", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/112e7s1/first_data_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/112e7s1/first_data_projects/", "subreddit_subscribers": 847789, "created_utc": 1676403831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nMost of the time I only have my old laptop available without a dGPU and a 5 year old I7 dual core.\n\nTraining on the thing takes lots of time. What could you suggest for training models online?\nMy datasets are often in the 2-10gb Range. I don\u2019t have a problem to pay like 30-50 Euros monthly.\n\nI heard colab pro was super good but since they changed to the compute units model it got pretty meh? Or is it still good? Otherwise I heard about paperclip. \n\nWhat else can you recommend? I only want to train models online and then export them using joblib. I am also a Student just in Case there are some nice discounts. \n\nAppreciate any help!", "author_fullname": "t2_3n8ebct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Train ML Models cheap", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1125mhy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676382036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Most of the time I only have my old laptop available without a dGPU and a 5 year old I7 dual core.&lt;/p&gt;\n\n&lt;p&gt;Training on the thing takes lots of time. What could you suggest for training models online?\nMy datasets are often in the 2-10gb Range. I don\u2019t have a problem to pay like 30-50 Euros monthly.&lt;/p&gt;\n\n&lt;p&gt;I heard colab pro was super good but since they changed to the compute units model it got pretty meh? Or is it still good? Otherwise I heard about paperclip. &lt;/p&gt;\n\n&lt;p&gt;What else can you recommend? I only want to train models online and then export them using joblib. I am also a Student just in Case there are some nice discounts. &lt;/p&gt;\n\n&lt;p&gt;Appreciate any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1125mhy", "is_robot_indexable": true, "report_reasons": null, "author": "Tyson1405", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1125mhy/train_ml_models_cheap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1125mhy/train_ml_models_cheap/", "subreddit_subscribers": 847789, "created_utc": 1676382036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[This paper](https://arxiv.org/abs/2112.13299) is super interesting, and by the same author who introduced CUPED.\n\nIn short, experiments with one sided non-compliance can result in a watered down ATE due to few users actually engaging with the treatment.  This paper builds on the instrumental variables literature (which we leverage a lot for these types of experiments) to use cuped to further reduce variance.\n\nIts super interesting and really useful for those of us who run experiments and need to increase precision of our estimates.  Best of all, there is some fairly food code attached as a footnote.", "author_fullname": "t2_131vu3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zero to Hero: Exploiting Null Effects to Achieve Variance Reduction in Experiments with One-sided Triggering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111rr5g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": "", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "modflair", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676342770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://arxiv.org/abs/2112.13299\"&gt;This paper&lt;/a&gt; is super interesting, and by the same author who introduced CUPED.&lt;/p&gt;\n\n&lt;p&gt;In short, experiments with one sided non-compliance can result in a watered down ATE due to few users actually engaging with the treatment.  This paper builds on the instrumental variables literature (which we leverage a lot for these types of experiments) to use cuped to further reduce variance.&lt;/p&gt;\n\n&lt;p&gt;Its super interesting and really useful for those of us who run experiments and need to increase precision of our estimates.  Best of all, there is some fairly food code attached as a footnote.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111rr5g", "is_robot_indexable": true, "report_reasons": null, "author": "__compactsupport__", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/111rr5g/zero_to_hero_exploiting_null_effects_to_achieve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111rr5g/zero_to_hero_exploiting_null_effects_to_achieve/", "subreddit_subscribers": 847789, "created_utc": 1676342770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I am a finance enthusiast and would check American market data in dashboards in the countless free products that exist.\n\nHowever, being in a country with ridiculous foreign exchange policies, the government keeps blocking every service or broker I use so I am locked out of the international markets.\n\nI started looking at local companies and there is only One single brokerage app that is remotely viable and the data absolutely sucks. I was trying to web scrape the data from companies' websites and faced a few issues:\n\n1. Every company website is different and they do not all have the \"Investor relations\" page in the same place. How can I write one program to get the data of all the listed stocks? which are around\n2. All the websites I checked had the data in pdf documents that you download. This was a problem since I was trying to get the data right off the website HTML  and javascript code. The documents are also full of useless pages I do not need. I only need the tables.\n\nI can't find specific information on this because the entire modern world can just use **APIs** to get this kind of data. I am absolutely certain that does not exist for the Egyptian exchange. At least at a price below thousands of dollars.\n\nWhat can I start doing in order to collect this kind of data? It must be possible. I know organizations are capable of scraping the web for incredible amounts of data and useful information. How do they do it and how are these **APIs** made?\n\nHere is an example IR page for a company I'm interested in :\n\n[Telecom Egypt :: Investor Relations](https://ir.te.eg/en/)\n\n**Please Upvote so more people would see this.**", "author_fullname": "t2_390z4sn3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Collecting company financial data in a developing country. Where do the free APIs like yahoo finance get their data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_112eijl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676405504.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676404587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am a finance enthusiast and would check American market data in dashboards in the countless free products that exist.&lt;/p&gt;\n\n&lt;p&gt;However, being in a country with ridiculous foreign exchange policies, the government keeps blocking every service or broker I use so I am locked out of the international markets.&lt;/p&gt;\n\n&lt;p&gt;I started looking at local companies and there is only One single brokerage app that is remotely viable and the data absolutely sucks. I was trying to web scrape the data from companies&amp;#39; websites and faced a few issues:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Every company website is different and they do not all have the &amp;quot;Investor relations&amp;quot; page in the same place. How can I write one program to get the data of all the listed stocks? which are around&lt;/li&gt;\n&lt;li&gt;All the websites I checked had the data in pdf documents that you download. This was a problem since I was trying to get the data right off the website HTML  and javascript code. The documents are also full of useless pages I do not need. I only need the tables.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I can&amp;#39;t find specific information on this because the entire modern world can just use &lt;strong&gt;APIs&lt;/strong&gt; to get this kind of data. I am absolutely certain that does not exist for the Egyptian exchange. At least at a price below thousands of dollars.&lt;/p&gt;\n\n&lt;p&gt;What can I start doing in order to collect this kind of data? It must be possible. I know organizations are capable of scraping the web for incredible amounts of data and useful information. How do they do it and how are these &lt;strong&gt;APIs&lt;/strong&gt; made?&lt;/p&gt;\n\n&lt;p&gt;Here is an example IR page for a company I&amp;#39;m interested in :&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ir.te.eg/en/\"&gt;Telecom Egypt :: Investor Relations&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Please Upvote so more people would see this.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "112eijl", "is_robot_indexable": true, "report_reasons": null, "author": "mostafa1022", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/112eijl/collecting_company_financial_data_in_a_developing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/112eijl/collecting_company_financial_data_in_a_developing/", "subreddit_subscribers": 847789, "created_utc": 1676404587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I'm working on a task of classifying text complaints and I extracted some features like Named Entities, Events, Time Expressions, Semantic Role Labels, etc. I want to classify the text according to these features. My question is how do I encode this data in order to feed it to a classifier?\n\nHere is examples of data extracted:  \nnamed\\_entities: (FedEx, Israel, Paris) , (Zara, London, Chris), ...\n\ntime\\_expressions: ('2021-08-31', '31/08/2021') , ('30 August', '2019'), ...\n\nsrl: {\"verbs\": \\[{\"verb\": \"write\", \"description\": \"I \\[V: write\\] \\[A1: a complaint\\] \\[A2: to FedEx\\] .\", \"tags\": \\[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-A1\", \"I-A1\", \"B-A2\", \"I-A2\", \"O\"\\]}\\], \"words\": \\[\"I\", \"to\", \"FedEx\", \".\"\\]}, {}, ...\n\nevents: {'T1': 'come', 'T2': 'present', 'T3': 'send','T4': 'destination','T5': 'instrument'}, {'T1': 'loader', 'T2': 'bearer', 'T3': 'cargo'} , ...\n\nPreviously I used word embeddings to encode the full text but now that the information is in vectors I don't know how to proceed.", "author_fullname": "t2_vk9nf48t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "#NLP Text classification using NER, SRL, keywords", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_112dhmv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676401967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a task of classifying text complaints and I extracted some features like Named Entities, Events, Time Expressions, Semantic Role Labels, etc. I want to classify the text according to these features. My question is how do I encode this data in order to feed it to a classifier?&lt;/p&gt;\n\n&lt;p&gt;Here is examples of data extracted:&lt;br/&gt;\nnamed_entities: (FedEx, Israel, Paris) , (Zara, London, Chris), ...&lt;/p&gt;\n\n&lt;p&gt;time_expressions: (&amp;#39;2021-08-31&amp;#39;, &amp;#39;31/08/2021&amp;#39;) , (&amp;#39;30 August&amp;#39;, &amp;#39;2019&amp;#39;), ...&lt;/p&gt;\n\n&lt;p&gt;srl: {&amp;quot;verbs&amp;quot;: [{&amp;quot;verb&amp;quot;: &amp;quot;write&amp;quot;, &amp;quot;description&amp;quot;: &amp;quot;I [V: write] [A1: a complaint] [A2: to FedEx] .&amp;quot;, &amp;quot;tags&amp;quot;: [&amp;quot;O&amp;quot;, &amp;quot;O&amp;quot;, &amp;quot;O&amp;quot;, &amp;quot;O&amp;quot;, &amp;quot;O&amp;quot;, &amp;quot;O&amp;quot;, &amp;quot;B-V&amp;quot;, &amp;quot;B-A1&amp;quot;, &amp;quot;I-A1&amp;quot;, &amp;quot;B-A2&amp;quot;, &amp;quot;I-A2&amp;quot;, &amp;quot;O&amp;quot;]}], &amp;quot;words&amp;quot;: [&amp;quot;I&amp;quot;, &amp;quot;to&amp;quot;, &amp;quot;FedEx&amp;quot;, &amp;quot;.&amp;quot;]}, {}, ...&lt;/p&gt;\n\n&lt;p&gt;events: {&amp;#39;T1&amp;#39;: &amp;#39;come&amp;#39;, &amp;#39;T2&amp;#39;: &amp;#39;present&amp;#39;, &amp;#39;T3&amp;#39;: &amp;#39;send&amp;#39;,&amp;#39;T4&amp;#39;: &amp;#39;destination&amp;#39;,&amp;#39;T5&amp;#39;: &amp;#39;instrument&amp;#39;}, {&amp;#39;T1&amp;#39;: &amp;#39;loader&amp;#39;, &amp;#39;T2&amp;#39;: &amp;#39;bearer&amp;#39;, &amp;#39;T3&amp;#39;: &amp;#39;cargo&amp;#39;} , ...&lt;/p&gt;\n\n&lt;p&gt;Previously I used word embeddings to encode the full text but now that the information is in vectors I don&amp;#39;t know how to proceed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "112dhmv", "is_robot_indexable": true, "report_reasons": null, "author": "Big_Persimmon226", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/112dhmv/nlp_text_classification_using_ner_srl_keywords/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/112dhmv/nlp_text_classification_using_ner_srl_keywords/", "subreddit_subscribers": 847789, "created_utc": 1676401967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm searching something like Leetcode for practicing Data Science, no only SQL problems also calculus, statistics and thing like that.  \n\n\nAny recommendation?   \nPS: I dont care if i have to pay", "author_fullname": "t2_e8dlac8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leetcode for DS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_112dak7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676401464.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m searching something like Leetcode for practicing Data Science, no only SQL problems also calculus, statistics and thing like that.  &lt;/p&gt;\n\n&lt;p&gt;Any recommendation?&lt;br/&gt;\nPS: I dont care if i have to pay&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "112dak7", "is_robot_indexable": true, "report_reasons": null, "author": "edhastamorir", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/112dak7/leetcode_for_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/112dak7/leetcode_for_ds/", "subreddit_subscribers": 847789, "created_utc": 1676401464.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI wrote 2 posts together with 2 colleagues on how to solve a compression problem from the insurance industry. We applied the Simplex algorithm to compress the number of model points (every model point is an insurance contract component like life-insurance) and fit them to our benchmark. \n\nHope it's ok to post this here, we'd like to get some input on our approach :)\n\n[https://medium.com/@patrick\\_hoefler/optimizing-model-points-of-a-life-insurance-portfolio-e9a61f01c5bc](https://medium.com/@patrick_hoefler/optimizing-model-points-of-a-life-insurance-portfolio-e9a61f01c5bc)", "author_fullname": "t2_o3c8q92a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing model points of a life insurance portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1123lts", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676375709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I wrote 2 posts together with 2 colleagues on how to solve a compression problem from the insurance industry. We applied the Simplex algorithm to compress the number of model points (every model point is an insurance contract component like life-insurance) and fit them to our benchmark. &lt;/p&gt;\n\n&lt;p&gt;Hope it&amp;#39;s ok to post this here, we&amp;#39;d like to get some input on our approach :)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@patrick_hoefler/optimizing-model-points-of-a-life-insurance-portfolio-e9a61f01c5bc\"&gt;https://medium.com/@patrick_hoefler/optimizing-model-points-of-a-life-insurance-portfolio-e9a61f01c5bc&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?auto=webp&amp;v=enabled&amp;s=39b7487c11640083423cc5f72878e41d50c52985", "width": 1200, "height": 674}, "resolutions": [{"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a87dc5fd57601babd8cccd07ab08f152705db880", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=16d9dcb285e4a0fcedf09daf75fde631e365c811", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1da345e1a0183836f33f06324a40e14c3d07797b", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9deeede5e62a8a28bf2b79b6cc86e9f050424f0b", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25a9d51b8f7fd5b613cda0840d860d090b44dabb", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7dd54cb0ce0513b9e57426247a325066126e823b", "width": 1080, "height": 606}], "variants": {}, "id": "OpkwD9oERvd4BGZ6Ps_8K-Wx2LjHM1jpWRNbPL6rYvc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1123lts", "is_robot_indexable": true, "report_reasons": null, "author": "phofl93", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1123lts/optimizing_model_points_of_a_life_insurance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1123lts/optimizing_model_points_of_a_life_insurance/", "subreddit_subscribers": 847789, "created_utc": 1676375709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying create a predictive model for a binary outcome (yes or no).\nI have 16 predictor variables, which are a combination of categorical and continuous variables. How do I go about deciding which to include in my model?\n\nI can\u2019t find any literature on the requirements/assumptions of x in a logistic regression. I\u2019m modelling in R therefore I can\u2019t really add all variables and use a Backwards/Forwards variable selection method used in programs such as SAS.\n\n\nAppreciate any assistance!", "author_fullname": "t2_tir3dln2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deciding on Predictors for Logistic Regression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111xm2s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676362978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying create a predictive model for a binary outcome (yes or no).\nI have 16 predictor variables, which are a combination of categorical and continuous variables. How do I go about deciding which to include in my model?&lt;/p&gt;\n\n&lt;p&gt;I can\u2019t find any literature on the requirements/assumptions of x in a logistic regression. I\u2019m modelling in R therefore I can\u2019t really add all variables and use a Backwards/Forwards variable selection method used in programs such as SAS.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any assistance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111xm2s", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Elevator_814", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111xm2s/deciding_on_predictors_for_logistic_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111xm2s/deciding_on_predictors_for_logistic_regression/", "subreddit_subscribers": 847789, "created_utc": 1676362978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Junior DS here, based in Italy. Lately I was looking for opportunities (helping a friend of mine) and noticed very few Data Science positions in the market (LinkedIn), at least for entry level ones. Instead, I noticed a huge request for Data Engineering stuff. What about your country?\n\nMy idea about this is that, at least in Italy, academia is pushing DS a lot, but the average industry is quite behind that and still struggling with data architectures (hence the need for Data Engs), ingestion and processing.", "author_fullname": "t2_12nt66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lack of DS jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112c5wq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676398695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Junior DS here, based in Italy. Lately I was looking for opportunities (helping a friend of mine) and noticed very few Data Science positions in the market (LinkedIn), at least for entry level ones. Instead, I noticed a huge request for Data Engineering stuff. What about your country?&lt;/p&gt;\n\n&lt;p&gt;My idea about this is that, at least in Italy, academia is pushing DS a lot, but the average industry is quite behind that and still struggling with data architectures (hence the need for Data Engs), ingestion and processing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "112c5wq", "is_robot_indexable": true, "report_reasons": null, "author": "masc98", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/112c5wq/lack_of_ds_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/112c5wq/lack_of_ds_jobs/", "subreddit_subscribers": 847789, "created_utc": 1676398695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a very sparse matrix of users products, 120 users and 4000 products. each cell represents the users purchases of that specific product. \n\nEach month purchases are represented by a separate matrix, assuming the missing values represent  purchases that are not captured. How do I produce an estimate for purchases for each missing user/product pair?  \n\nEX:\n\nmatrix\\_1: has the purchases of users for different products in January\n\nmatrix\\_2: has the purchases of users for different products  in February\n\nmatrix\\_1: has the purchases of users for different products  in March\n\netc\n\n..\n\n..\n\nIs it a valid approach to have a single matrix for each month, or should we combine them somehow into a single matrix to capture the temporal nature of the problem?", "author_fullname": "t2_8jmib0lw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NMF for a user/product matrix", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112a4y3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676393620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a very sparse matrix of users products, 120 users and 4000 products. each cell represents the users purchases of that specific product. &lt;/p&gt;\n\n&lt;p&gt;Each month purchases are represented by a separate matrix, assuming the missing values represent  purchases that are not captured. How do I produce an estimate for purchases for each missing user/product pair?  &lt;/p&gt;\n\n&lt;p&gt;EX:&lt;/p&gt;\n\n&lt;p&gt;matrix_1: has the purchases of users for different products in January&lt;/p&gt;\n\n&lt;p&gt;matrix_2: has the purchases of users for different products  in February&lt;/p&gt;\n\n&lt;p&gt;matrix_1: has the purchases of users for different products  in March&lt;/p&gt;\n\n&lt;p&gt;etc&lt;/p&gt;\n\n&lt;p&gt;..&lt;/p&gt;\n\n&lt;p&gt;..&lt;/p&gt;\n\n&lt;p&gt;Is it a valid approach to have a single matrix for each month, or should we combine them somehow into a single matrix to capture the temporal nature of the problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "112a4y3", "is_robot_indexable": true, "report_reasons": null, "author": "Riolite55", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/112a4y3/nmf_for_a_userproduct_matrix/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/112a4y3/nmf_for_a_userproduct_matrix/", "subreddit_subscribers": 847789, "created_utc": 1676393620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for a free/open source alternative to AWS data wrangler.\nI'd like a unified platform where to:\n- visualize the data, possibly from multiple data sources and pre-configured visualizations\n- preprocess the data with no code solutions, but with the possibility to add code and export the data transformation in python code\n\nDoes anything like this exist?", "author_fullname": "t2_11tvii", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS data wrangler alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1123lnu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676375693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a free/open source alternative to AWS data wrangler.\nI&amp;#39;d like a unified platform where to:\n- visualize the data, possibly from multiple data sources and pre-configured visualizations\n- preprocess the data with no code solutions, but with the possibility to add code and export the data transformation in python code&lt;/p&gt;\n\n&lt;p&gt;Does anything like this exist?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1123lnu", "is_robot_indexable": true, "report_reasons": null, "author": "LumosNox99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1123lnu/aws_data_wrangler_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1123lnu/aws_data_wrangler_alternatives/", "subreddit_subscribers": 847789, "created_utc": 1676375693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to set up a ci/cd workflow for databricks, using github actions. There seems to be a couple of main choices. \n\n* Either executing the code using the runNotebook action, so the code runs on my existing databricks cluster. I am worried that this will be a bit hacky, as I would have to rely on running scripts from the notebook instead of just regular old python scripts. Getting results back and forth from the notebook to the vm running from github actions also seeems like a hurdle to implementing a good script.\n* Or setting up the yaml to replicate the databricks environment on the virtual machine that github actions spins up. I have tried the latter, but I struggle to get all the versions of java, scala, spark, pyton, packages etc to be identical an have my code execute without issue.\n\nI mainly have access to using databricks to write code, but I could consider using vscode on a local or virtual machine, or even coder as a web based alternative. Setting up a workflow using vscode and dbx is an option, but I do not want to use conda at the moment, which is what the quickstart seems to require.   \n\n\nWhat approach would you recommend? running on the existing cluster or setting up an identical environment in the yaml that fires up a vm in github actions?", "author_fullname": "t2_lqsp3ck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up a databricks ci/cd pipeline with github actions - executing code on databricks cluster vs github VM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1120wo2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676369168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to set up a ci/cd workflow for databricks, using github actions. There seems to be a couple of main choices. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Either executing the code using the runNotebook action, so the code runs on my existing databricks cluster. I am worried that this will be a bit hacky, as I would have to rely on running scripts from the notebook instead of just regular old python scripts. Getting results back and forth from the notebook to the vm running from github actions also seeems like a hurdle to implementing a good script.&lt;/li&gt;\n&lt;li&gt;Or setting up the yaml to replicate the databricks environment on the virtual machine that github actions spins up. I have tried the latter, but I struggle to get all the versions of java, scala, spark, pyton, packages etc to be identical an have my code execute without issue.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I mainly have access to using databricks to write code, but I could consider using vscode on a local or virtual machine, or even coder as a web based alternative. Setting up a workflow using vscode and dbx is an option, but I do not want to use conda at the moment, which is what the quickstart seems to require.   &lt;/p&gt;\n\n&lt;p&gt;What approach would you recommend? running on the existing cluster or setting up an identical environment in the yaml that fires up a vm in github actions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1120wo2", "is_robot_indexable": true, "report_reasons": null, "author": "Tullsokk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1120wo2/setting_up_a_databricks_cicd_pipeline_with_github/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1120wo2/setting_up_a_databricks_cicd_pipeline_with_github/", "subreddit_subscribers": 847789, "created_utc": 1676369168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\nAnswering  questions based on domain knowledge (like internal documentation,  contracts, books, etc.) is challenging because of the size of the domain  knowledge.\n\nAs you might know,  Transformer-based models are limited in terms of input size (most of the  time it's hard to use more than 2048 tokens). So you cannot really do  question answering on a huge knowledge base with these models.\n\nYou  can try to fine-tune your own text generation model for that (like  GPT-3, GPT-J, etc.) but results are sometimes disappointing as the  fine-tuned models tends to forget some of the facts mentioned in the  dataset...\n\nAt NLP Cloud, the  strategy we prefer is about mixing semantic search and question  answering. Here is a quick article about how to do it:\n\n[https://nlpcloud.com/question-answering-on-domain-knowledge-with-semantic-search-and-text-generation.html](https://nlpcloud.com/question-answering-on-domain-knowledge-with-semantic-search-and-text-generation.html?utm_source=reddit&amp;utm_campaign=h5d7a9cc-3816-11ed-a261-0242ac140006)\n\nAs far as we know, this is the best way to get both a fluent and user friendly answer while being very accurate.\n\nI would love to hear your thoughts on this. Can you think of a better strategy for question answering on very large documents?\n\nJulien", "author_fullname": "t2_4z4m2qcs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question Answering On Domain Knowledge With Semantic Search And Text Generation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1120br9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676368470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;Answering  questions based on domain knowledge (like internal documentation,  contracts, books, etc.) is challenging because of the size of the domain  knowledge.&lt;/p&gt;\n\n&lt;p&gt;As you might know,  Transformer-based models are limited in terms of input size (most of the  time it&amp;#39;s hard to use more than 2048 tokens). So you cannot really do  question answering on a huge knowledge base with these models.&lt;/p&gt;\n\n&lt;p&gt;You  can try to fine-tune your own text generation model for that (like  GPT-3, GPT-J, etc.) but results are sometimes disappointing as the  fine-tuned models tends to forget some of the facts mentioned in the  dataset...&lt;/p&gt;\n\n&lt;p&gt;At NLP Cloud, the  strategy we prefer is about mixing semantic search and question  answering. Here is a quick article about how to do it:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://nlpcloud.com/question-answering-on-domain-knowledge-with-semantic-search-and-text-generation.html?utm_source=reddit&amp;amp;utm_campaign=h5d7a9cc-3816-11ed-a261-0242ac140006\"&gt;https://nlpcloud.com/question-answering-on-domain-knowledge-with-semantic-search-and-text-generation.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As far as we know, this is the best way to get both a fluent and user friendly answer while being very accurate.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear your thoughts on this. Can you think of a better strategy for question answering on very large documents?&lt;/p&gt;\n\n&lt;p&gt;Julien&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?auto=webp&amp;v=enabled&amp;s=d3760fef3f1ab6bf1d1dbe5461b5e2df024b7dd7", "width": 1024, "height": 683}, "resolutions": [{"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f32d166764978c9cd7cea214169c858b7f31626", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=330e05b09bb97fe6ac21be1ffc757f8fa7cf101a", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb05b30bd6775eca0fdf8ab431ffd783c78a3c3d", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d3e65e7ececfa70c71c17229f1689ccf7e4e577", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49bce8862474499c1b35d696de560211bd6ba757", "width": 960, "height": 640}], "variants": {}, "id": "jQb1GRiS1-tsk2CyjgZgae0Y0DSRywZFiupWPpk_E6M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1120br9", "is_robot_indexable": true, "report_reasons": null, "author": "juliensalinas", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1120br9/question_answering_on_domain_knowledge_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1120br9/question_answering_on_domain_knowledge_with/", "subreddit_subscribers": 847789, "created_utc": 1676368470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\n\nRecently I have been interviewing with some companies for DS roles, and there were many case studies involved. When given the case and not much data (just might be a basic graph), how do you come up with the hypotheses and draw conclusions quickly? The tasks are generally interesting given the time and the data, but having to answer on spot throws me off.", "author_fullname": "t2_venbqmo3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS interviews (case study)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111xlvi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676362955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;Recently I have been interviewing with some companies for DS roles, and there were many case studies involved. When given the case and not much data (just might be a basic graph), how do you come up with the hypotheses and draw conclusions quickly? The tasks are generally interesting given the time and the data, but having to answer on spot throws me off.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111xlvi", "is_robot_indexable": true, "report_reasons": null, "author": "shajiegdvmd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111xlvi/ds_interviews_case_study/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111xlvi/ds_interviews_case_study/", "subreddit_subscribers": 847789, "created_utc": 1676362955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a3gidxwy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One On One. No One Else Around. I Will Beat Your Data Like A Cherokee Drum", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_111k9bn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OJBTbJMDd7ZdkzBpqFObgmXTOEx9zskvQv_0aKEHg0I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676323018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4btt1nkcv0ia1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?auto=webp&amp;v=enabled&amp;s=74a9e1111540f83fce2b7b6d604841264ed65bb0", "width": 684, "height": 843}, "resolutions": [{"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=388e1cca3081453a39843770fa4eb3477395b504", "width": 108, "height": 133}, {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d02972a76dba42ec2bf3fbec40a6f35d2af75c3", "width": 216, "height": 266}, {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e8b7db0a56d1d58826c76a114f3bdfa45b07d08", "width": 320, "height": 394}, {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81de2a46be2ed129061391d2c71ea690d27c690d", "width": 640, "height": 788}], "variants": {}, "id": "WAsQdHMFCuG8cMNg15KA-PY9857EguJW9u5YGkGdzaY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "111k9bn", "is_robot_indexable": true, "report_reasons": null, "author": "malirkan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111k9bn/one_on_one_no_one_else_around_i_will_beat_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4btt1nkcv0ia1.png", "subreddit_subscribers": 847789, "created_utc": 1676323018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, I am a sophomore in college who knows python decently well and is beginning to learn R. Would you recommend continuing to learn languages or to learn skills like reinforcement learning? Any help or advice would be greatly appreciated!", "author_fullname": "t2_gslj3kjr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Language Questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112aizd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676394570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I am a sophomore in college who knows python decently well and is beginning to learn R. Would you recommend continuing to learn languages or to learn skills like reinforcement learning? Any help or advice would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "112aizd", "is_robot_indexable": true, "report_reasons": null, "author": "BaldProgrammer7", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/112aizd/language_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/112aizd/language_questions/", "subreddit_subscribers": 847789, "created_utc": 1676394570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am looking for help and opinions on where to start with getting some \u201everified\u201c background on data science (besides doing Bachelors/Masters). Are there any courses / trainings / bootcamps that provide a good start as well as a (kind of) official certificate?\n\nBackground: I did my bachelors in applied linguistics (statistics was a big part of it, eg linear regression on text corpora to determine readability) and have an MBA. Currently I am working in a Compliance/Risk Management Team and kind of drifted to a data analysis side role. Regularly I write sql code to extract data from our databases and see what we can learn from it. As I had no prior experience, I learned it from scratch by trial and error, asking around and some online tutorials. \n\nI have of lot of fun doing this (exploring data, writing code) and am looking to steer my career towards that direction more. For starters, I was thinking of doing something official and have some training budget to spend. Hence my question: do you have any tips on trainings that also issue certificates (ideally stuff that means sth). I am typically more of a hands on guy and don\u2019t think doing a 800\u20ac training is better than learning with coursera - but maybe I can have it both?what do you guys think? Is that a good idea?  or should I just do a python bootcamp and start from there? I don\u2019t know much about the field in general and have just started gathering information so any related tips are also highly appreciated.\n(Ofc I did some googling but I am overwhelmed and would appreciate your expertise)", "author_fullname": "t2_c7ye47jd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Training / Accreditation in Data Science - best start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1122vt6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676373140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for help and opinions on where to start with getting some \u201everified\u201c background on data science (besides doing Bachelors/Masters). Are there any courses / trainings / bootcamps that provide a good start as well as a (kind of) official certificate?&lt;/p&gt;\n\n&lt;p&gt;Background: I did my bachelors in applied linguistics (statistics was a big part of it, eg linear regression on text corpora to determine readability) and have an MBA. Currently I am working in a Compliance/Risk Management Team and kind of drifted to a data analysis side role. Regularly I write sql code to extract data from our databases and see what we can learn from it. As I had no prior experience, I learned it from scratch by trial and error, asking around and some online tutorials. &lt;/p&gt;\n\n&lt;p&gt;I have of lot of fun doing this (exploring data, writing code) and am looking to steer my career towards that direction more. For starters, I was thinking of doing something official and have some training budget to spend. Hence my question: do you have any tips on trainings that also issue certificates (ideally stuff that means sth). I am typically more of a hands on guy and don\u2019t think doing a 800\u20ac training is better than learning with coursera - but maybe I can have it both?what do you guys think? Is that a good idea?  or should I just do a python bootcamp and start from there? I don\u2019t know much about the field in general and have just started gathering information so any related tips are also highly appreciated.\n(Ofc I did some googling but I am overwhelmed and would appreciate your expertise)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1122vt6", "is_robot_indexable": true, "report_reasons": null, "author": "GoblinSwineRider", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1122vt6/training_accreditation_in_data_science_best_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1122vt6/training_accreditation_in_data_science_best_start/", "subreddit_subscribers": 847789, "created_utc": 1676373140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I barely cared about internships and work experience. Im in my fourth year of college and I realized I should have done more. So I found out how to make my own projects and portfolio. Finally, landed my first unpaid DS + machine learning intern spot. Excited to learn on the job, but how should I be climbing up the ladder to better positions with better pay. The internship is a small commitment under 10 hours a week. What should I be doing on the side?", "author_fullname": "t2_1bswoe14", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to move up in the industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111vvya", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676356192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I barely cared about internships and work experience. Im in my fourth year of college and I realized I should have done more. So I found out how to make my own projects and portfolio. Finally, landed my first unpaid DS + machine learning intern spot. Excited to learn on the job, but how should I be climbing up the ladder to better positions with better pay. The internship is a small commitment under 10 hours a week. What should I be doing on the side?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111vvya", "is_robot_indexable": true, "report_reasons": null, "author": "RebornMoki", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111vvya/how_to_move_up_in_the_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111vvya/how_to_move_up_in_the_industry/", "subreddit_subscribers": 847789, "created_utc": 1676356192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9fjoqhty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning from Machine Learning | Maarten Grootendorst: BERTopic, Data Science, Psychology", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_111qiz7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pZRnHxmbgEfUBFtjXKz7mV-b92W4pedM5bfWbvpv_Ec.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676339210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/learning-from-machine-learning-maarten-grootendorst-bertopic-data-science-psychology-9ed9b9b2921", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?auto=webp&amp;v=enabled&amp;s=2af3de0a635567916d800533a55cd697c2e49709", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac44d9743c4c3701ddcba20ed12007d32035b414", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef2dc42af09e18b3c440be824a655fe8b8e8b76f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbde90fcc329d0cfbded61f4c62f7ec86a70fdc3", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a9ccf33aaa4b63f4c23022aa7b056517e3b9c8f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8430bc16a5c60ccbee8a158f1e13c87576300a3f", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2419d66fe039ef54b334eecb4b3c7721b766165", "width": 1080, "height": 607}], "variants": {}, "id": "Px4aCnL6kflFq7V1b0qLJPfpjZKoXMS83ENgNHOLdIA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "111qiz7", "is_robot_indexable": true, "report_reasons": null, "author": "NLPnerd", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111qiz7/learning_from_machine_learning_maarten/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/learning-from-machine-learning-maarten-grootendorst-bertopic-data-science-psychology-9ed9b9b2921", "subreddit_subscribers": 847789, "created_utc": 1676339210.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}