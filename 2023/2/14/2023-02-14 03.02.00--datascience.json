{"kind": "Listing", "data": {"after": "t3_111c9ju", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7b3mpu85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "you're an angel!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_111dnva", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 574, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 574, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fRQStMinHGCEMfJNW1fDwAN-WrKdyQIPa4hoDaumscM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676306633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/539jft6hizha1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/539jft6hizha1.jpg?auto=webp&amp;v=enabled&amp;s=698d7256b3867119033c96be6c48e90c971650b9", "width": 1062, "height": 1092}, "resolutions": [{"url": "https://preview.redd.it/539jft6hizha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9031897f37c64ce7b642c25d702717308dafef7b", "width": 108, "height": 111}, {"url": "https://preview.redd.it/539jft6hizha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4278d9727a077b0eec3dd838b5759170f3e1bcbb", "width": 216, "height": 222}, {"url": "https://preview.redd.it/539jft6hizha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fbe1515e438b8985385afc2b17623cd1496bebbd", "width": 320, "height": 329}, {"url": "https://preview.redd.it/539jft6hizha1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=abc1e4cf33111e2851e27c8e3e5b19cdc2514374", "width": 640, "height": 658}, {"url": "https://preview.redd.it/539jft6hizha1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3cfe01728f0e30a84798781b0537d8933e19b77b", "width": 960, "height": 987}], "variants": {}, "id": "-z2k3VtrVjUY1u9BHjb7MXRvRdYqO9kNH74Rp_GmBbw"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "111dnva", "is_robot_indexable": true, "report_reasons": null, "author": "BrilliantCashew", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111dnva/youre_an_angel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/539jft6hizha1.jpg", "subreddit_subscribers": 847566, "created_utc": 1676306633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, I started using ChatGPT to gather literature references for my scientific project. Love the information it gives me, clear, accurate and so far correct. It will also give me papers supporting these findings when asked. \n\nHOWEVER, none of these papers actually exist. I can't find them on google scholar, google, or anywhere else. They can't be found by title or author names. When I ask it for a DOI it happily provides one, but it either is not taken or leads to a different paper that has nothing to do with the topic. I thought translations from different languages could be the cause and it was actually a thing for some papers, but not even the english ones could be traced anywhere online.\n\nDoes ChatGPR just generate random papers that look damn much like real ones?\n\nhttps://preview.redd.it/s8sa42mzixha1.png?width=824&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70dfc38d58b6219ea4d494142e5f9e4b75e92a7a", "author_fullname": "t2_847qh0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ghost papers provided by ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 103, "top_awarded_type": null, "hide_score": false, "media_metadata": {"s8sa42mzixha1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/s8sa42mzixha1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8cf62f95b4939e92302401ac3415ff1031dc3973"}, {"y": 159, "x": 216, "u": "https://preview.redd.it/s8sa42mzixha1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a79390ea24a28023e4f9dbf264aa475bd4bb449"}, {"y": 236, "x": 320, "u": "https://preview.redd.it/s8sa42mzixha1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0506a6e16d52c4d02b690625d2a821aff58c78b2"}, {"y": 472, "x": 640, "u": "https://preview.redd.it/s8sa42mzixha1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e6a5f9c05bc37fd6b3153fe836906febb459633"}], "s": {"y": 608, "x": 824, "u": "https://preview.redd.it/s8sa42mzixha1.png?width=824&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70dfc38d58b6219ea4d494142e5f9e4b75e92a7a"}, "id": "s8sa42mzixha1"}}, "name": "t3_1114q7e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 306, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 306, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6L710ySDHoGPiIdfzIbF4wZzzb7RjK356OL7gPAbEvY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676282549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I started using ChatGPT to gather literature references for my scientific project. Love the information it gives me, clear, accurate and so far correct. It will also give me papers supporting these findings when asked. &lt;/p&gt;\n\n&lt;p&gt;HOWEVER, none of these papers actually exist. I can&amp;#39;t find them on google scholar, google, or anywhere else. They can&amp;#39;t be found by title or author names. When I ask it for a DOI it happily provides one, but it either is not taken or leads to a different paper that has nothing to do with the topic. I thought translations from different languages could be the cause and it was actually a thing for some papers, but not even the english ones could be traced anywhere online.&lt;/p&gt;\n\n&lt;p&gt;Does ChatGPR just generate random papers that look damn much like real ones?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/s8sa42mzixha1.png?width=824&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=70dfc38d58b6219ea4d494142e5f9e4b75e92a7a\"&gt;https://preview.redd.it/s8sa42mzixha1.png?width=824&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=70dfc38d58b6219ea4d494142e5f9e4b75e92a7a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1114q7e", "is_robot_indexable": true, "report_reasons": null, "author": "flexeltheman", "discussion_type": null, "num_comments": 130, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1114q7e/ghost_papers_provided_by_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1114q7e/ghost_papers_provided_by_chatgpt/", "subreddit_subscribers": 847566, "created_utc": 1676282549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "One very useful benefit I found with ChatGPT for job seekers is asking it to serve as a Hiring Manager that asks you questions for the specific role you're interested in.\n\nTo help it guide you, you need to provide it with some context based on the job description. For example, you list out the job description to ChatGPT and say that you want to be asked questions on causality and experimentation.\n\nHere's the response from ChatGPT based on the following prompt I provided it after sharing the job description:\n\n===**PROMPT BY ME===**\n\n&gt;I would like you to be a hiring manager. I'll be soon interviewing with you for a Data Science role, and you are going to ask me questions related to causality and experimentation. What are the questions you would ask to test my knowledge?\n\n**==RESPONSE BY CHATGPT===**\n\nSure! As a hiring manager for a data science role, I would like to assess your understanding of causality and experimentation. Here are a few questions I might ask:\n\n1. Can you explain the difference between correlation and causation, and give an example of each?\n2. How do you design an experiment to test a causal hypothesis?\n3. How do you ensure that the results of an experiment are valid and reliable?\n4. Can you explain the concept of confounding variables, and how do you control for them in an experiment?\n5. Can you explain the difference between a randomized controlled trial (RCT) and an observational study?\n6. How do you measure the impact of a treatment or intervention in an experiment?\n7. Have you worked with any causal inference methods such as propensity score matching or instrumental variables? Can you give an example of when you used them?\n8. How do you determine which variables to include in an experiment, and how do you avoid overfitting in the modeling process?\n9. Can you discuss any challenges or limitations you have encountered in designing and conducting experiments, and how you overcame them?\n10. Can you give an example of a real-world scenario in which you applied causal inference or experimentation methods to solve a business problem?\n\n====\n\nYou can ask ChatGPT to provide a summary answer for each. However, I would highly recommend you validate the answers by researching as well as ChatGPT can give confident, wrong answers.\n\nHope this helps others!", "author_fullname": "t2_48648", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Hunting Tip: Practice Interviewing with ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111h9pp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676315601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One very useful benefit I found with ChatGPT for job seekers is asking it to serve as a Hiring Manager that asks you questions for the specific role you&amp;#39;re interested in.&lt;/p&gt;\n\n&lt;p&gt;To help it guide you, you need to provide it with some context based on the job description. For example, you list out the job description to ChatGPT and say that you want to be asked questions on causality and experimentation.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the response from ChatGPT based on the following prompt I provided it after sharing the job description:&lt;/p&gt;\n\n&lt;p&gt;===&lt;strong&gt;PROMPT BY ME===&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I would like you to be a hiring manager. I&amp;#39;ll be soon interviewing with you for a Data Science role, and you are going to ask me questions related to causality and experimentation. What are the questions you would ask to test my knowledge?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;==RESPONSE BY CHATGPT===&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Sure! As a hiring manager for a data science role, I would like to assess your understanding of causality and experimentation. Here are a few questions I might ask:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can you explain the difference between correlation and causation, and give an example of each?&lt;/li&gt;\n&lt;li&gt;How do you design an experiment to test a causal hypothesis?&lt;/li&gt;\n&lt;li&gt;How do you ensure that the results of an experiment are valid and reliable?&lt;/li&gt;\n&lt;li&gt;Can you explain the concept of confounding variables, and how do you control for them in an experiment?&lt;/li&gt;\n&lt;li&gt;Can you explain the difference between a randomized controlled trial (RCT) and an observational study?&lt;/li&gt;\n&lt;li&gt;How do you measure the impact of a treatment or intervention in an experiment?&lt;/li&gt;\n&lt;li&gt;Have you worked with any causal inference methods such as propensity score matching or instrumental variables? Can you give an example of when you used them?&lt;/li&gt;\n&lt;li&gt;How do you determine which variables to include in an experiment, and how do you avoid overfitting in the modeling process?&lt;/li&gt;\n&lt;li&gt;Can you discuss any challenges or limitations you have encountered in designing and conducting experiments, and how you overcame them?&lt;/li&gt;\n&lt;li&gt;Can you give an example of a real-world scenario in which you applied causal inference or experimentation methods to solve a business problem?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;&lt;/h1&gt;\n\n&lt;p&gt;You can ask ChatGPT to provide a summary answer for each. However, I would highly recommend you validate the answers by researching as well as ChatGPT can give confident, wrong answers.&lt;/p&gt;\n\n&lt;p&gt;Hope this helps others!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111h9pp", "is_robot_indexable": true, "report_reasons": null, "author": "forbiscuit", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111h9pp/job_hunting_tip_practice_interviewing_with_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111h9pp/job_hunting_tip_practice_interviewing_with_chatgpt/", "subreddit_subscribers": 847566, "created_utc": 1676315601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I had an interview with an interesting question. I had a solution that would have worked which would have required a recursive query, but the interviewer said there is a simpler solution. I was wondering if anyone here could figure it out\n\nFour column table:\n\n     1. UserID- unique string\n     2. Device Id- unique string\n     3. session_start_time- timestamp\n     4. session_end_time- timestamp\n\nIt's possible for users with different deviceIds to have overlapping sessions. \nThe goal is to have one row per user per overlapping session.\nSo let's say that I have a session on my phone from 10:30-11:30, and on my computer from 10:45-11:45. The goal would be to aggregate this into a single row:\n\n     UserId|session_start|session_end\n     aaquad|10:30|11:45\n\nMy strategy was to use a lag to bring up the next row in order to be able to compare them- and the recursion would have been required in cases where a user had 3 or more overlapping sessions. But according to the interviewer, there is a different solution (I asked and did not get the answer).\n\nAny ideas?", "author_fullname": "t2_13b1f3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interesting SQL Interview Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111232h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676272042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had an interview with an interesting question. I had a solution that would have worked which would have required a recursive query, but the interviewer said there is a simpler solution. I was wondering if anyone here could figure it out&lt;/p&gt;\n\n&lt;p&gt;Four column table:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt; 1. UserID- unique string\n 2. Device Id- unique string\n 3. session_start_time- timestamp\n 4. session_end_time- timestamp\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;It&amp;#39;s possible for users with different deviceIds to have overlapping sessions. \nThe goal is to have one row per user per overlapping session.\nSo let&amp;#39;s say that I have a session on my phone from 10:30-11:30, and on my computer from 10:45-11:45. The goal would be to aggregate this into a single row:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt; UserId|session_start|session_end\n aaquad|10:30|11:45\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;My strategy was to use a lag to bring up the next row in order to be able to compare them- and the recursion would have been required in cases where a user had 3 or more overlapping sessions. But according to the interviewer, there is a different solution (I asked and did not get the answer).&lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111232h", "is_robot_indexable": true, "report_reasons": null, "author": "aaquad", "discussion_type": null, "num_comments": 35, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111232h/interesting_sql_interview_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111232h/interesting_sql_interview_question/", "subreddit_subscribers": 847566, "created_utc": 1676272042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was not happy in my job for a while. Dead-end project, under-resourced, people leaving constantly.\n\nI spoke up a number of times in how unhappy I am but my boss took it semi-seriously and didn't really take much action.\n\nI recently got a new offer, although only 12% higher total package. Seems like this offer is for more interesting work and generally in a more dynamic environment. It's a downgrade in title and offers a bit less security though.\n\nI attempted to resign today but my boss promised me a new project and a new team. While it will take maybe a couple of months to tie up lose ends, my boss is generally trustworthy. He seemed genuinely distressed and sad that I am thinking of leaving.\n\nI don't know what to do.", "author_fullname": "t2_vw0djvfd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tried to resign but my boss talked me out of it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1113cce", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676276983.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was not happy in my job for a while. Dead-end project, under-resourced, people leaving constantly.&lt;/p&gt;\n\n&lt;p&gt;I spoke up a number of times in how unhappy I am but my boss took it semi-seriously and didn&amp;#39;t really take much action.&lt;/p&gt;\n\n&lt;p&gt;I recently got a new offer, although only 12% higher total package. Seems like this offer is for more interesting work and generally in a more dynamic environment. It&amp;#39;s a downgrade in title and offers a bit less security though.&lt;/p&gt;\n\n&lt;p&gt;I attempted to resign today but my boss promised me a new project and a new team. While it will take maybe a couple of months to tie up lose ends, my boss is generally trustworthy. He seemed genuinely distressed and sad that I am thinking of leaving.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know what to do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1113cce", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Potato-9181", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1113cce/tried_to_resign_but_my_boss_talked_me_out_of_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1113cce/tried_to_resign_but_my_boss_talked_me_out_of_it/", "subreddit_subscribers": 847566, "created_utc": 1676276983.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a3gidxwy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use tools for automatic EDA? Which ones? Why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 124, "top_awarded_type": null, "hide_score": false, "name": "t3_111bdx7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/0n-XkGoK9DGBd2apAPMmt0LMqEZD_mgZ2OiYHWzsGVQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676300959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ebndmkmo1zha1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ebndmkmo1zha1.png?auto=webp&amp;v=enabled&amp;s=361760fbb896149ca6627a89a02e5c114c1e3d37", "width": 573, "height": 511}, "resolutions": [{"url": "https://preview.redd.it/ebndmkmo1zha1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=daeee7c14463aaf455054d332f8070a5890259c3", "width": 108, "height": 96}, {"url": "https://preview.redd.it/ebndmkmo1zha1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c9652ddc761884172b566f646aab38498570190d", "width": 216, "height": 192}, {"url": "https://preview.redd.it/ebndmkmo1zha1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74a098147bdc4010d91343568db317ee8b207aae", "width": 320, "height": 285}], "variants": {}, "id": "zdkAAF1c8bR8rK7ISrL8SFsPBgatJO54h2qCQfS2lRU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "111bdx7", "is_robot_indexable": true, "report_reasons": null, "author": "malirkan", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111bdx7/do_you_use_tools_for_automatic_eda_which_ones_why/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ebndmkmo1zha1.png", "subreddit_subscribers": 847566, "created_utc": 1676300959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Been getting a tad annoyed with Conda lately, at least as a package manager. So I wanted to hear what everyone else likes to use.", "author_fullname": "t2_dqghhocz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use to manage your Python packages and environments? Do you prefer Conda or something like virtualenv + pip?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111djvu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676306360.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been getting a tad annoyed with Conda lately, at least as a package manager. So I wanted to hear what everyone else likes to use.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111djvu", "is_robot_indexable": true, "report_reasons": null, "author": "CardboardBoxPlot", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111djvu/what_do_you_use_to_manage_your_python_packages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111djvu/what_do_you_use_to_manage_your_python_packages/", "subreddit_subscribers": 847566, "created_utc": 1676306360.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I'm currently in my 6 month journey learning DS( I come from a mechanical engineering background), and I was wondering what tools/topics should I focus on if I want to get an entry level job in data science in the field of cancer research? \nIf anyone had an idea about this topic I would really appreciate your insight. Thank you!", "author_fullname": "t2_8773zq8m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going into cancer research in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111m24k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676327352.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m currently in my 6 month journey learning DS( I come from a mechanical engineering background), and I was wondering what tools/topics should I focus on if I want to get an entry level job in data science in the field of cancer research? \nIf anyone had an idea about this topic I would really appreciate your insight. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111m24k", "is_robot_indexable": true, "report_reasons": null, "author": "baydati", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111m24k/going_into_cancer_research_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111m24k/going_into_cancer_research_in_data_science/", "subreddit_subscribers": 847566, "created_utc": 1676327352.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'd love some clarification on these dimensionality reduction methods. I see PCA/PCR recommended as the go-to method for this type of task and almost never see people talk about using PLS to get principal components. It's my understanding that the key difference is that PLS considers the target when making components. \n\nIntuitively, I feel like this would make PLS stronger in many datasets, as it uses more of the available information to better inform the creation of components. I'm not an expert here and don't actually have a ton of expertise with how either of these methods work on a deep level, so any feedback from more experienced data scientists would be much appreciated. Thanks in advance for any thoughts or opinions here!", "author_fullname": "t2_vj9xwd07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is PCR recommended much more often than PLS for dimension reduction?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111kw8i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676324549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;d love some clarification on these dimensionality reduction methods. I see PCA/PCR recommended as the go-to method for this type of task and almost never see people talk about using PLS to get principal components. It&amp;#39;s my understanding that the key difference is that PLS considers the target when making components. &lt;/p&gt;\n\n&lt;p&gt;Intuitively, I feel like this would make PLS stronger in many datasets, as it uses more of the available information to better inform the creation of components. I&amp;#39;m not an expert here and don&amp;#39;t actually have a ton of expertise with how either of these methods work on a deep level, so any feedback from more experienced data scientists would be much appreciated. Thanks in advance for any thoughts or opinions here!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111kw8i", "is_robot_indexable": true, "report_reasons": null, "author": "NDVGuy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111kw8i/why_is_pcr_recommended_much_more_often_than_pls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111kw8i/why_is_pcr_recommended_much_more_often_than_pls/", "subreddit_subscribers": 847566, "created_utc": 1676324549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Should job posting with mentions of these tools be ignored or are they useful for a data scientists?", "author_fullname": "t2_17yq29", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What role does Tableau and Power BI play in your analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111lroh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676330349.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676326649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Should job posting with mentions of these tools be ignored or are they useful for a data scientists?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111lroh", "is_robot_indexable": true, "report_reasons": null, "author": "shastaslacker", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111lroh/what_role_does_tableau_and_power_bi_play_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111lroh/what_role_does_tableau_and_power_bi_play_in_your/", "subreddit_subscribers": 847566, "created_utc": 1676326649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a3gidxwy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One On One. No One Else Around. I Will Beat Your Data Like A Cherokee Drum", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_111k9bn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OJBTbJMDd7ZdkzBpqFObgmXTOEx9zskvQv_0aKEHg0I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676323018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4btt1nkcv0ia1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?auto=webp&amp;v=enabled&amp;s=74a9e1111540f83fce2b7b6d604841264ed65bb0", "width": 684, "height": 843}, "resolutions": [{"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=388e1cca3081453a39843770fa4eb3477395b504", "width": 108, "height": 133}, {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d02972a76dba42ec2bf3fbec40a6f35d2af75c3", "width": 216, "height": 266}, {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e8b7db0a56d1d58826c76a114f3bdfa45b07d08", "width": 320, "height": 394}, {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81de2a46be2ed129061391d2c71ea690d27c690d", "width": 640, "height": 788}], "variants": {}, "id": "WAsQdHMFCuG8cMNg15KA-PY9857EguJW9u5YGkGdzaY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "111k9bn", "is_robot_indexable": true, "report_reasons": null, "author": "malirkan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111k9bn/one_on_one_no_one_else_around_i_will_beat_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4btt1nkcv0ia1.png", "subreddit_subscribers": 847566, "created_utc": 1676323018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vuozxz2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reverse causality (reverse causation): an important concept when analyzing time series data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111duqu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1676307109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dsdaily.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://dsdaily.substack.com/p/ds-daily-reverse-causality?sd=pf", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111duqu", "is_robot_indexable": true, "report_reasons": null, "author": "RAFisherman", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111duqu/reverse_causality_reverse_causation_an_important/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dsdaily.substack.com/p/ds-daily-reverse-causality?sd=pf", "subreddit_subscribers": 847566, "created_utc": 1676307109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI am a beginner in data analytics and I find it very interesting. For a school project we have a case where company A only has a ERP system where all the transactions happen and it is connected to a single Database(SQL). The question in this case is what solution would be appropiate because the company doesn't have the manpower and budget to maintain data analytics.\n\nWe have learned the basics of ETL, Data warehousing with the Visual Studio tool and connection with SSIS package. But I did some research and found out you can do ETL in powerBI. But how reliable is this? And do you have to keep changing the relationsships in PowerBI everytime you want to make a dashboard or does it stay like that? I need to make a few KPI and dasboards for this school project.\n\nThanks for advance responses", "author_fullname": "t2_1m0nn2zz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "School", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1113ep1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676277222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am a beginner in data analytics and I find it very interesting. For a school project we have a case where company A only has a ERP system where all the transactions happen and it is connected to a single Database(SQL). The question in this case is what solution would be appropiate because the company doesn&amp;#39;t have the manpower and budget to maintain data analytics.&lt;/p&gt;\n\n&lt;p&gt;We have learned the basics of ETL, Data warehousing with the Visual Studio tool and connection with SSIS package. But I did some research and found out you can do ETL in powerBI. But how reliable is this? And do you have to keep changing the relationsships in PowerBI everytime you want to make a dashboard or does it stay like that? I need to make a few KPI and dasboards for this school project.&lt;/p&gt;\n\n&lt;p&gt;Thanks for advance responses&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1113ep1", "is_robot_indexable": true, "report_reasons": null, "author": "superarcady", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1113ep1/school/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1113ep1/school/", "subreddit_subscribers": 847566, "created_utc": 1676277222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9fjoqhty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning from Machine Learning | Maarten Grootendorst: BERTopic, Data Science, Psychology", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_111qiz7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pZRnHxmbgEfUBFtjXKz7mV-b92W4pedM5bfWbvpv_Ec.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676339210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/learning-from-machine-learning-maarten-grootendorst-bertopic-data-science-psychology-9ed9b9b2921", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?auto=webp&amp;v=enabled&amp;s=2af3de0a635567916d800533a55cd697c2e49709", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac44d9743c4c3701ddcba20ed12007d32035b414", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef2dc42af09e18b3c440be824a655fe8b8e8b76f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbde90fcc329d0cfbded61f4c62f7ec86a70fdc3", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a9ccf33aaa4b63f4c23022aa7b056517e3b9c8f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8430bc16a5c60ccbee8a158f1e13c87576300a3f", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2419d66fe039ef54b334eecb4b3c7721b766165", "width": 1080, "height": 607}], "variants": {}, "id": "Px4aCnL6kflFq7V1b0qLJPfpjZKoXMS83ENgNHOLdIA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "111qiz7", "is_robot_indexable": true, "report_reasons": null, "author": "NLPnerd", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111qiz7/learning_from_machine_learning_maarten/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/learning-from-machine-learning-maarten-grootendorst-bertopic-data-science-psychology-9ed9b9b2921", "subreddit_subscribers": 847566, "created_utc": 1676339210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys,\n\nI'm working on a pet-project where I'm trying to predict rental prices in a city. I web scrapped data from Facebook Marketplace, but now I'm facing a problem. When I'm trying to extract the areas of the properties, I'm getting a lot of NaN values (\\~80%). I'm not sure how to deal with them correctly.\n\nI was thinking about using the mean or median values based on specific property type, number of bedrooms, and bathrooms. But I'm not sure if that's the best approach. I would appreciate any suggestions or advice on how to handle these NaN values.\n\nThanks in advance for your help!", "author_fullname": "t2_9spnm15l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help with handling NaN values in rental price prediction project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111h0jz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676314978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a pet-project where I&amp;#39;m trying to predict rental prices in a city. I web scrapped data from Facebook Marketplace, but now I&amp;#39;m facing a problem. When I&amp;#39;m trying to extract the areas of the properties, I&amp;#39;m getting a lot of NaN values (~80%). I&amp;#39;m not sure how to deal with them correctly.&lt;/p&gt;\n\n&lt;p&gt;I was thinking about using the mean or median values based on specific property type, number of bedrooms, and bathrooms. But I&amp;#39;m not sure if that&amp;#39;s the best approach. I would appreciate any suggestions or advice on how to handle these NaN values.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111h0jz", "is_robot_indexable": true, "report_reasons": null, "author": "Elegant_Bad1311", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111h0jz/need_help_with_handling_nan_values_in_rental/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111h0jz/need_help_with_handling_nan_values_in_rental/", "subreddit_subscribers": 847566, "created_utc": 1676314978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm attempting to experiment with BERTopic on a small set of review site data (less than 1000 small text passages). I'm on an Intel Macbook air that is a couple years old, running python v 3.9.13. I've worked through some initial errors related to hdbscan, and now am getting the following error.\n\n    segmentation fault  python ml_bertopic.py\n\nAfter some googling, I [found this](https://github.com/MaartenGr/BERTopic/issues/112) (but for M1 chip Mac) --I wonder if I'm stuck. Is this laptop just not up for the job of working with sentence transformers? Appreciate your advice\n\nHere's the full code. When I run this in Jupyter Notebook, the kernal dies\n\n    import csv\n    import json\n    from bertopic import BERTopic\n    import pandas as pd\n\n    comm_list = []\n\n    with open(\"comments_short.csv\", \"r\") as f:\n        for i in f:\n            comm_list.append(i)\n\n\n    print(comm_list[:5])\n\n    topic_model = BERTopic(embedding_model=\"all-MiniLM-L6-v2\", verbose=True)\n\n    topics, probs = topic_model.fit_transform(comm_list)\n\n    topic_model.get_topic_info()", "author_fullname": "t2_z075s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sentence transformers (BERTopic) on a Macbook Air", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111ghwu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676318158.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676313715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m attempting to experiment with BERTopic on a small set of review site data (less than 1000 small text passages). I&amp;#39;m on an Intel Macbook air that is a couple years old, running python v 3.9.13. I&amp;#39;ve worked through some initial errors related to hdbscan, and now am getting the following error.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;segmentation fault  python ml_bertopic.py\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;After some googling, I &lt;a href=\"https://github.com/MaartenGr/BERTopic/issues/112\"&gt;found this&lt;/a&gt; (but for M1 chip Mac) --I wonder if I&amp;#39;m stuck. Is this laptop just not up for the job of working with sentence transformers? Appreciate your advice&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the full code. When I run this in Jupyter Notebook, the kernal dies&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import csv\nimport json\nfrom bertopic import BERTopic\nimport pandas as pd\n\ncomm_list = []\n\nwith open(&amp;quot;comments_short.csv&amp;quot;, &amp;quot;r&amp;quot;) as f:\n    for i in f:\n        comm_list.append(i)\n\n\nprint(comm_list[:5])\n\ntopic_model = BERTopic(embedding_model=&amp;quot;all-MiniLM-L6-v2&amp;quot;, verbose=True)\n\ntopics, probs = topic_model.fit_transform(comm_list)\n\ntopic_model.get_topic_info()\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bQYcKp3txeUoQ7HHj5ruZ4vI4lqlfoFkBT0nIMKovCA.jpg?auto=webp&amp;v=enabled&amp;s=bbf226a9c6b0720dd81923963fd2f24a15641dc4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/bQYcKp3txeUoQ7HHj5ruZ4vI4lqlfoFkBT0nIMKovCA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=227d45a3f306bcfac12c4ceda1049ff3a0ff71c9", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/bQYcKp3txeUoQ7HHj5ruZ4vI4lqlfoFkBT0nIMKovCA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2c6e4812556d1a69709eadc8eeccde110b39f43f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/bQYcKp3txeUoQ7HHj5ruZ4vI4lqlfoFkBT0nIMKovCA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9df78f0a92990abc3e8a390953bef7ba97b11609", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/bQYcKp3txeUoQ7HHj5ruZ4vI4lqlfoFkBT0nIMKovCA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae675f42c933fce8c3cc320c4c9e6b5dbff2492f", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/bQYcKp3txeUoQ7HHj5ruZ4vI4lqlfoFkBT0nIMKovCA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=118a9b11bdd6f7776c173b903a98b220803d900d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/bQYcKp3txeUoQ7HHj5ruZ4vI4lqlfoFkBT0nIMKovCA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26b9b660367bfc5b57f6ccc2a5c92fe433a8f70a", "width": 1080, "height": 540}], "variants": {}, "id": "S1XXqx7VXEl0y3YXL_GIXCAq06KFO9bt-xoKMSyC1Gc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111ghwu", "is_robot_indexable": true, "report_reasons": null, "author": "mogla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111ghwu/sentence_transformers_bertopic_on_a_macbook_air/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111ghwu/sentence_transformers_bertopic_on_a_macbook_air/", "subreddit_subscribers": 847566, "created_utc": 1676313715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am plotting my result, and the surface plot look really off. I know I am plotting right just its shape is not the best for clearness in 3D. Should I rotate or something or just use a heatmap instead of a surface plot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "name": "t3_11188bo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_70mnmect", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kex9KJDZoklIwlieJpu0bii6k_Jz0vJrrSlqScJ07QQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "labrats", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/0in8x9m7jyha1.png?width=1113&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3e50fe556f69570e5ea2c50973d440584fc6a6a8\n\nI used another dataset for similar shape so that my PI wont kill me", "author_fullname": "t2_70mnmect", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am plotting my result, and the surface plot look really off. I know I am plotting right just its shape is not the best for clearness in 3D. Should I rotate or something or just use a heatmap instead of a surface plot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/labrats", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "media_metadata": {"0in8x9m7jyha1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/0in8x9m7jyha1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d95166fa29b40fe643aa853bc1fa0abfa561165"}, {"y": 161, "x": 216, "u": "https://preview.redd.it/0in8x9m7jyha1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fe0b4b6cd770c5d458aa872c92d5375a6b10447"}, {"y": 239, "x": 320, "u": "https://preview.redd.it/0in8x9m7jyha1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c159efdd5754aaa58d36b9f9bde00a7be5eaab7"}, {"y": 479, "x": 640, "u": "https://preview.redd.it/0in8x9m7jyha1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e9715f18e6d2e63f27b9a61eb3a1fd4f18865e3"}, {"y": 719, "x": 960, "u": "https://preview.redd.it/0in8x9m7jyha1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eeb73c76ef5e6f72f1e9b5ac092bea4880c96e0a"}, {"y": 809, "x": 1080, "u": "https://preview.redd.it/0in8x9m7jyha1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d54e1c5906168529d31e4c7e8a4bba13f4c4e6f3"}], "s": {"y": 834, "x": 1113, "u": "https://preview.redd.it/0in8x9m7jyha1.png?width=1113&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3e50fe556f69570e5ea2c50973d440584fc6a6a8"}, "id": "0in8x9m7jyha1"}}, "name": "t3_111864p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "36fb6490-02ad-11e1-bcca-12313d192a33", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kex9KJDZoklIwlieJpu0bii6k_Jz0vJrrSlqScJ07QQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676294700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.labrats", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0in8x9m7jyha1.png?width=1113&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3e50fe556f69570e5ea2c50973d440584fc6a6a8\"&gt;https://preview.redd.it/0in8x9m7jyha1.png?width=1113&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3e50fe556f69570e5ea2c50973d440584fc6a6a8&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I used another dataset for similar shape so that my PI wont kill me&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "labrat that is in control group ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2srnv", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111864p", "is_robot_indexable": true, "report_reasons": null, "author": "Striking-Warning9533", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/labrats/comments/111864p/i_am_plotting_my_result_and_the_surface_plot_look/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/labrats/comments/111864p/i_am_plotting_my_result_and_the_surface_plot_look/", "subreddit_subscribers": 604933, "created_utc": 1676294700.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1676294885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.labrats", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/labrats/comments/111864p/i_am_plotting_my_result_and_the_surface_plot_look/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11188bo", "is_robot_indexable": true, "report_reasons": null, "author": "Striking-Warning9533", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_111864p", "author_flair_text_color": null, "permalink": "/r/datascience/comments/11188bo/i_am_plotting_my_result_and_the_surface_plot_look/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/labrats/comments/111864p/i_am_plotting_my_result_and_the_surface_plot_look/", "subreddit_subscribers": 847566, "created_utc": 1676294885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nI am working with a binary classification dataset with many features, and not much info about them. I made an extra trees classifier with an F1 of 0.99. I believe the data originated from a synthetic source, so I\u2019ll take that 0.99 as viable. \n\nAnyway, the many features give the most important ones about a 0.02 influence by itself. My question is, how can I see how these features may work together to influence the outcome? For example , perhaps features 3, 21, 78 create a 0.15 impact together. \n\nAny insight is appreciated!", "author_fullname": "t2_2f2zz72s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model interpretation with many features", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111884j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676294869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working with a binary classification dataset with many features, and not much info about them. I made an extra trees classifier with an F1 of 0.99. I believe the data originated from a synthetic source, so I\u2019ll take that 0.99 as viable. &lt;/p&gt;\n\n&lt;p&gt;Anyway, the many features give the most important ones about a 0.02 influence by itself. My question is, how can I see how these features may work together to influence the outcome? For example , perhaps features 3, 21, 78 create a 0.15 impact together. &lt;/p&gt;\n\n&lt;p&gt;Any insight is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111884j", "is_robot_indexable": true, "report_reasons": null, "author": "anon67543", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111884j/model_interpretation_with_many_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111884j/model_interpretation_with_many_features/", "subreddit_subscribers": 847566, "created_utc": 1676294869.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 13 Feb, 2023 - 20 Feb, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110zyau", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676264470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "110zyau", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 19, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/110zyau/weekly_entering_transitioning_thread_13_feb_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/110zyau/weekly_entering_transitioning_thread_13_feb_2023/", "subreddit_subscribers": 847566, "created_utc": 1676264470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, as You can read in the title I have a dataset with 50 columns. My first aproach is to do a PCA for dimensionality reduction, before i do that, i Made a correlation analysis and drop some columns. Before Made a PCA and using gbdt( xgboost ) and a rf regressor.\n\nBut My results aren't good r2=0.55 that is only 0.05 better than a baseline.\n\nI don't have any bussines context to improve My analisis.\n \nSome ideas to handle this problem", "author_fullname": "t2_bvpnqeta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are You do if your dataset have 50 columns?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111ouqb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676334531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, as You can read in the title I have a dataset with 50 columns. My first aproach is to do a PCA for dimensionality reduction, before i do that, i Made a correlation analysis and drop some columns. Before Made a PCA and using gbdt( xgboost ) and a rf regressor.&lt;/p&gt;\n\n&lt;p&gt;But My results aren&amp;#39;t good r2=0.55 that is only 0.05 better than a baseline.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have any bussines context to improve My analisis.&lt;/p&gt;\n\n&lt;p&gt;Some ideas to handle this problem&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111ouqb", "is_robot_indexable": true, "report_reasons": null, "author": "aaaasd12", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111ouqb/what_are_you_do_if_your_dataset_have_50_columns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111ouqb/what_are_you_do_if_your_dataset_have_50_columns/", "subreddit_subscribers": 847566, "created_utc": 1676334531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear Data Scientists, \n\nToday I got the amazing news that I am accepted for the MSc in Data Science. \nAs someone with a Bachelors in Finance (also included Stats,Maths and Programming electives). I wanted to know would you recommend being data scientist in the banking or finance sector? (With this I also mean are the working hours decent and do you have a social life, and are you allowed to WFH)\n\nThank you in advance for your answers\n\nKind Regards, \n\nA Future Data Scientist", "author_fullname": "t2_53y185cuu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists in the Banking/Finance sector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111inqf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676319055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear Data Scientists, &lt;/p&gt;\n\n&lt;p&gt;Today I got the amazing news that I am accepted for the MSc in Data Science. \nAs someone with a Bachelors in Finance (also included Stats,Maths and Programming electives). I wanted to know would you recommend being data scientist in the banking or finance sector? (With this I also mean are the working hours decent and do you have a social life, and are you allowed to WFH)&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your answers&lt;/p&gt;\n\n&lt;p&gt;Kind Regards, &lt;/p&gt;\n\n&lt;p&gt;A Future Data Scientist&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111inqf", "is_robot_indexable": true, "report_reasons": null, "author": "NotGettingFazed", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111inqf/data_scientists_in_the_bankingfinance_sector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111inqf/data_scientists_in_the_bankingfinance_sector/", "subreddit_subscribers": 847566, "created_utc": 1676319055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model Madness Bracket Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111gvq7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_9zon0c42", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "dataanalysis", "selftext": "Friends!   \nIf you're a fan of basketball, analytics, or basketball analytics, I invite you to join my Model Madness Bracket Challenge this March. The rules are fairly simple, each bracket submission for the NCAA Men's Basketball Tournament must be based on the results of some predictive model you created. It can be as simple or complex as you would like as long as it's your own work and not completely random (no \"my model is whatever so-and-so on ESPN says\"). If interested, shoot me a message and I'll get a discord started up for everyone shortly.", "author_fullname": "t2_9zon0c42", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Model Madness Bracket Challenge", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataanalysis", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_110ut1m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676248281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataanalysis", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Friends!&lt;br/&gt;\nIf you&amp;#39;re a fan of basketball, analytics, or basketball analytics, I invite you to join my Model Madness Bracket Challenge this March. The rules are fairly simple, each bracket submission for the NCAA Men&amp;#39;s Basketball Tournament must be based on the results of some predictive model you created. It can be as simple or complex as you would like as long as it&amp;#39;s your own work and not completely random (no &amp;quot;my model is whatever so-and-so on ESPN says&amp;quot;). If interested, shoot me a message and I&amp;#39;ll get a discord started up for everyone shortly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_32t3c", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "110ut1m", "is_robot_indexable": true, "report_reasons": null, "author": "Agreeable_Mixture978", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataanalysis/comments/110ut1m/model_madness_bracket_challenge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataanalysis/comments/110ut1m/model_madness_bracket_challenge/", "subreddit_subscribers": 46051, "created_utc": 1676248281.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1676314664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataanalysis", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/dataanalysis/comments/110ut1m/model_madness_bracket_challenge/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111gvq7", "is_robot_indexable": true, "report_reasons": null, "author": "Agreeable_Mixture978", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_110ut1m", "author_flair_text_color": null, "permalink": "/r/datascience/comments/111gvq7/model_madness_bracket_challenge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/dataanalysis/comments/110ut1m/model_madness_bracket_challenge/", "subreddit_subscribers": 847566, "created_utc": 1676314664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_uzoqx6k0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to load and use a pytorch model (.pth) without knowing the model class?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111gk2x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676313861.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111gk2x", "is_robot_indexable": true, "report_reasons": null, "author": "Haritha37", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111gk2x/is_it_possible_to_load_and_use_a_pytorch_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111gk2x/is_it_possible_to_load_and_use_a_pytorch_model/", "subreddit_subscribers": 847566, "created_utc": 1676313861.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I need someone to tell me I'm not crazy.  I work with a vendor for our learning management system. Each course, curriculum, etc. all have a subject you can apply and the subjects can be nested. Here is an example of a simple example use case:\n\nAUDIO  \n\\---SPEAKERS  \n\\------BL  \n\\------DAS AUDIO  \n\\---MICROPHONES  \n\\------WIRED  \n\\------WIRELESS\n\nMy issue is that when filtering by AUDIO, for example, there are no results from ANYTHING below it... only things that are in that top level category.\n\nI opened a trouble ticket and this is the response I received:\n\n&gt;We do understand your concern.  \nWe tested the same scenario in our local environment and found that if we search parent subject (Top level), the child LO is not returned in the search results.  \nThis is as designed, this only searches using the subject select and does not include child subjects.  \nAs a workaround, when the subjects are set up in training, you can also add the parent and child both subjects so that both will be displayed in the Search.\n\nI'm 95% sure this is a dumb answer, right? As in, if it wasn't going to be included in the search for the parent, then it's not really a nested \"child\" subject... it's just a... completely different subject.\n\nI feel like I'm taking crazy pills!", "author_fullname": "t2_igcoh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nested Subject Classes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111cxl0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676304827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need someone to tell me I&amp;#39;m not crazy.  I work with a vendor for our learning management system. Each course, curriculum, etc. all have a subject you can apply and the subjects can be nested. Here is an example of a simple example use case:&lt;/p&gt;\n\n&lt;p&gt;AUDIO&lt;br/&gt;\n---SPEAKERS&lt;br/&gt;\n------BL&lt;br/&gt;\n------DAS AUDIO&lt;br/&gt;\n---MICROPHONES&lt;br/&gt;\n------WIRED&lt;br/&gt;\n------WIRELESS&lt;/p&gt;\n\n&lt;p&gt;My issue is that when filtering by AUDIO, for example, there are no results from ANYTHING below it... only things that are in that top level category.&lt;/p&gt;\n\n&lt;p&gt;I opened a trouble ticket and this is the response I received:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;We do understand your concern.&lt;br/&gt;\nWe tested the same scenario in our local environment and found that if we search parent subject (Top level), the child LO is not returned in the search results.&lt;br/&gt;\nThis is as designed, this only searches using the subject select and does not include child subjects.&lt;br/&gt;\nAs a workaround, when the subjects are set up in training, you can also add the parent and child both subjects so that both will be displayed in the Search.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;m 95% sure this is a dumb answer, right? As in, if it wasn&amp;#39;t going to be included in the search for the parent, then it&amp;#39;s not really a nested &amp;quot;child&amp;quot; subject... it&amp;#39;s just a... completely different subject.&lt;/p&gt;\n\n&lt;p&gt;I feel like I&amp;#39;m taking crazy pills!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111cxl0", "is_robot_indexable": true, "report_reasons": null, "author": "djmikewatt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111cxl0/nested_subject_classes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111cxl0/nested_subject_classes/", "subreddit_subscribers": 847566, "created_utc": 1676304827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\n[GeoSpatial Analysis Using GeoPandas In Python](https://preview.redd.it/83rfq0fg8zha1.jpg?width=334&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=f0ef948961796fbd10a5103bfbdf97ad764505a6)\n\n[GeoSpatial Analysis Using GeoPandas In Python](https://spatial-dev.guru/2023/02/05/geospatial-analysis-using-geopandas-in-python/)", "author_fullname": "t2_avt84u4i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GeoSpatial Analysis Using GeoPandas In Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"83rfq0fg8zha1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 216, "x": 108, "u": "https://preview.redd.it/83rfq0fg8zha1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=11d1689578f1120c208fd0badd8f0f9343b2f5a6"}, {"y": 432, "x": 216, "u": "https://preview.redd.it/83rfq0fg8zha1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4bafadd687a05e6a0b12c7323e5cbb4dd20432c3"}, {"y": 640, "x": 320, "u": "https://preview.redd.it/83rfq0fg8zha1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8710dbf295763d3894aa9095c480f6e4b4b0bd68"}], "s": {"y": 692, "x": 334, "u": "https://preview.redd.it/83rfq0fg8zha1.jpg?width=334&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=f0ef948961796fbd10a5103bfbdf97ad764505a6"}, "id": "83rfq0fg8zha1"}}, "name": "t3_111c9ju", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ckf4o7Cioxu4zU3cmhXtaIrynURi-yauhNpO3IlRaXw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676303194.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/83rfq0fg8zha1.jpg?width=334&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f0ef948961796fbd10a5103bfbdf97ad764505a6\"&gt;GeoSpatial Analysis Using GeoPandas In Python&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://spatial-dev.guru/2023/02/05/geospatial-analysis-using-geopandas-in-python/\"&gt;GeoSpatial Analysis Using GeoPandas In Python&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111c9ju", "is_robot_indexable": true, "report_reasons": null, "author": "iamgeoknight", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111c9ju/geospatial_analysis_using_geopandas_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111c9ju/geospatial_analysis_using_geopandas_in_python/", "subreddit_subscribers": 847566, "created_utc": 1676303194.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}