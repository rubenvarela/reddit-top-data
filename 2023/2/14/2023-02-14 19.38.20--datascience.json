{"kind": "Listing", "data": {"after": "t3_1126zkj", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "One very useful benefit I found with ChatGPT for job seekers is asking it to serve as a Hiring Manager that asks you questions for the specific role you're interested in.\n\nTo help it guide you, you need to provide it with some context based on the job description. For example, you list out the job description to ChatGPT and say that you want to be asked questions on causality and experimentation.\n\nHere's the response from ChatGPT based on the following prompt I provided it after sharing the job description:\n\n===**PROMPT BY ME===**\n\n&gt;I would like you to be a hiring manager. I'll be soon interviewing with you for a Data Science role, and you are going to ask me questions related to causality and experimentation. What are the questions you would ask to test my knowledge?\n\n**==RESPONSE BY CHATGPT===**\n\nSure! As a hiring manager for a data science role, I would like to assess your understanding of causality and experimentation. Here are a few questions I might ask:\n\n1. Can you explain the difference between correlation and causation, and give an example of each?\n2. How do you design an experiment to test a causal hypothesis?\n3. How do you ensure that the results of an experiment are valid and reliable?\n4. Can you explain the concept of confounding variables, and how do you control for them in an experiment?\n5. Can you explain the difference between a randomized controlled trial (RCT) and an observational study?\n6. How do you measure the impact of a treatment or intervention in an experiment?\n7. Have you worked with any causal inference methods such as propensity score matching or instrumental variables? Can you give an example of when you used them?\n8. How do you determine which variables to include in an experiment, and how do you avoid overfitting in the modeling process?\n9. Can you discuss any challenges or limitations you have encountered in designing and conducting experiments, and how you overcame them?\n10. Can you give an example of a real-world scenario in which you applied causal inference or experimentation methods to solve a business problem?\n\n====\n\nYou can ask ChatGPT to provide a summary answer for each. However, I would highly recommend you validate the answers by researching as well as ChatGPT can give confident, wrong answers.\n\nHope this helps others!", "author_fullname": "t2_48648", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Hunting Tip: Practice Interviewing with ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111h9pp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 269, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 269, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676315601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One very useful benefit I found with ChatGPT for job seekers is asking it to serve as a Hiring Manager that asks you questions for the specific role you&amp;#39;re interested in.&lt;/p&gt;\n\n&lt;p&gt;To help it guide you, you need to provide it with some context based on the job description. For example, you list out the job description to ChatGPT and say that you want to be asked questions on causality and experimentation.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the response from ChatGPT based on the following prompt I provided it after sharing the job description:&lt;/p&gt;\n\n&lt;p&gt;===&lt;strong&gt;PROMPT BY ME===&lt;/strong&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I would like you to be a hiring manager. I&amp;#39;ll be soon interviewing with you for a Data Science role, and you are going to ask me questions related to causality and experimentation. What are the questions you would ask to test my knowledge?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;strong&gt;==RESPONSE BY CHATGPT===&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Sure! As a hiring manager for a data science role, I would like to assess your understanding of causality and experimentation. Here are a few questions I might ask:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can you explain the difference between correlation and causation, and give an example of each?&lt;/li&gt;\n&lt;li&gt;How do you design an experiment to test a causal hypothesis?&lt;/li&gt;\n&lt;li&gt;How do you ensure that the results of an experiment are valid and reliable?&lt;/li&gt;\n&lt;li&gt;Can you explain the concept of confounding variables, and how do you control for them in an experiment?&lt;/li&gt;\n&lt;li&gt;Can you explain the difference between a randomized controlled trial (RCT) and an observational study?&lt;/li&gt;\n&lt;li&gt;How do you measure the impact of a treatment or intervention in an experiment?&lt;/li&gt;\n&lt;li&gt;Have you worked with any causal inference methods such as propensity score matching or instrumental variables? Can you give an example of when you used them?&lt;/li&gt;\n&lt;li&gt;How do you determine which variables to include in an experiment, and how do you avoid overfitting in the modeling process?&lt;/li&gt;\n&lt;li&gt;Can you discuss any challenges or limitations you have encountered in designing and conducting experiments, and how you overcame them?&lt;/li&gt;\n&lt;li&gt;Can you give an example of a real-world scenario in which you applied causal inference or experimentation methods to solve a business problem?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;&lt;/h1&gt;\n\n&lt;p&gt;You can ask ChatGPT to provide a summary answer for each. However, I would highly recommend you validate the answers by researching as well as ChatGPT can give confident, wrong answers.&lt;/p&gt;\n\n&lt;p&gt;Hope this helps others!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111h9pp", "is_robot_indexable": true, "report_reasons": null, "author": "forbiscuit", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111h9pp/job_hunting_tip_practice_interviewing_with_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111h9pp/job_hunting_tip_practice_interviewing_with_chatgpt/", "subreddit_subscribers": 847771, "created_utc": 1676315601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Should job posting with mentions of these tools be ignored or are they useful for a data scientists?", "author_fullname": "t2_17yq29", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What role does Tableau and Power BI play in your analysis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111lroh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676330349.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676326649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Should job posting with mentions of these tools be ignored or are they useful for a data scientists?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111lroh", "is_robot_indexable": true, "report_reasons": null, "author": "shastaslacker", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111lroh/what_role_does_tableau_and_power_bi_play_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111lroh/what_role_does_tableau_and_power_bi_play_in_your/", "subreddit_subscribers": 847771, "created_utc": 1676326649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I knew that I wanted to do something data-related (or computer science-based) for a long time, but unfortunately my undergrad major was completely unrelated to DS. I self-taught myself Python/R while working a marketing job and was suuper fortunate to get into a DS/DA Master\u2019s Program at one of the Ivy League schools. I worked 24/7 to learn a ton about best data practices/tools, had 2 DS co-ops, generated a ton of material for my GitHub, etc.\n\nObviously, just finishing a Master\u2019s program isn\u2019t enough to enter DS, so my career counselor recommended me to \u201ctake a data analyst job at a low-maturity company, use your skills to upgrade the way they use data, become a data rockstar and you\u2019ll get all kinds of doors opened in no time.\u201d **Spoiler** \\- *I did not become a data rockstar*.\n\nI landed a marketing analyst position at a large insurance company, and, long story short, this job is just a mess. My boss is a lifer that recently celebrated 20 years in the same position at the same company and got promoted to manager right as I joined. 30% of my work is shuffling around Excel sheets/making ugly (because the style is regulated) PowerPoints, another 30% is attending useless meetings that she sets up for me to \u201chear what conversations are happening around here\u201d; 20% is making sense of the broken SPSS code that someone wrote for her 15 years ago; the rest of the time is allocated to using Power BI, SQL and R to pull data from various sources and create reports for the internal stakeholders.\n\nNothing at my job is Googlable because all of the processes are either created by someone from 20 years ago or my manager herself; each process can require up to 100 little steps of moving data between million Excel spreadsheets populated with billion formulas making it impossible to comprehend or even load. The documentation she provides me with is always incorrect/incomplete, forcing me to ask for her help, as it would take me many hours to figure this out myself. When I try to do things my way, she gets clearly upset and sometimes starts micromanaging me, making us miss a ton of deadlines just for the sake of making everything look perfect according to the internal standards.\u00a0\n\nI spend a ton of time outside of work hours (the last one to leave the office every single day) trying to make time for extra DS projects but the amount of \u201chigh-priority\u201d tasks I get assigned is too overwhelming. The most technical thing I've done is used VDI to automate an R script that imports a bunch of files, anti-joins them and outputs certain distributions into an Excel doc, but that was a one-time project. I told my manager that I enjoy coding the most and she promised to land me a \u201ccoding-heavy\u201d project with the DS team. However, I followed up 3 times throughout a month and she ended up telling me that the person who asked for help decided to leave the company (jeez I wonder why.)\u00a0\n\nI get so much stress from a seemingly \u201ceasy\u201d job (no one seems to care that everything is 2+ weeks past due or indefinitely undelivered) because I\u2019m trying so hard to get a chance to make an impact and have at least something I can use when applying for DS roles after hitting that 1-year mark. I\u2019m afraid that the advanced skills I acquired are slowly fading away and I\u2019m learning a lot of bad habits from my manager.\n\nWhat would you recommend in my situation to stay on the right track? I usually work through my lunch breaks too (I know, I know), but I had an idea of maybe using that time to read a stats book or something DS-related - any suggestions? Any advice is appreciated :)\n\nEdit: the reason I put \"Ivy League School\" is because, a couple of months ago, my manager gave me an impossible task; I asked for a suggestion on how to better approach this task, and she responded with \"well, I'm not the one with the Master's Degree from the Ivy Leagues.\" I got so butthurt from this because I haven't brought it up once since joining the company lol.\n\nTLDR: want to break into DS through low-maturity analytics job but feeling like it has a negative effect on my career potential - tips?\u00a0", "author_fullname": "t2_6kb6g3y1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it a mistake to enter DS through low-maturity Data Analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111wcmt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676358583.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676357925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I knew that I wanted to do something data-related (or computer science-based) for a long time, but unfortunately my undergrad major was completely unrelated to DS. I self-taught myself Python/R while working a marketing job and was suuper fortunate to get into a DS/DA Master\u2019s Program at one of the Ivy League schools. I worked 24/7 to learn a ton about best data practices/tools, had 2 DS co-ops, generated a ton of material for my GitHub, etc.&lt;/p&gt;\n\n&lt;p&gt;Obviously, just finishing a Master\u2019s program isn\u2019t enough to enter DS, so my career counselor recommended me to \u201ctake a data analyst job at a low-maturity company, use your skills to upgrade the way they use data, become a data rockstar and you\u2019ll get all kinds of doors opened in no time.\u201d &lt;strong&gt;Spoiler&lt;/strong&gt; - &lt;em&gt;I did not become a data rockstar&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;I landed a marketing analyst position at a large insurance company, and, long story short, this job is just a mess. My boss is a lifer that recently celebrated 20 years in the same position at the same company and got promoted to manager right as I joined. 30% of my work is shuffling around Excel sheets/making ugly (because the style is regulated) PowerPoints, another 30% is attending useless meetings that she sets up for me to \u201chear what conversations are happening around here\u201d; 20% is making sense of the broken SPSS code that someone wrote for her 15 years ago; the rest of the time is allocated to using Power BI, SQL and R to pull data from various sources and create reports for the internal stakeholders.&lt;/p&gt;\n\n&lt;p&gt;Nothing at my job is Googlable because all of the processes are either created by someone from 20 years ago or my manager herself; each process can require up to 100 little steps of moving data between million Excel spreadsheets populated with billion formulas making it impossible to comprehend or even load. The documentation she provides me with is always incorrect/incomplete, forcing me to ask for her help, as it would take me many hours to figure this out myself. When I try to do things my way, she gets clearly upset and sometimes starts micromanaging me, making us miss a ton of deadlines just for the sake of making everything look perfect according to the internal standards.\u00a0&lt;/p&gt;\n\n&lt;p&gt;I spend a ton of time outside of work hours (the last one to leave the office every single day) trying to make time for extra DS projects but the amount of \u201chigh-priority\u201d tasks I get assigned is too overwhelming. The most technical thing I&amp;#39;ve done is used VDI to automate an R script that imports a bunch of files, anti-joins them and outputs certain distributions into an Excel doc, but that was a one-time project. I told my manager that I enjoy coding the most and she promised to land me a \u201ccoding-heavy\u201d project with the DS team. However, I followed up 3 times throughout a month and she ended up telling me that the person who asked for help decided to leave the company (jeez I wonder why.)\u00a0&lt;/p&gt;\n\n&lt;p&gt;I get so much stress from a seemingly \u201ceasy\u201d job (no one seems to care that everything is 2+ weeks past due or indefinitely undelivered) because I\u2019m trying so hard to get a chance to make an impact and have at least something I can use when applying for DS roles after hitting that 1-year mark. I\u2019m afraid that the advanced skills I acquired are slowly fading away and I\u2019m learning a lot of bad habits from my manager.&lt;/p&gt;\n\n&lt;p&gt;What would you recommend in my situation to stay on the right track? I usually work through my lunch breaks too (I know, I know), but I had an idea of maybe using that time to read a stats book or something DS-related - any suggestions? Any advice is appreciated :)&lt;/p&gt;\n\n&lt;p&gt;Edit: the reason I put &amp;quot;Ivy League School&amp;quot; is because, a couple of months ago, my manager gave me an impossible task; I asked for a suggestion on how to better approach this task, and she responded with &amp;quot;well, I&amp;#39;m not the one with the Master&amp;#39;s Degree from the Ivy Leagues.&amp;quot; I got so butthurt from this because I haven&amp;#39;t brought it up once since joining the company lol.&lt;/p&gt;\n\n&lt;p&gt;TLDR: want to break into DS through low-maturity analytics job but feeling like it has a negative effect on my career potential - tips?\u00a0&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111wcmt", "is_robot_indexable": true, "report_reasons": null, "author": "busy_bee_movie", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111wcmt/is_it_a_mistake_to_enter_ds_through_lowmaturity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111wcmt/is_it_a_mistake_to_enter_ds_through_lowmaturity/", "subreddit_subscribers": 847771, "created_utc": 1676357925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in my second semester of a data science masters and I'm trying to look for internships but also have no interest in working at a FAANG company. Whenever I try to search for internships it's mostly those giant companies with all the results. Does anyone have a way to search for internships at lesser known companies?", "author_fullname": "t2_vruv52hj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find internships/jobs at smaller companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1126jck", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676384526.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in my second semester of a data science masters and I&amp;#39;m trying to look for internships but also have no interest in working at a FAANG company. Whenever I try to search for internships it&amp;#39;s mostly those giant companies with all the results. Does anyone have a way to search for internships at lesser known companies?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1126jck", "is_robot_indexable": true, "report_reasons": null, "author": "sdgso666", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1126jck/how_to_find_internshipsjobs_at_smaller_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1126jck/how_to_find_internshipsjobs_at_smaller_companies/", "subreddit_subscribers": 847771, "created_utc": 1676384526.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I'm currently in my 6 month journey learning DS( I come from a mechanical engineering background), and I was wondering what tools/topics should I focus on if I want to get an entry level job in data science in the field of cancer research? \nIf anyone had an idea about this topic I would really appreciate your insight. Thank you!", "author_fullname": "t2_8773zq8m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going into cancer research in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111m24k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676327352.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I&amp;#39;m currently in my 6 month journey learning DS( I come from a mechanical engineering background), and I was wondering what tools/topics should I focus on if I want to get an entry level job in data science in the field of cancer research? \nIf anyone had an idea about this topic I would really appreciate your insight. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111m24k", "is_robot_indexable": true, "report_reasons": null, "author": "baydati", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111m24k/going_into_cancer_research_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111m24k/going_into_cancer_research_in_data_science/", "subreddit_subscribers": 847771, "created_utc": 1676327352.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'd love some clarification on these dimensionality reduction methods. I see PCA/PCR recommended as the go-to method for this type of task and almost never see people talk about using PLS to get principal components. It's my understanding that the key difference is that PLS considers the target when making components. \n\nIntuitively, I feel like this would make PLS stronger in many datasets, as it uses more of the available information to better inform the creation of components. I'm not an expert here and don't actually have a ton of expertise with how either of these methods work on a deep level, so any feedback from more experienced data scientists would be much appreciated. Thanks in advance for any thoughts or opinions here!", "author_fullname": "t2_vj9xwd07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is PCR recommended much more often than PLS for dimension reduction?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111kw8i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676324549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;d love some clarification on these dimensionality reduction methods. I see PCA/PCR recommended as the go-to method for this type of task and almost never see people talk about using PLS to get principal components. It&amp;#39;s my understanding that the key difference is that PLS considers the target when making components. &lt;/p&gt;\n\n&lt;p&gt;Intuitively, I feel like this would make PLS stronger in many datasets, as it uses more of the available information to better inform the creation of components. I&amp;#39;m not an expert here and don&amp;#39;t actually have a ton of expertise with how either of these methods work on a deep level, so any feedback from more experienced data scientists would be much appreciated. Thanks in advance for any thoughts or opinions here!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111kw8i", "is_robot_indexable": true, "report_reasons": null, "author": "NDVGuy", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111kw8i/why_is_pcr_recommended_much_more_often_than_pls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111kw8i/why_is_pcr_recommended_much_more_often_than_pls/", "subreddit_subscribers": 847771, "created_utc": 1676324549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hey, im currently a 3rd year data science student looking to improve my DSA skills. I have some knowledge about DSA in C++ but i find C++ quite hard. i came across [this](https://www.udemy.com/course/data-structures-and-algorithms-bootcamp-in-python/) course which is DSA using python. Seem to cover most of the topics and has coding exercises and a few projects as well.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/dzyq3sdbn4ia1.png?width=1919&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2b77018ed3f7b99efadc2097c62725ed58034df1\n\nCan anyone share their experience if they have taken this course? is it worth it? Thanks!", "author_fullname": "t2_ch7655b2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "is this a good DSA course?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dzyq3sdbn4ia1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 52, "x": 108, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3d3c0d1cce45ff648fb146d272beaefd9c7e10e1"}, {"y": 104, "x": 216, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2b676f578fdf5a625c710ef785b1ab8c267569fb"}, {"y": 154, "x": 320, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e0d7a9ef89c17f958cd48d6c4e4a8b03a4f8d52"}, {"y": 309, "x": 640, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afe34c3669233fcbd077da6638565b3029784ea4"}, {"y": 464, "x": 960, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=18cabdd4be6c73373bf306a9d99e3fd40f4c3acf"}, {"y": 522, "x": 1080, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e0e44fa17cf89e757cb762f774cec8a89626c50"}], "s": {"y": 929, "x": 1919, "u": "https://preview.redd.it/dzyq3sdbn4ia1.png?width=1919&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2b77018ed3f7b99efadc2097c62725ed58034df1"}, "id": "dzyq3sdbn4ia1"}}, "name": "t3_1120x9u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LdZ5dXEqoN07EJIBk_dOsRGeSgGydtxuY3fmEbQKC-o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1676369188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey, im currently a 3rd year data science student looking to improve my DSA skills. I have some knowledge about DSA in C++ but i find C++ quite hard. i came across &lt;a href=\"https://www.udemy.com/course/data-structures-and-algorithms-bootcamp-in-python/\"&gt;this&lt;/a&gt; course which is DSA using python. Seem to cover most of the topics and has coding exercises and a few projects as well.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dzyq3sdbn4ia1.png?width=1919&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2b77018ed3f7b99efadc2097c62725ed58034df1\"&gt;https://preview.redd.it/dzyq3sdbn4ia1.png?width=1919&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=2b77018ed3f7b99efadc2097c62725ed58034df1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Can anyone share their experience if they have taken this course? is it worth it? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1UyxmMpDV4aOgzMDSsaH07C7J3ugsS2_rvR_fbJwOLs.jpg?auto=webp&amp;v=enabled&amp;s=2b6c15109bf537458fe84f654f0878e99a414666", "width": 480, "height": 270}, "resolutions": [{"url": "https://external-preview.redd.it/1UyxmMpDV4aOgzMDSsaH07C7J3ugsS2_rvR_fbJwOLs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e376fe87d706de37aa9fb69329a5b250391e04bf", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/1UyxmMpDV4aOgzMDSsaH07C7J3ugsS2_rvR_fbJwOLs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b1199fcd770c83cc79cbf0acd3e44aaaa9b2575", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/1UyxmMpDV4aOgzMDSsaH07C7J3ugsS2_rvR_fbJwOLs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e3cf345702747971dcdeeb972e10179defed76a", "width": 320, "height": 180}], "variants": {}, "id": "wTDgQS8KR6GH3dRBl51MiRq4yzRC5eYjErPu00M2_Vc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1120x9u", "is_robot_indexable": true, "report_reasons": null, "author": "swift__7", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1120x9u/is_this_a_good_dsa_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1120x9u/is_this_a_good_dsa_course/", "subreddit_subscribers": 847771, "created_utc": 1676369188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello,\n\nMost of the time I only have my old laptop available without a dGPU and a 5 year old I7 dual core.\n\nTraining on the thing takes lots of time. What could you suggest for training models online?\nMy datasets are often in the 2-10gb Range. I don\u2019t have a problem to pay like 30-50 Euros monthly.\n\nI heard colab pro was super good but since they changed to the compute units model it got pretty meh? Or is it still good? Otherwise I heard about paperclip. \n\nWhat else can you recommend? I only want to train models online and then export them using joblib. I am also a Student just in Case there are some nice discounts. \n\nAppreciate any help!", "author_fullname": "t2_3n8ebct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Train ML Models cheap", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1125mhy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676382036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Most of the time I only have my old laptop available without a dGPU and a 5 year old I7 dual core.&lt;/p&gt;\n\n&lt;p&gt;Training on the thing takes lots of time. What could you suggest for training models online?\nMy datasets are often in the 2-10gb Range. I don\u2019t have a problem to pay like 30-50 Euros monthly.&lt;/p&gt;\n\n&lt;p&gt;I heard colab pro was super good but since they changed to the compute units model it got pretty meh? Or is it still good? Otherwise I heard about paperclip. &lt;/p&gt;\n\n&lt;p&gt;What else can you recommend? I only want to train models online and then export them using joblib. I am also a Student just in Case there are some nice discounts. &lt;/p&gt;\n\n&lt;p&gt;Appreciate any help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1125mhy", "is_robot_indexable": true, "report_reasons": null, "author": "Tyson1405", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1125mhy/train_ml_models_cheap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1125mhy/train_ml_models_cheap/", "subreddit_subscribers": 847771, "created_utc": 1676382036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[This paper](https://arxiv.org/abs/2112.13299) is super interesting, and by the same author who introduced CUPED.\n\nIn short, experiments with one sided non-compliance can result in a watered down ATE due to few users actually engaging with the treatment.  This paper builds on the instrumental variables literature (which we leverage a lot for these types of experiments) to use cuped to further reduce variance.\n\nIts super interesting and really useful for those of us who run experiments and need to increase precision of our estimates.  Best of all, there is some fairly food code attached as a footnote.", "author_fullname": "t2_131vu3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zero to Hero: Exploiting Null Effects to Achieve Variance Reduction in Experiments with One-sided Triggering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111rr5g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": "", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "modflair", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676342770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://arxiv.org/abs/2112.13299\"&gt;This paper&lt;/a&gt; is super interesting, and by the same author who introduced CUPED.&lt;/p&gt;\n\n&lt;p&gt;In short, experiments with one sided non-compliance can result in a watered down ATE due to few users actually engaging with the treatment.  This paper builds on the instrumental variables literature (which we leverage a lot for these types of experiments) to use cuped to further reduce variance.&lt;/p&gt;\n\n&lt;p&gt;Its super interesting and really useful for those of us who run experiments and need to increase precision of our estimates.  Best of all, there is some fairly food code attached as a footnote.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111rr5g", "is_robot_indexable": true, "report_reasons": null, "author": "__compactsupport__", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/111rr5g/zero_to_hero_exploiting_null_effects_to_achieve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111rr5g/zero_to_hero_exploiting_null_effects_to_achieve/", "subreddit_subscribers": 847771, "created_utc": 1676342770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI wrote 2 posts together with 2 colleagues on how to solve a compression problem from the insurance industry. We applied the Simplex algorithm to compress the number of model points (every model point is an insurance contract component like life-insurance) and fit them to our benchmark. \n\nHope it's ok to post this here, we'd like to get some input on our approach :)\n\n[https://medium.com/@patrick\\_hoefler/optimizing-model-points-of-a-life-insurance-portfolio-e9a61f01c5bc](https://medium.com/@patrick_hoefler/optimizing-model-points-of-a-life-insurance-portfolio-e9a61f01c5bc)", "author_fullname": "t2_o3c8q92a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing model points of a life insurance portfolio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1123lts", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676375709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I wrote 2 posts together with 2 colleagues on how to solve a compression problem from the insurance industry. We applied the Simplex algorithm to compress the number of model points (every model point is an insurance contract component like life-insurance) and fit them to our benchmark. &lt;/p&gt;\n\n&lt;p&gt;Hope it&amp;#39;s ok to post this here, we&amp;#39;d like to get some input on our approach :)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@patrick_hoefler/optimizing-model-points-of-a-life-insurance-portfolio-e9a61f01c5bc\"&gt;https://medium.com/@patrick_hoefler/optimizing-model-points-of-a-life-insurance-portfolio-e9a61f01c5bc&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?auto=webp&amp;v=enabled&amp;s=39b7487c11640083423cc5f72878e41d50c52985", "width": 1200, "height": 674}, "resolutions": [{"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a87dc5fd57601babd8cccd07ab08f152705db880", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=16d9dcb285e4a0fcedf09daf75fde631e365c811", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1da345e1a0183836f33f06324a40e14c3d07797b", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9deeede5e62a8a28bf2b79b6cc86e9f050424f0b", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25a9d51b8f7fd5b613cda0840d860d090b44dabb", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/48RYEuW1lV4l7wX862MqoKVcHKxktBraOCFOjWAQDUQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7dd54cb0ce0513b9e57426247a325066126e823b", "width": 1080, "height": 606}], "variants": {}, "id": "OpkwD9oERvd4BGZ6Ps_8K-Wx2LjHM1jpWRNbPL6rYvc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1123lts", "is_robot_indexable": true, "report_reasons": null, "author": "phofl93", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1123lts/optimizing_model_points_of_a_life_insurance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1123lts/optimizing_model_points_of_a_life_insurance/", "subreddit_subscribers": 847771, "created_utc": 1676375709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying create a predictive model for a binary outcome (yes or no).\nI have 16 predictor variables, which are a combination of categorical and continuous variables. How do I go about deciding which to include in my model?\n\nI can\u2019t find any literature on the requirements/assumptions of x in a logistic regression. I\u2019m modelling in R therefore I can\u2019t really add all variables and use a Backwards/Forwards variable selection method used in programs such as SAS.\n\n\nAppreciate any assistance!", "author_fullname": "t2_tir3dln2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deciding on Predictors for Logistic Regression", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111xm2s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676362978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying create a predictive model for a binary outcome (yes or no).\nI have 16 predictor variables, which are a combination of categorical and continuous variables. How do I go about deciding which to include in my model?&lt;/p&gt;\n\n&lt;p&gt;I can\u2019t find any literature on the requirements/assumptions of x in a logistic regression. I\u2019m modelling in R therefore I can\u2019t really add all variables and use a Backwards/Forwards variable selection method used in programs such as SAS.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any assistance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111xm2s", "is_robot_indexable": true, "report_reasons": null, "author": "Fun_Elevator_814", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111xm2s/deciding_on_predictors_for_logistic_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111xm2s/deciding_on_predictors_for_logistic_regression/", "subreddit_subscribers": 847771, "created_utc": 1676362978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Junior DS here, based in Italy. Lately I was looking for opportunities (helping a friend of mine) and noticed very few Data Science positions in the market (LinkedIn), at least for entry level ones. Instead, I noticed a huge request for Data Engineering stuff. What about your country?\n\nMy idea about this is that, at least in Italy, academia is pushing DS a lot, but the average industry is quite behind that and still struggling with data architectures (hence the need for Data Engs), ingestion and processing.", "author_fullname": "t2_12nt66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lack of DS jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_112c5wq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676398695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Junior DS here, based in Italy. Lately I was looking for opportunities (helping a friend of mine) and noticed very few Data Science positions in the market (LinkedIn), at least for entry level ones. Instead, I noticed a huge request for Data Engineering stuff. What about your country?&lt;/p&gt;\n\n&lt;p&gt;My idea about this is that, at least in Italy, academia is pushing DS a lot, but the average industry is quite behind that and still struggling with data architectures (hence the need for Data Engs), ingestion and processing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "112c5wq", "is_robot_indexable": true, "report_reasons": null, "author": "masc98", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/112c5wq/lack_of_ds_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/112c5wq/lack_of_ds_jobs/", "subreddit_subscribers": 847771, "created_utc": 1676398695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a very sparse matrix of users products, 120 users and 4000 products. each cell represents the users purchases of that specific product. \n\nEach month purchases are represented by a separate matrix, assuming the missing values represent  purchases that are not captured. How do I produce an estimate for purchases for each missing user/product pair?  \n\nEX:\n\nmatrix\\_1: has the purchases of users for different products in January\n\nmatrix\\_2: has the purchases of users for different products  in February\n\nmatrix\\_1: has the purchases of users for different products  in March\n\netc\n\n..\n\n..\n\nIs it a valid approach to have a single matrix for each month, or should we combine them somehow into a single matrix to capture the temporal nature of the problem?", "author_fullname": "t2_8jmib0lw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NMF for a user/product matrix", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112a4y3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676393620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a very sparse matrix of users products, 120 users and 4000 products. each cell represents the users purchases of that specific product. &lt;/p&gt;\n\n&lt;p&gt;Each month purchases are represented by a separate matrix, assuming the missing values represent  purchases that are not captured. How do I produce an estimate for purchases for each missing user/product pair?  &lt;/p&gt;\n\n&lt;p&gt;EX:&lt;/p&gt;\n\n&lt;p&gt;matrix_1: has the purchases of users for different products in January&lt;/p&gt;\n\n&lt;p&gt;matrix_2: has the purchases of users for different products  in February&lt;/p&gt;\n\n&lt;p&gt;matrix_1: has the purchases of users for different products  in March&lt;/p&gt;\n\n&lt;p&gt;etc&lt;/p&gt;\n\n&lt;p&gt;..&lt;/p&gt;\n\n&lt;p&gt;..&lt;/p&gt;\n\n&lt;p&gt;Is it a valid approach to have a single matrix for each month, or should we combine them somehow into a single matrix to capture the temporal nature of the problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "112a4y3", "is_robot_indexable": true, "report_reasons": null, "author": "Riolite55", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/112a4y3/nmf_for_a_userproduct_matrix/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/112a4y3/nmf_for_a_userproduct_matrix/", "subreddit_subscribers": 847771, "created_utc": 1676393620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for a free/open source alternative to AWS data wrangler.\nI'd like a unified platform where to:\n- visualize the data, possibly from multiple data sources and pre-configured visualizations\n- preprocess the data with no code solutions, but with the possibility to add code and export the data transformation in python code\n\nDoes anything like this exist?", "author_fullname": "t2_11tvii", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS data wrangler alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1123lnu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676375693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a free/open source alternative to AWS data wrangler.\nI&amp;#39;d like a unified platform where to:\n- visualize the data, possibly from multiple data sources and pre-configured visualizations\n- preprocess the data with no code solutions, but with the possibility to add code and export the data transformation in python code&lt;/p&gt;\n\n&lt;p&gt;Does anything like this exist?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1123lnu", "is_robot_indexable": true, "report_reasons": null, "author": "LumosNox99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1123lnu/aws_data_wrangler_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1123lnu/aws_data_wrangler_alternatives/", "subreddit_subscribers": 847771, "created_utc": 1676375693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to set up a ci/cd workflow for databricks, using github actions. There seems to be a couple of main choices. \n\n* Either executing the code using the runNotebook action, so the code runs on my existing databricks cluster. I am worried that this will be a bit hacky, as I would have to rely on running scripts from the notebook instead of just regular old python scripts. Getting results back and forth from the notebook to the vm running from github actions also seeems like a hurdle to implementing a good script.\n* Or setting up the yaml to replicate the databricks environment on the virtual machine that github actions spins up. I have tried the latter, but I struggle to get all the versions of java, scala, spark, pyton, packages etc to be identical an have my code execute without issue.\n\nI mainly have access to using databricks to write code, but I could consider using vscode on a local or virtual machine, or even coder as a web based alternative. Setting up a workflow using vscode and dbx is an option, but I do not want to use conda at the moment, which is what the quickstart seems to require.   \n\n\nWhat approach would you recommend? running on the existing cluster or setting up an identical environment in the yaml that fires up a vm in github actions?", "author_fullname": "t2_lqsp3ck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Setting up a databricks ci/cd pipeline with github actions - executing code on databricks cluster vs github VM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1120wo2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676369168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to set up a ci/cd workflow for databricks, using github actions. There seems to be a couple of main choices. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Either executing the code using the runNotebook action, so the code runs on my existing databricks cluster. I am worried that this will be a bit hacky, as I would have to rely on running scripts from the notebook instead of just regular old python scripts. Getting results back and forth from the notebook to the vm running from github actions also seeems like a hurdle to implementing a good script.&lt;/li&gt;\n&lt;li&gt;Or setting up the yaml to replicate the databricks environment on the virtual machine that github actions spins up. I have tried the latter, but I struggle to get all the versions of java, scala, spark, pyton, packages etc to be identical an have my code execute without issue.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I mainly have access to using databricks to write code, but I could consider using vscode on a local or virtual machine, or even coder as a web based alternative. Setting up a workflow using vscode and dbx is an option, but I do not want to use conda at the moment, which is what the quickstart seems to require.   &lt;/p&gt;\n\n&lt;p&gt;What approach would you recommend? running on the existing cluster or setting up an identical environment in the yaml that fires up a vm in github actions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1120wo2", "is_robot_indexable": true, "report_reasons": null, "author": "Tullsokk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1120wo2/setting_up_a_databricks_cicd_pipeline_with_github/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1120wo2/setting_up_a_databricks_cicd_pipeline_with_github/", "subreddit_subscribers": 847771, "created_utc": 1676369168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\nAnswering  questions based on domain knowledge (like internal documentation,  contracts, books, etc.) is challenging because of the size of the domain  knowledge.\n\nAs you might know,  Transformer-based models are limited in terms of input size (most of the  time it's hard to use more than 2048 tokens). So you cannot really do  question answering on a huge knowledge base with these models.\n\nYou  can try to fine-tune your own text generation model for that (like  GPT-3, GPT-J, etc.) but results are sometimes disappointing as the  fine-tuned models tends to forget some of the facts mentioned in the  dataset...\n\nAt NLP Cloud, the  strategy we prefer is about mixing semantic search and question  answering. Here is a quick article about how to do it:\n\n[https://nlpcloud.com/question-answering-on-domain-knowledge-with-semantic-search-and-text-generation.html](https://nlpcloud.com/question-answering-on-domain-knowledge-with-semantic-search-and-text-generation.html?utm_source=reddit&amp;utm_campaign=h5d7a9cc-3816-11ed-a261-0242ac140006)\n\nAs far as we know, this is the best way to get both a fluent and user friendly answer while being very accurate.\n\nI would love to hear your thoughts on this. Can you think of a better strategy for question answering on very large documents?\n\nJulien", "author_fullname": "t2_4z4m2qcs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question Answering On Domain Knowledge With Semantic Search And Text Generation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1120br9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676368470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;Answering  questions based on domain knowledge (like internal documentation,  contracts, books, etc.) is challenging because of the size of the domain  knowledge.&lt;/p&gt;\n\n&lt;p&gt;As you might know,  Transformer-based models are limited in terms of input size (most of the  time it&amp;#39;s hard to use more than 2048 tokens). So you cannot really do  question answering on a huge knowledge base with these models.&lt;/p&gt;\n\n&lt;p&gt;You  can try to fine-tune your own text generation model for that (like  GPT-3, GPT-J, etc.) but results are sometimes disappointing as the  fine-tuned models tends to forget some of the facts mentioned in the  dataset...&lt;/p&gt;\n\n&lt;p&gt;At NLP Cloud, the  strategy we prefer is about mixing semantic search and question  answering. Here is a quick article about how to do it:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://nlpcloud.com/question-answering-on-domain-knowledge-with-semantic-search-and-text-generation.html?utm_source=reddit&amp;amp;utm_campaign=h5d7a9cc-3816-11ed-a261-0242ac140006\"&gt;https://nlpcloud.com/question-answering-on-domain-knowledge-with-semantic-search-and-text-generation.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As far as we know, this is the best way to get both a fluent and user friendly answer while being very accurate.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear your thoughts on this. Can you think of a better strategy for question answering on very large documents?&lt;/p&gt;\n\n&lt;p&gt;Julien&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?auto=webp&amp;v=enabled&amp;s=d3760fef3f1ab6bf1d1dbe5461b5e2df024b7dd7", "width": 1024, "height": 683}, "resolutions": [{"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f32d166764978c9cd7cea214169c858b7f31626", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=330e05b09bb97fe6ac21be1ffc757f8fa7cf101a", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fb05b30bd6775eca0fdf8ab431ffd783c78a3c3d", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d3e65e7ececfa70c71c17229f1689ccf7e4e577", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/mHYCtcmhwvyno0-uAta4G_T1My3-otrPscUd2OjvMes.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49bce8862474499c1b35d696de560211bd6ba757", "width": 960, "height": 640}], "variants": {}, "id": "jQb1GRiS1-tsk2CyjgZgae0Y0DSRywZFiupWPpk_E6M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1120br9", "is_robot_indexable": true, "report_reasons": null, "author": "juliensalinas", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1120br9/question_answering_on_domain_knowledge_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1120br9/question_answering_on_domain_knowledge_with/", "subreddit_subscribers": 847771, "created_utc": 1676368470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys,\n\nRecently I have been interviewing with some companies for DS roles, and there were many case studies involved. When given the case and not much data (just might be a basic graph), how do you come up with the hypotheses and draw conclusions quickly? The tasks are generally interesting given the time and the data, but having to answer on spot throws me off.", "author_fullname": "t2_venbqmo3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS interviews (case study)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111xlvi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676362955.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;Recently I have been interviewing with some companies for DS roles, and there were many case studies involved. When given the case and not much data (just might be a basic graph), how do you come up with the hypotheses and draw conclusions quickly? The tasks are generally interesting given the time and the data, but having to answer on spot throws me off.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111xlvi", "is_robot_indexable": true, "report_reasons": null, "author": "shajiegdvmd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111xlvi/ds_interviews_case_study/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111xlvi/ds_interviews_case_study/", "subreddit_subscribers": 847771, "created_utc": 1676362955.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a3gidxwy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One On One. No One Else Around. I Will Beat Your Data Like A Cherokee Drum", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_111k9bn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OJBTbJMDd7ZdkzBpqFObgmXTOEx9zskvQv_0aKEHg0I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676323018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/4btt1nkcv0ia1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?auto=webp&amp;v=enabled&amp;s=74a9e1111540f83fce2b7b6d604841264ed65bb0", "width": 684, "height": 843}, "resolutions": [{"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=388e1cca3081453a39843770fa4eb3477395b504", "width": 108, "height": 133}, {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d02972a76dba42ec2bf3fbec40a6f35d2af75c3", "width": 216, "height": 266}, {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7e8b7db0a56d1d58826c76a114f3bdfa45b07d08", "width": 320, "height": 394}, {"url": "https://preview.redd.it/4btt1nkcv0ia1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=81de2a46be2ed129061391d2c71ea690d27c690d", "width": 640, "height": 788}], "variants": {}, "id": "WAsQdHMFCuG8cMNg15KA-PY9857EguJW9u5YGkGdzaY"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "111k9bn", "is_robot_indexable": true, "report_reasons": null, "author": "malirkan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111k9bn/one_on_one_no_one_else_around_i_will_beat_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/4btt1nkcv0ia1.png", "subreddit_subscribers": 847771, "created_utc": 1676323018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "With the proliferation of LLMs like ChatGPT or whatever it is Google is calling their primary LLM these days (LAMDA or otherwise), do people think this will change the market for data scientists? In one world, the market basically stays the same, as more hardcore AI researchers inventing LLMs and cutting edge work remain concentrated in Big Tech. Then more \u201cnormal\u201d data science work remains the same elsewhere. In another world, LLMs replace lower level data science work and either decrease demand for data scientists overall or make them less valuable (highly unlikely imoz more likely to free up some lower levels tasks, for example around EDA, than actually replace anyone). In yet another world, the general shift to AI creates hype around the profession and encourages people to invest in data and analytics broadly, even if they\u2019re not doing AI work specifically (whatever AI work actually is). What do people think? Interesting discussion here in broader churn in engineering labor market given recent big tech layoffs: https://open.spotify.com/episode/01uyOv5cIvLZfqVdwWPK3a?si=IAqZ1638SPiib6UacPQUzg", "author_fullname": "t2_ioao8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "With the rise of LLMs like ChatGPT, how will demand for data scientists change?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112b6du", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676396223.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the proliferation of LLMs like ChatGPT or whatever it is Google is calling their primary LLM these days (LAMDA or otherwise), do people think this will change the market for data scientists? In one world, the market basically stays the same, as more hardcore AI researchers inventing LLMs and cutting edge work remain concentrated in Big Tech. Then more \u201cnormal\u201d data science work remains the same elsewhere. In another world, LLMs replace lower level data science work and either decrease demand for data scientists overall or make them less valuable (highly unlikely imoz more likely to free up some lower levels tasks, for example around EDA, than actually replace anyone). In yet another world, the general shift to AI creates hype around the profession and encourages people to invest in data and analytics broadly, even if they\u2019re not doing AI work specifically (whatever AI work actually is). What do people think? Interesting discussion here in broader churn in engineering labor market given recent big tech layoffs: &lt;a href=\"https://open.spotify.com/episode/01uyOv5cIvLZfqVdwWPK3a?si=IAqZ1638SPiib6UacPQUzg\"&gt;https://open.spotify.com/episode/01uyOv5cIvLZfqVdwWPK3a?si=IAqZ1638SPiib6UacPQUzg&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4Hq4_8a5feEcaykiDc83XGO2DiYZMVrXVCgkbzLJ59o.jpg?auto=webp&amp;v=enabled&amp;s=82a5dc5746b51312f316252155cd865f610dd27a", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/4Hq4_8a5feEcaykiDc83XGO2DiYZMVrXVCgkbzLJ59o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0215d8b0fae5a09f3e19cf35fb9625ea33920729", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/4Hq4_8a5feEcaykiDc83XGO2DiYZMVrXVCgkbzLJ59o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b255b65c2798179f65ea9cd41dfff29db4d0966", "width": 216, "height": 216}], "variants": {}, "id": "rnzV8zrB97bsXIFBcoZS1IR2DpVXEhySHDtGgqp4l9g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "112b6du", "is_robot_indexable": true, "report_reasons": null, "author": "mikeike93", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/112b6du/with_the_rise_of_llms_like_chatgpt_how_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/112b6du/with_the_rise_of_llms_like_chatgpt_how_will/", "subreddit_subscribers": 847771, "created_utc": 1676396223.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, I am a sophomore in college who knows python decently well and is beginning to learn R. Would you recommend continuing to learn languages or to learn skills like reinforcement learning? Any help or advice would be greatly appreciated!", "author_fullname": "t2_gslj3kjr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Language Questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_112aizd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676394570.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I am a sophomore in college who knows python decently well and is beginning to learn R. Would you recommend continuing to learn languages or to learn skills like reinforcement learning? Any help or advice would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "112aizd", "is_robot_indexable": true, "report_reasons": null, "author": "BaldProgrammer7", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/112aizd/language_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/112aizd/language_questions/", "subreddit_subscribers": 847771, "created_utc": 1676394570.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am looking for help and opinions on where to start with getting some \u201everified\u201c background on data science (besides doing Bachelors/Masters). Are there any courses / trainings / bootcamps that provide a good start as well as a (kind of) official certificate?\n\nBackground: I did my bachelors in applied linguistics (statistics was a big part of it, eg linear regression on text corpora to determine readability) and have an MBA. Currently I am working in a Compliance/Risk Management Team and kind of drifted to a data analysis side role. Regularly I write sql code to extract data from our databases and see what we can learn from it. As I had no prior experience, I learned it from scratch by trial and error, asking around and some online tutorials. \n\nI have of lot of fun doing this (exploring data, writing code) and am looking to steer my career towards that direction more. For starters, I was thinking of doing something official and have some training budget to spend. Hence my question: do you have any tips on trainings that also issue certificates (ideally stuff that means sth). I am typically more of a hands on guy and don\u2019t think doing a 800\u20ac training is better than learning with coursera - but maybe I can have it both?what do you guys think? Is that a good idea?  or should I just do a python bootcamp and start from there? I don\u2019t know much about the field in general and have just started gathering information so any related tips are also highly appreciated.\n(Ofc I did some googling but I am overwhelmed and would appreciate your expertise)", "author_fullname": "t2_c7ye47jd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Training / Accreditation in Data Science - best start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1122vt6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676373140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for help and opinions on where to start with getting some \u201everified\u201c background on data science (besides doing Bachelors/Masters). Are there any courses / trainings / bootcamps that provide a good start as well as a (kind of) official certificate?&lt;/p&gt;\n\n&lt;p&gt;Background: I did my bachelors in applied linguistics (statistics was a big part of it, eg linear regression on text corpora to determine readability) and have an MBA. Currently I am working in a Compliance/Risk Management Team and kind of drifted to a data analysis side role. Regularly I write sql code to extract data from our databases and see what we can learn from it. As I had no prior experience, I learned it from scratch by trial and error, asking around and some online tutorials. &lt;/p&gt;\n\n&lt;p&gt;I have of lot of fun doing this (exploring data, writing code) and am looking to steer my career towards that direction more. For starters, I was thinking of doing something official and have some training budget to spend. Hence my question: do you have any tips on trainings that also issue certificates (ideally stuff that means sth). I am typically more of a hands on guy and don\u2019t think doing a 800\u20ac training is better than learning with coursera - but maybe I can have it both?what do you guys think? Is that a good idea?  or should I just do a python bootcamp and start from there? I don\u2019t know much about the field in general and have just started gathering information so any related tips are also highly appreciated.\n(Ofc I did some googling but I am overwhelmed and would appreciate your expertise)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1122vt6", "is_robot_indexable": true, "report_reasons": null, "author": "GoblinSwineRider", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1122vt6/training_accreditation_in_data_science_best_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1122vt6/training_accreditation_in_data_science_best_start/", "subreddit_subscribers": 847771, "created_utc": 1676373140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I barely cared about internships and work experience. Im in my fourth year of college and I realized I should have done more. So I found out how to make my own projects and portfolio. Finally, landed my first unpaid DS + machine learning intern spot. Excited to learn on the job, but how should I be climbing up the ladder to better positions with better pay. The internship is a small commitment under 10 hours a week. What should I be doing on the side?", "author_fullname": "t2_1bswoe14", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to move up in the industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111vvya", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676356192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I barely cared about internships and work experience. Im in my fourth year of college and I realized I should have done more. So I found out how to make my own projects and portfolio. Finally, landed my first unpaid DS + machine learning intern spot. Excited to learn on the job, but how should I be climbing up the ladder to better positions with better pay. The internship is a small commitment under 10 hours a week. What should I be doing on the side?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111vvya", "is_robot_indexable": true, "report_reasons": null, "author": "RebornMoki", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111vvya/how_to_move_up_in_the_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111vvya/how_to_move_up_in_the_industry/", "subreddit_subscribers": 847771, "created_utc": 1676356192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_9fjoqhty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning from Machine Learning | Maarten Grootendorst: BERTopic, Data Science, Psychology", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_111qiz7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pZRnHxmbgEfUBFtjXKz7mV-b92W4pedM5bfWbvpv_Ec.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676339210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/learning-from-machine-learning-maarten-grootendorst-bertopic-data-science-psychology-9ed9b9b2921", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?auto=webp&amp;v=enabled&amp;s=2af3de0a635567916d800533a55cd697c2e49709", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ac44d9743c4c3701ddcba20ed12007d32035b414", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef2dc42af09e18b3c440be824a655fe8b8e8b76f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbde90fcc329d0cfbded61f4c62f7ec86a70fdc3", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a9ccf33aaa4b63f4c23022aa7b056517e3b9c8f", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8430bc16a5c60ccbee8a158f1e13c87576300a3f", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/yCA78lSuJjzSJ8YW7E6FfgT3vxyShTpjN4VUUKHSh2M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2419d66fe039ef54b334eecb4b3c7721b766165", "width": 1080, "height": 607}], "variants": {}, "id": "Px4aCnL6kflFq7V1b0qLJPfpjZKoXMS83ENgNHOLdIA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "111qiz7", "is_robot_indexable": true, "report_reasons": null, "author": "NLPnerd", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111qiz7/learning_from_machine_learning_maarten/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/learning-from-machine-learning-maarten-grootendorst-bertopic-data-science-psychology-9ed9b9b2921", "subreddit_subscribers": 847771, "created_utc": 1676339210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Dear Data Scientists, \n\nToday I got the amazing news that I am accepted for the MSc in Data Science. \nAs someone with a Bachelors in Finance (also included Stats,Maths and Programming electives). I wanted to know would you recommend being data scientist in the banking or finance sector? (With this I also mean are the working hours decent and do you have a social life, and are you allowed to WFH)\n\nThank you in advance for your answers\n\nKind Regards, \n\nA Future Data Scientist", "author_fullname": "t2_53y185cuu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientists in the Banking/Finance sector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_111inqf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676319055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear Data Scientists, &lt;/p&gt;\n\n&lt;p&gt;Today I got the amazing news that I am accepted for the MSc in Data Science. \nAs someone with a Bachelors in Finance (also included Stats,Maths and Programming electives). I wanted to know would you recommend being data scientist in the banking or finance sector? (With this I also mean are the working hours decent and do you have a social life, and are you allowed to WFH)&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your answers&lt;/p&gt;\n\n&lt;p&gt;Kind Regards, &lt;/p&gt;\n\n&lt;p&gt;A Future Data Scientist&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "111inqf", "is_robot_indexable": true, "report_reasons": null, "author": "NotGettingFazed", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/111inqf/data_scientists_in_the_bankingfinance_sector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/111inqf/data_scientists_in_the_bankingfinance_sector/", "subreddit_subscribers": 847771, "created_utc": 1676319055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8y0eht55", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI as a service might be the next thing .", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_1126zkj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/G9BPygak5V96kLwaT1pX3y735Tk7ET-MAolN-ptz0aY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676385702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "link.medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://link.medium.com/P6CksY6Ipxb", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/q5i0nFUZwLIz6gYjeM6xrtG2z8t9arA_Mbw4Dv6b-8o.jpg?auto=webp&amp;v=enabled&amp;s=ff3f9dcec94e498bc161707916c83b4776d005a5", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/q5i0nFUZwLIz6gYjeM6xrtG2z8t9arA_Mbw4Dv6b-8o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9341a809acd7cd73d9a62f12ae9aaaed248d9fb", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/q5i0nFUZwLIz6gYjeM6xrtG2z8t9arA_Mbw4Dv6b-8o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=503a049f904ea767b32044e3349b8c735d330a58", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/q5i0nFUZwLIz6gYjeM6xrtG2z8t9arA_Mbw4Dv6b-8o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a6c999bd1346860af9d61932d4e43816aa226489", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/q5i0nFUZwLIz6gYjeM6xrtG2z8t9arA_Mbw4Dv6b-8o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=224e2097667183efde102a3eecc4944c6ac99d56", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/q5i0nFUZwLIz6gYjeM6xrtG2z8t9arA_Mbw4Dv6b-8o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46d49f5f12e2d4e163af5740f6e35dfbfd4c9de2", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/q5i0nFUZwLIz6gYjeM6xrtG2z8t9arA_Mbw4Dv6b-8o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c16ee0e5ddff54fa1f3d9458e37be565ffe867d", "width": 1080, "height": 720}], "variants": {}, "id": "Fzj-wIVXRLIXCHXas9h5GHKGbLDfM1kMr1UX38KL21U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1126zkj", "is_robot_indexable": true, "report_reasons": null, "author": "Still_Ad_5968", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1126zkj/ai_as_a_service_might_be_the_next_thing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://link.medium.com/P6CksY6Ipxb", "subreddit_subscribers": 847771, "created_utc": 1676385702.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}