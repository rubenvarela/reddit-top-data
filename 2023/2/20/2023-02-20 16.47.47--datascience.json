{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_gbo2p1mi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "There are too many charlatans on Linkedin posing as Data Scientist. Gone through his profile, not a single mention of his work. Most of the posts are engagement farming. The awards also seems to be suspicious and paid. My main question is who should you follow for quality content ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_116yrs4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 228, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 228, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mqxGMYzRHijwhhOO_sR84Wp-LKu_-mtumj2eTnNlaBg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676871193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/n5wm8qxr4aja1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/n5wm8qxr4aja1.png?auto=webp&amp;v=enabled&amp;s=8f85af0d9d8cab68f26f815c61d56e4d4aa9b823", "width": 617, "height": 740}, "resolutions": [{"url": "https://preview.redd.it/n5wm8qxr4aja1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37222747d05d86d5aead534b4abe58c0d1426aef", "width": 108, "height": 129}, {"url": "https://preview.redd.it/n5wm8qxr4aja1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c50e48c9a60cf99f60fedc57ebfbf3cf1117cf98", "width": 216, "height": 259}, {"url": "https://preview.redd.it/n5wm8qxr4aja1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf62ebccdd7ec3d118100cb7396f92b4cb28d20b", "width": 320, "height": 383}], "variants": {}, "id": "dBKttO9EuDjVmm1Va3D1V8Vp6Hkjo6lp0FLuUzCiRI4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "116yrs4", "is_robot_indexable": true, "report_reasons": null, "author": "Mental-Leopard8027", "discussion_type": null, "num_comments": 80, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116yrs4/there_are_too_many_charlatans_on_linkedin_posing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/n5wm8qxr4aja1.png", "subreddit_subscribers": 849649, "created_utc": 1676871193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I often find myself wanting to run a couple SQL commands against a CSV, I have poor Excel skills, and so I made [https://sqlacsv.com/](https://sqlacsv.com/). You can drag-n-drop any CSV, its a completely offline app, and it gives a quick overview of each column's distribution.\n\n**Is this something people might find helpful? Would love to get some feedback on the tool.** \n\nHere some screenshots of what happens after you upload a CSV:\n\n[Simple SQL Editor](https://preview.redd.it/335fjx7cr8ja1.png?width=1886&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a22da852724c61f4846ca08f917111e9b99f980c)\n\n&amp;#x200B;\n\n[Overview of Values per Columns](https://preview.redd.it/qlt46ttdr8ja1.png?width=1873&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9d3e64d2eeac20b69c2d4805fd2e307b04ae6789)\n\nThanks in advanced!", "author_fullname": "t2_ynkil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Website to quickly SQL a CSV: feedback?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qlt46ttdr8ja1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06ae57099f905bf7f1f4b3e5095307e272000cd8"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=07a3b8e32d4f280bd71cb0a72166dafcc10d9ece"}, {"y": 151, "x": 320, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72afe3f4b2f2bbeab9a1377706cb078b7bb7e91d"}, {"y": 303, "x": 640, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ccb5242268ea20f744164a3cf836b4cf3cf5dec"}, {"y": 454, "x": 960, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9f9e7e8bb6c33dc377b4a8dcd08b79d4a18e8fa"}, {"y": 511, "x": 1080, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f5077f4a6108be495fa9bd2d7c3713b6a158af6"}], "s": {"y": 887, "x": 1873, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=1873&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9d3e64d2eeac20b69c2d4805fd2e307b04ae6789"}, "id": "qlt46ttdr8ja1"}, "335fjx7cr8ja1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 48, "x": 108, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fabf8f4c9f5c8081b68564f1e611e26daf15e6a"}, {"y": 97, "x": 216, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6487f140f6e5cc728157a3e43654a092d9746596"}, {"y": 145, "x": 320, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a3f3e60c3300cb9fd2d8405dad2d1ee21fa2edd"}, {"y": 290, "x": 640, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4592dd9d6b785c49da973a78fdcfb6018790445e"}, {"y": 435, "x": 960, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fb376923ab3ad675ccb2b34833b2203faf43082"}, {"y": 489, "x": 1080, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed1ba5c9dbd7103d8fb8a145ee88226085493528"}], "s": {"y": 855, "x": 1886, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=1886&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a22da852724c61f4846ca08f917111e9b99f980c"}, "id": "335fjx7cr8ja1"}}, "name": "t3_116tgd8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 74, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LcP4XMrwO1f_KnyFGINRJlIZ3JLRH3nA3V9u534oMQU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676854607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I often find myself wanting to run a couple SQL commands against a CSV, I have poor Excel skills, and so I made &lt;a href=\"https://sqlacsv.com/\"&gt;https://sqlacsv.com/&lt;/a&gt;. You can drag-n-drop any CSV, its a completely offline app, and it gives a quick overview of each column&amp;#39;s distribution.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is this something people might find helpful? Would love to get some feedback on the tool.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Here some screenshots of what happens after you upload a CSV:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/335fjx7cr8ja1.png?width=1886&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a22da852724c61f4846ca08f917111e9b99f980c\"&gt;Simple SQL Editor&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qlt46ttdr8ja1.png?width=1873&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9d3e64d2eeac20b69c2d4805fd2e307b04ae6789\"&gt;Overview of Values per Columns&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advanced!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116tgd8", "is_robot_indexable": true, "report_reasons": null, "author": "downvotedragon", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116tgd8/website_to_quickly_sql_a_csv_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116tgd8/website_to_quickly_sql_a_csv_feedback/", "subreddit_subscribers": 849649, "created_utc": 1676854607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just wondering if should make portfolio if I already have 3 years of experience in the data science field.", "author_fullname": "t2_6xabempy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you need a portfolio if you already have ~3 years of experience on the field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116l932", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 71, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 71, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676834048.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering if should make portfolio if I already have 3 years of experience in the data science field.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116l932", "is_robot_indexable": true, "report_reasons": null, "author": "marjose2", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116l932/do_you_need_a_portfolio_if_you_already_have_3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116l932/do_you_need_a_portfolio_if_you_already_have_3/", "subreddit_subscribers": 849649, "created_utc": 1676834048.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I'm planning to create a dashboard for data visualization, and I think I want to use Python for the project. I've been looking into Dash and Streamlit, but I'm not sure which one would be the best choice for a beginner like me. Do you have any suggestions on which library to use? Also, I'm hoping to find a library that won't have a very steep learning curve.\n\nIf you have any recommendations for other Python-based libraries for data visualization and dashboard creation, I'd love to hear them as well. Thanks in advance for your help!", "author_fullname": "t2_5qka7bxz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Python Libraries for Data Visualization and Dashboard Creation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116us5l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676858394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m planning to create a dashboard for data visualization, and I think I want to use Python for the project. I&amp;#39;ve been looking into Dash and Streamlit, but I&amp;#39;m not sure which one would be the best choice for a beginner like me. Do you have any suggestions on which library to use? Also, I&amp;#39;m hoping to find a library that won&amp;#39;t have a very steep learning curve.&lt;/p&gt;\n\n&lt;p&gt;If you have any recommendations for other Python-based libraries for data visualization and dashboard creation, I&amp;#39;d love to hear them as well. Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116us5l", "is_robot_indexable": true, "report_reasons": null, "author": "theflash444123", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116us5l/best_python_libraries_for_data_visualization_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116us5l/best_python_libraries_for_data_visualization_and/", "subreddit_subscribers": 849649, "created_utc": 1676858394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So Basically I have worked on a data science project with a professor in Cannada and we got good results in a medical dataset and got a good AUROC of .85 and we published the paper for it and got selected , but what surprised me was the professor never went through my code and just gave suggestions and tips to do improve the model , but isn't this a lot risky.Everyday I am scared that some person would go through my code and invalidate my entire results based on some simple error which could have been corrected if there were proper code reviews.\n\nFast forward 6 months , I got a job in  a data science company as an intern and he told me to develop self supervised model for their image dataset and I did that and it good kind of okay results and he told me to move on to another project , still there was no code reviews or code checks , do people in data science just blindly trust each others code , I feel managers should at least give a look through to see if we taking the correct data split or if the model is correct or if there is any data leakage.There is a lot of red flags in trusting the AUROC results blindly. Is this a norm or maybe its just for me.\n\nMoreover most of the data scientists in the company dont even write proper documentation and for interns like me its such a pain , it took  me 2 weeks to understand their entire training repo, data science people should talk with the data engineers and take some of their methods and practices.", "author_fullname": "t2_py4qwirz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal in the data Science field to not have that many code checks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11714te", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676880230.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676880002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So Basically I have worked on a data science project with a professor in Cannada and we got good results in a medical dataset and got a good AUROC of .85 and we published the paper for it and got selected , but what surprised me was the professor never went through my code and just gave suggestions and tips to do improve the model , but isn&amp;#39;t this a lot risky.Everyday I am scared that some person would go through my code and invalidate my entire results based on some simple error which could have been corrected if there were proper code reviews.&lt;/p&gt;\n\n&lt;p&gt;Fast forward 6 months , I got a job in  a data science company as an intern and he told me to develop self supervised model for their image dataset and I did that and it good kind of okay results and he told me to move on to another project , still there was no code reviews or code checks , do people in data science just blindly trust each others code , I feel managers should at least give a look through to see if we taking the correct data split or if the model is correct or if there is any data leakage.There is a lot of red flags in trusting the AUROC results blindly. Is this a norm or maybe its just for me.&lt;/p&gt;\n\n&lt;p&gt;Moreover most of the data scientists in the company dont even write proper documentation and for interns like me its such a pain , it took  me 2 weeks to understand their entire training repo, data science people should talk with the data engineers and take some of their methods and practices.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11714te", "is_robot_indexable": true, "report_reasons": null, "author": "skeletons_of_closet", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11714te/is_it_normal_in_the_data_science_field_to_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11714te/is_it_normal_in_the_data_science_field_to_not/", "subreddit_subscribers": 849649, "created_utc": 1676880002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I am fitting count data for each place. That means, my response variable is the count data and I want to regress them to given explanatory variables. And each row represents each place. But the problem is that the count data are collected over years and I found it has a seasonal pattern. I am sorry to confuse you but I also have another dataset that consists of count data according to time and I used this dataset to visualize the time series plot.\n\nSo, my main goal is to make a regression model of the count data using explanatory in the original dataset (that has no time component) while adjusting for seasonality and my question is how I can deal with this. Do I have to request for the new dataset that contains the time the count data were recorded and fit a regression model? Thank you in advance!", "author_fullname": "t2_4b2tl19h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Regression and Time Series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116qyz0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676848212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am fitting count data for each place. That means, my response variable is the count data and I want to regress them to given explanatory variables. And each row represents each place. But the problem is that the count data are collected over years and I found it has a seasonal pattern. I am sorry to confuse you but I also have another dataset that consists of count data according to time and I used this dataset to visualize the time series plot.&lt;/p&gt;\n\n&lt;p&gt;So, my main goal is to make a regression model of the count data using explanatory in the original dataset (that has no time component) while adjusting for seasonality and my question is how I can deal with this. Do I have to request for the new dataset that contains the time the count data were recorded and fit a regression model? Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116qyz0", "is_robot_indexable": true, "report_reasons": null, "author": "ZirhoZirk", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116qyz0/regression_and_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116qyz0/regression_and_time_series/", "subreddit_subscribers": 849649, "created_utc": 1676848212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Deploy Machine Learning Models with Django\n\nhttps://github.com/R-Mahmoudi/DeployMachineLearningModel", "author_fullname": "t2_8okds99o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploy Machine Learning Models with Django", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116qef7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676846814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Deploy Machine Learning Models with Django&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/R-Mahmoudi/DeployMachineLearningModel\"&gt;https://github.com/R-Mahmoudi/DeployMachineLearningModel&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?auto=webp&amp;v=enabled&amp;s=54fe2ce57a49bacdfccaa126f6e2b3929d963494", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0dcfccb0b32f4400bfdfe104f26239095176289", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1b585d921be17536437cad1c0f75a5cc5f54051", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ba5f88b0b60b8922164d573e76d11094050a9f4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d56082665ef2d7db8324e0f0f62579a5df6e41cf", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f9c70f7f579ccc9a99838f6fd1e5eb53292cac9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eeaf1ed5a485c360bf86e694b29e92fefe8da94f", "width": 1080, "height": 540}], "variants": {}, "id": "Buhe-VKKc_DiDzwK1BiE0lE1sSfhx-mcqd7OhXRvT9A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116qef7", "is_robot_indexable": true, "report_reasons": null, "author": "Smooth-Ad1528", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116qef7/deploy_machine_learning_models_with_django/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116qef7/deploy_machine_learning_models_with_django/", "subreddit_subscribers": 849649, "created_utc": 1676846814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am thinking about how Amazon reportedly axed a lot of Alexa teams.  This seems to point to negative.  But ChatGPT is taking up a lot of interest. This seems to point to positive.   What are your thoughts?", "author_fullname": "t2_y7l57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is NLP a sub-field with a lot of growth?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_117736x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676900874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking about how Amazon reportedly axed a lot of Alexa teams.  This seems to point to negative.  But ChatGPT is taking up a lot of interest. This seems to point to positive.   What are your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "117736x", "is_robot_indexable": true, "report_reasons": null, "author": "sonicking12", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/117736x/is_nlp_a_subfield_with_a_lot_of_growth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/117736x/is_nlp_a_subfield_with_a_lot_of_growth/", "subreddit_subscribers": 849649, "created_utc": 1676900874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI have recently been offered a data scientist position at my current company, but I was told that I would be working exclusively on the Google Cloud Platform (GCP), and that it won't be necessary to code in Python. I've spent the past year learning about data science, models, and programming, and I'm concerned that all of that knowledge won't be put to use in this new role. I always thought that a data scientist would be in front of their Jupyter notebook, so I'm worried that this is a cheap data scientist position.\n\nMy main question is: is it standard for data scientists to work solely on cloud computing platforms like GCP, and is it common to not code in Python? I'd love to hear your thoughts and experiences on this.\n\nThanks in advance for your help !", "author_fullname": "t2_7td50", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it standard for data scientists to work solely on cloud computing platforms like GCP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1171lyy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676881854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I have recently been offered a data scientist position at my current company, but I was told that I would be working exclusively on the Google Cloud Platform (GCP), and that it won&amp;#39;t be necessary to code in Python. I&amp;#39;ve spent the past year learning about data science, models, and programming, and I&amp;#39;m concerned that all of that knowledge won&amp;#39;t be put to use in this new role. I always thought that a data scientist would be in front of their Jupyter notebook, so I&amp;#39;m worried that this is a cheap data scientist position.&lt;/p&gt;\n\n&lt;p&gt;My main question is: is it standard for data scientists to work solely on cloud computing platforms like GCP, and is it common to not code in Python? I&amp;#39;d love to hear your thoughts and experiences on this.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1171lyy", "is_robot_indexable": true, "report_reasons": null, "author": "asmodee59", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1171lyy/is_it_standard_for_data_scientists_to_work_solely/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1171lyy/is_it_standard_for_data_scientists_to_work_solely/", "subreddit_subscribers": 849649, "created_utc": 1676881854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently between jobs; my last boss told me he believes that improving my coding level will help me become a better data scientist.\n\nAny ideas how to work on that?\nPython, of course..", "author_fullname": "t2_rzfif4vz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to improve my coding level", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116m6as", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676836308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently between jobs; my last boss told me he believes that improving my coding level will help me become a better data scientist.&lt;/p&gt;\n\n&lt;p&gt;Any ideas how to work on that?\nPython, of course..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116m6as", "is_robot_indexable": true, "report_reasons": null, "author": "NoManner4303", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116m6as/how_to_improve_my_coding_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116m6as/how_to_improve_my_coding_level/", "subreddit_subscribers": 849649, "created_utc": 1676836308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It seems like there are countless data providers that offer identity solutions like skip tracing and people search capabilities, but all references to obtaining this information seem very broad and vague. \n\nSo, how are all of these companies aggregating their people data like phone numbers, email addresses, relatives, etc in an efficient way and with large coverage of the US population? \n\nAre there public bulk datasets that include this information so it can be aggregated and sold for marketing purposes without violating GLBA or FCRA regulations?\n\nAs an expert, how would you go about acquiring this information in bulk and qualifying it for accuracy?\n\nCurrently, the big players in the space are IDI, TLO, Delvepoint, and Tracers. They all have access to regulated data from credit bureaus and other third-parties to be sold to specific industries, but they also provide unregulated data for public use cases, so where is that information coming from?\n\nThis one has had me stumped for years.", "author_fullname": "t2_h5y5l2xd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tracers, IDI, Enformion, PIPL, etc -- How do these companies obtain their data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116oddc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676841802.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems like there are countless data providers that offer identity solutions like skip tracing and people search capabilities, but all references to obtaining this information seem very broad and vague. &lt;/p&gt;\n\n&lt;p&gt;So, how are all of these companies aggregating their people data like phone numbers, email addresses, relatives, etc in an efficient way and with large coverage of the US population? &lt;/p&gt;\n\n&lt;p&gt;Are there public bulk datasets that include this information so it can be aggregated and sold for marketing purposes without violating GLBA or FCRA regulations?&lt;/p&gt;\n\n&lt;p&gt;As an expert, how would you go about acquiring this information in bulk and qualifying it for accuracy?&lt;/p&gt;\n\n&lt;p&gt;Currently, the big players in the space are IDI, TLO, Delvepoint, and Tracers. They all have access to regulated data from credit bureaus and other third-parties to be sold to specific industries, but they also provide unregulated data for public use cases, so where is that information coming from?&lt;/p&gt;\n\n&lt;p&gt;This one has had me stumped for years.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116oddc", "is_robot_indexable": true, "report_reasons": null, "author": "Helpful-Bus9011", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116oddc/tracers_idi_enformion_pipl_etc_how_do_these/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116oddc/tracers_idi_enformion_pipl_etc_how_do_these/", "subreddit_subscribers": 849649, "created_utc": 1676841802.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the ever-evolving world of insurance, data is the key to success. The insurance industry relies heavily on data to make informed decisions about risk assessment, pricing, and customer engagement. With the advent of data-driven technologies, the insurance industry is increasingly adopting DataOps practices to optimize their data-driven processes and improve decision making.\n\nDataOps refers to the set of practices and technologies that organizations use to manage their data operations in a more efficient and effective manner. It involves a combination of people, processes, and tools that enable organizations to collect, process, and analyze data in real-time.\n\nIn this blog, we will explore some of the most impactful DataOps use cases in the insurance industry and how they can help organizations optimize their operations.\n\n#### Claims Prediction:\n\nOne of the most significant applications of DataOps in the insurance industry is the prediction of claims. By leveraging data from various sources such as historical claims data, demographic data, and weather data, organizations can develop predictive models that can help them identify high-risk areas and predict the likelihood of claims in a specific area. This information can then be used to adjust the pricing of insurance policies and to optimize the allocation of resources for claims management.\n\n#### Lifetime Value Prediction:\n\nDataOps can also be used to predict the lifetime value of a customer. This is an important metric for insurance companies as it helps them to determine the cost of acquiring new customers and the expected return on investment. By analyzing customer data such as demographic information, purchase history, and engagement levels, insurance companies can develop predictive models that can help them to estimate the lifetime value of a customer.\n\n#### Influencing Customer Behaviour:\n\nDataOps can also be used to influence customer behavior. By analyzing customer data, insurance companies can identify patterns in customer behavior that can help them to optimize their engagement strategies. For example, by understanding which channels are most effective for reaching a specific customer segment, insurance companies can target their marketing campaigns more effectively and drive customer engagement.\n\n#### Personalizing Marketing Strategies And Targeting Specific Customer\u00a0Groups:\n\nDataOps can also be used to personalize marketing strategies and target specific customer groups. By analyzing customer data, insurance companies can segment their customers based on various demographic, behavioral, and psychographic characteristics. This information can then be used to tailor marketing campaigns to specific customer segments, resulting in more effective engagement and higher conversion rates.\n\n#### Detecting And Mitigating Risk In Real-Time:\n\nDataOps can also be used to detect and mitigate risk in real-time. By analyzing real-time data from various sources such as social media, news outlets, and weather data, insurance companies can identify emerging risks and take proactive measures to mitigate their impact. This can help organizations to respond quickly to changing conditions and minimize the impact of potential risks on their operations.\n\n#### Detection Of Fraudulent Claims:\n\nFinally, DataOps can be used to detect fraudulent claims. By analyzing claims data in real-time, insurance companies can identify anomalies and potential fraud. This information can then be used to investigate claims and prevent fraudulent activity from occurring.\n\n#### Conclusion:\n\nIn conclusion, DataOps has the potential to transform the insurance industry by enabling organizations to make more informed decisions, optimize their operations, and improve customer engagement. By leveraging data from various sources, insurance companies can gain a competitive advantage and drive growth in a rapidly changing market. Whether you are an established insurance company or a start-up, DataOps can help you to achieve your goals and stay ahead of the curve.\n\nISmile Technologies DataOps Managed Services enable organizations to collect, process, and analyze data in real-time, allowing them to make informed decisions about risk assessment, pricing, customer engagement, and more. With our expertise and cutting-edge technologies, insurance companies can optimize their data-driven processes, increase efficiency, and stay ahead of the competition. [Schedule your free assessment](https://www.ismiletechnologies.com/contact-us/) today.", "author_fullname": "t2_d0d2s92o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataOps Usecases for Insurance Industry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1178pyh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676905264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the ever-evolving world of insurance, data is the key to success. The insurance industry relies heavily on data to make informed decisions about risk assessment, pricing, and customer engagement. With the advent of data-driven technologies, the insurance industry is increasingly adopting DataOps practices to optimize their data-driven processes and improve decision making.&lt;/p&gt;\n\n&lt;p&gt;DataOps refers to the set of practices and technologies that organizations use to manage their data operations in a more efficient and effective manner. It involves a combination of people, processes, and tools that enable organizations to collect, process, and analyze data in real-time.&lt;/p&gt;\n\n&lt;p&gt;In this blog, we will explore some of the most impactful DataOps use cases in the insurance industry and how they can help organizations optimize their operations.&lt;/p&gt;\n\n&lt;h4&gt;Claims Prediction:&lt;/h4&gt;\n\n&lt;p&gt;One of the most significant applications of DataOps in the insurance industry is the prediction of claims. By leveraging data from various sources such as historical claims data, demographic data, and weather data, organizations can develop predictive models that can help them identify high-risk areas and predict the likelihood of claims in a specific area. This information can then be used to adjust the pricing of insurance policies and to optimize the allocation of resources for claims management.&lt;/p&gt;\n\n&lt;h4&gt;Lifetime Value Prediction:&lt;/h4&gt;\n\n&lt;p&gt;DataOps can also be used to predict the lifetime value of a customer. This is an important metric for insurance companies as it helps them to determine the cost of acquiring new customers and the expected return on investment. By analyzing customer data such as demographic information, purchase history, and engagement levels, insurance companies can develop predictive models that can help them to estimate the lifetime value of a customer.&lt;/p&gt;\n\n&lt;h4&gt;Influencing Customer Behaviour:&lt;/h4&gt;\n\n&lt;p&gt;DataOps can also be used to influence customer behavior. By analyzing customer data, insurance companies can identify patterns in customer behavior that can help them to optimize their engagement strategies. For example, by understanding which channels are most effective for reaching a specific customer segment, insurance companies can target their marketing campaigns more effectively and drive customer engagement.&lt;/p&gt;\n\n&lt;h4&gt;Personalizing Marketing Strategies And Targeting Specific Customer\u00a0Groups:&lt;/h4&gt;\n\n&lt;p&gt;DataOps can also be used to personalize marketing strategies and target specific customer groups. By analyzing customer data, insurance companies can segment their customers based on various demographic, behavioral, and psychographic characteristics. This information can then be used to tailor marketing campaigns to specific customer segments, resulting in more effective engagement and higher conversion rates.&lt;/p&gt;\n\n&lt;h4&gt;Detecting And Mitigating Risk In Real-Time:&lt;/h4&gt;\n\n&lt;p&gt;DataOps can also be used to detect and mitigate risk in real-time. By analyzing real-time data from various sources such as social media, news outlets, and weather data, insurance companies can identify emerging risks and take proactive measures to mitigate their impact. This can help organizations to respond quickly to changing conditions and minimize the impact of potential risks on their operations.&lt;/p&gt;\n\n&lt;h4&gt;Detection Of Fraudulent Claims:&lt;/h4&gt;\n\n&lt;p&gt;Finally, DataOps can be used to detect fraudulent claims. By analyzing claims data in real-time, insurance companies can identify anomalies and potential fraud. This information can then be used to investigate claims and prevent fraudulent activity from occurring.&lt;/p&gt;\n\n&lt;h4&gt;Conclusion:&lt;/h4&gt;\n\n&lt;p&gt;In conclusion, DataOps has the potential to transform the insurance industry by enabling organizations to make more informed decisions, optimize their operations, and improve customer engagement. By leveraging data from various sources, insurance companies can gain a competitive advantage and drive growth in a rapidly changing market. Whether you are an established insurance company or a start-up, DataOps can help you to achieve your goals and stay ahead of the curve.&lt;/p&gt;\n\n&lt;p&gt;ISmile Technologies DataOps Managed Services enable organizations to collect, process, and analyze data in real-time, allowing them to make informed decisions about risk assessment, pricing, customer engagement, and more. With our expertise and cutting-edge technologies, insurance companies can optimize their data-driven processes, increase efficiency, and stay ahead of the competition. &lt;a href=\"https://www.ismiletechnologies.com/contact-us/\"&gt;Schedule your free assessment&lt;/a&gt; today.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1178pyh", "is_robot_indexable": true, "report_reasons": null, "author": "ismiletechnologies", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1178pyh/dataops_usecases_for_insurance_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1178pyh/dataops_usecases_for_insurance_industry/", "subreddit_subscribers": 849649, "created_utc": 1676905264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_qvzyx40q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone enter the field in 2021 or after without grad school? What were your experiences?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11772ng", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676900837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11772ng", "is_robot_indexable": true, "report_reasons": null, "author": "Night_candles", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11772ng/anyone_enter_the_field_in_2021_or_after_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11772ng/anyone_enter_the_field_in_2021_or_after_without/", "subreddit_subscribers": 849649, "created_utc": 1676900837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "https://github.com/R-Mahmoudi/Real-Time-Object-Counting-on-Jetson-Nano", "author_fullname": "t2_8okds99o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-Time-Object-Counting-on-Jetson-Nano", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1174q4x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676893901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/R-Mahmoudi/Real-Time-Object-Counting-on-Jetson-Nano\"&gt;https://github.com/R-Mahmoudi/Real-Time-Object-Counting-on-Jetson-Nano&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?auto=webp&amp;v=enabled&amp;s=44264ddd1301fb6a2553dfbaf25de52e81859762", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0253366b8b56018bb1bc9ca6be804344a1f0ed2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4aa1e7389a4567ac813342b76497e7ca6b7ef666", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b71df4dce96e270510e17377eaff09611ae42978", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d43a79fda5038558c3bcbcb0a1d4aad0c98a9cb2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e2901efc803629163ace0798e8c357b3f5d651d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57150797dcf0e1913275c638aec18356ab63810d", "width": 1080, "height": 540}], "variants": {}, "id": "4wKxqSgXRjxXQr3e8zlhq2HaL0BhefQZ4vum0hJ6XFI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1174q4x", "is_robot_indexable": true, "report_reasons": null, "author": "Smooth-Ad1528", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1174q4x/realtimeobjectcountingonjetsonnano/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1174q4x/realtimeobjectcountingonjetsonnano/", "subreddit_subscribers": 849649, "created_utc": 1676893901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 20 Feb, 2023 - 27 Feb, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116y7t5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676869288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116y7t5", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116y7t5/weekly_entering_transitioning_thread_20_feb_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/116y7t5/weekly_entering_transitioning_thread_20_feb_2023/", "subreddit_subscribers": 849649, "created_utc": 1676869288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone!\n\nI have a situation that I\u2019d very much love your opinion on!\n\nA little bit about myself: \nI have a MS in biomedical engineering, and I\u2019m currently pursuing a MS in analytics. I\u2019m expected to finish the degree by the end of 2023.\n\nI have just over 2 years of experience in a hospital as a research associate. 50% of my job duty is experimental design (mostly A/B testing), analyzing experimental dataset, visualization, etc. The size of the data is usually very small (n=200 or less). And the other 50% is sensors integration and hands on clinical experimental work. I\u2019m also an adjunct professor in university teaching biomedical engineering classes.\n\nI have a couple abstracts in ML published, and one manuscript currently in the work. However,  the journals I submitted to are very health-oriented. The technical findings are not ground breaking, just applying known ML techniques to the experimental data.\n\nInitially I was planning to pursue a PhD in biomed after finishing the analytics MS program, but I find myself swaying away. I\u2019d like to change to a pure DSA career afterwards.\n\nMy question is, should I apply to intern jobs and start over, or is my experience in the hospital valid? My work is 100% Python based, I know a bit of SQL from course project and leetcode.\n\nIt feels like aiming for a mid level job (2year +) may be too far fetched since I technically only have one full year of experience in DS.\n\nSo that may leave me with a new grad/ intern option\n\nWhat do you guys think? \n\nThanks so much", "author_fullname": "t2_t8c8gas5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Go for internship, new grad, or mid level career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116ws9x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676864560.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;\n\n&lt;p&gt;I have a situation that I\u2019d very much love your opinion on!&lt;/p&gt;\n\n&lt;p&gt;A little bit about myself: \nI have a MS in biomedical engineering, and I\u2019m currently pursuing a MS in analytics. I\u2019m expected to finish the degree by the end of 2023.&lt;/p&gt;\n\n&lt;p&gt;I have just over 2 years of experience in a hospital as a research associate. 50% of my job duty is experimental design (mostly A/B testing), analyzing experimental dataset, visualization, etc. The size of the data is usually very small (n=200 or less). And the other 50% is sensors integration and hands on clinical experimental work. I\u2019m also an adjunct professor in university teaching biomedical engineering classes.&lt;/p&gt;\n\n&lt;p&gt;I have a couple abstracts in ML published, and one manuscript currently in the work. However,  the journals I submitted to are very health-oriented. The technical findings are not ground breaking, just applying known ML techniques to the experimental data.&lt;/p&gt;\n\n&lt;p&gt;Initially I was planning to pursue a PhD in biomed after finishing the analytics MS program, but I find myself swaying away. I\u2019d like to change to a pure DSA career afterwards.&lt;/p&gt;\n\n&lt;p&gt;My question is, should I apply to intern jobs and start over, or is my experience in the hospital valid? My work is 100% Python based, I know a bit of SQL from course project and leetcode.&lt;/p&gt;\n\n&lt;p&gt;It feels like aiming for a mid level job (2year +) may be too far fetched since I technically only have one full year of experience in DS.&lt;/p&gt;\n\n&lt;p&gt;So that may leave me with a new grad/ intern option&lt;/p&gt;\n\n&lt;p&gt;What do you guys think? &lt;/p&gt;\n\n&lt;p&gt;Thanks so much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116ws9x", "is_robot_indexable": true, "report_reasons": null, "author": "Fatcatthebestcat", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116ws9x/go_for_internship_new_grad_or_mid_level_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116ws9x/go_for_internship_new_grad_or_mid_level_career/", "subreddit_subscribers": 849649, "created_utc": 1676864560.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I apologize I don't really know enough about this subject yet. From my understanding, it seems like most of the Big Tech companies don't fully own personal data but they own the infrastructure in which it is stored. I am an architecture student and I'm really interested in doing research about data centers. I am concerned with surveillance capitalism and am wondering if there is any potential in redesigning the physical infrastructure of how data is stored.", "author_fullname": "t2_4yh9ceg2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would community-owned data centers help with the sovereignty of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116wql0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676864402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I apologize I don&amp;#39;t really know enough about this subject yet. From my understanding, it seems like most of the Big Tech companies don&amp;#39;t fully own personal data but they own the infrastructure in which it is stored. I am an architecture student and I&amp;#39;m really interested in doing research about data centers. I am concerned with surveillance capitalism and am wondering if there is any potential in redesigning the physical infrastructure of how data is stored.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116wql0", "is_robot_indexable": true, "report_reasons": null, "author": "proudmisfit", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116wql0/would_communityowned_data_centers_help_with_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116wql0/would_communityowned_data_centers_help_with_the/", "subreddit_subscribers": 849649, "created_utc": 1676864402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I am interested to see what tools are in high demand right now. In addition, are any automation tools part of your data process?", "author_fullname": "t2_s2o8t6mt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tool and framework are you currently using in your data process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116jvbv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676830712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I am interested to see what tools are in high demand right now. In addition, are any automation tools part of your data process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116jvbv", "is_robot_indexable": true, "report_reasons": null, "author": "osa1501", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116jvbv/what_tool_and_framework_are_you_currently_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116jvbv/what_tool_and_framework_are_you_currently_using/", "subreddit_subscribers": 849649, "created_utc": 1676830712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to pursue a career in data. My laptop broke and looking for a replacement. Is[this](https://www.bestbuy.com/site/hp-victus-15-6-gaming-laptop-intel-core-i5-12450h-8gb-memory-nvidia-geforce-gtx-1650-512gb-ssd-mica-silver/6503849.p?skuId=6503849) good enough? To work on personal projects, build up a portfolio, do hackathons, etc\u2026 (Basically, is it enough for me to improve myself until I can land a job and upgrade?) I\u2019m planning to upgrade the ram to 16 gb.", "author_fullname": "t2_u5jtyok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Laptop Recommendation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1171kvk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676881739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to pursue a career in data. My laptop broke and looking for a replacement. Is&lt;a href=\"https://www.bestbuy.com/site/hp-victus-15-6-gaming-laptop-intel-core-i5-12450h-8gb-memory-nvidia-geforce-gtx-1650-512gb-ssd-mica-silver/6503849.p?skuId=6503849\"&gt;this&lt;/a&gt; good enough? To work on personal projects, build up a portfolio, do hackathons, etc\u2026 (Basically, is it enough for me to improve myself until I can land a job and upgrade?) I\u2019m planning to upgrade the ram to 16 gb.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?auto=webp&amp;v=enabled&amp;s=82d309dcc0a3f4b06f43eea82cc1f6f7361f3027", "width": 1240, "height": 1058}, "resolutions": [{"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78b2b17ee55ebee49c6dd6687dfdd043929fc91c", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=907a9f43766c88b04d763cf016b5c0e8ac4d2094", "width": 216, "height": 184}, {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e81ada832c9cb2954de3aa683e4cc27f863e6a57", "width": 320, "height": 273}, {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54258cc1b18f6b8a3007a08322b8a83e52cdface", "width": 640, "height": 546}, {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3e14fecb8401d7404124369b21e40f25d7e6d51", "width": 960, "height": 819}, {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7deb74ca4d9b75a3bb0be3871e4b1ecbf26454b3", "width": 1080, "height": 921}], "variants": {}, "id": "ogusEl8GfwyZ-TFcxoIYQGnIluKtIjKc9j3PLFWmF48"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1171kvk", "is_robot_indexable": true, "report_reasons": null, "author": "hazurdv", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1171kvk/laptop_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1171kvk/laptop_recommendation/", "subreddit_subscribers": 849649, "created_utc": 1676881739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I tried a loop function for a single time series but doing it for 43 series looks difficult it would be helpful if anyone can help with R loop code for this or any other easy way using eviews/excel/R.", "author_fullname": "t2_1y725091", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to transform monthly panel data into annual panel data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116jocm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.36, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676830241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried a loop function for a single time series but doing it for 43 series looks difficult it would be helpful if anyone can help with R loop code for this or any other easy way using eviews/excel/R.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116jocm", "is_robot_indexable": true, "report_reasons": null, "author": "The_Sassy_girl", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116jocm/how_to_transform_monthly_panel_data_into_annual/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116jocm/how_to_transform_monthly_panel_data_into_annual/", "subreddit_subscribers": 849649, "created_utc": 1676830241.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}