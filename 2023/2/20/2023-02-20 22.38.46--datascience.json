{"kind": "Listing", "data": {"after": "t3_1171kvk", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_gbo2p1mi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "There are too many charlatans on Linkedin posing as Data Scientist. Gone through his profile, not a single mention of his work. Most of the posts are engagement farming. The awards also seems to be suspicious and paid. My main question is who should you follow for quality content ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_116yrs4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 345, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 345, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mqxGMYzRHijwhhOO_sR84Wp-LKu_-mtumj2eTnNlaBg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676871193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/n5wm8qxr4aja1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/n5wm8qxr4aja1.png?auto=webp&amp;v=enabled&amp;s=8f85af0d9d8cab68f26f815c61d56e4d4aa9b823", "width": 617, "height": 740}, "resolutions": [{"url": "https://preview.redd.it/n5wm8qxr4aja1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37222747d05d86d5aead534b4abe58c0d1426aef", "width": 108, "height": 129}, {"url": "https://preview.redd.it/n5wm8qxr4aja1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c50e48c9a60cf99f60fedc57ebfbf3cf1117cf98", "width": 216, "height": 259}, {"url": "https://preview.redd.it/n5wm8qxr4aja1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf62ebccdd7ec3d118100cb7396f92b4cb28d20b", "width": 320, "height": 383}], "variants": {}, "id": "dBKttO9EuDjVmm1Va3D1V8Vp6Hkjo6lp0FLuUzCiRI4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "116yrs4", "is_robot_indexable": true, "report_reasons": null, "author": "Mental-Leopard8027", "discussion_type": null, "num_comments": 120, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116yrs4/there_are_too_many_charlatans_on_linkedin_posing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/n5wm8qxr4aja1.png", "subreddit_subscribers": 849738, "created_utc": 1676871193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey, guys. We have made a plugin that turns your pandas data frame into a tableau-style component. It allows you to explore the data frame with an easy drag-and-drop UI.\n\nYou can use PyGWalker in Jupyter, Google Colab, or even Kaggle Notebook to easily explore your data and generate interactive visualizations.\n\nHere are some links to check it out:\n\nThe Github Repo: [https://github.com/Kanaries/pygwalker](https://github.com/Kanaries/pygwalker)\n\nUse PyGWalker in Kaggle: [https://www.kaggle.com/asmdef/pygwalker-test](https://www.kaggle.com/asmdef/pygwalker-test)\n\nFeedback and suggestions are appreciated! Please feel free to try it out and let us know what you think. Thanks for your support!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/a7jcuw1gbdja1.png?width=2748&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7a344854cfae94086999b448d5d992d3b6e60943\n\n&amp;#x200B;\n\n[Run PyGWalker in Kaggle](https://preview.redd.it/ev8ellb6bdja1.png?width=2748&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=30b4206cdc00b6ea2425680cd970cf7e1d23cecd)", "author_fullname": "t2_dnzigfn3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PyGWalker: Turn your Pandas Dataframe into a Tableau-style UI for Visual Analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "media_metadata": {"a7jcuw1gbdja1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/a7jcuw1gbdja1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=899a7fb01b8a7bd7956c74734c318f33a7826a30"}, {"y": 133, "x": 216, "u": "https://preview.redd.it/a7jcuw1gbdja1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=528ae415e801e79549d9999cf328683c0cf1ce14"}, {"y": 197, "x": 320, "u": "https://preview.redd.it/a7jcuw1gbdja1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=edfaba8716c9f5be8f61f1e3a3562c376738a904"}, {"y": 394, "x": 640, "u": "https://preview.redd.it/a7jcuw1gbdja1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a454c394737403f425879b1f7cc1148f4e13332f"}, {"y": 591, "x": 960, "u": "https://preview.redd.it/a7jcuw1gbdja1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=696bb2fa979f992b00496eb11705e39ca1be114d"}, {"y": 665, "x": 1080, "u": "https://preview.redd.it/a7jcuw1gbdja1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6184d1bdd8c6f85a1b00bf7989db2ff24d68fd14"}], "s": {"y": 1694, "x": 2748, "u": "https://preview.redd.it/a7jcuw1gbdja1.png?width=2748&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7a344854cfae94086999b448d5d992d3b6e60943"}, "id": "a7jcuw1gbdja1"}, "ev8ellb6bdja1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/ev8ellb6bdja1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=46f863b2c6be01893d71aa5eb2cb02a957736390"}, {"y": 138, "x": 216, "u": "https://preview.redd.it/ev8ellb6bdja1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4e113af0997e09fb2be87ddd4c6f52b7603de3aa"}, {"y": 204, "x": 320, "u": "https://preview.redd.it/ev8ellb6bdja1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d60017d77fffe03e418376cc965f7f351937ef1d"}, {"y": 409, "x": 640, "u": "https://preview.redd.it/ev8ellb6bdja1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4137906f81f966351e66ab070e1b1690472e2f4"}, {"y": 614, "x": 960, "u": "https://preview.redd.it/ev8ellb6bdja1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c32eadaae92d80467eb2b095e0921892b569729e"}, {"y": 691, "x": 1080, "u": "https://preview.redd.it/ev8ellb6bdja1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e8ef23b291998ea042108e8c67469f4df150215"}], "s": {"y": 1760, "x": 2748, "u": "https://preview.redd.it/ev8ellb6bdja1.png?width=2748&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=30b4206cdc00b6ea2425680cd970cf7e1d23cecd"}, "id": "ev8ellb6bdja1"}}, "name": "t3_117bptb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "ups": 111, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 111, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5D76FpC0816EQhDkzdYFtQM-6Rzt2HBFguqezhIMq8Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1676909557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, guys. We have made a plugin that turns your pandas data frame into a tableau-style component. It allows you to explore the data frame with an easy drag-and-drop UI.&lt;/p&gt;\n\n&lt;p&gt;You can use PyGWalker in Jupyter, Google Colab, or even Kaggle Notebook to easily explore your data and generate interactive visualizations.&lt;/p&gt;\n\n&lt;p&gt;Here are some links to check it out:&lt;/p&gt;\n\n&lt;p&gt;The Github Repo: &lt;a href=\"https://github.com/Kanaries/pygwalker\"&gt;https://github.com/Kanaries/pygwalker&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Use PyGWalker in Kaggle: &lt;a href=\"https://www.kaggle.com/asmdef/pygwalker-test\"&gt;https://www.kaggle.com/asmdef/pygwalker-test&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Feedback and suggestions are appreciated! Please feel free to try it out and let us know what you think. Thanks for your support!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/a7jcuw1gbdja1.png?width=2748&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7a344854cfae94086999b448d5d992d3b6e60943\"&gt;https://preview.redd.it/a7jcuw1gbdja1.png?width=2748&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=7a344854cfae94086999b448d5d992d3b6e60943&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ev8ellb6bdja1.png?width=2748&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=30b4206cdc00b6ea2425680cd970cf7e1d23cecd\"&gt;Run PyGWalker in Kaggle&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DSI35EaOSIDU1ZLIVuDjeadT3vtmLJU7pge0tHH9RKY.jpg?auto=webp&amp;v=enabled&amp;s=f6c093b3425a722c736364a35cc868543eff1413", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/DSI35EaOSIDU1ZLIVuDjeadT3vtmLJU7pge0tHH9RKY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3f2dc64d6b141c4e4c9cee7d7acf92b3701c290", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/DSI35EaOSIDU1ZLIVuDjeadT3vtmLJU7pge0tHH9RKY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=de1cf0550a09bd0403d0ab671090588ba9ad4f7f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/DSI35EaOSIDU1ZLIVuDjeadT3vtmLJU7pge0tHH9RKY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a5eec7b80b6d56d591e130b103f0667579df7e03", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/DSI35EaOSIDU1ZLIVuDjeadT3vtmLJU7pge0tHH9RKY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6460d3d3ad651962af35982f9ca7318e64e49a10", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/DSI35EaOSIDU1ZLIVuDjeadT3vtmLJU7pge0tHH9RKY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f7f9f506e6ce2f4a64e3a6b22c5b63e544bffe7", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/DSI35EaOSIDU1ZLIVuDjeadT3vtmLJU7pge0tHH9RKY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d3d0fcb761926b3cc1359c532de085aadaecb0b1", "width": 1080, "height": 540}], "variants": {}, "id": "ilf2WPnXAy0eaKb8JhIN3rP1-_pEPLnXfmF3g5bEZDw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "117bptb", "is_robot_indexable": true, "report_reasons": null, "author": "Sudden_Beginning_597", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/117bptb/pygwalker_turn_your_pandas_dataframe_into_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/117bptb/pygwalker_turn_your_pandas_dataframe_into_a/", "subreddit_subscribers": 849738, "created_utc": 1676909557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I often find myself wanting to run a couple SQL commands against a CSV, I have poor Excel skills, and so I made [https://sqlacsv.com/](https://sqlacsv.com/). You can drag-n-drop any CSV, its a completely offline app, and it gives a quick overview of each column's distribution.\n\n**Is this something people might find helpful? Would love to get some feedback on the tool.** \n\nHere some screenshots of what happens after you upload a CSV:\n\n[Simple SQL Editor](https://preview.redd.it/335fjx7cr8ja1.png?width=1886&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a22da852724c61f4846ca08f917111e9b99f980c)\n\n&amp;#x200B;\n\n[Overview of Values per Columns](https://preview.redd.it/qlt46ttdr8ja1.png?width=1873&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9d3e64d2eeac20b69c2d4805fd2e307b04ae6789)\n\nThanks in advanced!", "author_fullname": "t2_ynkil", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Website to quickly SQL a CSV: feedback?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 63, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qlt46ttdr8ja1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06ae57099f905bf7f1f4b3e5095307e272000cd8"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=07a3b8e32d4f280bd71cb0a72166dafcc10d9ece"}, {"y": 151, "x": 320, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72afe3f4b2f2bbeab9a1377706cb078b7bb7e91d"}, {"y": 303, "x": 640, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ccb5242268ea20f744164a3cf836b4cf3cf5dec"}, {"y": 454, "x": 960, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d9f9e7e8bb6c33dc377b4a8dcd08b79d4a18e8fa"}, {"y": 511, "x": 1080, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2f5077f4a6108be495fa9bd2d7c3713b6a158af6"}], "s": {"y": 887, "x": 1873, "u": "https://preview.redd.it/qlt46ttdr8ja1.png?width=1873&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9d3e64d2eeac20b69c2d4805fd2e307b04ae6789"}, "id": "qlt46ttdr8ja1"}, "335fjx7cr8ja1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 48, "x": 108, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fabf8f4c9f5c8081b68564f1e611e26daf15e6a"}, {"y": 97, "x": 216, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6487f140f6e5cc728157a3e43654a092d9746596"}, {"y": 145, "x": 320, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a3f3e60c3300cb9fd2d8405dad2d1ee21fa2edd"}, {"y": 290, "x": 640, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4592dd9d6b785c49da973a78fdcfb6018790445e"}, {"y": 435, "x": 960, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fb376923ab3ad675ccb2b34833b2203faf43082"}, {"y": 489, "x": 1080, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed1ba5c9dbd7103d8fb8a145ee88226085493528"}], "s": {"y": 855, "x": 1886, "u": "https://preview.redd.it/335fjx7cr8ja1.png?width=1886&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a22da852724c61f4846ca08f917111e9b99f980c"}, "id": "335fjx7cr8ja1"}}, "name": "t3_116tgd8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 89, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 89, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LcP4XMrwO1f_KnyFGINRJlIZ3JLRH3nA3V9u534oMQU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676854607.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I often find myself wanting to run a couple SQL commands against a CSV, I have poor Excel skills, and so I made &lt;a href=\"https://sqlacsv.com/\"&gt;https://sqlacsv.com/&lt;/a&gt;. You can drag-n-drop any CSV, its a completely offline app, and it gives a quick overview of each column&amp;#39;s distribution.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is this something people might find helpful? Would love to get some feedback on the tool.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Here some screenshots of what happens after you upload a CSV:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/335fjx7cr8ja1.png?width=1886&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=a22da852724c61f4846ca08f917111e9b99f980c\"&gt;Simple SQL Editor&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qlt46ttdr8ja1.png?width=1873&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9d3e64d2eeac20b69c2d4805fd2e307b04ae6789\"&gt;Overview of Values per Columns&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advanced!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116tgd8", "is_robot_indexable": true, "report_reasons": null, "author": "downvotedragon", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116tgd8/website_to_quickly_sql_a_csv_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116tgd8/website_to_quickly_sql_a_csv_feedback/", "subreddit_subscribers": 849738, "created_utc": 1676854607.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, I'm planning to create a dashboard for data visualization, and I think I want to use Python for the project. I've been looking into Dash and Streamlit, but I'm not sure which one would be the best choice for a beginner like me. Do you have any suggestions on which library to use? Also, I'm hoping to find a library that won't have a very steep learning curve.\n\nIf you have any recommendations for other Python-based libraries for data visualization and dashboard creation, I'd love to hear them as well. Thanks in advance for your help!", "author_fullname": "t2_5qka7bxz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Python Libraries for Data Visualization and Dashboard Creation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116us5l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676858394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m planning to create a dashboard for data visualization, and I think I want to use Python for the project. I&amp;#39;ve been looking into Dash and Streamlit, but I&amp;#39;m not sure which one would be the best choice for a beginner like me. Do you have any suggestions on which library to use? Also, I&amp;#39;m hoping to find a library that won&amp;#39;t have a very steep learning curve.&lt;/p&gt;\n\n&lt;p&gt;If you have any recommendations for other Python-based libraries for data visualization and dashboard creation, I&amp;#39;d love to hear them as well. Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116us5l", "is_robot_indexable": true, "report_reasons": null, "author": "theflash444123", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116us5l/best_python_libraries_for_data_visualization_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116us5l/best_python_libraries_for_data_visualization_and/", "subreddit_subscribers": 849738, "created_utc": 1676858394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So Basically I have worked on a data science project with a professor in Cannada and we got good results in a medical dataset and got a good AUROC of .85 and we published the paper for it and got selected , but what surprised me was the professor never went through my code and just gave suggestions and tips to do improve the model , but isn't this a lot risky.Everyday I am scared that some person would go through my code and invalidate my entire results based on some simple error which could have been corrected if there were proper code reviews.\n\nFast forward 6 months , I got a job in  a data science company as an intern and he told me to develop self supervised model for their image dataset and I did that and it good kind of okay results and he told me to move on to another project , still there was no code reviews or code checks , do people in data science just blindly trust each others code , I feel managers should at least give a look through to see if we taking the correct data split or if the model is correct or if there is any data leakage.There is a lot of red flags in trusting the AUROC results blindly. Is this a norm or maybe its just for me.\n\nMoreover most of the data scientists in the company dont even write proper documentation and for interns like me its such a pain , it took  me 2 weeks to understand their entire training repo, data science people should talk with the data engineers and take some of their methods and practices.", "author_fullname": "t2_py4qwirz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it normal in the data Science field to not have that many code checks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11714te", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676880230.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676880002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So Basically I have worked on a data science project with a professor in Cannada and we got good results in a medical dataset and got a good AUROC of .85 and we published the paper for it and got selected , but what surprised me was the professor never went through my code and just gave suggestions and tips to do improve the model , but isn&amp;#39;t this a lot risky.Everyday I am scared that some person would go through my code and invalidate my entire results based on some simple error which could have been corrected if there were proper code reviews.&lt;/p&gt;\n\n&lt;p&gt;Fast forward 6 months , I got a job in  a data science company as an intern and he told me to develop self supervised model for their image dataset and I did that and it good kind of okay results and he told me to move on to another project , still there was no code reviews or code checks , do people in data science just blindly trust each others code , I feel managers should at least give a look through to see if we taking the correct data split or if the model is correct or if there is any data leakage.There is a lot of red flags in trusting the AUROC results blindly. Is this a norm or maybe its just for me.&lt;/p&gt;\n\n&lt;p&gt;Moreover most of the data scientists in the company dont even write proper documentation and for interns like me its such a pain , it took  me 2 weeks to understand their entire training repo, data science people should talk with the data engineers and take some of their methods and practices.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11714te", "is_robot_indexable": true, "report_reasons": null, "author": "skeletons_of_closet", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11714te/is_it_normal_in_the_data_science_field_to_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11714te/is_it_normal_in_the_data_science_field_to_not/", "subreddit_subscribers": 849738, "created_utc": 1676880002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am thinking about how Amazon reportedly axed a lot of Alexa teams.  This seems to point to negative.  But ChatGPT is taking up a lot of interest. This seems to point to positive.   What are your thoughts?", "author_fullname": "t2_y7l57", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is NLP a sub-field with a lot of growth?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_117736x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676900874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am thinking about how Amazon reportedly axed a lot of Alexa teams.  This seems to point to negative.  But ChatGPT is taking up a lot of interest. This seems to point to positive.   What are your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "117736x", "is_robot_indexable": true, "report_reasons": null, "author": "sonicking12", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/117736x/is_nlp_a_subfield_with_a_lot_of_growth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/117736x/is_nlp_a_subfield_with_a_lot_of_growth/", "subreddit_subscribers": 849738, "created_utc": 1676900874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I am fitting count data for each place. That means, my response variable is the count data and I want to regress them to given explanatory variables. And each row represents each place. But the problem is that the count data are collected over years and I found it has a seasonal pattern. I am sorry to confuse you but I also have another dataset that consists of count data according to time and I used this dataset to visualize the time series plot.\n\nSo, my main goal is to make a regression model of the count data using explanatory in the original dataset (that has no time component) while adjusting for seasonality and my question is how I can deal with this. Do I have to request for the new dataset that contains the time the count data were recorded and fit a regression model? Thank you in advance!", "author_fullname": "t2_4b2tl19h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Regression and Time Series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116qyz0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676848212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am fitting count data for each place. That means, my response variable is the count data and I want to regress them to given explanatory variables. And each row represents each place. But the problem is that the count data are collected over years and I found it has a seasonal pattern. I am sorry to confuse you but I also have another dataset that consists of count data according to time and I used this dataset to visualize the time series plot.&lt;/p&gt;\n\n&lt;p&gt;So, my main goal is to make a regression model of the count data using explanatory in the original dataset (that has no time component) while adjusting for seasonality and my question is how I can deal with this. Do I have to request for the new dataset that contains the time the count data were recorded and fit a regression model? Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116qyz0", "is_robot_indexable": true, "report_reasons": null, "author": "ZirhoZirk", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116qyz0/regression_and_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116qyz0/regression_and_time_series/", "subreddit_subscribers": 849738, "created_utc": 1676848212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Deploy Machine Learning Models with Django\n\nhttps://github.com/R-Mahmoudi/DeployMachineLearningModel", "author_fullname": "t2_8okds99o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploy Machine Learning Models with Django", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116qef7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676846814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Deploy Machine Learning Models with Django&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/R-Mahmoudi/DeployMachineLearningModel\"&gt;https://github.com/R-Mahmoudi/DeployMachineLearningModel&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?auto=webp&amp;v=enabled&amp;s=54fe2ce57a49bacdfccaa126f6e2b3929d963494", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0dcfccb0b32f4400bfdfe104f26239095176289", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e1b585d921be17536437cad1c0f75a5cc5f54051", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8ba5f88b0b60b8922164d573e76d11094050a9f4", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d56082665ef2d7db8324e0f0f62579a5df6e41cf", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f9c70f7f579ccc9a99838f6fd1e5eb53292cac9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ZzaaH894sHSinNu5ukml0I7FzUSxYoBd5Wdu9dFgUvY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eeaf1ed5a485c360bf86e694b29e92fefe8da94f", "width": 1080, "height": 540}], "variants": {}, "id": "Buhe-VKKc_DiDzwK1BiE0lE1sSfhx-mcqd7OhXRvT9A"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116qef7", "is_robot_indexable": true, "report_reasons": null, "author": "Smooth-Ad1528", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116qef7/deploy_machine_learning_models_with_django/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116qef7/deploy_machine_learning_models_with_django/", "subreddit_subscribers": 849738, "created_utc": 1676846814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 20 Feb, 2023 - 27 Feb, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116y7t5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676869288.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116y7t5", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 22, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116y7t5/weekly_entering_transitioning_thread_20_feb_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/116y7t5/weekly_entering_transitioning_thread_20_feb_2023/", "subreddit_subscribers": 849738, "created_utc": 1676869288.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi how's it going?\n\nFor a long time I've been very perplexed as to *why* the Poisson and Exponential PDF are what they are. All the textbooks just say \"Here's the PDF, integrate it to get the CDF..there you go\".\n\nBut why the number E? I'm trying to really understand intuitively the Exponential family of distributions from the ground up. \n\nFor example I fully understand the Binomial from the viewpoint of combinations. It's the different orderings of a string of 1's and 0's essentially, weighted by their probabilities of occurring. Then you add up all the orderings where there are K 1's and that's P(X=k).\n\nI want to get that same intuition for the Poisson and Exponential distribution. Any good videos or books or articles?", "author_fullname": "t2_r24fq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best resource to understand intuitively the PDF of the Poisson and Exponential Distributions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_117j74m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676923985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi how&amp;#39;s it going?&lt;/p&gt;\n\n&lt;p&gt;For a long time I&amp;#39;ve been very perplexed as to &lt;em&gt;why&lt;/em&gt; the Poisson and Exponential PDF are what they are. All the textbooks just say &amp;quot;Here&amp;#39;s the PDF, integrate it to get the CDF..there you go&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;But why the number E? I&amp;#39;m trying to really understand intuitively the Exponential family of distributions from the ground up. &lt;/p&gt;\n\n&lt;p&gt;For example I fully understand the Binomial from the viewpoint of combinations. It&amp;#39;s the different orderings of a string of 1&amp;#39;s and 0&amp;#39;s essentially, weighted by their probabilities of occurring. Then you add up all the orderings where there are K 1&amp;#39;s and that&amp;#39;s P(X=k).&lt;/p&gt;\n\n&lt;p&gt;I want to get that same intuition for the Poisson and Exponential distribution. Any good videos or books or articles?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "117j74m", "is_robot_indexable": true, "report_reasons": null, "author": "Frank2234", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/117j74m/what_is_the_best_resource_to_understand/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/117j74m/what_is_the_best_resource_to_understand/", "subreddit_subscribers": 849738, "created_utc": 1676923985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1s1t73vu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I built a \"clone\" of the New Bing - I appreciate any feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2lmhpt5akeja1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/2lmhpt5akeja1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45d2a1b0341810472f9e2fe44698da010574f255"}, {"y": 108, "x": 216, "u": "https://preview.redd.it/2lmhpt5akeja1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a50a46f19a221706ce764a31a94bf1cd8cc801a4"}, {"y": 160, "x": 320, "u": "https://preview.redd.it/2lmhpt5akeja1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e81e62fa4b81ea926132d2e7fe4d96344172e7d5"}, {"y": 320, "x": 640, "u": "https://preview.redd.it/2lmhpt5akeja1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=962f3951a35868857ac0197b147e3a15690b151b"}, {"y": 480, "x": 960, "u": "https://preview.redd.it/2lmhpt5akeja1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4eac3700302244c799a0c549140e76bb5270377"}, {"y": 540, "x": 1080, "u": "https://preview.redd.it/2lmhpt5akeja1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b45d158e51e76fa1bf691c034624a3442a75d21"}], "s": {"y": 1282, "x": 2564, "u": "https://preview.redd.it/2lmhpt5akeja1.png?width=2564&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=130225eede40cc5290bfa9be150b2cab118bc96b"}, "id": "2lmhpt5akeja1"}, "5165a8m8keja1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 61, "x": 108, "u": "https://preview.redd.it/5165a8m8keja1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a8d0da8d12f37da699fdb1a87dbe6bd9a87b4fc2"}, {"y": 123, "x": 216, "u": "https://preview.redd.it/5165a8m8keja1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5714afc8752ec9ee09cb6d44594beb7755d1da05"}, {"y": 182, "x": 320, "u": "https://preview.redd.it/5165a8m8keja1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b5c9200c3b32d412cbc7d90c238aafdae21d4066"}, {"y": 365, "x": 640, "u": "https://preview.redd.it/5165a8m8keja1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d228f8cbf241572354a2aac7f4c4094003c2f51f"}, {"y": 548, "x": 960, "u": "https://preview.redd.it/5165a8m8keja1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08583adf5bb81a4ec1b83a24462fa67c68d31213"}, {"y": 616, "x": 1080, "u": "https://preview.redd.it/5165a8m8keja1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=211a677c72cc195a62c3e403da1707c459a9ef57"}], "s": {"y": 914, "x": 1600, "u": "https://preview.redd.it/5165a8m8keja1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8e9855861b98cebbb261d86428e022b587cf7edd"}, "id": "5165a8m8keja1"}, "l00z2bukkeja1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 61, "x": 108, "u": "https://preview.redd.it/l00z2bukkeja1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd6e4ee2ee5f8c45e85921ea6d1258dfc3b4f46d"}, {"y": 122, "x": 216, "u": "https://preview.redd.it/l00z2bukkeja1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fbfd736d90116edb7e8515085bac9028a8f6b2d0"}, {"y": 181, "x": 320, "u": "https://preview.redd.it/l00z2bukkeja1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8441d0cab2b32d5579734315feedcbf7867df0ad"}, {"y": 362, "x": 640, "u": "https://preview.redd.it/l00z2bukkeja1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ee8ff3b7ce67a36d8e040d437130bfd57e3c5f4c"}, {"y": 543, "x": 960, "u": "https://preview.redd.it/l00z2bukkeja1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=578df4dcd79a8591580db8d5f907a228eb60a5f2"}, {"y": 610, "x": 1080, "u": "https://preview.redd.it/l00z2bukkeja1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6f8278863023d7f8f5e68146b90209a304962a20"}], "s": {"y": 905, "x": 1600, "u": "https://preview.redd.it/l00z2bukkeja1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=bf9e1c079d9d72a6e10b94f1a563b1f1c5be1f37"}, "id": "l00z2bukkeja1"}, "9m052yk9keja1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 65, "x": 108, "u": "https://preview.redd.it/9m052yk9keja1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b77f0e2776e7082d428598581ee64ddc9dee0687"}, {"y": 131, "x": 216, "u": "https://preview.redd.it/9m052yk9keja1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f400ae68bb726732564c316932a60a57829b144d"}, {"y": 195, "x": 320, "u": "https://preview.redd.it/9m052yk9keja1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f44084a6fb6d0bbc911b04f6c49937579ba1e8c5"}, {"y": 390, "x": 640, "u": "https://preview.redd.it/9m052yk9keja1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=35c593efc3ad8885f9b8dd697cb36c6021f2b79b"}, {"y": 586, "x": 960, "u": "https://preview.redd.it/9m052yk9keja1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=85978ba115c445ddb07b1bc165344b0ff9eacb3c"}, {"y": 659, "x": 1080, "u": "https://preview.redd.it/9m052yk9keja1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d4b46acde7b869bf852075f0c87d4aa79bd9ca47"}], "s": {"y": 972, "x": 1592, "u": "https://preview.redd.it/9m052yk9keja1.jpg?width=1592&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6fc665c7b54620717c330428c7f7b2a396dcd201"}, "id": "9m052yk9keja1"}, "re8uvf9kkeja1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 61, "x": 108, "u": "https://preview.redd.it/re8uvf9kkeja1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ae735a57e1f765cbc01e791528166457e59dbe9"}, {"y": 123, "x": 216, "u": "https://preview.redd.it/re8uvf9kkeja1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be13d2b55d167c4c7bcddf03c5a6419a43bd2938"}, {"y": 182, "x": 320, "u": "https://preview.redd.it/re8uvf9kkeja1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=18197da482282a3dbca7c3cde42b6c4e833dd14c"}, {"y": 365, "x": 640, "u": "https://preview.redd.it/re8uvf9kkeja1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2bb9941541d30d92f1edcba5c873b593ff16abb8"}, {"y": 547, "x": 960, "u": "https://preview.redd.it/re8uvf9kkeja1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d69d977de828bd589b92766f32c4c9556827c921"}, {"y": 616, "x": 1080, "u": "https://preview.redd.it/re8uvf9kkeja1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb51c9c46b8f6803eb73a2af8c8c618ede7c638f"}], "s": {"y": 913, "x": 1600, "u": "https://preview.redd.it/re8uvf9kkeja1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6ee2875482c401f9d8a881cd46215857502cb01e"}, "id": "re8uvf9kkeja1"}}, "name": "t3_117jl6p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "GitHub repo", "outbound_url": "https://github.com/trantrikien239/cetasearch", "media_id": "2lmhpt5akeja1", "id": 242868351}, {"caption": "Details", "outbound_url": "https://master-data.science/portfolio/cetasearch-conversational-search-engine/", "media_id": "5165a8m8keja1", "id": 242868352}, {"media_id": "9m052yk9keja1", "id": 242868353}, {"outbound_url": "https://master-data.science/portfolio/cetasearch-conversational-search-engine/", "media_id": "re8uvf9kkeja1", "id": 242868354}, {"outbound_url": "https://master-data.science/portfolio/cetasearch-conversational-search-engine/", "media_id": "l00z2bukkeja1", "id": 242868355}]}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aiepcnsYhfn3vajPs8iCdXppsqzUn_uIja7YA17i8mk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676924923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/117jl6p", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": null, "id": "117jl6p", "is_robot_indexable": true, "report_reasons": null, "author": "trantrikien239", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/117jl6p/i_built_a_clone_of_the_new_bing_i_appreciate_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/trantrikien239/cetasearch", "subreddit_subscribers": 849738, "created_utc": 1676924923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This article shows some efficient ways how to share big NumPy arrays across python processes:\n\n[https://medium.com/p/abf0dc2a0ab2](https://medium.com/p/abf0dc2a0ab2) (no paywall)\n\nYou might find it very useful if you need to keep one or more NumPy arrays in memory that serve as the \u201cdatabase\u201d for specific computations (e.g. making online cbf recommendations).", "author_fullname": "t2_9pf7fclp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sharing big NumPy arrays across python processes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_117lsfi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676930156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This article shows some efficient ways how to share big NumPy arrays across python processes:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/p/abf0dc2a0ab2\"&gt;https://medium.com/p/abf0dc2a0ab2&lt;/a&gt; (no paywall)&lt;/p&gt;\n\n&lt;p&gt;You might find it very useful if you need to keep one or more NumPy arrays in memory that serve as the \u201cdatabase\u201d for specific computations (e.g. making online cbf recommendations).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qKVxDHuy58m7vwVL0jj3fJUTJxXTQaliAtmcLD0QU9w.jpg?auto=webp&amp;v=enabled&amp;s=b7df1162e1e686769f94bc08ba1eb86bca1cb4b2", "width": 1200, "height": 540}, "resolutions": [{"url": "https://external-preview.redd.it/qKVxDHuy58m7vwVL0jj3fJUTJxXTQaliAtmcLD0QU9w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f959c7aa11f673393a33e051be301c684b9315d8", "width": 108, "height": 48}, {"url": "https://external-preview.redd.it/qKVxDHuy58m7vwVL0jj3fJUTJxXTQaliAtmcLD0QU9w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=524302fc32d8994b1f7a6333e73beb135eff590d", "width": 216, "height": 97}, {"url": "https://external-preview.redd.it/qKVxDHuy58m7vwVL0jj3fJUTJxXTQaliAtmcLD0QU9w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bc3cf83ecf879c54d85259c0bfd68347052555e", "width": 320, "height": 144}, {"url": "https://external-preview.redd.it/qKVxDHuy58m7vwVL0jj3fJUTJxXTQaliAtmcLD0QU9w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=362032304b03d2e8c690c0f3aa4ada8073cbfc8e", "width": 640, "height": 288}, {"url": "https://external-preview.redd.it/qKVxDHuy58m7vwVL0jj3fJUTJxXTQaliAtmcLD0QU9w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49de2c9554006ca090b61000107c583863b36dae", "width": 960, "height": 432}, {"url": "https://external-preview.redd.it/qKVxDHuy58m7vwVL0jj3fJUTJxXTQaliAtmcLD0QU9w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ae95e94950d84e9da04e6b5827a0c3395285ddc9", "width": 1080, "height": 486}], "variants": {}, "id": "yz0JYODuigut_WUv20awuo6hGBbJ5Uk0vV61gBRD9wM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "117lsfi", "is_robot_indexable": true, "report_reasons": null, "author": "lmsena", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/117lsfi/sharing_big_numpy_arrays_across_python_processes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/117lsfi/sharing_big_numpy_arrays_across_python_processes/", "subreddit_subscribers": 849738, "created_utc": 1676930156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi - does anyone know a service which takes a barcode in an email and creates a capture/user action? Best example would be TripIt. How they add it to your trip and you just have to forward your flight or hotel itinerary..? Anyone? \nThanks!", "author_fullname": "t2_e6wyvub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question - email marketing feature", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_117kxyj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676928149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi - does anyone know a service which takes a barcode in an email and creates a capture/user action? Best example would be TripIt. How they add it to your trip and you just have to forward your flight or hotel itinerary..? Anyone? \nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "117kxyj", "is_robot_indexable": true, "report_reasons": null, "author": "OG_dfb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/117kxyj/question_email_marketing_feature/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/117kxyj/question_email_marketing_feature/", "subreddit_subscribers": 849738, "created_utc": 1676928149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "is it important for Machine Learning Engineer to have an extra Industry Level skill like Web development or Python Developer or not.  \nbecause, if he has good programming skills but don't know any web framework or dont know much about anything other than those python ML libraries. is it ok?", "author_fullname": "t2_c5y1p4fr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imp Q regarding Machine Learning Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_117jl6y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676924924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;is it important for Machine Learning Engineer to have an extra Industry Level skill like Web development or Python Developer or not.&lt;br/&gt;\nbecause, if he has good programming skills but don&amp;#39;t know any web framework or dont know much about anything other than those python ML libraries. is it ok?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "117jl6y", "is_robot_indexable": true, "report_reasons": null, "author": "IndependentFresh628", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/117jl6y/imp_q_regarding_machine_learning_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/117jl6y/imp_q_regarding_machine_learning_engineer/", "subreddit_subscribers": 849738, "created_utc": 1676924924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I finished an online Python course and wanted to start working on my own project, but I'm feeling a little directionless currently. I've written a function which accesses the API and creates a dictionary of dates and a user's rating on that date but I'm unsure what to do with this. I tried putting it into a SQLite database by using an online tutorial but the .db file was an unreadable jumble of red coloured characters. For someone who's essentially a beginner to data analysis, what should I try and learn/focus on to be able to do something useful with this data?", "author_fullname": "t2_koefmzaw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Taken data from a website's API - Now what?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_117j54j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676923857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I finished an online Python course and wanted to start working on my own project, but I&amp;#39;m feeling a little directionless currently. I&amp;#39;ve written a function which accesses the API and creates a dictionary of dates and a user&amp;#39;s rating on that date but I&amp;#39;m unsure what to do with this. I tried putting it into a SQLite database by using an online tutorial but the .db file was an unreadable jumble of red coloured characters. For someone who&amp;#39;s essentially a beginner to data analysis, what should I try and learn/focus on to be able to do something useful with this data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "117j54j", "is_robot_indexable": true, "report_reasons": null, "author": "sp00kyversity", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/117j54j/taken_data_from_a_websites_api_now_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/117j54j/taken_data_from_a_websites_api_now_what/", "subreddit_subscribers": 849738, "created_utc": 1676923857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the ever-evolving world of insurance, data is the key to success. The insurance industry relies heavily on data to make informed decisions about risk assessment, pricing, and customer engagement. With the advent of data-driven technologies, the insurance industry is increasingly adopting DataOps practices to optimize their data-driven processes and improve decision making.\n\nDataOps refers to the set of practices and technologies that organizations use to manage their data operations in a more efficient and effective manner. It involves a combination of people, processes, and tools that enable organizations to collect, process, and analyze data in real-time.\n\nIn this blog, we will explore some of the most impactful DataOps use cases in the insurance industry and how they can help organizations optimize their operations.\n\n#### Claims Prediction:\n\nOne of the most significant applications of DataOps in the insurance industry is the prediction of claims. By leveraging data from various sources such as historical claims data, demographic data, and weather data, organizations can develop predictive models that can help them identify high-risk areas and predict the likelihood of claims in a specific area. This information can then be used to adjust the pricing of insurance policies and to optimize the allocation of resources for claims management.\n\n#### Lifetime Value Prediction:\n\nDataOps can also be used to predict the lifetime value of a customer. This is an important metric for insurance companies as it helps them to determine the cost of acquiring new customers and the expected return on investment. By analyzing customer data such as demographic information, purchase history, and engagement levels, insurance companies can develop predictive models that can help them to estimate the lifetime value of a customer.\n\n#### Influencing Customer Behaviour:\n\nDataOps can also be used to influence customer behavior. By analyzing customer data, insurance companies can identify patterns in customer behavior that can help them to optimize their engagement strategies. For example, by understanding which channels are most effective for reaching a specific customer segment, insurance companies can target their marketing campaigns more effectively and drive customer engagement.\n\n#### Personalizing Marketing Strategies And Targeting Specific Customer\u00a0Groups:\n\nDataOps can also be used to personalize marketing strategies and target specific customer groups. By analyzing customer data, insurance companies can segment their customers based on various demographic, behavioral, and psychographic characteristics. This information can then be used to tailor marketing campaigns to specific customer segments, resulting in more effective engagement and higher conversion rates.\n\n#### Detecting And Mitigating Risk In Real-Time:\n\nDataOps can also be used to detect and mitigate risk in real-time. By analyzing real-time data from various sources such as social media, news outlets, and weather data, insurance companies can identify emerging risks and take proactive measures to mitigate their impact. This can help organizations to respond quickly to changing conditions and minimize the impact of potential risks on their operations.\n\n#### Detection Of Fraudulent Claims:\n\nFinally, DataOps can be used to detect fraudulent claims. By analyzing claims data in real-time, insurance companies can identify anomalies and potential fraud. This information can then be used to investigate claims and prevent fraudulent activity from occurring.\n\n#### Conclusion:\n\nIn conclusion, DataOps has the potential to transform the insurance industry by enabling organizations to make more informed decisions, optimize their operations, and improve customer engagement. By leveraging data from various sources, insurance companies can gain a competitive advantage and drive growth in a rapidly changing market. Whether you are an established insurance company or a start-up, DataOps can help you to achieve your goals and stay ahead of the curve.\n\nISmile Technologies DataOps Managed Services enable organizations to collect, process, and analyze data in real-time, allowing them to make informed decisions about risk assessment, pricing, customer engagement, and more. With our expertise and cutting-edge technologies, insurance companies can optimize their data-driven processes, increase efficiency, and stay ahead of the competition. [Schedule your free assessment](https://www.ismiletechnologies.com/contact-us/) today.", "author_fullname": "t2_d0d2s92o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataOps Usecases for Insurance Industry", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1178pyh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676905264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the ever-evolving world of insurance, data is the key to success. The insurance industry relies heavily on data to make informed decisions about risk assessment, pricing, and customer engagement. With the advent of data-driven technologies, the insurance industry is increasingly adopting DataOps practices to optimize their data-driven processes and improve decision making.&lt;/p&gt;\n\n&lt;p&gt;DataOps refers to the set of practices and technologies that organizations use to manage their data operations in a more efficient and effective manner. It involves a combination of people, processes, and tools that enable organizations to collect, process, and analyze data in real-time.&lt;/p&gt;\n\n&lt;p&gt;In this blog, we will explore some of the most impactful DataOps use cases in the insurance industry and how they can help organizations optimize their operations.&lt;/p&gt;\n\n&lt;h4&gt;Claims Prediction:&lt;/h4&gt;\n\n&lt;p&gt;One of the most significant applications of DataOps in the insurance industry is the prediction of claims. By leveraging data from various sources such as historical claims data, demographic data, and weather data, organizations can develop predictive models that can help them identify high-risk areas and predict the likelihood of claims in a specific area. This information can then be used to adjust the pricing of insurance policies and to optimize the allocation of resources for claims management.&lt;/p&gt;\n\n&lt;h4&gt;Lifetime Value Prediction:&lt;/h4&gt;\n\n&lt;p&gt;DataOps can also be used to predict the lifetime value of a customer. This is an important metric for insurance companies as it helps them to determine the cost of acquiring new customers and the expected return on investment. By analyzing customer data such as demographic information, purchase history, and engagement levels, insurance companies can develop predictive models that can help them to estimate the lifetime value of a customer.&lt;/p&gt;\n\n&lt;h4&gt;Influencing Customer Behaviour:&lt;/h4&gt;\n\n&lt;p&gt;DataOps can also be used to influence customer behavior. By analyzing customer data, insurance companies can identify patterns in customer behavior that can help them to optimize their engagement strategies. For example, by understanding which channels are most effective for reaching a specific customer segment, insurance companies can target their marketing campaigns more effectively and drive customer engagement.&lt;/p&gt;\n\n&lt;h4&gt;Personalizing Marketing Strategies And Targeting Specific Customer\u00a0Groups:&lt;/h4&gt;\n\n&lt;p&gt;DataOps can also be used to personalize marketing strategies and target specific customer groups. By analyzing customer data, insurance companies can segment their customers based on various demographic, behavioral, and psychographic characteristics. This information can then be used to tailor marketing campaigns to specific customer segments, resulting in more effective engagement and higher conversion rates.&lt;/p&gt;\n\n&lt;h4&gt;Detecting And Mitigating Risk In Real-Time:&lt;/h4&gt;\n\n&lt;p&gt;DataOps can also be used to detect and mitigate risk in real-time. By analyzing real-time data from various sources such as social media, news outlets, and weather data, insurance companies can identify emerging risks and take proactive measures to mitigate their impact. This can help organizations to respond quickly to changing conditions and minimize the impact of potential risks on their operations.&lt;/p&gt;\n\n&lt;h4&gt;Detection Of Fraudulent Claims:&lt;/h4&gt;\n\n&lt;p&gt;Finally, DataOps can be used to detect fraudulent claims. By analyzing claims data in real-time, insurance companies can identify anomalies and potential fraud. This information can then be used to investigate claims and prevent fraudulent activity from occurring.&lt;/p&gt;\n\n&lt;h4&gt;Conclusion:&lt;/h4&gt;\n\n&lt;p&gt;In conclusion, DataOps has the potential to transform the insurance industry by enabling organizations to make more informed decisions, optimize their operations, and improve customer engagement. By leveraging data from various sources, insurance companies can gain a competitive advantage and drive growth in a rapidly changing market. Whether you are an established insurance company or a start-up, DataOps can help you to achieve your goals and stay ahead of the curve.&lt;/p&gt;\n\n&lt;p&gt;ISmile Technologies DataOps Managed Services enable organizations to collect, process, and analyze data in real-time, allowing them to make informed decisions about risk assessment, pricing, customer engagement, and more. With our expertise and cutting-edge technologies, insurance companies can optimize their data-driven processes, increase efficiency, and stay ahead of the competition. &lt;a href=\"https://www.ismiletechnologies.com/contact-us/\"&gt;Schedule your free assessment&lt;/a&gt; today.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1178pyh", "is_robot_indexable": true, "report_reasons": null, "author": "ismiletechnologies", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1178pyh/dataops_usecases_for_insurance_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1178pyh/dataops_usecases_for_insurance_industry/", "subreddit_subscribers": 849738, "created_utc": 1676905264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "https://github.com/R-Mahmoudi/Real-Time-Object-Counting-on-Jetson-Nano", "author_fullname": "t2_8okds99o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-Time-Object-Counting-on-Jetson-Nano", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1174q4x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676893901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/R-Mahmoudi/Real-Time-Object-Counting-on-Jetson-Nano\"&gt;https://github.com/R-Mahmoudi/Real-Time-Object-Counting-on-Jetson-Nano&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?auto=webp&amp;v=enabled&amp;s=44264ddd1301fb6a2553dfbaf25de52e81859762", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0253366b8b56018bb1bc9ca6be804344a1f0ed2", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4aa1e7389a4567ac813342b76497e7ca6b7ef666", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b71df4dce96e270510e17377eaff09611ae42978", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d43a79fda5038558c3bcbcb0a1d4aad0c98a9cb2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e2901efc803629163ace0798e8c357b3f5d651d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/shtotNCVBDVhDVdVBbpjsrYDglJTdiIsa5liS9vpBKQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57150797dcf0e1913275c638aec18356ab63810d", "width": 1080, "height": 540}], "variants": {}, "id": "4wKxqSgXRjxXQr3e8zlhq2HaL0BhefQZ4vum0hJ6XFI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1174q4x", "is_robot_indexable": true, "report_reasons": null, "author": "Smooth-Ad1528", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1174q4x/realtimeobjectcountingonjetsonnano/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1174q4x/realtimeobjectcountingonjetsonnano/", "subreddit_subscribers": 849738, "created_utc": 1676893901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I apologize I don't really know enough about this subject yet. From my understanding, it seems like most of the Big Tech companies don't fully own personal data but they own the infrastructure in which it is stored. I am an architecture student and I'm really interested in doing research about data centers. I am concerned with surveillance capitalism and am wondering if there is any potential in redesigning the physical infrastructure of how data is stored.", "author_fullname": "t2_4yh9ceg2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would community-owned data centers help with the sovereignty of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116wql0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676864402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I apologize I don&amp;#39;t really know enough about this subject yet. From my understanding, it seems like most of the Big Tech companies don&amp;#39;t fully own personal data but they own the infrastructure in which it is stored. I am an architecture student and I&amp;#39;m really interested in doing research about data centers. I am concerned with surveillance capitalism and am wondering if there is any potential in redesigning the physical infrastructure of how data is stored.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116wql0", "is_robot_indexable": true, "report_reasons": null, "author": "proudmisfit", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116wql0/would_communityowned_data_centers_help_with_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116wql0/would_communityowned_data_centers_help_with_the/", "subreddit_subscribers": 849738, "created_utc": 1676864402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_pzr91bdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "John Cena as a spiderverse character using Img2img and Control net Depth", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_117i992", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nJ-fKnCzP00?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"John Cena as a Spiderverse character using SD\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "John Cena as a Spiderverse character using SD", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nJ-fKnCzP00?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"John Cena as a Spiderverse character using SD\"&gt;&lt;/iframe&gt;", "author_name": "What The AI", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/nJ-fKnCzP00/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WhattheAI"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nJ-fKnCzP00?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"John Cena as a Spiderverse character using SD\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/117i992", "height": 200}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/c6OgL9PW71_rSm_JCdrRkSfnhoh8DqSV78HJB4ZvJfs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676921768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=nJ-fKnCzP00", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Cc6iO7H4tGTpXvFXG9g55vireIGusL6Tkhk94zmQauQ.jpg?auto=webp&amp;v=enabled&amp;s=8fe99d0177b0062c8d56fda7589ec91cf762f6c7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Cc6iO7H4tGTpXvFXG9g55vireIGusL6Tkhk94zmQauQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b4e574ac8af9add5956fd031d11969d9115b6c98", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Cc6iO7H4tGTpXvFXG9g55vireIGusL6Tkhk94zmQauQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=154a2abedcc5c4dabca2d2f6b8b19ccf77df87a3", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Cc6iO7H4tGTpXvFXG9g55vireIGusL6Tkhk94zmQauQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d205df1952d50ed78c2d51a8d0d36c71c4f47d3", "width": 320, "height": 240}], "variants": {}, "id": "QvfnJhO9CQ2Q9aU-4lPxRoJn0RES6Osd09ag5UaLuKY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "117i992", "is_robot_indexable": true, "report_reasons": null, "author": "oridnary_artist", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/117i992/john_cena_as_a_spiderverse_character_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=nJ-fKnCzP00", "subreddit_subscribers": 849738, "created_utc": 1676921768.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "John Cena as a Spiderverse character using SD", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/nJ-fKnCzP00?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"John Cena as a Spiderverse character using SD\"&gt;&lt;/iframe&gt;", "author_name": "What The AI", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/nJ-fKnCzP00/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@WhattheAI"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NeuralNextG v0.1.0: Analyzing Rocket League games automatically with Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_117br7d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_rzvez8xf", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/6silkWiOVa1p-7c_k147_VHSp7pRCCE-iEZ4dRkyP-k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "RocketLeague", "selftext": "", "author_fullname": "t2_rzvez8xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NeuralNextG v0.1.0: Analyzing Rocket League games automatically with Machine Learning", "link_flair_richtext": [{"a": ":Useful:", "e": "emoji", "u": "https://emoji.redditmedia.com/nmk0u7nb0uf61_t5_30cz1/Useful"}, {"e": "text", "t": " USEFUL"}], "subreddit_name_prefixed": "r/RocketLeague", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_1174g5l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 31, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": ":Useful: USEFUL", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/6silkWiOVa1p-7c_k147_VHSp7pRCCE-iEZ4dRkyP-k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_3": 1}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676892906.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "joeydotcomputer.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://joeydotcomputer.substack.com/p/neuralnextg-v010-analyzing-rocket", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8hyPyB3hrVKfH4bOUZD7lwBTcB6lhkCd0eQAI-RFTrM.jpg?auto=webp&amp;v=enabled&amp;s=f04bb164adf81e52264cf1f7a2dba8eb445f2b29", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/8hyPyB3hrVKfH4bOUZD7lwBTcB6lhkCd0eQAI-RFTrM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b09bef2759fca8fcb390adbb12e85403b92e847", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/8hyPyB3hrVKfH4bOUZD7lwBTcB6lhkCd0eQAI-RFTrM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=453369c84b23a93d382c34e82fc76a38534241b0", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/8hyPyB3hrVKfH4bOUZD7lwBTcB6lhkCd0eQAI-RFTrM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=204a629a8ded215902741017290e50467a2919d5", "width": 320, "height": 240}], "variants": {}, "id": "Fvfy8qM4jaE5Ff0vjXXFFmJFFBRZ1WVKXtDFP8Loe7E"}], "enabled": false}, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": 31, "coin_price": 1800, "id": "gid_3", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/platinum_512.png", "days_of_premium": 31, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/platinum_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 700 Reddit Coins and a month of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Platinum", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/platinum_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/platinum_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/platinum_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "6d68a9ae-6863-11eb-b635-0e98e5e934f7", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_30cz1", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#838d94", "id": "1174g5l", "is_robot_indexable": true, "report_reasons": null, "author": "joeydotcomputer", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/RocketLeague/comments/1174g5l/neuralnextg_v010_analyzing_rocket_league_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://joeydotcomputer.substack.com/p/neuralnextg-v010-analyzing-rocket", "subreddit_subscribers": 1167826, "created_utc": 1676892906.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1676909608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "joeydotcomputer.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://joeydotcomputer.substack.com/p/neuralnextg-v010-analyzing-rocket", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8hyPyB3hrVKfH4bOUZD7lwBTcB6lhkCd0eQAI-RFTrM.jpg?auto=webp&amp;v=enabled&amp;s=f04bb164adf81e52264cf1f7a2dba8eb445f2b29", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/8hyPyB3hrVKfH4bOUZD7lwBTcB6lhkCd0eQAI-RFTrM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b09bef2759fca8fcb390adbb12e85403b92e847", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/8hyPyB3hrVKfH4bOUZD7lwBTcB6lhkCd0eQAI-RFTrM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=453369c84b23a93d382c34e82fc76a38534241b0", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/8hyPyB3hrVKfH4bOUZD7lwBTcB6lhkCd0eQAI-RFTrM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=204a629a8ded215902741017290e50467a2919d5", "width": 320, "height": 240}], "variants": {}, "id": "Fvfy8qM4jaE5Ff0vjXXFFmJFFBRZ1WVKXtDFP8Loe7E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "117br7d", "is_robot_indexable": true, "report_reasons": null, "author": "joeydotcomputer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1174g5l", "author_flair_text_color": null, "permalink": "/r/datascience/comments/117br7d/neuralnextg_v010_analyzing_rocket_league_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://joeydotcomputer.substack.com/p/neuralnextg-v010-analyzing-rocket", "subreddit_subscribers": 849738, "created_utc": 1676909608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI have recently been offered a data scientist position at my current company, but I was told that I would be working exclusively on the Google Cloud Platform (GCP), and that it won't be necessary to code in Python. I've spent the past year learning about data science, models, and programming, and I'm concerned that all of that knowledge won't be put to use in this new role. I always thought that a data scientist would be in front of their Jupyter notebook, so I'm worried that this is a cheap data scientist position.\n\nMy main question is: is it standard for data scientists to work solely on cloud computing platforms like GCP, and is it common to not code in Python? I'd love to hear your thoughts and experiences on this.\n\nThanks in advance for your help !", "author_fullname": "t2_7td50", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it standard for data scientists to work solely on cloud computing platforms like GCP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1171lyy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676881854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I have recently been offered a data scientist position at my current company, but I was told that I would be working exclusively on the Google Cloud Platform (GCP), and that it won&amp;#39;t be necessary to code in Python. I&amp;#39;ve spent the past year learning about data science, models, and programming, and I&amp;#39;m concerned that all of that knowledge won&amp;#39;t be put to use in this new role. I always thought that a data scientist would be in front of their Jupyter notebook, so I&amp;#39;m worried that this is a cheap data scientist position.&lt;/p&gt;\n\n&lt;p&gt;My main question is: is it standard for data scientists to work solely on cloud computing platforms like GCP, and is it common to not code in Python? I&amp;#39;d love to hear your thoughts and experiences on this.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1171lyy", "is_robot_indexable": true, "report_reasons": null, "author": "asmodee59", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1171lyy/is_it_standard_for_data_scientists_to_work_solely/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1171lyy/is_it_standard_for_data_scientists_to_work_solely/", "subreddit_subscribers": 849738, "created_utc": 1676881854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone!\n\nI have a situation that I\u2019d very much love your opinion on!\n\nA little bit about myself: \nI have a MS in biomedical engineering, and I\u2019m currently pursuing a MS in analytics. I\u2019m expected to finish the degree by the end of 2023.\n\nI have just over 2 years of experience in a hospital as a research associate. 50% of my job duty is experimental design (mostly A/B testing), analyzing experimental dataset, visualization, etc. The size of the data is usually very small (n=200 or less). And the other 50% is sensors integration and hands on clinical experimental work. I\u2019m also an adjunct professor in university teaching biomedical engineering classes.\n\nI have a couple abstracts in ML published, and one manuscript currently in the work. However,  the journals I submitted to are very health-oriented. The technical findings are not ground breaking, just applying known ML techniques to the experimental data.\n\nInitially I was planning to pursue a PhD in biomed after finishing the analytics MS program, but I find myself swaying away. I\u2019d like to change to a pure DSA career afterwards.\n\nMy question is, should I apply to intern jobs and start over, or is my experience in the hospital valid? My work is 100% Python based, I know a bit of SQL from course project and leetcode.\n\nIt feels like aiming for a mid level job (2year +) may be too far fetched since I technically only have one full year of experience in DS.\n\nSo that may leave me with a new grad/ intern option\n\nWhat do you guys think? \n\nThanks so much", "author_fullname": "t2_t8c8gas5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Go for internship, new grad, or mid level career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116ws9x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676864560.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;\n\n&lt;p&gt;I have a situation that I\u2019d very much love your opinion on!&lt;/p&gt;\n\n&lt;p&gt;A little bit about myself: \nI have a MS in biomedical engineering, and I\u2019m currently pursuing a MS in analytics. I\u2019m expected to finish the degree by the end of 2023.&lt;/p&gt;\n\n&lt;p&gt;I have just over 2 years of experience in a hospital as a research associate. 50% of my job duty is experimental design (mostly A/B testing), analyzing experimental dataset, visualization, etc. The size of the data is usually very small (n=200 or less). And the other 50% is sensors integration and hands on clinical experimental work. I\u2019m also an adjunct professor in university teaching biomedical engineering classes.&lt;/p&gt;\n\n&lt;p&gt;I have a couple abstracts in ML published, and one manuscript currently in the work. However,  the journals I submitted to are very health-oriented. The technical findings are not ground breaking, just applying known ML techniques to the experimental data.&lt;/p&gt;\n\n&lt;p&gt;Initially I was planning to pursue a PhD in biomed after finishing the analytics MS program, but I find myself swaying away. I\u2019d like to change to a pure DSA career afterwards.&lt;/p&gt;\n\n&lt;p&gt;My question is, should I apply to intern jobs and start over, or is my experience in the hospital valid? My work is 100% Python based, I know a bit of SQL from course project and leetcode.&lt;/p&gt;\n\n&lt;p&gt;It feels like aiming for a mid level job (2year +) may be too far fetched since I technically only have one full year of experience in DS.&lt;/p&gt;\n\n&lt;p&gt;So that may leave me with a new grad/ intern option&lt;/p&gt;\n\n&lt;p&gt;What do you guys think? &lt;/p&gt;\n\n&lt;p&gt;Thanks so much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "116ws9x", "is_robot_indexable": true, "report_reasons": null, "author": "Fatcatthebestcat", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/116ws9x/go_for_internship_new_grad_or_mid_level_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/116ws9x/go_for_internship_new_grad_or_mid_level_career/", "subreddit_subscribers": 849738, "created_utc": 1676864560.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Someone who\u2019s well versed in good data practices but isn\u2019t familiar with the CRM software being used (in this case, Salesforce) or the tools used with it?\n\nOr someone who knows SF very well but has little to no experience in data practices?\n\nWould time be a factor in your decision?\n\nNew to the group, data steward since 2011. Thanks kindly in advance!", "author_fullname": "t2_6kftfg7c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Who would you rather train in data stewardship?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_117gogj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676918130.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Someone who\u2019s well versed in good data practices but isn\u2019t familiar with the CRM software being used (in this case, Salesforce) or the tools used with it?&lt;/p&gt;\n\n&lt;p&gt;Or someone who knows SF very well but has little to no experience in data practices?&lt;/p&gt;\n\n&lt;p&gt;Would time be a factor in your decision?&lt;/p&gt;\n\n&lt;p&gt;New to the group, data steward since 2011. Thanks kindly in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "117gogj", "is_robot_indexable": true, "report_reasons": null, "author": "usarasa", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/117gogj/who_would_you_rather_train_in_data_stewardship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/117gogj/who_would_you_rather_train_in_data_stewardship/", "subreddit_subscribers": 849738, "created_utc": 1676918130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_qvzyx40q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone enter the field in 2021 or after without grad school? What were your experiences?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11772ng", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676900837.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "11772ng", "is_robot_indexable": true, "report_reasons": null, "author": "Night_candles", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/11772ng/anyone_enter_the_field_in_2021_or_after_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/11772ng/anyone_enter_the_field_in_2021_or_after_without/", "subreddit_subscribers": 849738, "created_utc": 1676900837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to pursue a career in data. My laptop broke and looking for a replacement. Is[this](https://www.bestbuy.com/site/hp-victus-15-6-gaming-laptop-intel-core-i5-12450h-8gb-memory-nvidia-geforce-gtx-1650-512gb-ssd-mica-silver/6503849.p?skuId=6503849) good enough? To work on personal projects, build up a portfolio, do hackathons, etc\u2026 (Basically, is it enough for me to improve myself until I can land a job and upgrade?) I\u2019m planning to upgrade the ram to 16 gb.", "author_fullname": "t2_u5jtyok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Laptop Recommendation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1171kvk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676881739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to pursue a career in data. My laptop broke and looking for a replacement. Is&lt;a href=\"https://www.bestbuy.com/site/hp-victus-15-6-gaming-laptop-intel-core-i5-12450h-8gb-memory-nvidia-geforce-gtx-1650-512gb-ssd-mica-silver/6503849.p?skuId=6503849\"&gt;this&lt;/a&gt; good enough? To work on personal projects, build up a portfolio, do hackathons, etc\u2026 (Basically, is it enough for me to improve myself until I can land a job and upgrade?) I\u2019m planning to upgrade the ram to 16 gb.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?auto=webp&amp;v=enabled&amp;s=82d309dcc0a3f4b06f43eea82cc1f6f7361f3027", "width": 1240, "height": 1058}, "resolutions": [{"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=78b2b17ee55ebee49c6dd6687dfdd043929fc91c", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=907a9f43766c88b04d763cf016b5c0e8ac4d2094", "width": 216, "height": 184}, {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e81ada832c9cb2954de3aa683e4cc27f863e6a57", "width": 320, "height": 273}, {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54258cc1b18f6b8a3007a08322b8a83e52cdface", "width": 640, "height": 546}, {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f3e14fecb8401d7404124369b21e40f25d7e6d51", "width": 960, "height": 819}, {"url": "https://external-preview.redd.it/47oQA6eXfbucG6moslAmQSrvXQJ29Nd-c717BybGYKE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7deb74ca4d9b75a3bb0be3871e4b1ecbf26454b3", "width": 1080, "height": 921}], "variants": {}, "id": "ogusEl8GfwyZ-TFcxoIYQGnIluKtIjKc9j3PLFWmF48"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1171kvk", "is_robot_indexable": true, "report_reasons": null, "author": "hazurdv", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1171kvk/laptop_recommendation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1171kvk/laptop_recommendation/", "subreddit_subscribers": 849738, "created_utc": 1676881739.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}