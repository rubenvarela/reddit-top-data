{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I will start.\n\nI would create a standardized framework to create airflow dags. Due to our inexperience with airflow, everyone created their own version of dags to achieve the same ETL tasks. This has led to unnecessary duplication of code and maintenance nightmare. And since all the jobs are prod critical and interdependent, we cannot phase these dags out. Hence we are perpetually stuck with them", "author_fullname": "t2_virernyk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you could redo your company's data warehouse/data lake/data infrastructure, what would you do differently due to the benefit of hindsight?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1169v89", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676812023.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will start.&lt;/p&gt;\n\n&lt;p&gt;I would create a standardized framework to create airflow dags. Due to our inexperience with airflow, everyone created their own version of dags to achieve the same ETL tasks. This has led to unnecessary duplication of code and maintenance nightmare. And since all the jobs are prod critical and interdependent, we cannot phase these dags out. Hence we are perpetually stuck with them&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1169v89", "is_robot_indexable": true, "report_reasons": null, "author": "Hitoxi", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1169v89/if_you_could_redo_your_companys_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1169v89/if_you_could_redo_your_companys_data/", "subreddit_subscribers": 90244, "created_utc": 1676812023.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "*Hoping for an interesting thread*", "author_fullname": "t2_27lz615w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the toughest DE problem you faced in your work career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116a03p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676812430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;Hoping for an interesting thread&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "116a03p", "is_robot_indexable": true, "report_reasons": null, "author": "priprocks", "discussion_type": null, "num_comments": 62, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116a03p/whats_the_toughest_de_problem_you_faced_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/116a03p/whats_the_toughest_de_problem_you_faced_in_your/", "subreddit_subscribers": 90244, "created_utc": 1676812430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Learn the differences between streaming databases, real-time OLAP databases, and stream processing", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 92, "top_awarded_type": null, "hide_score": false, "name": "t3_116273b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/m12X5bRyTnF43-JWIEJfJbtDedSSegMSyogc5hlyxtY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676783255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learn the differences between streaming databases, real-time OLAP databases, and stream processing&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/hubertdulay/p/stream-processing-vs-real-time-olap?r=46sqk&amp;utm_medium=ios&amp;utm_campaign=post", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KX06YEAZo6UwEurj6f4qJNas1REF60deBNxl4N3bf5o.jpg?auto=webp&amp;v=enabled&amp;s=a7d0085c1936bbf1782ea420f65e41cfe6d80cdd", "width": 906, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/KX06YEAZo6UwEurj6f4qJNas1REF60deBNxl4N3bf5o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=01cc6aa5aab2ce0b5e9eec8e037aabea3ce231ce", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/KX06YEAZo6UwEurj6f4qJNas1REF60deBNxl4N3bf5o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83e9ebbf277433dc7eed8d70e5f8d67d09ce8103", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/KX06YEAZo6UwEurj6f4qJNas1REF60deBNxl4N3bf5o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2db8dd20a1ef9ec3489697f6b91206f1fc602049", "width": 320, "height": 211}, {"url": "https://external-preview.redd.it/KX06YEAZo6UwEurj6f4qJNas1REF60deBNxl4N3bf5o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8360069fd7707d9466c134b46d8389113481223", "width": 640, "height": 423}], "variants": {}, "id": "_VuVKTXnegN6nzjepsmw478Ywq3LWIdi_B29ArkOsZ4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "116273b", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116273b/streaming_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/hubertdulay/p/stream-processing-vs-real-time-olap?r=46sqk&amp;utm_medium=ios&amp;utm_campaign=post", "subreddit_subscribers": 90244, "created_utc": 1676783255.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I wrote a post that you might enjoy if you're working with Delta tables and are struggling to keep them at max performance. It's a hands-on tutorial with a default dataset that shows how Delta's maintenance commands work at a lower level.\n\n[https://medium.com/towards-data-science/delta-lake-keeping-it-fast-and-clean-3c9d4f9e2f5e](https://medium.com/towards-data-science/delta-lake-keeping-it-fast-and-clean-3c9d4f9e2f5e)\n\nIf you like it, don't hesitate to drop a follow as I write often about Data and the Apache Spark ecosystem", "author_fullname": "t2_jxqw29xi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake - Keeping it fast and clean", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1169lak", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676811193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wrote a post that you might enjoy if you&amp;#39;re working with Delta tables and are struggling to keep them at max performance. It&amp;#39;s a hands-on tutorial with a default dataset that shows how Delta&amp;#39;s maintenance commands work at a lower level.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/towards-data-science/delta-lake-keeping-it-fast-and-clean-3c9d4f9e2f5e\"&gt;https://medium.com/towards-data-science/delta-lake-keeping-it-fast-and-clean-3c9d4f9e2f5e&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you like it, don&amp;#39;t hesitate to drop a follow as I write often about Data and the Apache Spark ecosystem&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/68Czml4E3N3IwSpgu9g32uRHu74kN_kcM4sqBj9rpcQ.jpg?auto=webp&amp;v=enabled&amp;s=00b7fe2c8dc3d0d997638f61ae9d08eba78b699d", "width": 1063, "height": 777}, "resolutions": [{"url": "https://external-preview.redd.it/68Czml4E3N3IwSpgu9g32uRHu74kN_kcM4sqBj9rpcQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=60633c68620342e9e456784cd2273bfb52644bca", "width": 108, "height": 78}, {"url": "https://external-preview.redd.it/68Czml4E3N3IwSpgu9g32uRHu74kN_kcM4sqBj9rpcQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1da243eda34aa2295752f812e454828c560ac14", "width": 216, "height": 157}, {"url": "https://external-preview.redd.it/68Czml4E3N3IwSpgu9g32uRHu74kN_kcM4sqBj9rpcQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f2d16d68365e7c4bc1f7a1047f974d6c03299f55", "width": 320, "height": 233}, {"url": "https://external-preview.redd.it/68Czml4E3N3IwSpgu9g32uRHu74kN_kcM4sqBj9rpcQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc8c922a41a754aa05dbd16081f985e3c2120aad", "width": 640, "height": 467}, {"url": "https://external-preview.redd.it/68Czml4E3N3IwSpgu9g32uRHu74kN_kcM4sqBj9rpcQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bbd639b9a8ec5091e663fe3dcdce6ed195b7cef3", "width": 960, "height": 701}], "variants": {}, "id": "vyVHtKourTs-IBsK9lRJgvoNCNNc6PhgHIcVh1WBfuE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1169lak", "is_robot_indexable": true, "report_reasons": null, "author": "orpheuz24", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1169lak/delta_lake_keeping_it_fast_and_clean/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1169lak/delta_lake_keeping_it_fast_and_clean/", "subreddit_subscribers": 90244, "created_utc": 1676811193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm reading about Dagster for some time. I was wondering to use it as an orchestrator in my organization's data lake (Azure, Databricks). But as I dig into it I realized that the only way to schedule Databricks jobs is to use Dagster's 'op'. For me using ops only looks like a regular task-based orchestrator rather than asset-based (as Dagster claims to be). Am I missing something or Dagster, for now, is good only for small projects running in single-node systems?", "author_fullname": "t2_h57m9xk7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Dagster well suited for data lakes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116k3dv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676831252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m reading about Dagster for some time. I was wondering to use it as an orchestrator in my organization&amp;#39;s data lake (Azure, Databricks). But as I dig into it I realized that the only way to schedule Databricks jobs is to use Dagster&amp;#39;s &amp;#39;op&amp;#39;. For me using ops only looks like a regular task-based orchestrator rather than asset-based (as Dagster claims to be). Am I missing something or Dagster, for now, is good only for small projects running in single-node systems?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "116k3dv", "is_robot_indexable": true, "report_reasons": null, "author": "Advanced_Turnip_6090", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116k3dv/is_dagster_well_suited_for_data_lakes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/116k3dv/is_dagster_well_suited_for_data_lakes/", "subreddit_subscribers": 90244, "created_utc": 1676831252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there an option for me here? Currently on Snowflake, and I know both our unit cost as well as our usage.\n\nWe\u2019re on AWS. I\u2019m trying to understand what the likely cost would be of running the same pipelines using dbt on Hudi over S3 or Databricks in comparison to the existing cost of dbt on Snowflake.\n\nIs there an easy (ish) way to go about this?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to understand likely costs without needing to PoC everything", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1163cc7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676787363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there an option for me here? Currently on Snowflake, and I know both our unit cost as well as our usage.&lt;/p&gt;\n\n&lt;p&gt;We\u2019re on AWS. I\u2019m trying to understand what the likely cost would be of running the same pipelines using dbt on Hudi over S3 or Databricks in comparison to the existing cost of dbt on Snowflake.&lt;/p&gt;\n\n&lt;p&gt;Is there an easy (ish) way to go about this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1163cc7", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1163cc7/trying_to_understand_likely_costs_without_needing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1163cc7/trying_to_understand_likely_costs_without_needing/", "subreddit_subscribers": 90244, "created_utc": 1676787363.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What would be the best way to setup RabbitMQ output to TimescaleDB? Is there any \u201cnative\u201d way without using any third application as a middleware? Or we need to setup some API endpoint for the DB?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RabbitMQ output to TimescaleDB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1165n0e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676796261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What would be the best way to setup RabbitMQ output to TimescaleDB? Is there any \u201cnative\u201d way without using any third application as a middleware? Or we need to setup some API endpoint for the DB?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1165n0e", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1165n0e/rabbitmq_output_to_timescaledb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1165n0e/rabbitmq_output_to_timescaledb/", "subreddit_subscribers": 90244, "created_utc": 1676796261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am new to this field I feel I want to have a clear understanding of data modeling.\nPlease suggest some good resource beginner friendly\nApart from Kimball book", "author_fullname": "t2_pwnfr6q3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good data modeling course for a beginner", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_116tx9y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676855873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to this field I feel I want to have a clear understanding of data modeling.\nPlease suggest some good resource beginner friendly\nApart from Kimball book&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "116tx9y", "is_robot_indexable": true, "report_reasons": null, "author": "reddituseless", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116tx9y/good_data_modeling_course_for_a_beginner/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/116tx9y/good_data_modeling_course_for_a_beginner/", "subreddit_subscribers": 90244, "created_utc": 1676855873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_puwuw2q2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OpenTelemetry and Jaeger backend integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 80, "top_awarded_type": null, "hide_score": false, "name": "t3_1166bc3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fEXyZ_c3fZGe2j4rQPkjNteedWy9j3_-iLRCy7vAQFk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676798999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "sprkl.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://sprkl.dev/opentelemetry-and-jaeger-backend-integration/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SN2jvKBCIvUyGHfQED-TVEgM8INfDlcrp_mzaegQMms.jpg?auto=webp&amp;v=enabled&amp;s=e259aa7b86787155a6797f091035f0f0462de52f", "width": 2400, "height": 1372}, "resolutions": [{"url": "https://external-preview.redd.it/SN2jvKBCIvUyGHfQED-TVEgM8INfDlcrp_mzaegQMms.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6a75b7661a406d3316b092c671d75c39fe3ae4a", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/SN2jvKBCIvUyGHfQED-TVEgM8INfDlcrp_mzaegQMms.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdce88fb6d1189b4e8368b8401ed276ba8679862", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/SN2jvKBCIvUyGHfQED-TVEgM8INfDlcrp_mzaegQMms.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54b127893599f27dc179177c71ff1f367f744940", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/SN2jvKBCIvUyGHfQED-TVEgM8INfDlcrp_mzaegQMms.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1508f19437ab96c30328b48e5694c4f783ce537", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/SN2jvKBCIvUyGHfQED-TVEgM8INfDlcrp_mzaegQMms.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4c9b32202a7a3a4668219731ae2b7999aa2d269e", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/SN2jvKBCIvUyGHfQED-TVEgM8INfDlcrp_mzaegQMms.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9118d8fe1a143ae1dde1d977b351e03a6b7687d2", "width": 1080, "height": 617}], "variants": {}, "id": "72XcLpUgjyfjcmTmotcL-rNH5PXjxPQwKx42jDMLYJA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1166bc3", "is_robot_indexable": true, "report_reasons": null, "author": "observability_geek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1166bc3/opentelemetry_and_jaeger_backend_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://sprkl.dev/opentelemetry-and-jaeger-backend-integration/", "subreddit_subscribers": 90244, "created_utc": 1676798999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Correct me if I\u2019m wrong but in overall it seems like ML folks are better off these days, considering the recent shift to AI. FAANG is currently only hiring for AI positions. Comp has always been slightly higher on average imho.\n\nWas wondering if anyone has gone through similar transition and hoping to get some advice on whether it was worth it or not.", "author_fullname": "t2_ntpsm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Considering switching to ML/AI after 8 years in DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116qth0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676847830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Correct me if I\u2019m wrong but in overall it seems like ML folks are better off these days, considering the recent shift to AI. FAANG is currently only hiring for AI positions. Comp has always been slightly higher on average imho.&lt;/p&gt;\n\n&lt;p&gt;Was wondering if anyone has gone through similar transition and hoping to get some advice on whether it was worth it or not.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "116qth0", "is_robot_indexable": true, "report_reasons": null, "author": "DCman1993", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116qth0/considering_switching_to_mlai_after_8_years_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/116qth0/considering_switching_to_mlai_after_8_years_in_de/", "subreddit_subscribers": 90244, "created_utc": 1676847830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone familiar with how AWS DMS works with CDC? From what I understand, DMS requires a worker node to do the replication tasks to move data from source to destination. For CDC, does the worker aways run? If so, is it possible to only run it in batches so it\u2019s not always running?\n\nAnd anyone know how much the cost is compared to other cdc solutions?", "author_fullname": "t2_7jt0qboi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS DMS Pricing for CDC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116qd2k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676846720.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone familiar with how AWS DMS works with CDC? From what I understand, DMS requires a worker node to do the replication tasks to move data from source to destination. For CDC, does the worker aways run? If so, is it possible to only run it in batches so it\u2019s not always running?&lt;/p&gt;\n\n&lt;p&gt;And anyone know how much the cost is compared to other cdc solutions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "116qd2k", "is_robot_indexable": true, "report_reasons": null, "author": "omscsdatathrow", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116qd2k/aws_dms_pricing_for_cdc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/116qd2k/aws_dms_pricing_for_cdc/", "subreddit_subscribers": 90244, "created_utc": 1676846720.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw this video form this data analyst and thought to myself most of the tools he is using to conduct this research are tools that I always see on data engineering projects. I was wondering if the following project could be classified as a data engineering project ,data analyst or data scientitst project. Mayber all three?\n\nI'm fairly new to this field and was wondering how do differentiate between those three fields of data work. \n\nAlso, if you believe this a data engineer project rate it on a scale of 10. \n\n1-''meh'' uses very little data engineering tools, don't put on CV\n\n5- uses some\n\n10-excellent definitely recommend having on CV\n\nVideo Link: [https://www.youtube.com/watch?v=7G\\_Kz5MOqps&amp;t=1s](https://www.youtube.com/watch?v=7G_Kz5MOqps&amp;t=1s)\n\nLink to site: [https://datanerd.tech/](https://datanerd.tech/)\n\n&amp;#x200B;\n\nthank you for your time and input in advance", "author_fullname": "t2_4jav853u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Classify if the following project is a data engineering project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116mutn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676837998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw this video form this data analyst and thought to myself most of the tools he is using to conduct this research are tools that I always see on data engineering projects. I was wondering if the following project could be classified as a data engineering project ,data analyst or data scientitst project. Mayber all three?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m fairly new to this field and was wondering how do differentiate between those three fields of data work. &lt;/p&gt;\n\n&lt;p&gt;Also, if you believe this a data engineer project rate it on a scale of 10. &lt;/p&gt;\n\n&lt;p&gt;1-&amp;#39;&amp;#39;meh&amp;#39;&amp;#39; uses very little data engineering tools, don&amp;#39;t put on CV&lt;/p&gt;\n\n&lt;p&gt;5- uses some&lt;/p&gt;\n\n&lt;p&gt;10-excellent definitely recommend having on CV&lt;/p&gt;\n\n&lt;p&gt;Video Link: &lt;a href=\"https://www.youtube.com/watch?v=7G_Kz5MOqps&amp;amp;t=1s\"&gt;https://www.youtube.com/watch?v=7G_Kz5MOqps&amp;amp;t=1s&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Link to site: &lt;a href=\"https://datanerd.tech/\"&gt;https://datanerd.tech/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thank you for your time and input in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fKcjglWlBNvglJyKxq_VNCRqKFIPP-BYTnYK5MDh3gA.jpg?auto=webp&amp;v=enabled&amp;s=7c8eb5b3561c82cf378d4094e36b52ec0725ab5b", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/fKcjglWlBNvglJyKxq_VNCRqKFIPP-BYTnYK5MDh3gA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5c741f9cf018304aef2f02a7df1cc9326870dbd7", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/fKcjglWlBNvglJyKxq_VNCRqKFIPP-BYTnYK5MDh3gA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1343a3cd9ae1409f0d9163a4cfa2c55c421de954", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/fKcjglWlBNvglJyKxq_VNCRqKFIPP-BYTnYK5MDh3gA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=767e774660121ed324da3f82e6c88b57bf554355", "width": 320, "height": 240}], "variants": {}, "id": "VLgRjvWOt1lZyzDyBI6R6SNzWIQF7OwlhKQmZb15aVw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "116mutn", "is_robot_indexable": true, "report_reasons": null, "author": "RatedRForRegression", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116mutn/classify_if_the_following_project_is_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/116mutn/classify_if_the_following_project_is_a_data/", "subreddit_subscribers": 90244, "created_utc": 1676837998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n\nI am new in the field and I am trying to design an architecture to improve our current system. At first I have two cases:\n\n \n\n1. Several ETL pipelines that will be triggered periodically at specified times.\n\n2. ETL pipelines that will be triggered manually by users with custom parameters.\n\n\n\nThe user-triggered pipelines would often be the same as the automatic ones. I wonder if Prefect could be used to queue up the same automatic and manual pipelines with different parameters and distribute this execution queue to different machines for processing. Is there a better tool to solve this problem? Below is a diagram of the problem.\n\n\n\nhttps://imgur.com/a/ru3Jl4X", "author_fullname": "t2_9ca451os", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone give me suggestions for modeling my system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_116ujw1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676857694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new in the field and I am trying to design an architecture to improve our current system. At first I have two cases:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Several ETL pipelines that will be triggered periodically at specified times.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;ETL pipelines that will be triggered manually by users with custom parameters.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The user-triggered pipelines would often be the same as the automatic ones. I wonder if Prefect could be used to queue up the same automatic and manual pipelines with different parameters and distribute this execution queue to different machines for processing. Is there a better tool to solve this problem? Below is a diagram of the problem.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/ru3Jl4X\"&gt;https://imgur.com/a/ru3Jl4X&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AdxMNeOC3p1LMf-suYv3_QnETH7zCjefye6XxWfV3fQ.jpg?auto=webp&amp;v=enabled&amp;s=945488c3866319a1db45f35a7dd7a0b75d58637e", "width": 2725, "height": 1187}, "resolutions": [{"url": "https://external-preview.redd.it/AdxMNeOC3p1LMf-suYv3_QnETH7zCjefye6XxWfV3fQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e819550c7aad4347e30a20ab362faf42fb9a127", "width": 108, "height": 47}, {"url": "https://external-preview.redd.it/AdxMNeOC3p1LMf-suYv3_QnETH7zCjefye6XxWfV3fQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf0ade7cbd53490686b72b64275d59d0c4786beb", "width": 216, "height": 94}, {"url": "https://external-preview.redd.it/AdxMNeOC3p1LMf-suYv3_QnETH7zCjefye6XxWfV3fQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8b2fd01a454dc7573b32420d284ad3a6e7c80977", "width": 320, "height": 139}, {"url": "https://external-preview.redd.it/AdxMNeOC3p1LMf-suYv3_QnETH7zCjefye6XxWfV3fQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b6c342f245a6a772fe6ad49ae0477bf87c4b0ca4", "width": 640, "height": 278}, {"url": "https://external-preview.redd.it/AdxMNeOC3p1LMf-suYv3_QnETH7zCjefye6XxWfV3fQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74a22171349a0ac3bd0a3b40aaa5670958d12182", "width": 960, "height": 418}, {"url": "https://external-preview.redd.it/AdxMNeOC3p1LMf-suYv3_QnETH7zCjefye6XxWfV3fQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8da0c8e2c743cdc77a1b3223c0c5c8aad8dc271", "width": 1080, "height": 470}], "variants": {}, "id": "-DDE0WNCgkhPiOHSL0UQnIcnULKFa1wd7xsE3cytSXM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "116ujw1", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableAstronaut77", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116ujw1/can_anyone_give_me_suggestions_for_modeling_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/116ujw1/can_anyone_give_me_suggestions_for_modeling_my/", "subreddit_subscribers": 90244, "created_utc": 1676857694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At the end of our pipeline there's an aggregate table `'agg_table'` serving user requests from a webpage in realtime. The user request consists of just 3 parameter values (`A, B, C`) identifying the row in the table, s.t. it can basically be interpreted as the query `SELECT * FROM agg_table WHERE key_1=A AND key_2=B AND key_3=C`. However, it is rarely the case that a row with all 3 (or even 2) values exists in the table, s.t. it then defaults (according to business/domain logic) to `WHERE key_1=A AND key_2=B`, if that doesn't exist to `WHERE key_1=A AND key_3=C`, if that doesn't exist to `WHERE key_2=B AND key_3=C`, if that doesn't exist to `WHERE key_1=A` etc.\n\nIs there a recommended way to model the analytics table, with respect to dimensional modelling?", "author_fullname": "t2_cgxiixth", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to deal with fallbacks for webpage-serving analytics table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1168siq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676808397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At the end of our pipeline there&amp;#39;s an aggregate table &lt;code&gt;&amp;#39;agg_table&amp;#39;&lt;/code&gt; serving user requests from a webpage in realtime. The user request consists of just 3 parameter values (&lt;code&gt;A, B, C&lt;/code&gt;) identifying the row in the table, s.t. it can basically be interpreted as the query &lt;code&gt;SELECT * FROM agg_table WHERE key_1=A AND key_2=B AND key_3=C&lt;/code&gt;. However, it is rarely the case that a row with all 3 (or even 2) values exists in the table, s.t. it then defaults (according to business/domain logic) to &lt;code&gt;WHERE key_1=A AND key_2=B&lt;/code&gt;, if that doesn&amp;#39;t exist to &lt;code&gt;WHERE key_1=A AND key_3=C&lt;/code&gt;, if that doesn&amp;#39;t exist to &lt;code&gt;WHERE key_2=B AND key_3=C&lt;/code&gt;, if that doesn&amp;#39;t exist to &lt;code&gt;WHERE key_1=A&lt;/code&gt; etc.&lt;/p&gt;\n\n&lt;p&gt;Is there a recommended way to model the analytics table, with respect to dimensional modelling?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1168siq", "is_robot_indexable": true, "report_reasons": null, "author": "BusyFture", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1168siq/how_to_deal_with_fallbacks_for_webpageserving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1168siq/how_to_deal_with_fallbacks_for_webpageserving/", "subreddit_subscribers": 90244, "created_utc": 1676808397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How did your company or your team handle the massive influx of data that is currently being generated?", "author_fullname": "t2_s2o8t6mt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What techniques you or your company used to handle the massive amount of data being generated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116jxv3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676830879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How did your company or your team handle the massive influx of data that is currently being generated?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "116jxv3", "is_robot_indexable": true, "report_reasons": null, "author": "osa1501", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116jxv3/what_techniques_you_or_your_company_used_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/116jxv3/what_techniques_you_or_your_company_used_to/", "subreddit_subscribers": 90244, "created_utc": 1676830879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I'm in the final interview stage which should be scheduled for sometime next week. \n\nThey've told me there will be an hour allocated to a 'case study' with no extra details. I have asked for some extra info but if they don't reply soon what can I do to prepare for in the meantime? Also they said in the previous stage there's no live coding test.", "author_fullname": "t2_4ba5z1zq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Case study for a final interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11692c3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676809409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m in the final interview stage which should be scheduled for sometime next week. &lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;ve told me there will be an hour allocated to a &amp;#39;case study&amp;#39; with no extra details. I have asked for some extra info but if they don&amp;#39;t reply soon what can I do to prepare for in the meantime? Also they said in the previous stage there&amp;#39;s no live coding test.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "11692c3", "is_robot_indexable": true, "report_reasons": null, "author": "dreamr49", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11692c3/case_study_for_a_final_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11692c3/case_study_for_a_final_interview/", "subreddit_subscribers": 90244, "created_utc": 1676809409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Helo, a few days ago I posted if a CS degree is better than a DE degree,and by concensus the answer was yes for various of reasons,such as this being a new major it won't be well constructed,in addition to not seeing what a DE degree could offer more than a CS one.\n\nWhere I live, which is not the US or UK this major is becoming very will known,so don't worry about jop opportunities.\n\nThe point of this post is that you guys presented some true and interesting points that made me look into the syllabus of the degree,and since you are more knowledgeable than me you can tell me if these courses that this degree is not worth it.\n\nSome of the courses:\nSoftware engineering .\nIntroduction to CS.\nInfinitesimal calculus and algebra.\nComputer organisation and operating. \nGame theory and economic behaviour.\nData structure and algorithms.\nIntroduction to compubility and complexity.\nFundamentals of AI and its applications.\nAlgebraic methods in DE.\nDistributed information systems.\nComputational learning. \n\nTo my knowledge the first 2 years we learn the same as CS students.\n\n\nEdit to add:with this degree I can work as a SE,DS,DA,and finally a ML engineer. \n\nThank you for your Patience and help :)", "author_fullname": "t2_tzb9l6f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This is what a DE degree include!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11666si", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676799878.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676798465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Helo, a few days ago I posted if a CS degree is better than a DE degree,and by concensus the answer was yes for various of reasons,such as this being a new major it won&amp;#39;t be well constructed,in addition to not seeing what a DE degree could offer more than a CS one.&lt;/p&gt;\n\n&lt;p&gt;Where I live, which is not the US or UK this major is becoming very will known,so don&amp;#39;t worry about jop opportunities.&lt;/p&gt;\n\n&lt;p&gt;The point of this post is that you guys presented some true and interesting points that made me look into the syllabus of the degree,and since you are more knowledgeable than me you can tell me if these courses that this degree is not worth it.&lt;/p&gt;\n\n&lt;p&gt;Some of the courses:\nSoftware engineering .\nIntroduction to CS.\nInfinitesimal calculus and algebra.\nComputer organisation and operating. \nGame theory and economic behaviour.\nData structure and algorithms.\nIntroduction to compubility and complexity.\nFundamentals of AI and its applications.\nAlgebraic methods in DE.\nDistributed information systems.\nComputational learning. &lt;/p&gt;\n\n&lt;p&gt;To my knowledge the first 2 years we learn the same as CS students.&lt;/p&gt;\n\n&lt;p&gt;Edit to add:with this degree I can work as a SE,DS,DA,and finally a ML engineer. &lt;/p&gt;\n\n&lt;p&gt;Thank you for your Patience and help :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11666si", "is_robot_indexable": true, "report_reasons": null, "author": "khtoto", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11666si/this_is_what_a_de_degree_include/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11666si/this_is_what_a_de_degree_include/", "subreddit_subscribers": 90244, "created_utc": 1676798465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am wondering if you couldn't get away with a relational database for vectorisation.\n\nA while back I got to play with vectorisation of terms using BERT. We then held the vectors within an instance of Facebook's Fais. One of the irritating things was having to initialise a Fais instance which took a lot of time.\n\nWhich got me thinking, vectorisation is basically breaking unstructured data into tokens (groups of terms, a term is a word) e.g.\n\n&gt; The cat in the hat sat on the mat and drank milk from a jug\n\nFirst we remove stop words \n\n&gt; Cat hat sat mat drank milk from jug\n\nNow we convert into tokens\n\n* Cat hat sat mat\n* Hat sat mat drank\n* Sat mat drank milk\n* mat drank milk jug\n\nA Machine Learning model like bert has been trained on billions of tokens and has given them positions (vectors) within an N dimensional array (called vectorspace).\n\nThe idea is \"cat\" should be located near \"pet\", \"hat\" is close to \"headgear\", etc.. \n\nSo you provide tokens and in return you get vectors indicating where in vectorspace your token resides.\n\nWhich got me thinking, in every example I can think of there is normally an easy way to keep the size of a corpus (dataset) small. For example with facebook each user would represent a corpus.\n\nFacebook Fais requires a lot of RAM and Storage and you have to preload data for it to the index everything and it can literally take days to start. \n\nSo my thinking is.\n\nCreate a relational database (e.g postgres) for each corpus. The database should contain a \"vectors\" table. \n\nThe vector table contains an integer field for each vector column. A vector can have a many to many relationship with the \"token\" table.\n\nThe token table contains each token generated within a corpus and some means to reference the document tokenised.\n\nSo when a user enters a search string, we tokenise it and generate a list of vectors. We then build a query for each vector allowing a range around each vector field.\n\nWe run these queries on each database collecting the responses to each query. \n\nWe then rank the tokens based on the number of matching vectors.\n\nBecause our corpus is bounded each database will likely be limited to thousands of tokens and a few million vectors. Which is within the abilities of something like postgres.\n\nThis would let us replicate the same capability as Facebook Fais or Word2Vec.\n\nThoughts?", "author_fullname": "t2_172g1e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vectorisation and Querying", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1164fus", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676792314.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676791562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am wondering if you couldn&amp;#39;t get away with a relational database for vectorisation.&lt;/p&gt;\n\n&lt;p&gt;A while back I got to play with vectorisation of terms using BERT. We then held the vectors within an instance of Facebook&amp;#39;s Fais. One of the irritating things was having to initialise a Fais instance which took a lot of time.&lt;/p&gt;\n\n&lt;p&gt;Which got me thinking, vectorisation is basically breaking unstructured data into tokens (groups of terms, a term is a word) e.g.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The cat in the hat sat on the mat and drank milk from a jug&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;First we remove stop words &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Cat hat sat mat drank milk from jug&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Now we convert into tokens&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Cat hat sat mat&lt;/li&gt;\n&lt;li&gt;Hat sat mat drank&lt;/li&gt;\n&lt;li&gt;Sat mat drank milk&lt;/li&gt;\n&lt;li&gt;mat drank milk jug&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;A Machine Learning model like bert has been trained on billions of tokens and has given them positions (vectors) within an N dimensional array (called vectorspace).&lt;/p&gt;\n\n&lt;p&gt;The idea is &amp;quot;cat&amp;quot; should be located near &amp;quot;pet&amp;quot;, &amp;quot;hat&amp;quot; is close to &amp;quot;headgear&amp;quot;, etc.. &lt;/p&gt;\n\n&lt;p&gt;So you provide tokens and in return you get vectors indicating where in vectorspace your token resides.&lt;/p&gt;\n\n&lt;p&gt;Which got me thinking, in every example I can think of there is normally an easy way to keep the size of a corpus (dataset) small. For example with facebook each user would represent a corpus.&lt;/p&gt;\n\n&lt;p&gt;Facebook Fais requires a lot of RAM and Storage and you have to preload data for it to the index everything and it can literally take days to start. &lt;/p&gt;\n\n&lt;p&gt;So my thinking is.&lt;/p&gt;\n\n&lt;p&gt;Create a relational database (e.g postgres) for each corpus. The database should contain a &amp;quot;vectors&amp;quot; table. &lt;/p&gt;\n\n&lt;p&gt;The vector table contains an integer field for each vector column. A vector can have a many to many relationship with the &amp;quot;token&amp;quot; table.&lt;/p&gt;\n\n&lt;p&gt;The token table contains each token generated within a corpus and some means to reference the document tokenised.&lt;/p&gt;\n\n&lt;p&gt;So when a user enters a search string, we tokenise it and generate a list of vectors. We then build a query for each vector allowing a range around each vector field.&lt;/p&gt;\n\n&lt;p&gt;We run these queries on each database collecting the responses to each query. &lt;/p&gt;\n\n&lt;p&gt;We then rank the tokens based on the number of matching vectors.&lt;/p&gt;\n\n&lt;p&gt;Because our corpus is bounded each database will likely be limited to thousands of tokens and a few million vectors. Which is within the abilities of something like postgres.&lt;/p&gt;\n\n&lt;p&gt;This would let us replicate the same capability as Facebook Fais or Word2Vec.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1164fus", "is_robot_indexable": true, "report_reasons": null, "author": "stevecrox0914", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1164fus/vectorisation_and_querying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1164fus/vectorisation_and_querying/", "subreddit_subscribers": 90244, "created_utc": 1676791562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I downloaded my extended streams from Spotify and I created two dimension tables one with the Track Metadata which contains the Artist Uri which connects an Artist Metadata. When I created the Artist Dimension table, I discovered that they can have multiple genres and some cases many genres. I am not sure how I should finalize this table. This will be a csv going into cloud storage. \n\nCurrently, I have it as follows \n\n    Artist_ID              Genres                                                                                                                                    \n    00FQb4jTyendYWaN8pK0wa art pop|pop                                                                 00G1NTDAoU7rBpjG4KoYAM downtempo|electronica|japanese old school \n    00sAr10UTV1JZtHqxsLVn4 canadian psychedelic rock| space rock\n\nI have each one separated with pipes, so when I query, I guess I could do like operator or some kind of sperate, take the nth one. \n\nThe other option though is to have the Artist\\_ID repeat for each unique genre but I'm not a fan off repeating the Artist\\_ID. \n\nWhat do you guys think would be the best solution in this case?", "author_fullname": "t2_z321026", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spotify Genre Date: Debating how I should store this table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_115zj00", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676774800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I downloaded my extended streams from Spotify and I created two dimension tables one with the Track Metadata which contains the Artist Uri which connects an Artist Metadata. When I created the Artist Dimension table, I discovered that they can have multiple genres and some cases many genres. I am not sure how I should finalize this table. This will be a csv going into cloud storage. &lt;/p&gt;\n\n&lt;p&gt;Currently, I have it as follows &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Artist_ID              Genres                                                                                                                                    \n00FQb4jTyendYWaN8pK0wa art pop|pop                                                                 00G1NTDAoU7rBpjG4KoYAM downtempo|electronica|japanese old school \n00sAr10UTV1JZtHqxsLVn4 canadian psychedelic rock| space rock\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I have each one separated with pipes, so when I query, I guess I could do like operator or some kind of sperate, take the nth one. &lt;/p&gt;\n\n&lt;p&gt;The other option though is to have the Artist_ID repeat for each unique genre but I&amp;#39;m not a fan off repeating the Artist_ID. &lt;/p&gt;\n\n&lt;p&gt;What do you guys think would be the best solution in this case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "115zj00", "is_robot_indexable": true, "report_reasons": null, "author": "raz_the_kid0901", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/115zj00/spotify_genre_date_debating_how_i_should_store/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/115zj00/spotify_genre_date_debating_how_i_should_store/", "subreddit_subscribers": 90244, "created_utc": 1676774800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_iji1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI and Chatbots: The Role of Linux in their Growth", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_116ou3f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/M5DDhyxTxyOkufyyg2FiCKA23YpUaEX9NUgb74Zw5Eo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676842979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "haydenjames.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://haydenjames.io/ai-chatbots-the-role-of-linux-in-growth/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DWLSqI__8pBJv2K05pTvil9eGb92AccX2Ds-dhNNeS0.jpg?auto=webp&amp;v=enabled&amp;s=2689922decdb413bd4d8bc364a10908854e3a653", "width": 868, "height": 579}, "resolutions": [{"url": "https://external-preview.redd.it/DWLSqI__8pBJv2K05pTvil9eGb92AccX2Ds-dhNNeS0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6758107858aedecf544056406ba03d0ab0db4a83", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/DWLSqI__8pBJv2K05pTvil9eGb92AccX2Ds-dhNNeS0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73f0a9671a26f93a9e5c729ac08028a7d87def7a", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/DWLSqI__8pBJv2K05pTvil9eGb92AccX2Ds-dhNNeS0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c2be78f151987b21173e49bacfa24b2aea0c21e5", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/DWLSqI__8pBJv2K05pTvil9eGb92AccX2Ds-dhNNeS0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=558414cb6ef2a151ff7b8c2365a7228043622e07", "width": 640, "height": 426}], "variants": {}, "id": "ea9I59PrT6KRTj_EQG7f7L_hlzbA7Tk2vG_4c_ClEBU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "116ou3f", "is_robot_indexable": true, "report_reasons": null, "author": "modelop", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116ou3f/ai_and_chatbots_the_role_of_linux_in_their_growth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://haydenjames.io/ai-chatbots-the-role-of-linux-in-growth/", "subreddit_subscribers": 90244, "created_utc": 1676842979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can task like data cleansing, data structuring, data validation, and data transformation be automated using GPT 2? Has it been done already? I don't believe it is feasible because it isn't that great at formatting.", "author_fullname": "t2_s2o8t6mt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My manager wants me to use GPT2 to automate certain tasks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116kf89", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676832036.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can task like data cleansing, data structuring, data validation, and data transformation be automated using GPT 2? Has it been done already? I don&amp;#39;t believe it is feasible because it isn&amp;#39;t that great at formatting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "116kf89", "is_robot_indexable": true, "report_reasons": null, "author": "osa1501", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116kf89/my_manager_wants_me_to_use_gpt2_to_automate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/116kf89/my_manager_wants_me_to_use_gpt2_to_automate/", "subreddit_subscribers": 90244, "created_utc": 1676832036.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am not sure I understand datalake folder structuring correctly:\n\nIf I get everyday new file for lets say sales for some region I would save this file like this:\n\nsales/region/yyyy/mm/dd/file\n\nor\n\nsales/file ?\n\n\nBecause if I understand it correctly - e.g. in Trino I pass the folder with the data (parquet files) and Trino itself loads the files. But if I would have each file in separate folder it would be a problem? I would have to create table for each file manually? Also if I go with \u201csales/region\u201d I can create table with partitions by date and Trino automatically would create these \u201cyyyy/mm/dd\u201d folders? Sorry not sure I understand it correctly.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datalake - partitions vs folder structure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_116iqu0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676827986.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not sure I understand datalake folder structuring correctly:&lt;/p&gt;\n\n&lt;p&gt;If I get everyday new file for lets say sales for some region I would save this file like this:&lt;/p&gt;\n\n&lt;p&gt;sales/region/yyyy/mm/dd/file&lt;/p&gt;\n\n&lt;p&gt;or&lt;/p&gt;\n\n&lt;p&gt;sales/file ?&lt;/p&gt;\n\n&lt;p&gt;Because if I understand it correctly - e.g. in Trino I pass the folder with the data (parquet files) and Trino itself loads the files. But if I would have each file in separate folder it would be a problem? I would have to create table for each file manually? Also if I go with \u201csales/region\u201d I can create table with partitions by date and Trino automatically would create these \u201cyyyy/mm/dd\u201d folders? Sorry not sure I understand it correctly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "116iqu0", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/116iqu0/datalake_partitions_vs_folder_structure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/116iqu0/datalake_partitions_vs_folder_structure/", "subreddit_subscribers": 90244, "created_utc": 1676827986.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been told that I should be careful telling people that I\u2019m a \u2018data engineer\u2019 because I don\u2019t have an engineering degree, and only qualified engineers can call themselves engineers. I\u2019m not trying to trick anyone into thinking that I have an electrical engineering degree or something, I just say that because it\u2019s my job title. Is this something people care about?", "author_fullname": "t2_py81dzz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I call myself a data engineer if I don\u2019t have an \u2018engineering\u2019 qualification?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1162sjq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676785392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been told that I should be careful telling people that I\u2019m a \u2018data engineer\u2019 because I don\u2019t have an engineering degree, and only qualified engineers can call themselves engineers. I\u2019m not trying to trick anyone into thinking that I have an electrical engineering degree or something, I just say that because it\u2019s my job title. Is this something people care about?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1162sjq", "is_robot_indexable": true, "report_reasons": null, "author": "CyclicDombo", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1162sjq/can_i_call_myself_a_data_engineer_if_i_dont_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1162sjq/can_i_call_myself_a_data_engineer_if_i_dont_have/", "subreddit_subscribers": 90244, "created_utc": 1676785392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m getting myself a new laptop for work and will be maintaining a few databases for clients within. This would be mostly 3rd party platform data, in the 10\u2019s of millions of rows.\n\nI would have a cloud backup of course and consider migrating to a cloud based sql server. \n\nWould I see a real world impact data wise without ECC ram?", "author_fullname": "t2_5cwjpire", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ECC ram? Warehousing client reporting data\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11604np", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676776564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m getting myself a new laptop for work and will be maintaining a few databases for clients within. This would be mostly 3rd party platform data, in the 10\u2019s of millions of rows.&lt;/p&gt;\n\n&lt;p&gt;I would have a cloud backup of course and consider migrating to a cloud based sql server. &lt;/p&gt;\n\n&lt;p&gt;Would I see a real world impact data wise without ECC ram?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11604np", "is_robot_indexable": true, "report_reasons": null, "author": "JusticeSoup", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11604np/ecc_ram_warehousing_client_reporting_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11604np/ecc_ram_warehousing_client_reporting_data/", "subreddit_subscribers": 90244, "created_utc": 1676776564.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}