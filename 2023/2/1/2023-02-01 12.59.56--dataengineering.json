{"kind": "Listing", "data": {"after": "t3_10qrefc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I'm sorry if this post is long...there's a **tldr** at the bottom. I just want a place to vent and get feedback - I feel discouraged and frustrated. About three weeks ago, I had an initial screening with a recruiter from a tech start-up based in Europe. It led to a technical interview for a remote data engineering role (US) with them. The first technical interview went well, and I was informed that the next step would be a take-home assignment. The assignment asked me to do pretty much what I would be doing if I received the position:\n\n1. Write an API that connects to one of their datasets\n2. include multiple parameters for aggregation, querying, and filtering\n3. put it on the cloud\n4. write documentation for it\n5. Write a report of why you chose the tools you did and what you would do differently.\n\nThe time limit on the assignment was approximately three hours. This struck me as a red flag because I felt like this was a lot of work to accomplish in less than half a work day (I would love your thoughts on that, actually. Maybe I'm just slow.)? The assignment was also very open-ended. There was no mention of which dataset to connect to, how to connect to it, which tools to use, or really any expectations on their end.\n\nI'm not a fan of take-home assignments because I've heard horror stories of people getting used for their free work. Since it was so open-ended, only three hours long, and the interviewer was super chill when talking about the assignment (\"We just need something to get a feel for your Python skills\") I assumed it was ok to build a small application showcasing the fundamentals of API development.\n\nI used one of their smaller datasets, coded my API in Python using Django and Pandas, hosted it on an EC2 instance, and wrote markdown documentation. In my report, I mention how I would use Spark, tokenization (I was working with text data), and a proper database if I were to make this app production grade. I included all the drawbacks of my current application and how I would fix them - because of course - the assignment was only supposed to be three hours long, and there was only so much I was willing to do for a take-home assignment. I felt like this was a lot of work as it is, and it took me roughly 6.5 hours to complete.\n\nAfter submitting my assignment, I got an email the next day telling me I did a great job and they would like to proceed with the second technical interview. The second interview ended well, with the interviewer telling me they would schedule a final interview with the CTO. Instead, I received another email three days later stating that the company decided to terminate the interview process. Why? Because my app was not using a large enough dataset, my code wasn't efficient enough, pretty much telling me that it wasn't applicable for a large-scale system. ????????. Of course not? This is a take-home assignment that was supposed to take 3 hours to finish. I am honestly baffled. Is this normal? I understand there are people out there who probably can write an enterprise-level API in 3 hours, but even so, why do it for free during the interview process? At this point, I feel a bit sketched out and like I dodged a bullet. It's still discouraging to make it so far in the interview process and not get an offer, though.\n\n&amp;#x200B;\n\n**TLDR**; *I completed a take-home assignment, and I feel kind of shitty about it. Considering avoiding companies that ask me to do this in the future...*", "author_fullname": "t2_kju9dvol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feel a bit burned from a take-home assignment I completed during an interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qdxjr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675208982.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675207533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m sorry if this post is long...there&amp;#39;s a &lt;strong&gt;tldr&lt;/strong&gt; at the bottom. I just want a place to vent and get feedback - I feel discouraged and frustrated. About three weeks ago, I had an initial screening with a recruiter from a tech start-up based in Europe. It led to a technical interview for a remote data engineering role (US) with them. The first technical interview went well, and I was informed that the next step would be a take-home assignment. The assignment asked me to do pretty much what I would be doing if I received the position:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Write an API that connects to one of their datasets&lt;/li&gt;\n&lt;li&gt;include multiple parameters for aggregation, querying, and filtering&lt;/li&gt;\n&lt;li&gt;put it on the cloud&lt;/li&gt;\n&lt;li&gt;write documentation for it&lt;/li&gt;\n&lt;li&gt;Write a report of why you chose the tools you did and what you would do differently.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The time limit on the assignment was approximately three hours. This struck me as a red flag because I felt like this was a lot of work to accomplish in less than half a work day (I would love your thoughts on that, actually. Maybe I&amp;#39;m just slow.)? The assignment was also very open-ended. There was no mention of which dataset to connect to, how to connect to it, which tools to use, or really any expectations on their end.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not a fan of take-home assignments because I&amp;#39;ve heard horror stories of people getting used for their free work. Since it was so open-ended, only three hours long, and the interviewer was super chill when talking about the assignment (&amp;quot;We just need something to get a feel for your Python skills&amp;quot;) I assumed it was ok to build a small application showcasing the fundamentals of API development.&lt;/p&gt;\n\n&lt;p&gt;I used one of their smaller datasets, coded my API in Python using Django and Pandas, hosted it on an EC2 instance, and wrote markdown documentation. In my report, I mention how I would use Spark, tokenization (I was working with text data), and a proper database if I were to make this app production grade. I included all the drawbacks of my current application and how I would fix them - because of course - the assignment was only supposed to be three hours long, and there was only so much I was willing to do for a take-home assignment. I felt like this was a lot of work as it is, and it took me roughly 6.5 hours to complete.&lt;/p&gt;\n\n&lt;p&gt;After submitting my assignment, I got an email the next day telling me I did a great job and they would like to proceed with the second technical interview. The second interview ended well, with the interviewer telling me they would schedule a final interview with the CTO. Instead, I received another email three days later stating that the company decided to terminate the interview process. Why? Because my app was not using a large enough dataset, my code wasn&amp;#39;t efficient enough, pretty much telling me that it wasn&amp;#39;t applicable for a large-scale system. ????????. Of course not? This is a take-home assignment that was supposed to take 3 hours to finish. I am honestly baffled. Is this normal? I understand there are people out there who probably can write an enterprise-level API in 3 hours, but even so, why do it for free during the interview process? At this point, I feel a bit sketched out and like I dodged a bullet. It&amp;#39;s still discouraging to make it so far in the interview process and not get an offer, though.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;; &lt;em&gt;I completed a take-home assignment, and I feel kind of shitty about it. Considering avoiding companies that ask me to do this in the future...&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10qdxjr", "is_robot_indexable": true, "report_reasons": null, "author": "LusciousPigeon", "discussion_type": null, "num_comments": 67, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qdxjr/feel_a_bit_burned_from_a_takehome_assignment_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qdxjr/feel_a_bit_burned_from_a_takehome_assignment_i/", "subreddit_subscribers": 88127, "created_utc": 1675207533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My plan is just to learn as many new skills at my current job as possible and try taking on new projects.  Luckily, I'm pretty happy with my current company, but I always have skills and Leetcode in the back of my mind given the economy.\n\n\n\n\n\nIf I were to look for another company, I don't think I would find a new job that I like since recruiters on LinkedIn are messaging less and the numbers of jobs posted in my area have gone significantly down.  This is even the case at 4 years of experience, with 2 of those years at a tech unicorn.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should experienced data engineers be doing until the economy improves?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pxqcl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675167962.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My plan is just to learn as many new skills at my current job as possible and try taking on new projects.  Luckily, I&amp;#39;m pretty happy with my current company, but I always have skills and Leetcode in the back of my mind given the economy.&lt;/p&gt;\n\n&lt;p&gt;If I were to look for another company, I don&amp;#39;t think I would find a new job that I like since recruiters on LinkedIn are messaging less and the numbers of jobs posted in my area have gone significantly down.  This is even the case at 4 years of experience, with 2 of those years at a tech unicorn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10pxqcl", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10pxqcl/what_should_experienced_data_engineers_be_doing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pxqcl/what_should_experienced_data_engineers_be_doing/", "subreddit_subscribers": 88127, "created_utc": 1675167962.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys! So I'm an integrations engineer at a startup, basically scripting parsers, loading data, etc. However, I got an offer for a 22% raise elsewhere.\nHere's the deal:\n\n-Current Job: Integrations engineer, Salas startup, average compensation. Most of the time dealing with Django, AWS and Python. No possibility to grow in the near future.\n\n-Offered Job: 60% data analysis and 40% Data Engineer at a consulting firm, it's like a hybrid, most of the time dealing with PowerBI, Azure, SQL and Python. Possibility to become head of analysis in 2-3 years. 22% raise.\n\nWhat do you guys think? Is it worth it to jump over a 22% raise? I mean, being an integrations engineer you just are a glorified light-backend dev imo\n\n\n\n\n\nIs this worth it? I mean, it would be", "author_fullname": "t2_171ccp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "22% difference salary worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q9uvv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675197735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys! So I&amp;#39;m an integrations engineer at a startup, basically scripting parsers, loading data, etc. However, I got an offer for a 22% raise elsewhere.\nHere&amp;#39;s the deal:&lt;/p&gt;\n\n&lt;p&gt;-Current Job: Integrations engineer, Salas startup, average compensation. Most of the time dealing with Django, AWS and Python. No possibility to grow in the near future.&lt;/p&gt;\n\n&lt;p&gt;-Offered Job: 60% data analysis and 40% Data Engineer at a consulting firm, it&amp;#39;s like a hybrid, most of the time dealing with PowerBI, Azure, SQL and Python. Possibility to become head of analysis in 2-3 years. 22% raise.&lt;/p&gt;\n\n&lt;p&gt;What do you guys think? Is it worth it to jump over a 22% raise? I mean, being an integrations engineer you just are a glorified light-backend dev imo&lt;/p&gt;\n\n&lt;p&gt;Is this worth it? I mean, it would be&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10q9uvv", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_Nicotine", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q9uvv/22_difference_salary_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q9uvv/22_difference_salary_worth_it/", "subreddit_subscribers": 88127, "created_utc": 1675197735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello data engineering community!\n\nI would like to learn more about Kafka since I'm supposed to use it in the near future at my current job. Our current stack consists of numerous batch processing pipelines and we don't use streaming at all.\n\nI understand the basic concepts of Kafka and message brokers in general but I would need a more in depth course on how to use, basic configuration, etc. to help with my future tasks.\n\nThus, please don't mention any Kafka basics course since those should be a waste of time.\n\nThank you in advance for your input!", "author_fullname": "t2_ce7do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka course recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q4jux", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675185166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello data engineering community!&lt;/p&gt;\n\n&lt;p&gt;I would like to learn more about Kafka since I&amp;#39;m supposed to use it in the near future at my current job. Our current stack consists of numerous batch processing pipelines and we don&amp;#39;t use streaming at all.&lt;/p&gt;\n\n&lt;p&gt;I understand the basic concepts of Kafka and message brokers in general but I would need a more in depth course on how to use, basic configuration, etc. to help with my future tasks.&lt;/p&gt;\n\n&lt;p&gt;Thus, please don&amp;#39;t mention any Kafka basics course since those should be a waste of time.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10q4jux", "is_robot_indexable": true, "report_reasons": null, "author": "ulysses_black", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10q4jux/kafka_course_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q4jux/kafka_course_recommendations/", "subreddit_subscribers": 88127, "created_utc": 1675185166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One of the challenges I hear about over and over in the data space is the giant gap that exists between those working on the data operation and those having a stake in the data operation's deliverables.  \n\n\nThis often results in a tumultuous first few weeks in a new technical data role, as one weighs the need to deliver value quickly, agains the desire to build something with a strong foundation.  \n\n\nI started a mini-series of medium articles that seeks to strike a balance between the two opposing forces - designed to go over a viable path that quickly delivers on a fictional data ask, in a cloud environment, on a shoestring budget:  \n\n\n[part I - we set the stage](https://medium.com/@syampols/data-pipeline-on-a-shoestring-part-i-where-to-begin-a085bb397470) \u2014 whether you\u2019re a hobbyist looking to build a fun data pipeline or you just landed in a startup that needs data served yesterday and you're looking for a perspective on how to deliver, this summarizes a good problem statement.  \n\n\n[part II - we pose a data need](https://medium.com/@syampols/data-pipeline-on-a-shoestring-part-ii-the-data-need-and-the-architecture-to-solve-for-it-bed5f208de36) \u2014 we describe the fictional ask from our imaginary stakeholder, and propose the architecture that will solve for the need, from ingestion, to transformation, to serving the data, on a shoestring, of course.  \n\n\n[part III - we lay the foundation for the work](https://medium.com/@syampols/data-pipeline-on-a-shoestring-part-iii-laying-the-foundation-d74014112f0) \u2014 using a combination of service oriented architecture principles in combination with infrastructure as code, we prime our cloud environments and describe a framework to deploy the resources needed to solve for the fictional data problem.  \n\n\nIn part IV (coming soon), we build the pipeline \u2014 using the foundation and deployment process outlined in part III, we continue to deploy the resources that make the pipeline run, as outlined in the architecture in part II.  \n\n\nIn part V (coming soon), we wrap \u2014 Using the prior framework laid out in the prior four articles, we talk about pathways to scale the solution, as this is, after all, a pipeline on a budget, and will/should not be used beyond a solid proof of concept (unless ye seek technical debt).  \n\n\nEnjoy! I would give you rotten tomatoes to throw my way but then it would end up on your monitor, that said, I would love any feedback you may have!", "author_fullname": "t2_daui6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Pipeline on a Shoestring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qm36f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675231129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One of the challenges I hear about over and over in the data space is the giant gap that exists between those working on the data operation and those having a stake in the data operation&amp;#39;s deliverables.  &lt;/p&gt;\n\n&lt;p&gt;This often results in a tumultuous first few weeks in a new technical data role, as one weighs the need to deliver value quickly, agains the desire to build something with a strong foundation.  &lt;/p&gt;\n\n&lt;p&gt;I started a mini-series of medium articles that seeks to strike a balance between the two opposing forces - designed to go over a viable path that quickly delivers on a fictional data ask, in a cloud environment, on a shoestring budget:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@syampols/data-pipeline-on-a-shoestring-part-i-where-to-begin-a085bb397470\"&gt;part I - we set the stage&lt;/a&gt; \u2014 whether you\u2019re a hobbyist looking to build a fun data pipeline or you just landed in a startup that needs data served yesterday and you&amp;#39;re looking for a perspective on how to deliver, this summarizes a good problem statement.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@syampols/data-pipeline-on-a-shoestring-part-ii-the-data-need-and-the-architecture-to-solve-for-it-bed5f208de36\"&gt;part II - we pose a data need&lt;/a&gt; \u2014 we describe the fictional ask from our imaginary stakeholder, and propose the architecture that will solve for the need, from ingestion, to transformation, to serving the data, on a shoestring, of course.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@syampols/data-pipeline-on-a-shoestring-part-iii-laying-the-foundation-d74014112f0\"&gt;part III - we lay the foundation for the work&lt;/a&gt; \u2014 using a combination of service oriented architecture principles in combination with infrastructure as code, we prime our cloud environments and describe a framework to deploy the resources needed to solve for the fictional data problem.  &lt;/p&gt;\n\n&lt;p&gt;In part IV (coming soon), we build the pipeline \u2014 using the foundation and deployment process outlined in part III, we continue to deploy the resources that make the pipeline run, as outlined in the architecture in part II.  &lt;/p&gt;\n\n&lt;p&gt;In part V (coming soon), we wrap \u2014 Using the prior framework laid out in the prior four articles, we talk about pathways to scale the solution, as this is, after all, a pipeline on a budget, and will/should not be used beyond a solid proof of concept (unless ye seek technical debt).  &lt;/p&gt;\n\n&lt;p&gt;Enjoy! I would give you rotten tomatoes to throw my way but then it would end up on your monitor, that said, I would love any feedback you may have!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/X1UjVNIpjNDAip8AKmYwRjmbXYy06CldchWMsB0Spig.jpg?auto=webp&amp;v=enabled&amp;s=f3f0d8bb3a99ce5b99739efd8864c8c1983bbd4d", "width": 800, "height": 1088}, "resolutions": [{"url": "https://external-preview.redd.it/X1UjVNIpjNDAip8AKmYwRjmbXYy06CldchWMsB0Spig.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cad18c9f8041c9b317470b7d68352b6d50b19dbe", "width": 108, "height": 146}, {"url": "https://external-preview.redd.it/X1UjVNIpjNDAip8AKmYwRjmbXYy06CldchWMsB0Spig.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=36f906a4b6545525dea99f0ec146006ccfe33416", "width": 216, "height": 293}, {"url": "https://external-preview.redd.it/X1UjVNIpjNDAip8AKmYwRjmbXYy06CldchWMsB0Spig.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e7418e2a1e9f58e4bed983544bb241d9a1d496db", "width": 320, "height": 435}, {"url": "https://external-preview.redd.it/X1UjVNIpjNDAip8AKmYwRjmbXYy06CldchWMsB0Spig.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c16cdcb7d1d29145a69c84315cef39c3a3f2fe9d", "width": 640, "height": 870}], "variants": {}, "id": "jDcIGIjerCPbG0NdHcBNB5qc0vI-g436N3O6fz4iSQQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10qm36f", "is_robot_indexable": true, "report_reasons": null, "author": "JaJ_Judy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qm36f/data_pipeline_on_a_shoestring/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qm36f/data_pipeline_on_a_shoestring/", "subreddit_subscribers": 88127, "created_utc": 1675231129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, \n\nI have a new project in my team I\u2019m supporting our data analysts. They are going to build some simple classification model based on surveys, so then we can use order data to classify the rest of customers. Our stack is flexible, we have databricks running on s3, and we also have dbt+snowflake. \n\nI have knowledge working with ML models but in a DS perspective (building and tunning models) but not as a DE. Don\u2019t really know what are the best practices for storing and versionin models (mlflow I guess, have never used it) and also how to provide the data and then saving it for later use. \n\nHow to observe the model results? For example, if I have a snapshot table saving the current and \u201cnew\u201d customer classification. What would happen if a model changes the customer classification after every run. Doesn\u2019t seem very efficient to keep updating the customer. I guess we can apply some rules but don\u2019t really know where and if there is a tool that can help with that (like mlflow?). This is just an example of trying to know best practices, I\u2019m guessing there are other scenarios. \n\nAny help will be appreciated and if anyone knows a blog or something similar than can help me get a quick start.", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE best practices when working with ML (MLops?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pz27i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675171771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\n\n&lt;p&gt;I have a new project in my team I\u2019m supporting our data analysts. They are going to build some simple classification model based on surveys, so then we can use order data to classify the rest of customers. Our stack is flexible, we have databricks running on s3, and we also have dbt+snowflake. &lt;/p&gt;\n\n&lt;p&gt;I have knowledge working with ML models but in a DS perspective (building and tunning models) but not as a DE. Don\u2019t really know what are the best practices for storing and versionin models (mlflow I guess, have never used it) and also how to provide the data and then saving it for later use. &lt;/p&gt;\n\n&lt;p&gt;How to observe the model results? For example, if I have a snapshot table saving the current and \u201cnew\u201d customer classification. What would happen if a model changes the customer classification after every run. Doesn\u2019t seem very efficient to keep updating the customer. I guess we can apply some rules but don\u2019t really know where and if there is a tool that can help with that (like mlflow?). This is just an example of trying to know best practices, I\u2019m guessing there are other scenarios. &lt;/p&gt;\n\n&lt;p&gt;Any help will be appreciated and if anyone knows a blog or something similar than can help me get a quick start.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10pz27i", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pz27i/de_best_practices_when_working_with_ml_mlops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pz27i/de_best_practices_when_working_with_ml_mlops/", "subreddit_subscribers": 88127, "created_utc": 1675171771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, wanted to ask the group what are the most common \"data engineering\" tools used today. i have a background on informatica ETL, back 20 years ago, and today work a lot with customers that use azure data factory, but i'm curious to know what are the most common tools used today (as in 2023).", "author_fullname": "t2_imia197u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most common data engineering tools used today?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qgu0f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675215159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, wanted to ask the group what are the most common &amp;quot;data engineering&amp;quot; tools used today. i have a background on informatica ETL, back 20 years ago, and today work a lot with customers that use azure data factory, but i&amp;#39;m curious to know what are the most common tools used today (as in 2023).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qgu0f", "is_robot_indexable": true, "report_reasons": null, "author": "Pty_Rick", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qgu0f/most_common_data_engineering_tools_used_today/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qgu0f/most_common_data_engineering_tools_used_today/", "subreddit_subscribers": 88127, "created_utc": 1675215159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The US Army is changing the title of a 26B (a Military Occupational Specialty) from information system engineers to data engineers. As part of the first wave of \u201cdata engineers\u201d, how can I be a better asset for a DoD organization? I hold a lot of IT certifications (CISSP, CISM, CCNA etc etc) but nothing that really helps me in this role. I\u2019m picking up some technical skills on my own and starting to feel my way around how my organization ingests and interprets it\u2019s data but I\u2019m feeling a little lost at the moment. Anyone have any advice?", "author_fullname": "t2_81izlu1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering in the US Army", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q97ag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675196166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The US Army is changing the title of a 26B (a Military Occupational Specialty) from information system engineers to data engineers. As part of the first wave of \u201cdata engineers\u201d, how can I be a better asset for a DoD organization? I hold a lot of IT certifications (CISSP, CISM, CCNA etc etc) but nothing that really helps me in this role. I\u2019m picking up some technical skills on my own and starting to feel my way around how my organization ingests and interprets it\u2019s data but I\u2019m feeling a little lost at the moment. Anyone have any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10q97ag", "is_robot_indexable": true, "report_reasons": null, "author": "Bane_of_Titan", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q97ag/data_engineering_in_the_us_army/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q97ag/data_engineering_in_the_us_army/", "subreddit_subscribers": 88127, "created_utc": 1675196166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just wondering if it's something I should invest in, pretty sure the people in charge of the DMBOK offer one.", "author_fullname": "t2_41lgybw3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Governance certifications: how useful are they in this field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q5xke", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675188370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering if it&amp;#39;s something I should invest in, pretty sure the people in charge of the DMBOK offer one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10q5xke", "is_robot_indexable": true, "report_reasons": null, "author": "arminredditer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q5xke/data_governance_certifications_how_useful_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q5xke/data_governance_certifications_how_useful_are/", "subreddit_subscribers": 88127, "created_utc": 1675188370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m going back and forth with our devops engineer, we only have 4GB ram and 2Vcpu for scheduler and Webserver and 8GB 4VCPU for workers. We push about 200 dags daily and about 1billion rows across batch and real-time. Devops keeps telling me to rewrite the flows because that is the recommended start size for airflow", "author_fullname": "t2_ldunk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What size is your airflow cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q0teh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675176287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m going back and forth with our devops engineer, we only have 4GB ram and 2Vcpu for scheduler and Webserver and 8GB 4VCPU for workers. We push about 200 dags daily and about 1billion rows across batch and real-time. Devops keeps telling me to rewrite the flows because that is the recommended start size for airflow&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q0teh", "is_robot_indexable": true, "report_reasons": null, "author": "wytesmurf", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q0teh/what_size_is_your_airflow_cluster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q0teh/what_size_is_your_airflow_cluster/", "subreddit_subscribers": 88127, "created_utc": 1675176287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Happened to stumble upon this today\u2026 [https://www.fivetran.com/blog/fivetran-pricing](https://www.fivetran.com/blog/fivetran-pricing)\n\n*February 1, 2023 update: We\u2019re offering a Free Plan, replacing the Standard Select tier. On top of that, we lowered pay-as-you-go pricing by 11 percent.* [*Check out the announcement.*](https://www.fivetran.com/fivetran-free-plan)\n\nThe announcement link is currently a 404. Maybe it will be up tomorrow.", "author_fullname": "t2_8fr7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran launching a free tier", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qh91r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675216314.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happened to stumble upon this today\u2026 &lt;a href=\"https://www.fivetran.com/blog/fivetran-pricing\"&gt;https://www.fivetran.com/blog/fivetran-pricing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;February 1, 2023 update: We\u2019re offering a Free Plan, replacing the Standard Select tier. On top of that, we lowered pay-as-you-go pricing by 11 percent.&lt;/em&gt; &lt;a href=\"https://www.fivetran.com/fivetran-free-plan\"&gt;&lt;em&gt;Check out the announcement.&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The announcement link is currently a 404. Maybe it will be up tomorrow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?auto=webp&amp;v=enabled&amp;s=6f76ad332b9778f9e5c8b936f874ac86d6b803a5", "width": 2000, "height": 1001}, "resolutions": [{"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3856080cf62bd92071ebc9f672d05a051a8bcaf4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=506ff27238e7e3b069d4ce2480b79701a9683d76", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a1c7c5e73f51b9dd57bccd28f3504341244b39f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d33f1659cd8f7cfe30c21ed294c91b712389b68", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=388e9e8cd9d4f86495d58145de24d40764151151", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0109a6302cd8c6284059bcf54a763c1db7ac347e", "width": 1080, "height": 540}], "variants": {}, "id": "PJzWrjCOMY508Zf959hjx2rzPDC0ORXbiulae7FDjho"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qh91r", "is_robot_indexable": true, "report_reasons": null, "author": "CEOnnor", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qh91r/fivetran_launching_a_free_tier/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qh91r/fivetran_launching_a_free_tier/", "subreddit_subscribers": 88127, "created_utc": 1675216314.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From HackerNews: Heroku deleted my database with no warning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qadtn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1675198937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "news.ycombinator.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://news.ycombinator.com/item?id=34598563", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qadtn", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qadtn/from_hackernews_heroku_deleted_my_database_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://news.ycombinator.com/item?id=34598563", "subreddit_subscribers": 88127, "created_utc": 1675198937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any particular patterns, native libraries or other?\n\n(We know data sciencists have pandas, numpy etc..)", "author_fullname": "t2_2pxsf0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which aspects of the python programming language help you be a better data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qa5zk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675198446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any particular patterns, native libraries or other?&lt;/p&gt;\n\n&lt;p&gt;(We know data sciencists have pandas, numpy etc..)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qa5zk", "is_robot_indexable": true, "report_reasons": null, "author": "blue_trains_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qa5zk/which_aspects_of_the_python_programming_language/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qa5zk/which_aspects_of_the_python_programming_language/", "subreddit_subscribers": 88127, "created_utc": 1675198446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Today I found out about AWS Quicksight Q which helps answering business questions using NLP based on reports created in it (like what was my sales for the last week?)\n\nI want to know if there is a solution could be integrated via slack bots to help people get quick answers to such queries. Currently Quicksight Q doesn\u2019t allow slack integration I think. \n\nFeel like this feature can be helpful for quick answers rather than searching through a report.", "author_fullname": "t2_dv4ply58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NLP support for reports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qp8dc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675243625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Today I found out about AWS Quicksight Q which helps answering business questions using NLP based on reports created in it (like what was my sales for the last week?)&lt;/p&gt;\n\n&lt;p&gt;I want to know if there is a solution could be integrated via slack bots to help people get quick answers to such queries. Currently Quicksight Q doesn\u2019t allow slack integration I think. &lt;/p&gt;\n\n&lt;p&gt;Feel like this feature can be helpful for quick answers rather than searching through a report.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10qp8dc", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Apple_420", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qp8dc/nlp_support_for_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qp8dc/nlp_support_for_reports/", "subreddit_subscribers": 88127, "created_utc": 1675243625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I'm currently enrolled a Master's in Software Engineering and have been very interested in DE since my undergrad and completed various projects and an internship within the space, and I definitely plan on pursuing more internships if possible. \n\nI've read a lot that getting a job as a DE right out of university with no professional experience is very difficult due to the nature of the job. From what I've read on this sub, people recommend going through a different role in Software Engineering and then transitioning into a DE role. \n\nIs this accurate? If so, what other role is the best suited for this transition? Backend development is something I've seen mentioned a lot.\n\nThanks!", "author_fullname": "t2_49e7c0kc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Entering DE as a grad with no experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qgc2m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675213835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I&amp;#39;m currently enrolled a Master&amp;#39;s in Software Engineering and have been very interested in DE since my undergrad and completed various projects and an internship within the space, and I definitely plan on pursuing more internships if possible. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read a lot that getting a job as a DE right out of university with no professional experience is very difficult due to the nature of the job. From what I&amp;#39;ve read on this sub, people recommend going through a different role in Software Engineering and then transitioning into a DE role. &lt;/p&gt;\n\n&lt;p&gt;Is this accurate? If so, what other role is the best suited for this transition? Backend development is something I&amp;#39;ve seen mentioned a lot.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qgc2m", "is_robot_indexable": true, "report_reasons": null, "author": "infiniteAggression-", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qgc2m/entering_de_as_a_grad_with_no_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qgc2m/entering_de_as_a_grad_with_no_experience/", "subreddit_subscribers": 88127, "created_utc": 1675213835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to create a brand new data system for my company. I managed to create Python scripts that pulls data from APIs, wrangle them into a Pandas DataFrame, and export them into an Excel file. We are trying to do this process automatically daily on the cloud, store them in BigQuery, and display them in Data Studio.\n\nThis is the system that I have in mind. I put the scripts on Cloud Functions, but instead of export them into excel files, I use pandas\\_gbq to store them to BigQuery. For the cron jobs, I use Cloud Scheduler to trigger the scripts on the Cloud Functions by sending HTTP requests. What do you think of this system?", "author_fullname": "t2_2knag8t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think about my data pipeline system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qcb4w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675203530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to create a brand new data system for my company. I managed to create Python scripts that pulls data from APIs, wrangle them into a Pandas DataFrame, and export them into an Excel file. We are trying to do this process automatically daily on the cloud, store them in BigQuery, and display them in Data Studio.&lt;/p&gt;\n\n&lt;p&gt;This is the system that I have in mind. I put the scripts on Cloud Functions, but instead of export them into excel files, I use pandas_gbq to store them to BigQuery. For the cron jobs, I use Cloud Scheduler to trigger the scripts on the Cloud Functions by sending HTTP requests. What do you think of this system?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10qcb4w", "is_robot_indexable": true, "report_reasons": null, "author": "lordgriefter", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qcb4w/what_do_you_think_about_my_data_pipeline_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qcb4w/what_do_you_think_about_my_data_pipeline_system/", "subreddit_subscribers": 88127, "created_utc": 1675203530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious to hear about other experiences here.\n\nThe kind of DE I've done before was focused on cleaning, transforming and restructuring raw data loaded from a combination of a MySQL DB and a queue of events that were both loaded into Snowflake. All data cleaning and transformation etc. was done in Snowflake. Specifically, I defined javascript stored procedures that generated SQL statements dynamically (depending on input params) so all repeated logic was effectively encapsulated in a relatively small number of SPs. These SPs were called from an ETL tool which passed in the correct params and managed the execution flow etc.\n\nI'm currently doing DE Zoomcamp and it's been great so far learning about docker and python etc. But it got me thinking. In which scenarios does it make sense to do these data cleaning and transformation steps in python rather than SQL? I've never encountered anything I wanted to do but couldn't do with SQL. We were leveraging the compute of snowflake so complex operations even on huge datasets were relatively quick. Plus with all the data in snowflake, you can easily query it to have a look at it. What environment allows you to \"see\" the data so well if you are using python to manipulate data?\n\nIs the kind of DE where you download data from some external source then ingest it with a python script reserved for relatively small datasets? Or datasets loaded from sources where you don't have direct access to the DB?\n\nI feel I am missing some key part of the picture regarding \"why everyone uses python\", or the kinds of tools they are using that depend on python rather than SQL.", "author_fullname": "t2_5n8mvd7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Different types of DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q9s2t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675197553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious to hear about other experiences here.&lt;/p&gt;\n\n&lt;p&gt;The kind of DE I&amp;#39;ve done before was focused on cleaning, transforming and restructuring raw data loaded from a combination of a MySQL DB and a queue of events that were both loaded into Snowflake. All data cleaning and transformation etc. was done in Snowflake. Specifically, I defined javascript stored procedures that generated SQL statements dynamically (depending on input params) so all repeated logic was effectively encapsulated in a relatively small number of SPs. These SPs were called from an ETL tool which passed in the correct params and managed the execution flow etc.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently doing DE Zoomcamp and it&amp;#39;s been great so far learning about docker and python etc. But it got me thinking. In which scenarios does it make sense to do these data cleaning and transformation steps in python rather than SQL? I&amp;#39;ve never encountered anything I wanted to do but couldn&amp;#39;t do with SQL. We were leveraging the compute of snowflake so complex operations even on huge datasets were relatively quick. Plus with all the data in snowflake, you can easily query it to have a look at it. What environment allows you to &amp;quot;see&amp;quot; the data so well if you are using python to manipulate data?&lt;/p&gt;\n\n&lt;p&gt;Is the kind of DE where you download data from some external source then ingest it with a python script reserved for relatively small datasets? Or datasets loaded from sources where you don&amp;#39;t have direct access to the DB?&lt;/p&gt;\n\n&lt;p&gt;I feel I am missing some key part of the picture regarding &amp;quot;why everyone uses python&amp;quot;, or the kinds of tools they are using that depend on python rather than SQL.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q9s2t", "is_robot_indexable": true, "report_reasons": null, "author": "kaiso_gunkan", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q9s2t/different_types_of_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q9s2t/different_types_of_de/", "subreddit_subscribers": 88127, "created_utc": 1675197553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone here done the Databricks Data Engineer Associate cert? I've completed the Data Engineering with Databricks training on the partner academy, would that be sufficient? \n\nI'm trying to gage whether I've prepared enough.\n\nThanks in advance!", "author_fullname": "t2_jgs2foti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Data Eng Associate Cert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q4055", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675183910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone here done the Databricks Data Engineer Associate cert? I&amp;#39;ve completed the Data Engineering with Databricks training on the partner academy, would that be sufficient? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to gage whether I&amp;#39;ve prepared enough.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10q4055", "is_robot_indexable": true, "report_reasons": null, "author": "aak55", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q4055/databricks_data_eng_associate_cert/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q4055/databricks_data_eng_associate_cert/", "subreddit_subscribers": 88127, "created_utc": 1675183910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please help decide:\n8 YOE + H1-B Visa\nBoth remote jobs\nGiven the current Layoffs and possible recession, unable to decide which is better.\n\nCurrent Company (Staff Data Engineer): \n170K base + 40K bonus at year-end.\nGreat work-life balance (&lt; 6 hrs a day of work) and rest for personal skills.\nThe job is 100% secure and working with the team for 3+ years.\nSkills: Airflow, Meltano, dbt, Snowflake, AWS\n\nSeries A Start-Up (Senior Analytics Engineer):\n190K base + 0.05% (~250K) vested over 4 years.\nInsurance Industry. Revenue ~30 Mil and raised ~30 Mil in 2022.\n8-10 hrs work depending on the learning needed.\nThe Hiring Manager says the job is secure for at least 2 years.\nSkills: Dagster, GCP, dbt, python", "author_fullname": "t2_pzyrjzd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Current company vs Series A Startup (almost Series B)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qggo2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675214179.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please help decide:\n8 YOE + H1-B Visa\nBoth remote jobs\nGiven the current Layoffs and possible recession, unable to decide which is better.&lt;/p&gt;\n\n&lt;p&gt;Current Company (Staff Data Engineer): \n170K base + 40K bonus at year-end.\nGreat work-life balance (&amp;lt; 6 hrs a day of work) and rest for personal skills.\nThe job is 100% secure and working with the team for 3+ years.\nSkills: Airflow, Meltano, dbt, Snowflake, AWS&lt;/p&gt;\n\n&lt;p&gt;Series A Start-Up (Senior Analytics Engineer):\n190K base + 0.05% (~250K) vested over 4 years.\nInsurance Industry. Revenue ~30 Mil and raised ~30 Mil in 2022.\n8-10 hrs work depending on the learning needed.\nThe Hiring Manager says the job is secure for at least 2 years.\nSkills: Dagster, GCP, dbt, python&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10qggo2", "is_robot_indexable": true, "report_reasons": null, "author": "mothikikm", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qggo2/current_company_vs_series_a_startup_almost_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qggo2/current_company_vs_series_a_startup_almost_series/", "subreddit_subscribers": 88127, "created_utc": 1675214179.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone ever used Databricks with an on premise source control system? If so, can you provide what's steps you did for code development and CICD.", "author_fullname": "t2_4anjpw7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks and On Premise Source Control", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q5xek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675188361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone ever used Databricks with an on premise source control system? If so, can you provide what&amp;#39;s steps you did for code development and CICD.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q5xek", "is_robot_indexable": true, "report_reasons": null, "author": "B1WR2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q5xek/databricks_and_on_premise_source_control/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q5xek/databricks_and_on_premise_source_control/", "subreddit_subscribers": 88127, "created_utc": 1675188361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I stumbled upon a usecase where reports were automated using RDF and triply. Data from there would get exported to powerbi.  Normally you see a datawarehouses for these kind of usecases.\n\nIs this linked data a viable option or is it just a niche?", "author_fullname": "t2_mv3d8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RDF/triply for building dataplatform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q2ejq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675180122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I stumbled upon a usecase where reports were automated using RDF and triply. Data from there would get exported to powerbi.  Normally you see a datawarehouses for these kind of usecases.&lt;/p&gt;\n\n&lt;p&gt;Is this linked data a viable option or is it just a niche?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q2ejq", "is_robot_indexable": true, "report_reasons": null, "author": "artopaper", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q2ejq/rdftriply_for_building_dataplatform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q2ejq/rdftriply_for_building_dataplatform/", "subreddit_subscribers": 88127, "created_utc": 1675180122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, i come from a finance background and want to move into data. I'm not sure whether I should start with data analysi, data science, data engineering, BI, etc. So many things out there which makes it equally confusing for me to choose from. I don't know if data even is for me.\nAt the same time i don't want to just sit idle till i come to a decision. \nWhat would you suggest i start with atleast so that i can figure out the process as i go? \n\nI'm a qualified CMA and have experience in accounts and costing, zero idea of data science and don't know where/how to start.", "author_fullname": "t2_gny7wjxw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data for non science background people", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pyi28", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675170214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, i come from a finance background and want to move into data. I&amp;#39;m not sure whether I should start with data analysi, data science, data engineering, BI, etc. So many things out there which makes it equally confusing for me to choose from. I don&amp;#39;t know if data even is for me.\nAt the same time i don&amp;#39;t want to just sit idle till i come to a decision. \nWhat would you suggest i start with atleast so that i can figure out the process as i go? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a qualified CMA and have experience in accounts and costing, zero idea of data science and don&amp;#39;t know where/how to start.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10pyi28", "is_robot_indexable": true, "report_reasons": null, "author": "quixoticlife1301", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pyi28/data_for_non_science_background_people/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pyi28/data_for_non_science_background_people/", "subreddit_subscribers": 88127, "created_utc": 1675170214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I understand one can define a dbt model, but how it can be orchestrated/scheduled for everyday run? I am asking because you define the model usict some WITH/SELECT statements which I can imagine can work perfectly when initializing the database/table. But how about periodic updates/increments of the result tables? I mean - everyday we would run some workflow that should add a new data into some table, but dbt model is doing select \\* from the source, right? So everyday it would do a full load of the models? Or is it possible to somehow use dbt models to run everyday increment jobs?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt and Airflow - increments?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10qsgqy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675252692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand one can define a dbt model, but how it can be orchestrated/scheduled for everyday run? I am asking because you define the model usict some WITH/SELECT statements which I can imagine can work perfectly when initializing the database/table. But how about periodic updates/increments of the result tables? I mean - everyday we would run some workflow that should add a new data into some table, but dbt model is doing select * from the source, right? So everyday it would do a full load of the models? Or is it possible to somehow use dbt models to run everyday increment jobs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qsgqy", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qsgqy/dbt_and_airflow_increments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qsgqy/dbt_and_airflow_increments/", "subreddit_subscribers": 88127, "created_utc": 1675252692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you handle a destructive change to the table used in production? Let's say we have a Postgres as production warehouse and applications query the data from it (obviously). And now we want to change some table in the WH and let's say we want to delete some columns. How do you manage this process? You create a clone table with the same data and give some period to all applications to adapt to the new table and then discontinue the old one? Or what is the best practice in such scenario?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handling table schema change in production", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10qs3or", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675252031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you handle a destructive change to the table used in production? Let&amp;#39;s say we have a Postgres as production warehouse and applications query the data from it (obviously). And now we want to change some table in the WH and let&amp;#39;s say we want to delete some columns. How do you manage this process? You create a clone table with the same data and give some period to all applications to adapt to the new table and then discontinue the old one? Or what is the best practice in such scenario?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qs3or", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qs3or/handling_table_schema_change_in_production/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qs3or/handling_table_schema_change_in_production/", "subreddit_subscribers": 88127, "created_utc": 1675252031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the actual use cases of the data contracts? I just read about them and from what I understand, it is used mainly for defining data schema for streaming data? I.e. you define schema you expect your data to adhere when reading such data from e.g. Kafka? And it is useful because e.g. protobuf can be implemented using different languages? Or are data contracts used in some other way? Do they make any sense for batch data processing?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data contracts actual use cases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_10qrefc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675250797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the actual use cases of the data contracts? I just read about them and from what I understand, it is used mainly for defining data schema for streaming data? I.e. you define schema you expect your data to adhere when reading such data from e.g. Kafka? And it is useful because e.g. protobuf can be implemented using different languages? Or are data contracts used in some other way? Do they make any sense for batch data processing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qrefc", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qrefc/data_contracts_actual_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qrefc/data_contracts_actual_use_cases/", "subreddit_subscribers": 88127, "created_utc": 1675250797.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}