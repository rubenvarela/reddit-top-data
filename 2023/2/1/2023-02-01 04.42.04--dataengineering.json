{"kind": "Listing", "data": {"after": "t3_10q7yfz", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is my second data project. Creating an Extract Transform Load pipeline using python and automating with airflow.\n\n# Problem Statement:\n\nWe need to use Spotify\u2019s API to read the data and perform some basic transformations and Data Quality checks finally will load the retrieved data to PostgreSQL DB and then automate the entire process through airflow. **Est.Time:**\\[4\u20137 Hours\\]\n\n# Tech Stack / Skill used:\n\n1. Python\n2. API\u2019s\n3. Docker\n4. Airflow\n5. PostgreSQL\n\n# Learning Outcomes:\n\n1. Understand how to interact with API to retrieve data\n2. Handling Dataframe in pandas\n3. Setting up Airflow and PostgreSQL through Docker-Compose.\n4. Learning to Create DAGs in Airflow\n\nHere is the [GitHub repo](https://github.com/sidharth1805/Spotify_etl).\n\nHere is a blog where I have documented my project [Blog](https://medium.com/p/432dd8e4ffa3)\n\n[Design Diagram](https://preview.redd.it/a6kh9au6nbfa1.png?width=2283&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f095b1352bc9c4a72e9898a386e80bd2928598ef)\n\n&amp;#x200B;\n\n[Tree View of Airflow DAG](https://preview.redd.it/7gqn7up8pbfa1.png?width=635&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=02d5b357c50c80801f9b5131a042988870ee21ec)", "author_fullname": "t2_7oampu1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekend Data Engineering Project-Building Spotify pipeline using Python and Airflow. Est.Time:[4\u20137 Hours]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7gqn7up8pbfa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/7gqn7up8pbfa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccf217d1cbeabe7fa98b54afa04fc6acd096bdf7"}, {"y": 72, "x": 216, "u": "https://preview.redd.it/7gqn7up8pbfa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dbca526fa4987a747670b35104f949cff3f03245"}, {"y": 107, "x": 320, "u": "https://preview.redd.it/7gqn7up8pbfa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47cf32337b3b9cb2ff8773ebc675ed19612c36c2"}], "s": {"y": 213, "x": 635, "u": "https://preview.redd.it/7gqn7up8pbfa1.png?width=635&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=02d5b357c50c80801f9b5131a042988870ee21ec"}, "id": "7gqn7up8pbfa1"}, "a6kh9au6nbfa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 63, "x": 108, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fa8ab55f6aec6eab0c802c8bef7e65cf249f3698"}, {"y": 126, "x": 216, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=25629e845ca0317c63c72e79c7e612519398a3a2"}, {"y": 186, "x": 320, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1597e2954b5165241d2de8f220c7862d4bb0e54c"}, {"y": 373, "x": 640, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b23007973e1096d3695f50cd59d0acf70ca2be8"}, {"y": 560, "x": 960, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bce285750a2d3706c51493936f5a3e221f8b8442"}, {"y": 630, "x": 1080, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=af3a89566d07560692d6c465f79e765bf02b4bf6"}], "s": {"y": 1332, "x": 2283, "u": "https://preview.redd.it/a6kh9au6nbfa1.png?width=2283&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f095b1352bc9c4a72e9898a386e80bd2928598ef"}, "id": "a6kh9au6nbfa1"}}, "name": "t3_10pqspk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": "transparent", "ups": 101, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 101, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/VxmI86MsFsJ7Q2igGddKbdyJNb9dokMDikebUBRapKM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1675146406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is my second data project. Creating an Extract Transform Load pipeline using python and automating with airflow.&lt;/p&gt;\n\n&lt;h1&gt;Problem Statement:&lt;/h1&gt;\n\n&lt;p&gt;We need to use Spotify\u2019s API to read the data and perform some basic transformations and Data Quality checks finally will load the retrieved data to PostgreSQL DB and then automate the entire process through airflow. &lt;strong&gt;Est.Time:&lt;/strong&gt;[4\u20137 Hours]&lt;/p&gt;\n\n&lt;h1&gt;Tech Stack / Skill used:&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Python&lt;/li&gt;\n&lt;li&gt;API\u2019s&lt;/li&gt;\n&lt;li&gt;Docker&lt;/li&gt;\n&lt;li&gt;Airflow&lt;/li&gt;\n&lt;li&gt;PostgreSQL&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Learning Outcomes:&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Understand how to interact with API to retrieve data&lt;/li&gt;\n&lt;li&gt;Handling Dataframe in pandas&lt;/li&gt;\n&lt;li&gt;Setting up Airflow and PostgreSQL through Docker-Compose.&lt;/li&gt;\n&lt;li&gt;Learning to Create DAGs in Airflow&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Here is the &lt;a href=\"https://github.com/sidharth1805/Spotify_etl\"&gt;GitHub repo&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Here is a blog where I have documented my project &lt;a href=\"https://medium.com/p/432dd8e4ffa3\"&gt;Blog&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/a6kh9au6nbfa1.png?width=2283&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=f095b1352bc9c4a72e9898a386e80bd2928598ef\"&gt;Design Diagram&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7gqn7up8pbfa1.png?width=635&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=02d5b357c50c80801f9b5131a042988870ee21ec\"&gt;Tree View of Airflow DAG&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?auto=webp&amp;v=enabled&amp;s=e336fd843f5783ca5cfbb9c5dc232f8cb1c6b4b2", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5e1f2a75d54de15a628ab56bfb234c9ce7cf638b", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57d58d4288d7dd1c07c271f50d96770a1adfbdd2", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63f310fb6864de7bd744aebbc202bec6fcc597c9", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7d3a00191306057f6dba6db6b400cfd215b5a6a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=729e3e9648986c5d575283a4ba741b79f9d69540", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/a-4h0Yu_lPtCew0TrQ2xYHuJfu7R7r4gqnMTNcpn7pI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=006dd09a81cf5747871d0419dc0e3a1026d4f2e6", "width": 1080, "height": 540}], "variants": {}, "id": "T31bODdgOZMYN-TPAk0oYZ_YSgsbZ9pNCQo_R6CXdWU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "10pqspk", "is_robot_indexable": true, "report_reasons": null, "author": "Sidharth_r", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10pqspk/weekend_data_engineering_projectbuilding_spotify/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pqspk/weekend_data_engineering_projectbuilding_spotify/", "subreddit_subscribers": 88091, "created_utc": 1675146406.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I'm sorry if this post is long...there's a **tldr** at the bottom. I just want a place to vent and get feedback - I feel discouraged and frustrated. About three weeks ago, I had an initial screening with a recruiter from a tech start-up based in Europe. It led to a technical interview for a remote data engineering role (US) with them. The first technical interview went well, and I was informed that the next step would be a take-home assignment. The assignment asked me to do pretty much what I would be doing if I received the position:\n\n1. Write an API that connects to one of their datasets\n2. include multiple parameters for aggregation, querying, and filtering\n3. put it on the cloud\n4. write documentation for it\n5. Write a report of why you chose the tools you did and what you would do differently.\n\nThe time limit on the assignment was approximately three hours. This struck me as a red flag because I felt like this was a lot of work to accomplish in less than half a work day (I would love your thoughts on that, actually. Maybe I'm just slow.)? The assignment was also very open-ended. There was no mention of which dataset to connect to, how to connect to it, which tools to use, or really any expectations on their end.\n\nI'm not a fan of take-home assignments because I've heard horror stories of people getting used for their free work. Since it was so open-ended, only three hours long, and the interviewer was super chill when talking about the assignment (\"We just need something to get a feel for your Python skills\") I assumed it was ok to build a small application showcasing the fundamentals of API development.\n\nI used one of their smaller datasets, coded my API in Python using Django and Pandas, hosted it on an EC2 instance, and wrote markdown documentation. In my report, I mention how I would use Spark, tokenization (I was working with text data), and a proper database if I were to make this app production grade. I included all the drawbacks of my current application and how I would fix them - because of course - the assignment was only supposed to be three hours long, and there was only so much I was willing to do for a take-home assignment. I felt like this was a lot of work as it is, and it took me roughly 6.5 hours to complete.\n\nAfter submitting my assignment, I got an email the next day telling me I did a great job and they would like to proceed with the second technical interview. The second interview ended well, with the interviewer telling me they would schedule a final interview with the CTO. Instead, I received another email three days later stating that the company decided to terminate the interview process. Why? Because my app was not using a large enough dataset, my code wasn't efficient enough, pretty much telling me that it wasn't applicable for a large-scale system. ????????. Of course not? This is a take-home assignment that was supposed to take 3 hours to finish. I am honestly baffled. Is this normal? I understand there are people out there who probably can write an enterprise-level API in 3 hours, but even so, why do it for free during the interview process? At this point, I feel a bit sketched out and like I dodged a bullet. It's still discouraging to make it so far in the interview process and not get an offer, though.\n\n&amp;#x200B;\n\n**TLDR**; *I completed a take-home assignment, and I feel kind of shitty about it. Considering avoiding companies that ask me to do this in the future...*", "author_fullname": "t2_kju9dvol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feel a bit burned from a take-home assignment I completed during an interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qdxjr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1675208982.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675207533.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m sorry if this post is long...there&amp;#39;s a &lt;strong&gt;tldr&lt;/strong&gt; at the bottom. I just want a place to vent and get feedback - I feel discouraged and frustrated. About three weeks ago, I had an initial screening with a recruiter from a tech start-up based in Europe. It led to a technical interview for a remote data engineering role (US) with them. The first technical interview went well, and I was informed that the next step would be a take-home assignment. The assignment asked me to do pretty much what I would be doing if I received the position:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Write an API that connects to one of their datasets&lt;/li&gt;\n&lt;li&gt;include multiple parameters for aggregation, querying, and filtering&lt;/li&gt;\n&lt;li&gt;put it on the cloud&lt;/li&gt;\n&lt;li&gt;write documentation for it&lt;/li&gt;\n&lt;li&gt;Write a report of why you chose the tools you did and what you would do differently.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The time limit on the assignment was approximately three hours. This struck me as a red flag because I felt like this was a lot of work to accomplish in less than half a work day (I would love your thoughts on that, actually. Maybe I&amp;#39;m just slow.)? The assignment was also very open-ended. There was no mention of which dataset to connect to, how to connect to it, which tools to use, or really any expectations on their end.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not a fan of take-home assignments because I&amp;#39;ve heard horror stories of people getting used for their free work. Since it was so open-ended, only three hours long, and the interviewer was super chill when talking about the assignment (&amp;quot;We just need something to get a feel for your Python skills&amp;quot;) I assumed it was ok to build a small application showcasing the fundamentals of API development.&lt;/p&gt;\n\n&lt;p&gt;I used one of their smaller datasets, coded my API in Python using Django and Pandas, hosted it on an EC2 instance, and wrote markdown documentation. In my report, I mention how I would use Spark, tokenization (I was working with text data), and a proper database if I were to make this app production grade. I included all the drawbacks of my current application and how I would fix them - because of course - the assignment was only supposed to be three hours long, and there was only so much I was willing to do for a take-home assignment. I felt like this was a lot of work as it is, and it took me roughly 6.5 hours to complete.&lt;/p&gt;\n\n&lt;p&gt;After submitting my assignment, I got an email the next day telling me I did a great job and they would like to proceed with the second technical interview. The second interview ended well, with the interviewer telling me they would schedule a final interview with the CTO. Instead, I received another email three days later stating that the company decided to terminate the interview process. Why? Because my app was not using a large enough dataset, my code wasn&amp;#39;t efficient enough, pretty much telling me that it wasn&amp;#39;t applicable for a large-scale system. ????????. Of course not? This is a take-home assignment that was supposed to take 3 hours to finish. I am honestly baffled. Is this normal? I understand there are people out there who probably can write an enterprise-level API in 3 hours, but even so, why do it for free during the interview process? At this point, I feel a bit sketched out and like I dodged a bullet. It&amp;#39;s still discouraging to make it so far in the interview process and not get an offer, though.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt;; &lt;em&gt;I completed a take-home assignment, and I feel kind of shitty about it. Considering avoiding companies that ask me to do this in the future...&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "10qdxjr", "is_robot_indexable": true, "report_reasons": null, "author": "LusciousPigeon", "discussion_type": null, "num_comments": 43, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qdxjr/feel_a_bit_burned_from_a_takehome_assignment_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qdxjr/feel_a_bit_burned_from_a_takehome_assignment_i/", "subreddit_subscribers": 88091, "created_utc": 1675207533.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My plan is just to learn as many new skills at my current job as possible and try taking on new projects.  Luckily, I'm pretty happy with my current company, but I always have skills and Leetcode in the back of my mind given the economy.\n\n\n\n\n\nIf I were to look for another company, I don't think I would find a new job that I like since recruiters on LinkedIn are messaging less and the numbers of jobs posted in my area have gone significantly down.  This is even the case at 4 years of experience, with 2 of those years at a tech unicorn.", "author_fullname": "t2_3v6ob2bf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What should experienced data engineers be doing until the economy improves?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pxqcl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675167962.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My plan is just to learn as many new skills at my current job as possible and try taking on new projects.  Luckily, I&amp;#39;m pretty happy with my current company, but I always have skills and Leetcode in the back of my mind given the economy.&lt;/p&gt;\n\n&lt;p&gt;If I were to look for another company, I don&amp;#39;t think I would find a new job that I like since recruiters on LinkedIn are messaging less and the numbers of jobs posted in my area have gone significantly down.  This is even the case at 4 years of experience, with 2 of those years at a tech unicorn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10pxqcl", "is_robot_indexable": true, "report_reasons": null, "author": "data_preprocessing", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10pxqcl/what_should_experienced_data_engineers_be_doing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pxqcl/what_should_experienced_data_engineers_be_doing/", "subreddit_subscribers": 88091, "created_utc": 1675167962.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello data engineering community!\n\nI would like to learn more about Kafka since I'm supposed to use it in the near future at my current job. Our current stack consists of numerous batch processing pipelines and we don't use streaming at all.\n\nI understand the basic concepts of Kafka and message brokers in general but I would need a more in depth course on how to use, basic configuration, etc. to help with my future tasks.\n\nThus, please don't mention any Kafka basics course since those should be a waste of time.\n\nThank you in advance for your input!", "author_fullname": "t2_ce7do", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka course recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q4jux", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675185166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello data engineering community!&lt;/p&gt;\n\n&lt;p&gt;I would like to learn more about Kafka since I&amp;#39;m supposed to use it in the near future at my current job. Our current stack consists of numerous batch processing pipelines and we don&amp;#39;t use streaming at all.&lt;/p&gt;\n\n&lt;p&gt;I understand the basic concepts of Kafka and message brokers in general but I would need a more in depth course on how to use, basic configuration, etc. to help with my future tasks.&lt;/p&gt;\n\n&lt;p&gt;Thus, please don&amp;#39;t mention any Kafka basics course since those should be a waste of time.&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10q4jux", "is_robot_indexable": true, "report_reasons": null, "author": "ulysses_black", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/10q4jux/kafka_course_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q4jux/kafka_course_recommendations/", "subreddit_subscribers": 88091, "created_utc": 1675185166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys! So I'm an integrations engineer at a startup, basically scripting parsers, loading data, etc. However, I got an offer for a 22% raise elsewhere.\nHere's the deal:\n\n-Current Job: Integrations engineer, Salas startup, average compensation. Most of the time dealing with Django, AWS and Python. No possibility to grow in the near future.\n\n-Offered Job: 60% data analysis and 40% Data Engineer at a consulting firm, it's like a hybrid, most of the time dealing with PowerBI, Azure, SQL and Python. Possibility to become head of analysis in 2-3 years. 22% raise.\n\nWhat do you guys think? Is it worth it to jump over a 22% raise? I mean, being an integrations engineer you just are a glorified light-backend dev imo\n\n\n\n\n\nIs this worth it? I mean, it would be", "author_fullname": "t2_171ccp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "22% difference salary worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q9uvv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675197735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys! So I&amp;#39;m an integrations engineer at a startup, basically scripting parsers, loading data, etc. However, I got an offer for a 22% raise elsewhere.\nHere&amp;#39;s the deal:&lt;/p&gt;\n\n&lt;p&gt;-Current Job: Integrations engineer, Salas startup, average compensation. Most of the time dealing with Django, AWS and Python. No possibility to grow in the near future.&lt;/p&gt;\n\n&lt;p&gt;-Offered Job: 60% data analysis and 40% Data Engineer at a consulting firm, it&amp;#39;s like a hybrid, most of the time dealing with PowerBI, Azure, SQL and Python. Possibility to become head of analysis in 2-3 years. 22% raise.&lt;/p&gt;\n\n&lt;p&gt;What do you guys think? Is it worth it to jump over a 22% raise? I mean, being an integrations engineer you just are a glorified light-backend dev imo&lt;/p&gt;\n\n&lt;p&gt;Is this worth it? I mean, it would be&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10q9uvv", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_Nicotine", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q9uvv/22_difference_salary_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q9uvv/22_difference_salary_worth_it/", "subreddit_subscribers": 88091, "created_utc": 1675197735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, \n\nI have a new project in my team I\u2019m supporting our data analysts. They are going to build some simple classification model based on surveys, so then we can use order data to classify the rest of customers. Our stack is flexible, we have databricks running on s3, and we also have dbt+snowflake. \n\nI have knowledge working with ML models but in a DS perspective (building and tunning models) but not as a DE. Don\u2019t really know what are the best practices for storing and versionin models (mlflow I guess, have never used it) and also how to provide the data and then saving it for later use. \n\nHow to observe the model results? For example, if I have a snapshot table saving the current and \u201cnew\u201d customer classification. What would happen if a model changes the customer classification after every run. Doesn\u2019t seem very efficient to keep updating the customer. I guess we can apply some rules but don\u2019t really know where and if there is a tool that can help with that (like mlflow?). This is just an example of trying to know best practices, I\u2019m guessing there are other scenarios. \n\nAny help will be appreciated and if anyone knows a blog or something similar than can help me get a quick start.", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE best practices when working with ML (MLops?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pz27i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675171771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, &lt;/p&gt;\n\n&lt;p&gt;I have a new project in my team I\u2019m supporting our data analysts. They are going to build some simple classification model based on surveys, so then we can use order data to classify the rest of customers. Our stack is flexible, we have databricks running on s3, and we also have dbt+snowflake. &lt;/p&gt;\n\n&lt;p&gt;I have knowledge working with ML models but in a DS perspective (building and tunning models) but not as a DE. Don\u2019t really know what are the best practices for storing and versionin models (mlflow I guess, have never used it) and also how to provide the data and then saving it for later use. &lt;/p&gt;\n\n&lt;p&gt;How to observe the model results? For example, if I have a snapshot table saving the current and \u201cnew\u201d customer classification. What would happen if a model changes the customer classification after every run. Doesn\u2019t seem very efficient to keep updating the customer. I guess we can apply some rules but don\u2019t really know where and if there is a tool that can help with that (like mlflow?). This is just an example of trying to know best practices, I\u2019m guessing there are other scenarios. &lt;/p&gt;\n\n&lt;p&gt;Any help will be appreciated and if anyone knows a blog or something similar than can help me get a quick start.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10pz27i", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pz27i/de_best_practices_when_working_with_ml_mlops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pz27i/de_best_practices_when_working_with_ml_mlops/", "subreddit_subscribers": 88091, "created_utc": 1675171771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m going back and forth with our devops engineer, we only have 4GB ram and 2Vcpu for scheduler and Webserver and 8GB 4VCPU for workers. We push about 200 dags daily and about 1billion rows across batch and real-time. Devops keeps telling me to rewrite the flows because that is the recommended start size for airflow", "author_fullname": "t2_ldunk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What size is your airflow cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q0teh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675176287.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m going back and forth with our devops engineer, we only have 4GB ram and 2Vcpu for scheduler and Webserver and 8GB 4VCPU for workers. We push about 200 dags daily and about 1billion rows across batch and real-time. Devops keeps telling me to rewrite the flows because that is the recommended start size for airflow&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q0teh", "is_robot_indexable": true, "report_reasons": null, "author": "wytesmurf", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q0teh/what_size_is_your_airflow_cluster/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q0teh/what_size_is_your_airflow_cluster/", "subreddit_subscribers": 88091, "created_utc": 1675176287.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just wondering if it's something I should invest in, pretty sure the people in charge of the DMBOK offer one.", "author_fullname": "t2_41lgybw3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Governance certifications: how useful are they in this field?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q5xke", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675188370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering if it&amp;#39;s something I should invest in, pretty sure the people in charge of the DMBOK offer one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10q5xke", "is_robot_indexable": true, "report_reasons": null, "author": "arminredditer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q5xke/data_governance_certifications_how_useful_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q5xke/data_governance_certifications_how_useful_are/", "subreddit_subscribers": 88091, "created_utc": 1675188370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The raise in popularity of ChatGPT/GPT3 and LLMs in general got me wondering.  \nDid these tools make it into the hands of the data community already?  \nAre you using such a tool for your daily work?\n\nPlease share your stories on the topic.\n\n&amp;#x200B;\n\nAdded an example from ChatGPT usage:\n\n&amp;#x200B;\n\n[ChatGPT creates DDL from natural language request](https://preview.redd.it/afg46q8pncfa1.png?width=718&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fcaaec1219a9d725c1baa6cf6ff3db1c7dd8423b)\n\n[View Poll](https://www.reddit.com/poll/10puzjt)", "author_fullname": "t2_ayp5oyir", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Usage of generative AI for SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 123, "top_awarded_type": null, "hide_score": false, "media_metadata": {"afg46q8pncfa1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 94, "x": 108, "u": "https://preview.redd.it/afg46q8pncfa1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b11400a12393d67551dbfb1c2afde422d1faad95"}, {"y": 189, "x": 216, "u": "https://preview.redd.it/afg46q8pncfa1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7212b9f51d5d68c4db4c9582c0dc9b7c5a5dd9d1"}, {"y": 281, "x": 320, "u": "https://preview.redd.it/afg46q8pncfa1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8da9a58d6bcff85eb7038a6fc9705e9a13007807"}, {"y": 562, "x": 640, "u": "https://preview.redd.it/afg46q8pncfa1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9f43f49dcc2002aa246f9bd939b653c94ce96225"}], "s": {"y": 631, "x": 718, "u": "https://preview.redd.it/afg46q8pncfa1.png?width=718&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=fcaaec1219a9d725c1baa6cf6ff3db1c7dd8423b"}, "id": "afg46q8pncfa1"}}, "name": "t3_10puzjt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XXXj7AhFbzIb6u2z6sbL4WgAmrthuGMRjAbxy6yS0OM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675158380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The raise in popularity of ChatGPT/GPT3 and LLMs in general got me wondering.&lt;br/&gt;\nDid these tools make it into the hands of the data community already?&lt;br/&gt;\nAre you using such a tool for your daily work?&lt;/p&gt;\n\n&lt;p&gt;Please share your stories on the topic.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Added an example from ChatGPT usage:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/afg46q8pncfa1.png?width=718&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=fcaaec1219a9d725c1baa6cf6ff3db1c7dd8423b\"&gt;ChatGPT creates DDL from natural language request&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/10puzjt\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10puzjt", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded_Dog_614", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1675244780952, "options": [{"text": "I'm not sure how to implement it in my day-to-day work", "id": "21341009"}, {"text": "I use it all the time! ChatGPT FTW", "id": "21341010"}, {"text": "I use GitHub co-pilot in vscode", "id": "21341011"}, {"text": "I think this is over hyped buzz with no significant value", "id": "21341012"}, {"text": "I think it has a lot of potential but not intuitive to use", "id": "21341013"}, {"text": "I just want to see the results", "id": "21341014"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 156, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10puzjt/usage_of_generative_ai_for_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/10puzjt/usage_of_generative_ai_for_sql/", "subreddit_subscribers": 88091, "created_utc": 1675158380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From HackerNews: Heroku deleted my database with no warning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qadtn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1675198937.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "news.ycombinator.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://news.ycombinator.com/item?id=34598563", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qadtn", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qadtn/from_hackernews_heroku_deleted_my_database_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://news.ycombinator.com/item?id=34598563", "subreddit_subscribers": 88091, "created_utc": 1675198937.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, wanted to ask the group what are the most common \"data engineering\" tools used today. i have a background on informatica ETL, back 20 years ago, and today work a lot with customers that use azure data factory, but i'm curious to know what are the most common tools used today (as in 2023).", "author_fullname": "t2_imia197u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most common data engineering tools used today?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qgu0f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675215159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, wanted to ask the group what are the most common &amp;quot;data engineering&amp;quot; tools used today. i have a background on informatica ETL, back 20 years ago, and today work a lot with customers that use azure data factory, but i&amp;#39;m curious to know what are the most common tools used today (as in 2023).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qgu0f", "is_robot_indexable": true, "report_reasons": null, "author": "Pty_Rick", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qgu0f/most_common_data_engineering_tools_used_today/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qgu0f/most_common_data_engineering_tools_used_today/", "subreddit_subscribers": 88091, "created_utc": 1675215159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The US Army is changing the title of a 26B (a Military Occupational Specialty) from information system engineers to data engineers. As part of the first wave of \u201cdata engineers\u201d, how can I be a better asset for a DoD organization? I hold a lot of IT certifications (CISSP, CISM, CCNA etc etc) but nothing that really helps me in this role. I\u2019m picking up some technical skills on my own and starting to feel my way around how my organization ingests and interprets it\u2019s data but I\u2019m feeling a little lost at the moment. Anyone have any advice?", "author_fullname": "t2_81izlu1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering in the US Army", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q97ag", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675196166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The US Army is changing the title of a 26B (a Military Occupational Specialty) from information system engineers to data engineers. As part of the first wave of \u201cdata engineers\u201d, how can I be a better asset for a DoD organization? I hold a lot of IT certifications (CISSP, CISM, CCNA etc etc) but nothing that really helps me in this role. I\u2019m picking up some technical skills on my own and starting to feel my way around how my organization ingests and interprets it\u2019s data but I\u2019m feeling a little lost at the moment. Anyone have any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10q97ag", "is_robot_indexable": true, "report_reasons": null, "author": "Bane_of_Titan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q97ag/data_engineering_in_the_us_army/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q97ag/data_engineering_in_the_us_army/", "subreddit_subscribers": 88091, "created_utc": 1675196166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any particular patterns, native libraries or other?\n\n(We know data sciencists have pandas, numpy etc..)", "author_fullname": "t2_2pxsf0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which aspects of the python programming language help you be a better data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qa5zk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675198446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any particular patterns, native libraries or other?&lt;/p&gt;\n\n&lt;p&gt;(We know data sciencists have pandas, numpy etc..)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qa5zk", "is_robot_indexable": true, "report_reasons": null, "author": "blue_trains_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qa5zk/which_aspects_of_the_python_programming_language/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qa5zk/which_aspects_of_the_python_programming_language/", "subreddit_subscribers": 88091, "created_utc": 1675198446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious to hear about other experiences here.\n\nThe kind of DE I've done before was focused on cleaning, transforming and restructuring raw data loaded from a combination of a MySQL DB and a queue of events that were both loaded into Snowflake. All data cleaning and transformation etc. was done in Snowflake. Specifically, I defined javascript stored procedures that generated SQL statements dynamically (depending on input params) so all repeated logic was effectively encapsulated in a relatively small number of SPs. These SPs were called from an ETL tool which passed in the correct params and managed the execution flow etc.\n\nI'm currently doing DE Zoomcamp and it's been great so far learning about docker and python etc. But it got me thinking. In which scenarios does it make sense to do these data cleaning and transformation steps in python rather than SQL? I've never encountered anything I wanted to do but couldn't do with SQL. We were leveraging the compute of snowflake so complex operations even on huge datasets were relatively quick. Plus with all the data in snowflake, you can easily query it to have a look at it. What environment allows you to \"see\" the data so well if you are using python to manipulate data?\n\nIs the kind of DE where you download data from some external source then ingest it with a python script reserved for relatively small datasets? Or datasets loaded from sources where you don't have direct access to the DB?\n\nI feel I am missing some key part of the picture regarding \"why everyone uses python\", or the kinds of tools they are using that depend on python rather than SQL.", "author_fullname": "t2_5n8mvd7p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Different types of DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q9s2t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675197553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious to hear about other experiences here.&lt;/p&gt;\n\n&lt;p&gt;The kind of DE I&amp;#39;ve done before was focused on cleaning, transforming and restructuring raw data loaded from a combination of a MySQL DB and a queue of events that were both loaded into Snowflake. All data cleaning and transformation etc. was done in Snowflake. Specifically, I defined javascript stored procedures that generated SQL statements dynamically (depending on input params) so all repeated logic was effectively encapsulated in a relatively small number of SPs. These SPs were called from an ETL tool which passed in the correct params and managed the execution flow etc.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently doing DE Zoomcamp and it&amp;#39;s been great so far learning about docker and python etc. But it got me thinking. In which scenarios does it make sense to do these data cleaning and transformation steps in python rather than SQL? I&amp;#39;ve never encountered anything I wanted to do but couldn&amp;#39;t do with SQL. We were leveraging the compute of snowflake so complex operations even on huge datasets were relatively quick. Plus with all the data in snowflake, you can easily query it to have a look at it. What environment allows you to &amp;quot;see&amp;quot; the data so well if you are using python to manipulate data?&lt;/p&gt;\n\n&lt;p&gt;Is the kind of DE where you download data from some external source then ingest it with a python script reserved for relatively small datasets? Or datasets loaded from sources where you don&amp;#39;t have direct access to the DB?&lt;/p&gt;\n\n&lt;p&gt;I feel I am missing some key part of the picture regarding &amp;quot;why everyone uses python&amp;quot;, or the kinds of tools they are using that depend on python rather than SQL.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q9s2t", "is_robot_indexable": true, "report_reasons": null, "author": "kaiso_gunkan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q9s2t/different_types_of_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q9s2t/different_types_of_de/", "subreddit_subscribers": 88091, "created_utc": 1675197553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Happened to stumble upon this today\u2026 [https://www.fivetran.com/blog/fivetran-pricing](https://www.fivetran.com/blog/fivetran-pricing)\n\n*February 1, 2023 update: We\u2019re offering a Free Plan, replacing the Standard Select tier. On top of that, we lowered pay-as-you-go pricing by 11 percent.* [*Check out the announcement.*](https://www.fivetran.com/fivetran-free-plan)\n\nThe announcement link is currently a 404. Maybe it will be up tomorrow.", "author_fullname": "t2_8fr7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran launching a free tier", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qh91r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1675216314.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Happened to stumble upon this today\u2026 &lt;a href=\"https://www.fivetran.com/blog/fivetran-pricing\"&gt;https://www.fivetran.com/blog/fivetran-pricing&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;February 1, 2023 update: We\u2019re offering a Free Plan, replacing the Standard Select tier. On top of that, we lowered pay-as-you-go pricing by 11 percent.&lt;/em&gt; &lt;a href=\"https://www.fivetran.com/fivetran-free-plan\"&gt;&lt;em&gt;Check out the announcement.&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The announcement link is currently a 404. Maybe it will be up tomorrow.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?auto=webp&amp;v=enabled&amp;s=6f76ad332b9778f9e5c8b936f874ac86d6b803a5", "width": 2000, "height": 1001}, "resolutions": [{"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3856080cf62bd92071ebc9f672d05a051a8bcaf4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=506ff27238e7e3b069d4ce2480b79701a9683d76", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a1c7c5e73f51b9dd57bccd28f3504341244b39f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d33f1659cd8f7cfe30c21ed294c91b712389b68", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=388e9e8cd9d4f86495d58145de24d40764151151", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/B9XwF2PzIiw_ZW3rcoAXVLgUZ9hL8BA0u9-EUUjgBtk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0109a6302cd8c6284059bcf54a763c1db7ac347e", "width": 1080, "height": 540}], "variants": {}, "id": "PJzWrjCOMY508Zf959hjx2rzPDC0ORXbiulae7FDjho"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qh91r", "is_robot_indexable": true, "report_reasons": null, "author": "CEOnnor", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qh91r/fivetran_launching_a_free_tier/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qh91r/fivetran_launching_a_free_tier/", "subreddit_subscribers": 88091, "created_utc": 1675216314.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I'm currently enrolled a Master's in Software Engineering and have been very interested in DE since my undergrad and completed various projects and an internship within the space, and I definitely plan on pursuing more internships if possible. \n\nI've read a lot that getting a job as a DE right out of university with no professional experience is very difficult due to the nature of the job. From what I've read on this sub, people recommend going through a different role in Software Engineering and then transitioning into a DE role. \n\nIs this accurate? If so, what other role is the best suited for this transition? Backend development is something I've seen mentioned a lot.\n\nThanks!", "author_fullname": "t2_49e7c0kc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Entering DE as a grad with no experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qgc2m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675213835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I&amp;#39;m currently enrolled a Master&amp;#39;s in Software Engineering and have been very interested in DE since my undergrad and completed various projects and an internship within the space, and I definitely plan on pursuing more internships if possible. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read a lot that getting a job as a DE right out of university with no professional experience is very difficult due to the nature of the job. From what I&amp;#39;ve read on this sub, people recommend going through a different role in Software Engineering and then transitioning into a DE role. &lt;/p&gt;\n\n&lt;p&gt;Is this accurate? If so, what other role is the best suited for this transition? Backend development is something I&amp;#39;ve seen mentioned a lot.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10qgc2m", "is_robot_indexable": true, "report_reasons": null, "author": "infiniteAggression-", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qgc2m/entering_de_as_a_grad_with_no_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qgc2m/entering_de_as_a_grad_with_no_experience/", "subreddit_subscribers": 88091, "created_utc": 1675213835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to create a brand new data system for my company. I managed to create Python scripts that pulls data from APIs, wrangle them into a Pandas DataFrame, and export them into an Excel file. We are trying to do this process automatically daily on the cloud, store them in BigQuery, and display them in Data Studio.\n\nThis is the system that I have in mind. I put the scripts on Cloud Functions, but instead of export them into excel files, I use pandas\\_gbq to store them to BigQuery. For the cron jobs, I use Cloud Scheduler to trigger the scripts on the Cloud Functions by sending HTTP requests. What do you think of this system?", "author_fullname": "t2_2knag8t3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think about my data pipeline system?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qcb4w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675203530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to create a brand new data system for my company. I managed to create Python scripts that pulls data from APIs, wrangle them into a Pandas DataFrame, and export them into an Excel file. We are trying to do this process automatically daily on the cloud, store them in BigQuery, and display them in Data Studio.&lt;/p&gt;\n\n&lt;p&gt;This is the system that I have in mind. I put the scripts on Cloud Functions, but instead of export them into excel files, I use pandas_gbq to store them to BigQuery. For the cron jobs, I use Cloud Scheduler to trigger the scripts on the Cloud Functions by sending HTTP requests. What do you think of this system?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10qcb4w", "is_robot_indexable": true, "report_reasons": null, "author": "lordgriefter", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qcb4w/what_do_you_think_about_my_data_pipeline_system/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qcb4w/what_do_you_think_about_my_data_pipeline_system/", "subreddit_subscribers": 88091, "created_utc": 1675203530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone ever used Databricks with an on premise source control system? If so, can you provide what's steps you did for code development and CICD.", "author_fullname": "t2_4anjpw7w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks and On Premise Source Control", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q5xek", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675188361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone ever used Databricks with an on premise source control system? If so, can you provide what&amp;#39;s steps you did for code development and CICD.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q5xek", "is_robot_indexable": true, "report_reasons": null, "author": "B1WR2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q5xek/databricks_and_on_premise_source_control/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q5xek/databricks_and_on_premise_source_control/", "subreddit_subscribers": 88091, "created_utc": 1675188361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone here done the Databricks Data Engineer Associate cert? I've completed the Data Engineering with Databricks training on the partner academy, would that be sufficient? \n\nI'm trying to gage whether I've prepared enough.\n\nThanks in advance!", "author_fullname": "t2_jgs2foti", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Data Eng Associate Cert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q4055", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675183910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone here done the Databricks Data Engineer Associate cert? I&amp;#39;ve completed the Data Engineering with Databricks training on the partner academy, would that be sufficient? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to gage whether I&amp;#39;ve prepared enough.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10q4055", "is_robot_indexable": true, "report_reasons": null, "author": "aak55", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q4055/databricks_data_eng_associate_cert/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q4055/databricks_data_eng_associate_cert/", "subreddit_subscribers": 88091, "created_utc": 1675183910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I stumbled upon a usecase where reports were automated using RDF and triply. Data from there would get exported to powerbi.  Normally you see a datawarehouses for these kind of usecases.\n\nIs this linked data a viable option or is it just a niche?", "author_fullname": "t2_mv3d8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RDF/triply for building dataplatform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10q2ejq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675180122.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I stumbled upon a usecase where reports were automated using RDF and triply. Data from there would get exported to powerbi.  Normally you see a datawarehouses for these kind of usecases.&lt;/p&gt;\n\n&lt;p&gt;Is this linked data a viable option or is it just a niche?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "10q2ejq", "is_robot_indexable": true, "report_reasons": null, "author": "artopaper", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q2ejq/rdftriply_for_building_dataplatform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10q2ejq/rdftriply_for_building_dataplatform/", "subreddit_subscribers": 88091, "created_utc": 1675180122.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. \n\nSo a company I recently started at have previously attempted to implement a medallion architecture using Databricks and ADLS.\n\nIn the silver stage, data is being written out as Delta Lakes (only overwrite mode, never upserts) however a new directory is being created for each run, for example:\n\n    DatasetName\n    \u251c\u2500 Jan\n    \u2502  \u251c\u2500 15\n    \u2502  \u2502  \u251c\u2500 _delta_log\n    \u2502  \u2502  \u251c\u2500 part000...parquet\n    \u2502  \u251c\u2500 31\n    \u2502  \u2502  \u251c\u2500 _delta_log\n    \u2502  \u2502  \u251c\u2500 part000...parquet\n    \u251c\u2500 Feb\n    \n    etc...\n\nFrom my understanding, this completely misses the point of using delta to begin with? I think there should just be a single Delta Lake for a given dataset and this should just be overwritten every time like this:\n\n    DatasetName\n    \u251c\u2500 _delta_log\n    \u251c\u2500 part000...parquet\n    \u251c\u2500 part001...parquet\n    \u251c\u2500 part002...parquet\n    \n    etc...\n\nTheir argument is that these Delta Lakes will need to be kept for upwards of 10/20 years, and that they were told it would be more cost efficient to save out each version to a separate directory, rather than overwriting an existing Delta Lake and using time travel when required for audits etc. \n\nThis doesn't really make much sense to me as it over complicates the pipelines, and from my understanding of how the delta log works time travelling shouldn't really have much of a computational/cost overhead if they wanted to go back years when compared to loading data from different data/month/day directories?\n\nWould anybody be able to clarify which approach is correct here, and if so then why?\n\nThanks!", "author_fullname": "t2_152cpk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost of delta lake time travel", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10pw3na", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675162443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. &lt;/p&gt;\n\n&lt;p&gt;So a company I recently started at have previously attempted to implement a medallion architecture using Databricks and ADLS.&lt;/p&gt;\n\n&lt;p&gt;In the silver stage, data is being written out as Delta Lakes (only overwrite mode, never upserts) however a new directory is being created for each run, for example:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;DatasetName\n\u251c\u2500 Jan\n\u2502  \u251c\u2500 15\n\u2502  \u2502  \u251c\u2500 _delta_log\n\u2502  \u2502  \u251c\u2500 part000...parquet\n\u2502  \u251c\u2500 31\n\u2502  \u2502  \u251c\u2500 _delta_log\n\u2502  \u2502  \u251c\u2500 part000...parquet\n\u251c\u2500 Feb\n\netc...\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;From my understanding, this completely misses the point of using delta to begin with? I think there should just be a single Delta Lake for a given dataset and this should just be overwritten every time like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;DatasetName\n\u251c\u2500 _delta_log\n\u251c\u2500 part000...parquet\n\u251c\u2500 part001...parquet\n\u251c\u2500 part002...parquet\n\netc...\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Their argument is that these Delta Lakes will need to be kept for upwards of 10/20 years, and that they were told it would be more cost efficient to save out each version to a separate directory, rather than overwriting an existing Delta Lake and using time travel when required for audits etc. &lt;/p&gt;\n\n&lt;p&gt;This doesn&amp;#39;t really make much sense to me as it over complicates the pipelines, and from my understanding of how the delta log works time travelling shouldn&amp;#39;t really have much of a computational/cost overhead if they wanted to go back years when compared to loading data from different data/month/day directories?&lt;/p&gt;\n\n&lt;p&gt;Would anybody be able to clarify which approach is correct here, and if so then why?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10pw3na", "is_robot_indexable": true, "report_reasons": null, "author": "Battery_Powered_Box", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10pw3na/cost_of_delta_lake_time_travel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10pw3na/cost_of_delta_lake_time_travel/", "subreddit_subscribers": 88091, "created_utc": 1675162443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Background: I recently graduated with a Master's degree in bioinformatics and I'm looking to break in to the field of data engineering.  I'm based in the UK with a 2-year graduate visa and have intermediate skills in Python and R. I don't have any job experience, because I did my master's straight after my undergrad (biochemistry).\n\nAfter researching this subreddit, I have a clear idea of what skills to pick up and how to do it. However, I'm not sure which approach in terms of job hunting to take in order to make it more realistic.\n\nShould I:\n\n1. Focus on learning and simultaneously applying for junior DE positions until I land a role?\n2. Start by finding a data analyst or similar data-related job to gain experience?\n3. Target a specific role that will help me make the transition to data engineering more easily?\n\nI would appreciate your thoughts and suggestions. Thank you!", "author_fullname": "t2_v7lrnxcl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career path for a Bioinformatician", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qhf4n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675216797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Background: I recently graduated with a Master&amp;#39;s degree in bioinformatics and I&amp;#39;m looking to break in to the field of data engineering.  I&amp;#39;m based in the UK with a 2-year graduate visa and have intermediate skills in Python and R. I don&amp;#39;t have any job experience, because I did my master&amp;#39;s straight after my undergrad (biochemistry).&lt;/p&gt;\n\n&lt;p&gt;After researching this subreddit, I have a clear idea of what skills to pick up and how to do it. However, I&amp;#39;m not sure which approach in terms of job hunting to take in order to make it more realistic.&lt;/p&gt;\n\n&lt;p&gt;Should I:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Focus on learning and simultaneously applying for junior DE positions until I land a role?&lt;/li&gt;\n&lt;li&gt;Start by finding a data analyst or similar data-related job to gain experience?&lt;/li&gt;\n&lt;li&gt;Target a specific role that will help me make the transition to data engineering more easily?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I would appreciate your thoughts and suggestions. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "10qhf4n", "is_robot_indexable": true, "report_reasons": null, "author": "LivingOnTheMullet", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qhf4n/career_path_for_a_bioinformatician/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qhf4n/career_path_for_a_bioinformatician/", "subreddit_subscribers": 88091, "created_utc": 1675216797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am an experienced pyspark developer, never tried java before. I can write very efficient spark jobs using Python.   \nI want to get started in data streaming, but worried if learning java would be a language barrier.   \nIf someone can advise me  \n1) If I need to learn Java ?  \n2) Fastest way to catch up pace in streaming data engineering as a python based data engineer.   \n3) Any resources ?  \n\n\nThanks.", "author_fullname": "t2_8tke9kpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting into streaming data engineering as a Pyspark batch pipeline professional.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qdqof", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675207051.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am an experienced pyspark developer, never tried java before. I can write very efficient spark jobs using Python.&lt;br/&gt;\nI want to get started in data streaming, but worried if learning java would be a language barrier.&lt;br/&gt;\nIf someone can advise me&lt;br/&gt;\n1) If I need to learn Java ?&lt;br/&gt;\n2) Fastest way to catch up pace in streaming data engineering as a python based data engineer.&lt;br/&gt;\n3) Any resources ?  &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10qdqof", "is_robot_indexable": true, "report_reasons": null, "author": "International_Bed703", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qdqof/getting_into_streaming_data_engineering_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qdqof/getting_into_streaming_data_engineering_as_a/", "subreddit_subscribers": 88091, "created_utc": 1675207051.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, i am trying to build a data pipeline where data is extracted from an excel file (highly edited and used by other users) read using pandas dataframe converted into json and inserted whole row of excel as a json clob in the table. The table json values are then called and merge procedure puts data into the required tables with respective columns and that final table is used in our application for our metric. The issue is excel file is constantly changing weekly and metrics in app is being affected.\n\nAny idea how to solve this?\n\nOr any standard process is there for using excel file data into oracle data table for app UI?", "author_fullname": "t2_5svl00at", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need solution ideas - excel to oracle table for viewing in app. Help!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_10qdo8o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1675206883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, i am trying to build a data pipeline where data is extracted from an excel file (highly edited and used by other users) read using pandas dataframe converted into json and inserted whole row of excel as a json clob in the table. The table json values are then called and merge procedure puts data into the required tables with respective columns and that final table is used in our application for our metric. The issue is excel file is constantly changing weekly and metrics in app is being affected.&lt;/p&gt;\n\n&lt;p&gt;Any idea how to solve this?&lt;/p&gt;\n\n&lt;p&gt;Or any standard process is there for using excel file data into oracle data table for app UI?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "10qdo8o", "is_robot_indexable": true, "report_reasons": null, "author": "Few_War_6750", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10qdo8o/need_solution_ideas_excel_to_oracle_table_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/10qdo8o/need_solution_ideas_excel_to_oracle_table_for/", "subreddit_subscribers": 88091, "created_utc": 1675206883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6khnrfh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyzing Real-Time Data in Python with AWS Kinesis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_10q7yfz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/dGkjbrBFrz7uvXLdTN6NRiNtkA0iWacQfulF5q9GJP8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1675193121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bytewax.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.bytewax.io/blog/kinesis-bytewax/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/60itRLMY6C709WtP5-KN37CrMlPJLvJMHQvLUZYTuAs.jpg?auto=webp&amp;v=enabled&amp;s=f162db27dca8c1ee15066ca23db1ad9de8f74ae2", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/60itRLMY6C709WtP5-KN37CrMlPJLvJMHQvLUZYTuAs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7700d416d581661433a6da5cea918405ecca774c", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/60itRLMY6C709WtP5-KN37CrMlPJLvJMHQvLUZYTuAs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=751c1d193db37e261420939058e51ff4a70933a9", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/60itRLMY6C709WtP5-KN37CrMlPJLvJMHQvLUZYTuAs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5b7edeafb0a77b60498f5935f85e1421093b2a6a", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/60itRLMY6C709WtP5-KN37CrMlPJLvJMHQvLUZYTuAs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bff4bbd03285dfcb739f55bd8cf07cc8f30b7634", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/60itRLMY6C709WtP5-KN37CrMlPJLvJMHQvLUZYTuAs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da219a2d30041b1d7f9b8ec7a4471ea3db362a1b", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/60itRLMY6C709WtP5-KN37CrMlPJLvJMHQvLUZYTuAs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4fc8e8ac1fb0259420a1002a89bf91db8b36dbe5", "width": 1080, "height": 564}], "variants": {}, "id": "-x4aiShWiW2Yyi0cM-CnY_WpqvbLyc39VruR_6SQb0E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "10q7yfz", "is_robot_indexable": true, "report_reasons": null, "author": "semicausal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/10q7yfz/analyzing_realtime_data_in_python_with_aws_kinesis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.bytewax.io/blog/kinesis-bytewax/", "subreddit_subscribers": 88091, "created_utc": 1675193121.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}