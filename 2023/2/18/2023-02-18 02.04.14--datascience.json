{"kind": "Listing", "data": {"after": "t3_114x7sb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_c1uwm29g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Europe data salary benchmark 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 44, "top_awarded_type": null, "hide_score": false, "name": "t3_114ews9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 277, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 277, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bZv_ul7ok4cVrY9x9EvIK097ZoF72IkI6sFB0oK5Ttw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676624353.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/40cum96grpia1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/40cum96grpia1.png?auto=webp&amp;v=enabled&amp;s=7f4af5d927ec17c3b4fccab2e216002bc88c8ab1", "width": 3672, "height": 1172}, "resolutions": [{"url": "https://preview.redd.it/40cum96grpia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6c1a685b4fe3faeddcec0f10b75fae22c62529d2", "width": 108, "height": 34}, {"url": "https://preview.redd.it/40cum96grpia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b412caf0ae89eb7bd5b71c838067aa1380608151", "width": 216, "height": 68}, {"url": "https://preview.redd.it/40cum96grpia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95ef07734f5602a380bd418a2ad87674ee30e854", "width": 320, "height": 102}, {"url": "https://preview.redd.it/40cum96grpia1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32de1738f71370883669bb103ba4dbef4f5121b5", "width": 640, "height": 204}, {"url": "https://preview.redd.it/40cum96grpia1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b85253f336336b1e901dab7870af2ff0daaf19f7", "width": 960, "height": 306}, {"url": "https://preview.redd.it/40cum96grpia1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5dd23cddc874cb42257af71c7b3872fd9f6dc790", "width": 1080, "height": 344}], "variants": {}, "id": "REH_IhQ75Ulp56ke_KHYLHm-RYVfdOOk5zHa4Kzvt9g"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "114ews9", "is_robot_indexable": true, "report_reasons": null, "author": "Different_Eggplant97", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114ews9/europe_data_salary_benchmark_2023/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/40cum96grpia1.png", "subreddit_subscribers": 848857, "created_utc": 1676624353.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey there , is there a site like [R for Data Science](https://r4ds.had.co.nz/index.html) but for Data Science with Python? For me it breaks down everything into smaller concepts and makes it easy to digest. Also provides examples and some exercises.", "author_fullname": "t2_11cw6lt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Site like r4ds but for Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114ge4u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676629275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there , is there a site like &lt;a href=\"https://r4ds.had.co.nz/index.html\"&gt;R for Data Science&lt;/a&gt; but for Data Science with Python? For me it breaks down everything into smaller concepts and makes it easy to digest. Also provides examples and some exercises.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dX3T8UC_GylpVlrUMrYvH-2nM0oxTSosN0Q-7yoOac4.jpg?auto=webp&amp;v=enabled&amp;s=be1d95ead684e21361d0c9018d708d051e4c065d", "width": 500, "height": 750}, "resolutions": [{"url": "https://external-preview.redd.it/dX3T8UC_GylpVlrUMrYvH-2nM0oxTSosN0Q-7yoOac4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=69ede938c8888fac58a866183918e001c3db4d7f", "width": 108, "height": 162}, {"url": "https://external-preview.redd.it/dX3T8UC_GylpVlrUMrYvH-2nM0oxTSosN0Q-7yoOac4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7db88d4db4887859d9f3ed8ecd76353719cdb46", "width": 216, "height": 324}, {"url": "https://external-preview.redd.it/dX3T8UC_GylpVlrUMrYvH-2nM0oxTSosN0Q-7yoOac4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19547aeab1720910512e4eed0cba4903f84ff464", "width": 320, "height": 480}], "variants": {}, "id": "N_ZYgQxGMscE67OV4DhF9HugRbJUyzPy6u5WBBYiWc8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114ge4u", "is_robot_indexable": true, "report_reasons": null, "author": "daskou_", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114ge4u/site_like_r4ds_but_for_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114ge4u/site_like_r4ds_but_for_python/", "subreddit_subscribers": 848857, "created_utc": 1676629275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for a reference that I can use to help me select the best model to train based on whatever dataset I'm working with.  Ideally something that shows any pre-processing requirements too.\n\nSomething like a decision tree flow chart.", "author_fullname": "t2_i0r4k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reference for guiding model selection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1146of8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676596151.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a reference that I can use to help me select the best model to train based on whatever dataset I&amp;#39;m working with.  Ideally something that shows any pre-processing requirements too.&lt;/p&gt;\n\n&lt;p&gt;Something like a decision tree flow chart.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1146of8", "is_robot_indexable": true, "report_reasons": null, "author": "guessishouldjoin", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1146of8/reference_for_guiding_model_selection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1146of8/reference_for_guiding_model_selection/", "subreddit_subscribers": 848857, "created_utc": 1676596151.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone!\n\nI am undergrad majoring in Political Science and minoring in Data Science. I am now working on my undergraduate thesis and have realized that, while scraping election data from the websites of different states, there is very little consistency. In a single state, URLs are formatted completely differently, the tables come out in many different forms after I scrape, and reformatting takes me quite a bit (\\~15 minutes for each site, but I have 100 of these to go through, making the data cleaning alone a 25 hour project).\n\nAre there any \"tricks\" to automating data cleaning/making a robust program that can accept many different data forms? Or is data cleaning always just a bit of a pain in the a\\*\\*?", "author_fullname": "t2_hzows1av", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "General Question on Scraping Websites and Data Cleaning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114scf7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676654671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;\n\n&lt;p&gt;I am undergrad majoring in Political Science and minoring in Data Science. I am now working on my undergraduate thesis and have realized that, while scraping election data from the websites of different states, there is very little consistency. In a single state, URLs are formatted completely differently, the tables come out in many different forms after I scrape, and reformatting takes me quite a bit (~15 minutes for each site, but I have 100 of these to go through, making the data cleaning alone a 25 hour project).&lt;/p&gt;\n\n&lt;p&gt;Are there any &amp;quot;tricks&amp;quot; to automating data cleaning/making a robust program that can accept many different data forms? Or is data cleaning always just a bit of a pain in the a**?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114scf7", "is_robot_indexable": true, "report_reasons": null, "author": "NotAPurpleDino", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114scf7/general_question_on_scraping_websites_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114scf7/general_question_on_scraping_websites_and_data/", "subreddit_subscribers": 848857, "created_utc": 1676654671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a problem which involves robots displaying error codes, then they will be taken and a certain fix will be done to them and I need to determine which fixes are the most effective and which are least. I have a variable that defines the performance before and after the fix but I was wondering what model would be best to highlight which fixes in the list have least and most effect. Thank you!!", "author_fullname": "t2_91ryy99k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Identifying significance of variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114f340", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676625085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a problem which involves robots displaying error codes, then they will be taken and a certain fix will be done to them and I need to determine which fixes are the most effective and which are least. I have a variable that defines the performance before and after the fix but I was wondering what model would be best to highlight which fixes in the list have least and most effect. Thank you!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114f340", "is_robot_indexable": true, "report_reasons": null, "author": "Engineeringstudent87", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114f340/identifying_significance_of_variables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114f340/identifying_significance_of_variables/", "subreddit_subscribers": 848857, "created_utc": 1676625085.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_vnwc3gdo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Virtual meet-up: Automated monitoring and anomaly detection to improve the user experience for consumer products!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_114ulbm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OJOQjtkdf9334OF5wvvfwTgVBQQdXikiCO6vXCQyIME.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676660326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/mcb5ysbeqsia1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/mcb5ysbeqsia1.png?auto=webp&amp;v=enabled&amp;s=08d31bbd56972449c872cbc683aed9be26c54c73", "width": 918, "height": 514}, "resolutions": [{"url": "https://preview.redd.it/mcb5ysbeqsia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7c459e5c7383f0ceafc8294f2ed7278946717117", "width": 108, "height": 60}, {"url": "https://preview.redd.it/mcb5ysbeqsia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c123d32f6a852bd208fdcdeb59c90afada2953c8", "width": 216, "height": 120}, {"url": "https://preview.redd.it/mcb5ysbeqsia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42ddbaf98309f3a95f26b74b47a59a3738d06792", "width": 320, "height": 179}, {"url": "https://preview.redd.it/mcb5ysbeqsia1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c28569a7140dca4e4d5b7de67641a228994bf022", "width": 640, "height": 358}], "variants": {}, "id": "OeOjMWcLf9Mk7YtlMAyp_qAsuta7T0m86h39flU7V0E"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "114ulbm", "is_robot_indexable": true, "report_reasons": null, "author": "Madhumita2023", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114ulbm/virtual_meetup_automated_monitoring_and_anomaly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/mcb5ysbeqsia1.png", "subreddit_subscribers": 848857, "created_utc": 1676660326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For people here from the UK, is it good over there? I'm considering moving to the UK (with an HPI visa). Of course I love the place, but I have a young family as dependents (wife and a kid), so I need to be sure it's the right move financially too. So, I'm looking for honest opinions from data scientists in the UK if the move is going to be worth it. Is it easy to get jobs? Are most jobs ok with a hybrid arrangement? Are employers usually willing to sponsor work visa to foreign nationals? Anything else you think I should know?", "author_fullname": "t2_79v29l8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How's the data science job market in the UK?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114tros", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676664518.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676658237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For people here from the UK, is it good over there? I&amp;#39;m considering moving to the UK (with an HPI visa). Of course I love the place, but I have a young family as dependents (wife and a kid), so I need to be sure it&amp;#39;s the right move financially too. So, I&amp;#39;m looking for honest opinions from data scientists in the UK if the move is going to be worth it. Is it easy to get jobs? Are most jobs ok with a hybrid arrangement? Are employers usually willing to sponsor work visa to foreign nationals? Anything else you think I should know?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114tros", "is_robot_indexable": true, "report_reasons": null, "author": "ResearcherNo4728", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114tros/hows_the_data_science_job_market_in_the_uk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114tros/hows_the_data_science_job_market_in_the_uk/", "subreddit_subscribers": 848857, "created_utc": 1676658237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a 26 year old Social Sciences grad considering a return to academia and I'm very interested in applying ML methods as part of a PhD research proposal at the intersection of Political Science / Public Policy and Development Studies.\n\nMore specifically I'd like to assess the value provided by ML methods as part of a mixed methods approach to research with the aid of one or several case studies, with significant attention paid to methodological and epistemological concerns, engaging with the work of forerunners in the field such as Lakoff, Zadeh, Sartori and David Collier. As such, applying ML methods would be a significant portion of my research, but definitely a minority. Specific algorithms of interest would be determined by the case studies in question and what I'm capable of competently applying, but would likely centre around regression/classification and text analysis.\n\nOnce upon a time I had basic but fairly solid statistical skills along with more rudimentary technical skills in SQL, R and to a lesser extent Python, but these have unfortunately atrophied to the point of non existence after 3-4 years in a non-technical Data Science adjacent role. I therefore have a pretty steep hill to climb in terms of foundational skills before I could even submit my research proposal. I'm currently brushing up on algebra, calculus and statistical skills before pushing in to the unknown, most likely via the MITx Micromasters in Data, Development and Economics and/or in Data Science. However the sheer scope and complexity of the content I need to cover combined with working a full time job and the fact that a PhD position is by no means guaranteed at the end of it (I'm provisionally interested in Oxford or LSE) is pretty disheartening. As a result I'm interested in exploring low code / no code options such as KNIME and DataIku (I'd also welcome alternative suggestions) for data prep and model build to reduce the barrier to entry. I'd really value any input on whether these would be fit for purpose, specifically:\n\n1. Will the choice of algorithms available fit my needs?\n2. How low code are they exactly? In practice will I need to plug in significant amounts of my own code?\n3. Do they provide sufficient guidance or hand holding to build models of sufficient quality for a top tier PhD program (keeping in mind that building the ML models would only be a relatively small portion of my research - I certainly wouldn't expect this to be the case if it was a purely quantitative thesis). To take some basic examples, would they flag if my variables were collinear, heteroskedastic etc\n\nThanks for reading, I'd really value any input! Happy to provide some more details on my (somewhat vague) research proposal if that'd be helpful or of any interest.", "author_fullname": "t2_abf5eaxo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feasibility of using no code / low code platforms such as KNIME and DataIku for social science research", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114sprj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676655603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a 26 year old Social Sciences grad considering a return to academia and I&amp;#39;m very interested in applying ML methods as part of a PhD research proposal at the intersection of Political Science / Public Policy and Development Studies.&lt;/p&gt;\n\n&lt;p&gt;More specifically I&amp;#39;d like to assess the value provided by ML methods as part of a mixed methods approach to research with the aid of one or several case studies, with significant attention paid to methodological and epistemological concerns, engaging with the work of forerunners in the field such as Lakoff, Zadeh, Sartori and David Collier. As such, applying ML methods would be a significant portion of my research, but definitely a minority. Specific algorithms of interest would be determined by the case studies in question and what I&amp;#39;m capable of competently applying, but would likely centre around regression/classification and text analysis.&lt;/p&gt;\n\n&lt;p&gt;Once upon a time I had basic but fairly solid statistical skills along with more rudimentary technical skills in SQL, R and to a lesser extent Python, but these have unfortunately atrophied to the point of non existence after 3-4 years in a non-technical Data Science adjacent role. I therefore have a pretty steep hill to climb in terms of foundational skills before I could even submit my research proposal. I&amp;#39;m currently brushing up on algebra, calculus and statistical skills before pushing in to the unknown, most likely via the MITx Micromasters in Data, Development and Economics and/or in Data Science. However the sheer scope and complexity of the content I need to cover combined with working a full time job and the fact that a PhD position is by no means guaranteed at the end of it (I&amp;#39;m provisionally interested in Oxford or LSE) is pretty disheartening. As a result I&amp;#39;m interested in exploring low code / no code options such as KNIME and DataIku (I&amp;#39;d also welcome alternative suggestions) for data prep and model build to reduce the barrier to entry. I&amp;#39;d really value any input on whether these would be fit for purpose, specifically:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Will the choice of algorithms available fit my needs?&lt;/li&gt;\n&lt;li&gt;How low code are they exactly? In practice will I need to plug in significant amounts of my own code?&lt;/li&gt;\n&lt;li&gt;Do they provide sufficient guidance or hand holding to build models of sufficient quality for a top tier PhD program (keeping in mind that building the ML models would only be a relatively small portion of my research - I certainly wouldn&amp;#39;t expect this to be the case if it was a purely quantitative thesis). To take some basic examples, would they flag if my variables were collinear, heteroskedastic etc&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks for reading, I&amp;#39;d really value any input! Happy to provide some more details on my (somewhat vague) research proposal if that&amp;#39;d be helpful or of any interest.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114sprj", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Translator_7017", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114sprj/feasibility_of_using_no_code_low_code_platforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114sprj/feasibility_of_using_no_code_low_code_platforms/", "subreddit_subscribers": 848857, "created_utc": 1676655603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was trying to get any insight or examples from industry or even academia on ways to incorporate the traditional DS approach or statistical modeling into the A/B experiment process. At my company, we do some A/B tests where we may test one machine learning algorithm vs another algorithm to see which one performs better on our platform in terms of key metrics. But those models are already built by ML engineers and we are just testing which one performs better. \n\nInstead, what I'm interested is ways to use ML or modeling or help aid in running better/more successful A/B tests or be more efficient in the testing process, etc. For example, in our historical experiments we've ran we have data attributes such as whether the test was successful, the opportunity size estimate for the test (pre-deployment), type of test, target audience used, etc. One example I could think of is using these inputs into a model to predict the probability of success for new experiments in the backlog. Or maybe to help generate a target consumer audience for an experiment. \n\nI'm wondering if anyone has any insights on anything like this or other ways to apply data science approach to aid your experimentation process.", "author_fullname": "t2_f7pv9pl4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using ML or data science approach to aid A/B testing process", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114b84z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676610234.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was trying to get any insight or examples from industry or even academia on ways to incorporate the traditional DS approach or statistical modeling into the A/B experiment process. At my company, we do some A/B tests where we may test one machine learning algorithm vs another algorithm to see which one performs better on our platform in terms of key metrics. But those models are already built by ML engineers and we are just testing which one performs better. &lt;/p&gt;\n\n&lt;p&gt;Instead, what I&amp;#39;m interested is ways to use ML or modeling or help aid in running better/more successful A/B tests or be more efficient in the testing process, etc. For example, in our historical experiments we&amp;#39;ve ran we have data attributes such as whether the test was successful, the opportunity size estimate for the test (pre-deployment), type of test, target audience used, etc. One example I could think of is using these inputs into a model to predict the probability of success for new experiments in the backlog. Or maybe to help generate a target consumer audience for an experiment. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if anyone has any insights on anything like this or other ways to apply data science approach to aid your experimentation process.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114b84z", "is_robot_indexable": true, "report_reasons": null, "author": "snowshow45", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114b84z/using_ml_or_data_science_approach_to_aid_ab/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114b84z/using_ml_or_data_science_approach_to_aid_ab/", "subreddit_subscribers": 848857, "created_utc": 1676610234.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've been the lone DS at my company\\~ a year now. We have a 200 person IT department but completely lack any in house data science besides myself.\n\nI spent a few years here as an analyst before becoming DS, so I have good relationships with the business areas, but I just don't know where to start. So far I've tackled some low hanging fruit but I have no clue how to establish an organization wide program, drive business involvement, establish culture, etc. \n\nAny advice or tips?", "author_fullname": "t2_cln96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for a Solo Data Scientist at a big co", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1148t81", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676602506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been the lone DS at my company~ a year now. We have a 200 person IT department but completely lack any in house data science besides myself.&lt;/p&gt;\n\n&lt;p&gt;I spent a few years here as an analyst before becoming DS, so I have good relationships with the business areas, but I just don&amp;#39;t know where to start. So far I&amp;#39;ve tackled some low hanging fruit but I have no clue how to establish an organization wide program, drive business involvement, establish culture, etc. &lt;/p&gt;\n\n&lt;p&gt;Any advice or tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1148t81", "is_robot_indexable": true, "report_reasons": null, "author": "IDontLikeUsernamez", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1148t81/advice_for_a_solo_data_scientist_at_a_big_co/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1148t81/advice_for_a_solo_data_scientist_at_a_big_co/", "subreddit_subscribers": 848857, "created_utc": 1676602506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_bxlrd6rn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are actuarial jobs easier to find than data science/analysis jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114xsue", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676668435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114xsue", "is_robot_indexable": true, "report_reasons": null, "author": "No_Blackberry_6741", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114xsue/are_actuarial_jobs_easier_to_find_than_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114xsue/are_actuarial_jobs_easier_to_find_than_data/", "subreddit_subscribers": 848857, "created_utc": 1676668435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, \n\nI wanna start learning progress of data science. Can you give me some aadvice", "author_fullname": "t2_cp67rb7x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1152v8y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676682107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;I wanna start learning progress of data science. Can you give me some aadvice&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1152v8y", "is_robot_indexable": true, "report_reasons": null, "author": "Zolardinjo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1152v8y/starter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1152v8y/starter/", "subreddit_subscribers": 848857, "created_utc": 1676682107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let's say I put in production a fraud detection model based on an initial dataset. Over time this model will introduce a bias because there are transaction getting rejected due to the model. If I retrain the model with the new data, then the model may 'forget' how to catch the old fraudulent transactions. \nHow do you call this model induced drift and how do you deal with it?", "author_fullname": "t2_kguah", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about drift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1151pp1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676678774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say I put in production a fraud detection model based on an initial dataset. Over time this model will introduce a bias because there are transaction getting rejected due to the model. If I retrain the model with the new data, then the model may &amp;#39;forget&amp;#39; how to catch the old fraudulent transactions. \nHow do you call this model induced drift and how do you deal with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1151pp1", "is_robot_indexable": true, "report_reasons": null, "author": "chocolate_dealer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1151pp1/question_about_drift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1151pp1/question_about_drift/", "subreddit_subscribers": 848857, "created_utc": 1676678774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello. In R I have data in a list composed of 198 vectors, each vector with 70.000 values. Each vector is a feature/variable. It's data I need to make searches on (the first vector is the time, like the unique key). What's the best way to organize the data, in a dataframe or transposing it to a list of 70000 lists each one with 198 values, or keeping it like this...?\nI'm trying to iterate on it as it is now but is very slow...", "author_fullname": "t2_dr6xhswp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big data in list of vectors or in dataframe (R)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114z2hc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676671686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. In R I have data in a list composed of 198 vectors, each vector with 70.000 values. Each vector is a feature/variable. It&amp;#39;s data I need to make searches on (the first vector is the time, like the unique key). What&amp;#39;s the best way to organize the data, in a dataframe or transposing it to a list of 70000 lists each one with 198 values, or keeping it like this...?\nI&amp;#39;m trying to iterate on it as it is now but is very slow...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114z2hc", "is_robot_indexable": true, "report_reasons": null, "author": "estrellaDeOriente", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114z2hc/big_data_in_list_of_vectors_or_in_dataframe_r/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114z2hc/big_data_in_list_of_vectors_or_in_dataframe_r/", "subreddit_subscribers": 848857, "created_utc": 1676671686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am starting a position as an implementation specialist next week and I was wondering how I could incorporate some tasks on data analytics to this job. \n\nSo a background of what I will be doing is that I will be helping new clients onboard to our company's SAaS products that is suitable on the client's business environment. Ultimately, I will be training them on our products but will implement the software based on their business needs. \n\nI have a background in project management and sales so even though the role seems to be a bit more technical, it's one skill I love to learn as I go through it. I can leverage my skills in project management and sales to get me up to speed on this new role. \n\nBut on the other hand, I would want to incorporate some data analytics task to my job since I've always wanted to go to a more technically-focused career. I know that data analytics will have tasks such as data analysis and dashboard reporting, data processing, and perhaps a little bit of statistics. \n\nI really don't have a formal training on it though I know that the tasks I did in my previous jobs on my own initiative entailed having data analytics tasks. \n\nBut what can you suggest what tools I use to be able to perform data analytics? Even basic excel will do as long as I get to understand the principles of data analytics and by then create a dashboard for my projects/accounts. I'm not sure yet if I will be touching SQL and other database tools but I just want to anticipate as early what I can do to incorporate it in my next role. \n\nThank you so much!", "author_fullname": "t2_vp41v7io", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to incorporate a data analytics task to a implementations specialist job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114yklz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676670412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am starting a position as an implementation specialist next week and I was wondering how I could incorporate some tasks on data analytics to this job. &lt;/p&gt;\n\n&lt;p&gt;So a background of what I will be doing is that I will be helping new clients onboard to our company&amp;#39;s SAaS products that is suitable on the client&amp;#39;s business environment. Ultimately, I will be training them on our products but will implement the software based on their business needs. &lt;/p&gt;\n\n&lt;p&gt;I have a background in project management and sales so even though the role seems to be a bit more technical, it&amp;#39;s one skill I love to learn as I go through it. I can leverage my skills in project management and sales to get me up to speed on this new role. &lt;/p&gt;\n\n&lt;p&gt;But on the other hand, I would want to incorporate some data analytics task to my job since I&amp;#39;ve always wanted to go to a more technically-focused career. I know that data analytics will have tasks such as data analysis and dashboard reporting, data processing, and perhaps a little bit of statistics. &lt;/p&gt;\n\n&lt;p&gt;I really don&amp;#39;t have a formal training on it though I know that the tasks I did in my previous jobs on my own initiative entailed having data analytics tasks. &lt;/p&gt;\n\n&lt;p&gt;But what can you suggest what tools I use to be able to perform data analytics? Even basic excel will do as long as I get to understand the principles of data analytics and by then create a dashboard for my projects/accounts. I&amp;#39;m not sure yet if I will be touching SQL and other database tools but I just want to anticipate as early what I can do to incorporate it in my next role. &lt;/p&gt;\n\n&lt;p&gt;Thank you so much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114yklz", "is_robot_indexable": true, "report_reasons": null, "author": "ferdie999", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114yklz/how_to_incorporate_a_data_analytics_task_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114yklz/how_to_incorporate_a_data_analytics_task_to_a/", "subreddit_subscribers": 848857, "created_utc": 1676670412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I   have a B.E in Computer Science and my main language was JAVA throughout the course. I have learned different languages since then but not in-depth as I have done for JAVA. I will be pivoting to Data Science or Machine learning(Doing both simultaneously). I am doing Courses from Coursera and going through books to learn important concepts of Statistics, Probability, etc. But I lack practical experience in main python programming. I can create the codes I want using google or reading the documentation, but I don't know the syntax in my head. Like I know they exist but I have to them up(For JAVA this is not a major issue).\n\nI  had only basic knowledge of python, but for my job, I created an Automation  Testing framework using SeleniumBase and python without any prior knowledge of the Subject. I could do this as I have experience building mobile applications and web development, going through the documentation and finding solutions on the Internet.\n\nNow the issue is I feel like it would be awkward to google search things during any interview that I will have since I don't know the basic syntax of python(Even though I can create most of the programs that will be requested of me). I know the basics but I struggle with the Lambda function, apply function, the advanced syntax of for loop etc. How do I get good at this? where can I get practice for high-level python without learning what variables or loops are from the beginning?", "author_fullname": "t2_k7ds1cx7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance regarding Python practice for Data Science or Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114nrkc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676646737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I   have a B.E in Computer Science and my main language was JAVA throughout the course. I have learned different languages since then but not in-depth as I have done for JAVA. I will be pivoting to Data Science or Machine learning(Doing both simultaneously). I am doing Courses from Coursera and going through books to learn important concepts of Statistics, Probability, etc. But I lack practical experience in main python programming. I can create the codes I want using google or reading the documentation, but I don&amp;#39;t know the syntax in my head. Like I know they exist but I have to them up(For JAVA this is not a major issue).&lt;/p&gt;\n\n&lt;p&gt;I  had only basic knowledge of python, but for my job, I created an Automation  Testing framework using SeleniumBase and python without any prior knowledge of the Subject. I could do this as I have experience building mobile applications and web development, going through the documentation and finding solutions on the Internet.&lt;/p&gt;\n\n&lt;p&gt;Now the issue is I feel like it would be awkward to google search things during any interview that I will have since I don&amp;#39;t know the basic syntax of python(Even though I can create most of the programs that will be requested of me). I know the basics but I struggle with the Lambda function, apply function, the advanced syntax of for loop etc. How do I get good at this? where can I get practice for high-level python without learning what variables or loops are from the beginning?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114nrkc", "is_robot_indexable": true, "report_reasons": null, "author": "Intelligent_Put8678", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114nrkc/guidance_regarding_python_practice_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114nrkc/guidance_regarding_python_practice_for_data/", "subreddit_subscribers": 848857, "created_utc": 1676646737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just kind of looking for advice more than anything. I\u2019ve been job hunting since September and made it to last round of a few interviews including Amazon, but haven\u2019t gotten any takers. And it seems the longer I\u2019m hunting the fewer interviews I get. At this point I\u2019ve been shotgunning everything on LinkedIn, but haven\u2019t gotten anything in 1.5 months.\n\nI have 2.5 years experience including a couple deployments under my belt with GCP. I have a Physics masters, but no academic ML work. \n\nI feel like I\u2019m on the cusp of finally cracking the interview process, but I need more interviews.\n\nI think my resume looks clean with an active personal project and my LinkedIn looks fine, but isn\u2019t as flashy as some of the ones I\u2019ve seen. \n\nShould I be looking for job differently, pursuing certifications, getting a formal DS Ms, upload more recent code on GitHub, write blogs, network at a meetup? Idk what to do anymore and this is starting to feel hopeless.\n\nAny advice is appreciated", "author_fullname": "t2_3jkqpk22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Losing hope and direction in trying to find a new position", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114gz2u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676630412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just kind of looking for advice more than anything. I\u2019ve been job hunting since September and made it to last round of a few interviews including Amazon, but haven\u2019t gotten any takers. And it seems the longer I\u2019m hunting the fewer interviews I get. At this point I\u2019ve been shotgunning everything on LinkedIn, but haven\u2019t gotten anything in 1.5 months.&lt;/p&gt;\n\n&lt;p&gt;I have 2.5 years experience including a couple deployments under my belt with GCP. I have a Physics masters, but no academic ML work. &lt;/p&gt;\n\n&lt;p&gt;I feel like I\u2019m on the cusp of finally cracking the interview process, but I need more interviews.&lt;/p&gt;\n\n&lt;p&gt;I think my resume looks clean with an active personal project and my LinkedIn looks fine, but isn\u2019t as flashy as some of the ones I\u2019ve seen. &lt;/p&gt;\n\n&lt;p&gt;Should I be looking for job differently, pursuing certifications, getting a formal DS Ms, upload more recent code on GitHub, write blogs, network at a meetup? Idk what to do anymore and this is starting to feel hopeless.&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114gz2u", "is_robot_indexable": true, "report_reasons": null, "author": "Wizzman17", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114gz2u/losing_hope_and_direction_in_trying_to_find_a_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114gz2u/losing_hope_and_direction_in_trying_to_find_a_new/", "subreddit_subscribers": 848857, "created_utc": 1676630412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I want to know if it's possible to work in a virtual environment while ssh'ed to google colab. I tried ssh'ing to google colab and did it but when I was going to code a .ipynb file I needed to select the kernel and when I tried selecting the one from my Conda Virtual Environment it did nothing. Wanted to know if it's possible or if I did something wrong. If you know some guide or video that teaches how to do this link it if possible, I already searched but found nothing. Thanks", "author_fullname": "t2_3zulpl6aq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can i work locally with a virtual environment while ssh'ed to google colab", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114d0v4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676616712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I want to know if it&amp;#39;s possible to work in a virtual environment while ssh&amp;#39;ed to google colab. I tried ssh&amp;#39;ing to google colab and did it but when I was going to code a .ipynb file I needed to select the kernel and when I tried selecting the one from my Conda Virtual Environment it did nothing. Wanted to know if it&amp;#39;s possible or if I did something wrong. If you know some guide or video that teaches how to do this link it if possible, I already searched but found nothing. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114d0v4", "is_robot_indexable": true, "report_reasons": null, "author": "SelectSpecialist9952", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114d0v4/can_i_work_locally_with_a_virtual_environment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114d0v4/can_i_work_locally_with_a_virtual_environment/", "subreddit_subscribers": 848857, "created_utc": 1676616712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Need help with detecting data drift in multivariate time series data for many customers. Suppose your dataset has x columns and you have separate datasets for n customers and you need to detect data drift in the fastest way possible without compromising on the quality of the detections. Please help", "author_fullname": "t2_bw0jpdhw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to detect data drift in multivariate time series data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114810c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676600140.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need help with detecting data drift in multivariate time series data for many customers. Suppose your dataset has x columns and you have separate datasets for n customers and you need to detect data drift in the fastest way possible without compromising on the quality of the detections. Please help&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114810c", "is_robot_indexable": true, "report_reasons": null, "author": "Few_Comfortable5782", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114810c/how_to_detect_data_drift_in_multivariate_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114810c/how_to_detect_data_drift_in_multivariate_time/", "subreddit_subscribers": 848857, "created_utc": 1676600140.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Made my first medium article analyzing my own chess games, tell me what you guys think! Any feedback is greatly appreciated!\n\n&amp;#x200B;\n\n[https://medium.com/@imadahmad97/chessalytics-analyzing-my-chess-games-to-better-understand-my-play-style-d08c75d7fc9b](https://medium.com/@imadahmad97/chessalytics-analyzing-my-chess-games-to-better-understand-my-play-style-d08c75d7fc9b)", "author_fullname": "t2_16k701ce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Chessalytics: Analyzing my chess games to better understand my play style", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1151xl4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676679403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Made my first medium article analyzing my own chess games, tell me what you guys think! Any feedback is greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@imadahmad97/chessalytics-analyzing-my-chess-games-to-better-understand-my-play-style-d08c75d7fc9b\"&gt;https://medium.com/@imadahmad97/chessalytics-analyzing-my-chess-games-to-better-understand-my-play-style-d08c75d7fc9b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cEIlJQdDjXRK7ZxD3L3TCpD8ttPh-gZ5jsweBjRFxUc.jpg?auto=webp&amp;v=enabled&amp;s=b75b331492c5a2c620db315fe62a416e63b287b2", "width": 1200, "height": 1213}, "resolutions": [{"url": "https://external-preview.redd.it/cEIlJQdDjXRK7ZxD3L3TCpD8ttPh-gZ5jsweBjRFxUc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e9583be9fc76de61fc497b96fb5a641c8838442", "width": 108, "height": 109}, {"url": "https://external-preview.redd.it/cEIlJQdDjXRK7ZxD3L3TCpD8ttPh-gZ5jsweBjRFxUc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7de974fa0f875f55068903c5c83d1d6deb4b4b5d", "width": 216, "height": 218}, {"url": "https://external-preview.redd.it/cEIlJQdDjXRK7ZxD3L3TCpD8ttPh-gZ5jsweBjRFxUc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb3c8c9f06f443064b8d06ef92a580280a2bf82c", "width": 320, "height": 323}, {"url": "https://external-preview.redd.it/cEIlJQdDjXRK7ZxD3L3TCpD8ttPh-gZ5jsweBjRFxUc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a147a0d0082acfea7f1e3fafe404733683192c6", "width": 640, "height": 646}, {"url": "https://external-preview.redd.it/cEIlJQdDjXRK7ZxD3L3TCpD8ttPh-gZ5jsweBjRFxUc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33e27287e34bdead7317e0ba380e57c28c1ce0c1", "width": 960, "height": 970}, {"url": "https://external-preview.redd.it/cEIlJQdDjXRK7ZxD3L3TCpD8ttPh-gZ5jsweBjRFxUc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0d7deebb28b47eb6740f4ae73b6a30312d7222e", "width": 1080, "height": 1091}], "variants": {}, "id": "p5wmloJcJs2-dVituJyijVHAlMk-CO6m25ZGyAWTJaE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1151xl4", "is_robot_indexable": true, "report_reasons": null, "author": "ENISAS", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1151xl4/chessalytics_analyzing_my_chess_games_to_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1151xl4/chessalytics_analyzing_my_chess_games_to_better/", "subreddit_subscribers": 848857, "created_utc": 1676679403.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there,\n\nI am a research data scientist, and excited to release a new feature engineering library, designed to help you streamline the process of machine learning even more than before. **Headjack is an open library which provides a ML features transformation based on self-supervised learning models**, similar to huggingface as a hub, but which currently focuses on exchanging features for tabular data models.\n\nCompared to textual data, tabular data are different in that each data set has different column length and attributes, this means that it cannot be typed consistently unlike the token embedded in NLP tasks. Therefore, Headjack is different from NLP\u2019s pre-trained model with single domain transformation, but by performing with two different domain transformations. **In other words, we can perform features transform between two domains without the same key value.** In addition, release the potential of data that is not typically used. For example, enhance the prediction of the Boston housing price task applied in the Titanic domain, or enhance the prediction of the customers churn task applied in the African traffic domain and so on.\n\n[Github](https://github.com/jimliu741523/headjackai-sdk)\n\n[Introduction](https://medium.com/p/385a90ff413c)  \n\n\n&amp;#x200B;\n\n[The IRIS dataset with California House Price Feature Transformation](https://preview.redd.it/kujhd1bkbpia1.png?width=2110&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=039faa54d7346e4172564bd129985d948a74b7ae)\n\n[The IRIS dataset with Titanic Feature Transformation](https://preview.redd.it/jwlebjrlbpia1.png?width=2102&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ec2aa0d06a70337c1fb01defc71d77956720582b)\n\n[The IRIS dataset with KPMG Customer Demorgraphy Feature Transformation](https://preview.redd.it/5tpe76nmbpia1.png?width=2052&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d2c7139259d43c8574da4a0ea1a65056dccad916)", "author_fullname": "t2_vxh860rw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Table Feature Transformation Library Release", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "media_metadata": {"kujhd1bkbpia1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/kujhd1bkbpia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=54fff06d6560edc02a5d7d487fa38c6fc24e7ad0"}, {"y": 95, "x": 216, "u": "https://preview.redd.it/kujhd1bkbpia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7da39761ee3e0efd30a02edc26f50a82cee53550"}, {"y": 141, "x": 320, "u": "https://preview.redd.it/kujhd1bkbpia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b93b75246c7947b982fd7fc93d12d8282b6ebeec"}, {"y": 282, "x": 640, "u": "https://preview.redd.it/kujhd1bkbpia1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=781463dbf701227cb625f35d0f3a7ccbc06620c8"}, {"y": 424, "x": 960, "u": "https://preview.redd.it/kujhd1bkbpia1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9e33ee79578e8476766e87d3582c0741b31be7c8"}, {"y": 477, "x": 1080, "u": "https://preview.redd.it/kujhd1bkbpia1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=714ecb44a39728a95375a3271ade6ab2269d3ee1"}], "s": {"y": 932, "x": 2110, "u": "https://preview.redd.it/kujhd1bkbpia1.png?width=2110&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=039faa54d7346e4172564bd129985d948a74b7ae"}, "id": "kujhd1bkbpia1"}, "jwlebjrlbpia1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 47, "x": 108, "u": "https://preview.redd.it/jwlebjrlbpia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a00d3cd5ff3402f0cfd671c44f83b170b83c1d76"}, {"y": 94, "x": 216, "u": "https://preview.redd.it/jwlebjrlbpia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1b86224b14c3fcc2e0d925f77b3eafbda4e116b9"}, {"y": 139, "x": 320, "u": "https://preview.redd.it/jwlebjrlbpia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=37c81b8a0c0a34a76622151ac2e50e1b7bf3b148"}, {"y": 278, "x": 640, "u": "https://preview.redd.it/jwlebjrlbpia1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e126c79eeb644406a00b0ac8f8ee836bbca22589"}, {"y": 418, "x": 960, "u": "https://preview.redd.it/jwlebjrlbpia1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=731314c653c62f5fabb15e81403339286b4388f8"}, {"y": 470, "x": 1080, "u": "https://preview.redd.it/jwlebjrlbpia1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96e90136efff88acb381cd99702b4cc5ed19c8c4"}], "s": {"y": 916, "x": 2102, "u": "https://preview.redd.it/jwlebjrlbpia1.png?width=2102&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ec2aa0d06a70337c1fb01defc71d77956720582b"}, "id": "jwlebjrlbpia1"}, "5tpe76nmbpia1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 49, "x": 108, "u": "https://preview.redd.it/5tpe76nmbpia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13da76a7e38f727f2861e3c7453703d913111b1b"}, {"y": 98, "x": 216, "u": "https://preview.redd.it/5tpe76nmbpia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2deec0c74bd2dcb73a44a8a2a7c5f24c98e7319"}, {"y": 145, "x": 320, "u": "https://preview.redd.it/5tpe76nmbpia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c572ac41b26e961785040449c5805f93a5346219"}, {"y": 290, "x": 640, "u": "https://preview.redd.it/5tpe76nmbpia1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=70bffe41aa65fa8e5cce8f15b50e90ac649f9734"}, {"y": 436, "x": 960, "u": "https://preview.redd.it/5tpe76nmbpia1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=816fdf0a46b85d8b03f62e053958875bbc85dbd2"}, {"y": 490, "x": 1080, "u": "https://preview.redd.it/5tpe76nmbpia1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=50cfc8369a4c22a6840b86225d5cdfa0e2b488f3"}], "s": {"y": 932, "x": 2052, "u": "https://preview.redd.it/5tpe76nmbpia1.png?width=2052&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d2c7139259d43c8574da4a0ea1a65056dccad916"}, "id": "5tpe76nmbpia1"}}, "name": "t3_114dmwc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/d5y1QM1_kWc_Bn1qPi_L8f7DvtqV7PdaadZYREHvSeE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676619058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there,&lt;/p&gt;\n\n&lt;p&gt;I am a research data scientist, and excited to release a new feature engineering library, designed to help you streamline the process of machine learning even more than before. &lt;strong&gt;Headjack is an open library which provides a ML features transformation based on self-supervised learning models&lt;/strong&gt;, similar to huggingface as a hub, but which currently focuses on exchanging features for tabular data models.&lt;/p&gt;\n\n&lt;p&gt;Compared to textual data, tabular data are different in that each data set has different column length and attributes, this means that it cannot be typed consistently unlike the token embedded in NLP tasks. Therefore, Headjack is different from NLP\u2019s pre-trained model with single domain transformation, but by performing with two different domain transformations. &lt;strong&gt;In other words, we can perform features transform between two domains without the same key value.&lt;/strong&gt; In addition, release the potential of data that is not typically used. For example, enhance the prediction of the Boston housing price task applied in the Titanic domain, or enhance the prediction of the customers churn task applied in the African traffic domain and so on.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/jimliu741523/headjackai-sdk\"&gt;Github&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/p/385a90ff413c\"&gt;Introduction&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/kujhd1bkbpia1.png?width=2110&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=039faa54d7346e4172564bd129985d948a74b7ae\"&gt;The IRIS dataset with California House Price Feature Transformation&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/jwlebjrlbpia1.png?width=2102&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=ec2aa0d06a70337c1fb01defc71d77956720582b\"&gt;The IRIS dataset with Titanic Feature Transformation&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/5tpe76nmbpia1.png?width=2052&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=d2c7139259d43c8574da4a0ea1a65056dccad916\"&gt;The IRIS dataset with KPMG Customer Demorgraphy Feature Transformation&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114dmwc", "is_robot_indexable": true, "report_reasons": null, "author": "jimliu741523", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114dmwc/the_table_feature_transformation_library_release/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114dmwc/the_table_feature_transformation_library_release/", "subreddit_subscribers": 848857, "created_utc": 1676619058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[Spotify](https://open.spotify.com/playlist/6BoTD9WeyBN5rD5uyhbROO) | [Apple](https://music.apple.com/playlist/synthwave-focus-i/pl.u-b3b8Nm9C5MmMyM) | [Youtube](https://youtube.com/playlist?list=PLwO9YUACGAzS_XaTchS3qLgK5EGsb3qwa) | [Amazon](https://music.amazon.com/user-playlists/0375bdbe2f3d41f39523ddb35fc92ca0b1r)", "author_fullname": "t2_uf0zp4ob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Here\u2019s a playlist of 7 hours of music with NO VOCALS I use to focus when I\u2019m coding /learning . Post yours as well if you also have one!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114wkzt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1676665366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://open.spotify.com/playlist/6BoTD9WeyBN5rD5uyhbROO\"&gt;Spotify&lt;/a&gt; | &lt;a href=\"https://music.apple.com/playlist/synthwave-focus-i/pl.u-b3b8Nm9C5MmMyM\"&gt;Apple&lt;/a&gt; | &lt;a href=\"https://youtube.com/playlist?list=PLwO9YUACGAzS_XaTchS3qLgK5EGsb3qwa\"&gt;Youtube&lt;/a&gt; | &lt;a href=\"https://music.amazon.com/user-playlists/0375bdbe2f3d41f39523ddb35fc92ca0b1r\"&gt;Amazon&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/FvUbhMmhdhYln-CrJb5YhDkvlXy7pLqRx9FqeTZeCt0.jpg?auto=webp&amp;v=enabled&amp;s=6586578886a42fc8deb61dececd48e73e4c2e63f", "width": 300, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/FvUbhMmhdhYln-CrJb5YhDkvlXy7pLqRx9FqeTZeCt0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6222673fa21bc5240176f6b575abbdd808456c7", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/FvUbhMmhdhYln-CrJb5YhDkvlXy7pLqRx9FqeTZeCt0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=61bc8d25792b39098c537b1c8842477638607c63", "width": 216, "height": 216}], "variants": {}, "id": "l82v_GO2_4f-BOSs1nenERac7KtkIYbX6QHV36mgjM0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114wkzt", "is_robot_indexable": true, "report_reasons": null, "author": "letsstartanew2", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114wkzt/heres_a_playlist_of_7_hours_of_music_with_no/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114wkzt/heres_a_playlist_of_7_hours_of_music_with_no/", "subreddit_subscribers": 848857, "created_utc": 1676665366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Lately on this sub there have been many \u201csky is falling\u201d posts related to ChatGPT. Most of the posts have drastically overestimated ChatGPT\u2019s current use cases in the industry. What is a capability that if ChatGPT could do it, you would actually worry about the future of the data science field? More specifically worried about mass job loss within the field, if you foresee that.", "author_fullname": "t2_9mqjhcrl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is something ChatGPT (or any LLM) could do, that it can\u2019t currently, that would actually worry you about the future of data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114zcik", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.37, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676672396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lately on this sub there have been many \u201csky is falling\u201d posts related to ChatGPT. Most of the posts have drastically overestimated ChatGPT\u2019s current use cases in the industry. What is a capability that if ChatGPT could do it, you would actually worry about the future of the data science field? More specifically worried about mass job loss within the field, if you foresee that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114zcik", "is_robot_indexable": true, "report_reasons": null, "author": "cjrook", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114zcik/what_is_something_chatgpt_or_any_llm_could_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114zcik/what_is_something_chatgpt_or_any_llm_could_do/", "subreddit_subscribers": 848857, "created_utc": 1676672396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_uzoqx6k0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the three main challenges in machine learning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114v4bg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676661671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114v4bg", "is_robot_indexable": true, "report_reasons": null, "author": "Haritha37", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114v4bg/what_are_the_three_main_challenges_in_machine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114v4bg/what_are_the_three_main_challenges_in_machine/", "subreddit_subscribers": 848857, "created_utc": 1676661671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, my name is Toni and I\u2019m coming from Croatia.\n\nI have a master's degree in Business with specialization in informatics and I am a part-time lecturer at Uni of Business. I have been into trading (forex, stocks, crypto) for many years and I have found a very promising strategy based on Bill Williams\u2019 indicators and I improved it together with my team. The strategy is based on fractal geometry.\n\nI found a team of developers (5 of us, from Europe) 2 years ago and we built a very robust infrastructure in Python (Binance) and MQL4 for MetaTrader platform (forex, index, metals, stocks). We have a backtester that provides us with many detailed statistics. Our backtests are good and I can provide you with samples; however, we are looking for a Statistician or Data Scientist to join our team to help us to interpret the data and do magic with numbers.\n\nThis is not a paid job, but we all share the source code as our reward and you can use it for your own purpose. I am also here to learn about data science and statistics and we are willing to discuss anything regarding trading (any stock tickers or forex, etc.), about trading bots. Feel free to ask anything!", "author_fullname": "t2_yz5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a new team member - strong in statistics - we have already created a Trading Bot for multiple markets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114x7sb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676666974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, my name is Toni and I\u2019m coming from Croatia.&lt;/p&gt;\n\n&lt;p&gt;I have a master&amp;#39;s degree in Business with specialization in informatics and I am a part-time lecturer at Uni of Business. I have been into trading (forex, stocks, crypto) for many years and I have found a very promising strategy based on Bill Williams\u2019 indicators and I improved it together with my team. The strategy is based on fractal geometry.&lt;/p&gt;\n\n&lt;p&gt;I found a team of developers (5 of us, from Europe) 2 years ago and we built a very robust infrastructure in Python (Binance) and MQL4 for MetaTrader platform (forex, index, metals, stocks). We have a backtester that provides us with many detailed statistics. Our backtests are good and I can provide you with samples; however, we are looking for a Statistician or Data Scientist to join our team to help us to interpret the data and do magic with numbers.&lt;/p&gt;\n\n&lt;p&gt;This is not a paid job, but we all share the source code as our reward and you can use it for your own purpose. I am also here to learn about data science and statistics and we are willing to discuss anything regarding trading (any stock tickers or forex, etc.), about trading bots. Feel free to ask anything!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "114x7sb", "is_robot_indexable": true, "report_reasons": null, "author": "evilbunny", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/114x7sb/looking_for_a_new_team_member_strong_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/114x7sb/looking_for_a_new_team_member_strong_in/", "subreddit_subscribers": 848857, "created_utc": 1676666974.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}