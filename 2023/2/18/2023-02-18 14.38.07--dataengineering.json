{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8ke8s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake pushing snowpark really hard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_114vyvz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 175, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 175, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KJiD1dNn3al9rBoJFfOiNxKBzzQF375BgpmUiQZDT8o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676663827.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/enkguffr0tia1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/enkguffr0tia1.png?auto=webp&amp;v=enabled&amp;s=c9233f4999592c3218705beff92f0ee41c8cece3", "width": 481, "height": 501}, "resolutions": [{"url": "https://preview.redd.it/enkguffr0tia1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3aba0ae4ee8abbdf3a348f3b8b58f8f08fb8f7f6", "width": 108, "height": 112}, {"url": "https://preview.redd.it/enkguffr0tia1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b408c87016ce8e959f03f57350bb7d917442b5f4", "width": 216, "height": 224}, {"url": "https://preview.redd.it/enkguffr0tia1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bbcadedcd28186ce2776ab30f4047152d3c12c9", "width": 320, "height": 333}], "variants": {}, "id": "V-Br5pUBSerbH8K5v10Yo1-zwOGDGTnfBcPhYCI0o9w"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "114vyvz", "is_robot_indexable": true, "report_reasons": null, "author": "letmebefrankwithyou", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114vyvz/snowflake_pushing_snowpark_really_hard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/enkguffr0tia1.png", "subreddit_subscribers": 90007, "created_utc": 1676663827.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just wanted to get some quick thoughts on this. I have a pretty good resume academically speaking, and I just passed my DP203 cert, but I don't really have any projects built, or any relevant work experience. I know portfolios are regarded as very important for front-end roles, but was wondering if it was the same for DE roles too. Would I be wasting my time applying without first building a decent portfolio? Any advice/thoughts would be great.", "author_fullname": "t2_7c6o6rew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important are portfolios when applying for Junior/Entry Data-engineering roles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114qlzh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676650785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just wanted to get some quick thoughts on this. I have a pretty good resume academically speaking, and I just passed my DP203 cert, but I don&amp;#39;t really have any projects built, or any relevant work experience. I know portfolios are regarded as very important for front-end roles, but was wondering if it was the same for DE roles too. Would I be wasting my time applying without first building a decent portfolio? Any advice/thoughts would be great.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "114qlzh", "is_robot_indexable": true, "report_reasons": null, "author": "Ahab1996", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114qlzh/how_important_are_portfolios_when_applying_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114qlzh/how_important_are_portfolios_when_applying_for/", "subreddit_subscribers": 90007, "created_utc": 1676650785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Posting this under an anonymous name but I want to get people\u2019s feedback and advice. \n\nI started at my current role a little under 2 years ago and was a junior data engineer who didn\u2019t know much. I had previously been an analyst who loved working with data. I learned a lot of best practices from here, slack, communities, videos, blog posts, etc\u2026 I was able to implement them at my current company. \n\nSome of these include basic things from delta jobs to building out our whole CICD pipelines, IaC, providing a way to manage our work, optimizing things to save the company money, teaching everyone git, getting compliance to approve of our processes. \nPreviously anyone could move things to production without a review process, people were running full loads off our source databases for jobs that run every 20 mins, data types were never considered or thought about. \n\nAnd the company was good to me and promoted me within a year and gave me a raise which I appreciate. \n\nNow though I am at an impasse because I want to keep growing my technical skills and I know I have so much more to learn. For example we only use SQL and our senior level people didn\u2019t know how to utilize CTEs. I am contemplating starting to look for new roles where the practices listed above are standard and they are utilizing more advanced techniques and I can learn from more senior people. \n\nIn addition the person who\u2019s role I semi took over has been treating me pretty poorly. The company in general is lacking a lot of technical resources. \n\nI have some projects I have started that I want to finish but I think I should start looking for new roles. Has anyone been in a similar spot? I don\u2019t want to job hop too much.", "author_fullname": "t2_uww96dnc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Decision - What to do after outgrowing a team?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_115119h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676676893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Posting this under an anonymous name but I want to get people\u2019s feedback and advice. &lt;/p&gt;\n\n&lt;p&gt;I started at my current role a little under 2 years ago and was a junior data engineer who didn\u2019t know much. I had previously been an analyst who loved working with data. I learned a lot of best practices from here, slack, communities, videos, blog posts, etc\u2026 I was able to implement them at my current company. &lt;/p&gt;\n\n&lt;p&gt;Some of these include basic things from delta jobs to building out our whole CICD pipelines, IaC, providing a way to manage our work, optimizing things to save the company money, teaching everyone git, getting compliance to approve of our processes. \nPreviously anyone could move things to production without a review process, people were running full loads off our source databases for jobs that run every 20 mins, data types were never considered or thought about. &lt;/p&gt;\n\n&lt;p&gt;And the company was good to me and promoted me within a year and gave me a raise which I appreciate. &lt;/p&gt;\n\n&lt;p&gt;Now though I am at an impasse because I want to keep growing my technical skills and I know I have so much more to learn. For example we only use SQL and our senior level people didn\u2019t know how to utilize CTEs. I am contemplating starting to look for new roles where the practices listed above are standard and they are utilizing more advanced techniques and I can learn from more senior people. &lt;/p&gt;\n\n&lt;p&gt;In addition the person who\u2019s role I semi took over has been treating me pretty poorly. The company in general is lacking a lot of technical resources. &lt;/p&gt;\n\n&lt;p&gt;I have some projects I have started that I want to finish but I think I should start looking for new roles. Has anyone been in a similar spot? I don\u2019t want to job hop too much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "115119h", "is_robot_indexable": true, "report_reasons": null, "author": "anon_data_person", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/115119h/career_decision_what_to_do_after_outgrowing_a_team/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/115119h/career_decision_what_to_do_after_outgrowing_a_team/", "subreddit_subscribers": 90007, "created_utc": 1676676893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As far as I understand, DBT is used to write models and transform already ingested raw data.\n\nHowever, how does one creates and populates raw tables ? Imagine that I have a S3 bucket regularly updated with data, and that I want to stream this into a Snowflake table, which will be used as a source for my future transformations. Is it possible to create the empty table and configure the snowpipe with dbt ?\n\nIf not, which tool would I use ? The only one I could think about is liquibase (or equivalent) but I find it odd to use several tools to manage tables living together.", "author_fullname": "t2_7wiej82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to write raw ingestion code when working with dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114pa8z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676648826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As far as I understand, DBT is used to write models and transform already ingested raw data.&lt;/p&gt;\n\n&lt;p&gt;However, how does one creates and populates raw tables ? Imagine that I have a S3 bucket regularly updated with data, and that I want to stream this into a Snowflake table, which will be used as a source for my future transformations. Is it possible to create the empty table and configure the snowpipe with dbt ?&lt;/p&gt;\n\n&lt;p&gt;If not, which tool would I use ? The only one I could think about is liquibase (or equivalent) but I find it odd to use several tools to manage tables living together.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "114pa8z", "is_robot_indexable": true, "report_reasons": null, "author": "otineb_", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114pa8z/how_to_write_raw_ingestion_code_when_working_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114pa8z/how_to_write_raw_ingestion_code_when_working_with/", "subreddit_subscribers": 90007, "created_utc": 1676648826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_31ilk7t8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Snowflake query tags for enhanced cost and performance monitoring", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_114tc9s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1xR1IMDmVJFSjW_ZYqa76j6UoEYKtxddR8tCPo8pO5w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1676657175.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "select.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://select.dev/posts/snowflake-query-tags", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hrsl8K-JgIWRV2XPTLfckfMI8VA6QkXqWITZ5cP-ACo.jpg?auto=webp&amp;v=enabled&amp;s=876dd41abccdbc5bddaa4ba666e8992bb01aea98", "width": 1618, "height": 818}, "resolutions": [{"url": "https://external-preview.redd.it/hrsl8K-JgIWRV2XPTLfckfMI8VA6QkXqWITZ5cP-ACo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=41d70e4e9940ae08537b6701fd6c50cb6e3daca6", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/hrsl8K-JgIWRV2XPTLfckfMI8VA6QkXqWITZ5cP-ACo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4eb7b540e83761d9574c4315e5397a592f7e5c0e", "width": 216, "height": 109}, {"url": "https://external-preview.redd.it/hrsl8K-JgIWRV2XPTLfckfMI8VA6QkXqWITZ5cP-ACo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1c7712ae5ff2344753d3c4329f2c654f529d24e", "width": 320, "height": 161}, {"url": "https://external-preview.redd.it/hrsl8K-JgIWRV2XPTLfckfMI8VA6QkXqWITZ5cP-ACo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fc56948e645d279e978174e3be277f2044c18f76", "width": 640, "height": 323}, {"url": "https://external-preview.redd.it/hrsl8K-JgIWRV2XPTLfckfMI8VA6QkXqWITZ5cP-ACo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ddaf708e3aadc91dabfaa43515c0dbb2579cacc9", "width": 960, "height": 485}, {"url": "https://external-preview.redd.it/hrsl8K-JgIWRV2XPTLfckfMI8VA6QkXqWITZ5cP-ACo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f75b25eeed97594421d8cb3465dd6a61b501d11d", "width": 1080, "height": 546}], "variants": {}, "id": "I3-KxaX7toapKInRmIyXg0X6aM1nPG276NX8dr4PCds"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "114tc9s", "is_robot_indexable": true, "report_reasons": null, "author": "ian-whitestone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114tc9s/using_snowflake_query_tags_for_enhanced_cost_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://select.dev/posts/snowflake-query-tags", "subreddit_subscribers": 90007, "created_utc": 1676657175.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nHow does a DE best keep track of all the pipelines and projects? \n\nI just imagine it to get very complex with time - all specifications and extra steps that differ from project or project. \n\nAre there any good tools to map out flows and tools used? Or any hints / strategies on how to best document?\n\nThanks \ud83d\ude42", "author_fullname": "t2_9v9dakww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[How to keep track of all pipelines?] [DE in training]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114ym8u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676670536.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;How does a DE best keep track of all the pipelines and projects? &lt;/p&gt;\n\n&lt;p&gt;I just imagine it to get very complex with time - all specifications and extra steps that differ from project or project. &lt;/p&gt;\n\n&lt;p&gt;Are there any good tools to map out flows and tools used? Or any hints / strategies on how to best document?&lt;/p&gt;\n\n&lt;p&gt;Thanks \ud83d\ude42&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data &amp; Analytics Engineer in training", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "114ym8u", "is_robot_indexable": true, "report_reasons": null, "author": "binchentso", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/114ym8u/how_to_keep_track_of_all_pipelines_de_in_training/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114ym8u/how_to_keep_track_of_all_pipelines_de_in_training/", "subreddit_subscribers": 90007, "created_utc": 1676670536.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Many of read blogs by big tech companies solving interesting Tech problems and follow their Github repos.\n\nBut every now and then, I stumble onto an underrated Github/Gitlab repository which I peruse and pick up ideas I can directly apply at my job as a Data Engineer. \n\nIt could be any of these:\n\n* Collection of notes/best practices/error debugging with proper screenshots and such\n* End to end project with thorough documentation (including architecture diagram, tests, installation instructions, makefiles etc)\n* Handy Recipes/Cookbooks with code snippets \n\nDo you have any suggestions of such underrated repos (including your own) to share with the community? Also, please leave a star as encouragement for repos that get recommended here in comments.", "author_fullname": "t2_g4v8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some underrated open source repositories to read and learn from?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1155ozs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676690884.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Many of read blogs by big tech companies solving interesting Tech problems and follow their Github repos.&lt;/p&gt;\n\n&lt;p&gt;But every now and then, I stumble onto an underrated Github/Gitlab repository which I peruse and pick up ideas I can directly apply at my job as a Data Engineer. &lt;/p&gt;\n\n&lt;p&gt;It could be any of these:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Collection of notes/best practices/error debugging with proper screenshots and such&lt;/li&gt;\n&lt;li&gt;End to end project with thorough documentation (including architecture diagram, tests, installation instructions, makefiles etc)&lt;/li&gt;\n&lt;li&gt;Handy Recipes/Cookbooks with code snippets &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Do you have any suggestions of such underrated repos (including your own) to share with the community? Also, please leave a star as encouragement for repos that get recommended here in comments.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1155ozs", "is_robot_indexable": true, "report_reasons": null, "author": "swapripper", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1155ozs/what_are_some_underrated_open_source_repositories/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1155ozs/what_are_some_underrated_open_source_repositories/", "subreddit_subscribers": 90007, "created_utc": 1676690884.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a ML engineer trying to pick a workflow orchestrator in Python. The problem with this decision is you can't know a project's limitations until you're 3 weeks into setting it up. I spent 5+ hours this week recently exploring these tools and doing tutorials and decided I need more help.\n\nHere's my use case:\n\n1. I want to build dozens of models (think nested for loops, one loop is for target variable, the other loop is for algorithm).\n2. I want to have a pipeline that has \"steps\" where I can easily say \"run from step 3, skipping step 2\". Why? Step 1-2 are computationally expensive and step 3 is making some plots using the output of steps 1-2. So I need to be able to easily re-run just step 3 or from step 3 onward.\n3. Each step in the pipeline needs to save artifacts that will be fed into the next steps. (This is so I can debug them.)\n4. Needs to work locally and remotely. Meaning, when I run locally on my mac it saves stuff in a local folder, when I run on a big cloud instance it saves to S3/GCS.\n5. Needs to be controllable 100% from python scripts or a click module (I re-run my code every 20 seconds and I'm not going to go into a UI to clear the state of something).\n\nThings I don't care about:\n\n* Timeouts/Retries: The code should either work or it doesn't. I'm not webscraping.\n\nI love/hate all workflow orchestrators for different reasons:\n\n1. **Airflow** has a good community, tons of maturity. But was made for data engineers and has this horrible notion of \"backfill\". it's also too verbose.\n2. **Luigi** is great because it auto-generates the dag, doesn't rely on any database. But it's pretty verbose and you have to build the Dag yourself. UI seems lacking according to the docs.\n3. **Dagster** has a great UI but seems to have a poor API compared to Luigi. How do I do the parallelized, nested for loops? Was this built for data scientists or data engineers? I like the notion of decorators and assets, but can't seem to find how to do what I'm trying to do.  \n\n   1. Can't figure out how to read in output from a run.\n   2. Can't figure out how to parallelize code without learning a ton about operators and DynamicOutput or something.\n4. **Prefect** is beautifully simple: it's just python decorators. the .map()  \n operator is amazing. But the artifact management is lacking.\n5. **Metaflow** seems to be built specifically for the data science use case. I'm not sure how to figure out how to save artifacts. But I saw one youtube that people are leaving metaflow for prefect, why?\n6. **Kedro:** Someone referred me to this but I'm not sure if it can do the looping. Can it dynamically generate a graph?\n7. **Bash scripts:** After hitting my head against the wall I'm considering just looping my code using a parallelized bash script and calling it a day. But then i have to build all this logic for try-except. I want to easily track my failures.", "author_fullname": "t2_sfvtui5u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which ML orchestration tool fits my use case? Kedro vs. Airflow vs. Metaflow vs. Luigi vs. Dagster etc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1152wow", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676682218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a ML engineer trying to pick a workflow orchestrator in Python. The problem with this decision is you can&amp;#39;t know a project&amp;#39;s limitations until you&amp;#39;re 3 weeks into setting it up. I spent 5+ hours this week recently exploring these tools and doing tutorials and decided I need more help.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my use case:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I want to build dozens of models (think nested for loops, one loop is for target variable, the other loop is for algorithm).&lt;/li&gt;\n&lt;li&gt;I want to have a pipeline that has &amp;quot;steps&amp;quot; where I can easily say &amp;quot;run from step 3, skipping step 2&amp;quot;. Why? Step 1-2 are computationally expensive and step 3 is making some plots using the output of steps 1-2. So I need to be able to easily re-run just step 3 or from step 3 onward.&lt;/li&gt;\n&lt;li&gt;Each step in the pipeline needs to save artifacts that will be fed into the next steps. (This is so I can debug them.)&lt;/li&gt;\n&lt;li&gt;Needs to work locally and remotely. Meaning, when I run locally on my mac it saves stuff in a local folder, when I run on a big cloud instance it saves to S3/GCS.&lt;/li&gt;\n&lt;li&gt;Needs to be controllable 100% from python scripts or a click module (I re-run my code every 20 seconds and I&amp;#39;m not going to go into a UI to clear the state of something).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Things I don&amp;#39;t care about:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Timeouts/Retries: The code should either work or it doesn&amp;#39;t. I&amp;#39;m not webscraping.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I love/hate all workflow orchestrators for different reasons:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Airflow&lt;/strong&gt; has a good community, tons of maturity. But was made for data engineers and has this horrible notion of &amp;quot;backfill&amp;quot;. it&amp;#39;s also too verbose.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Luigi&lt;/strong&gt; is great because it auto-generates the dag, doesn&amp;#39;t rely on any database. But it&amp;#39;s pretty verbose and you have to build the Dag yourself. UI seems lacking according to the docs.&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dagster&lt;/strong&gt; has a great UI but seems to have a poor API compared to Luigi. How do I do the parallelized, nested for loops? Was this built for data scientists or data engineers? I like the notion of decorators and assets, but can&amp;#39;t seem to find how to do what I&amp;#39;m trying to do.  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can&amp;#39;t figure out how to read in output from a run.&lt;/li&gt;\n&lt;li&gt;Can&amp;#39;t figure out how to parallelize code without learning a ton about operators and DynamicOutput or something.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Prefect&lt;/strong&gt; is beautifully simple: it&amp;#39;s just python decorators. the .map()&lt;br/&gt;\noperator is amazing. But the artifact management is lacking.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Metaflow&lt;/strong&gt; seems to be built specifically for the data science use case. I&amp;#39;m not sure how to figure out how to save artifacts. But I saw one youtube that people are leaving metaflow for prefect, why?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Kedro:&lt;/strong&gt; Someone referred me to this but I&amp;#39;m not sure if it can do the looping. Can it dynamically generate a graph?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Bash scripts:&lt;/strong&gt; After hitting my head against the wall I&amp;#39;m considering just looping my code using a parallelized bash script and calling it a day. But then i have to build all this logic for try-except. I want to easily track my failures.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1152wow", "is_robot_indexable": true, "report_reasons": null, "author": "Comfortable_Way_8441", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1152wow/which_ml_orchestration_tool_fits_my_use_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1152wow/which_ml_orchestration_tool_fits_my_use_case/", "subreddit_subscribers": 90007, "created_utc": 1676682218.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi friends, just curious did you manage to hop from DE to DevOps? What's the experience? What did you study to grab the position?", "author_fullname": "t2_bmsha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Did anyone successfully hop to a DevOps position?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1150ebf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676675161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends, just curious did you manage to hop from DE to DevOps? What&amp;#39;s the experience? What did you study to grab the position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1150ebf", "is_robot_indexable": true, "report_reasons": null, "author": "levelworm", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1150ebf/did_anyone_successfully_hop_to_a_devops_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1150ebf/did_anyone_successfully_hop_to_a_devops_position/", "subreddit_subscribers": 90007, "created_utc": 1676675161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m comfortable with SQL, Python and I\u2019m looking to start learning another. \n\nI don\u2019t really want to learn something with similar use cases as I don\u2019t feel that will add a great deal of value, but I want the next language to add to my Data Engineering resume so open to all suggestions. What would you recommend and why?", "author_fullname": "t2_j68xrjb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Language suggestions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11501ng", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676674219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m comfortable with SQL, Python and I\u2019m looking to start learning another. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t really want to learn something with similar use cases as I don\u2019t feel that will add a great deal of value, but I want the next language to add to my Data Engineering resume so open to all suggestions. What would you recommend and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "11501ng", "is_robot_indexable": true, "report_reasons": null, "author": "Yimmy_90", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11501ng/language_suggestions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11501ng/language_suggestions/", "subreddit_subscribers": 90007, "created_utc": 1676674219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When you read a data engineering book or follow some theory videos, let's say Fundamental of Data Engineering, how you make sure that you can remember some concepts/ ideas you have read? I find it really hard to translate the knowledge in books to real life.\nI have been thinking to write down everything I read or watch to help me remember it but not sure if it is a great approach \n\nThanks in advance :)", "author_fullname": "t2_pp0zirow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you learn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114xqi9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676668272.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When you read a data engineering book or follow some theory videos, let&amp;#39;s say Fundamental of Data Engineering, how you make sure that you can remember some concepts/ ideas you have read? I find it really hard to translate the knowledge in books to real life.\nI have been thinking to write down everything I read or watch to help me remember it but not sure if it is a great approach &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "114xqi9", "is_robot_indexable": true, "report_reasons": null, "author": "These_Rip_9327", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114xqi9/how_do_you_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114xqi9/how_do_you_learn/", "subreddit_subscribers": 90007, "created_utc": 1676668272.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would like to hear some experience from ppl that made that transition. \n\nI guess in some companies this responsability is also shared by senior DE's but there seem to be also many companies who divide that responsabilities in a exclusive role that sounds somewhat more laid back to me.\n\nSo far I've been working as a Senior DE for quite some time but while interviewing, I've realised that there had been architects with five or less years experience of being a DE prior. I wonder what change of responsibilities that would include? Do architects do really nothing but designing the technical blue print for DE's to implement? Do they also spent time on troubleshooting pipelines while constantly learning new technologies? They should be more experienced but is their job either harder or more relaxed since they don't need to worry about details or implementation efforts that much?", "author_fullname": "t2_uetytl1k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Move: Senior DE -&gt; Data Architect/Solutions Architect", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114vxh4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676663727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would like to hear some experience from ppl that made that transition. &lt;/p&gt;\n\n&lt;p&gt;I guess in some companies this responsability is also shared by senior DE&amp;#39;s but there seem to be also many companies who divide that responsabilities in a exclusive role that sounds somewhat more laid back to me.&lt;/p&gt;\n\n&lt;p&gt;So far I&amp;#39;ve been working as a Senior DE for quite some time but while interviewing, I&amp;#39;ve realised that there had been architects with five or less years experience of being a DE prior. I wonder what change of responsibilities that would include? Do architects do really nothing but designing the technical blue print for DE&amp;#39;s to implement? Do they also spent time on troubleshooting pipelines while constantly learning new technologies? They should be more experienced but is their job either harder or more relaxed since they don&amp;#39;t need to worry about details or implementation efforts that much?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "114vxh4", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Book-6052", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114vxh4/career_move_senior_de_data_architectsolutions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114vxh4/career_move_senior_de_data_architectsolutions/", "subreddit_subscribers": 90007, "created_utc": 1676663727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi fellow data manglers \n\n  \nI currently work for a large railway company in Europe and provide internal consulting on our data engineering tech stack. Which is Snowflake, Snowpark for Python, Openshift, ADF and Argo Workflows.   \nOver the next two years the companies analytical applications should transition from the previous two techstack generations, which are PowerCenter or Hadoop/Spark, to the above-mentioned.   \nDue to the extreme shortage of data engineering profiles in the company, our goal is to enable full stack Java developers to create, migrate and maintain the plethora of analytical applications. (Teach a bear to dance, but don't wonder if your head gets bitten off)   \nTo achieve this, we provide sample applications, pilot migrations and a lot of documentation and tutorials on (best) practice with the formerly described stack. \n\n  \nSince half a year, I maintain a hefty discussion concerning the test concept. Since we're using Python for implementing our pipelines and some developers in our teams are former fullstack developers/application architects, a conflicting position around unit testing arose. According to my view and experience, the classical test pyramid, where unit testing forms the foundation, is not applicable, when implementing data pipelines. Automated measuring of data quality dimensions\\[1\\] and conducting user acceptance tests with personas who have the required insight, always deemed me much more significant. It's not even true unit testing, because the Snowpark API requires a Snowflake connection in order to generate the SQL statements, so it is violating isolation anyway. \n\n  \nI'd like to have your opinions and experience on testing in data engineering context, maybe I'm a little short-sighted/biased concerning the matter. Thanks!\n\n  \n\\[1\\][https://www.sciencedirect.com/topics/computer-science/data-quality-dimension](https://www.sciencedirect.com/topics/computer-science/data-quality-dimension)", "author_fullname": "t2_88g9czbu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Your opinion on testing in data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_115akgk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676708606.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellow data manglers &lt;/p&gt;\n\n&lt;p&gt;I currently work for a large railway company in Europe and provide internal consulting on our data engineering tech stack. Which is Snowflake, Snowpark for Python, Openshift, ADF and Argo Workflows.&lt;br/&gt;\nOver the next two years the companies analytical applications should transition from the previous two techstack generations, which are PowerCenter or Hadoop/Spark, to the above-mentioned.&lt;br/&gt;\nDue to the extreme shortage of data engineering profiles in the company, our goal is to enable full stack Java developers to create, migrate and maintain the plethora of analytical applications. (Teach a bear to dance, but don&amp;#39;t wonder if your head gets bitten off)&lt;br/&gt;\nTo achieve this, we provide sample applications, pilot migrations and a lot of documentation and tutorials on (best) practice with the formerly described stack. &lt;/p&gt;\n\n&lt;p&gt;Since half a year, I maintain a hefty discussion concerning the test concept. Since we&amp;#39;re using Python for implementing our pipelines and some developers in our teams are former fullstack developers/application architects, a conflicting position around unit testing arose. According to my view and experience, the classical test pyramid, where unit testing forms the foundation, is not applicable, when implementing data pipelines. Automated measuring of data quality dimensions[1] and conducting user acceptance tests with personas who have the required insight, always deemed me much more significant. It&amp;#39;s not even true unit testing, because the Snowpark API requires a Snowflake connection in order to generate the SQL statements, so it is violating isolation anyway. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to have your opinions and experience on testing in data engineering context, maybe I&amp;#39;m a little short-sighted/biased concerning the matter. Thanks!&lt;/p&gt;\n\n&lt;p&gt;[1]&lt;a href=\"https://www.sciencedirect.com/topics/computer-science/data-quality-dimension\"&gt;https://www.sciencedirect.com/topics/computer-science/data-quality-dimension&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "115akgk", "is_robot_indexable": true, "report_reasons": null, "author": "SuccessfulEar9225", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/115akgk/your_opinion_on_testing_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/115akgk/your_opinion_on_testing_in_data_engineering/", "subreddit_subscribers": 90007, "created_utc": 1676708606.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI'm just beginning to learn the airflow and it's a little confusing to me. Spark has the driver that manages the workers and airflow has scheduler that also manages workers.\n\nSo right now at work we run both spark and airflow on one machine, 12 CPUs. Airflow is allowed to run 3 tasks at once, each of these tasks being a spark job (serializing data), and spark dynamically allocates resources to the executors.\n\nWhat does an airflow worker do here? If one worker takes one task at a time, does this worker talk to the spark driver, which then talks to spark executors? \n\nCan you please help me understand the relations between the airflow scheduler -&gt; a. workers -&gt; spark driver -&gt; s. workers in the context of airflow/spark pipeline?\n\nThank you", "author_fullname": "t2_gfx5s46h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Relationship between airflow workers and spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_115fgep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676727324.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just beginning to learn the airflow and it&amp;#39;s a little confusing to me. Spark has the driver that manages the workers and airflow has scheduler that also manages workers.&lt;/p&gt;\n\n&lt;p&gt;So right now at work we run both spark and airflow on one machine, 12 CPUs. Airflow is allowed to run 3 tasks at once, each of these tasks being a spark job (serializing data), and spark dynamically allocates resources to the executors.&lt;/p&gt;\n\n&lt;p&gt;What does an airflow worker do here? If one worker takes one task at a time, does this worker talk to the spark driver, which then talks to spark executors? &lt;/p&gt;\n\n&lt;p&gt;Can you please help me understand the relations between the airflow scheduler -&amp;gt; a. workers -&amp;gt; spark driver -&amp;gt; s. workers in the context of airflow/spark pipeline?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "115fgep", "is_robot_indexable": true, "report_reasons": null, "author": "LeftHelicopter5297", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/115fgep/relationship_between_airflow_workers_and_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/115fgep/relationship_between_airflow_workers_and_spark/", "subreddit_subscribers": 90007, "created_utc": 1676727324.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI have been solve a problem since 5 days. I\u2019ve never faced any problem like this. To clarify,\n\nI am running a gradient classifier using pandas udf. The function takes as input the spark DF that I got from oracle. I send the input to the function by partitioning the client number inside to 128 (input, single on the basis of client number).\nThe problem is, while examining the output, I noticed that some client numbers are duplicate and some clients are crushed and not restored.\n \nThe total number of lines of input and output count, but I don't understand why I'm facing such a problem. I don't understand if there is a problem with running parallel nodes.\n\nIs there anyone faced this problem. I'm also curious about your comments.\n\nThank you,\n\n\n\nExample:\n\nExpected output:\n\nClient 1\u2014-Score 1\n\nClient 2\u2014-Score 2\n\nClient 3\u2014-Score 3\n\nClient 4 \u2014-Score 4\n\nOutput ( its changing every run )\n\nClient 1\u2014-Score 1\n\nClient 1\u2014-Score 1\n\nClient 1\u2014-Score 1\n\nClient 4 \u2014-Score 4", "author_fullname": "t2_njq84xk3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Duplication Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_115f49x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676726253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I have been solve a problem since 5 days. I\u2019ve never faced any problem like this. To clarify,&lt;/p&gt;\n\n&lt;p&gt;I am running a gradient classifier using pandas udf. The function takes as input the spark DF that I got from oracle. I send the input to the function by partitioning the client number inside to 128 (input, single on the basis of client number).\nThe problem is, while examining the output, I noticed that some client numbers are duplicate and some clients are crushed and not restored.&lt;/p&gt;\n\n&lt;p&gt;The total number of lines of input and output count, but I don&amp;#39;t understand why I&amp;#39;m facing such a problem. I don&amp;#39;t understand if there is a problem with running parallel nodes.&lt;/p&gt;\n\n&lt;p&gt;Is there anyone faced this problem. I&amp;#39;m also curious about your comments.&lt;/p&gt;\n\n&lt;p&gt;Thank you,&lt;/p&gt;\n\n&lt;p&gt;Example:&lt;/p&gt;\n\n&lt;p&gt;Expected output:&lt;/p&gt;\n\n&lt;p&gt;Client 1\u2014-Score 1&lt;/p&gt;\n\n&lt;p&gt;Client 2\u2014-Score 2&lt;/p&gt;\n\n&lt;p&gt;Client 3\u2014-Score 3&lt;/p&gt;\n\n&lt;p&gt;Client 4 \u2014-Score 4&lt;/p&gt;\n\n&lt;p&gt;Output ( its changing every run )&lt;/p&gt;\n\n&lt;p&gt;Client 1\u2014-Score 1&lt;/p&gt;\n\n&lt;p&gt;Client 1\u2014-Score 1&lt;/p&gt;\n\n&lt;p&gt;Client 1\u2014-Score 1&lt;/p&gt;\n\n&lt;p&gt;Client 4 \u2014-Score 4&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "115f49x", "is_robot_indexable": true, "report_reasons": null, "author": "No_Rule871", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/115f49x/spark_duplication_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/115f49x/spark_duplication_problem/", "subreddit_subscribers": 90007, "created_utc": 1676726253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Could anyone please tell if you are aware of Debezium CDC Usage keeping Production method in mind. Reading from Some DB and propogating to DW (say Azure ADLS Gen2/S3)", "author_fullname": "t2_sr3rc27q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Debezium CDC Integration Blog/Tutorial", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_115em3z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676724576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could anyone please tell if you are aware of Debezium CDC Usage keeping Production method in mind. Reading from Some DB and propogating to DW (say Azure ADLS Gen2/S3)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "115em3z", "is_robot_indexable": true, "report_reasons": null, "author": "honey12123", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/115em3z/debezium_cdc_integration_blogtutorial/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/115em3z/debezium_cdc_integration_blogtutorial/", "subreddit_subscribers": 90007, "created_utc": 1676724576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI have recently switched from Data Science to Data Engineering.\n\nBasically, I like what I'm doing now and I have nice colleagues. I have learned an extreme amount in the first few weeks and find it all exciting. But at the same time, I have the problem that I constantly feel overwhelmed and it's getting worse rather than better.\n\nThere are good times when I can get tickets done quickly, but there are also times when I scroll through code for hours and feel completely at a loss.\n\nRight now I'm doing a ticket on our infrastructure with Terraform. There is S3 storage to be created, permissions to be assigned, etc. It took me 5 hours to even find the right repositories to change (it's multi repo with all components in a single repository) and now it's turned into a total of 7 pull requests where I don't even know if that's it or if it will work in the end.\n\nThis uncertainty nags me a lot. I feel like I'm in the middle of a fog and basically everything I do takes way too much time. No one is pressuring me in this respect, but I am a rather impatient person and obviously not made for reading documentation and code for hours and then writing a line of code to maybe solve a problem.\n\nIs this something that gets better with time? Is there anything I can actively do to change this state? I currently feel like I am running into a burnout.\n\nThank you!", "author_fullname": "t2_5fudhnqra", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding a good way to deal with complex tasks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_115c72p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676715229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have recently switched from Data Science to Data Engineering.&lt;/p&gt;\n\n&lt;p&gt;Basically, I like what I&amp;#39;m doing now and I have nice colleagues. I have learned an extreme amount in the first few weeks and find it all exciting. But at the same time, I have the problem that I constantly feel overwhelmed and it&amp;#39;s getting worse rather than better.&lt;/p&gt;\n\n&lt;p&gt;There are good times when I can get tickets done quickly, but there are also times when I scroll through code for hours and feel completely at a loss.&lt;/p&gt;\n\n&lt;p&gt;Right now I&amp;#39;m doing a ticket on our infrastructure with Terraform. There is S3 storage to be created, permissions to be assigned, etc. It took me 5 hours to even find the right repositories to change (it&amp;#39;s multi repo with all components in a single repository) and now it&amp;#39;s turned into a total of 7 pull requests where I don&amp;#39;t even know if that&amp;#39;s it or if it will work in the end.&lt;/p&gt;\n\n&lt;p&gt;This uncertainty nags me a lot. I feel like I&amp;#39;m in the middle of a fog and basically everything I do takes way too much time. No one is pressuring me in this respect, but I am a rather impatient person and obviously not made for reading documentation and code for hours and then writing a line of code to maybe solve a problem.&lt;/p&gt;\n\n&lt;p&gt;Is this something that gets better with time? Is there anything I can actively do to change this state? I currently feel like I am running into a burnout.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "115c72p", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious_Effect319", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/115c72p/finding_a_good_way_to_deal_with_complex_tasks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/115c72p/finding_a_good_way_to_deal_with_complex_tasks/", "subreddit_subscribers": 90007, "created_utc": 1676715229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Other than the pricing (rent vs buy upfront), is there anything I con do in the cloud that I couldn\u2019t do on-prem from a data engineer perspective?\n\nEdit: cloud vs. on-prem. Can\u2019t change the title.", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud vs on-prom", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1151dfq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1676682545.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676677831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Other than the pricing (rent vs buy upfront), is there anything I con do in the cloud that I couldn\u2019t do on-prem from a data engineer perspective?&lt;/p&gt;\n\n&lt;p&gt;Edit: cloud vs. on-prem. Can\u2019t change the title.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1151dfq", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1151dfq/cloud_vs_onprom/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1151dfq/cloud_vs_onprom/", "subreddit_subscribers": 90007, "created_utc": 1676677831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey\n\nIs here anyone who got a job as a data engineer or data analyst/scientist in NZ on a WHV ? I'm just moving in the end of this year, trying to check how easy it is to find such a job. Seems not so easy tho.", "author_fullname": "t2_a0llj66p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WHV in NZ as DE or DA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114wzbp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676666373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey&lt;/p&gt;\n\n&lt;p&gt;Is here anyone who got a job as a data engineer or data analyst/scientist in NZ on a WHV ? I&amp;#39;m just moving in the end of this year, trying to check how easy it is to find such a job. Seems not so easy tho.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "114wzbp", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Promotion_420", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114wzbp/whv_in_nz_as_de_or_da/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114wzbp/whv_in_nz_as_de_or_da/", "subreddit_subscribers": 90007, "created_utc": 1676666373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working with some teams pulling primary data from API events that have been stored in Kibana indexes. The teams ingest the indexes using various tools and languages. I am finding Python quite easy to use for this. \n\nA big problem we encounter is that the JSON objects change without the teams knowing about the changes. So they are constantly reviewing the JSON manually when these exceptions occur and add new JSON objects are added. The objects are not stored as fields all the time, but actually as open ended JSON objects. \n\nMy question is twofold.\n\n1. What's the easiest way to manage the expections or changes to the JSON object? Do you have a mask or base model of all model iterations?\n2. If there a library to use that can assist in creating those nested objects into data frames, to be able to make the reviewing process easier? Or are there easier ways to do this?", "author_fullname": "t2_11t26p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kibana as a source data stream. how do you guys manage the ingestion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114wift", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676665188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working with some teams pulling primary data from API events that have been stored in Kibana indexes. The teams ingest the indexes using various tools and languages. I am finding Python quite easy to use for this. &lt;/p&gt;\n\n&lt;p&gt;A big problem we encounter is that the JSON objects change without the teams knowing about the changes. So they are constantly reviewing the JSON manually when these exceptions occur and add new JSON objects are added. The objects are not stored as fields all the time, but actually as open ended JSON objects. &lt;/p&gt;\n\n&lt;p&gt;My question is twofold.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What&amp;#39;s the easiest way to manage the expections or changes to the JSON object? Do you have a mask or base model of all model iterations?&lt;/li&gt;\n&lt;li&gt;If there a library to use that can assist in creating those nested objects into data frames, to be able to make the reviewing process easier? Or are there easier ways to do this?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "114wift", "is_robot_indexable": true, "report_reasons": null, "author": "byeproduct", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114wift/kibana_as_a_source_data_stream_how_do_you_guys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114wift/kibana_as_a_source_data_stream_how_do_you_guys/", "subreddit_subscribers": 90007, "created_utc": 1676665188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have e.g. JSON files in the S3. We take these files and using python transform them into parquet. What is the next step if we want to use Trino? Go to Trino CLI and use CREATE TABLE \u2026 WITH s3://path/to/parquet ..? And everytime we add new parquet file the table automatically updates? Is this good approach? Can we do anything differently/more efficiently?\n\nAlso then my idea is to use probably dbt to create some aggregations over these parquet tables and execute them using Trino again and store them as Iceberg tables. Does it sound reasonable? My concern is we are going to have a lot of parts (python app, dbt, Trino, scheduler (Airflow)).", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trino create table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114vepw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676662406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have e.g. JSON files in the S3. We take these files and using python transform them into parquet. What is the next step if we want to use Trino? Go to Trino CLI and use CREATE TABLE \u2026 WITH s3://path/to/parquet ..? And everytime we add new parquet file the table automatically updates? Is this good approach? Can we do anything differently/more efficiently?&lt;/p&gt;\n\n&lt;p&gt;Also then my idea is to use probably dbt to create some aggregations over these parquet tables and execute them using Trino again and store them as Iceberg tables. Does it sound reasonable? My concern is we are going to have a lot of parts (python app, dbt, Trino, scheduler (Airflow)).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "114vepw", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114vepw/trino_create_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114vepw/trino_create_table/", "subreddit_subscribers": 90007, "created_utc": 1676662406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Here's my log4j configuration:\n\n    log4j.rootLogger=INFO, loggerId\n    log4j.appender.loggerId=org.apache.log4j.rolling.RollingFileAppender\n    log4j.appender.loggerId.rollingPolicy=org.apache.log4j.rolling.TimeBasedRollingPolicy\n    log4j.appender.loggerId.rollingPolicy.ActiveFileName=${spark.yarn.app.container.log.dir}/spark.log\n    log4j.appender.loggerId.rollingPolicy.FileNamePattern=${spark.yarn.app.container.log.dir}/spark_%d{dd-HHmm}.log.gz\n    log4j.appender.loggerId.layout=org.apache.log4j.PatternLayout\n    log4j.appender.loggerId.layout.ConversionPattern=%d %p %t %c usecase=${spark.yarn.appMasterEnv.usecase} usecase2=${spark.executorEnv.usecase}\n    logdir=${spark.yarn.app.container.log.dir} - %m%n\n    log4j.appender.loggerId.encoding=UTF-8 \n\nIn the ConversionPattern key, I can see logdir value but not usecase or usecase2. When I go to Spark UI, I can see spark.yarn.appMasterEnv.usecase &amp; spark.executorEnv.usecase values are set. These values are set during spark-submit. My only guess is these values are set after log4j is instantiated, that's why there are no values. If that's the case, how can I set spark environment variables sooner? Or is there another way around this?", "author_fullname": "t2_1tbzh2ae", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark environment variables in log4j ConversionPattern", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_114wi24", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1676665159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here&amp;#39;s my log4j configuration:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;log4j.rootLogger=INFO, loggerId\nlog4j.appender.loggerId=org.apache.log4j.rolling.RollingFileAppender\nlog4j.appender.loggerId.rollingPolicy=org.apache.log4j.rolling.TimeBasedRollingPolicy\nlog4j.appender.loggerId.rollingPolicy.ActiveFileName=${spark.yarn.app.container.log.dir}/spark.log\nlog4j.appender.loggerId.rollingPolicy.FileNamePattern=${spark.yarn.app.container.log.dir}/spark_%d{dd-HHmm}.log.gz\nlog4j.appender.loggerId.layout=org.apache.log4j.PatternLayout\nlog4j.appender.loggerId.layout.ConversionPattern=%d %p %t %c usecase=${spark.yarn.appMasterEnv.usecase} usecase2=${spark.executorEnv.usecase}\nlogdir=${spark.yarn.app.container.log.dir} - %m%n\nlog4j.appender.loggerId.encoding=UTF-8 \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;In the ConversionPattern key, I can see logdir value but not usecase or usecase2. When I go to Spark UI, I can see spark.yarn.appMasterEnv.usecase &amp;amp; spark.executorEnv.usecase values are set. These values are set during spark-submit. My only guess is these values are set after log4j is instantiated, that&amp;#39;s why there are no values. If that&amp;#39;s the case, how can I set spark environment variables sooner? Or is there another way around this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "114wi24", "is_robot_indexable": true, "report_reasons": null, "author": "TeslaMecca", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/114wi24/spark_environment_variables_in_log4j/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/114wi24/spark_environment_variables_in_log4j/", "subreddit_subscribers": 90007, "created_utc": 1676665159.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}