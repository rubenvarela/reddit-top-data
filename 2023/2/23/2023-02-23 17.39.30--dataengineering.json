{"kind": "Listing", "data": {"after": "t3_119qxna", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone \ud83d\udc4b I\u2019m Ian \u2014 I used to work on data tooling at Stripe. My friend Justin (ex data science at Cruise) and I have been building a new free local editor made specifically for dbt core called Turntable ([https://www.turntable.so/](https://www.turntable.so/))\n\nI love VS Code and other local IDEs, but they don\u2019t have some core features I need for dbt development. Turntable has visual lineage, query preview, and more built in (quick [demo](https://www.loom.com/share/8db10268612d4769893123b00500ad35) below).\n\nNext, we\u2019re planning to explore column-level lineage and code/yaml autocomplete using AI. I\u2019d love to hear what you think and whether the problems / solution resonates. And if you want to try it out, comment or send me a DM\u2026 thanks!\n\n[https://www.loom.com/share/8db10268612d4769893123b00500ad35](https://www.loom.com/share/8db10268612d4769893123b00500ad35)", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a better local dbt experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119oxil", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677130632.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677128125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone \ud83d\udc4b I\u2019m Ian \u2014 I used to work on data tooling at Stripe. My friend Justin (ex data science at Cruise) and I have been building a new free local editor made specifically for dbt core called Turntable (&lt;a href=\"https://www.turntable.so/\"&gt;https://www.turntable.so/&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;I love VS Code and other local IDEs, but they don\u2019t have some core features I need for dbt development. Turntable has visual lineage, query preview, and more built in (quick &lt;a href=\"https://www.loom.com/share/8db10268612d4769893123b00500ad35\"&gt;demo&lt;/a&gt; below).&lt;/p&gt;\n\n&lt;p&gt;Next, we\u2019re planning to explore column-level lineage and code/yaml autocomplete using AI. I\u2019d love to hear what you think and whether the problems / solution resonates. And if you want to try it out, comment or send me a DM\u2026 thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.loom.com/share/8db10268612d4769893123b00500ad35\"&gt;https://www.loom.com/share/8db10268612d4769893123b00500ad35&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "119oxil", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119oxil/building_a_better_local_dbt_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119oxil/building_a_better_local_dbt_experience/", "subreddit_subscribers": 90836, "created_utc": 1677128125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What tips &amp; tricks would you recommend to the beginner pandas users? What to definitely avoid?\n\n(I would like to provide a pandas workshop to our business users so collecting ideas)", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your best pandas tips&amp;tricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1199zm1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677095572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What tips &amp;amp; tricks would you recommend to the beginner pandas users? What to definitely avoid?&lt;/p&gt;\n\n&lt;p&gt;(I would like to provide a pandas workshop to our business users so collecting ideas)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1199zm1", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1199zm1/what_are_your_best_pandas_tipstricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1199zm1/what_are_your_best_pandas_tipstricks/", "subreddit_subscribers": 90836, "created_utc": 1677095572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Polars is getting pretty popular recently but I would like to know what pandas can do and polars still can not.\n\nE. g. I found polars cannot work efficiently with json (missing e.g. json_normalize function).", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What pandas can do and polars can\u2019t?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119a3vs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677095736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Polars is getting pretty popular recently but I would like to know what pandas can do and polars still can not.&lt;/p&gt;\n\n&lt;p&gt;E. g. I found polars cannot work efficiently with json (missing e.g. json_normalize function).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "119a3vs", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119a3vs/what_pandas_can_do_and_polars_cant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119a3vs/what_pandas_can_do_and_polars_cant/", "subreddit_subscribers": 90836, "created_utc": 1677095736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "dbt is getting pretty popular recently, but is it really that \u201cnecessary\u201d? I mean what are the added benefit of introducing new tool when you can do all transformations using python (polars, duckDB\u2026) + in python you can also do the \u201cextract\u201d step so basically you are able to cover entire ETL lifecycle with one tool? Also you can unit test your code better. As python disadvantage I see the dependency management. The only advantage of dbt I can see is you do not have to explicitly create tables as it creates it for you.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is dbt really necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119s7yv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677139328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;dbt is getting pretty popular recently, but is it really that \u201cnecessary\u201d? I mean what are the added benefit of introducing new tool when you can do all transformations using python (polars, duckDB\u2026) + in python you can also do the \u201cextract\u201d step so basically you are able to cover entire ETL lifecycle with one tool? Also you can unit test your code better. As python disadvantage I see the dependency management. The only advantage of dbt I can see is you do not have to explicitly create tables as it creates it for you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "119s7yv", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 57, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119s7yv/is_dbt_really_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119s7yv/is_dbt_really_necessary/", "subreddit_subscribers": 90836, "created_utc": 1677139328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_em2yi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How I Decreased ETL Cost by Leveraging the Apache Arrow Ecosystem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "name": "t3_119g5nc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QZH3QHnUFoosVA85lVKFbP13HNR91vebAHaKr_M4qCU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677105257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "rcpassos.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://rcpassos.me/post/apache-arrow-future-of-data-engineering", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?auto=webp&amp;v=enabled&amp;s=0dbc90e7190608d0a5c7f3b79b3cc14dcf40e005", "width": 2048, "height": 1170}, "resolutions": [{"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9346544144f2d70bd9adf0c2d91e5037f1e1bb50", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45759a1b653546d00c5c5eace4bbf344355bcc14", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c4e1c29f639231505e892e2d07b2e35afb9b80f", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58b9cc2cf6daa644cca89de9c250f43bb88b6b73", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=143764eb76d7d1dcd28d1a82935d3f9ffdc93209", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d6dcdb61c28ea1a4275ccc32506478a736e4833", "width": 1080, "height": 616}], "variants": {}, "id": "aaEDVnIXM_-RMbLWzDpeO6CMM6TnSdzuUj2_DeBa8lk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "119g5nc", "is_robot_indexable": true, "report_reasons": null, "author": "auyer", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119g5nc/how_i_decreased_etl_cost_by_leveraging_the_apache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://rcpassos.me/post/apache-arrow-future-of-data-engineering", "subreddit_subscribers": 90836, "created_utc": 1677105257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All --\n\nI am not a data engineer -- I'm an analyst, but I use a very robust and convoluted data infrastructure built by a team of data engineers. The data infrastructure that I use on a day-to-day basis has almost no documentation regarding how the ETLs map to higher abstractions of unstructured data, nor really any good descriptions of source data systems underlying the ETL process.\n\n&amp;#x200B;\n\nDoes anyone know if there are any documentation frameworks for documenting this sort of thing? My goal is to reduce tribal knowledge of our data engineering team to make things more accessible for our analysts.\n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_5b1wzyfu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to build documentation for a data infrastructure? any existing tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1195ts7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677087389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All --&lt;/p&gt;\n\n&lt;p&gt;I am not a data engineer -- I&amp;#39;m an analyst, but I use a very robust and convoluted data infrastructure built by a team of data engineers. The data infrastructure that I use on a day-to-day basis has almost no documentation regarding how the ETLs map to higher abstractions of unstructured data, nor really any good descriptions of source data systems underlying the ETL process.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anyone know if there are any documentation frameworks for documenting this sort of thing? My goal is to reduce tribal knowledge of our data engineering team to make things more accessible for our analysts.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1195ts7", "is_robot_indexable": true, "report_reasons": null, "author": "MrNezzer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1195ts7/whats_the_best_way_to_build_documentation_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1195ts7/whats_the_best_way_to_build_documentation_for_a/", "subreddit_subscribers": 90836, "created_utc": 1677087389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pandas 2.0 and the Arrow revolution (part I)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119ig9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1677110639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datapythonista.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://datapythonista.me/blog/pandas-20-and-the-arrow-revolution-part-i", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "119ig9h", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119ig9h/pandas_20_and_the_arrow_revolution_part_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://datapythonista.me/blog/pandas-20-and-the-arrow-revolution-part-i", "subreddit_subscribers": 90836, "created_utc": 1677110639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just joined a small B2C company that produces written content similar to spark notes. They have no data warehouse and is using Postgres for housing content to deliver via their website. Separately they also have data scientists scraping web data to find which books are popular.\n\nI need to setup a data warehouse and a database for the company. The first purpose would be to automate the scraping process - it is currently manual and the datasets are stored on someone\u2019s computer lol.\n\nI\u2019ll considering using all of Google Cloud\u2019s suite of tools. What are the risks here? Google Cloud seems to have everything - BigQuery as the warehouse, SQL database, data studio as BI tool, and Cloud Run to automate python scrapers.\n\nWhat are the pros and cons of using every tool from one provider (aka Google here)? \n\nFor context, I am more familiar with Snowflake and Looker setup from my last job.", "author_fullname": "t2_gfy8k6mh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting DataOps function from Scratch at small B2C company.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119emfw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677102222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just joined a small B2C company that produces written content similar to spark notes. They have no data warehouse and is using Postgres for housing content to deliver via their website. Separately they also have data scientists scraping web data to find which books are popular.&lt;/p&gt;\n\n&lt;p&gt;I need to setup a data warehouse and a database for the company. The first purpose would be to automate the scraping process - it is currently manual and the datasets are stored on someone\u2019s computer lol.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ll considering using all of Google Cloud\u2019s suite of tools. What are the risks here? Google Cloud seems to have everything - BigQuery as the warehouse, SQL database, data studio as BI tool, and Cloud Run to automate python scrapers.&lt;/p&gt;\n\n&lt;p&gt;What are the pros and cons of using every tool from one provider (aka Google here)? &lt;/p&gt;\n\n&lt;p&gt;For context, I am more familiar with Snowflake and Looker setup from my last job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119emfw", "is_robot_indexable": true, "report_reasons": null, "author": "FivePointyChickens", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119emfw/starting_dataops_function_from_scratch_at_small/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119emfw/starting_dataops_function_from_scratch_at_small/", "subreddit_subscribers": 90836, "created_utc": 1677102222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've recently joined a company who is doing the majority of data transformation in lookml.  Seems like there are 2 reasons for this from what I'm told:  \n\n1. Every end user wants a different level of aggregation and that would require creating duplicative tables in Snowflake (think something like marketing wants product level, finance wants order level, but user specific not business specific)\n\n2. If we change the data structure of a table that would require a lot of maintenance in Snowflake \n\n\nI'm very self taught and still very much a beginner so I'm looking for a sanity check. My thought is having a solid groundwork laid out in Snowflake is going to solve the majority of those concerns. Define the aggregate levels by the business needs and if a single user has a specific request evaluate the business need for it. That way the data warehouse is our source of truth.\n\n\nIdeally, what is the right way to use Looker?", "author_fullname": "t2_2q171de9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does Looker fit into the data stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119ailf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677096297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently joined a company who is doing the majority of data transformation in lookml.  Seems like there are 2 reasons for this from what I&amp;#39;m told:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Every end user wants a different level of aggregation and that would require creating duplicative tables in Snowflake (think something like marketing wants product level, finance wants order level, but user specific not business specific)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;If we change the data structure of a table that would require a lot of maintenance in Snowflake &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m very self taught and still very much a beginner so I&amp;#39;m looking for a sanity check. My thought is having a solid groundwork laid out in Snowflake is going to solve the majority of those concerns. Define the aggregate levels by the business needs and if a single user has a specific request evaluate the business need for it. That way the data warehouse is our source of truth.&lt;/p&gt;\n\n&lt;p&gt;Ideally, what is the right way to use Looker?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119ailf", "is_robot_indexable": true, "report_reasons": null, "author": "lahma_mama", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119ailf/where_does_looker_fit_into_the_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119ailf/where_does_looker_fit_into_the_data_stack/", "subreddit_subscribers": 90836, "created_utc": 1677096297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have spend the better part of the past two weeks reading about data engineering (and MLOps). The space seems to be dominated by Python-based workflows and tools like Apache Airflow, Dagster, MLFlow etc", "author_fullname": "t2_srfmey5u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should data engineering be done in a non-Python organization that is dominated by C#/.Net developers and data science people who prefer R?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119hqbf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677108845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have spend the better part of the past two weeks reading about data engineering (and MLOps). The space seems to be dominated by Python-based workflows and tools like Apache Airflow, Dagster, MLFlow etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119hqbf", "is_robot_indexable": true, "report_reasons": null, "author": "gheex", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119hqbf/how_should_data_engineering_be_done_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119hqbf/how_should_data_engineering_be_done_in_a/", "subreddit_subscribers": 90836, "created_utc": 1677108845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently researching Unity Catalog for my organization. We have 3 storage account data lakes, one for dev test and prod. We currently mount the appropriate account to our Databricks workspace and so all the paths to tables are constant in our code, and we don\u2019t have to specify which to use when our pipelines run. \n\nWith the switch to Unity Catalog, I am wondering how people specify which catalog to use? Do you have a variable that gets set in the the release? Do you specify a \u201cuse catalog name\u201d somewhere before running a pipeline? Any advice is appreciated!", "author_fullname": "t2_1yo0xaq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unity Catalog and CI/CD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119et7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677102545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently researching Unity Catalog for my organization. We have 3 storage account data lakes, one for dev test and prod. We currently mount the appropriate account to our Databricks workspace and so all the paths to tables are constant in our code, and we don\u2019t have to specify which to use when our pipelines run. &lt;/p&gt;\n\n&lt;p&gt;With the switch to Unity Catalog, I am wondering how people specify which catalog to use? Do you have a variable that gets set in the the release? Do you specify a \u201cuse catalog name\u201d somewhere before running a pipeline? Any advice is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119et7b", "is_robot_indexable": true, "report_reasons": null, "author": "justanator101", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119et7b/unity_catalog_and_cicd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119et7b/unity_catalog_and_cicd/", "subreddit_subscribers": 90836, "created_utc": 1677102545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I enjoyed listening to this 30-minute [Data Engineering Podcast](https://www.dataengineeringpodcast.com/six-year-retrospective-episode-361?t=57) episode with its summary of the ecosystem today. The commentary on how we got here too was interesting. \n\nIf you've listened to it do you agree with the summary, or did he miss anything important out?", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Podcast] \ud83c\udfa7 A useful summary of the data engineering ecosystem today", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1195xdc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677087629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I enjoyed listening to this 30-minute &lt;a href=\"https://www.dataengineeringpodcast.com/six-year-retrospective-episode-361?t=57\"&gt;Data Engineering Podcast&lt;/a&gt; episode with its summary of the ecosystem today. The commentary on how we got here too was interesting. &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve listened to it do you agree with the summary, or did he miss anything important out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?auto=webp&amp;v=enabled&amp;s=e23e22e97e3722d0f8f9a61615e50ebcb3fa1826", "width": 1400, "height": 1400}, "resolutions": [{"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9da709a3840cf93e0a7b0b851bac03e773481d2b", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=358185c1b969237f260a000561002ac68e71b2dd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=142a7305c615c834abda063fa9659d4312a4db7f", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8482cb9ec4aa7be58a4defea83030c21e651314f", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1672edce28c8d7b5be11836f2e364a11b78dacb7", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d6af140426178eebb01eca44ec153b253ef8cd1", "width": 1080, "height": 1080}], "variants": {}, "id": "T69lnyzJjP6GC8oxXuuJPHNQnXgo_9t63cJnvtec6xw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1195xdc", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1195xdc/podcast_a_useful_summary_of_the_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1195xdc/podcast_a_useful_summary_of_the_data_engineering/", "subreddit_subscribers": 90836, "created_utc": 1677087629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you have defined some SLOs on your data? Meaning for example you guarantee your users dataset XYZ will have no more than 5% NULL values in column ABC? If so, how do you present it to the user? Is it e.g. part of the data catalog?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data products SLO", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11960zu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677087868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you have defined some SLOs on your data? Meaning for example you guarantee your users dataset XYZ will have no more than 5% NULL values in column ABC? If so, how do you present it to the user? Is it e.g. part of the data catalog?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11960zu", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11960zu/data_products_slo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11960zu/data_products_slo/", "subreddit_subscribers": 90836, "created_utc": 1677087868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a table with complex type such as array of dictionaries . I would need to flatten the table  in such a way that every dictionary item value in a array shows as a separate column. How do I achieve this in spark or hive without exploding(and thereby increasing the rows) to multiple rows.\n\nTldr: sample data is A,B,[dict(key1=\"Col3\",value1=\"col3_value\"),dict(key1=\"Col4\",value1=\"col4_value\")].\n\nFinal expected result:\nCol1,col2,col3,col4\nA,B,col3_value,col4_value", "author_fullname": "t2_9fhhwjm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to solve this with hive or spark?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119xrc4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677159046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a table with complex type such as array of dictionaries . I would need to flatten the table  in such a way that every dictionary item value in a array shows as a separate column. How do I achieve this in spark or hive without exploding(and thereby increasing the rows) to multiple rows.&lt;/p&gt;\n\n&lt;p&gt;Tldr: sample data is A,B,[dict(key1=&amp;quot;Col3&amp;quot;,value1=&amp;quot;col3_value&amp;quot;),dict(key1=&amp;quot;Col4&amp;quot;,value1=&amp;quot;col4_value&amp;quot;)].&lt;/p&gt;\n\n&lt;p&gt;Final expected result:\nCol1,col2,col3,col4\nA,B,col3_value,col4_value&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "119xrc4", "is_robot_indexable": true, "report_reasons": null, "author": "cieloskyg", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119xrc4/how_to_solve_this_with_hive_or_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119xrc4/how_to_solve_this_with_hive_or_spark/", "subreddit_subscribers": 90836, "created_utc": 1677159046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks!   \n\n\nI work on a logistics startup that currently relies on Superset and Power BI as viz toolings. Superset works as self-service BI, while Power BI has an extra layer of validation by the BI team. \n\nI would like to know if you use tools like **Redash**, **Superset** or **Metabase**, what do you do to extract the most from them? Do you have a routine in place to keep the tools clean? Or somehow certify Dashboards official?", "author_fullname": "t2_ijp90vxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How your company uses Superset? Is it on a big scale?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119wc2e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677154698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks!   &lt;/p&gt;\n\n&lt;p&gt;I work on a logistics startup that currently relies on Superset and Power BI as viz toolings. Superset works as self-service BI, while Power BI has an extra layer of validation by the BI team. &lt;/p&gt;\n\n&lt;p&gt;I would like to know if you use tools like &lt;strong&gt;Redash&lt;/strong&gt;, &lt;strong&gt;Superset&lt;/strong&gt; or &lt;strong&gt;Metabase&lt;/strong&gt;, what do you do to extract the most from them? Do you have a routine in place to keep the tools clean? Or somehow certify Dashboards official?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "119wc2e", "is_robot_indexable": true, "report_reasons": null, "author": "CzarSantos98", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119wc2e/how_your_company_uses_superset_is_it_on_a_big/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119wc2e/how_your_company_uses_superset_is_it_on_a_big/", "subreddit_subscribers": 90836, "created_utc": 1677154698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In VSCode,the colorizer feature,\n\n ([@id](https://github.com/id):editor.bracketPairColorization.enabled [@id](https://github.com/id):editor.guides.bracketPairs) \n\ndoes not work for brackets inside strings for ex: scores in (), greatest (), cast() etc. The example provided below is very basic, but we've run into nested functions that span &gt; 10 lines which makes debugging difficult. This would be very helpful to a lot of engineers who use sql/jinja. \n\n&amp;#x200B;\n\nhttps://preview.redd.it/bdl9glzcyuja1.png?width=733&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0df85a635fa49a48208b518ea7c57fe8657eaef2\n\nI created an issue for this feature on the official VSCode Github , \n\n[https://github.com/microsoft/vscode/issues/169649](https://github.com/microsoft/vscode/issues/169649)\n\n&amp;#x200B;\n\nIt requires 20 votes for it to move it to their backlog. If you find this would be helpful, please upvote it on github  \n(more on upvoting here: [https://github.com/microsoft/vscode/wiki/Issues-Triaging#up-voting-a-feature-request](https://github.com/microsoft/vscode/wiki/Issues-Triaging#up-voting-a-feature-request))", "author_fullname": "t2_5rikt61xq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bracket Pair Colorizer for SQL - VSCode issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "media_metadata": {"bdl9glzcyuja1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 74, "x": 108, "u": "https://preview.redd.it/bdl9glzcyuja1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=414f2f2e2a175ed9f5f488dac842aa05835d0df1"}, {"y": 149, "x": 216, "u": "https://preview.redd.it/bdl9glzcyuja1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=888f9acb467f86766ec4bd54d06812bff16cb0da"}, {"y": 221, "x": 320, "u": "https://preview.redd.it/bdl9glzcyuja1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9eedc1f55b572f5dec02d33a88172d47fb407a5"}, {"y": 442, "x": 640, "u": "https://preview.redd.it/bdl9glzcyuja1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0266046deeea13439e0e6d664f2fa31f9c00bcb0"}], "s": {"y": 507, "x": 733, "u": "https://preview.redd.it/bdl9glzcyuja1.png?width=733&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0df85a635fa49a48208b518ea7c57fe8657eaef2"}, "id": "bdl9glzcyuja1"}}, "name": "t3_119na3a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b32GTmNvzTSoMHbew6yaoKUffq22YJ4yrtm6BLCeMHk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1677123247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In VSCode,the colorizer feature,&lt;/p&gt;\n\n&lt;p&gt;(&lt;a href=\"https://github.com/id\"&gt;@id&lt;/a&gt;:editor.bracketPairColorization.enabled &lt;a href=\"https://github.com/id\"&gt;@id&lt;/a&gt;:editor.guides.bracketPairs) &lt;/p&gt;\n\n&lt;p&gt;does not work for brackets inside strings for ex: scores in (), greatest (), cast() etc. The example provided below is very basic, but we&amp;#39;ve run into nested functions that span &amp;gt; 10 lines which makes debugging difficult. This would be very helpful to a lot of engineers who use sql/jinja. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bdl9glzcyuja1.png?width=733&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0df85a635fa49a48208b518ea7c57fe8657eaef2\"&gt;https://preview.redd.it/bdl9glzcyuja1.png?width=733&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0df85a635fa49a48208b518ea7c57fe8657eaef2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I created an issue for this feature on the official VSCode Github , &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/microsoft/vscode/issues/169649\"&gt;https://github.com/microsoft/vscode/issues/169649&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It requires 20 votes for it to move it to their backlog. If you find this would be helpful, please upvote it on github&lt;br/&gt;\n(more on upvoting here: &lt;a href=\"https://github.com/microsoft/vscode/wiki/Issues-Triaging#up-voting-a-feature-request\"&gt;https://github.com/microsoft/vscode/wiki/Issues-Triaging#up-voting-a-feature-request&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ghVpdNpMmwiBDZW_KhU3rfCPHnN-8y_NZ9Elg-wRm04.jpg?auto=webp&amp;v=enabled&amp;s=6dd45d060d304a95d84693ac89a3463494910530", "width": 336, "height": 336}, "resolutions": [{"url": "https://external-preview.redd.it/ghVpdNpMmwiBDZW_KhU3rfCPHnN-8y_NZ9Elg-wRm04.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd83866d1749754918daa4b1d42d8da603983899", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ghVpdNpMmwiBDZW_KhU3rfCPHnN-8y_NZ9Elg-wRm04.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0c884a660b38a41899fb3b5e3e3308d51e7e9ec", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/ghVpdNpMmwiBDZW_KhU3rfCPHnN-8y_NZ9Elg-wRm04.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f19d55525044730593b95c0af01f089482efa199", "width": 320, "height": 320}], "variants": {}, "id": "wWaXLNqFaTps7pGrJM9prEG2Htb0x9UlwSG11gTLPCc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "119na3a", "is_robot_indexable": true, "report_reasons": null, "author": "KangarOOCase", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119na3a/bracket_pair_colorizer_for_sql_vscode_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119na3a/bracket_pair_colorizer_for_sql_vscode_issue/", "subreddit_subscribers": 90836, "created_utc": 1677123247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently finished my internship as a juco student at an MNC and have tapped on a bit of data engineering work in terms of data wrangling, activation, preparation, migration. Not so much about building pipelines.\n\nPrior to that, I didn't have much experience and this internship opportunity has allowed me to discover an interest into this field. As I have a short break before the next steps into my career, I want to get more involved into the aspects of data engineering (build pipelines etc) and embark on some basic projects.\n\nI am mainly proficient in Python. \n\nWhat are the resources that I can seek for pertaining to data engineering?", "author_fullname": "t2_czigz4m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Side Project Ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119hdb5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677107994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently finished my internship as a juco student at an MNC and have tapped on a bit of data engineering work in terms of data wrangling, activation, preparation, migration. Not so much about building pipelines.&lt;/p&gt;\n\n&lt;p&gt;Prior to that, I didn&amp;#39;t have much experience and this internship opportunity has allowed me to discover an interest into this field. As I have a short break before the next steps into my career, I want to get more involved into the aspects of data engineering (build pipelines etc) and embark on some basic projects.&lt;/p&gt;\n\n&lt;p&gt;I am mainly proficient in Python. &lt;/p&gt;\n\n&lt;p&gt;What are the resources that I can seek for pertaining to data engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119hdb5", "is_robot_indexable": true, "report_reasons": null, "author": "NotYule", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119hdb5/beginner_side_project_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119hdb5/beginner_side_project_ideas/", "subreddit_subscribers": 90836, "created_utc": 1677107994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently working for a mid size tech company. The Data Science team I\u2019m a part of, is in its infancy and there is not a lot of direction from my team lead. The current senior data engineer is not very helpful in most situations as he is usually swamped with requests and I have a feeling the person is planning to leave soon. This would put a lot more pressure on my shoulders. I have Business Intelligence and Software Development experience (about 8 years overall) but I\u2019ve recently internally moved into the Data Engineer position. This team heavily uses Spark, Scala and Kafka. I haven\u2019t worked on these technologies before. With the lack of clear leadership in my team, I\u2019m struggling to learn anything. What resources in terms of blogs/YouTube/tutorials/books can I use to be ready for a senior role if it comes to that? Thank you for any information you guys can share.", "author_fullname": "t2_1reibdu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources/Books that help transition into a Senior Data Engineering role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1199ilk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677094879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently working for a mid size tech company. The Data Science team I\u2019m a part of, is in its infancy and there is not a lot of direction from my team lead. The current senior data engineer is not very helpful in most situations as he is usually swamped with requests and I have a feeling the person is planning to leave soon. This would put a lot more pressure on my shoulders. I have Business Intelligence and Software Development experience (about 8 years overall) but I\u2019ve recently internally moved into the Data Engineer position. This team heavily uses Spark, Scala and Kafka. I haven\u2019t worked on these technologies before. With the lack of clear leadership in my team, I\u2019m struggling to learn anything. What resources in terms of blogs/YouTube/tutorials/books can I use to be ready for a senior role if it comes to that? Thank you for any information you guys can share.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1199ilk", "is_robot_indexable": true, "report_reasons": null, "author": "luckykanwar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1199ilk/resourcesbooks_that_help_transition_into_a_senior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1199ilk/resourcesbooks_that_help_transition_into_a_senior/", "subreddit_subscribers": 90836, "created_utc": 1677094879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey,\n\n I got might get a scholarship from [Turing College's Data Engineering course](https://www.turingcollege.com/data-engineering) \\- which comes with an obligation to accept a DE job from their partner companies. If no offer given within 1 month after finishing the course (around 8 months duration), you can apply to other companies as well. Fair, but though. I would need to accept a Data Engineering position with the pay levels they advertise (50k\u20ac), after graduation.\n\nWould you rather\u2026\n\n* ...stick to [self-curated curriculum](https://binchentso.notion.site/My-learning-path-516014e8d523457cbb277c9e2f00e409) aligned with a DE mentor, using the slack time at my current role to work on portfolio projects?\n* ...or follow up with the Turing College course, for 6\u20138 months and afterward have the chance to land a job with their hiring partners?", "author_fullname": "t2_9v9dakww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Self-curated curriculum vs. Turing College | Data Engineer in training", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_11a13ge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677167900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I got might get a scholarship from &lt;a href=\"https://www.turingcollege.com/data-engineering\"&gt;Turing College&amp;#39;s Data Engineering course&lt;/a&gt; - which comes with an obligation to accept a DE job from their partner companies. If no offer given within 1 month after finishing the course (around 8 months duration), you can apply to other companies as well. Fair, but though. I would need to accept a Data Engineering position with the pay levels they advertise (50k\u20ac), after graduation.&lt;/p&gt;\n\n&lt;p&gt;Would you rather\u2026&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;...stick to &lt;a href=\"https://binchentso.notion.site/My-learning-path-516014e8d523457cbb277c9e2f00e409\"&gt;self-curated curriculum&lt;/a&gt; aligned with a DE mentor, using the slack time at my current role to work on portfolio projects?&lt;/li&gt;\n&lt;li&gt;...or follow up with the Turing College course, for 6\u20138 months and afterward have the chance to land a job with their hiring partners?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KPEAGoZ2QYkiiV9psiCaDhpnUCbzJ_Y1e4Lytbi71a4.jpg?auto=webp&amp;v=enabled&amp;s=df68ae1816dc7afdf03ee42537ebb0b71aacabcb", "width": 2400, "height": 1254}, "resolutions": [{"url": "https://external-preview.redd.it/KPEAGoZ2QYkiiV9psiCaDhpnUCbzJ_Y1e4Lytbi71a4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3bb2164dd8b8974933cbe4b231a8477df4f32097", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/KPEAGoZ2QYkiiV9psiCaDhpnUCbzJ_Y1e4Lytbi71a4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ccd665a3aea84b67300a43e71c0a49fb8b49a715", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/KPEAGoZ2QYkiiV9psiCaDhpnUCbzJ_Y1e4Lytbi71a4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=beffcdca2b7995bee20a409769a64d46f43ff5ce", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/KPEAGoZ2QYkiiV9psiCaDhpnUCbzJ_Y1e4Lytbi71a4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=11ea4960f04d10d36ba6bd388fada31e58ba1825", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/KPEAGoZ2QYkiiV9psiCaDhpnUCbzJ_Y1e4Lytbi71a4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=31bfc7b9868fcd83a8c8798e05af9af474a2f682", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/KPEAGoZ2QYkiiV9psiCaDhpnUCbzJ_Y1e4Lytbi71a4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=82c9ac111fe09001c54f00087a00654e84a211e8", "width": 1080, "height": 564}], "variants": {}, "id": "XqCbOvusBXQkcj77ZU8r51MvvlCHrNaKfTmnqOakYNI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data &amp; Analytics Engineer in training", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "11a13ge", "is_robot_indexable": true, "report_reasons": null, "author": "binchentso", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11a13ge/selfcurated_curriculum_vs_turing_college_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11a13ge/selfcurated_curriculum_vs_turing_college_data/", "subreddit_subscribers": 90836, "created_utc": 1677167900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&gt;The **Bronze layer** is where we land all the data from external source systems. The table structures in this layer correspond to the source system table structures \"as-is,\" along with any additional metadata columns that capture the load date/time, process ID, etc. The focus in this layer is quick Change Data Capture and the ability to provide an historical archive of source (cold storage), data lineage, auditability, reprocessing if needed without rereading the data from the source system.\n\n[Databricks Guide on Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)\n\n[View Poll](https://www.reddit.com/poll/11a0cmf)", "author_fullname": "t2_txvugrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you follow Medallion Architecture and utilize Bronze layer storage for ingested data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11a0cmf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677166004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;The &lt;strong&gt;Bronze layer&lt;/strong&gt; is where we land all the data from external source systems. The table structures in this layer correspond to the source system table structures &amp;quot;as-is,&amp;quot; along with any additional metadata columns that capture the load date/time, process ID, etc. The focus in this layer is quick Change Data Capture and the ability to provide an historical archive of source (cold storage), data lineage, auditability, reprocessing if needed without rereading the data from the source system.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.databricks.com/glossary/medallion-architecture\"&gt;Databricks Guide on Medallion Architecture&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/poll/11a0cmf\"&gt;View Poll&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?auto=webp&amp;v=enabled&amp;s=15e7319434e1e103352a37e7fabfbd9456a168ef", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1176850e76031e71bb122f9c353101bd7abe6bf", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=429d70d1e08de4ce9c49426ac4caa101f4c3e264", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29cde5f1616959571c9b58b8c1c1900201c77f7e", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=83b58b543aa8701ba0a87a3198960697d53ff22c", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dfd2d8ab37cf854034f841dea22a655dc91a5f3b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/oXmGBjnOGbMLNj6ZyveOgQGOrgxxEmgC0EwkH-pffPo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47ceb6115a4ccc0e21696967727505ec48f78f37", "width": 1080, "height": 567}], "variants": {}, "id": "RDPFo3n-9ZSpTUT0k9sCNnHc7tSD0wBu2TyDFfITIDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Company", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11a0cmf", "is_robot_indexable": true, "report_reasons": null, "author": "prequel_co", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "poll_data": {"prediction_status": null, "total_stake_amount": null, "voting_end_timestamp": 1677425204031, "options": [{"text": "Yes, but stored without schemas (JSON blobs of each row, CSVs, etc)", "id": "21744110"}, {"text": "Yes, but typed (Parquet/Avro/Table/etc)", "id": "21744111"}, {"text": "No", "id": "21744112"}, {"text": "Other (Add comment)", "id": "21744113"}, {"text": "See Results", "id": "21744114"}], "vote_updates_remained": null, "is_prediction": false, "resolved_option_id": null, "user_won_amount": null, "user_selection": null, "total_vote_count": 26, "tournament_id": null}, "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/11a0cmf/do_you_follow_medallion_architecture_and_utilize/", "parent_whitelist_status": "all_ads", "stickied": false, "mod_reports": [], "url": "https://old.reddit.com/r/dataengineering/comments/11a0cmf/do_you_follow_medallion_architecture_and_utilize/", "subreddit_subscribers": 90836, "created_utc": 1677166004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After having worked at different companies, at different sizes and needs. The larger companies seem to keep building pipeline, with lots of duplicated code, deployment scripts, versioning scripts, CI pipelines etc for each process in their business.\n\nThere is a common theme in places where I have worked, where people tend to think of things as either a batch or a stream. Now, given Kafka is embraced at your company and event streaming is implemented heavily. Why not just treat the batch data sources as a stream? By this I mean, just model the pipeline as a producer to a topic and then go on about your transformations. (Confluent's kSQL fb and Connectors help a lot with this).\n\nTime and time again, I keep seeing a lot of re inventing because of the decision to separate the two. It seems much easier, (perhaps with hindsight) to treat data as a first-class citizen and write less code to just produce and consume messages with the data itself, at a record level and use fan-out accordingly. This way the workflow or orchestration is embedded within the services and how they operate. This requires no need for DAGs or step function configurations. Granted this is usually best for one domain where it is appropriate.\n\nWhat is your take? There are of course edge cases and different approaches based on you business needs. But I think simply embracing the architecture of kafka and allowing services to easily plug in to a topic and do a certain transformation at the record level, makes things much easier to reason about.   \n\n\nFor example, SFTP files to an athena table can be simplified greatly.\n\nSpecifically from:\n\n\\-&gt; Poll (x source) (Python Application) -&gt; S3 -&gt; Spark (EMR) Hudi Table -&gt; Athena -&gt; Consumption\n\nExtra configuration (Check state of source, Metrics, Obersvability, Workflow Code (Airflow DAGs, Deployment Code etc)\n\nto:\n\n\\-&gt; Kafka Connector (source) -&gt; Topic -&gt; kSQL DB/Consumer -&gt; Sink\n\nPerhaps I am missing some details but for simpler integrations it seems easier to follow this logic. Where your data is pushed through and is masked (PII). Instead of pushing references to data and then orchestrating each workflow and for each case.", "author_fullname": "t2_7jhnfjx5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your thoughts on thinking of everything as a stream and not a batch?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119xan6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677157717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After having worked at different companies, at different sizes and needs. The larger companies seem to keep building pipeline, with lots of duplicated code, deployment scripts, versioning scripts, CI pipelines etc for each process in their business.&lt;/p&gt;\n\n&lt;p&gt;There is a common theme in places where I have worked, where people tend to think of things as either a batch or a stream. Now, given Kafka is embraced at your company and event streaming is implemented heavily. Why not just treat the batch data sources as a stream? By this I mean, just model the pipeline as a producer to a topic and then go on about your transformations. (Confluent&amp;#39;s kSQL fb and Connectors help a lot with this).&lt;/p&gt;\n\n&lt;p&gt;Time and time again, I keep seeing a lot of re inventing because of the decision to separate the two. It seems much easier, (perhaps with hindsight) to treat data as a first-class citizen and write less code to just produce and consume messages with the data itself, at a record level and use fan-out accordingly. This way the workflow or orchestration is embedded within the services and how they operate. This requires no need for DAGs or step function configurations. Granted this is usually best for one domain where it is appropriate.&lt;/p&gt;\n\n&lt;p&gt;What is your take? There are of course edge cases and different approaches based on you business needs. But I think simply embracing the architecture of kafka and allowing services to easily plug in to a topic and do a certain transformation at the record level, makes things much easier to reason about.   &lt;/p&gt;\n\n&lt;p&gt;For example, SFTP files to an athena table can be simplified greatly.&lt;/p&gt;\n\n&lt;p&gt;Specifically from:&lt;/p&gt;\n\n&lt;p&gt;-&amp;gt; Poll (x source) (Python Application) -&amp;gt; S3 -&amp;gt; Spark (EMR) Hudi Table -&amp;gt; Athena -&amp;gt; Consumption&lt;/p&gt;\n\n&lt;p&gt;Extra configuration (Check state of source, Metrics, Obersvability, Workflow Code (Airflow DAGs, Deployment Code etc)&lt;/p&gt;\n\n&lt;p&gt;to:&lt;/p&gt;\n\n&lt;p&gt;-&amp;gt; Kafka Connector (source) -&amp;gt; Topic -&amp;gt; kSQL DB/Consumer -&amp;gt; Sink&lt;/p&gt;\n\n&lt;p&gt;Perhaps I am missing some details but for simpler integrations it seems easier to follow this logic. Where your data is pushed through and is masked (PII). Instead of pushing references to data and then orchestrating each workflow and for each case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "119xan6", "is_robot_indexable": true, "report_reasons": null, "author": "the_real_tobo", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119xan6/what_are_your_thoughts_on_thinking_of_everything/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119xan6/what_are_your_thoughts_on_thinking_of_everything/", "subreddit_subscribers": 90836, "created_utc": 1677157717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[This article](https://medium.com/everything-full-stack/action-position-data-quality-assessment-framework-d833f6b77b7) is a nice summary of different patterns for dealing with DQ issues. It got me to wondering: what (or even *if*) people tend to do with data quality errors? \n\nDo you use Write-Audit-Publish? Just ignore the errors? Not even check for DQ and wait until users start to scream?\u2026", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do *you* implement data quality in your pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119x43k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677157190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://medium.com/everything-full-stack/action-position-data-quality-assessment-framework-d833f6b77b7\"&gt;This article&lt;/a&gt; is a nice summary of different patterns for dealing with DQ issues. It got me to wondering: what (or even &lt;em&gt;if&lt;/em&gt;) people tend to do with data quality errors? &lt;/p&gt;\n\n&lt;p&gt;Do you use Write-Audit-Publish? Just ignore the errors? Not even check for DQ and wait until users start to scream?\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gYWTe07z3ri27fN9NarOSIXF6PfDL2jjCtQnEHyFRwA.jpg?auto=webp&amp;v=enabled&amp;s=39aec5dfc16d1e4ae17045f2d7d70d73355a13af", "width": 785, "height": 728}, "resolutions": [{"url": "https://external-preview.redd.it/gYWTe07z3ri27fN9NarOSIXF6PfDL2jjCtQnEHyFRwA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7294aa8fb39ec073993e20336f03ccb896c909ad", "width": 108, "height": 100}, {"url": "https://external-preview.redd.it/gYWTe07z3ri27fN9NarOSIXF6PfDL2jjCtQnEHyFRwA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d81961ca0665d92b74e24fc5026f076840b0233d", "width": 216, "height": 200}, {"url": "https://external-preview.redd.it/gYWTe07z3ri27fN9NarOSIXF6PfDL2jjCtQnEHyFRwA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=639b9bb187d5aee4fc8cfeb506ce07ec645c6d95", "width": 320, "height": 296}, {"url": "https://external-preview.redd.it/gYWTe07z3ri27fN9NarOSIXF6PfDL2jjCtQnEHyFRwA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0f96b3288b28b4a13363a07f45117094b4671108", "width": 640, "height": 593}], "variants": {}, "id": "EtMVakfqU2sDntG3RUUPf0qPToPTaAd3rB7HkaZsRIE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "119x43k", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119x43k/how_do_you_implement_data_quality_in_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119x43k/how_do_you_implement_data_quality_in_your/", "subreddit_subscribers": 90836, "created_utc": 1677157190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have little experience myself with DAGs so please correct me if I'm wrong, but I get the feeling that there's a good amount of DE practitioners that doesn't like DAGs.\n\nThe feeling is reinforced by my current experience with Prefect, which seems to make the fact that it doesn't use DAGs one of their selling points (e.g. https://www.prefect.io/guide/blog/workflow-orchestration-without-dags/)\n\nWhat's the deal? What am I missing?", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's wrong with DAGs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119wyu1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677156735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have little experience myself with DAGs so please correct me if I&amp;#39;m wrong, but I get the feeling that there&amp;#39;s a good amount of DE practitioners that doesn&amp;#39;t like DAGs.&lt;/p&gt;\n\n&lt;p&gt;The feeling is reinforced by my current experience with Prefect, which seems to make the fact that it doesn&amp;#39;t use DAGs one of their selling points (e.g. &lt;a href=\"https://www.prefect.io/guide/blog/workflow-orchestration-without-dags/\"&gt;https://www.prefect.io/guide/blog/workflow-orchestration-without-dags/&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the deal? What am I missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Mhjpb6z8Gun8-vNr0i6aPYtzDViWPofEeLUVIx3EX9k.jpg?auto=webp&amp;v=enabled&amp;s=547594bb7ad1461e2bf376971cdf95a74f1db4d2", "width": 6930, "height": 4220}, "resolutions": [{"url": "https://external-preview.redd.it/Mhjpb6z8Gun8-vNr0i6aPYtzDViWPofEeLUVIx3EX9k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3a957033059ab0398722232920683d08838f596a", "width": 108, "height": 65}, {"url": "https://external-preview.redd.it/Mhjpb6z8Gun8-vNr0i6aPYtzDViWPofEeLUVIx3EX9k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=84decadd5dfee4b9d747e77e10a678f0bfab0d9d", "width": 216, "height": 131}, {"url": "https://external-preview.redd.it/Mhjpb6z8Gun8-vNr0i6aPYtzDViWPofEeLUVIx3EX9k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad3d118771a2f5516054663ffee041741d83b000", "width": 320, "height": 194}, {"url": "https://external-preview.redd.it/Mhjpb6z8Gun8-vNr0i6aPYtzDViWPofEeLUVIx3EX9k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=285b88fd76ca6cb55d0eaee34d6d8326d1eeba32", "width": 640, "height": 389}, {"url": "https://external-preview.redd.it/Mhjpb6z8Gun8-vNr0i6aPYtzDViWPofEeLUVIx3EX9k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=119a69e1370db6e473c0f3edbbbea4890b69e281", "width": 960, "height": 584}, {"url": "https://external-preview.redd.it/Mhjpb6z8Gun8-vNr0i6aPYtzDViWPofEeLUVIx3EX9k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=521052318c5d7fd560d892a96b70506c103b8440", "width": 1080, "height": 657}], "variants": {}, "id": "i8z4NJBB0EQA17Rwbx0Uu43Y6kWtvPxTeve2tIChgrI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "119wyu1", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119wyu1/whats_wrong_with_dags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119wyu1/whats_wrong_with_dags/", "subreddit_subscribers": 90836, "created_utc": 1677156735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI\u2019m the son of a restaurant owner. I basically wait on tables, clean dishes, and maybe chop up some of the veggies.\n\nI did go university and study maths or computer science.\n\nAnyways, I\u2019m kind of making a unified data platform. So we can understand all of our costs, customers, and marketing we do.\n\nI\u2019m trying to automate as much as possible (I\u2019m not an amazing coder).\n\nSo far I\u2019ve got AirByte doing the pulling of data via these things called APIs, I got the data going into a storage place Heroku, and I got this process running by itself with a thing called Dagster.\n\nI got a bunch of sources like deliveroo, facebook, wordpress, and accounting systems.\n\nI\u2019m getting to the stage I gotta do data architecture/modelling and I was wondering if there anything out there that can help make recommendation of what the data model should look like and I can review and edit it.\n\nThe plan afterwards is to get Grafana and h20 so I can represent the current state of the restaurant and maybe predict future revenue.\n\nI ask people who I went to school with and they keep telling me to leave and become an engineer. I\u2019m a restaurant boy but just wanna get this bit right!\n\nThank you everyone", "author_fullname": "t2_5i7ldi97v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there anything out there that can automate data architecture modelling?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119uj2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677148253.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m the son of a restaurant owner. I basically wait on tables, clean dishes, and maybe chop up some of the veggies.&lt;/p&gt;\n\n&lt;p&gt;I did go university and study maths or computer science.&lt;/p&gt;\n\n&lt;p&gt;Anyways, I\u2019m kind of making a unified data platform. So we can understand all of our costs, customers, and marketing we do.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to automate as much as possible (I\u2019m not an amazing coder).&lt;/p&gt;\n\n&lt;p&gt;So far I\u2019ve got AirByte doing the pulling of data via these things called APIs, I got the data going into a storage place Heroku, and I got this process running by itself with a thing called Dagster.&lt;/p&gt;\n\n&lt;p&gt;I got a bunch of sources like deliveroo, facebook, wordpress, and accounting systems.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m getting to the stage I gotta do data architecture/modelling and I was wondering if there anything out there that can help make recommendation of what the data model should look like and I can review and edit it.&lt;/p&gt;\n\n&lt;p&gt;The plan afterwards is to get Grafana and h20 so I can represent the current state of the restaurant and maybe predict future revenue.&lt;/p&gt;\n\n&lt;p&gt;I ask people who I went to school with and they keep telling me to leave and become an engineer. I\u2019m a restaurant boy but just wanna get this bit right!&lt;/p&gt;\n\n&lt;p&gt;Thank you everyone&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119uj2h", "is_robot_indexable": true, "report_reasons": null, "author": "biltor-pol", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119uj2h/is_there_anything_out_there_that_can_automate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119uj2h/is_there_anything_out_there_that_can_automate/", "subreddit_subscribers": 90836, "created_utc": 1677148253.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I've been a DBA for about 8 years now (currently an MSSQL DBA), and I'm looking to learn more about data engineering and other, non-RDBMS systems. \n\nFor a first project, I want to do some basic extraction of data from various apis/web scraping, load it into a data warehouse (either directly into a traditional DW or use parquet files for a data lake). I put together the first steps of such on GCS using python scripts, duckdb, cloud storage and BigQuery. However, I'm not sure if given my background on the Microsoft side of things. This makes me think that I might want to focus on learning Azure, but looking over Synapse, I'm not sure how I feel about it, as it doesn't seem as simple as BigQuery did to me at first, as ADLS gen2 seems a bit odd, as my current parquet files aren't split down into many files, which seems to be the way to go for ADLS?\n\nI thought about using Databricks, but I'm hesitant, as I can't find much about how much it'll cost me to use as a small DW for learning, and I don't have a free tier to use anymore (used it a few years back for basic learning).\n\nI'm thinking of maybe trying out a different DW, something like ClickHouse, and running that on an Azure VM, but I'm not sure if doing that is a good idea for learning, since it isn't an \"official\" Azure tool. Also considered SingleStore, but a VM large enough to self host it might be too much (the docs recommend 4 CPUs/4GB RAM.\n\n&amp;#x200B;\n\nI guess to give TLDR, I currently work as a DBA in the Microsoft Stack, and when trying to figure out where to start learning DE, I feel like Azure is a natural starting point, but I'm not sure if I'm a fan of Synapse at first, compared to my first impressions of BigQuery.\n\nThanks!", "author_fullname": "t2_ssh4888", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What stack to focus on for learning for my background?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119qxna", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677134613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;ve been a DBA for about 8 years now (currently an MSSQL DBA), and I&amp;#39;m looking to learn more about data engineering and other, non-RDBMS systems. &lt;/p&gt;\n\n&lt;p&gt;For a first project, I want to do some basic extraction of data from various apis/web scraping, load it into a data warehouse (either directly into a traditional DW or use parquet files for a data lake). I put together the first steps of such on GCS using python scripts, duckdb, cloud storage and BigQuery. However, I&amp;#39;m not sure if given my background on the Microsoft side of things. This makes me think that I might want to focus on learning Azure, but looking over Synapse, I&amp;#39;m not sure how I feel about it, as it doesn&amp;#39;t seem as simple as BigQuery did to me at first, as ADLS gen2 seems a bit odd, as my current parquet files aren&amp;#39;t split down into many files, which seems to be the way to go for ADLS?&lt;/p&gt;\n\n&lt;p&gt;I thought about using Databricks, but I&amp;#39;m hesitant, as I can&amp;#39;t find much about how much it&amp;#39;ll cost me to use as a small DW for learning, and I don&amp;#39;t have a free tier to use anymore (used it a few years back for basic learning).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of maybe trying out a different DW, something like ClickHouse, and running that on an Azure VM, but I&amp;#39;m not sure if doing that is a good idea for learning, since it isn&amp;#39;t an &amp;quot;official&amp;quot; Azure tool. Also considered SingleStore, but a VM large enough to self host it might be too much (the docs recommend 4 CPUs/4GB RAM.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I guess to give TLDR, I currently work as a DBA in the Microsoft Stack, and when trying to figure out where to start learning DE, I feel like Azure is a natural starting point, but I&amp;#39;m not sure if I&amp;#39;m a fan of Synapse at first, compared to my first impressions of BigQuery.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119qxna", "is_robot_indexable": true, "report_reasons": null, "author": "dontmakemeplaypool", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119qxna/what_stack_to_focus_on_for_learning_for_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119qxna/what_stack_to_focus_on_for_learning_for_my/", "subreddit_subscribers": 90836, "created_utc": 1677134613.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}