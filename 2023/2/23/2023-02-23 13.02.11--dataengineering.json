{"kind": "Listing", "data": {"after": "t3_119fzhj", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently on Azure datafactory (orcestration)  + Azure SQL database (ETL done using procedures + presentation layer). We tested databricks and liked the functionality so are utilizing that for newer ETL development. The company has decided to go to AWS so now we are exploring options there. \n\nSo my question to you would be which orcestration tools, databases/data warehouses, CICD tools are you using and why?", "author_fullname": "t2_4doyx62l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what does your company's current data landscape look like? Which tools and technologies did you go for and why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1191ia8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 80, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 80, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677077301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently on Azure datafactory (orcestration)  + Azure SQL database (ETL done using procedures + presentation layer). We tested databricks and liked the functionality so are utilizing that for newer ETL development. The company has decided to go to AWS so now we are exploring options there. &lt;/p&gt;\n\n&lt;p&gt;So my question to you would be which orcestration tools, databases/data warehouses, CICD tools are you using and why?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1191ia8", "is_robot_indexable": true, "report_reasons": null, "author": "fancyshamancy", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1191ia8/what_does_your_companys_current_data_landscape/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1191ia8/what_does_your_companys_current_data_landscape/", "subreddit_subscribers": 90648, "created_utc": 1677077301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone \ud83d\udc4b I\u2019m Ian \u2014 I used to work on data tooling at Stripe. My friend Justin (ex data science at Cruise) and I have been building a new free local editor made specifically for dbt core called Turntable ([https://www.turntable.so/](https://www.turntable.so/))\n\nI love VS Code and other local IDEs, but they don\u2019t have some core features I need for dbt development. Turntable has visual lineage, query preview, and more built in (quick [demo](https://www.loom.com/share/8db10268612d4769893123b00500ad35) below).\n\nNext, we\u2019re planning to explore column-level lineage and code/yaml autocomplete using AI. I\u2019d love to hear what you think and whether the problems / solution resonates. And if you want to try it out, comment or send me a DM\u2026 thanks!\n\n[https://www.loom.com/share/8db10268612d4769893123b00500ad35](https://www.loom.com/share/8db10268612d4769893123b00500ad35)", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a better local dbt experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119oxil", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1677130632.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677128125.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone \ud83d\udc4b I\u2019m Ian \u2014 I used to work on data tooling at Stripe. My friend Justin (ex data science at Cruise) and I have been building a new free local editor made specifically for dbt core called Turntable (&lt;a href=\"https://www.turntable.so/\"&gt;https://www.turntable.so/&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;I love VS Code and other local IDEs, but they don\u2019t have some core features I need for dbt development. Turntable has visual lineage, query preview, and more built in (quick &lt;a href=\"https://www.loom.com/share/8db10268612d4769893123b00500ad35\"&gt;demo&lt;/a&gt; below).&lt;/p&gt;\n\n&lt;p&gt;Next, we\u2019re planning to explore column-level lineage and code/yaml autocomplete using AI. I\u2019d love to hear what you think and whether the problems / solution resonates. And if you want to try it out, comment or send me a DM\u2026 thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.loom.com/share/8db10268612d4769893123b00500ad35\"&gt;https://www.loom.com/share/8db10268612d4769893123b00500ad35&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "119oxil", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119oxil/building_a_better_local_dbt_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119oxil/building_a_better_local_dbt_experience/", "subreddit_subscribers": 90648, "created_utc": 1677128125.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What tips &amp; tricks would you recommend to the beginner pandas users? What to definitely avoid?\n\n(I would like to provide a pandas workshop to our business users so collecting ideas)", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your best pandas tips&amp;tricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1199zm1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677095572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What tips &amp;amp; tricks would you recommend to the beginner pandas users? What to definitely avoid?&lt;/p&gt;\n\n&lt;p&gt;(I would like to provide a pandas workshop to our business users so collecting ideas)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1199zm1", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1199zm1/what_are_your_best_pandas_tipstricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1199zm1/what_are_your_best_pandas_tipstricks/", "subreddit_subscribers": 90648, "created_utc": 1677095572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Polars is getting pretty popular recently but I would like to know what pandas can do and polars still can not.\n\nE. g. I found polars cannot work efficiently with json (missing e.g. json_normalize function).", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What pandas can do and polars can\u2019t?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119a3vs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677095736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Polars is getting pretty popular recently but I would like to know what pandas can do and polars still can not.&lt;/p&gt;\n\n&lt;p&gt;E. g. I found polars cannot work efficiently with json (missing e.g. json_normalize function).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "119a3vs", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119a3vs/what_pandas_can_do_and_polars_cant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119a3vs/what_pandas_can_do_and_polars_cant/", "subreddit_subscribers": 90648, "created_utc": 1677095736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm building the modern data stack but curious if anyone uses Kafka. What use cases have you utilized it for and what stack have you integrated it with to get the most value out of this data that you're collecting?", "author_fullname": "t2_j1vd6s00", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using Kafka?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1194ppe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677084762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m building the modern data stack but curious if anyone uses Kafka. What use cases have you utilized it for and what stack have you integrated it with to get the most value out of this data that you&amp;#39;re collecting?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1194ppe", "is_robot_indexable": true, "report_reasons": null, "author": "crhumble", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1194ppe/anyone_using_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1194ppe/anyone_using_kafka/", "subreddit_subscribers": 90648, "created_utc": 1677084762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "dbt is getting pretty popular recently, but is it really that \u201cnecessary\u201d? I mean what are the added benefit of introducing new tool when you can do all transformations using python (polars, duckDB\u2026) + in python you can also do the \u201cextract\u201d step so basically you are able to cover entire ETL lifecycle with one tool? Also you can unit test your code better. As python disadvantage I see the dependency management. The only advantage of dbt I can see is you do not have to explicitly create tables as it creates it for you.", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is dbt really necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119s7yv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677139328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;dbt is getting pretty popular recently, but is it really that \u201cnecessary\u201d? I mean what are the added benefit of introducing new tool when you can do all transformations using python (polars, duckDB\u2026) + in python you can also do the \u201cextract\u201d step so basically you are able to cover entire ETL lifecycle with one tool? Also you can unit test your code better. As python disadvantage I see the dependency management. The only advantage of dbt I can see is you do not have to explicitly create tables as it creates it for you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "119s7yv", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119s7yv/is_dbt_really_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119s7yv/is_dbt_really_necessary/", "subreddit_subscribers": 90648, "created_utc": 1677139328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_em2yi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How I Decreased ETL Cost by Leveraging the Apache Arrow Ecosystem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "name": "t3_119g5nc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/QZH3QHnUFoosVA85lVKFbP13HNR91vebAHaKr_M4qCU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1677105257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "rcpassos.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://rcpassos.me/post/apache-arrow-future-of-data-engineering", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?auto=webp&amp;v=enabled&amp;s=0dbc90e7190608d0a5c7f3b79b3cc14dcf40e005", "width": 2048, "height": 1170}, "resolutions": [{"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9346544144f2d70bd9adf0c2d91e5037f1e1bb50", "width": 108, "height": 61}, {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=45759a1b653546d00c5c5eace4bbf344355bcc14", "width": 216, "height": 123}, {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c4e1c29f639231505e892e2d07b2e35afb9b80f", "width": 320, "height": 182}, {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=58b9cc2cf6daa644cca89de9c250f43bb88b6b73", "width": 640, "height": 365}, {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=143764eb76d7d1dcd28d1a82935d3f9ffdc93209", "width": 960, "height": 548}, {"url": "https://external-preview.redd.it/hiYMqBu6iaHtrs89QTU3Z0cevu_mdcbV6u5wa9WXVs4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d6dcdb61c28ea1a4275ccc32506478a736e4833", "width": 1080, "height": 616}], "variants": {}, "id": "aaEDVnIXM_-RMbLWzDpeO6CMM6TnSdzuUj2_DeBa8lk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "119g5nc", "is_robot_indexable": true, "report_reasons": null, "author": "auyer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119g5nc/how_i_decreased_etl_cost_by_leveraging_the_apache/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://rcpassos.me/post/apache-arrow-future-of-data-engineering", "subreddit_subscribers": 90648, "created_utc": 1677105257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All --\n\nI am not a data engineer -- I'm an analyst, but I use a very robust and convoluted data infrastructure built by a team of data engineers. The data infrastructure that I use on a day-to-day basis has almost no documentation regarding how the ETLs map to higher abstractions of unstructured data, nor really any good descriptions of source data systems underlying the ETL process.\n\n&amp;#x200B;\n\nDoes anyone know if there are any documentation frameworks for documenting this sort of thing? My goal is to reduce tribal knowledge of our data engineering team to make things more accessible for our analysts.\n\n&amp;#x200B;\n\nThanks!", "author_fullname": "t2_5b1wzyfu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to build documentation for a data infrastructure? any existing tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1195ts7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677087389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All --&lt;/p&gt;\n\n&lt;p&gt;I am not a data engineer -- I&amp;#39;m an analyst, but I use a very robust and convoluted data infrastructure built by a team of data engineers. The data infrastructure that I use on a day-to-day basis has almost no documentation regarding how the ETLs map to higher abstractions of unstructured data, nor really any good descriptions of source data systems underlying the ETL process.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anyone know if there are any documentation frameworks for documenting this sort of thing? My goal is to reduce tribal knowledge of our data engineering team to make things more accessible for our analysts.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1195ts7", "is_robot_indexable": true, "report_reasons": null, "author": "MrNezzer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1195ts7/whats_the_best_way_to_build_documentation_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1195ts7/whats_the_best_way_to_build_documentation_for_a/", "subreddit_subscribers": 90648, "created_utc": 1677087389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just joined a small B2C company that produces written content similar to spark notes. They have no data warehouse and is using Postgres for housing content to deliver via their website. Separately they also have data scientists scraping web data to find which books are popular.\n\nI need to setup a data warehouse and a database for the company. The first purpose would be to automate the scraping process - it is currently manual and the datasets are stored on someone\u2019s computer lol.\n\nI\u2019ll considering using all of Google Cloud\u2019s suite of tools. What are the risks here? Google Cloud seems to have everything - BigQuery as the warehouse, SQL database, data studio as BI tool, and Cloud Run to automate python scrapers.\n\nWhat are the pros and cons of using every tool from one provider (aka Google here)? \n\nFor context, I am more familiar with Snowflake and Looker setup from my last job.", "author_fullname": "t2_gfy8k6mh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Starting DataOps function from Scratch at small B2C company.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119emfw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677102222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just joined a small B2C company that produces written content similar to spark notes. They have no data warehouse and is using Postgres for housing content to deliver via their website. Separately they also have data scientists scraping web data to find which books are popular.&lt;/p&gt;\n\n&lt;p&gt;I need to setup a data warehouse and a database for the company. The first purpose would be to automate the scraping process - it is currently manual and the datasets are stored on someone\u2019s computer lol.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ll considering using all of Google Cloud\u2019s suite of tools. What are the risks here? Google Cloud seems to have everything - BigQuery as the warehouse, SQL database, data studio as BI tool, and Cloud Run to automate python scrapers.&lt;/p&gt;\n\n&lt;p&gt;What are the pros and cons of using every tool from one provider (aka Google here)? &lt;/p&gt;\n\n&lt;p&gt;For context, I am more familiar with Snowflake and Looker setup from my last job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119emfw", "is_robot_indexable": true, "report_reasons": null, "author": "FivePointyChickens", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119emfw/starting_dataops_function_from_scratch_at_small/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119emfw/starting_dataops_function_from_scratch_at_small/", "subreddit_subscribers": 90648, "created_utc": 1677102222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've recently joined a company who is doing the majority of data transformation in lookml.  Seems like there are 2 reasons for this from what I'm told:  \n\n1. Every end user wants a different level of aggregation and that would require creating duplicative tables in Snowflake (think something like marketing wants product level, finance wants order level, but user specific not business specific)\n\n2. If we change the data structure of a table that would require a lot of maintenance in Snowflake \n\n\nI'm very self taught and still very much a beginner so I'm looking for a sanity check. My thought is having a solid groundwork laid out in Snowflake is going to solve the majority of those concerns. Define the aggregate levels by the business needs and if a single user has a specific request evaluate the business need for it. That way the data warehouse is our source of truth.\n\n\nIdeally, what is the right way to use Looker?", "author_fullname": "t2_2q171de9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where does Looker fit into the data stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119ailf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677096297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently joined a company who is doing the majority of data transformation in lookml.  Seems like there are 2 reasons for this from what I&amp;#39;m told:  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Every end user wants a different level of aggregation and that would require creating duplicative tables in Snowflake (think something like marketing wants product level, finance wants order level, but user specific not business specific)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;If we change the data structure of a table that would require a lot of maintenance in Snowflake &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m very self taught and still very much a beginner so I&amp;#39;m looking for a sanity check. My thought is having a solid groundwork laid out in Snowflake is going to solve the majority of those concerns. Define the aggregate levels by the business needs and if a single user has a specific request evaluate the business need for it. That way the data warehouse is our source of truth.&lt;/p&gt;\n\n&lt;p&gt;Ideally, what is the right way to use Looker?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119ailf", "is_robot_indexable": true, "report_reasons": null, "author": "lahma_mama", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119ailf/where_does_looker_fit_into_the_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119ailf/where_does_looker_fit_into_the_data_stack/", "subreddit_subscribers": 90648, "created_utc": 1677096297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am building a no-code data platform that will hookup to various data sources to move data from one source to another. Would like some feedback on the concept if anyone has time. I may be open to open sourcing some of the connector logic that I build.\n\nThe pain point that I am trying to solve is having to spend time building custom connectors and core logic to move data from various sources to your data warehouse for further processing or to other core business systems that you and your team use.\n\nWould appreciate any feedback on the idea / concept. Currently in a conceptual / ideation phase.\n\n[decouple.ai](https://decouple-ai.webflow.io/)", "author_fullname": "t2_tboe0h8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "feedback on data platform concept", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1197sp1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677091933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am building a no-code data platform that will hookup to various data sources to move data from one source to another. Would like some feedback on the concept if anyone has time. I may be open to open sourcing some of the connector logic that I build.&lt;/p&gt;\n\n&lt;p&gt;The pain point that I am trying to solve is having to spend time building custom connectors and core logic to move data from various sources to your data warehouse for further processing or to other core business systems that you and your team use.&lt;/p&gt;\n\n&lt;p&gt;Would appreciate any feedback on the idea / concept. Currently in a conceptual / ideation phase.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://decouple-ai.webflow.io/\"&gt;decouple.ai&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qNjewdgx32ue_xkhs376YFgcEltnmy2cSZrGFKZ4kao.jpg?auto=webp&amp;v=enabled&amp;s=bcdaf7024adf75785ab27ccbb7781293f2663b62", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/qNjewdgx32ue_xkhs376YFgcEltnmy2cSZrGFKZ4kao.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d63f88fc7621545a599bdc28869d81c6f7075a28", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/qNjewdgx32ue_xkhs376YFgcEltnmy2cSZrGFKZ4kao.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7d099f9ff0132f8c58729912b675a633d2784b4", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/qNjewdgx32ue_xkhs376YFgcEltnmy2cSZrGFKZ4kao.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f9bb2c9f14c6733db0c7b7ea997487b60339ba97", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/qNjewdgx32ue_xkhs376YFgcEltnmy2cSZrGFKZ4kao.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2925489094c89ce9f52ca3bc20a562fbf2894513", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/qNjewdgx32ue_xkhs376YFgcEltnmy2cSZrGFKZ4kao.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3cc0f379e132c42b374c704b5007f1459a17301a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/qNjewdgx32ue_xkhs376YFgcEltnmy2cSZrGFKZ4kao.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9872dc5fa45242e80a7314c079ba7d5428862057", "width": 1080, "height": 567}], "variants": {}, "id": "N_GVmsM00cAQGHLporpzUSZ1pQHBjxv2qEICAWCoMrc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1197sp1", "is_robot_indexable": true, "report_reasons": null, "author": "gardendotplace", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1197sp1/feedback_on_data_platform_concept/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1197sp1/feedback_on_data_platform_concept/", "subreddit_subscribers": 90648, "created_utc": 1677091933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently researching Unity Catalog for my organization. We have 3 storage account data lakes, one for dev test and prod. We currently mount the appropriate account to our Databricks workspace and so all the paths to tables are constant in our code, and we don\u2019t have to specify which to use when our pipelines run. \n\nWith the switch to Unity Catalog, I am wondering how people specify which catalog to use? Do you have a variable that gets set in the the release? Do you specify a \u201cuse catalog name\u201d somewhere before running a pipeline? Any advice is appreciated!", "author_fullname": "t2_1yo0xaq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unity Catalog and CI/CD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119et7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677102545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently researching Unity Catalog for my organization. We have 3 storage account data lakes, one for dev test and prod. We currently mount the appropriate account to our Databricks workspace and so all the paths to tables are constant in our code, and we don\u2019t have to specify which to use when our pipelines run. &lt;/p&gt;\n\n&lt;p&gt;With the switch to Unity Catalog, I am wondering how people specify which catalog to use? Do you have a variable that gets set in the the release? Do you specify a \u201cuse catalog name\u201d somewhere before running a pipeline? Any advice is appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119et7b", "is_robot_indexable": true, "report_reasons": null, "author": "justanator101", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119et7b/unity_catalog_and_cicd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119et7b/unity_catalog_and_cicd/", "subreddit_subscribers": 90648, "created_utc": 1677102545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "March 7 at 12 pm ET (17:00 UTC), join Zhamak Dehghani, founder and CEO of Nextdata and founder of the concept of Data Mesh, for the [ACM TechTalk](https://acm-org.zoom.us/webinar/register/9116770839344/WN_oqLHsa1GTnmtqafja30RNQ) \"**State of Data Mesh.**\"\n\nIn this talk Zhamak tells a short story of why we are here and what has happened before the inflection point of Data Mesh. What does the destination of an organization toward Data Mesh look like, after the inflection point? What is anchoring organizations to move forward and move fast? She leaves the audience with some practical steps to rewire an organizational brain\u2014behavior and technology\u2014to make atomic changes toward Data Mesh and move to new heights.\n\n[Register](https://acm-org.zoom.us/webinar/register/9116770839344/WN_oqLHsa1GTnmtqafja30RNQ) to attend this talk live or on demand.", "author_fullname": "t2_cd4qjhv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "March 7, Free Talk with Data Mesh Founder Zhamak Dehghani, Founder and CEO of Nextdata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1194fln", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677084092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;March 7 at 12 pm ET (17:00 UTC), join Zhamak Dehghani, founder and CEO of Nextdata and founder of the concept of Data Mesh, for the &lt;a href=\"https://acm-org.zoom.us/webinar/register/9116770839344/WN_oqLHsa1GTnmtqafja30RNQ\"&gt;ACM TechTalk&lt;/a&gt; &amp;quot;&lt;strong&gt;State of Data Mesh.&lt;/strong&gt;&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;In this talk Zhamak tells a short story of why we are here and what has happened before the inflection point of Data Mesh. What does the destination of an organization toward Data Mesh look like, after the inflection point? What is anchoring organizations to move forward and move fast? She leaves the audience with some practical steps to rewire an organizational brain\u2014behavior and technology\u2014to make atomic changes toward Data Mesh and move to new heights.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://acm-org.zoom.us/webinar/register/9116770839344/WN_oqLHsa1GTnmtqafja30RNQ\"&gt;Register&lt;/a&gt; to attend this talk live or on demand.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-TdXzS9iAsjf4dUR8tBzLdampPsR6fNnRPpBR3xMsmE.jpg?auto=webp&amp;v=enabled&amp;s=244c59d4d7c0afb6b0df199d693b7efda7162db6", "width": 60, "height": 60}, "resolutions": [], "variants": {}, "id": "Ow6yc0WkWVXCRxHUhhRq4t7_TN18fLOlAO-3jycS2Z4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1194fln", "is_robot_indexable": true, "report_reasons": null, "author": "ACMLearning", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1194fln/march_7_free_talk_with_data_mesh_founder_zhamak/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1194fln/march_7_free_talk_with_data_mesh_founder_zhamak/", "subreddit_subscribers": 90648, "created_utc": 1677084092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pandas 2.0 and the Arrow revolution (part I)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119ig9h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1677110639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "datapythonista.me", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://datapythonista.me/blog/pandas-20-and-the-arrow-revolution-part-i", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "119ig9h", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119ig9h/pandas_20_and_the_arrow_revolution_part_i/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://datapythonista.me/blog/pandas-20-and-the-arrow-revolution-part-i", "subreddit_subscribers": 90648, "created_utc": 1677110639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I enjoyed listening to this 30-minute [Data Engineering Podcast](https://www.dataengineeringpodcast.com/six-year-retrospective-episode-361?t=57) episode with its summary of the ecosystem today. The commentary on how we got here too was interesting. \n\nIf you've listened to it do you agree with the summary, or did he miss anything important out?", "author_fullname": "t2_bvkm0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Podcast] \ud83c\udfa7 A useful summary of the data engineering ecosystem today", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1195xdc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1677087629.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I enjoyed listening to this 30-minute &lt;a href=\"https://www.dataengineeringpodcast.com/six-year-retrospective-episode-361?t=57\"&gt;Data Engineering Podcast&lt;/a&gt; episode with its summary of the ecosystem today. The commentary on how we got here too was interesting. &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve listened to it do you agree with the summary, or did he miss anything important out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?auto=webp&amp;v=enabled&amp;s=e23e22e97e3722d0f8f9a61615e50ebcb3fa1826", "width": 1400, "height": 1400}, "resolutions": [{"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9da709a3840cf93e0a7b0b851bac03e773481d2b", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=358185c1b969237f260a000561002ac68e71b2dd", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=142a7305c615c834abda063fa9659d4312a4db7f", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8482cb9ec4aa7be58a4defea83030c21e651314f", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1672edce28c8d7b5be11836f2e364a11b78dacb7", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/yqRqF_wh_bUOV1-09CKYUysdUkhID2Ds1TevGDSoVV4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d6af140426178eebb01eca44ec153b253ef8cd1", "width": 1080, "height": 1080}], "variants": {}, "id": "T69lnyzJjP6GC8oxXuuJPHNQnXgo_9t63cJnvtec6xw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1195xdc", "is_robot_indexable": true, "report_reasons": null, "author": "rmoff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1195xdc/podcast_a_useful_summary_of_the_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1195xdc/podcast_a_useful_summary_of_the_data_engineering/", "subreddit_subscribers": 90648, "created_utc": 1677087629.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you have defined some SLOs on your data? Meaning for example you guarantee your users dataset XYZ will have no more than 5% NULL values in column ABC? If so, how do you present it to the user? Is it e.g. part of the data catalog?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data products SLO", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_11960zu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677087868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you have defined some SLOs on your data? Meaning for example you guarantee your users dataset XYZ will have no more than 5% NULL values in column ABC? If so, how do you present it to the user? Is it e.g. part of the data catalog?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "11960zu", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/11960zu/data_products_slo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/11960zu/data_products_slo/", "subreddit_subscribers": 90648, "created_utc": 1677087868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I\u2019m currently a BI dev but have worked loosely with data engineering concepts like warehousing. I know the theoretical side of it but lack practical experience.\n\nDoes anyone know where I could find any data warehousing projects to improve my skillset and put the theory to practical", "author_fullname": "t2_bnbu4t02", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a data warehousing project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1193qmi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677082446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I\u2019m currently a BI dev but have worked loosely with data engineering concepts like warehousing. I know the theoretical side of it but lack practical experience.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know where I could find any data warehousing projects to improve my skillset and put the theory to practical&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1193qmi", "is_robot_indexable": true, "report_reasons": null, "author": "Electrical-Respect39", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1193qmi/looking_for_a_data_warehousing_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1193qmi/looking_for_a_data_warehousing_project/", "subreddit_subscribers": 90648, "created_utc": 1677082446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "  \nhow does your bronze silver gold layers look like? do you use different storage accounts for each layer?   \ndo you have one metastore for multiple workspaces? (prod, dev, sandbox) or one metastore for each workspace?    \ndo you use managed tables or managed tables with external locations so that you can have visibility of the underlying files?   \nin the 3 level namespace, how do you name your ***catalog.schema.tables***? do you use Prod.bronze.salesforce\\_table1 or something like prod\\_bronze.salesforce.customers (just an example to get the discussion going).", "author_fullname": "t2_4doyx62l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "people who are using databricks and dataricks unity catalog, how does your setup look like? have you come across any downsides or limitations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1193j3m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677081962.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;how does your bronze silver gold layers look like? do you use different storage accounts for each layer?&lt;br/&gt;\ndo you have one metastore for multiple workspaces? (prod, dev, sandbox) or one metastore for each workspace?&lt;br/&gt;\ndo you use managed tables or managed tables with external locations so that you can have visibility of the underlying files?&lt;br/&gt;\nin the 3 level namespace, how do you name your &lt;strong&gt;&lt;em&gt;catalog.schema.tables&lt;/em&gt;&lt;/strong&gt;? do you use Prod.bronze.salesforce_table1 or something like prod_bronze.salesforce.customers (just an example to get the discussion going).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1193j3m", "is_robot_indexable": true, "report_reasons": null, "author": "fancyshamancy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1193j3m/people_who_are_using_databricks_and_dataricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1193j3m/people_who_are_using_databricks_and_dataricks/", "subreddit_subscribers": 90648, "created_utc": 1677081962.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In VSCode,the colorizer feature,\n\n ([@id](https://github.com/id):editor.bracketPairColorization.enabled [@id](https://github.com/id):editor.guides.bracketPairs) \n\ndoes not work for brackets inside strings for ex: scores in (), greatest (), cast() etc. The example provided below is very basic, but we've run into nested functions that span &gt; 10 lines which makes debugging difficult. This would be very helpful to a lot of engineers who use sql/jinja. \n\n&amp;#x200B;\n\nhttps://preview.redd.it/bdl9glzcyuja1.png?width=733&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0df85a635fa49a48208b518ea7c57fe8657eaef2\n\nI created an issue for this feature on the official VSCode Github , \n\n[https://github.com/microsoft/vscode/issues/169649](https://github.com/microsoft/vscode/issues/169649)\n\n&amp;#x200B;\n\nIt requires 20 votes for it to move it to their backlog. If you find this would be helpful, please upvote it on github  \n(more on upvoting here: [https://github.com/microsoft/vscode/wiki/Issues-Triaging#up-voting-a-feature-request](https://github.com/microsoft/vscode/wiki/Issues-Triaging#up-voting-a-feature-request))", "author_fullname": "t2_5rikt61xq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bracket Pair Colorizer for SQL - VSCode issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "media_metadata": {"bdl9glzcyuja1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 74, "x": 108, "u": "https://preview.redd.it/bdl9glzcyuja1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=414f2f2e2a175ed9f5f488dac842aa05835d0df1"}, {"y": 149, "x": 216, "u": "https://preview.redd.it/bdl9glzcyuja1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=888f9acb467f86766ec4bd54d06812bff16cb0da"}, {"y": 221, "x": 320, "u": "https://preview.redd.it/bdl9glzcyuja1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9eedc1f55b572f5dec02d33a88172d47fb407a5"}, {"y": 442, "x": 640, "u": "https://preview.redd.it/bdl9glzcyuja1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0266046deeea13439e0e6d664f2fa31f9c00bcb0"}], "s": {"y": 507, "x": 733, "u": "https://preview.redd.it/bdl9glzcyuja1.png?width=733&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0df85a635fa49a48208b518ea7c57fe8657eaef2"}, "id": "bdl9glzcyuja1"}}, "name": "t3_119na3a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/b32GTmNvzTSoMHbew6yaoKUffq22YJ4yrtm6BLCeMHk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1677123247.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In VSCode,the colorizer feature,&lt;/p&gt;\n\n&lt;p&gt;(&lt;a href=\"https://github.com/id\"&gt;@id&lt;/a&gt;:editor.bracketPairColorization.enabled &lt;a href=\"https://github.com/id\"&gt;@id&lt;/a&gt;:editor.guides.bracketPairs) &lt;/p&gt;\n\n&lt;p&gt;does not work for brackets inside strings for ex: scores in (), greatest (), cast() etc. The example provided below is very basic, but we&amp;#39;ve run into nested functions that span &amp;gt; 10 lines which makes debugging difficult. This would be very helpful to a lot of engineers who use sql/jinja. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bdl9glzcyuja1.png?width=733&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0df85a635fa49a48208b518ea7c57fe8657eaef2\"&gt;https://preview.redd.it/bdl9glzcyuja1.png?width=733&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=0df85a635fa49a48208b518ea7c57fe8657eaef2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I created an issue for this feature on the official VSCode Github , &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/microsoft/vscode/issues/169649\"&gt;https://github.com/microsoft/vscode/issues/169649&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It requires 20 votes for it to move it to their backlog. If you find this would be helpful, please upvote it on github&lt;br/&gt;\n(more on upvoting here: &lt;a href=\"https://github.com/microsoft/vscode/wiki/Issues-Triaging#up-voting-a-feature-request\"&gt;https://github.com/microsoft/vscode/wiki/Issues-Triaging#up-voting-a-feature-request&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ghVpdNpMmwiBDZW_KhU3rfCPHnN-8y_NZ9Elg-wRm04.jpg?auto=webp&amp;v=enabled&amp;s=6dd45d060d304a95d84693ac89a3463494910530", "width": 336, "height": 336}, "resolutions": [{"url": "https://external-preview.redd.it/ghVpdNpMmwiBDZW_KhU3rfCPHnN-8y_NZ9Elg-wRm04.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd83866d1749754918daa4b1d42d8da603983899", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/ghVpdNpMmwiBDZW_KhU3rfCPHnN-8y_NZ9Elg-wRm04.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e0c884a660b38a41899fb3b5e3e3308d51e7e9ec", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/ghVpdNpMmwiBDZW_KhU3rfCPHnN-8y_NZ9Elg-wRm04.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f19d55525044730593b95c0af01f089482efa199", "width": 320, "height": 320}], "variants": {}, "id": "wWaXLNqFaTps7pGrJM9prEG2Htb0x9UlwSG11gTLPCc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "119na3a", "is_robot_indexable": true, "report_reasons": null, "author": "KangarOOCase", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119na3a/bracket_pair_colorizer_for_sql_vscode_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119na3a/bracket_pair_colorizer_for_sql_vscode_issue/", "subreddit_subscribers": 90648, "created_utc": 1677123247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have spend the better part of the past two weeks reading about data engineering (and MLOps). The space seems to be dominated by Python-based workflows and tools like Apache Airflow, Dagster, MLFlow etc", "author_fullname": "t2_srfmey5u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should data engineering be done in a non-Python organization that is dominated by C#/.Net developers and data science people who prefer R?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119hqbf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677108845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have spend the better part of the past two weeks reading about data engineering (and MLOps). The space seems to be dominated by Python-based workflows and tools like Apache Airflow, Dagster, MLFlow etc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119hqbf", "is_robot_indexable": true, "report_reasons": null, "author": "gheex", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119hqbf/how_should_data_engineering_be_done_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119hqbf/how_should_data_engineering_be_done_in_a/", "subreddit_subscribers": 90648, "created_utc": 1677108845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently finished my internship as a juco student at an MNC and have tapped on a bit of data engineering work in terms of data wrangling, activation, preparation, migration. Not so much about building pipelines.\n\nPrior to that, I didn't have much experience and this internship opportunity has allowed me to discover an interest into this field. As I have a short break before the next steps into my career, I want to get more involved into the aspects of data engineering (build pipelines etc) and embark on some basic projects.\n\nI am mainly proficient in Python. \n\nWhat are the resources that I can seek for pertaining to data engineering?", "author_fullname": "t2_czigz4m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Beginner Side Project Ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119hdb5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677107994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently finished my internship as a juco student at an MNC and have tapped on a bit of data engineering work in terms of data wrangling, activation, preparation, migration. Not so much about building pipelines.&lt;/p&gt;\n\n&lt;p&gt;Prior to that, I didn&amp;#39;t have much experience and this internship opportunity has allowed me to discover an interest into this field. As I have a short break before the next steps into my career, I want to get more involved into the aspects of data engineering (build pipelines etc) and embark on some basic projects.&lt;/p&gt;\n\n&lt;p&gt;I am mainly proficient in Python. &lt;/p&gt;\n\n&lt;p&gt;What are the resources that I can seek for pertaining to data engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119hdb5", "is_robot_indexable": true, "report_reasons": null, "author": "NotYule", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119hdb5/beginner_side_project_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119hdb5/beginner_side_project_ideas/", "subreddit_subscribers": 90648, "created_utc": 1677107994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently working for a mid size tech company. The Data Science team I\u2019m a part of, is in its infancy and there is not a lot of direction from my team lead. The current senior data engineer is not very helpful in most situations as he is usually swamped with requests and I have a feeling the person is planning to leave soon. This would put a lot more pressure on my shoulders. I have Business Intelligence and Software Development experience (about 8 years overall) but I\u2019ve recently internally moved into the Data Engineer position. This team heavily uses Spark, Scala and Kafka. I haven\u2019t worked on these technologies before. With the lack of clear leadership in my team, I\u2019m struggling to learn anything. What resources in terms of blogs/YouTube/tutorials/books can I use to be ready for a senior role if it comes to that? Thank you for any information you guys can share.", "author_fullname": "t2_1reibdu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources/Books that help transition into a Senior Data Engineering role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1199ilk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677094879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently working for a mid size tech company. The Data Science team I\u2019m a part of, is in its infancy and there is not a lot of direction from my team lead. The current senior data engineer is not very helpful in most situations as he is usually swamped with requests and I have a feeling the person is planning to leave soon. This would put a lot more pressure on my shoulders. I have Business Intelligence and Software Development experience (about 8 years overall) but I\u2019ve recently internally moved into the Data Engineer position. This team heavily uses Spark, Scala and Kafka. I haven\u2019t worked on these technologies before. With the lack of clear leadership in my team, I\u2019m struggling to learn anything. What resources in terms of blogs/YouTube/tutorials/books can I use to be ready for a senior role if it comes to that? Thank you for any information you guys can share.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1199ilk", "is_robot_indexable": true, "report_reasons": null, "author": "luckykanwar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1199ilk/resourcesbooks_that_help_transition_into_a_senior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1199ilk/resourcesbooks_that_help_transition_into_a_senior/", "subreddit_subscribers": 90648, "created_utc": 1677094879.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHi,\n\nI'm using Delta Live Tables to create a medallion architecture and am having trouble defining a parameterised function to upsert data from bronze into silver. I used the [CDC](https://docs.databricks.com/workflows/delta-live-tables/delta-live-tables-cdc.html) documentation but I also want my silver table to have expectations, schema hints and new columns, which I don't think is possible using streaming\\_live\\_table.\n\nAs a reference, I created the below function to take data from a bronze table and upsert into silver:\n\n    def generate_silver_streaming_live_table(env, schema_name, object_name, dedupe_key, seq):\n        dlt.create_streaming_live_table(\n            name = env + \"_\" + object_name + \"live_silver\",\n            comment = \"Silver data for \" + env + \"_\" + object_name,\n            path = \"abfss://datalakepath.dfs.core.windows.net/\" + env +\"/\" + schema_name + \"/\" + object_name + \"/silver\"\n        )\n        dlt.apply_changes(\n            target = env + \"_\" + object_name + \"live_silver\",\n            source = env + \"_\" + object_name + \"_bronze\",\n            keys = dedupe_key,\n            sequence_by = seq\n        )\n\nThis works well but like I mentioned is not compatible with expectations, schema hints and new columns. I then changed tactics to use the more traditional dlt.table decorator, but this is having a lot of trouble with upserts. ForEachBatch is not compatible with DLT - i've tried using dropDuplicates but this keeps the first update made rather than changes, i've also tried using merge statements like below but this isn't working for me either because the silver table has no columns yet so can't do the merge on silver.dedupe\\_key.\n\n    def generate_silver_table(env, object_name, dedupe_key):\n        @dlt.table(\n            name = env + \"_\" + object_name + \"static_silver\",\n            comment = \"Silver data for \" + env + \"_\" + object_name,\n        )\n        def silverincremental():\n                df = dlt.read_stream(\n                    env + \"_\" + object_name + \"_bronze\"\n                )\n                silver_table = DeltaTable.forPath(spark, \"dbfs:/pathtosilvertable\")\n                return(\n                silver_table.alias(\"silver\").merge(df.alias('source'), \"source.\" + dedupe_key + \"= silver.\" + dedupe_key)\n                    .whenMatchedUpdateAll()\n                    .whenNotMatchedInsertAll()\n                    .execute()\n                )\n\nI'm at a loose end here but there must be something i'm missing? This is a very simple and very common business problem using recommended steps in the medallion architecture recommended by Databricks and I can't believe it's so difficult to implement.", "author_fullname": "t2_ocur3kkm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Live Tables Upsert to Silver", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_118zrd4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677074324.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using Delta Live Tables to create a medallion architecture and am having trouble defining a parameterised function to upsert data from bronze into silver. I used the &lt;a href=\"https://docs.databricks.com/workflows/delta-live-tables/delta-live-tables-cdc.html\"&gt;CDC&lt;/a&gt; documentation but I also want my silver table to have expectations, schema hints and new columns, which I don&amp;#39;t think is possible using streaming_live_table.&lt;/p&gt;\n\n&lt;p&gt;As a reference, I created the below function to take data from a bronze table and upsert into silver:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def generate_silver_streaming_live_table(env, schema_name, object_name, dedupe_key, seq):\n    dlt.create_streaming_live_table(\n        name = env + &amp;quot;_&amp;quot; + object_name + &amp;quot;live_silver&amp;quot;,\n        comment = &amp;quot;Silver data for &amp;quot; + env + &amp;quot;_&amp;quot; + object_name,\n        path = &amp;quot;abfss://datalakepath.dfs.core.windows.net/&amp;quot; + env +&amp;quot;/&amp;quot; + schema_name + &amp;quot;/&amp;quot; + object_name + &amp;quot;/silver&amp;quot;\n    )\n    dlt.apply_changes(\n        target = env + &amp;quot;_&amp;quot; + object_name + &amp;quot;live_silver&amp;quot;,\n        source = env + &amp;quot;_&amp;quot; + object_name + &amp;quot;_bronze&amp;quot;,\n        keys = dedupe_key,\n        sequence_by = seq\n    )\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This works well but like I mentioned is not compatible with expectations, schema hints and new columns. I then changed tactics to use the more traditional dlt.table decorator, but this is having a lot of trouble with upserts. ForEachBatch is not compatible with DLT - i&amp;#39;ve tried using dropDuplicates but this keeps the first update made rather than changes, i&amp;#39;ve also tried using merge statements like below but this isn&amp;#39;t working for me either because the silver table has no columns yet so can&amp;#39;t do the merge on silver.dedupe_key.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def generate_silver_table(env, object_name, dedupe_key):\n    @dlt.table(\n        name = env + &amp;quot;_&amp;quot; + object_name + &amp;quot;static_silver&amp;quot;,\n        comment = &amp;quot;Silver data for &amp;quot; + env + &amp;quot;_&amp;quot; + object_name,\n    )\n    def silverincremental():\n            df = dlt.read_stream(\n                env + &amp;quot;_&amp;quot; + object_name + &amp;quot;_bronze&amp;quot;\n            )\n            silver_table = DeltaTable.forPath(spark, &amp;quot;dbfs:/pathtosilvertable&amp;quot;)\n            return(\n            silver_table.alias(&amp;quot;silver&amp;quot;).merge(df.alias(&amp;#39;source&amp;#39;), &amp;quot;source.&amp;quot; + dedupe_key + &amp;quot;= silver.&amp;quot; + dedupe_key)\n                .whenMatchedUpdateAll()\n                .whenNotMatchedInsertAll()\n                .execute()\n            )\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;m at a loose end here but there must be something i&amp;#39;m missing? This is a very simple and very common business problem using recommended steps in the medallion architecture recommended by Databricks and I can&amp;#39;t believe it&amp;#39;s so difficult to implement.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "118zrd4", "is_robot_indexable": true, "report_reasons": null, "author": "OutlandishnessOdd695", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/118zrd4/delta_live_tables_upsert_to_silver/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/118zrd4/delta_live_tables_upsert_to_silver/", "subreddit_subscribers": 90648, "created_utc": 1677074324.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I've been a DBA for about 8 years now (currently an MSSQL DBA), and I'm looking to learn more about data engineering and other, non-RDBMS systems. \n\nFor a first project, I want to do some basic extraction of data from various apis/web scraping, load it into a data warehouse (either directly into a traditional DW or use parquet files for a data lake). I put together the first steps of such on GCS using python scripts, duckdb, cloud storage and BigQuery. However, I'm not sure if given my background on the Microsoft side of things. This makes me think that I might want to focus on learning Azure, but looking over Synapse, I'm not sure how I feel about it, as it doesn't seem as simple as BigQuery did to me at first, as ADLS gen2 seems a bit odd, as my current parquet files aren't split down into many files, which seems to be the way to go for ADLS?\n\nI thought about using Databricks, but I'm hesitant, as I can't find much about how much it'll cost me to use as a small DW for learning, and I don't have a free tier to use anymore (used it a few years back for basic learning).\n\nI'm thinking of maybe trying out a different DW, something like ClickHouse, and running that on an Azure VM, but I'm not sure if doing that is a good idea for learning, since it isn't an \"official\" Azure tool. Also considered SingleStore, but a VM large enough to self host it might be too much (the docs recommend 4 CPUs/4GB RAM.\n\n&amp;#x200B;\n\nI guess to give TLDR, I currently work as a DBA in the Microsoft Stack, and when trying to figure out where to start learning DE, I feel like Azure is a natural starting point, but I'm not sure if I'm a fan of Synapse at first, compared to my first impressions of BigQuery.\n\nThanks!", "author_fullname": "t2_ssh4888", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What stack to focus on for learning for my background?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119qxna", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677134613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;ve been a DBA for about 8 years now (currently an MSSQL DBA), and I&amp;#39;m looking to learn more about data engineering and other, non-RDBMS systems. &lt;/p&gt;\n\n&lt;p&gt;For a first project, I want to do some basic extraction of data from various apis/web scraping, load it into a data warehouse (either directly into a traditional DW or use parquet files for a data lake). I put together the first steps of such on GCS using python scripts, duckdb, cloud storage and BigQuery. However, I&amp;#39;m not sure if given my background on the Microsoft side of things. This makes me think that I might want to focus on learning Azure, but looking over Synapse, I&amp;#39;m not sure how I feel about it, as it doesn&amp;#39;t seem as simple as BigQuery did to me at first, as ADLS gen2 seems a bit odd, as my current parquet files aren&amp;#39;t split down into many files, which seems to be the way to go for ADLS?&lt;/p&gt;\n\n&lt;p&gt;I thought about using Databricks, but I&amp;#39;m hesitant, as I can&amp;#39;t find much about how much it&amp;#39;ll cost me to use as a small DW for learning, and I don&amp;#39;t have a free tier to use anymore (used it a few years back for basic learning).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of maybe trying out a different DW, something like ClickHouse, and running that on an Azure VM, but I&amp;#39;m not sure if doing that is a good idea for learning, since it isn&amp;#39;t an &amp;quot;official&amp;quot; Azure tool. Also considered SingleStore, but a VM large enough to self host it might be too much (the docs recommend 4 CPUs/4GB RAM.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I guess to give TLDR, I currently work as a DBA in the Microsoft Stack, and when trying to figure out where to start learning DE, I feel like Azure is a natural starting point, but I&amp;#39;m not sure if I&amp;#39;m a fan of Synapse at first, compared to my first impressions of BigQuery.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119qxna", "is_robot_indexable": true, "report_reasons": null, "author": "dontmakemeplaypool", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119qxna/what_stack_to_focus_on_for_learning_for_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119qxna/what_stack_to_focus_on_for_learning_for_my/", "subreddit_subscribers": 90648, "created_utc": 1677134613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello engineers,\n\nI am building a data pipeline that starts from the custom code of webflow to rudderstack to big query.\nSo far everything works, but I have trouble understanding how to track more detailed events, like add to cart or buy\nI can see what user visitate, but that's not enough for my purpose.\nI know rudderstack has some documentation in how to set up the JavaScript code, still I wasn't successful in the implementation.\nDoes anyone have a JavaScript sdk code that could work for track e-commerce events?\n\nThank you, it's really really Appreciated!", "author_fullname": "t2_gudylfm7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which way to track webflow e-commerce events?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_119fzhj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1677104877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello engineers,&lt;/p&gt;\n\n&lt;p&gt;I am building a data pipeline that starts from the custom code of webflow to rudderstack to big query.\nSo far everything works, but I have trouble understanding how to track more detailed events, like add to cart or buy\nI can see what user visitate, but that&amp;#39;s not enough for my purpose.\nI know rudderstack has some documentation in how to set up the JavaScript code, still I wasn&amp;#39;t successful in the implementation.\nDoes anyone have a JavaScript sdk code that could work for track e-commerce events?&lt;/p&gt;\n\n&lt;p&gt;Thank you, it&amp;#39;s really really Appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "119fzhj", "is_robot_indexable": true, "report_reasons": null, "author": "Entire-Candidate-839", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/119fzhj/which_way_to_track_webflow_ecommerce_events/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/119fzhj/which_way_to_track_webflow_ecommerce_events/", "subreddit_subscribers": 90648, "created_utc": 1677104877.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}