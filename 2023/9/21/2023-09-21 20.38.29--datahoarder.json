{"kind": "Listing", "data": {"after": "t3_16o97sj", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been wanting to announce this here for a while now, but if you do download stuff from the website please don't download a lot of stuff at once!\n\n&amp;#x200B;\n\n**This is ExternalTube**, an early, read-only, YouTube archive/preservation project \\[made by my friend IdioticSniper\\] with a lot of lost, normal and rare videos scraped from the old YouTube CDNs. We've gotten some amazingly rare stuff, like old videos with almost 2 views at-most, videos from the user \"videos\" \\[their channel was completely wiped by YouTube themselves\\] and lost-until-now videos from the user \"steve\". More than 100 CDNs have been scraped and the archive is currently at 120GB, with the hard-drive hosting the files and everything supporting 3TB.\n\nI recommend you check it out on an Adobe Flash-compatible browser, it's amazing!\n\nhttps://preview.redd.it/8ff1il0d8lpb1.png?width=521&amp;format=png&amp;auto=webp&amp;s=64625e8b53793741b6543a9f9c2b6a68431767e4\n\nQuick warning though: Since this is from the old YouTube CDNs, those are all in FLV quality and use the old YouTube Flash player from 2005.\n\nSo what are you waiting for? **Dig through the archives.**\n\n[**https://exttube.snippr.win**](https://exttube.snippr.win)\n\n&amp;#x200B;\n\n**EDIT:** The source code has been released! [**https://github.com/IdioticSniper/externaltube**](https://github.com/IdioticSniper/externaltube)\n\n**EDIT 2: 150 UPVOTES!** Okay, I quite honestly didn't expect this to **get stickied** and be a \"**post-of-the-day**\", but thank you all! **Please also thank** [**u/aaaahhmyballs**](https://www.reddit.com/u/aaaahhmyballs/) **(A.K.A. website dev and owner) for making all this** (except me, andry6702, I just made the Reddit post lmao). Y'all are awesome!!!", "author_fullname": "t2_7a9ymbww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ExternalTube - A YouTube archive project that ranges with videos from 2005-2009.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8ff1il0d8lpb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 125, "x": 108, "u": "https://preview.redd.it/8ff1il0d8lpb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3f9d765ff6f49d0bdc003ad0091b991393d75ac4"}, {"y": 251, "x": 216, "u": "https://preview.redd.it/8ff1il0d8lpb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8df8bbb2d6e089ad8481051195db925ddd1e5157"}, {"y": 372, "x": 320, "u": "https://preview.redd.it/8ff1il0d8lpb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8b7982594d2f006755d988b6e3ec7b05481d1623"}], "s": {"y": 606, "x": 521, "u": "https://preview.redd.it/8ff1il0d8lpb1.png?width=521&amp;format=png&amp;auto=webp&amp;s=64625e8b53793741b6543a9f9c2b6a68431767e4"}, "id": "8ff1il0d8lpb1"}}, "name": "t3_16ocljy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 187, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 187, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uIbBDETLrN3yy7Qy8Ajyf14E5-clV7VqsL0TPzdiYVs.jpg", "edited": 1695321896.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695293113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been wanting to announce this here for a while now, but if you do download stuff from the website please don&amp;#39;t download a lot of stuff at once!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;This is ExternalTube&lt;/strong&gt;, an early, read-only, YouTube archive/preservation project [made by my friend IdioticSniper] with a lot of lost, normal and rare videos scraped from the old YouTube CDNs. We&amp;#39;ve gotten some amazingly rare stuff, like old videos with almost 2 views at-most, videos from the user &amp;quot;videos&amp;quot; [their channel was completely wiped by YouTube themselves] and lost-until-now videos from the user &amp;quot;steve&amp;quot;. More than 100 CDNs have been scraped and the archive is currently at 120GB, with the hard-drive hosting the files and everything supporting 3TB.&lt;/p&gt;\n\n&lt;p&gt;I recommend you check it out on an Adobe Flash-compatible browser, it&amp;#39;s amazing!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8ff1il0d8lpb1.png?width=521&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=64625e8b53793741b6543a9f9c2b6a68431767e4\"&gt;https://preview.redd.it/8ff1il0d8lpb1.png?width=521&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=64625e8b53793741b6543a9f9c2b6a68431767e4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Quick warning though: Since this is from the old YouTube CDNs, those are all in FLV quality and use the old YouTube Flash player from 2005.&lt;/p&gt;\n\n&lt;p&gt;So what are you waiting for? &lt;strong&gt;Dig through the archives.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://exttube.snippr.win\"&gt;&lt;strong&gt;https://exttube.snippr.win&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; The source code has been released! &lt;a href=\"https://github.com/IdioticSniper/externaltube\"&gt;&lt;strong&gt;https://github.com/IdioticSniper/externaltube&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT 2: 150 UPVOTES!&lt;/strong&gt; Okay, I quite honestly didn&amp;#39;t expect this to &lt;strong&gt;get stickied&lt;/strong&gt; and be a &amp;quot;&lt;strong&gt;post-of-the-day&lt;/strong&gt;&amp;quot;, but thank you all! &lt;strong&gt;Please also thank&lt;/strong&gt; &lt;a href=\"https://www.reddit.com/u/aaaahhmyballs/\"&gt;&lt;strong&gt;u/aaaahhmyballs&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;(A.K.A. website dev and owner) for making all this&lt;/strong&gt; (except me, andry6702, I just made the Reddit post lmao). Y&amp;#39;all are awesome!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ocljy", "is_robot_indexable": true, "report_reasons": null, "author": "Peak_Environmental", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ocljy/externaltube_a_youtube_archive_project_that/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/16ocljy/externaltube_a_youtube_archive_project_that/", "subreddit_subscribers": 703028, "created_utc": 1695293113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Okay this is a weird one, and I feel like I might be alone in this one, does anyone else hoard Blu-ray images, by that I mean full copies of the disk using MakeMKV (decrypted files) I don't know why I started to do this, but I have a big fear of my Blu-rays dying eventually, or worse getting damaged or stolen. So for months I've been hoarding the full disk to my drives. Is this just silly? Should I just keep a remux of the main file? I just like the idea of if one died, I could essentially buy a blank 50gb+ disc and burn a copy back that would be just the same as the original.", "author_fullname": "t2_b5jpuno7e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone else hoard BluRay images?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nytnr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695249369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay this is a weird one, and I feel like I might be alone in this one, does anyone else hoard Blu-ray images, by that I mean full copies of the disk using MakeMKV (decrypted files) I don&amp;#39;t know why I started to do this, but I have a big fear of my Blu-rays dying eventually, or worse getting damaged or stolen. So for months I&amp;#39;ve been hoarding the full disk to my drives. Is this just silly? Should I just keep a remux of the main file? I just like the idea of if one died, I could essentially buy a blank 50gb+ disc and burn a copy back that would be just the same as the original.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16nytnr", "is_robot_indexable": true, "report_reasons": null, "author": "Hastetheapple", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nytnr/does_anyone_else_hoard_bluray_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nytnr/does_anyone_else_hoard_bluray_images/", "subreddit_subscribers": 703028, "created_utc": 1695249369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve seen a lot of good comments on serverpartsdeals.com so I decided to take the plunge last week.  Bought 2 recertified seagate x20 18tb exos drives for cheap.  Both arrived quickly and well packaged.  On top of that, THEY HAD 0 HOURS ON THEM.  Currently half way through unraids full preclear cycle(god I wish this tool existed on other OSs) and absolutely no errors or anything.\n\nJust wanted to post this as others have mentioned they have good results from them as well.", "author_fullname": "t2_ytkgh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just another positive experience with serverpartsdeals", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nwfhg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695243779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve seen a lot of good comments on serverpartsdeals.com so I decided to take the plunge last week.  Bought 2 recertified seagate x20 18tb exos drives for cheap.  Both arrived quickly and well packaged.  On top of that, THEY HAD 0 HOURS ON THEM.  Currently half way through unraids full preclear cycle(god I wish this tool existed on other OSs) and absolutely no errors or anything.&lt;/p&gt;\n\n&lt;p&gt;Just wanted to post this as others have mentioned they have good results from them as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "708TB Unraid", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nwfhg", "is_robot_indexable": true, "report_reasons": null, "author": "sittingmongoose", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16nwfhg/just_another_positive_experience_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nwfhg/just_another_positive_experience_with/", "subreddit_subscribers": 703028, "created_utc": 1695243779.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File Mover", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16oledm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_14qvy6", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "unRAID", "selftext": "I've just set up unraid and got the usual requirement of wanting to organize family photos and videos from a large collection (phones, cameras, cloud etc)\n\nI'm thinking of a 'dump' share for the family to use where they would drop their photos and videos when ever they want to back them up from various devices\n\nI'm then wanting some file mover to periodically grab files from the dump share and move them to various subfolders into either a video or photo share based on their file type\n\nWithin them two video and photo shares I'd like them to be moved into subfolders based on, ideally exif year of date taken if available, but if not then just year the file was created\n\n&amp;#x200B;\n\nAnyone aware of any file mover dockers or plugins that would move ", "author_fullname": "t2_14qvy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File Mover", "link_flair_richtext": [], "subreddit_name_prefixed": "r/unRAID", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16oi4t7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695308389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.unRAID", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just set up unraid and got the usual requirement of wanting to organize family photos and videos from a large collection (phones, cameras, cloud etc)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of a &amp;#39;dump&amp;#39; share for the family to use where they would drop their photos and videos when ever they want to back them up from various devices&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m then wanting some file mover to periodically grab files from the dump share and move them to various subfolders into either a video or photo share based on their file type&lt;/p&gt;\n\n&lt;p&gt;Within them two video and photo shares I&amp;#39;d like them to be moved into subfolders based on, ideally exif year of date taken if available, but if not then just year the file was created&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyone aware of any file mover dockers or plugins that would move &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sn94", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16oi4t7", "is_robot_indexable": true, "report_reasons": null, "author": "labelsonshampoo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/unRAID/comments/16oi4t7/file_mover/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/unRAID/comments/16oi4t7/file_mover/", "subreddit_subscribers": 55968, "created_utc": 1695308389.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1695316479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.unRAID", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/unRAID/comments/16oi4t7/file_mover/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16oledm", "is_robot_indexable": true, "report_reasons": null, "author": "labelsonshampoo", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_16oi4t7", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16oledm/file_mover/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/unRAID/comments/16oi4t7/file_mover/", "subreddit_subscribers": 703028, "created_utc": 1695316479.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, as in title. How do You put your psychical book into computer? I want to do so mostly to be able to \"grep\" over my book collections but it also feel handy as ripping CD so I can access my bookshelf from remote location. \n\n&amp;#x200B;\n\nSo that's a question as I hoard ton of papier lately", "author_fullname": "t2_11am0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you digitalize Your books?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16og3dj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695303265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, as in title. How do You put your psychical book into computer? I want to do so mostly to be able to &amp;quot;grep&amp;quot; over my book collections but it also feel handy as ripping CD so I can access my bookshelf from remote location. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So that&amp;#39;s a question as I hoard ton of papier lately&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16og3dj", "is_robot_indexable": true, "report_reasons": null, "author": "wytrzeszcz", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16og3dj/how_do_you_digitalize_your_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16og3dj/how_do_you_digitalize_your_books/", "subreddit_subscribers": 703028, "created_utc": 1695303265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I've been struggling with this for the past hour. I have a video I want to archive from a website that no longer exists. I'm pretty sure Internet Archived it because I was able to play the video once (and then it stopped working). The video I'm trying to download is a flash video but it loads up using Ruffle. How can I download this video: [https://web.archive.org/web/20121005125354/http://debatevision.com/videos/122/spartan-debate-institute-2011-how-to-learn-by-watching](https://web.archive.org/web/20121005125354/http://debatevision.com/videos/122/spartan-debate-institute-2011-how-to-learn-by-watching) ", "author_fullname": "t2_7zjm3ef7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download a flash video from Internet Archive (not YouTube).", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o2p74", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695259731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been struggling with this for the past hour. I have a video I want to archive from a website that no longer exists. I&amp;#39;m pretty sure Internet Archived it because I was able to play the video once (and then it stopped working). The video I&amp;#39;m trying to download is a flash video but it loads up using Ruffle. How can I download this video: &lt;a href=\"https://web.archive.org/web/20121005125354/http://debatevision.com/videos/122/spartan-debate-institute-2011-how-to-learn-by-watching\"&gt;https://web.archive.org/web/20121005125354/http://debatevision.com/videos/122/spartan-debate-institute-2011-how-to-learn-by-watching&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o2p74", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Loomer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o2p74/how_to_download_a_flash_video_from_internet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o2p74/how_to_download_a_flash_video_from_internet/", "subreddit_subscribers": 703028, "created_utc": 1695259731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Tl;dr: I want convert VHS tapes to digital on my PC, but my VCR only has Scart connectors.\n\nI've got a few dozen tapes I want to digitize. I've found excellent tutorials online, including this one: [https://www.youtube.com/watch?v=tk-n7IlrXI4](https://www.youtube.com/watch?v=tk-n7IlrXI4)\n\nBut the capture cards recommended in that tutorial have RCA connectors. My VCR (Panasonic NV-FJ622F-S) has Scart connectors. It seems I have two options: buy a high quality capture card like the  I-O Data GV-USB2 and buy a Scart to RCA adaptor; or buy a high quality capture card with a Scart connector. I don't know of any such devices, however.\n\nAfter perusing a forum online I ascertained that Scart might be superior to RCA because the output signal is RGB, while the older RCA connectors only offer a composite output signal. I'm not looking to spend $100s or $1000s on this project. I just want something that will help me convert my VHS tapes in a decent quality. ", "author_fullname": "t2_l3d1z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digitizing VHS tapes using a Scart VCR", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16oll55", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695316961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tl;dr: I want convert VHS tapes to digital on my PC, but my VCR only has Scart connectors.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a few dozen tapes I want to digitize. I&amp;#39;ve found excellent tutorials online, including this one: &lt;a href=\"https://www.youtube.com/watch?v=tk-n7IlrXI4\"&gt;https://www.youtube.com/watch?v=tk-n7IlrXI4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But the capture cards recommended in that tutorial have RCA connectors. My VCR (Panasonic NV-FJ622F-S) has Scart connectors. It seems I have two options: buy a high quality capture card like the  I-O Data GV-USB2 and buy a Scart to RCA adaptor; or buy a high quality capture card with a Scart connector. I don&amp;#39;t know of any such devices, however.&lt;/p&gt;\n\n&lt;p&gt;After perusing a forum online I ascertained that Scart might be superior to RCA because the output signal is RGB, while the older RCA connectors only offer a composite output signal. I&amp;#39;m not looking to spend $100s or $1000s on this project. I just want something that will help me convert my VHS tapes in a decent quality. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/owshpG4G9cycG-VzEtF7JGb8rIOuiaxTUk90rW3jHMg.jpg?auto=webp&amp;s=0ff299b36e896de2fdf217212f436a70a15afbfe", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/owshpG4G9cycG-VzEtF7JGb8rIOuiaxTUk90rW3jHMg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8ffea08f3d3bdf4b64409656e08c3165cea80207", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/owshpG4G9cycG-VzEtF7JGb8rIOuiaxTUk90rW3jHMg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bc036c6e225ed6da22fc67406488ae642e2534f8", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/owshpG4G9cycG-VzEtF7JGb8rIOuiaxTUk90rW3jHMg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4f1141f261dff0ea1a2752ecfe9c40fe0b133f3f", "width": 320, "height": 240}], "variants": {}, "id": "TNw3I0ufneO6qTbuzfxsAwXvakKOQwPKYRAirzVNYxc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16oll55", "is_robot_indexable": true, "report_reasons": null, "author": "Steebee_Weebee", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16oll55/digitizing_vhs_tapes_using_a_scart_vcr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16oll55/digitizing_vhs_tapes_using_a_scart_vcr/", "subreddit_subscribers": 703028, "created_utc": 1695316961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, I'm the manager of a new educative Workspace Fundamentals, per my knowledge all Google Drive storage is now pooled, no unlimited anymore which is fine for us, however I was migrating some data to shared drives and I noticed even after 48 hours that Shared Drives space was not pooled or showing up on the storage bar, is this normal? It seems to be unlimited or am I doing something wrong? Checking also the subscriptions and billing part as we don't want any overcharges but I don't see any \"surprise\" charges.  \n\n\nI don't have any intention on using more than 100Tb, but just curious about it.\n\n&amp;#x200B;\n\nThank you all!\n\nhttps://preview.redd.it/k52spzieikpb1.png?width=2003&amp;format=png&amp;auto=webp&amp;s=81182cd2242462d178815f508695d0ae743642d6", "author_fullname": "t2_11x0y2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shared Drives not part as Pooled Storage? Google Drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 42, "top_awarded_type": null, "hide_score": false, "media_metadata": {"k52spzieikpb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 32, "x": 108, "u": "https://preview.redd.it/k52spzieikpb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a04b233c13b2c51fd83bac625f8be0f0ade506f"}, {"y": 65, "x": 216, "u": "https://preview.redd.it/k52spzieikpb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c953ff63ee88f290c6f0813713738012b441fca2"}, {"y": 97, "x": 320, "u": "https://preview.redd.it/k52spzieikpb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=77912a1ff9c27283a90314ed51e8ffa22c46da17"}, {"y": 194, "x": 640, "u": "https://preview.redd.it/k52spzieikpb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=714062537d226855060b049ba48cd369214c27ac"}, {"y": 291, "x": 960, "u": "https://preview.redd.it/k52spzieikpb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=53d167726462d7c006c0999f3d55b0e71bd0de74"}, {"y": 328, "x": 1080, "u": "https://preview.redd.it/k52spzieikpb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=852dc131265fbaa6a0bea4a3e3c6cdeccabec429"}], "s": {"y": 609, "x": 2003, "u": "https://preview.redd.it/k52spzieikpb1.png?width=2003&amp;format=png&amp;auto=webp&amp;s=81182cd2242462d178815f508695d0ae743642d6"}, "id": "k52spzieikpb1"}}, "name": "t3_16oa7np", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1LCn13ikVyKDN7PrXK2lqBmTOEwOjemV9Lk1xhf_amY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695284238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;m the manager of a new educative Workspace Fundamentals, per my knowledge all Google Drive storage is now pooled, no unlimited anymore which is fine for us, however I was migrating some data to shared drives and I noticed even after 48 hours that Shared Drives space was not pooled or showing up on the storage bar, is this normal? It seems to be unlimited or am I doing something wrong? Checking also the subscriptions and billing part as we don&amp;#39;t want any overcharges but I don&amp;#39;t see any &amp;quot;surprise&amp;quot; charges.  &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have any intention on using more than 100Tb, but just curious about it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you all!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/k52spzieikpb1.png?width=2003&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81182cd2242462d178815f508695d0ae743642d6\"&gt;https://preview.redd.it/k52spzieikpb1.png?width=2003&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81182cd2242462d178815f508695d0ae743642d6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16oa7np", "is_robot_indexable": true, "report_reasons": null, "author": "alemonpie", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16oa7np/shared_drives_not_part_as_pooled_storage_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16oa7np/shared_drives_not_part_as_pooled_storage_google/", "subreddit_subscribers": 703028, "created_utc": 1695284238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m working on a archival project for a certain youtuber, he spams his community tab all day with stuff and I\u2019d like a efficient way for me to archive it. \n\nIs there any software or script that will automatically scan and take screenshots or something of the community posts? I\u2019d prefer fully automatic as I\u2019ll probably forget eventually but if not that\u2019s alright. \n\nI don\u2019t know how to code or anything so the terminal and python stuff really confuses me. But I will learn if I have to.", "author_fullname": "t2_g9dhzldt6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone help me find a way to automatically archive Youtube Community Post?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o9yg9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695283266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on a archival project for a certain youtuber, he spams his community tab all day with stuff and I\u2019d like a efficient way for me to archive it. &lt;/p&gt;\n\n&lt;p&gt;Is there any software or script that will automatically scan and take screenshots or something of the community posts? I\u2019d prefer fully automatic as I\u2019ll probably forget eventually but if not that\u2019s alright. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t know how to code or anything so the terminal and python stuff really confuses me. But I will learn if I have to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o9yg9", "is_robot_indexable": true, "report_reasons": null, "author": "YendoZakari", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o9yg9/can_anyone_help_me_find_a_way_to_automatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o9yg9/can_anyone_help_me_find_a_way_to_automatically/", "subreddit_subscribers": 703028, "created_utc": 1695283266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Have a new (to me) 16bay100TB SuperMicro dual Xeon E5-2695 v2,  Quadro P4000, 198GB ECC Ram, 10Gb NIC server just waiting for a new OS.  Which one?  Have just all of the listed ones but Unraid and wanted to see what everyone thought would be the best for a home server/NAS/Docker Arr apps/Plex all-in-one headless server.  Don't run many VM's, have other hardware for that right now. Have run Ubuntu server and Windows 2022 servers in the past and may start one or two up if the need arises. \n\nI know it's overkill city, but it fell in my lap and I hate to piece it out.  Just needed to move HD's from my retired NAS.", "author_fullname": "t2_ba6cz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unraid, TrueNAS Scale, Proxmox, OpenMediaVault: Which one?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16opa4s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695325488.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have a new (to me) 16bay100TB SuperMicro dual Xeon E5-2695 v2,  Quadro P4000, 198GB ECC Ram, 10Gb NIC server just waiting for a new OS.  Which one?  Have just all of the listed ones but Unraid and wanted to see what everyone thought would be the best for a home server/NAS/Docker Arr apps/Plex all-in-one headless server.  Don&amp;#39;t run many VM&amp;#39;s, have other hardware for that right now. Have run Ubuntu server and Windows 2022 servers in the past and may start one or two up if the need arises. &lt;/p&gt;\n\n&lt;p&gt;I know it&amp;#39;s overkill city, but it fell in my lap and I hate to piece it out.  Just needed to move HD&amp;#39;s from my retired NAS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16opa4s", "is_robot_indexable": true, "report_reasons": null, "author": "macfound32", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16opa4s/unraid_truenas_scale_proxmox_openmediavault_which/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16opa4s/unraid_truenas_scale_proxmox_openmediavault_which/", "subreddit_subscribers": 703028, "created_utc": 1695325488.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "In 2020, I grabbed off of ebay an LSI 9207-8i (HP 9205-8i) SATA/SAS PCI-E 3.0 expander card for $45. It was flashed to IT mode and flashed to remove the MPT Bios and I have been using it to simply add more SATA HDDs to my large Fractal cases.\n\nI see they are still available, now for $60.\n\nIs this still the best option to get, or is there a newer/superior recommendation?\n\nAs well, back when I got this I had seen some recommend adding this very small noctua fan to keep the card cooler, which I did with good results: [https://www.amazon.com/gp/product/B07DXRNYNX/ref=ppx\\_yo\\_dt\\_b\\_search\\_asin\\_title?ie=UTF8&amp;psc=1](https://www.amazon.com/gp/product/B07DXRNYNX/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1)\n\nIs that still recommended as well?\n\nThanks for the help!", "author_fullname": "t2_cmfdu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the current best PCIe SATA expansion card for home server use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16onge4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695321252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In 2020, I grabbed off of ebay an LSI 9207-8i (HP 9205-8i) SATA/SAS PCI-E 3.0 expander card for $45. It was flashed to IT mode and flashed to remove the MPT Bios and I have been using it to simply add more SATA HDDs to my large Fractal cases.&lt;/p&gt;\n\n&lt;p&gt;I see they are still available, now for $60.&lt;/p&gt;\n\n&lt;p&gt;Is this still the best option to get, or is there a newer/superior recommendation?&lt;/p&gt;\n\n&lt;p&gt;As well, back when I got this I had seen some recommend adding this very small noctua fan to keep the card cooler, which I did with good results: &lt;a href=\"https://www.amazon.com/gp/product/B07DXRNYNX/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;amp;psc=1\"&gt;https://www.amazon.com/gp/product/B07DXRNYNX/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;amp;psc=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Is that still recommended as well?&lt;/p&gt;\n\n&lt;p&gt;Thanks for the help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16onge4", "is_robot_indexable": true, "report_reasons": null, "author": "filmguy123", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16onge4/what_is_the_current_best_pcie_sata_expansion_card/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16onge4/what_is_the_current_best_pcie_sata_expansion_card/", "subreddit_subscribers": 703028, "created_utc": 1695321252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_102ft9mv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I extract the data from a 1.5 TB, WD 15NMVW external hard drive? There are no docking stations that I can find that micro b can fit into", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16omj6d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/StNwFko1HBRa5WjqVKbcr67tEdVLmpaj1e2XHGDEuVE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695319044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/sxkkb01xdnpb1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/sxkkb01xdnpb1.jpg?auto=webp&amp;s=e5b0a7efa4af20460ab05a58f0208841e6f8cd2b", "width": 4032, "height": 3024}, "resolutions": [{"url": "https://preview.redd.it/sxkkb01xdnpb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=26484f046022b0a9f6efb0ff8bd403729d2f0687", "width": 108, "height": 81}, {"url": "https://preview.redd.it/sxkkb01xdnpb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d19544cb9f79eb6d75bd5a655ed12327a5338e95", "width": 216, "height": 162}, {"url": "https://preview.redd.it/sxkkb01xdnpb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4226477910a7ad27c7a7f56dc242bab6d686bf20", "width": 320, "height": 240}, {"url": "https://preview.redd.it/sxkkb01xdnpb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a063e3cafe2a7485d77754dca90eb275682427ef", "width": 640, "height": 480}, {"url": "https://preview.redd.it/sxkkb01xdnpb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b8c95f362427d67bd84e33eea7d278973ece83c1", "width": 960, "height": 720}, {"url": "https://preview.redd.it/sxkkb01xdnpb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5709fa609a28667725e3900cb4a9c17198673f38", "width": 1080, "height": 810}], "variants": {}, "id": "iCOzFCvbkUbHYt9N04bOHwhWfmyhmGHVi5l5zSBnlxU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16omj6d", "is_robot_indexable": true, "report_reasons": null, "author": "bomb_adrenaline", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16omj6d/how_can_i_extract_the_data_from_a_15_tb_wd_15nmvw/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/sxkkb01xdnpb1.jpg", "subreddit_subscribers": 703028, "created_utc": 1695319044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm interested in backing up my photo collection to backblaze b2b (as it seems the best value supplier)\n\nI am considering using rclone and crypt as it seems like the best solution.\n\nThe query is this, what is the best workflow to approach this from ?  I have some historic bitrot and I want to ensure that duplicate photos are deleted but the files themselves are not bit identical as picasa and myself have edited the exif metadata.  So only the underlying image data should be checked.\n\nHas anyone else approached this ?  Filesystem deduplication doesn't seem to be the answer.\n\nI have been thinking about using exiftool to export the sha1 to an xmp sidecar, and use python to identify duplicate checksums.  Is this a good approach ?\n\nAs an aside, I have also exported my data from google takeout in case my local data lacks integrity, but that has its exifdata stripped and the images resized I believe.\n\nAny advice would be appreciated.  Cheers.", "author_fullname": "t2_1w5zqtt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backing up and deduplicating digital camera photos to the cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16oarur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695286407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in backing up my photo collection to backblaze b2b (as it seems the best value supplier)&lt;/p&gt;\n\n&lt;p&gt;I am considering using rclone and crypt as it seems like the best solution.&lt;/p&gt;\n\n&lt;p&gt;The query is this, what is the best workflow to approach this from ?  I have some historic bitrot and I want to ensure that duplicate photos are deleted but the files themselves are not bit identical as picasa and myself have edited the exif metadata.  So only the underlying image data should be checked.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else approached this ?  Filesystem deduplication doesn&amp;#39;t seem to be the answer.&lt;/p&gt;\n\n&lt;p&gt;I have been thinking about using exiftool to export the sha1 to an xmp sidecar, and use python to identify duplicate checksums.  Is this a good approach ?&lt;/p&gt;\n\n&lt;p&gt;As an aside, I have also exported my data from google takeout in case my local data lacks integrity, but that has its exifdata stripped and the images resized I believe.&lt;/p&gt;\n\n&lt;p&gt;Any advice would be appreciated.  Cheers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16oarur", "is_robot_indexable": true, "report_reasons": null, "author": "simonmcnair", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16oarur/backing_up_and_deduplicating_digital_camera/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16oarur/backing_up_and_deduplicating_digital_camera/", "subreddit_subscribers": 703028, "created_utc": 1695286407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CD-Drives and Ferrite Cores: Are they necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o5q90", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_118v1j", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Cd_collectors", "selftext": "I have a set of external DVD-drives, and they came with USB Mini cables, which all the cables have ferrite cores.\n\nI picked up some second hand DVD-drives that didn't come with USB Mini  cables. I bought some spare cables, and recently picked up more ferrite cores.\n\n&amp;#x200B;\n\n**Question:**\n\nDo external portable CD-Drives need a ferrite core, if all it's doing is reading/writing data? Or would it be fine to use USB mini cables without the ferrite core?\n\nAlso, the USB Mini cables I picked up are pretty cheap.\n\nBut I don't know how noise would interfere with any CD or DVD extraction. Is noise or interference  possible in my case?", "author_fullname": "t2_118v1j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CD-Drives and Ferrite Cores: Are they necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Cd_collectors", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o5o6l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695268267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Cd_collectors", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a set of external DVD-drives, and they came with USB Mini cables, which all the cables have ferrite cores.&lt;/p&gt;\n\n&lt;p&gt;I picked up some second hand DVD-drives that didn&amp;#39;t come with USB Mini  cables. I bought some spare cables, and recently picked up more ferrite cores.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Do external portable CD-Drives need a ferrite core, if all it&amp;#39;s doing is reading/writing data? Or would it be fine to use USB mini cables without the ferrite core?&lt;/p&gt;\n\n&lt;p&gt;Also, the USB Mini cables I picked up are pretty cheap.&lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t know how noise would interfere with any CD or DVD extraction. Is noise or interference  possible in my case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "49431bd4-437f-11ec-97c0-c2be14adce00", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2uxz7", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#646d73", "id": "16o5o6l", "is_robot_indexable": true, "report_reasons": null, "author": "nPrevail", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Cd_collectors/comments/16o5o6l/cddrives_and_ferrite_cores_are_they_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/Cd_collectors/comments/16o5o6l/cddrives_and_ferrite_cores_are_they_necessary/", "subreddit_subscribers": 33774, "created_utc": 1695268267.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1695268449.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Cd_collectors", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/Cd_collectors/comments/16o5o6l/cddrives_and_ferrite_cores_are_they_necessary/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16o5q90", "is_robot_indexable": true, "report_reasons": null, "author": "nPrevail", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_16o5o6l", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o5q90/cddrives_and_ferrite_cores_are_they_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/Cd_collectors/comments/16o5o6l/cddrives_and_ferrite_cores_are_they_necessary/", "subreddit_subscribers": 703028, "created_utc": 1695268449.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "(Originally posted here: https://unix.stackexchange.com/q/757117)\n\nIf we do\n\n    rsync -a --link-dest=dest1 src dest2\n\nThen rsync will only copy files in `src` which have been modified compared to `dest1`. However, even if only one byte in a 1GB file is modified, the entire 1GB will be copied.\n\nHow to change the command so that\n\n 1. Old versions of the backup are all kept;\n 2. Only the delta of each file is copied;\n 3. We can restore any version of any files;\n 4. We can, in some way, remove the old backups while keeping newer versions?\n\n(This is sort of like snapshots in filesystems like ZFS.)", "author_fullname": "t2_nw8uzkwp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most space-efficient way of using rsync to do incremental back up, saving only deltas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o4ee9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695264425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Originally posted here: &lt;a href=\"https://unix.stackexchange.com/q/757117\"&gt;https://unix.stackexchange.com/q/757117&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;If we do&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;rsync -a --link-dest=dest1 src dest2\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then rsync will only copy files in &lt;code&gt;src&lt;/code&gt; which have been modified compared to &lt;code&gt;dest1&lt;/code&gt;. However, even if only one byte in a 1GB file is modified, the entire 1GB will be copied.&lt;/p&gt;\n\n&lt;p&gt;How to change the command so that&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Old versions of the backup are all kept;&lt;/li&gt;\n&lt;li&gt;Only the delta of each file is copied;&lt;/li&gt;\n&lt;li&gt;We can restore any version of any files;&lt;/li&gt;\n&lt;li&gt;We can, in some way, remove the old backups while keeping newer versions?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;(This is sort of like snapshots in filesystems like ZFS.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bK4oXKNpgxoE53LCEzd4qyFMVNZmmo1f8nfKJ6xAfwY.jpg?auto=webp&amp;s=4d3a3fdcce8a0b6f57eff17914edd41d6cba223d", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/bK4oXKNpgxoE53LCEzd4qyFMVNZmmo1f8nfKJ6xAfwY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=101ef2d5c1c11cd19dc570a3de92b1d42dd4619f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/bK4oXKNpgxoE53LCEzd4qyFMVNZmmo1f8nfKJ6xAfwY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a374f1faf62ab4af6a8201f9deb3ea9b18c78dc5", "width": 216, "height": 216}], "variants": {}, "id": "Eu27KCJ9gAHAoJ1FuuHqnnJTGcSqDhwVFQAcFhKk4cc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o4ee9", "is_robot_indexable": true, "report_reasons": null, "author": "spherical_shell", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o4ee9/most_spaceefficient_way_of_using_rsync_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o4ee9/most_spaceefficient_way_of_using_rsync_to_do/", "subreddit_subscribers": 703028, "created_utc": 1695264425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am sure this question has been asked many many (many) times, but I wanted to ensure I had my exact situation covered. \n\nI have a Mac-formatted 2TB external HDD. On the 'get info' panel, the format states \"Mac OS Extended (Journaled)\". I have a bunch of stuff on here that I want to transfer to another brand-new external HDD. This is not formatted for a Mac. The intention is to be able to have these files read by a Windows operating system, so I do not want to have to re-format to Mac. \n\nIs there any way I can transfer from the first HDD to the new one in such a way that the new HDD can be in a read/write state for Windows?", "author_fullname": "t2_6zrr9l4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External HDD --&gt; External HDD via Macbook", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o0duu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695253432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am sure this question has been asked many many (many) times, but I wanted to ensure I had my exact situation covered. &lt;/p&gt;\n\n&lt;p&gt;I have a Mac-formatted 2TB external HDD. On the &amp;#39;get info&amp;#39; panel, the format states &amp;quot;Mac OS Extended (Journaled)&amp;quot;. I have a bunch of stuff on here that I want to transfer to another brand-new external HDD. This is not formatted for a Mac. The intention is to be able to have these files read by a Windows operating system, so I do not want to have to re-format to Mac. &lt;/p&gt;\n\n&lt;p&gt;Is there any way I can transfer from the first HDD to the new one in such a way that the new HDD can be in a read/write state for Windows?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o0duu", "is_robot_indexable": true, "report_reasons": null, "author": "DrSimonMetin", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o0duu/external_hdd_external_hdd_via_macbook/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o0duu/external_hdd_external_hdd_via_macbook/", "subreddit_subscribers": 703028, "created_utc": 1695253432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 24 - 2TB SSDs and am unclear if the Dell PowerVault MD1220 will allow for all of them? The spec sheet only mentions 1.6TB SSDs, but I think thats what the option was to ship with? The Max capacity says \" Maximum capacity (per enclosure) Up to 48TB when using 24 x 2TB NL-SAS 2.5\u201d HDDs \" but does that apply to SSDs as well or only Nearline?\n\n[https://i.dell.com/sites/csdocuments/Shared-Content\\_data-Sheets\\_Documents/en/storage-powervault-md1220-specsheet.pdf](https://i.dell.com/sites/csdocuments/Shared-Content_data-Sheets_Documents/en/storage-powervault-md1220-specsheet.pdf)\n\n&amp;#x200B;", "author_fullname": "t2_i8t2x35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dell PowerVault MD1220 SSD Capacity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16onzzr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695322494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 24 - 2TB SSDs and am unclear if the Dell PowerVault MD1220 will allow for all of them? The spec sheet only mentions 1.6TB SSDs, but I think thats what the option was to ship with? The Max capacity says &amp;quot; Maximum capacity (per enclosure) Up to 48TB when using 24 x 2TB NL-SAS 2.5\u201d HDDs &amp;quot; but does that apply to SSDs as well or only Nearline?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://i.dell.com/sites/csdocuments/Shared-Content_data-Sheets_Documents/en/storage-powervault-md1220-specsheet.pdf\"&gt;https://i.dell.com/sites/csdocuments/Shared-Content_data-Sheets_Documents/en/storage-powervault-md1220-specsheet.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16onzzr", "is_robot_indexable": true, "report_reasons": null, "author": "fluce13", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16onzzr/dell_powervault_md1220_ssd_capacity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16onzzr/dell_powervault_md1220_ssd_capacity/", "subreddit_subscribers": 703028, "created_utc": 1695322494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to store complete copies of BluRay disks as ISO or BDMV folders (for playback with menu support on an Oppo player), but then also rip these disks into a compatible format for a PLEX library (mp4 or mkv, depending on which method would result in the most efficient dedup). \n\nIs there any viable deduplication strategy for such a setup, so that it would only require the storage space of approximately that single ISO/BDMV, and no additional storage space for the mp4/mkv files? \n\nWould block level dedup like offered by ZFS be viable for this? Are there better options?", "author_fullname": "t2_1nu5vo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deduplication options for movie library.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ofxls", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695302848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to store complete copies of BluRay disks as ISO or BDMV folders (for playback with menu support on an Oppo player), but then also rip these disks into a compatible format for a PLEX library (mp4 or mkv, depending on which method would result in the most efficient dedup). &lt;/p&gt;\n\n&lt;p&gt;Is there any viable deduplication strategy for such a setup, so that it would only require the storage space of approximately that single ISO/BDMV, and no additional storage space for the mp4/mkv files? &lt;/p&gt;\n\n&lt;p&gt;Would block level dedup like offered by ZFS be viable for this? Are there better options?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ofxls", "is_robot_indexable": true, "report_reasons": null, "author": "elecsys", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ofxls/deduplication_options_for_movie_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16ofxls/deduplication_options_for_movie_library/", "subreddit_subscribers": 703028, "created_utc": 1695302848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking for budget 3x SSD RAID 1 for Synology NAS, but i am afraid that drives will die at same time.\n\nWhat if i bought one 870 EVO (TLC) and 2x cheap 870 QVO (QLC)? Are there any possible issues with this setup ?\nMaybe even take one TLC SSD from different manufacturer.", "author_fullname": "t2_60vpu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2x QVO and 1x EVO in RAID 1 ? (Samsung 870)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16oengr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695300213.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695299391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for budget 3x SSD RAID 1 for Synology NAS, but i am afraid that drives will die at same time.&lt;/p&gt;\n\n&lt;p&gt;What if i bought one 870 EVO (TLC) and 2x cheap 870 QVO (QLC)? Are there any possible issues with this setup ?\nMaybe even take one TLC SSD from different manufacturer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16oengr", "is_robot_indexable": true, "report_reasons": null, "author": "Harrierx", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16oengr/2x_qvo_and_1x_evo_in_raid_1_samsung_870/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16oengr/2x_qvo_and_1x_evo_in_raid_1_samsung_870/", "subreddit_subscribers": 703028, "created_utc": 1695299391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I've been planning to buy a Crucial MX500 for data storage but when I check the 1-star reviews on amazon a lot of reviews say that they failed as a system drive. So, I would like to know if it's good for data storage. Thanks.", "author_fullname": "t2_s017aqbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crucial MX500 for Data Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16odnnq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695296587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve been planning to buy a Crucial MX500 for data storage but when I check the 1-star reviews on amazon a lot of reviews say that they failed as a system drive. So, I would like to know if it&amp;#39;s good for data storage. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "0B", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16odnnq", "is_robot_indexable": true, "report_reasons": null, "author": "-KasaneTeto-", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16odnnq/crucial_mx500_for_data_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16odnnq/crucial_mx500_for_data_storage/", "subreddit_subscribers": 703028, "created_utc": 1695296587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Title", "author_fullname": "t2_ldb4c05u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are servermonkey refurbished Dell HDDs good for the cheap price?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16omalt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695318468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16omalt", "is_robot_indexable": true, "report_reasons": null, "author": "sexpusa", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16omalt/are_servermonkey_refurbished_dell_hdds_good_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16omalt/are_servermonkey_refurbished_dell_hdds_good_for/", "subreddit_subscribers": 703028, "created_utc": 1695318468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know reddit hard limits posts to 40 pages (you can view last 1000 posted), but is there an already made script that does this + grabs comments+posts etc. \n\n&amp;nbsp;\n\nI could write something with wget and python myself, but there's probably an already existing solution. I looked on github but couldn't find anything specifically written that does this.", "author_fullname": "t2_fiawk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a subreddit scraper that can fetch everything upto limit? (1000 posts)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16od39y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695294797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know reddit hard limits posts to 40 pages (you can view last 1000 posted), but is there an already made script that does this + grabs comments+posts etc. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I could write something with wget and python myself, but there&amp;#39;s probably an already existing solution. I looked on github but couldn&amp;#39;t find anything specifically written that does this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16od39y", "is_robot_indexable": true, "report_reasons": null, "author": "Xillenn", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16od39y/is_there_a_subreddit_scraper_that_can_fetch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16od39y/is_there_a_subreddit_scraper_that_can_fetch/", "subreddit_subscribers": 703028, "created_utc": 1695294797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there\n\nI have a few questions regarding how I should set up my home NAS. The goal is to use it as storage for a PleX/media library, computer backups, a TimeMachine backup, and whatever else might come along. I'm planning on using TrueNAS to manage it all.\n\nI have 5x 14TB Seagate EXOS drives, but I'm not sure how many I should use (3, 4, or 5), or if I should be using RAID 5 or RAID 6. The main goal is 'future-proofing' (as much as we hate that term) so that I'm not having to rebuild/expand 5 years from now.\n\nMy questions are:\n\n\\-If I use 3 disks, and use them in RAID 5 (or whatever the TrueNAS terminology is), can I simply pop in another identical drive in the future to expand storage? Or are there particular issues with this/do I have to format the existing data to do so?\n\n\\-What RAID config. and number of disks would you recommend? I'm interested in using the least amount of disks possible to get \\~24TB, with a reasonable amount of redundancy. These drives are loud as hell so I really don't want to use all 5 unless I have to.\n\n\\-Wtf is ZFS?\n\n\\-Is there anything else I missed or additional questions I should be asking myself?\n\nThanks in advance for the guidance, I really appreciate it!", "author_fullname": "t2_8d4xgtcg0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAID Config Suggestions? 5x 14TB HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o27kr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695259214.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695258386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there&lt;/p&gt;\n\n&lt;p&gt;I have a few questions regarding how I should set up my home NAS. The goal is to use it as storage for a PleX/media library, computer backups, a TimeMachine backup, and whatever else might come along. I&amp;#39;m planning on using TrueNAS to manage it all.&lt;/p&gt;\n\n&lt;p&gt;I have 5x 14TB Seagate EXOS drives, but I&amp;#39;m not sure how many I should use (3, 4, or 5), or if I should be using RAID 5 or RAID 6. The main goal is &amp;#39;future-proofing&amp;#39; (as much as we hate that term) so that I&amp;#39;m not having to rebuild/expand 5 years from now.&lt;/p&gt;\n\n&lt;p&gt;My questions are:&lt;/p&gt;\n\n&lt;p&gt;-If I use 3 disks, and use them in RAID 5 (or whatever the TrueNAS terminology is), can I simply pop in another identical drive in the future to expand storage? Or are there particular issues with this/do I have to format the existing data to do so?&lt;/p&gt;\n\n&lt;p&gt;-What RAID config. and number of disks would you recommend? I&amp;#39;m interested in using the least amount of disks possible to get ~24TB, with a reasonable amount of redundancy. These drives are loud as hell so I really don&amp;#39;t want to use all 5 unless I have to.&lt;/p&gt;\n\n&lt;p&gt;-Wtf is ZFS?&lt;/p&gt;\n\n&lt;p&gt;-Is there anything else I missed or additional questions I should be asking myself?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for the guidance, I really appreciate it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o27kr", "is_robot_indexable": true, "report_reasons": null, "author": "_buttsnorkel", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o27kr/raid_config_suggestions_5x_14tb_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o27kr/raid_config_suggestions_5x_14tb_hdds/", "subreddit_subscribers": 703028, "created_utc": 1695258386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As Uptobox seems to be finished for good, do you know of a decent alternative ?", "author_fullname": "t2_vukgz0f2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative to uptobox?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o9hqf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695281443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As Uptobox seems to be finished for good, do you know of a decent alternative ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o9hqf", "is_robot_indexable": true, "report_reasons": null, "author": "JeanCompot", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o9hqf/alternative_to_uptobox/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o9hqf/alternative_to_uptobox/", "subreddit_subscribers": 703028, "created_utc": 1695281443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to recover some deleted Twitch videos(A particular streamer) and I was wondering if there were any hoarders!\n\nhttps://m.twitch.tv/hjihae29/clips", "author_fullname": "t2_qeqw2bmc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi, is there anyone who hoards Twitch videos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o97sj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695283912.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695280413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to recover some deleted Twitch videos(A particular streamer) and I was wondering if there were any hoarders!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://m.twitch.tv/hjihae29/clips\"&gt;https://m.twitch.tv/hjihae29/clips&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2i4C6YiwLaNyJn54AWW8skKndQihqC01Oogdo7SlnNM.jpg?auto=webp&amp;s=3175dd663c0d13856c3f9aa8d43b9345b100cee3", "width": 262, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/2i4C6YiwLaNyJn54AWW8skKndQihqC01Oogdo7SlnNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=45c8dbb731ad7a3a12735f854f64e13df2fdc3cc", "width": 108, "height": 82}, {"url": "https://external-preview.redd.it/2i4C6YiwLaNyJn54AWW8skKndQihqC01Oogdo7SlnNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5dd50b2b25dfbe8474f443aa3e60abdbc34df29c", "width": 216, "height": 164}], "variants": {}, "id": "pBgDB-nWlH1d9nm0GMhb7-1kZNBZKPjWWWJL-GlPp0E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o97sj", "is_robot_indexable": true, "report_reasons": null, "author": "renata_m_00", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o97sj/hi_is_there_anyone_who_hoards_twitch_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o97sj/hi_is_there_anyone_who_hoards_twitch_videos/", "subreddit_subscribers": 703028, "created_utc": 1695280413.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}