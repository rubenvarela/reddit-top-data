{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On my PC, I really couldn't be bothered to fit a 3.5 inch drive in the case that I have, so instead I use an external hard drive enclosure that connects through USB 3.1 that also has to be plugged into an outlet. I use this hard drive (14tb) to store all of my shows and movies that I own to use for Plex! Thing is, what I've been doing is whenever I want to watch something, I'll turn on the PC and then turn on the drive. Once I'm done for the day, I turn the drive off, and then put my PC to sleep. Whenever I turn on the drive or when it has to \"wake up\" when it's already on, it does a bunch of click noises for a few seconds as it's booting up, which is normal. My question is, does the drive booting up put more strain on it then if I were to just keep it on? And if I were to keep it on, is there a way to prevent the drive from \"going to sleep\" while it's turned on? Or should I just stick to turning it off whenever I don't use it? Thanks!", "author_fullname": "t2_5e3g1q3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should a hard drive be powered off when not in use, or is it better to keep it on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16npix0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695226990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On my PC, I really couldn&amp;#39;t be bothered to fit a 3.5 inch drive in the case that I have, so instead I use an external hard drive enclosure that connects through USB 3.1 that also has to be plugged into an outlet. I use this hard drive (14tb) to store all of my shows and movies that I own to use for Plex! Thing is, what I&amp;#39;ve been doing is whenever I want to watch something, I&amp;#39;ll turn on the PC and then turn on the drive. Once I&amp;#39;m done for the day, I turn the drive off, and then put my PC to sleep. Whenever I turn on the drive or when it has to &amp;quot;wake up&amp;quot; when it&amp;#39;s already on, it does a bunch of click noises for a few seconds as it&amp;#39;s booting up, which is normal. My question is, does the drive booting up put more strain on it then if I were to just keep it on? And if I were to keep it on, is there a way to prevent the drive from &amp;quot;going to sleep&amp;quot; while it&amp;#39;s turned on? Or should I just stick to turning it off whenever I don&amp;#39;t use it? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16npix0", "is_robot_indexable": true, "report_reasons": null, "author": "WaldyTMS", "discussion_type": null, "num_comments": 89, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16npix0/should_a_hard_drive_be_powered_off_when_not_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16npix0/should_a_hard_drive_be_powered_off_when_not_in/", "subreddit_subscribers": 702996, "created_utc": 1695226990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been wanting to announce this here for a while now, but if you do download stuff from the website please don't download a lot of stuff at once!\n\n&amp;#x200B;\n\n**This is ExternalTube**, an early, read-only, YouTube archive/preservation project \\[made by my friend IdioticSniper\\] with a lot of lost, normal and rare videos scraped from the old YouTube CDNs. We've gotten some amazingly rare stuff, like old videos with almost 2 views at-most, videos from the user \"videos\" \\[their channel was completely wiped by YouTube themselves\\] and lost-until-now videos from the user \"steve\". More than 100 CDNs have been scraped and the archive is currently at 120GB, with the hard-drive hosting the files and everything supporting 3TB.\n\nI recommend you check it out on an Adobe Flash-compatible browser, it's amazing!\n\nhttps://preview.redd.it/8ff1il0d8lpb1.png?width=521&amp;format=png&amp;auto=webp&amp;s=64625e8b53793741b6543a9f9c2b6a68431767e4\n\nQuick warning though: Since this is from the old YouTube CDNs, those are all in FLV quality and use the old YouTube Flash player from 2005.\n\nSo what are you waiting for? **Dig through the archives.**\n\n[**https://exttube.snippr.win**](https://exttube.snippr.win)\n\n&amp;#x200B;\n\n**EDIT:** The source code has been released! [**https://github.com/IdioticSniper/externaltube**](https://github.com/IdioticSniper/externaltube)", "author_fullname": "t2_7a9ymbww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ExternalTube - A YouTube archive project that ranges with videos from 2005-2009.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"8ff1il0d8lpb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 125, "x": 108, "u": "https://preview.redd.it/8ff1il0d8lpb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3f9d765ff6f49d0bdc003ad0091b991393d75ac4"}, {"y": 251, "x": 216, "u": "https://preview.redd.it/8ff1il0d8lpb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8df8bbb2d6e089ad8481051195db925ddd1e5157"}, {"y": 372, "x": 320, "u": "https://preview.redd.it/8ff1il0d8lpb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8b7982594d2f006755d988b6e3ec7b05481d1623"}], "s": {"y": 606, "x": 521, "u": "https://preview.redd.it/8ff1il0d8lpb1.png?width=521&amp;format=png&amp;auto=webp&amp;s=64625e8b53793741b6543a9f9c2b6a68431767e4"}, "id": "8ff1il0d8lpb1"}}, "name": "t3_16ocljy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 98, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 98, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uIbBDETLrN3yy7Qy8Ajyf14E5-clV7VqsL0TPzdiYVs.jpg", "edited": 1695297169.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695293113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been wanting to announce this here for a while now, but if you do download stuff from the website please don&amp;#39;t download a lot of stuff at once!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;This is ExternalTube&lt;/strong&gt;, an early, read-only, YouTube archive/preservation project [made by my friend IdioticSniper] with a lot of lost, normal and rare videos scraped from the old YouTube CDNs. We&amp;#39;ve gotten some amazingly rare stuff, like old videos with almost 2 views at-most, videos from the user &amp;quot;videos&amp;quot; [their channel was completely wiped by YouTube themselves] and lost-until-now videos from the user &amp;quot;steve&amp;quot;. More than 100 CDNs have been scraped and the archive is currently at 120GB, with the hard-drive hosting the files and everything supporting 3TB.&lt;/p&gt;\n\n&lt;p&gt;I recommend you check it out on an Adobe Flash-compatible browser, it&amp;#39;s amazing!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8ff1il0d8lpb1.png?width=521&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=64625e8b53793741b6543a9f9c2b6a68431767e4\"&gt;https://preview.redd.it/8ff1il0d8lpb1.png?width=521&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=64625e8b53793741b6543a9f9c2b6a68431767e4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Quick warning though: Since this is from the old YouTube CDNs, those are all in FLV quality and use the old YouTube Flash player from 2005.&lt;/p&gt;\n\n&lt;p&gt;So what are you waiting for? &lt;strong&gt;Dig through the archives.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://exttube.snippr.win\"&gt;&lt;strong&gt;https://exttube.snippr.win&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; The source code has been released! &lt;a href=\"https://github.com/IdioticSniper/externaltube\"&gt;&lt;strong&gt;https://github.com/IdioticSniper/externaltube&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ocljy", "is_robot_indexable": true, "report_reasons": null, "author": "Peak_Environmental", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ocljy/externaltube_a_youtube_archive_project_that/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/DataHoarder/comments/16ocljy/externaltube_a_youtube_archive_project_that/", "subreddit_subscribers": 702996, "created_utc": 1695293113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just seen that WD has an insane 26TB drive available in the DC: [https://www.westerndigital.com/products/internal-drives/data-center-drives/ultrastar-dc-hc670-hdd#ultrastar-dc-hc670-26-tb](https://www.westerndigital.com/products/internal-drives/data-center-drives/ultrastar-dc-hc670-hdd#ultrastar-dc-hc670-26-tb)\n\nScientifically, what's the biggest we could possibly fit on spinning disk in the current form factor? Surely there's a physical limit? ", "author_fullname": "t2_ro8ik", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At what point will we reach peak storage size in hard drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16numz6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695239424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just seen that WD has an insane 26TB drive available in the DC: &lt;a href=\"https://www.westerndigital.com/products/internal-drives/data-center-drives/ultrastar-dc-hc670-hdd#ultrastar-dc-hc670-26-tb\"&gt;https://www.westerndigital.com/products/internal-drives/data-center-drives/ultrastar-dc-hc670-hdd#ultrastar-dc-hc670-26-tb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Scientifically, what&amp;#39;s the biggest we could possibly fit on spinning disk in the current form factor? Surely there&amp;#39;s a physical limit? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?auto=webp&amp;s=a41ff0fdcfcde1d1841bca3867a64d20af98599e", "width": 1680, "height": 1680}, "resolutions": [{"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e35c72523a88d628c886733aebf3b71702d4ae31", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=004b63d44cedb6c233c4b5037b0003f95f7eeca4", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1bc5f9dbdf2de000fd3fa3c6a3088f990b9b383c", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1f51e2df3ad2186e36eabf026bc6ec7375d73d8b", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=83228573b58ab085899e58c54b9b7b2b9fe29b54", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/PSfzLBiEwk-eX-3McDum8-hW0ra85BFcmEbF7vqyKZU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8abf82144a3038cc55fbeec4e3a1a25517915075", "width": 1080, "height": 1080}], "variants": {}, "id": "Khc_0UMAclTalgRJT3IYyERuIUrcrmbqKAeBllAcL7U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "2.8e+9 KBs", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16numz6", "is_robot_indexable": true, "report_reasons": null, "author": "westie1010", "discussion_type": null, "num_comments": 133, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16numz6/at_what_point_will_we_reach_peak_storage_size_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16numz6/at_what_point_will_we_reach_peak_storage_size_in/", "subreddit_subscribers": 702996, "created_utc": 1695239424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Okay this is a weird one, and I feel like I might be alone in this one, does anyone else hoard Blu-ray images, by that I mean full copies of the disk using MakeMKV (decrypted files) I don't know why I started to do this, but I have a big fear of my Blu-rays dying eventually, or worse getting damaged or stolen. So for months I've been hoarding the full disk to my drives. Is this just silly? Should I just keep a remux of the main file? I just like the idea of if one died, I could essentially buy a blank 50gb+ disc and burn a copy back that would be just the same as the original.", "author_fullname": "t2_b5jpuno7e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone else hoard BluRay images?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nytnr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695249369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Okay this is a weird one, and I feel like I might be alone in this one, does anyone else hoard Blu-ray images, by that I mean full copies of the disk using MakeMKV (decrypted files) I don&amp;#39;t know why I started to do this, but I have a big fear of my Blu-rays dying eventually, or worse getting damaged or stolen. So for months I&amp;#39;ve been hoarding the full disk to my drives. Is this just silly? Should I just keep a remux of the main file? I just like the idea of if one died, I could essentially buy a blank 50gb+ disc and burn a copy back that would be just the same as the original.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16nytnr", "is_robot_indexable": true, "report_reasons": null, "author": "Hastetheapple", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nytnr/does_anyone_else_hoard_bluray_images/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nytnr/does_anyone_else_hoard_bluray_images/", "subreddit_subscribers": 702996, "created_utc": 1695249369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve seen a lot of good comments on serverpartsdeals.com so I decided to take the plunge last week.  Bought 2 recertified seagate x20 18tb exos drives for cheap.  Both arrived quickly and well packaged.  On top of that, THEY HAD 0 HOURS ON THEM.  Currently half way through unraids full preclear cycle(god I wish this tool existed on other OSs) and absolutely no errors or anything.\n\nJust wanted to post this as others have mentioned they have good results from them as well.", "author_fullname": "t2_ytkgh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just another positive experience with serverpartsdeals", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nwfhg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695243779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve seen a lot of good comments on serverpartsdeals.com so I decided to take the plunge last week.  Bought 2 recertified seagate x20 18tb exos drives for cheap.  Both arrived quickly and well packaged.  On top of that, THEY HAD 0 HOURS ON THEM.  Currently half way through unraids full preclear cycle(god I wish this tool existed on other OSs) and absolutely no errors or anything.&lt;/p&gt;\n\n&lt;p&gt;Just wanted to post this as others have mentioned they have good results from them as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "708TB Unraid", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nwfhg", "is_robot_indexable": true, "report_reasons": null, "author": "sittingmongoose", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16nwfhg/just_another_positive_experience_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nwfhg/just_another_positive_experience_with/", "subreddit_subscribers": 702996, "created_utc": 1695243779.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently running 3x 8tb drives in RAID 5 (Windows configuration)  with a few additional smaller drives on the side. Pretty much just an old gaming pc, because I already had it. It's served it's purpose well, but I'm at the point where the motherboard itself can't handle many more drives. Any ideas on where I should go from here? Mainly looking for ideas on how I can 'future-proof' the number of drives I'll collect and want to attach in the next couple years. I'd love to continue using most of the hardware I have if possible, considering it still works fine. Are there motherboards I should be looking for specifically with this purpose? Do they make some sort of SATA expansion slot for PCIE or any other solutions? Would like to prepare for 10-15 drives within the next 2-3 years.\n\nAlso, been looking for a different RAID solution but not too sure on what's hot these days. Are hardware RAID controllers the way to go?", "author_fullname": "t2_txa4pf2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Number of drives getting pretty high. Looking for where to upgrade next in order to expand amount of drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nph5n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695226868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently running 3x 8tb drives in RAID 5 (Windows configuration)  with a few additional smaller drives on the side. Pretty much just an old gaming pc, because I already had it. It&amp;#39;s served it&amp;#39;s purpose well, but I&amp;#39;m at the point where the motherboard itself can&amp;#39;t handle many more drives. Any ideas on where I should go from here? Mainly looking for ideas on how I can &amp;#39;future-proof&amp;#39; the number of drives I&amp;#39;ll collect and want to attach in the next couple years. I&amp;#39;d love to continue using most of the hardware I have if possible, considering it still works fine. Are there motherboards I should be looking for specifically with this purpose? Do they make some sort of SATA expansion slot for PCIE or any other solutions? Would like to prepare for 10-15 drives within the next 2-3 years.&lt;/p&gt;\n\n&lt;p&gt;Also, been looking for a different RAID solution but not too sure on what&amp;#39;s hot these days. Are hardware RAID controllers the way to go?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nph5n", "is_robot_indexable": true, "report_reasons": null, "author": "empaw1", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nph5n/number_of_drives_getting_pretty_high_looking_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nph5n/number_of_drives_getting_pretty_high_looking_for/", "subreddit_subscribers": 702996, "created_utc": 1695226868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I've been struggling with this for the past hour. I have a video I want to archive from a website that no longer exists. I'm pretty sure Internet Archived it because I was able to play the video once (and then it stopped working). The video I'm trying to download is a flash video but it loads up using Ruffle. How can I download this video: [https://web.archive.org/web/20121005125354/http://debatevision.com/videos/122/spartan-debate-institute-2011-how-to-learn-by-watching](https://web.archive.org/web/20121005125354/http://debatevision.com/videos/122/spartan-debate-institute-2011-how-to-learn-by-watching) ", "author_fullname": "t2_7zjm3ef7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download a flash video from Internet Archive (not YouTube).", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o2p74", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695259731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been struggling with this for the past hour. I have a video I want to archive from a website that no longer exists. I&amp;#39;m pretty sure Internet Archived it because I was able to play the video once (and then it stopped working). The video I&amp;#39;m trying to download is a flash video but it loads up using Ruffle. How can I download this video: &lt;a href=\"https://web.archive.org/web/20121005125354/http://debatevision.com/videos/122/spartan-debate-institute-2011-how-to-learn-by-watching\"&gt;https://web.archive.org/web/20121005125354/http://debatevision.com/videos/122/spartan-debate-institute-2011-how-to-learn-by-watching&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o2p74", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Loomer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o2p74/how_to_download_a_flash_video_from_internet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o2p74/how_to_download_a_flash_video_from_internet/", "subreddit_subscribers": 702996, "created_utc": 1695259731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, as in title. How do You put your psychical book into computer? I want to do so mostly to be able to \"grep\" over my book collections but it also feel handy as ripping CD so I can access my bookshelf from remote location. \n\n&amp;#x200B;\n\nSo that's a question as I hoard ton of papier lately", "author_fullname": "t2_11am0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you digitalize Your books?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16og3dj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695303265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, as in title. How do You put your psychical book into computer? I want to do so mostly to be able to &amp;quot;grep&amp;quot; over my book collections but it also feel handy as ripping CD so I can access my bookshelf from remote location. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So that&amp;#39;s a question as I hoard ton of papier lately&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16og3dj", "is_robot_indexable": true, "report_reasons": null, "author": "wytrzeszcz", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16og3dj/how_do_you_digitalize_your_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16og3dj/how_do_you_digitalize_your_books/", "subreddit_subscribers": 702996, "created_utc": 1695303265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking for budget 3x SSD RAID 1 for Synology NAS, but i am afraid that drives will die at same time.\n\nWhat if i bought one 870 EVO (TLC) and 2x cheap 870 QVO (QLC)? Are there any possible issues with this setup ?\nMaybe even take one TLC SSD from different manufacturer.", "author_fullname": "t2_60vpu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "2x QVO and 1x EVO in RAID 1 ? (Samsung 870)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16oengr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695300213.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695299391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for budget 3x SSD RAID 1 for Synology NAS, but i am afraid that drives will die at same time.&lt;/p&gt;\n\n&lt;p&gt;What if i bought one 870 EVO (TLC) and 2x cheap 870 QVO (QLC)? Are there any possible issues with this setup ?\nMaybe even take one TLC SSD from different manufacturer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16oengr", "is_robot_indexable": true, "report_reasons": null, "author": "Harrierx", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16oengr/2x_qvo_and_1x_evo_in_raid_1_samsung_870/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16oengr/2x_qvo_and_1x_evo_in_raid_1_samsung_870/", "subreddit_subscribers": 702996, "created_utc": 1695299391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m working on a archival project for a certain youtuber, he spams his community tab all day with stuff and I\u2019d like a efficient way for me to archive it. \n\nIs there any software or script that will automatically scan and take screenshots or something of the community posts? I\u2019d prefer fully automatic as I\u2019ll probably forget eventually but if not that\u2019s alright. \n\nI don\u2019t know how to code or anything so the terminal and python stuff really confuses me. But I will learn if I have to.", "author_fullname": "t2_g9dhzldt6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone help me find a way to automatically archive Youtube Community Post?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o9yg9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695283266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on a archival project for a certain youtuber, he spams his community tab all day with stuff and I\u2019d like a efficient way for me to archive it. &lt;/p&gt;\n\n&lt;p&gt;Is there any software or script that will automatically scan and take screenshots or something of the community posts? I\u2019d prefer fully automatic as I\u2019ll probably forget eventually but if not that\u2019s alright. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t know how to code or anything so the terminal and python stuff really confuses me. But I will learn if I have to.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o9yg9", "is_robot_indexable": true, "report_reasons": null, "author": "YendoZakari", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o9yg9/can_anyone_help_me_find_a_way_to_automatically/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o9yg9/can_anyone_help_me_find_a_way_to_automatically/", "subreddit_subscribers": 702996, "created_utc": 1695283266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey, so I'm planning on building a new PC and want to use my old one as a data storage. For that purpose I would install a minimal Linux distro, get a few HDDs, create a ZFS from them and share the mountpoint with Samba.  \nI plan to use 8 WD Ultrastar 18TB drives with SAS, get a [LSI 9211-8i](https://www.ebay.com/itm/163846248833?hash=item2625ff5981:g:shEAAOSwPKZdbst~) from an ebay store named theartofserver which I've heard is quite good, connect them with two SFF-8087 to 4x SFF-8482 adapters with SATA-power ports for each drive and get two 4x power splitters since my PSU doesn't have enough slots.  \nTo reduce the cost for now, I'd first like to get 4 drives and add another 4 later on.  \nI was thinking of RAID-Z2\\*ing them; even though my CPU (i7-6700) does not support ECC memory, so I won't upgrade and keep using the 32GB of non-ECC I already have.  \nNow my questions:\n\n1. Is it feasible to add the other drives later or would that be overly complicated/make the system worse in any way?\n2. Pretty sure deduplication is out of question with that small amout of memory?\n3. Is the setup I've planned in general even recommendable?\n4. Could I have family members on Windows also access the storage? It says there is a Windows version of OpenZFS, so I guess they should be able to just connect to it (after installing the driver, if necessary)?\n5. Is there anything else I didn't ask I still probably need to know?  \n\n\nThis is my first time building a dedicated hoarding setup so I'm relying on you guys' expertise to not make the stupidest of rookie mistakes.  \nThanks for your help!", "author_fullname": "t2_6wjy8pd6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advise for planned setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nsrh6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695234806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, so I&amp;#39;m planning on building a new PC and want to use my old one as a data storage. For that purpose I would install a minimal Linux distro, get a few HDDs, create a ZFS from them and share the mountpoint with Samba.&lt;br/&gt;\nI plan to use 8 WD Ultrastar 18TB drives with SAS, get a &lt;a href=\"https://www.ebay.com/itm/163846248833?hash=item2625ff5981:g:shEAAOSwPKZdbst%7E\"&gt;LSI 9211-8i&lt;/a&gt; from an ebay store named theartofserver which I&amp;#39;ve heard is quite good, connect them with two SFF-8087 to 4x SFF-8482 adapters with SATA-power ports for each drive and get two 4x power splitters since my PSU doesn&amp;#39;t have enough slots.&lt;br/&gt;\nTo reduce the cost for now, I&amp;#39;d first like to get 4 drives and add another 4 later on.&lt;br/&gt;\nI was thinking of RAID-Z2*ing them; even though my CPU (i7-6700) does not support ECC memory, so I won&amp;#39;t upgrade and keep using the 32GB of non-ECC I already have.&lt;br/&gt;\nNow my questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Is it feasible to add the other drives later or would that be overly complicated/make the system worse in any way?&lt;/li&gt;\n&lt;li&gt;Pretty sure deduplication is out of question with that small amout of memory?&lt;/li&gt;\n&lt;li&gt;Is the setup I&amp;#39;ve planned in general even recommendable?&lt;/li&gt;\n&lt;li&gt;Could I have family members on Windows also access the storage? It says there is a Windows version of OpenZFS, so I guess they should be able to just connect to it (after installing the driver, if necessary)?&lt;/li&gt;\n&lt;li&gt;Is there anything else I didn&amp;#39;t ask I still probably need to know?&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This is my first time building a dedicated hoarding setup so I&amp;#39;m relying on you guys&amp;#39; expertise to not make the stupidest of rookie mistakes.&lt;br/&gt;\nThanks for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TqXvIsIFQU0KNh3zcKqZz1yu6UD08NQ0nMcm8OoTXs4.jpg?auto=webp&amp;s=8aeff900e01acec1e41cd355023f8d283ad21598", "width": 500, "height": 383}, "resolutions": [{"url": "https://external-preview.redd.it/TqXvIsIFQU0KNh3zcKqZz1yu6UD08NQ0nMcm8OoTXs4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=70fccbe6158c56b90cde7366dd9bf0d491b165ca", "width": 108, "height": 82}, {"url": "https://external-preview.redd.it/TqXvIsIFQU0KNh3zcKqZz1yu6UD08NQ0nMcm8OoTXs4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a3b1d8f4764219c389669b87f83234af73ea4596", "width": 216, "height": 165}, {"url": "https://external-preview.redd.it/TqXvIsIFQU0KNh3zcKqZz1yu6UD08NQ0nMcm8OoTXs4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8df5e0f34094b3dd3e2e397d4a5b96fd0f75180a", "width": 320, "height": 245}], "variants": {}, "id": "PiwoR-McPwZnB1QbMRKxlkPC6TN9l4V2l4nkzOcq5rM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nsrh6", "is_robot_indexable": true, "report_reasons": null, "author": "Alathic", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nsrh6/advise_for_planned_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nsrh6/advise_for_planned_setup/", "subreddit_subscribers": 702996, "created_utc": 1695234806.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm interested in backing up my photo collection to backblaze b2b (as it seems the best value supplier)\n\nI am considering using rclone and crypt as it seems like the best solution.\n\nThe query is this, what is the best workflow to approach this from ?  I have some historic bitrot and I want to ensure that duplicate photos are deleted but the files themselves are not bit identical as picasa and myself have edited the exif metadata.  So only the underlying image data should be checked.\n\nHas anyone else approached this ?  Filesystem deduplication doesn't seem to be the answer.\n\nI have been thinking about using exiftool to export the sha1 to an xmp sidecar, and use python to identify duplicate checksums.  Is this a good approach ?\n\nAs an aside, I have also exported my data from google takeout in case my local data lacks integrity, but that has its exifdata stripped and the images resized I believe.\n\nAny advice would be appreciated.  Cheers.", "author_fullname": "t2_1w5zqtt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backing up and deduplicating digital camera photos to the cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16oarur", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695286407.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in backing up my photo collection to backblaze b2b (as it seems the best value supplier)&lt;/p&gt;\n\n&lt;p&gt;I am considering using rclone and crypt as it seems like the best solution.&lt;/p&gt;\n\n&lt;p&gt;The query is this, what is the best workflow to approach this from ?  I have some historic bitrot and I want to ensure that duplicate photos are deleted but the files themselves are not bit identical as picasa and myself have edited the exif metadata.  So only the underlying image data should be checked.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else approached this ?  Filesystem deduplication doesn&amp;#39;t seem to be the answer.&lt;/p&gt;\n\n&lt;p&gt;I have been thinking about using exiftool to export the sha1 to an xmp sidecar, and use python to identify duplicate checksums.  Is this a good approach ?&lt;/p&gt;\n\n&lt;p&gt;As an aside, I have also exported my data from google takeout in case my local data lacks integrity, but that has its exifdata stripped and the images resized I believe.&lt;/p&gt;\n\n&lt;p&gt;Any advice would be appreciated.  Cheers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16oarur", "is_robot_indexable": true, "report_reasons": null, "author": "simonmcnair", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16oarur/backing_up_and_deduplicating_digital_camera/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16oarur/backing_up_and_deduplicating_digital_camera/", "subreddit_subscribers": 702996, "created_utc": 1695286407.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So, I'm the manager of a new educative Workspace Fundamentals, per my knowledge all Google Drive storage is now pooled, no unlimited anymore which is fine for us, however I was migrating some data to shared drives and I noticed even after 48 hours that Shared Drives space was not pooled or showing up on the storage bar, is this normal? It seems to be unlimited or am I doing something wrong? Checking also the subscriptions and billing part as we don't want any overcharges but I don't see any \"surprise\" charges.  \n\n\nI don't have any intention on using more than 100Tb, but just curious about it.\n\n&amp;#x200B;\n\nThank you all!\n\nhttps://preview.redd.it/k52spzieikpb1.png?width=2003&amp;format=png&amp;auto=webp&amp;s=81182cd2242462d178815f508695d0ae743642d6", "author_fullname": "t2_11x0y2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shared Drives not part as Pooled Storage? Google Drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 42, "top_awarded_type": null, "hide_score": false, "media_metadata": {"k52spzieikpb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 32, "x": 108, "u": "https://preview.redd.it/k52spzieikpb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a04b233c13b2c51fd83bac625f8be0f0ade506f"}, {"y": 65, "x": 216, "u": "https://preview.redd.it/k52spzieikpb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c953ff63ee88f290c6f0813713738012b441fca2"}, {"y": 97, "x": 320, "u": "https://preview.redd.it/k52spzieikpb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=77912a1ff9c27283a90314ed51e8ffa22c46da17"}, {"y": 194, "x": 640, "u": "https://preview.redd.it/k52spzieikpb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=714062537d226855060b049ba48cd369214c27ac"}, {"y": 291, "x": 960, "u": "https://preview.redd.it/k52spzieikpb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=53d167726462d7c006c0999f3d55b0e71bd0de74"}, {"y": 328, "x": 1080, "u": "https://preview.redd.it/k52spzieikpb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=852dc131265fbaa6a0bea4a3e3c6cdeccabec429"}], "s": {"y": 609, "x": 2003, "u": "https://preview.redd.it/k52spzieikpb1.png?width=2003&amp;format=png&amp;auto=webp&amp;s=81182cd2242462d178815f508695d0ae743642d6"}, "id": "k52spzieikpb1"}}, "name": "t3_16oa7np", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1LCn13ikVyKDN7PrXK2lqBmTOEwOjemV9Lk1xhf_amY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695284238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I&amp;#39;m the manager of a new educative Workspace Fundamentals, per my knowledge all Google Drive storage is now pooled, no unlimited anymore which is fine for us, however I was migrating some data to shared drives and I noticed even after 48 hours that Shared Drives space was not pooled or showing up on the storage bar, is this normal? It seems to be unlimited or am I doing something wrong? Checking also the subscriptions and billing part as we don&amp;#39;t want any overcharges but I don&amp;#39;t see any &amp;quot;surprise&amp;quot; charges.  &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have any intention on using more than 100Tb, but just curious about it.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you all!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/k52spzieikpb1.png?width=2003&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81182cd2242462d178815f508695d0ae743642d6\"&gt;https://preview.redd.it/k52spzieikpb1.png?width=2003&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81182cd2242462d178815f508695d0ae743642d6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16oa7np", "is_robot_indexable": true, "report_reasons": null, "author": "alemonpie", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16oa7np/shared_drives_not_part_as_pooled_storage_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16oa7np/shared_drives_not_part_as_pooled_storage_google/", "subreddit_subscribers": 702996, "created_utc": 1695284238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As Uptobox seems to be finished for good, do you know of a decent alternative ?", "author_fullname": "t2_vukgz0f2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative to uptobox?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o9hqf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695281443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As Uptobox seems to be finished for good, do you know of a decent alternative ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o9hqf", "is_robot_indexable": true, "report_reasons": null, "author": "JeanCompot", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o9hqf/alternative_to_uptobox/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o9hqf/alternative_to_uptobox/", "subreddit_subscribers": 702996, "created_utc": 1695281443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CD-Drives and Ferrite Cores: Are they necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o5q90", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_118v1j", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Cd_collectors", "selftext": "I have a set of external DVD-drives, and they came with USB Mini cables, which all the cables have ferrite cores.\n\nI picked up some second hand DVD-drives that didn't come with USB Mini  cables. I bought some spare cables, and recently picked up more ferrite cores.\n\n&amp;#x200B;\n\n**Question:**\n\nDo external portable CD-Drives need a ferrite core, if all it's doing is reading/writing data? Or would it be fine to use USB mini cables without the ferrite core?\n\nAlso, the USB Mini cables I picked up are pretty cheap.\n\nBut I don't know how noise would interfere with any CD or DVD extraction. Is noise or interference  possible in my case?", "author_fullname": "t2_118v1j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CD-Drives and Ferrite Cores: Are they necessary?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Cd_collectors", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o5o6l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695268267.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Cd_collectors", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a set of external DVD-drives, and they came with USB Mini cables, which all the cables have ferrite cores.&lt;/p&gt;\n\n&lt;p&gt;I picked up some second hand DVD-drives that didn&amp;#39;t come with USB Mini  cables. I bought some spare cables, and recently picked up more ferrite cores.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Do external portable CD-Drives need a ferrite core, if all it&amp;#39;s doing is reading/writing data? Or would it be fine to use USB mini cables without the ferrite core?&lt;/p&gt;\n\n&lt;p&gt;Also, the USB Mini cables I picked up are pretty cheap.&lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t know how noise would interfere with any CD or DVD extraction. Is noise or interference  possible in my case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "49431bd4-437f-11ec-97c0-c2be14adce00", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2uxz7", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#646d73", "id": "16o5o6l", "is_robot_indexable": true, "report_reasons": null, "author": "nPrevail", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Cd_collectors/comments/16o5o6l/cddrives_and_ferrite_cores_are_they_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/Cd_collectors/comments/16o5o6l/cddrives_and_ferrite_cores_are_they_necessary/", "subreddit_subscribers": 33752, "created_utc": 1695268267.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1695268449.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Cd_collectors", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/Cd_collectors/comments/16o5o6l/cddrives_and_ferrite_cores_are_they_necessary/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16o5q90", "is_robot_indexable": true, "report_reasons": null, "author": "nPrevail", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_16o5o6l", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o5q90/cddrives_and_ferrite_cores_are_they_necessary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/Cd_collectors/comments/16o5o6l/cddrives_and_ferrite_cores_are_they_necessary/", "subreddit_subscribers": 702996, "created_utc": 1695268449.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "(Originally posted here: https://unix.stackexchange.com/q/757117)\n\nIf we do\n\n    rsync -a --link-dest=dest1 src dest2\n\nThen rsync will only copy files in `src` which have been modified compared to `dest1`. However, even if only one byte in a 1GB file is modified, the entire 1GB will be copied.\n\nHow to change the command so that\n\n 1. Old versions of the backup are all kept;\n 2. Only the delta of each file is copied;\n 3. We can restore any version of any files;\n 4. We can, in some way, remove the old backups while keeping newer versions?\n\n(This is sort of like snapshots in filesystems like ZFS.)", "author_fullname": "t2_nw8uzkwp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most space-efficient way of using rsync to do incremental back up, saving only deltas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o4ee9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695264425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Originally posted here: &lt;a href=\"https://unix.stackexchange.com/q/757117\"&gt;https://unix.stackexchange.com/q/757117&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;If we do&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;rsync -a --link-dest=dest1 src dest2\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then rsync will only copy files in &lt;code&gt;src&lt;/code&gt; which have been modified compared to &lt;code&gt;dest1&lt;/code&gt;. However, even if only one byte in a 1GB file is modified, the entire 1GB will be copied.&lt;/p&gt;\n\n&lt;p&gt;How to change the command so that&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Old versions of the backup are all kept;&lt;/li&gt;\n&lt;li&gt;Only the delta of each file is copied;&lt;/li&gt;\n&lt;li&gt;We can restore any version of any files;&lt;/li&gt;\n&lt;li&gt;We can, in some way, remove the old backups while keeping newer versions?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;(This is sort of like snapshots in filesystems like ZFS.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bK4oXKNpgxoE53LCEzd4qyFMVNZmmo1f8nfKJ6xAfwY.jpg?auto=webp&amp;s=4d3a3fdcce8a0b6f57eff17914edd41d6cba223d", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/bK4oXKNpgxoE53LCEzd4qyFMVNZmmo1f8nfKJ6xAfwY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=101ef2d5c1c11cd19dc570a3de92b1d42dd4619f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/bK4oXKNpgxoE53LCEzd4qyFMVNZmmo1f8nfKJ6xAfwY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a374f1faf62ab4af6a8201f9deb3ea9b18c78dc5", "width": 216, "height": 216}], "variants": {}, "id": "Eu27KCJ9gAHAoJ1FuuHqnnJTGcSqDhwVFQAcFhKk4cc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o4ee9", "is_robot_indexable": true, "report_reasons": null, "author": "spherical_shell", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o4ee9/most_spaceefficient_way_of_using_rsync_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o4ee9/most_spaceefficient_way_of_using_rsync_to_do/", "subreddit_subscribers": 702996, "created_utc": 1695264425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am sure this question has been asked many many (many) times, but I wanted to ensure I had my exact situation covered. \n\nI have a Mac-formatted 2TB external HDD. On the 'get info' panel, the format states \"Mac OS Extended (Journaled)\". I have a bunch of stuff on here that I want to transfer to another brand-new external HDD. This is not formatted for a Mac. The intention is to be able to have these files read by a Windows operating system, so I do not want to have to re-format to Mac. \n\nIs there any way I can transfer from the first HDD to the new one in such a way that the new HDD can be in a read/write state for Windows?", "author_fullname": "t2_6zrr9l4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External HDD --&gt; External HDD via Macbook", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o0duu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695253432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am sure this question has been asked many many (many) times, but I wanted to ensure I had my exact situation covered. &lt;/p&gt;\n\n&lt;p&gt;I have a Mac-formatted 2TB external HDD. On the &amp;#39;get info&amp;#39; panel, the format states &amp;quot;Mac OS Extended (Journaled)&amp;quot;. I have a bunch of stuff on here that I want to transfer to another brand-new external HDD. This is not formatted for a Mac. The intention is to be able to have these files read by a Windows operating system, so I do not want to have to re-format to Mac. &lt;/p&gt;\n\n&lt;p&gt;Is there any way I can transfer from the first HDD to the new one in such a way that the new HDD can be in a read/write state for Windows?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o0duu", "is_robot_indexable": true, "report_reasons": null, "author": "DrSimonMetin", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o0duu/external_hdd_external_hdd_via_macbook/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o0duu/external_hdd_external_hdd_via_macbook/", "subreddit_subscribers": 702996, "created_utc": 1695253432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! I need help figuring out the best (but not overly priced) equipment to digitalize my Panasonic  PV-L354 VHS-C Camcorder. I have a power cord and getting the correct A/V out cord for it. I did buy a converter but after hours of various tutorials and tweaking and several programs, I learned it is not great and doesn't work most of the time. So I need a different one so I can take my lots of old tapes and digitalize them.\n\nYes I know I could pay someone X amount per tape to digitalize it but tbh that would get super pricey really quickly since I have so many. I'd rather spend the $100ish to get the correct equipment to do it myself. I have several different types of recording software and pretty good knowledge of how to do this sort of thing. All I'm lacking is the correct converter. I'll place the links to the DVR thing I used before that ended up a POS and my exact Panasonic (since apparently it is on Amazon lol)\n\nFrom what I've been gathering the Startech converter seems to be the best choice and works with OBS? But any help would be greatly appreciated.\n\nThe converter I bought: [https://www.amazon.com/dp/B087TDN2FL?psc=1&amp;ref=ppx\\_yo2ov\\_dt\\_b\\_product\\_details](https://www.amazon.com/dp/B087TDN2FL?psc=1&amp;ref=ppx_yo2ov_dt_b_product_details)\n\nMy Panasonic: [https://www.amazon.com/dp/B0001DBEHE?tag=namespacebran506-20&amp;asc\\_source=01H2RCFWNNZMQFGXGXS3RMXVE5&amp;psc=0&amp;ref\\_=list\\_c\\_wl\\_lv\\_ov\\_lig\\_dp\\_it](https://www.amazon.com/dp/B0001DBEHE?tag=namespacebran506-20&amp;asc_source=01H2RCFWNNZMQFGXGXS3RMXVE5&amp;psc=0&amp;ref_=list_c_wl_lv_ov_lig_dp_it)", "author_fullname": "t2_7u6flpms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help to get equipment for VHS-C (Panasonic) to digital (windows)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16nt5ho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695235752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I need help figuring out the best (but not overly priced) equipment to digitalize my Panasonic  PV-L354 VHS-C Camcorder. I have a power cord and getting the correct A/V out cord for it. I did buy a converter but after hours of various tutorials and tweaking and several programs, I learned it is not great and doesn&amp;#39;t work most of the time. So I need a different one so I can take my lots of old tapes and digitalize them.&lt;/p&gt;\n\n&lt;p&gt;Yes I know I could pay someone X amount per tape to digitalize it but tbh that would get super pricey really quickly since I have so many. I&amp;#39;d rather spend the $100ish to get the correct equipment to do it myself. I have several different types of recording software and pretty good knowledge of how to do this sort of thing. All I&amp;#39;m lacking is the correct converter. I&amp;#39;ll place the links to the DVR thing I used before that ended up a POS and my exact Panasonic (since apparently it is on Amazon lol)&lt;/p&gt;\n\n&lt;p&gt;From what I&amp;#39;ve been gathering the Startech converter seems to be the best choice and works with OBS? But any help would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;The converter I bought: &lt;a href=\"https://www.amazon.com/dp/B087TDN2FL?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details\"&gt;https://www.amazon.com/dp/B087TDN2FL?psc=1&amp;amp;ref=ppx_yo2ov_dt_b_product_details&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My Panasonic: &lt;a href=\"https://www.amazon.com/dp/B0001DBEHE?tag=namespacebran506-20&amp;amp;asc_source=01H2RCFWNNZMQFGXGXS3RMXVE5&amp;amp;psc=0&amp;amp;ref_=list_c_wl_lv_ov_lig_dp_it\"&gt;https://www.amazon.com/dp/B0001DBEHE?tag=namespacebran506-20&amp;amp;asc_source=01H2RCFWNNZMQFGXGXS3RMXVE5&amp;amp;psc=0&amp;amp;ref_=list_c_wl_lv_ov_lig_dp_it&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16nt5ho", "is_robot_indexable": true, "report_reasons": null, "author": "NilaoriPlays", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16nt5ho/help_to_get_equipment_for_vhsc_panasonic_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16nt5ho/help_to_get_equipment_for_vhsc_panasonic_to/", "subreddit_subscribers": 702996, "created_utc": 1695235752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to store complete copies of BluRay disks as ISO or BDMV folders (for playback with menu support on an Oppo player), but then also rip these disks into a compatible format for a PLEX library (mp4 or mkv, depending on which method would result in the most efficient dedup). \n\nIs there any viable deduplication strategy for such a setup, so that it would only require the storage space of approximately that single ISO/BDMV, and no additional storage space for the mp4/mkv files? \n\nWould block level dedup like offered by ZFS be viable for this? Are there better options?", "author_fullname": "t2_1nu5vo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deduplication options for movie library.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ofxls", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695302848.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to store complete copies of BluRay disks as ISO or BDMV folders (for playback with menu support on an Oppo player), but then also rip these disks into a compatible format for a PLEX library (mp4 or mkv, depending on which method would result in the most efficient dedup). &lt;/p&gt;\n\n&lt;p&gt;Is there any viable deduplication strategy for such a setup, so that it would only require the storage space of approximately that single ISO/BDMV, and no additional storage space for the mp4/mkv files? &lt;/p&gt;\n\n&lt;p&gt;Would block level dedup like offered by ZFS be viable for this? Are there better options?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ofxls", "is_robot_indexable": true, "report_reasons": null, "author": "elecsys", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ofxls/deduplication_options_for_movie_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16ofxls/deduplication_options_for_movie_library/", "subreddit_subscribers": 702996, "created_utc": 1695302848.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know reddit hard limits posts to 40 pages (you can view last 1000 posted), but is there an already made script that does this + grabs comments+posts etc. \n\n&amp;nbsp;\n\nI could write something with wget and python myself, but there's probably an already existing solution. I looked on github but couldn't find anything specifically written that does this.", "author_fullname": "t2_fiawk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a subreddit scraper that can fetch everything upto limit? (1000 posts)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16od39y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695294797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know reddit hard limits posts to 40 pages (you can view last 1000 posted), but is there an already made script that does this + grabs comments+posts etc. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I could write something with wget and python myself, but there&amp;#39;s probably an already existing solution. I looked on github but couldn&amp;#39;t find anything specifically written that does this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16od39y", "is_robot_indexable": true, "report_reasons": null, "author": "Xillenn", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16od39y/is_there_a_subreddit_scraper_that_can_fetch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16od39y/is_there_a_subreddit_scraper_that_can_fetch/", "subreddit_subscribers": 702996, "created_utc": 1695294797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to recover some deleted Twitch videos(A particular streamer) and I was wondering if there were any hoarders!\n\nhttps://m.twitch.tv/hjihae29/clips", "author_fullname": "t2_qeqw2bmc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hi, is there anyone who hoards Twitch videos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o97sj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695283912.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695280413.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to recover some deleted Twitch videos(A particular streamer) and I was wondering if there were any hoarders!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://m.twitch.tv/hjihae29/clips\"&gt;https://m.twitch.tv/hjihae29/clips&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2i4C6YiwLaNyJn54AWW8skKndQihqC01Oogdo7SlnNM.jpg?auto=webp&amp;s=3175dd663c0d13856c3f9aa8d43b9345b100cee3", "width": 262, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/2i4C6YiwLaNyJn54AWW8skKndQihqC01Oogdo7SlnNM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=45c8dbb731ad7a3a12735f854f64e13df2fdc3cc", "width": 108, "height": 82}, {"url": "https://external-preview.redd.it/2i4C6YiwLaNyJn54AWW8skKndQihqC01Oogdo7SlnNM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5dd50b2b25dfbe8474f443aa3e60abdbc34df29c", "width": 216, "height": 164}], "variants": {}, "id": "pBgDB-nWlH1d9nm0GMhb7-1kZNBZKPjWWWJL-GlPp0E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o97sj", "is_robot_indexable": true, "report_reasons": null, "author": "renata_m_00", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o97sj/hi_is_there_anyone_who_hoards_twitch_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o97sj/hi_is_there_anyone_who_hoards_twitch_videos/", "subreddit_subscribers": 702996, "created_utc": 1695280413.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It's a 4 year old drive, has 1400 uncorrectable sectors and 58,000 pending remappings. \n\nWould a chkdsk even do anything at this point? I'm guessing everyone's recommendation is to replace the drive ASAP.", "author_fullname": "t2_6npej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "58,000 pending sector count(for remapping) Is it worth even trying to remediate or should I replace ASAP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ns24h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695233109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a 4 year old drive, has 1400 uncorrectable sectors and 58,000 pending remappings. &lt;/p&gt;\n\n&lt;p&gt;Would a chkdsk even do anything at this point? I&amp;#39;m guessing everyone&amp;#39;s recommendation is to replace the drive ASAP.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ns24h", "is_robot_indexable": true, "report_reasons": null, "author": "chubby_cheese", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ns24h/58000_pending_sector_countfor_remapping_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16ns24h/58000_pending_sector_countfor_remapping_is_it/", "subreddit_subscribers": 702996, "created_utc": 1695233109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I've been planning to buy a Crucial MX500 for data storage but when I check the 1-star reviews on amazon a lot of reviews say that they failed as a system drive. So, I would like to know if it's good for data storage. Thanks.", "author_fullname": "t2_s017aqbz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Crucial MX500 for Data Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16odnnq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695296587.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve been planning to buy a Crucial MX500 for data storage but when I check the 1-star reviews on amazon a lot of reviews say that they failed as a system drive. So, I would like to know if it&amp;#39;s good for data storage. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "0B", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16odnnq", "is_robot_indexable": true, "report_reasons": null, "author": "-KasaneTeto-", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16odnnq/crucial_mx500_for_data_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16odnnq/crucial_mx500_for_data_storage/", "subreddit_subscribers": 702996, "created_utc": 1695296587.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there\n\nI have a few questions regarding how I should set up my home NAS. The goal is to use it as storage for a PleX/media library, computer backups, a TimeMachine backup, and whatever else might come along. I'm planning on using TrueNAS to manage it all.\n\nI have 5x 14TB Seagate EXOS drives, but I'm not sure how many I should use (3, 4, or 5), or if I should be using RAID 5 or RAID 6. The main goal is 'future-proofing' (as much as we hate that term) so that I'm not having to rebuild/expand 5 years from now.\n\nMy questions are:\n\n\\-If I use 3 disks, and use them in RAID 5 (or whatever the TrueNAS terminology is), can I simply pop in another identical drive in the future to expand storage? Or are there particular issues with this/do I have to format the existing data to do so?\n\n\\-What RAID config. and number of disks would you recommend? I'm interested in using the least amount of disks possible to get \\~24TB, with a reasonable amount of redundancy. These drives are loud as hell so I really don't want to use all 5 unless I have to.\n\n\\-Wtf is ZFS?\n\n\\-Is there anything else I missed or additional questions I should be asking myself?\n\nThanks in advance for the guidance, I really appreciate it!", "author_fullname": "t2_8d4xgtcg0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAID Config Suggestions? 5x 14TB HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16o27kr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695259214.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695258386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there&lt;/p&gt;\n\n&lt;p&gt;I have a few questions regarding how I should set up my home NAS. The goal is to use it as storage for a PleX/media library, computer backups, a TimeMachine backup, and whatever else might come along. I&amp;#39;m planning on using TrueNAS to manage it all.&lt;/p&gt;\n\n&lt;p&gt;I have 5x 14TB Seagate EXOS drives, but I&amp;#39;m not sure how many I should use (3, 4, or 5), or if I should be using RAID 5 or RAID 6. The main goal is &amp;#39;future-proofing&amp;#39; (as much as we hate that term) so that I&amp;#39;m not having to rebuild/expand 5 years from now.&lt;/p&gt;\n\n&lt;p&gt;My questions are:&lt;/p&gt;\n\n&lt;p&gt;-If I use 3 disks, and use them in RAID 5 (or whatever the TrueNAS terminology is), can I simply pop in another identical drive in the future to expand storage? Or are there particular issues with this/do I have to format the existing data to do so?&lt;/p&gt;\n\n&lt;p&gt;-What RAID config. and number of disks would you recommend? I&amp;#39;m interested in using the least amount of disks possible to get ~24TB, with a reasonable amount of redundancy. These drives are loud as hell so I really don&amp;#39;t want to use all 5 unless I have to.&lt;/p&gt;\n\n&lt;p&gt;-Wtf is ZFS?&lt;/p&gt;\n\n&lt;p&gt;-Is there anything else I missed or additional questions I should be asking myself?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for the guidance, I really appreciate it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16o27kr", "is_robot_indexable": true, "report_reasons": null, "author": "_buttsnorkel", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16o27kr/raid_config_suggestions_5x_14tb_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16o27kr/raid_config_suggestions_5x_14tb_hdds/", "subreddit_subscribers": 702996, "created_utc": 1695258386.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}