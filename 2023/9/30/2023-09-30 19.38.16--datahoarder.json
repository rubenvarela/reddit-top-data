{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/tdnwqkc64brb1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=52582ca186fe3c897a5c4ce1b3ddfe065feb2620\n\n \n\n# [An exabyte of disk storage at CERN](https://home.cern/news/news/computing/exabyte-disk-storage-cern)\n\nNothing to add. Just salivating.", "author_fullname": "t2_c7efjvl7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "An exabyte of disk storage at CERN", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tdnwqkc64brb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 72, "x": 108, "u": "https://preview.redd.it/tdnwqkc64brb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=95e955aa6b15d5bb96f13acb3c05670b5ca6f330"}, {"y": 144, "x": 216, "u": "https://preview.redd.it/tdnwqkc64brb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4b35aa98107d2377c542f82e8d8803208b3c9a39"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/tdnwqkc64brb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=97d70ac7fe0b638bd6d7a5f4d023a029206937ff"}, {"y": 427, "x": 640, "u": "https://preview.redd.it/tdnwqkc64brb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2047018b39ed122ab531aa84dd0f9ecbcddd9044"}, {"y": 640, "x": 960, "u": "https://preview.redd.it/tdnwqkc64brb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3354f3dfa015e7d196cde17986f8d77fe499ea0e"}, {"y": 720, "x": 1080, "u": "https://preview.redd.it/tdnwqkc64brb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=46875fdb8d38378b9698e9240710895e36a72a3d"}], "s": {"y": 961, "x": 1440, "u": "https://preview.redd.it/tdnwqkc64brb1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=52582ca186fe3c897a5c4ce1b3ddfe065feb2620"}, "id": "tdnwqkc64brb1"}}, "name": "t3_16vvlgc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 136, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 136, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6a42gV9zxnq3CmZFvWPqKmKG26_oK25qGun-ZOWsXdA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696042340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tdnwqkc64brb1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=52582ca186fe3c897a5c4ce1b3ddfe065feb2620\"&gt;https://preview.redd.it/tdnwqkc64brb1.png?width=1440&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=52582ca186fe3c897a5c4ce1b3ddfe065feb2620&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;&lt;a href=\"https://home.cern/news/news/computing/exabyte-disk-storage-cern\"&gt;An exabyte of disk storage at CERN&lt;/a&gt;&lt;/h1&gt;\n\n&lt;p&gt;Nothing to add. Just salivating.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vvlgc", "is_robot_indexable": true, "report_reasons": null, "author": "costafilh0", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vvlgc/an_exabyte_of_disk_storage_at_cern/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vvlgc/an_exabyte_of_disk_storage_at_cern/", "subreddit_subscribers": 704217, "created_utc": 1696042340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Not sure if anyone shucks mobile drives but found these on clearance at my Walmart might grab on and see if I can get it to work in my laptop for local media storage while traveling. Thought it might help some of y'all as well.", "author_fullname": "t2_6wl6hd6n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheap laptop drives 4tb $51 5tb $58", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_16vspo0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/8zaMLYtnEfeurfMfnnSC5etXqnCsLzRHu1THHqQQKRQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696034378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if anyone shucks mobile drives but found these on clearance at my Walmart might grab on and see if I can get it to work in my laptop for local media storage while traveling. Thought it might help some of y&amp;#39;all as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/vzad8ozygarb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/vzad8ozygarb1.jpg?auto=webp&amp;s=3fcf11bd9e074bbe83c595a7c2e9347a951a3709", "width": 3072, "height": 4080}, "resolutions": [{"url": "https://preview.redd.it/vzad8ozygarb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d7328fd67f1a9accd8ccecb59df2e1b1eb38b8ed", "width": 108, "height": 143}, {"url": "https://preview.redd.it/vzad8ozygarb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=17726313fb24c84731a95954ab48d2abce3173d3", "width": 216, "height": 286}, {"url": "https://preview.redd.it/vzad8ozygarb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4c038b75e2f0226d1ee35c2b41f27a193b655dc1", "width": 320, "height": 425}, {"url": "https://preview.redd.it/vzad8ozygarb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8325f0ab3fd54e82839873bc75d3cdae036aecc1", "width": 640, "height": 850}, {"url": "https://preview.redd.it/vzad8ozygarb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8c1b2260b362fad87a7fdd543bffc5f5da1720fa", "width": 960, "height": 1275}, {"url": "https://preview.redd.it/vzad8ozygarb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=523036e63b2154fc569cc00397c5ae62b41ff997", "width": 1080, "height": 1434}], "variants": {}, "id": "SxZVYgGwFgqOHxeSErCucDLFciMWiI3TkhdU5Ig6WOU"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vspo0", "is_robot_indexable": true, "report_reasons": null, "author": "Strosts", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vspo0/cheap_laptop_drives_4tb_51_5tb_58/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/vzad8ozygarb1.jpg", "subreddit_subscribers": 704217, "created_utc": 1696034378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI bought 2 \"New\" Seagate 8TB Ironwolf drives from Amazon, sold and shipped by amazon themselves. The item condition was listed as new, and nowhere did it indicate otherwise. Upon receiving the drives, both of them have this sticker on them, see below. \n\nI am confused as to whether they are new or refurbished, and whether I should be a bit annoyed rn. \n\nThanks for the help.\n\nhttps://preview.redd.it/l2ah38frkdrb1.png?width=622&amp;format=png&amp;auto=webp&amp;s=faa08cfdc0e7ce68c837e277a0ec6dd4a9f5e76d", "author_fullname": "t2_2xiam8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are these Seagate Ironwolf drives refurbs or new?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "media_metadata": {"l2ah38frkdrb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 74, "x": 108, "u": "https://preview.redd.it/l2ah38frkdrb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f1ec06ab1178c8e1887713036beeff667951abc2"}, {"y": 148, "x": 216, "u": "https://preview.redd.it/l2ah38frkdrb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d72d0ce9a7623fb7ebf89b63a8a481172fddec40"}, {"y": 219, "x": 320, "u": "https://preview.redd.it/l2ah38frkdrb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=628fc71660ccd7bc76fc44c3ff67ec9e4d5e2f38"}], "s": {"y": 427, "x": 622, "u": "https://preview.redd.it/l2ah38frkdrb1.png?width=622&amp;format=png&amp;auto=webp&amp;s=faa08cfdc0e7ce68c837e277a0ec6dd4a9f5e76d"}, "id": "l2ah38frkdrb1"}}, "name": "t3_16w431k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/glcVTHJuD-PTTq0jEvKmhaP5EVwvynmWgOtYwlqZtFQ.jpg", "edited": 1696091157.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696072097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I bought 2 &amp;quot;New&amp;quot; Seagate 8TB Ironwolf drives from Amazon, sold and shipped by amazon themselves. The item condition was listed as new, and nowhere did it indicate otherwise. Upon receiving the drives, both of them have this sticker on them, see below. &lt;/p&gt;\n\n&lt;p&gt;I am confused as to whether they are new or refurbished, and whether I should be a bit annoyed rn. &lt;/p&gt;\n\n&lt;p&gt;Thanks for the help.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/l2ah38frkdrb1.png?width=622&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=faa08cfdc0e7ce68c837e277a0ec6dd4a9f5e76d\"&gt;https://preview.redd.it/l2ah38frkdrb1.png?width=622&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=faa08cfdc0e7ce68c837e277a0ec6dd4a9f5e76d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16w431k", "is_robot_indexable": true, "report_reasons": null, "author": "MyLifesTragic", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16w431k/are_these_seagate_ironwolf_drives_refurbs_or_new/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16w431k/are_these_seagate_ironwolf_drives_refurbs_or_new/", "subreddit_subscribers": 704217, "created_utc": 1696072097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, this is my first post here and I'm not sure if this is the right place for it, but I recently found a very neat site that has french public domain books that I haven't been able to find, even on Project Gutenberg, and they have a web page where you can download their entire public domain collection via torrents, one torrent for each file type!\n\nI found them in my search for Arnould Galopin's 1906 \"Le Docteur Omega\" in the original french so I can make an english translation that is public domain :) \n\n[https://www.ebooksgratuits.com/torrent.php](https://www.ebooksgratuits.com/torrent.php)\n\nit's only around \\~7GB to get all 1.8k public domain books in all the formats :D\n\n(the original website is in french, if you have Firefox or Chrome browser you can translate the entire webpage) ", "author_fullname": "t2_vxyg60uk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1,863 Public domain books in french available!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vwklf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696045286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, this is my first post here and I&amp;#39;m not sure if this is the right place for it, but I recently found a very neat site that has french public domain books that I haven&amp;#39;t been able to find, even on Project Gutenberg, and they have a web page where you can download their entire public domain collection via torrents, one torrent for each file type!&lt;/p&gt;\n\n&lt;p&gt;I found them in my search for Arnould Galopin&amp;#39;s 1906 &amp;quot;Le Docteur Omega&amp;quot; in the original french so I can make an english translation that is public domain :) &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.ebooksgratuits.com/torrent.php\"&gt;https://www.ebooksgratuits.com/torrent.php&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;it&amp;#39;s only around ~7GB to get all 1.8k public domain books in all the formats :D&lt;/p&gt;\n\n&lt;p&gt;(the original website is in french, if you have Firefox or Chrome browser you can translate the entire webpage) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vwklf", "is_robot_indexable": true, "report_reasons": null, "author": "WalksTheAges", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vwklf/1863_public_domain_books_in_french_available/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vwklf/1863_public_domain_books_in_french_available/", "subreddit_subscribers": 704217, "created_utc": 1696045286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This post is a follow-up to the one made from Sept. 19 which for some reason was [deleted](https://www.reddit.com/r/DataHoarder/comments/16n6sbg/redditor_provides_a_personal_archive_of_every/). That post specifically highlighted [this one](https://old.reddit.com/r/Radiolab/comments/j5r558/downloading_the_entire_radiolab_archive/g7xgypm/) from 2 years ago in which a contributor in r/Radiolab put together an archive of what seems to be all RL episodes with associated metadata. The data is ordered twice (so, duplicated in the directory) by \"OrderedByReleaseYear\" and \"OrderedByTheWiki\" and also includes a RadiolabEpisodeList.csv for cross-referencing against the Wikipedia list of RL episodes.\n\nThe contributor, u/Loucash, made the data available via a public Google Drive folder.\n\nI've taken that data, unaltered, and archived it into this item on [Archive.org](https://Archive.org) for preservation and indefinite accessibility with two options:\n\n* Each of the 3 directory folders and their subfolders and files have been directly uploaded for in-browser access. IA created spectrogram derivative files for each of the .mp3 files.\n* I also decided to pack the entire directory into a non-compressed .zip should the end-user of the future want to pull everything down at once. Note, the .csv isn't included in the .zip.\n* All credit goes to u/Loucash for compiling the data in what I'm sure was a tedious process.\n\n[https://archive.org/details/radiolab-wnyc-radio-series](https://archive.org/details/radiolab-wnyc-radio-series)\n\nDisclaimer: Internet Archive routinely archives all podcasts from all the major platforms. So, the Radiolab episodes already exist on [Archive.org](https://Archive.org). However, they are marked as restricted with a lock icon next to the episode file. IA does this as a means to not upset the content distributors. This item has been created independent of IA staff and data offered is as-is for academic and preservation purposes only.", "author_fullname": "t2_37m680iv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WNYC's Radiolab Series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16w9uyc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696087934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This post is a follow-up to the one made from Sept. 19 which for some reason was &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/16n6sbg/redditor_provides_a_personal_archive_of_every/\"&gt;deleted&lt;/a&gt;. That post specifically highlighted &lt;a href=\"https://old.reddit.com/r/Radiolab/comments/j5r558/downloading_the_entire_radiolab_archive/g7xgypm/\"&gt;this one&lt;/a&gt; from 2 years ago in which a contributor in &lt;a href=\"/r/Radiolab\"&gt;r/Radiolab&lt;/a&gt; put together an archive of what seems to be all RL episodes with associated metadata. The data is ordered twice (so, duplicated in the directory) by &amp;quot;OrderedByReleaseYear&amp;quot; and &amp;quot;OrderedByTheWiki&amp;quot; and also includes a RadiolabEpisodeList.csv for cross-referencing against the Wikipedia list of RL episodes.&lt;/p&gt;\n\n&lt;p&gt;The contributor, &lt;a href=\"/u/Loucash\"&gt;u/Loucash&lt;/a&gt;, made the data available via a public Google Drive folder.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve taken that data, unaltered, and archived it into this item on &lt;a href=\"https://Archive.org\"&gt;Archive.org&lt;/a&gt; for preservation and indefinite accessibility with two options:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Each of the 3 directory folders and their subfolders and files have been directly uploaded for in-browser access. IA created spectrogram derivative files for each of the .mp3 files.&lt;/li&gt;\n&lt;li&gt;I also decided to pack the entire directory into a non-compressed .zip should the end-user of the future want to pull everything down at once. Note, the .csv isn&amp;#39;t included in the .zip.&lt;/li&gt;\n&lt;li&gt;All credit goes to &lt;a href=\"/u/Loucash\"&gt;u/Loucash&lt;/a&gt; for compiling the data in what I&amp;#39;m sure was a tedious process.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://archive.org/details/radiolab-wnyc-radio-series\"&gt;https://archive.org/details/radiolab-wnyc-radio-series&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: Internet Archive routinely archives all podcasts from all the major platforms. So, the Radiolab episodes already exist on &lt;a href=\"https://Archive.org\"&gt;Archive.org&lt;/a&gt;. However, they are marked as restricted with a lock icon next to the episode file. IA does this as a means to not upset the content distributors. This item has been created independent of IA staff and data offered is as-is for academic and preservation purposes only.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16w9uyc", "is_robot_indexable": true, "report_reasons": null, "author": "Archivist_Goals", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16w9uyc/wnycs_radiolab_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16w9uyc/wnycs_radiolab_series/", "subreddit_subscribers": 704217, "created_utc": 1696087934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm archiving some youtube channels that have active uploads.  Some of the playlists append to the top, some to the bottom.  Some post more than one per day.  I'm looking for a single output format that will handle all of them and let you import it into plex.  \n\nThis means that for a particular folder there can only be one season/episode type number or it will be added as multiple parts.\n\nWhat I've done to date is:\n\n\\-o \"%(playlist\\_uploader)s - \\[%(playlist\\_uploader\\_id)s\\]/%(playlist)s - \\[%(playlist\\_id)s\\]/S01E%(upload\\_date)s - %(title)s - \\[%(id)s\\].%(ext)s\" **Works except for multiple posts in one date**\n\n\\-o \"%(uploader)s - \\[%(uploader\\_id)s\\]/%(uploader)s Videos \\[%(channel\\_id)s\\]/S01E%(upload\\_date)s - %(title)s - \\[%(height)sp\\] \\[%(id)s\\].%(ext)s\" **Same as above but for /videos and not playlists**\n\n\\-o \"%(uploader)s/%(uploader)s - %(playlist\\_title)s - \\[%(playlist\\_id)s\\]/%(playlist\\_index)s - %(title)s \\[%(id)s\\].%(ext)s\" **Playlist index isn't stable over months of running and 01 reused multiple times**\n\nLooking at various github repos and posts here it seems that post just rely on either upload\\_date and hope for no collisions or playlist\\_index and assume it'll only be run once.\n\n&amp;#x200B;\n\nI was thinking something like %(upload\\_date) but in the format of YYYYMMDDHHMM, can I get that from release\\_timestamp?", "author_fullname": "t2_3v4q7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a stable long term yt-dlp output format for active playlists", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vqri9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696029530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m archiving some youtube channels that have active uploads.  Some of the playlists append to the top, some to the bottom.  Some post more than one per day.  I&amp;#39;m looking for a single output format that will handle all of them and let you import it into plex.  &lt;/p&gt;\n\n&lt;p&gt;This means that for a particular folder there can only be one season/episode type number or it will be added as multiple parts.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;ve done to date is:&lt;/p&gt;\n\n&lt;p&gt;-o &amp;quot;%(playlist_uploader)s - [%(playlist_uploader_id)s]/%(playlist)s - [%(playlist_id)s]/S01E%(upload_date)s - %(title)s - [%(id)s].%(ext)s&amp;quot; &lt;strong&gt;Works except for multiple posts in one date&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;-o &amp;quot;%(uploader)s - [%(uploader_id)s]/%(uploader)s Videos [%(channel_id)s]/S01E%(upload_date)s - %(title)s - [%(height)sp] [%(id)s].%(ext)s&amp;quot; &lt;strong&gt;Same as above but for /videos and not playlists&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;-o &amp;quot;%(uploader)s/%(uploader)s - %(playlist_title)s - [%(playlist_id)s]/%(playlist_index)s - %(title)s [%(id)s].%(ext)s&amp;quot; &lt;strong&gt;Playlist index isn&amp;#39;t stable over months of running and 01 reused multiple times&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Looking at various github repos and posts here it seems that post just rely on either upload_date and hope for no collisions or playlist_index and assume it&amp;#39;ll only be run once.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was thinking something like %(upload_date) but in the format of YYYYMMDDHHMM, can I get that from release_timestamp?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "170TB /Z2", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vqri9", "is_robot_indexable": true, "report_reasons": null, "author": "Hughlander", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16vqri9/looking_for_a_stable_long_term_ytdlp_output/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vqri9/looking_for_a_stable_long_term_ytdlp_output/", "subreddit_subscribers": 704217, "created_utc": 1696029530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to craft my own backup solution to save some money, and was hoping someone here could tell me if there's something wrong with my scheme.\n\nBackblaze is increasing my personal backup prices by 45% next billing cycle, which will put me at over $300 a year for 3 machines. I store less than 2TB of data this way, so this is extremely excessive in my opinion. In addition, I have roughly 4TB of data I backup in B2 buckets from my 20TB, home-built NAS running FreeNAS.\n\nThe scheme: I want to eliminate the personal backups entirely to eliminate this payment, and instead use different software to back my machines up to my NAS which has plenty of storage. I already have my buckets configured in B2, all I need to do is just make a folder for machine backups in my NAS shares. They will be automatically backed up to the cloud via a nightly cron job. \n\nThis, in theory, should put me at about 2TB + 4TB = 6TB of storage in B2, which is \\~$30/mo. With the price increase, I would be paying $30/mo just for the personal backups and another $20/mo for my current B2 buckets.\n\nAnyone see a problem with this? Or even a way to improve it? ", "author_fullname": "t2_hdxaq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backblaze boogaloo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16we873", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696098860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to craft my own backup solution to save some money, and was hoping someone here could tell me if there&amp;#39;s something wrong with my scheme.&lt;/p&gt;\n\n&lt;p&gt;Backblaze is increasing my personal backup prices by 45% next billing cycle, which will put me at over $300 a year for 3 machines. I store less than 2TB of data this way, so this is extremely excessive in my opinion. In addition, I have roughly 4TB of data I backup in B2 buckets from my 20TB, home-built NAS running FreeNAS.&lt;/p&gt;\n\n&lt;p&gt;The scheme: I want to eliminate the personal backups entirely to eliminate this payment, and instead use different software to back my machines up to my NAS which has plenty of storage. I already have my buckets configured in B2, all I need to do is just make a folder for machine backups in my NAS shares. They will be automatically backed up to the cloud via a nightly cron job. &lt;/p&gt;\n\n&lt;p&gt;This, in theory, should put me at about 2TB + 4TB = 6TB of storage in B2, which is ~$30/mo. With the price increase, I would be paying $30/mo just for the personal backups and another $20/mo for my current B2 buckets.&lt;/p&gt;\n\n&lt;p&gt;Anyone see a problem with this? Or even a way to improve it? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16we873", "is_robot_indexable": true, "report_reasons": null, "author": "Xerxes004", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16we873/backblaze_boogaloo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16we873/backblaze_boogaloo/", "subreddit_subscribers": 704217, "created_utc": 1696098860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We Have Prepared the Dataset of 250K Books and 1.5M Scholarly Papers with Extracted Text Layers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16w2ib3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_7sj9ysbpm", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "science_nexus", "selftext": "Presenting the largest text corpus that surpasses every existing dataset used to train AI, including the likes of [books3](https://authorsguild.org/news/you-just-found-out-your-book-was-used-to-train-ai-now-what/).\n\nSpread the word and share with your developer friends. If you want to see General AI come to fruition sooner rather than later, this is your chance.\n\n\u2699\ufe0f **Parameters**\n\nSize: **170GB**\n\nBooks: **250K**\n\nPapers: 1.5M\n\nRecognition quality of extracted text layers: **GROBID + EPUB Extraction**\n\n\ud83e\udd14 **How To Use? Same as** [**before**](https://t.me/nexus_search/150)**:**\n\n\\- [Install IPFS](https://docs.ipfs.tech/install/ipfs-desktop/) and launch it\n\n\\- `pip3 install stc-geck &amp;&amp; geck - documents`\n\n\ud83d\udc4a **Support our efforts by seeding**\n\n`ipfs pin add /ipns/standard-template-construct.org --progress`\n\n\ud83c\udf1a\ufe0f\ufe0f\ufe0f\ufe0f\ufe0f\ufe0f **Our next goal?**\n\n1 million books!", "author_fullname": "t2_7sj9ysbpm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We Have Prepared the Dataset of 250K Books and 1.5M Scholarly Papers with Extracted Text Layers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/science_nexus", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vj7w2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696014022.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696011872.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.science_nexus", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Presenting the largest text corpus that surpasses every existing dataset used to train AI, including the likes of &lt;a href=\"https://authorsguild.org/news/you-just-found-out-your-book-was-used-to-train-ai-now-what/\"&gt;books3&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Spread the word and share with your developer friends. If you want to see General AI come to fruition sooner rather than later, this is your chance.&lt;/p&gt;\n\n&lt;p&gt;\u2699\ufe0f &lt;strong&gt;Parameters&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Size: &lt;strong&gt;170GB&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Books: &lt;strong&gt;250K&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Papers: 1.5M&lt;/p&gt;\n\n&lt;p&gt;Recognition quality of extracted text layers: &lt;strong&gt;GROBID + EPUB Extraction&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83e\udd14 &lt;strong&gt;How To Use? Same as&lt;/strong&gt; &lt;a href=\"https://t.me/nexus_search/150\"&gt;&lt;strong&gt;before&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- &lt;a href=\"https://docs.ipfs.tech/install/ipfs-desktop/\"&gt;Install IPFS&lt;/a&gt; and launch it&lt;/p&gt;\n\n&lt;p&gt;- &lt;code&gt;pip3 install stc-geck &amp;amp;&amp;amp; geck - documents&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc4a &lt;strong&gt;Support our efforts by seeding&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ipfs pin add /ipns/standard-template-construct.org --progress&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udf1a\ufe0f\ufe0f\ufe0f\ufe0f\ufe0f\ufe0f &lt;strong&gt;Our next goal?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;1 million books!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?auto=webp&amp;s=278ed2a73aad5d3c62e648d9bf2216fafa8d1586", "width": 1500, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8efa10c160969e66b7e886aefe1d2d49f218ab82", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=754f662f9de5912ff2f3cc53d6b354128581206e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5743d533bdda5c33bdcd8a2c97d927efcd3f014c", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=95a428a676282b8a6d330ae39de43ae774557af1", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e29f9537e50d1fb10a5f33f407af69ad29cd4cc7", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cb16b07f3363a1d12a7c664d9d8a61360179f7ad", "width": 1080, "height": 720}], "variants": {}, "id": "xXXVw62pN5HMpiP8UrGeFmKJ78AnJl7YIyLqCDhzYcU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_9btioz", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16vj7w2", "is_robot_indexable": true, "report_reasons": null, "author": "ultra_nymous", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/science_nexus/comments/16vj7w2/we_have_prepared_the_dataset_of_250k_books_and/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/science_nexus/comments/16vj7w2/we_have_prepared_the_dataset_of_250k_books_and/", "subreddit_subscribers": 97, "created_utc": 1696011872.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1696066433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.science_nexus", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/science_nexus/comments/16vj7w2/we_have_prepared_the_dataset_of_250k_books_and/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?auto=webp&amp;s=278ed2a73aad5d3c62e648d9bf2216fafa8d1586", "width": 1500, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8efa10c160969e66b7e886aefe1d2d49f218ab82", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=754f662f9de5912ff2f3cc53d6b354128581206e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5743d533bdda5c33bdcd8a2c97d927efcd3f014c", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=95a428a676282b8a6d330ae39de43ae774557af1", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e29f9537e50d1fb10a5f33f407af69ad29cd4cc7", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/rD2mmAVeFY0_P5iRi1uYNVG64UAASRFYYEVxjAYGbMU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cb16b07f3363a1d12a7c664d9d8a61360179f7ad", "width": 1080, "height": 720}], "variants": {}, "id": "xXXVw62pN5HMpiP8UrGeFmKJ78AnJl7YIyLqCDhzYcU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16w2ib3", "is_robot_indexable": true, "report_reasons": null, "author": "ultra_nymous", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_16vj7w2", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16w2ib3/we_have_prepared_the_dataset_of_250k_books_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/science_nexus/comments/16vj7w2/we_have_prepared_the_dataset_of_250k_books_and/", "subreddit_subscribers": 704217, "created_utc": 1696066433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nStumbled upon this sub a week ago after building my own NAS from an old computer of mine. Long story short I\u2019ve already realized the 4tb Seagate Ironwolf drives I bought from Newegg aren\u2019t going to cut it very long so I\u2019d like to purchase some drives from serverpartdeals.com. Specifically 4 WD Ultrastar 14tb remanufactured drives. My problem is serverparts shows several different 14tb Ultrastar models. I\u2019m not sure what to choose here or what the differences are between them. \n\nMy server is going to be for home use. i5-6500k, 16gb ram, 500tb evo m.2 SSD as cache drive. Backup of photos and other data plus some sort of video server is about it for now. Using Unraid if that matters. \n\nI would appreciate any help \n\nAdditional question - when I had the server running with the 4 Seagate drives when it\u2019s idle it was pulling about 50 watts. I was impressed it was so low. Total KW usage over 36 hour period was about 1.5kw. In my area that equals about .11 cents a day to run it. I\u2019m shocked it wasn\u2019t more. Is this normal or should I expect lower/higher power consumption? The rig is being powered by a 700w Corsair PSU\n\nAll of this stuff is so fascinating.! I\u2019m learning a lot from all of you. Keep it up \ud83d\ude01", "author_fullname": "t2_7qkjeyui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help picking HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vulif", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696039501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Stumbled upon this sub a week ago after building my own NAS from an old computer of mine. Long story short I\u2019ve already realized the 4tb Seagate Ironwolf drives I bought from Newegg aren\u2019t going to cut it very long so I\u2019d like to purchase some drives from serverpartdeals.com. Specifically 4 WD Ultrastar 14tb remanufactured drives. My problem is serverparts shows several different 14tb Ultrastar models. I\u2019m not sure what to choose here or what the differences are between them. &lt;/p&gt;\n\n&lt;p&gt;My server is going to be for home use. i5-6500k, 16gb ram, 500tb evo m.2 SSD as cache drive. Backup of photos and other data plus some sort of video server is about it for now. Using Unraid if that matters. &lt;/p&gt;\n\n&lt;p&gt;I would appreciate any help &lt;/p&gt;\n\n&lt;p&gt;Additional question - when I had the server running with the 4 Seagate drives when it\u2019s idle it was pulling about 50 watts. I was impressed it was so low. Total KW usage over 36 hour period was about 1.5kw. In my area that equals about .11 cents a day to run it. I\u2019m shocked it wasn\u2019t more. Is this normal or should I expect lower/higher power consumption? The rig is being powered by a 700w Corsair PSU&lt;/p&gt;\n\n&lt;p&gt;All of this stuff is so fascinating.! I\u2019m learning a lot from all of you. Keep it up \ud83d\ude01&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vulif", "is_robot_indexable": true, "report_reasons": null, "author": "crappygeneral", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vulif/help_picking_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vulif/help_picking_hdd/", "subreddit_subscribers": 704217, "created_utc": 1696039501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm eyeing the 30tb version. Does it act as a normal sas drive? Thoughts on putting 4 of them in raid 6 with 2 hot spares? Want to use it for high performance, high capacity application with minimum number of drives.", "author_fullname": "t2_97kwl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have experience with the Samsung pm1643a series 30tb sas ssds?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vl0kl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696015959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m eyeing the 30tb version. Does it act as a normal sas drive? Thoughts on putting 4 of them in raid 6 with 2 hot spares? Want to use it for high performance, high capacity application with minimum number of drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vl0kl", "is_robot_indexable": true, "report_reasons": null, "author": "TitanXD", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vl0kl/anyone_have_experience_with_the_samsung_pm1643a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vl0kl/anyone_have_experience_with_the_samsung_pm1643a/", "subreddit_subscribers": 704217, "created_utc": 1696015959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've never really tried to hoard anything above 2TB. I have a pretty big steam and epic library (\\~8 TB) and I was wondering if there are any recommendations on a drive to play them from. I'd prefer an internal drive over an external or NAS type set-up. Does anyone have a recommendation on any specific drive that would work for gaming? I've tried searching my self and see drives like a WD Black, but I'm unsure of the performance. \n\nThanks in advance", "author_fullname": "t2_55h5n1jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good drive for storing games to play?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16wc2qp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696093537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve never really tried to hoard anything above 2TB. I have a pretty big steam and epic library (~8 TB) and I was wondering if there are any recommendations on a drive to play them from. I&amp;#39;d prefer an internal drive over an external or NAS type set-up. Does anyone have a recommendation on any specific drive that would work for gaming? I&amp;#39;ve tried searching my self and see drives like a WD Black, but I&amp;#39;m unsure of the performance. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16wc2qp", "is_robot_indexable": true, "report_reasons": null, "author": "Klibara", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16wc2qp/good_drive_for_storing_games_to_play/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16wc2qp/good_drive_for_storing_games_to_play/", "subreddit_subscribers": 704217, "created_utc": 1696093537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 2 Samsung 4Tb QVO on my desktop which I've been using mostly as a \"manual mirror\" while managing docs photos music and movies , rescuing data from DVDs and when I had it sorted I copy  them from disk1 to disk 2, so to say. \n\nI like this SSDs because of the factor form, the SATA 550 Mb/s speed and the fact that don't need heatsink , as I manage the computer with a 2Tb M.2 which is faster and better prepared for heavy load, games and stuff.  \nThe question here is: I'm transferring files from disk 1 to disk 2 (Almost 2 Tb in a single go) and speed is at a consistent 150 Mb/s, while when I'm transferring from an external disk on a USB-C 20Gbps I have in the computer I have reached 460-480 Mb/s without problems... How can the SATA inside be that slow? I know is not the Mobo or CPU or RAM (All quite decent) so the options I've thought are:  \n\n\n1- QVO design, even quality one from Samsung , suffer when files are about 1Gb+ each, and TLC would behave better than this QLC  \n2- QVO design, even quality one from Samsung , suffer when total transfer is more than a certain amount, let's say 1 Tb, or more than half of an SSD, or x times more their cache  \n3- It's a desktop failure by my side and two SATAs can't communicate between them at 500MB/s because they lose speed going trough buffers or whatnot, I like to play with hardware but I'm well aware I don't have a proper learning so sometimes I overshoot on configs or just plainly put dumb decisions thinking they are great  \n\n\nThanks in advance on any light you guys can direct me on this. Not thinking on taking any action rn but just would love to understand better what is going on and why  \n\n\n  \n", "author_fullname": "t2_fbf1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSDs and speed in desktop", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16w584w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696075917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 2 Samsung 4Tb QVO on my desktop which I&amp;#39;ve been using mostly as a &amp;quot;manual mirror&amp;quot; while managing docs photos music and movies , rescuing data from DVDs and when I had it sorted I copy  them from disk1 to disk 2, so to say. &lt;/p&gt;\n\n&lt;p&gt;I like this SSDs because of the factor form, the SATA 550 Mb/s speed and the fact that don&amp;#39;t need heatsink , as I manage the computer with a 2Tb M.2 which is faster and better prepared for heavy load, games and stuff.&lt;br/&gt;\nThe question here is: I&amp;#39;m transferring files from disk 1 to disk 2 (Almost 2 Tb in a single go) and speed is at a consistent 150 Mb/s, while when I&amp;#39;m transferring from an external disk on a USB-C 20Gbps I have in the computer I have reached 460-480 Mb/s without problems... How can the SATA inside be that slow? I know is not the Mobo or CPU or RAM (All quite decent) so the options I&amp;#39;ve thought are:  &lt;/p&gt;\n\n&lt;p&gt;1- QVO design, even quality one from Samsung , suffer when files are about 1Gb+ each, and TLC would behave better than this QLC&lt;br/&gt;\n2- QVO design, even quality one from Samsung , suffer when total transfer is more than a certain amount, let&amp;#39;s say 1 Tb, or more than half of an SSD, or x times more their cache&lt;br/&gt;\n3- It&amp;#39;s a desktop failure by my side and two SATAs can&amp;#39;t communicate between them at 500MB/s because they lose speed going trough buffers or whatnot, I like to play with hardware but I&amp;#39;m well aware I don&amp;#39;t have a proper learning so sometimes I overshoot on configs or just plainly put dumb decisions thinking they are great  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance on any light you guys can direct me on this. Not thinking on taking any action rn but just would love to understand better what is going on and why  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "10 TB + 10TB Offline", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16w584w", "is_robot_indexable": true, "report_reasons": null, "author": "Renotron", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16w584w/ssds_and_speed_in_desktop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16w584w/ssds_and_speed_in_desktop/", "subreddit_subscribers": 704217, "created_utc": 1696075917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to buy an optical drive for ripping some optical discs but also writing some backups on Blu-Rays.\n\nMy computer doesn't have 5.25 bay, so the drive will be used externally. I will figure out an adapter to connect any drive type, this is not the question.\n\nMy main question is whether I should choose a full hight (5.25, desktop style) or a slim (laptop style) drive? If we assume that both drives will support the same disk types, which style would you consider the best in terms of reliability and otherwise?", "author_fullname": "t2_h91na", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Full high or slim optical drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16w3k56", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696070216.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to buy an optical drive for ripping some optical discs but also writing some backups on Blu-Rays.&lt;/p&gt;\n\n&lt;p&gt;My computer doesn&amp;#39;t have 5.25 bay, so the drive will be used externally. I will figure out an adapter to connect any drive type, this is not the question.&lt;/p&gt;\n\n&lt;p&gt;My main question is whether I should choose a full hight (5.25, desktop style) or a slim (laptop style) drive? If we assume that both drives will support the same disk types, which style would you consider the best in terms of reliability and otherwise?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16w3k56", "is_robot_indexable": true, "report_reasons": null, "author": "rememedy", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16w3k56/full_high_or_slim_optical_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16w3k56/full_high_or_slim_optical_drive/", "subreddit_subscribers": 704217, "created_utc": 1696070216.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to run snapraid on my plex media library. Before I moved all the data onto the new disks I did a test run with snapraid with some other data I had. Once I knew I had it working I deleted the content files and partiy files, moved my media libraries to the new disks. Now I am organised with that data I want to run snapraid but it seems to be looking for the old files. How do I essentially wipe the old test I did with snapraid from it's memeory and star again as if from scratch?\n\nThis is my info from the snapraid sync\n\nC:\\\\snapraid&gt;snapraid sync\n\nSelf test...\n\nLoading state from C:/snapraid.content...\n\nWARNING! Content file 'C:/snapraid.content' not found, trying with another copy...\n\nLoading state from X:/snapraid.content...\n\nWARNING! Content file 'X:/snapraid.content' not found, trying with another copy...\n\nLoading state from Y:/snapraid.content...\n\nNo content file found. Assuming empty.\n\nScanning...\n\nScanned d2 in 2 seconds\n\nScanned d1 in 62 seconds\n\nUsing 607 MiB of memory for the file-system.\n\nInitializing...\n\nResizing...\n\nSaving state to C:/snapraid.content...\n\nSaving state to X:/snapraid.content...\n\nSaving state to Y:/snapraid.content...\n\nError opening the temporary content file 'C:/snapraid.content.tmp'. Permission denied \\[13/5\\].", "author_fullname": "t2_4chl1w282", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I do a fresh set up of snapraid?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vl8d7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696016471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to run snapraid on my plex media library. Before I moved all the data onto the new disks I did a test run with snapraid with some other data I had. Once I knew I had it working I deleted the content files and partiy files, moved my media libraries to the new disks. Now I am organised with that data I want to run snapraid but it seems to be looking for the old files. How do I essentially wipe the old test I did with snapraid from it&amp;#39;s memeory and star again as if from scratch?&lt;/p&gt;\n\n&lt;p&gt;This is my info from the snapraid sync&lt;/p&gt;\n\n&lt;p&gt;C:\\snapraid&amp;gt;snapraid sync&lt;/p&gt;\n\n&lt;p&gt;Self test...&lt;/p&gt;\n\n&lt;p&gt;Loading state from C:/snapraid.content...&lt;/p&gt;\n\n&lt;p&gt;WARNING! Content file &amp;#39;C:/snapraid.content&amp;#39; not found, trying with another copy...&lt;/p&gt;\n\n&lt;p&gt;Loading state from X:/snapraid.content...&lt;/p&gt;\n\n&lt;p&gt;WARNING! Content file &amp;#39;X:/snapraid.content&amp;#39; not found, trying with another copy...&lt;/p&gt;\n\n&lt;p&gt;Loading state from Y:/snapraid.content...&lt;/p&gt;\n\n&lt;p&gt;No content file found. Assuming empty.&lt;/p&gt;\n\n&lt;p&gt;Scanning...&lt;/p&gt;\n\n&lt;p&gt;Scanned d2 in 2 seconds&lt;/p&gt;\n\n&lt;p&gt;Scanned d1 in 62 seconds&lt;/p&gt;\n\n&lt;p&gt;Using 607 MiB of memory for the file-system.&lt;/p&gt;\n\n&lt;p&gt;Initializing...&lt;/p&gt;\n\n&lt;p&gt;Resizing...&lt;/p&gt;\n\n&lt;p&gt;Saving state to C:/snapraid.content...&lt;/p&gt;\n\n&lt;p&gt;Saving state to X:/snapraid.content...&lt;/p&gt;\n\n&lt;p&gt;Saving state to Y:/snapraid.content...&lt;/p&gt;\n\n&lt;p&gt;Error opening the temporary content file &amp;#39;C:/snapraid.content.tmp&amp;#39;. Permission denied [13/5].&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vl8d7", "is_robot_indexable": true, "report_reasons": null, "author": "Havel68", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vl8d7/how_do_i_do_a_fresh_set_up_of_snapraid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vl8d7/how_do_i_do_a_fresh_set_up_of_snapraid/", "subreddit_subscribers": 704217, "created_utc": 1696016471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to build a homemade system starting at about 5PB with future intents to expand to perhaps about 10-15PB, what are the best type of disk drives that I could buy and also what sort of system would it require?  \n\n\n&amp;#x200B;", "author_fullname": "t2_bueay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommend me configuration to build 5PB+ homemade storage solution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16wbg5g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696091940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to build a homemade system starting at about 5PB with future intents to expand to perhaps about 10-15PB, what are the best type of disk drives that I could buy and also what sort of system would it require?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16wbg5g", "is_robot_indexable": true, "report_reasons": null, "author": "Lhomiuvel", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16wbg5g/recommend_me_configuration_to_build_5pb_homemade/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16wbg5g/recommend_me_configuration_to_build_5pb_homemade/", "subreddit_subscribers": 704217, "created_utc": 1696091940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello fellow hoarders,\n\nI've got a few QNAP NAS devices at home, which I've been using to store all my data, including backups, along with my collection of family photos and videos. I've chosen this setup over iCloud and Apple's photo app because I've accumulated about 600GB of memories and I'm concerned about the potential costs and complications that come with cloud storage as my collection continues to grow.\n\n**Here's a breakdown of my current setup:**\n\nStorage and Organisation: I rely on Qfile to download my photos and videos onto the NAS, neatly organised into folders by the year. It's been working reasonably well in terms of keeping things in order.\n\n**Access at Home:** Sharing these memories on our TVs via Plex is easy and makes viewing at home convenient.\n\nHowever, I've encountered a few challenges:\n\nMobile Access: The hitch in my system is accessing these files while I'm away from home. Having to turn on a VPN, wait for it to connect to the QNAP, launch Qumagie, and then wait for all the thumbnails to load can be frustrating. Often, by the time I've gone through all these steps I have just lost interest.\n\n**Video Playback Issues**: The biggest roadblock I face is that I've never been able to get Qumagie to play videos on my phone (or even in my browser). Whenever I try, I receive the message, \"Failed to play. Play this file using transcoding or the native player.\" This is baffling because I'm trying to play videos on my iPhone, the same device I used to record them. I've also upgraded my CAYIN MediaSign Player license to the plus version, which should theoretically support the current iPhone format. However, transcoding remains a mystery to me. I understand the basics, such as matching the video format to the device's capabilities, but I'm stumped as to why this isn't working. It seems that to resolve this, I'd need to transcode all my videos, resulting in duplicate files and extra storage usage on my NAS.\n\nGiven these challenges, I've recently contemplated whether I should bite the bullet and invest in iCloud storage, primarily for the convenience of using Apple's photo applications while relegating the QNAP to backup duty only. This isn't my preferred option, however the Apple app handles photos and videos exceptionally well.\n\nThat said, I'm eager to hear if anyone in the community has discovered clever solutions to address these issues. I'd love to know what methods or apps you're using to streamline the process of managing and accessing photos and videos on your QNAP NAS, especially while on the go. Additionally, if anyone can provide guidance on transcoding, I'd greatly appreciate your help, I really don\u2019t get it.\n\nThanks for reading.", "author_fullname": "t2_fjwgdlwdp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on Efficient Photo and Video Management with QNAP NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vssv0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696034609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow hoarders,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a few QNAP NAS devices at home, which I&amp;#39;ve been using to store all my data, including backups, along with my collection of family photos and videos. I&amp;#39;ve chosen this setup over iCloud and Apple&amp;#39;s photo app because I&amp;#39;ve accumulated about 600GB of memories and I&amp;#39;m concerned about the potential costs and complications that come with cloud storage as my collection continues to grow.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here&amp;#39;s a breakdown of my current setup:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Storage and Organisation: I rely on Qfile to download my photos and videos onto the NAS, neatly organised into folders by the year. It&amp;#39;s been working reasonably well in terms of keeping things in order.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Access at Home:&lt;/strong&gt; Sharing these memories on our TVs via Plex is easy and makes viewing at home convenient.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;ve encountered a few challenges:&lt;/p&gt;\n\n&lt;p&gt;Mobile Access: The hitch in my system is accessing these files while I&amp;#39;m away from home. Having to turn on a VPN, wait for it to connect to the QNAP, launch Qumagie, and then wait for all the thumbnails to load can be frustrating. Often, by the time I&amp;#39;ve gone through all these steps I have just lost interest.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Video Playback Issues&lt;/strong&gt;: The biggest roadblock I face is that I&amp;#39;ve never been able to get Qumagie to play videos on my phone (or even in my browser). Whenever I try, I receive the message, &amp;quot;Failed to play. Play this file using transcoding or the native player.&amp;quot; This is baffling because I&amp;#39;m trying to play videos on my iPhone, the same device I used to record them. I&amp;#39;ve also upgraded my CAYIN MediaSign Player license to the plus version, which should theoretically support the current iPhone format. However, transcoding remains a mystery to me. I understand the basics, such as matching the video format to the device&amp;#39;s capabilities, but I&amp;#39;m stumped as to why this isn&amp;#39;t working. It seems that to resolve this, I&amp;#39;d need to transcode all my videos, resulting in duplicate files and extra storage usage on my NAS.&lt;/p&gt;\n\n&lt;p&gt;Given these challenges, I&amp;#39;ve recently contemplated whether I should bite the bullet and invest in iCloud storage, primarily for the convenience of using Apple&amp;#39;s photo applications while relegating the QNAP to backup duty only. This isn&amp;#39;t my preferred option, however the Apple app handles photos and videos exceptionally well.&lt;/p&gt;\n\n&lt;p&gt;That said, I&amp;#39;m eager to hear if anyone in the community has discovered clever solutions to address these issues. I&amp;#39;d love to know what methods or apps you&amp;#39;re using to streamline the process of managing and accessing photos and videos on your QNAP NAS, especially while on the go. Additionally, if anyone can provide guidance on transcoding, I&amp;#39;d greatly appreciate your help, I really don\u2019t get it.&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vssv0", "is_robot_indexable": true, "report_reasons": null, "author": "RealLychee8799", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vssv0/advice_on_efficient_photo_and_video_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vssv0/advice_on_efficient_photo_and_video_management/", "subreddit_subscribers": 704217, "created_utc": 1696034609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for a storage pooling solution that supports hard links for Plex on Windows 10, and ideally I would not have to format my drives for, does such a thing exist?\n\nThanks in advance.", "author_fullname": "t2_yzxks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storage pooling solution that supports hard links on Windows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vn662", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696021170.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a storage pooling solution that supports hard links for Plex on Windows 10, and ideally I would not have to format my drives for, does such a thing exist?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vn662", "is_robot_indexable": true, "report_reasons": null, "author": "DrewtShite", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vn662/storage_pooling_solution_that_supports_hard_links/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vn662/storage_pooling_solution_that_supports_hard_links/", "subreddit_subscribers": 704217, "created_utc": 1696021170.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I've just jumped from DVD to BluRay (not 4k), and I'm wondering if anyone can give suggestions for a decent external (or internal with a case) for ripping and burning. \n\n\nI have a Pioneer BDR-XD07S 6x Slim Portable USB 3.0 BD/DVD/CD Burner, but man the thing is giving me a heck of a time with errors and such. I'm thinking the drive itself might be bad. I'd say it only completed a disc about 15% of the time, and before the obvious comes up... yeah the discs are fine and clean. I've used DVDfab and MakeMKV both with identical results.\n\nJust wondering what everybody else is using and what they find to be most compatible.", "author_fullname": "t2_69hdh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External burner/ripper suggestions for backing up BluRay movie discs.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vmikv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696019591.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve just jumped from DVD to BluRay (not 4k), and I&amp;#39;m wondering if anyone can give suggestions for a decent external (or internal with a case) for ripping and burning. &lt;/p&gt;\n\n&lt;p&gt;I have a Pioneer BDR-XD07S 6x Slim Portable USB 3.0 BD/DVD/CD Burner, but man the thing is giving me a heck of a time with errors and such. I&amp;#39;m thinking the drive itself might be bad. I&amp;#39;d say it only completed a disc about 15% of the time, and before the obvious comes up... yeah the discs are fine and clean. I&amp;#39;ve used DVDfab and MakeMKV both with identical results.&lt;/p&gt;\n\n&lt;p&gt;Just wondering what everybody else is using and what they find to be most compatible.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vmikv", "is_robot_indexable": true, "report_reasons": null, "author": "CosmosMouse", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vmikv/external_burnerripper_suggestions_for_backing_up/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vmikv/external_burnerripper_suggestions_for_backing_up/", "subreddit_subscribers": 704217, "created_utc": 1696019591.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all. I know this is a common question and I\u2019m sorry. I\u2019ve looked at suggestions from other posts. I was wondering what is the most compact ATX case with room for 4+ drives y\u2019all would recommend? I wanted to mess around with homelab stuff but most importantly need to get a nas going. Had two ssd failures in the last month and tired of reinstalling games and software. I already got a epyc 7402 and a mobo for it and a supermicro sc745 chassis to use as a case, but that case is monstrous and was trying to find something smaller that would fit as many drives, I don\u2019t care about the hot swap and this chassis seems to use up a lot of room with hot swap components. Makes sense for the chassis, but not for me lol. I didn\u2019t know that there was even a mitx sp3 mobo till two days ago otherwise I would\u2019ve gone that direction but a $600 mobo when I already have one is out of the budget atm. If you have any suggestions please I\u2019m all ears. My house is kinda cramped that\u2019s why I\u2019m looking for something more compact but obviously with the mobo and the drives there\u2019s only so small I can go. (I also already have like 18 4tb hdds that I want to utilize).", "author_fullname": "t2_6c9iumag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nas/server case help please", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vlqlj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696052098.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696017708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all. I know this is a common question and I\u2019m sorry. I\u2019ve looked at suggestions from other posts. I was wondering what is the most compact ATX case with room for 4+ drives y\u2019all would recommend? I wanted to mess around with homelab stuff but most importantly need to get a nas going. Had two ssd failures in the last month and tired of reinstalling games and software. I already got a epyc 7402 and a mobo for it and a supermicro sc745 chassis to use as a case, but that case is monstrous and was trying to find something smaller that would fit as many drives, I don\u2019t care about the hot swap and this chassis seems to use up a lot of room with hot swap components. Makes sense for the chassis, but not for me lol. I didn\u2019t know that there was even a mitx sp3 mobo till two days ago otherwise I would\u2019ve gone that direction but a $600 mobo when I already have one is out of the budget atm. If you have any suggestions please I\u2019m all ears. My house is kinda cramped that\u2019s why I\u2019m looking for something more compact but obviously with the mobo and the drives there\u2019s only so small I can go. (I also already have like 18 4tb hdds that I want to utilize).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vlqlj", "is_robot_indexable": true, "report_reasons": null, "author": "tharussianbear", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vlqlj/nasserver_case_help_please/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vlqlj/nasserver_case_help_please/", "subreddit_subscribers": 704217, "created_utc": 1696017708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The drive was barely working when I took it to them, when I'd boot up windows wanted to repair it. I asked then to clone it, they took it, let windows run a repair,  called and said it shows nothing on the drive,  so they moved on to data recovery, after 1 week they said it was showing that it was working and to call in 2 weeks. \n\nIs this normal?", "author_fullname": "t2_2gofd58i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "6tb drive getting prof data recovery. Is 2 to 3 weeks a reasonable estimate from them?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16w6hjo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696079484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The drive was barely working when I took it to them, when I&amp;#39;d boot up windows wanted to repair it. I asked then to clone it, they took it, let windows run a repair,  called and said it shows nothing on the drive,  so they moved on to data recovery, after 1 week they said it was showing that it was working and to call in 2 weeks. &lt;/p&gt;\n\n&lt;p&gt;Is this normal?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16w6hjo", "is_robot_indexable": true, "report_reasons": null, "author": "Beleg1234", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16w6hjo/6tb_drive_getting_prof_data_recovery_is_2_to_3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16w6hjo/6tb_drive_getting_prof_data_recovery_is_2_to_3/", "subreddit_subscribers": 704217, "created_utc": 1696079484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I wanted some advice about Raid, it might be a bit convoluted but i think is relevant to data hoarding? 4TB ain't much but it's the concept (and for users that have inexpensive hardware xD (get your 8TB SSD away)\n\n&amp;#x200B;\n\n//Rambling START//\n\nI'm a beginner trying to make a Raid setup and know to avoid hardware (for its difficulties recovering the data) and that Linux Raid setups are vastly superior to having the best file systems (like ZFS). But i can't change my main PC from Windows nor virtualize it (can't pass through a GPU for reasons) this is why I'm sticking to Windows and trying to make something stupid. \n\nFrom my understanding Windows only available Software Raid is \"Storage spaces\" and \"Disk management\" (but they almost do the same thing if they aren't the same) and as far as 3D party goes Stablebit drive pool is the only good choice? \n\nRegardless i wanted to avoid Parity Raid since its heavy on the CPU and slower in transfer speed and rebuild time (risking another disk failure) for what essentially Raid 10 can do faster (sacrificing more HDD space but for smaller setups like 4 HDD is not that bad)\n\n//Rambling END//\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nThis is what led me to Raid 10 and consequentially Raid 0, why is that you can't just Mix Raid types together on a partition level? so as to have the amazing speed of Raid 0 and \"reliability\" of Raid 10\n\n&amp;#x200B;\n\nfor example: having 4 HDD of 1TB each you build two Raid 0 arrays of 1TB each (1TB + 1TB)\n\nand with the rest of the 2TB giving a 1TB of Raid 10 \n\nthen combining them to mirror each other so as to use the 1TB Raid 0 as \"cache\" and have the redundancy of Raid 10 (with the other Raid chance for programs) \n\n[obviously, it can be fine-tuned to anyone needs.. ](https://preview.redd.it/68wm5ung4erb1.png?width=801&amp;format=png&amp;auto=webp&amp;s=5f8147a33eb798701caba43ce10ff3bf81f36bc6)\n\nbut why everyone isn't using already a small Raid  0 + Raid 1 cache?", "author_fullname": "t2_7n7gre8g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mixed Software Raid Partition??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "media_metadata": {"68wm5ung4erb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 57, "x": 108, "u": "https://preview.redd.it/68wm5ung4erb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=35232f358449ffddf0313b15f8c9a45b67fe0991"}, {"y": 115, "x": 216, "u": "https://preview.redd.it/68wm5ung4erb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4341282ffeb522f4fd3fae7c84a92a5f36928b9d"}, {"y": 171, "x": 320, "u": "https://preview.redd.it/68wm5ung4erb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a7d3cf9b6d8a58d85b460a93fb807505fbfb9f27"}, {"y": 343, "x": 640, "u": "https://preview.redd.it/68wm5ung4erb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bf6d248b16e4035911dd0f0fdaa2807d9fbe9b19"}], "s": {"y": 430, "x": 801, "u": "https://preview.redd.it/68wm5ung4erb1.png?width=801&amp;format=png&amp;auto=webp&amp;s=5f8147a33eb798701caba43ce10ff3bf81f36bc6"}, "id": "68wm5ung4erb1"}}, "name": "t3_16w6eev", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/iygt6az9iNR3YtXZTbkB9lTE5nGn3oIaouRtE6Ed_YE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696079232.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted some advice about Raid, it might be a bit convoluted but i think is relevant to data hoarding? 4TB ain&amp;#39;t much but it&amp;#39;s the concept (and for users that have inexpensive hardware xD (get your 8TB SSD away)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;//Rambling START//&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a beginner trying to make a Raid setup and know to avoid hardware (for its difficulties recovering the data) and that Linux Raid setups are vastly superior to having the best file systems (like ZFS). But i can&amp;#39;t change my main PC from Windows nor virtualize it (can&amp;#39;t pass through a GPU for reasons) this is why I&amp;#39;m sticking to Windows and trying to make something stupid. &lt;/p&gt;\n\n&lt;p&gt;From my understanding Windows only available Software Raid is &amp;quot;Storage spaces&amp;quot; and &amp;quot;Disk management&amp;quot; (but they almost do the same thing if they aren&amp;#39;t the same) and as far as 3D party goes Stablebit drive pool is the only good choice? &lt;/p&gt;\n\n&lt;p&gt;Regardless i wanted to avoid Parity Raid since its heavy on the CPU and slower in transfer speed and rebuild time (risking another disk failure) for what essentially Raid 10 can do faster (sacrificing more HDD space but for smaller setups like 4 HDD is not that bad)&lt;/p&gt;\n\n&lt;p&gt;//Rambling END//&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is what led me to Raid 10 and consequentially Raid 0, why is that you can&amp;#39;t just Mix Raid types together on a partition level? so as to have the amazing speed of Raid 0 and &amp;quot;reliability&amp;quot; of Raid 10&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;for example: having 4 HDD of 1TB each you build two Raid 0 arrays of 1TB each (1TB + 1TB)&lt;/p&gt;\n\n&lt;p&gt;and with the rest of the 2TB giving a 1TB of Raid 10 &lt;/p&gt;\n\n&lt;p&gt;then combining them to mirror each other so as to use the 1TB Raid 0 as &amp;quot;cache&amp;quot; and have the redundancy of Raid 10 (with the other Raid chance for programs) &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/68wm5ung4erb1.png?width=801&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5f8147a33eb798701caba43ce10ff3bf81f36bc6\"&gt;obviously, it can be fine-tuned to anyone needs.. &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;but why everyone isn&amp;#39;t using already a small Raid  0 + Raid 1 cache?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16w6eev", "is_robot_indexable": true, "report_reasons": null, "author": "Biggodes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16w6eev/mixed_software_raid_partition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16w6eev/mixed_software_raid_partition/", "subreddit_subscribers": 704217, "created_utc": 1696079232.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hi all,\ncould someone tell me if this is shuckable?\nhttps://www.amazon.co.uk/UnionSine-External-Portable-Storage-Compatible/dp/B091FV14V9/ref=sr_1_1_sspa?crid=3LYED6UM00DUB&amp;keywords=usb%2Bhdd&amp;qid=1696077406&amp;sprefix=usb%2Bhdd%2Caps%2C284&amp;sr=8-1-spons&amp;sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&amp;th=1\nI am completely blind, so will try shucking this if it is.\nnot bort yet.\nthank you for any answeres given, i'm greatful in advance.\nis this like the wd and toshiba 2.5 inch drives?\nthe usb soldered to the bord?\nis this a good drive to get?\nwill be used for backing up the os via clonezilla.\nsorry if any rules have been broken by me asking more than a single question.\nhappy data hoarding!\nMajid", "author_fullname": "t2_2g661pzk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "query, is this 2.5 inch hdd shuckable?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16w69mb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696078880.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi all,\ncould someone tell me if this is shuckable?\n&lt;a href=\"https://www.amazon.co.uk/UnionSine-External-Portable-Storage-Compatible/dp/B091FV14V9/ref=sr_1_1_sspa?crid=3LYED6UM00DUB&amp;amp;keywords=usb%2Bhdd&amp;amp;qid=1696077406&amp;amp;sprefix=usb%2Bhdd%2Caps%2C284&amp;amp;sr=8-1-spons&amp;amp;sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&amp;amp;th=1\"&gt;https://www.amazon.co.uk/UnionSine-External-Portable-Storage-Compatible/dp/B091FV14V9/ref=sr_1_1_sspa?crid=3LYED6UM00DUB&amp;amp;keywords=usb%2Bhdd&amp;amp;qid=1696077406&amp;amp;sprefix=usb%2Bhdd%2Caps%2C284&amp;amp;sr=8-1-spons&amp;amp;sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&amp;amp;th=1&lt;/a&gt;\nI am completely blind, so will try shucking this if it is.\nnot bort yet.\nthank you for any answeres given, i&amp;#39;m greatful in advance.\nis this like the wd and toshiba 2.5 inch drives?\nthe usb soldered to the bord?\nis this a good drive to get?\nwill be used for backing up the os via clonezilla.\nsorry if any rules have been broken by me asking more than a single question.\nhappy data hoarding!\nMajid&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16w69mb", "is_robot_indexable": true, "report_reasons": null, "author": "maj01", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16w69mb/query_is_this_25_inch_hdd_shuckable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16w69mb/query_is_this_25_inch_hdd_shuckable/", "subreddit_subscribers": 704217, "created_utc": 1696078880.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was wondering if any exists? I know there's a GUI for youtube-dl, but yt-dlp is a fork. And also, can anyone share your settings for downloading the best quality? I'm not sure why sometimes it downloads in webm and other times in mp4/m4v.", "author_fullname": "t2_2yggv6i0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any GUI for yt-dlp?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vtftp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696036303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if any exists? I know there&amp;#39;s a GUI for youtube-dl, but yt-dlp is a fork. And also, can anyone share your settings for downloading the best quality? I&amp;#39;m not sure why sometimes it downloads in webm and other times in mp4/m4v.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vtftp", "is_robot_indexable": true, "report_reasons": null, "author": "mdknight666", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vtftp/any_gui_for_ytdlp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vtftp/any_gui_for_ytdlp/", "subreddit_subscribers": 704217, "created_utc": 1696036303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\nSince my [last thread from yesterday with remaining unanswered questions](https://reddit.com/r/DataHoarder/s/YerCrRMWZ5) was a disaster, yet still completely tame, hopefully this one is a little bit simpler.\n\nQ1: How can you make it so no one but yourself can access the data on your SD card/flash drive?\n\nQ2: How can you make it so no one but yourself can access the data on your SD card/flash drive?  **like, not even data recovery people.**\n\n*Please* treat both questions separately.\n\n\nWhen searching on Reddit, I couldn\u2019t find an answer. People are different uses for similar questions. I did not apply to me at all.\n\nWhen googling, all you see is different sites advertising different types of programs and I don\u2019t even know where to start. Plus, half of them might not apply to me, or might just be spam, etc.\n\nSD or flash drive only.", "author_fullname": "t2_twezzrht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can you make it so no one but yourself can access the data on your SD card/flash drive? like, not even data recovery people.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16vyare", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.36, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696051556.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696050975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since my &lt;a href=\"https://reddit.com/r/DataHoarder/s/YerCrRMWZ5\"&gt;last thread from yesterday with remaining unanswered questions&lt;/a&gt; was a disaster, yet still completely tame, hopefully this one is a little bit simpler.&lt;/p&gt;\n\n&lt;p&gt;Q1: How can you make it so no one but yourself can access the data on your SD card/flash drive?&lt;/p&gt;\n\n&lt;p&gt;Q2: How can you make it so no one but yourself can access the data on your SD card/flash drive?  &lt;strong&gt;like, not even data recovery people.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Please&lt;/em&gt; treat both questions separately.&lt;/p&gt;\n\n&lt;p&gt;When searching on Reddit, I couldn\u2019t find an answer. People are different uses for similar questions. I did not apply to me at all.&lt;/p&gt;\n\n&lt;p&gt;When googling, all you see is different sites advertising different types of programs and I don\u2019t even know where to start. Plus, half of them might not apply to me, or might just be spam, etc.&lt;/p&gt;\n\n&lt;p&gt;SD or flash drive only.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16vyare", "is_robot_indexable": true, "report_reasons": null, "author": "Skarmory113", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16vyare/how_can_you_make_it_so_no_one_but_yourself_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16vyare/how_can_you_make_it_so_no_one_but_yourself_can/", "subreddit_subscribers": 704217, "created_utc": 1696050975.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}