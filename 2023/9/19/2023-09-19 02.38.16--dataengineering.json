{"kind": "Listing", "data": {"after": "t3_16m8d8p", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For example, I once manually deleted a partition of a table by going to the AWS console and permanently deleting an S3 folder. What\u2019s something similar that you have done?", "author_fullname": "t2_h9grrinuz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the most \u201cagainst best DE practices\u201d things you have ever done at your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lkxuz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695008901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For example, I once manually deleted a partition of a table by going to the AWS console and permanently deleting an S3 folder. What\u2019s something similar that you have done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "16lkxuz", "is_robot_indexable": true, "report_reasons": null, "author": "anabaranamarana", "discussion_type": null, "num_comments": 51, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16lkxuz/whats_the_most_against_best_de_practices_things/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16lkxuz/whats_the_most_against_best_de_practices_things/", "subreddit_subscribers": 129133, "created_utc": 1695008901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear subreddit, there have been many complaints here lately about the quality of posts. I present to you this hidden gem that I found, which has gone under the radar. Please read the article and I encourage some healthy discussion. I also highly encourage criticism of this artchitecture because I am smitten by these numbers and I would like someone to slap me back to reality.\n\nThe article can be found here and it's from Coiled. It uses Coiled, Dask and Xarray:\n\nBlog: [https://blog.coiled.io/blog/coiled-xarray.html](https://blog.coiled.io/blog/coiled-xarray.html)    \nCode: [https://github.com/coiled/examples/blob/main/national-water-model/xarray-water-model.py](https://github.com/coiled/examples/blob/main/national-water-model/xarray-water-model.py)\n\nApart from Dask, I haven't heard of the Coiled or Xarray but they seem to be pip installable so I don't think there's not much overhead in using them.\n\nGiven that Spark might be the goto choice for this scale of data and given that I'd never willingly use Spark and admit to it, I'd have to come up with alternative strategies to process 250TB. So far, I have not been able to come up with an alternative strategy that can achieve the same time and cost efficiency.\n\n**What would be your approach to replicate what's been done in the article? You can assume an alterate but similar problem. Please mention the following:**\n\n* **Tools you would use?**\n* **How much time it would take you to bootstrap this?**\n* **Estimated time to completion?**\n* **Estimated total cloud cost?**\n* **Additional comments on why your strategy is better?**\n\nIn my opinion being able to download and process 250TB within 20 minutes is an darn good benchmark. I do want to point out that initially, I was repulsed by the fact that they use 200 VMs in their Coiled cluster. It seems like too much overhead. But when I thought about it further, it might actually be a pretty genius move. It wasn't mentioned in the article so I'm of the opinion the author doesn't realize it either that each AWS VM, ie. the r7g.2xlarge (64GB RAM) has a network bandwidth limit of 15 Gbps (1.875 GBps) but the r7g.metal (512GB RAM) instance has a network bandwidth limit of only 30 Gbps (3.75 GBps) which only 2x more than the r7g.2xlarge but is 8x more expensive. So this means it is optimal to use many smaller VMs instead of a few large ones if you want to actually download 250TB really quickly.\n\nP.S. Not affiliated to any of the companies here.", "author_fullname": "t2_l2e9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Process 250TB in 20 minutes for $25 using a 200 VM cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lu20w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695039664.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear subreddit, there have been many complaints here lately about the quality of posts. I present to you this hidden gem that I found, which has gone under the radar. Please read the article and I encourage some healthy discussion. I also highly encourage criticism of this artchitecture because I am smitten by these numbers and I would like someone to slap me back to reality.&lt;/p&gt;\n\n&lt;p&gt;The article can be found here and it&amp;#39;s from Coiled. It uses Coiled, Dask and Xarray:&lt;/p&gt;\n\n&lt;p&gt;Blog: &lt;a href=\"https://blog.coiled.io/blog/coiled-xarray.html\"&gt;https://blog.coiled.io/blog/coiled-xarray.html&lt;/a&gt;&lt;br/&gt;\nCode: &lt;a href=\"https://github.com/coiled/examples/blob/main/national-water-model/xarray-water-model.py\"&gt;https://github.com/coiled/examples/blob/main/national-water-model/xarray-water-model.py&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Apart from Dask, I haven&amp;#39;t heard of the Coiled or Xarray but they seem to be pip installable so I don&amp;#39;t think there&amp;#39;s not much overhead in using them.&lt;/p&gt;\n\n&lt;p&gt;Given that Spark might be the goto choice for this scale of data and given that I&amp;#39;d never willingly use Spark and admit to it, I&amp;#39;d have to come up with alternative strategies to process 250TB. So far, I have not been able to come up with an alternative strategy that can achieve the same time and cost efficiency.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What would be your approach to replicate what&amp;#39;s been done in the article? You can assume an alterate but similar problem. Please mention the following:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Tools you would use?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;How much time it would take you to bootstrap this?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Estimated time to completion?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Estimated total cloud cost?&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Additional comments on why your strategy is better?&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In my opinion being able to download and process 250TB within 20 minutes is an darn good benchmark. I do want to point out that initially, I was repulsed by the fact that they use 200 VMs in their Coiled cluster. It seems like too much overhead. But when I thought about it further, it might actually be a pretty genius move. It wasn&amp;#39;t mentioned in the article so I&amp;#39;m of the opinion the author doesn&amp;#39;t realize it either that each AWS VM, ie. the r7g.2xlarge (64GB RAM) has a network bandwidth limit of 15 Gbps (1.875 GBps) but the r7g.metal (512GB RAM) instance has a network bandwidth limit of only 30 Gbps (3.75 GBps) which only 2x more than the r7g.2xlarge but is 8x more expensive. So this means it is optimal to use many smaller VMs instead of a few large ones if you want to actually download 250TB really quickly.&lt;/p&gt;\n\n&lt;p&gt;P.S. Not affiliated to any of the companies here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16lu20w", "is_robot_indexable": true, "report_reasons": null, "author": "nitred", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16lu20w/process_250tb_in_20_minutes_for_25_using_a_200_vm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16lu20w/process_250tb_in_20_minutes_for_25_using_a_200_vm/", "subreddit_subscribers": 129133, "created_utc": 1695039664.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Going to be starting as a Sr. Data Analytics Engineer. \n\nI have never started a job remotely. I have experiencing onboarding new hires remotely and tbh(coming from the onboarding end) this is the one thing of WFH that I have found especially intimidating.\n\nWhat advice do y'll have?", "author_fullname": "t2_5vqn2nya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Day 1 of a new job starting remotely - what do you do to make it to smoothly?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lsx5u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695036462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Going to be starting as a Sr. Data Analytics Engineer. &lt;/p&gt;\n\n&lt;p&gt;I have never started a job remotely. I have experiencing onboarding new hires remotely and tbh(coming from the onboarding end) this is the one thing of WFH that I have found especially intimidating.&lt;/p&gt;\n\n&lt;p&gt;What advice do y&amp;#39;ll have?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16lsx5u", "is_robot_indexable": true, "report_reasons": null, "author": "recentcurrency", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16lsx5u/day_1_of_a_new_job_starting_remotely_what_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16lsx5u/day_1_of_a_new_job_starting_remotely_what_do_you/", "subreddit_subscribers": 129133, "created_utc": 1695036462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Apache Iceberg is a popular open-source table format for large data sets, but I'm curious to know more about how it's being used in the real world. What are some specific use cases where Iceberg is solving problems that were difficult or impossible to solve before? What were the challenges before Iceberg, and how has it made things easier?\n\nI'm particularly interested in hearing from data engineers and scientists who have used Iceberg in production. What are your favorite features? What are some of the challenges you've faced, and how have you overcome them?", "author_fullname": "t2_6cx43fk3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the real use cases being solved using Apache Iceberg and how was it done before or what were the challenges?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lknys", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695008038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apache Iceberg is a popular open-source table format for large data sets, but I&amp;#39;m curious to know more about how it&amp;#39;s being used in the real world. What are some specific use cases where Iceberg is solving problems that were difficult or impossible to solve before? What were the challenges before Iceberg, and how has it made things easier?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m particularly interested in hearing from data engineers and scientists who have used Iceberg in production. What are your favorite features? What are some of the challenges you&amp;#39;ve faced, and how have you overcome them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16lknys", "is_robot_indexable": true, "report_reasons": null, "author": "SnooHesitations2050", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16lknys/what_are_the_real_use_cases_being_solved_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16lknys/what_are_the_real_use_cases_being_solved_using/", "subreddit_subscribers": 129133, "created_utc": 1695008038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI found a job position that I really like and decided to apply. They are looking for a data engineer, but instead of (only) doing ETL moving data from A to B, they also want the DE to work on developing an event-driven microservices architecture.\n\nDo you see it like a career progression or regression?\nPersonally speaking I really enjoy the idea of being in a DE/SWE hybrid role. It could also be an opportunity to play with beam, stream processing engines, and real time analytics tools like druid or Pinot", "author_fullname": "t2_do2bj7xa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transition to develop event-driven architecture?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lnp6o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "08789422-ac9d-11eb-aade-0e32c0bdd4fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695018079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I found a job position that I really like and decided to apply. They are looking for a data engineer, but instead of (only) doing ETL moving data from A to B, they also want the DE to work on developing an event-driven microservices architecture.&lt;/p&gt;\n\n&lt;p&gt;Do you see it like a career progression or regression?\nPersonally speaking I really enjoy the idea of being in a DE/SWE hybrid role. It could also be an opportunity to play with beam, stream processing engines, and real time analytics tools like druid or Pinot&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Big Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16lnp6o", "is_robot_indexable": true, "report_reasons": null, "author": "somerandomdataeng", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16lnp6o/transition_to_develop_eventdriven_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16lnp6o/transition_to_develop_eventdriven_architecture/", "subreddit_subscribers": 129133, "created_utc": 1695018079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I have the following workflow:\n\nExtract .csvs from a database (typically SQL Server), save them to blob storage in Azure\n\nIn a Python script, read the .csvs, do some data cleaning (remove unused columns, validate formats etc), and then, using \"pyodbc\", loading all the data into database_temp.\n\nOnce that is done, another Python script runs that gets SQL queries I also have in Azure blob storage, and executes them on the database_temp. The query results are then loaded onto destination_database, which is used to connect Power BI for reporting.\n\nSeems pretty simple but I see the following issues:\n\n1. It's using Azure functions to run the scripts. The first script runs through an HTTP function that gets two parameters, and the second function is also an HTTP triggered one that gets called after the first one is finished. Am I supposed to be using something else?\n\n2. No CDC. I have no control over the databases so that's no really a possibility (afaik). I implemented a pure Python source destination comparison but I'm not convinced. It requires that every table has IDs (which is very often not a thing...), and is done by loading the source .csv on memory, and, for each table, comparing rows in the form of dictionaries: if ID doesn't exist in target, insert row. If ID is in target but not in source, delete row. If any value of a key in a row changes, it gets deleted and inserted. Works, but it's hell to do any kind of error handling, and both the whole .csv has to be loaded in memory, plus querying the target database for all rows in a table...\n\n3. Two databases. Is there any benefit to this? Should I just do it in one (temp_database can have any amount of tables, while destination_database always has 20)?\n\n4. How am I supposed to notify of any errors? Send a mail to myself? A message to Teams chat? Lol.\n\nAny input or recommendations appreciated.", "author_fullname": "t2_sfbys1gt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What tools should I be using to make this small process the most robust/efficient?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lyd7r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695050358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I have the following workflow:&lt;/p&gt;\n\n&lt;p&gt;Extract .csvs from a database (typically SQL Server), save them to blob storage in Azure&lt;/p&gt;\n\n&lt;p&gt;In a Python script, read the .csvs, do some data cleaning (remove unused columns, validate formats etc), and then, using &amp;quot;pyodbc&amp;quot;, loading all the data into database_temp.&lt;/p&gt;\n\n&lt;p&gt;Once that is done, another Python script runs that gets SQL queries I also have in Azure blob storage, and executes them on the database_temp. The query results are then loaded onto destination_database, which is used to connect Power BI for reporting.&lt;/p&gt;\n\n&lt;p&gt;Seems pretty simple but I see the following issues:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;It&amp;#39;s using Azure functions to run the scripts. The first script runs through an HTTP function that gets two parameters, and the second function is also an HTTP triggered one that gets called after the first one is finished. Am I supposed to be using something else?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;No CDC. I have no control over the databases so that&amp;#39;s no really a possibility (afaik). I implemented a pure Python source destination comparison but I&amp;#39;m not convinced. It requires that every table has IDs (which is very often not a thing...), and is done by loading the source .csv on memory, and, for each table, comparing rows in the form of dictionaries: if ID doesn&amp;#39;t exist in target, insert row. If ID is in target but not in source, delete row. If any value of a key in a row changes, it gets deleted and inserted. Works, but it&amp;#39;s hell to do any kind of error handling, and both the whole .csv has to be loaded in memory, plus querying the target database for all rows in a table...&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Two databases. Is there any benefit to this? Should I just do it in one (temp_database can have any amount of tables, while destination_database always has 20)?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How am I supposed to notify of any errors? Send a mail to myself? A message to Teams chat? Lol.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any input or recommendations appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16lyd7r", "is_robot_indexable": true, "report_reasons": null, "author": "necesitorespuestas", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16lyd7r/what_tools_should_i_be_using_to_make_this_small/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16lyd7r/what_tools_should_i_be_using_to_make_this_small/", "subreddit_subscribers": 129133, "created_utc": 1695050358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Team is currently evaluating these two and so was curious what everyone thought - what are the main technical differentiators that would lead you to pick one over the other?", "author_fullname": "t2_g5clk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fabric vs Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m8v6s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695074671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Team is currently evaluating these two and so was curious what everyone thought - what are the main technical differentiators that would lead you to pick one over the other?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16m8v6s", "is_robot_indexable": true, "report_reasons": null, "author": "Dabli", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16m8v6s/fabric_vs_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16m8v6s/fabric_vs_databricks/", "subreddit_subscribers": 129133, "created_utc": 1695074671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a software/data engineer, and I'm trying to help a small non-profit streamline some data processes. Tens of thousands of rows, basically a rounding error in \"big data\" terms, but big enough that wrangling spreadsheets is unwieldy, manual and error-prone.\n\nThe requirements are to manage a small database with a handful of tables, with joins and aggregations between them, and some reporting based on this: Memberships, payment of dues, donations, sign-up for various activities. Payments are of course handled by a third-party provider, so we need to integrate with them using a REST API. Reporting includes keeping track of membership dues payment, and that attendants at activities have current memberships (a regulatory requirement).\n\nI'm a volunteer: Whatever we come up with, the key requirement is that it's as completely self-running SaaS as possible so it does not present an ongoing support commitment for me. I'd like it to be quite modern and no-code so someone who isn't an engineer could be comfortable working in the system. They're a non-profit so it should cost an arm and a leg, but it doesn't have to be free. We have reviewed a range of dedicated membership platforms, but we have found them to be very expensive and with a poor feature fit (we don't need AI-based churn prediction and an app for members).\n\nWhat do I mean by completely self-running? I am trialing Databricks, and there's a swamp of Azure/AWS admin stuff before you get to the tool. I hit a wall on Databricks with some quotas that apparently wasn't set up on the cloud provider side, so it couldn't do anything, just huge, red errors telling me to request quote increases. I can see how this is valuable for large, complex deployments, but at my scale, I simply do not want to deal with this level of complexity. Databricks does look promising though, and I've reached out to their onboarding support with this issue, so let's see.\n\nI looked at Airtable, and initially liked it, but it does not seem to be very elegant to import data into it (and my payment provider doesn't have an existing Airtable integration). The joining and aggregating between tables seems very limited, something as simple as joining payments, members and membership types to have a single view of current members was very awkward and not very transparent.\n\nAny ideas from this community for simple tools that will meet these requirements would be greatly appreciated!", "author_fullname": "t2_12pyoj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lightweight completely SaaS data platform for small org", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lx1ju", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695047217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a software/data engineer, and I&amp;#39;m trying to help a small non-profit streamline some data processes. Tens of thousands of rows, basically a rounding error in &amp;quot;big data&amp;quot; terms, but big enough that wrangling spreadsheets is unwieldy, manual and error-prone.&lt;/p&gt;\n\n&lt;p&gt;The requirements are to manage a small database with a handful of tables, with joins and aggregations between them, and some reporting based on this: Memberships, payment of dues, donations, sign-up for various activities. Payments are of course handled by a third-party provider, so we need to integrate with them using a REST API. Reporting includes keeping track of membership dues payment, and that attendants at activities have current memberships (a regulatory requirement).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a volunteer: Whatever we come up with, the key requirement is that it&amp;#39;s as completely self-running SaaS as possible so it does not present an ongoing support commitment for me. I&amp;#39;d like it to be quite modern and no-code so someone who isn&amp;#39;t an engineer could be comfortable working in the system. They&amp;#39;re a non-profit so it should cost an arm and a leg, but it doesn&amp;#39;t have to be free. We have reviewed a range of dedicated membership platforms, but we have found them to be very expensive and with a poor feature fit (we don&amp;#39;t need AI-based churn prediction and an app for members).&lt;/p&gt;\n\n&lt;p&gt;What do I mean by completely self-running? I am trialing Databricks, and there&amp;#39;s a swamp of Azure/AWS admin stuff before you get to the tool. I hit a wall on Databricks with some quotas that apparently wasn&amp;#39;t set up on the cloud provider side, so it couldn&amp;#39;t do anything, just huge, red errors telling me to request quote increases. I can see how this is valuable for large, complex deployments, but at my scale, I simply do not want to deal with this level of complexity. Databricks does look promising though, and I&amp;#39;ve reached out to their onboarding support with this issue, so let&amp;#39;s see.&lt;/p&gt;\n\n&lt;p&gt;I looked at Airtable, and initially liked it, but it does not seem to be very elegant to import data into it (and my payment provider doesn&amp;#39;t have an existing Airtable integration). The joining and aggregating between tables seems very limited, something as simple as joining payments, members and membership types to have a single view of current members was very awkward and not very transparent.&lt;/p&gt;\n\n&lt;p&gt;Any ideas from this community for simple tools that will meet these requirements would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16lx1ju", "is_robot_indexable": true, "report_reasons": null, "author": "mseebach", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16lx1ju/lightweight_completely_saas_data_platform_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16lx1ju/lightweight_completely_saas_data_platform_for/", "subreddit_subscribers": 129133, "created_utc": 1695047217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_rw361lg4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use your database to power state machines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": false, "name": "t3_16lpcb7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aaU7_X-WB-HMtIDWU3Oc5qvfJuguzs1pR5lGH-JTqhk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695024105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.lawrencejones.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.lawrencejones.dev/state-machines/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/CDNJfJF_zNSx2ND1QaUhM3JJyNLcQXwrvo7VolekkHE.jpg?auto=webp&amp;s=a730af5855e53ec3bbdb66730507000e5e36dcd7", "width": 1564, "height": 968}, "resolutions": [{"url": "https://external-preview.redd.it/CDNJfJF_zNSx2ND1QaUhM3JJyNLcQXwrvo7VolekkHE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=099aab54556c4315a77c42548e5418f1dd5d14f7", "width": 108, "height": 66}, {"url": "https://external-preview.redd.it/CDNJfJF_zNSx2ND1QaUhM3JJyNLcQXwrvo7VolekkHE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=99f9d52fcea6882216ceeaa6f669fda61fe802e4", "width": 216, "height": 133}, {"url": "https://external-preview.redd.it/CDNJfJF_zNSx2ND1QaUhM3JJyNLcQXwrvo7VolekkHE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4f31631b4ad347e8c0a51f695c8a7f387f38db13", "width": 320, "height": 198}, {"url": "https://external-preview.redd.it/CDNJfJF_zNSx2ND1QaUhM3JJyNLcQXwrvo7VolekkHE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ae673b985a4aabfef4a9c32dde4f59ed11ab6cf7", "width": 640, "height": 396}, {"url": "https://external-preview.redd.it/CDNJfJF_zNSx2ND1QaUhM3JJyNLcQXwrvo7VolekkHE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b3de185486edcb791c5071068deb49f0e578f1ef", "width": 960, "height": 594}, {"url": "https://external-preview.redd.it/CDNJfJF_zNSx2ND1QaUhM3JJyNLcQXwrvo7VolekkHE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=270bab0e9b32770cea16b06ca42bbb81c899e0ef", "width": 1080, "height": 668}], "variants": {}, "id": "yROKtsBuPdy6F1ObOAybTxtWzXLTV7DUTE8pfvK-IFg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16lpcb7", "is_robot_indexable": true, "report_reasons": null, "author": "ginantmad", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16lpcb7/use_your_database_to_power_state_machines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.lawrencejones.dev/state-machines/", "subreddit_subscribers": 129133, "created_utc": 1695024105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI've been working within the Data Engineering world (at least that's what I believe) for 5 years, and there was never any use of Python in projects I've been involved in. Even though we use ADF, Databricks (Spark), Synapse Analytics, and so on, what scares me is that anytime I search through job offers it is always about an experience with Python (PySpark). I went through a lot of books regarding that, and did some personal projects, but it was always only about reading dataframes, doing some basic aggregations, grouping data, putting them in some kind of warehouse/lakehouse whatever, which could easily be done using SparkSQL (which we do in our pretty HUGE project, with a small amount of Scala to save DFs/tables to other sources like ADLS and warehouse..), though I don't feel like that's enough to make into a DE role with Python, can you tell my how does it really look like in huge DE projects, based on Python? Is it really just that, or it's more about implementing something special idk? I'm just lost \ud83d\ude2d", "author_fullname": "t2_4xcszhdt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of Python is used within DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m7ozt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695071965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working within the Data Engineering world (at least that&amp;#39;s what I believe) for 5 years, and there was never any use of Python in projects I&amp;#39;ve been involved in. Even though we use ADF, Databricks (Spark), Synapse Analytics, and so on, what scares me is that anytime I search through job offers it is always about an experience with Python (PySpark). I went through a lot of books regarding that, and did some personal projects, but it was always only about reading dataframes, doing some basic aggregations, grouping data, putting them in some kind of warehouse/lakehouse whatever, which could easily be done using SparkSQL (which we do in our pretty HUGE project, with a small amount of Scala to save DFs/tables to other sources like ADLS and warehouse..), though I don&amp;#39;t feel like that&amp;#39;s enough to make into a DE role with Python, can you tell my how does it really look like in huge DE projects, based on Python? Is it really just that, or it&amp;#39;s more about implementing something special idk? I&amp;#39;m just lost \ud83d\ude2d&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16m7ozt", "is_robot_indexable": true, "report_reasons": null, "author": "tanssive", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16m7ozt/what_kind_of_python_is_used_within_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16m7ozt/what_kind_of_python_is_used_within_de/", "subreddit_subscribers": 129133, "created_utc": 1695071965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " A curated reading list for the adversarial perspective in deep reinforcement learning.\n\n[https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning](https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning)", "author_fullname": "t2_dxnb75vp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adversarial Reinforcement Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lrb1j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695031286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A curated reading list for the adversarial perspective in deep reinforcement learning.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning\"&gt;https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Kb9A_i-HoN65QNTa-RLQPLO6V5m6B7yexmXWeFeGibw.jpg?auto=webp&amp;s=01ef2f0765a64f8915eaad19e36abb855f5eda46", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Kb9A_i-HoN65QNTa-RLQPLO6V5m6B7yexmXWeFeGibw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d10db165b96ac09da0f15dd148535be8e22b2659", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Kb9A_i-HoN65QNTa-RLQPLO6V5m6B7yexmXWeFeGibw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=54b92eba5cf7efb24ab20250c915cc2dc1fd8c44", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Kb9A_i-HoN65QNTa-RLQPLO6V5m6B7yexmXWeFeGibw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f5b8fcae0d6e04177531d5b22143a411882aab2b", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Kb9A_i-HoN65QNTa-RLQPLO6V5m6B7yexmXWeFeGibw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=cf0318b6072e518e6735d8c0d5a4ad3357e1c68a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Kb9A_i-HoN65QNTa-RLQPLO6V5m6B7yexmXWeFeGibw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3c316b325330d8b817c1d1e25c2a11066dd95282", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Kb9A_i-HoN65QNTa-RLQPLO6V5m6B7yexmXWeFeGibw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3e5773cb3a76824fd15cdcc11aa609bb409ee379", "width": 1080, "height": 540}], "variants": {}, "id": "hdP6nzsrcXS-yyUiIq6LVzHReJMvniqfNPGIiddzk00"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16lrb1j", "is_robot_indexable": true, "report_reasons": null, "author": "ml_dnn", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16lrb1j/adversarial_reinforcement_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16lrb1j/adversarial_reinforcement_learning/", "subreddit_subscribers": 129133, "created_utc": 1695031286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a big, complex, ever-changing data pipeline hosted on BigQuery, but it ultimately has to feed into a dashboard so that executives can understand it. And that dashboard has to load quickly.\n\nThat means that we need to group out data to make it smaller -- but I'm not sure the best way to do that.\n\nWould you create a table, a view, or something else?\n\n**Why I can't just pipe the raw data into the pipeline**\n\nOur model is dedicated to trying to understand and continuously rewrite our customers' journeys based on data in a number of different sources. That means that the key tables use either user\\_id, session\\_id, or timestamps as their primary keys, which just means that they tend to be very large.\n\nCreating another table that uses groups lowers the size of the data for dashboard ingestion, but...\n\n**The problems I'm having with tables**\n\n... the data is constantly changing. We're constantly rewriting customer journeys as we learn more about the users, and we also just sometimes throw changes into the model when we come up with ways to improve it.\n\nThat can be a problem, because, for efficiency, we update our dashboards by pulling data for the past 2 days only and merging it. When something historical changes, we have to delete and rewrite the whole table, which can put the dashboards out of commission for a bit.\n\nAlso, there's just so much in this pipeline that it's just a pain to try to update everything every time something changes.\n\n**The problems I'm having with Views**\n\nViews solve that problem because they don't have to be updated -- but, obviously, they're not very efficient. Since they have to run the queries every time, they're basically equivalent to rewriting the dashboard tables every time someone opens the dashboard.\n\n**Is there something else?**\n\nI feel like this is not at all a unique problem and there's got to be an ideal solution for it, but I can't find a good consensus online.\n\nHow do you tackle condensing data for dashboards?", "author_fullname": "t2_bxdnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practices for Prepping Data for a Dashboard: Views, Tables, or Both?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m6ias", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695069237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a big, complex, ever-changing data pipeline hosted on BigQuery, but it ultimately has to feed into a dashboard so that executives can understand it. And that dashboard has to load quickly.&lt;/p&gt;\n\n&lt;p&gt;That means that we need to group out data to make it smaller -- but I&amp;#39;m not sure the best way to do that.&lt;/p&gt;\n\n&lt;p&gt;Would you create a table, a view, or something else?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why I can&amp;#39;t just pipe the raw data into the pipeline&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Our model is dedicated to trying to understand and continuously rewrite our customers&amp;#39; journeys based on data in a number of different sources. That means that the key tables use either user_id, session_id, or timestamps as their primary keys, which just means that they tend to be very large.&lt;/p&gt;\n\n&lt;p&gt;Creating another table that uses groups lowers the size of the data for dashboard ingestion, but...&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The problems I&amp;#39;m having with tables&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;... the data is constantly changing. We&amp;#39;re constantly rewriting customer journeys as we learn more about the users, and we also just sometimes throw changes into the model when we come up with ways to improve it.&lt;/p&gt;\n\n&lt;p&gt;That can be a problem, because, for efficiency, we update our dashboards by pulling data for the past 2 days only and merging it. When something historical changes, we have to delete and rewrite the whole table, which can put the dashboards out of commission for a bit.&lt;/p&gt;\n\n&lt;p&gt;Also, there&amp;#39;s just so much in this pipeline that it&amp;#39;s just a pain to try to update everything every time something changes.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The problems I&amp;#39;m having with Views&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Views solve that problem because they don&amp;#39;t have to be updated -- but, obviously, they&amp;#39;re not very efficient. Since they have to run the queries every time, they&amp;#39;re basically equivalent to rewriting the dashboard tables every time someone opens the dashboard.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is there something else?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I feel like this is not at all a unique problem and there&amp;#39;s got to be an ideal solution for it, but I can&amp;#39;t find a good consensus online.&lt;/p&gt;\n\n&lt;p&gt;How do you tackle condensing data for dashboards?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16m6ias", "is_robot_indexable": true, "report_reasons": null, "author": "takenorinvalid", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16m6ias/best_practices_for_prepping_data_for_a_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16m6ias/best_practices_for_prepping_data_for_a_dashboard/", "subreddit_subscribers": 129133, "created_utc": 1695069237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're mainly sql server based and we are considering using dbt tests (and dbt great expectations package) as a our data testing method. Has anyone used dbt core solely for tests? \n\nWe receive data from many clients and always seem to have issues - they break something upstream, they include data on some new product they didn't tell us about, etc. \n\nWe want to \n\n* check for freshness of data\n* any kind of anomalies based on historical data (ex a difference of 2 std devs compared to last week). \n   * especially when sliced by different dims. \n* relationship (orphan) checks\n* business logic checks  (x field always populated for y product)\n\nWe use airflow for orchestration. We would trigger dbt test either at the end of the dag or have a separate dag to run the tests after everything has loaded. \n\n&amp;#x200B;\n\nHave been passively looking at Soda Core, as well.", "author_fullname": "t2_3yozg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using dbt only as test suite?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m3qhq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695062912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re mainly sql server based and we are considering using dbt tests (and dbt great expectations package) as a our data testing method. Has anyone used dbt core solely for tests? &lt;/p&gt;\n\n&lt;p&gt;We receive data from many clients and always seem to have issues - they break something upstream, they include data on some new product they didn&amp;#39;t tell us about, etc. &lt;/p&gt;\n\n&lt;p&gt;We want to &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;check for freshness of data&lt;/li&gt;\n&lt;li&gt;any kind of anomalies based on historical data (ex a difference of 2 std devs compared to last week). \n\n&lt;ul&gt;\n&lt;li&gt;especially when sliced by different dims. &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;relationship (orphan) checks&lt;/li&gt;\n&lt;li&gt;business logic checks  (x field always populated for y product)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We use airflow for orchestration. We would trigger dbt test either at the end of the dag or have a separate dag to run the tests after everything has loaded. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Have been passively looking at Soda Core, as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16m3qhq", "is_robot_indexable": true, "report_reasons": null, "author": "gman1023", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16m3qhq/using_dbt_only_as_test_suite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16m3qhq/using_dbt_only_as_test_suite/", "subreddit_subscribers": 129133, "created_utc": 1695062912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I hope this blog post finds you well and provides you with some valuable and interesting insights. I would love to get some feedback. In particular, I would be interested to hear about your experiences with datahub and openmetadata.\u00a0", "author_fullname": "t2_h8l33sqhs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparison of Open Source Data Catalogs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_16m1lz9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7dpIywNZ2xs_te1s8D0RQwQvD7Tqe0c2Lo1cGHGxqjU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695057995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "inovex.de", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I hope this blog post finds you well and provides you with some valuable and interesting insights. I would love to get some feedback. In particular, I would be interested to hear about your experiences with datahub and openmetadata.\u00a0&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.inovex.de/de/blog/data-observability-is-key-a-hands-on-comparison-of-open-source-data-catalog-tools/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/N1CUPBIBo2usafSclE469R_jdKgdmwXdt9KS8ciAM3k.jpg?auto=webp&amp;s=2778b754c6f5eb084071c5439b1d2ca9951dc6a9", "width": 1500, "height": 880}, "resolutions": [{"url": "https://external-preview.redd.it/N1CUPBIBo2usafSclE469R_jdKgdmwXdt9KS8ciAM3k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c1ef5d8a22746bc4e7b35615efb8356c2949b5a8", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/N1CUPBIBo2usafSclE469R_jdKgdmwXdt9KS8ciAM3k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b287c1fa803322b854d307e18463126d9f0552f0", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/N1CUPBIBo2usafSclE469R_jdKgdmwXdt9KS8ciAM3k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c5b6de14c1bf9e82d39e3a7537f890aba6bbfec", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/N1CUPBIBo2usafSclE469R_jdKgdmwXdt9KS8ciAM3k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7eb5e96baa9583ab06130af84a83ecab632a16e0", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/N1CUPBIBo2usafSclE469R_jdKgdmwXdt9KS8ciAM3k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=986c88d4a5a764466bff3297b1d865cc1d44b967", "width": 960, "height": 563}, {"url": "https://external-preview.redd.it/N1CUPBIBo2usafSclE469R_jdKgdmwXdt9KS8ciAM3k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fd0f16e03a7c009cc66e2cb931cf9ca9ae25befe", "width": 1080, "height": 633}], "variants": {}, "id": "tvlDCTwhfThqWP-0qD7nHjldKp54rhORKSF3uTr5Ho4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16m1lz9", "is_robot_indexable": true, "report_reasons": null, "author": "infopost253", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16m1lz9/comparison_of_open_source_data_catalogs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.inovex.de/de/blog/data-observability-is-key-a-hands-on-comparison-of-open-source-data-catalog-tools/", "subreddit_subscribers": 129133, "created_utc": 1695057995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm deep into a project that's all about creating a data marketplace where users can seamlessly share, access, and even monetize datasets and databases - and other little quirks. I had a conversation with a friend who's a data engineer at this big Asset Management firm. His job? Migrating purchased external datasets into their own data warehouse. \n\nHe shared some nightmare stories of how the API side of things can become a really complicated endeavor. Everything from schema shape-shifting at a whim, API uptime, downtime, data format not aligning with internal structures, handling error codes etc... The whole saga of dealing with authentication mechanisms, from API keys to OAuth tokens, can be a headache. Ensuring secure handling of these credentials can be a project in itself.\n\nWhat are your main worries when dealing with external data access? Have you faced unique challenges in your job or specific projects? And what did you wish existed that would make the process easier? \n\n*P.S: Let's not talk about compliance cause that's a whole annoying beast in itself -.-*", "author_fullname": "t2_f2cuk7se", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is accessing external databases complicated?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ltyir", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695039392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m deep into a project that&amp;#39;s all about creating a data marketplace where users can seamlessly share, access, and even monetize datasets and databases - and other little quirks. I had a conversation with a friend who&amp;#39;s a data engineer at this big Asset Management firm. His job? Migrating purchased external datasets into their own data warehouse. &lt;/p&gt;\n\n&lt;p&gt;He shared some nightmare stories of how the API side of things can become a really complicated endeavor. Everything from schema shape-shifting at a whim, API uptime, downtime, data format not aligning with internal structures, handling error codes etc... The whole saga of dealing with authentication mechanisms, from API keys to OAuth tokens, can be a headache. Ensuring secure handling of these credentials can be a project in itself.&lt;/p&gt;\n\n&lt;p&gt;What are your main worries when dealing with external data access? Have you faced unique challenges in your job or specific projects? And what did you wish existed that would make the process easier? &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;P.S: Let&amp;#39;s not talk about compliance cause that&amp;#39;s a whole annoying beast in itself -.-&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ltyir", "is_robot_indexable": true, "report_reasons": null, "author": "nobilis_rex_", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ltyir/why_is_accessing_external_databases_complicated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ltyir/why_is_accessing_external_databases_complicated/", "subreddit_subscribers": 129133, "created_utc": 1695039392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So Postman finally removed the workspace/scratchpad or whatever the feature was called where you could have your Api calls saved  which I used for debugging my internal APIs and now shows just the history (which is irrelevant for me as I don't want to scroll 2 weeks of history to find an API call I used back then).\n\nAny suggestions for alternatives? I'm pretty set on ditching Postman as their approach seemed very heavy handed for the functionality I was using.", "author_fullname": "t2_9d1jjuxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternatives to Postman?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m4r9t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695065405.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695065206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So Postman finally removed the workspace/scratchpad or whatever the feature was called where you could have your Api calls saved  which I used for debugging my internal APIs and now shows just the history (which is irrelevant for me as I don&amp;#39;t want to scroll 2 weeks of history to find an API call I used back then).&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for alternatives? I&amp;#39;m pretty set on ditching Postman as their approach seemed very heavy handed for the functionality I was using.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16m4r9t", "is_robot_indexable": true, "report_reasons": null, "author": "boggle_thy_mind", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16m4r9t/alternatives_to_postman/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16m4r9t/alternatives_to_postman/", "subreddit_subscribers": 129133, "created_utc": 1695065206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm interested in learning about distributed systems. I've been following the MIT distributed systems course on youtube. It's really interesting but their practice projects are done in a way that, imo, requires access to the teaching staff in order to solve the many doubts and issues that may arise (which makes sense, as that what people pay for) I was able to complete the raft part, but after that, it's just too hard to do without some kind of guidance. Are there any online courses similar to those with plenty of practice material that I could use to become more familiar with distributed systems?", "author_fullname": "t2_w21eqzr0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning and practicing distributed systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lj2fz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695003190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m interested in learning about distributed systems. I&amp;#39;ve been following the MIT distributed systems course on youtube. It&amp;#39;s really interesting but their practice projects are done in a way that, imo, requires access to the teaching staff in order to solve the many doubts and issues that may arise (which makes sense, as that what people pay for) I was able to complete the raft part, but after that, it&amp;#39;s just too hard to do without some kind of guidance. Are there any online courses similar to those with plenty of practice material that I could use to become more familiar with distributed systems?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16lj2fz", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering-Spite234", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16lj2fz/learning_and_practicing_distributed_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16lj2fz/learning_and_practicing_distributed_systems/", "subreddit_subscribers": 129133, "created_utc": 1695003190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are thinking of getting a self-serve data wrangling/preparation tool for our team. I want to know if anyone has any experience with these tools, any limitations and if are they better than writing code and when. How do they work with the rest of the data engineering pipelines in your team?\n\nTools in consideration:\n\n1. [**Alteryx**](https://www.g2.com/products/alteryx/reviews)\n2. [**Trifacta**](https://www.g2.com/products/trifacta/reviews)\n3. [**Altair Monarch**](https://www.g2.com/products/altair-monarch/reviews)\n4. [**TIMi Suite**](https://www.g2.com/products/timi-suite/reviews)\n5. [**Incorta**](https://www.g2.com/products/incorta/reviews)", "author_fullname": "t2_dogbygvr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your experience with self-serve data wrangling/preparation tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mabh6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695078178.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are thinking of getting a self-serve data wrangling/preparation tool for our team. I want to know if anyone has any experience with these tools, any limitations and if are they better than writing code and when. How do they work with the rest of the data engineering pipelines in your team?&lt;/p&gt;\n\n&lt;p&gt;Tools in consideration:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://www.g2.com/products/alteryx/reviews\"&gt;&lt;strong&gt;Alteryx&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.g2.com/products/trifacta/reviews\"&gt;&lt;strong&gt;Trifacta&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.g2.com/products/altair-monarch/reviews\"&gt;&lt;strong&gt;Altair Monarch&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.g2.com/products/timi-suite/reviews\"&gt;&lt;strong&gt;TIMi Suite&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.g2.com/products/incorta/reviews\"&gt;&lt;strong&gt;Incorta&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16mabh6", "is_robot_indexable": true, "report_reasons": null, "author": "vinayak_singh_k", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mabh6/what_is_your_experience_with_selfserve_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mabh6/what_is_your_experience_with_selfserve_data/", "subreddit_subscribers": 129133, "created_utc": 1695078178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This'd be for SQL questions - usually I'd just sign up if for the site and do some practice questions (annoyingly are always a billion times easier than the interview questions).  But the practice options have no SQL here have no. This site seems pretty heavily geared towards companies (as opposed to say leetcode which targets the faang wannabes).\n\nAnyone used it and can you confirm that if I practice on say leetcode like the faang wannabe I am, it'll be somewhat useful?", "author_fullname": "t2_1w1o79i7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone had any technical interviews with CodeSignal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m4wpi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695065551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This&amp;#39;d be for SQL questions - usually I&amp;#39;d just sign up if for the site and do some practice questions (annoyingly are always a billion times easier than the interview questions).  But the practice options have no SQL here have no. This site seems pretty heavily geared towards companies (as opposed to say leetcode which targets the faang wannabes).&lt;/p&gt;\n\n&lt;p&gt;Anyone used it and can you confirm that if I practice on say leetcode like the faang wannabe I am, it&amp;#39;ll be somewhat useful?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16m4wpi", "is_robot_indexable": true, "report_reasons": null, "author": "tea_horse", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16m4wpi/anyone_had_any_technical_interviews_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16m4wpi/anyone_had_any_technical_interviews_with/", "subreddit_subscribers": 129133, "created_utc": 1695065551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the computer science careers Reddit group, I hear a lot about SWE layoffs and SWEs having a tough time finding a job. Same post, different person.\n\nCurious, what has been the experience of Data Engineers during this time? Curious about the comparison.", "author_fullname": "t2_7x2alm42", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job prospects compared to SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ljox2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695005039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the computer science careers Reddit group, I hear a lot about SWE layoffs and SWEs having a tough time finding a job. Same post, different person.&lt;/p&gt;\n\n&lt;p&gt;Curious, what has been the experience of Data Engineers during this time? Curious about the comparison.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ljox2", "is_robot_indexable": true, "report_reasons": null, "author": "InstaMastery", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ljox2/job_prospects_compared_to_swe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ljox2/job_prospects_compared_to_swe/", "subreddit_subscribers": 129133, "created_utc": 1695005039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi \nI really want to get into the field of data engineering. What are the topmost skills and what is the learning curve to enter into field. \nCan someone explain this please. Please also suggest  any useful resources you know of.\n\nThankyou.", "author_fullname": "t2_tltd04hi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to start learning to get into data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16mdul1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695087608.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi \nI really want to get into the field of data engineering. What are the topmost skills and what is the learning curve to enter into field. \nCan someone explain this please. Please also suggest  any useful resources you know of.&lt;/p&gt;\n\n&lt;p&gt;Thankyou.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16mdul1", "is_robot_indexable": true, "report_reasons": null, "author": "Unhappy_Low_4538", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mdul1/how_to_start_learning_to_get_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mdul1/how_to_start_learning_to_get_into_data_engineering/", "subreddit_subscribers": 129133, "created_utc": 1695087608.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company uses Azure, but I\u2019m looking to compare how people use Spark (particularly Pyspark) across different cloud environments to run your DE pipelines. \n\nTo direct this a little\n\n1. In Azure do you use VMs or other IaaS to host Spark or do you depend solely on Databricks, Synapse/Fabric, or ADF?\n\n2. How do you orchestrate your spark pipelines? Do you depend on ADF in Azure? What do you use in AWS or GCP?\n\n3. Does anybody use alternatives to the big 3 to run Spark jobs? How does that work?\n\nI offer these as starting points, but answer with what you know!", "author_fullname": "t2_v98q7m1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running Spark in the Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mbryz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695081925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company uses Azure, but I\u2019m looking to compare how people use Spark (particularly Pyspark) across different cloud environments to run your DE pipelines. &lt;/p&gt;\n\n&lt;p&gt;To direct this a little&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;In Azure do you use VMs or other IaaS to host Spark or do you depend solely on Databricks, Synapse/Fabric, or ADF?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you orchestrate your spark pipelines? Do you depend on ADF in Azure? What do you use in AWS or GCP?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Does anybody use alternatives to the big 3 to run Spark jobs? How does that work?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I offer these as starting points, but answer with what you know!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16mbryz", "is_robot_indexable": true, "report_reasons": null, "author": "bryangoodrich", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16mbryz/running_spark_in_the_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16mbryz/running_spark_in_the_cloud/", "subreddit_subscribers": 129133, "created_utc": 1695081925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team are moving Databricks pipelines into Snowflake/Snowpark, hoping to simplify flows and gain efficiencies. We are also exploring whether we can move pipeline orchestration from Airflow to Snowflake using Snowflake tasks. I am just wondering if anyone has experience with such a move (Airflow to Snowflake tasks for orchestration). ", "author_fullname": "t2_sl8u7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feasibility of Task/DAG orchestration within Snowflake (without Airflow)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m9cej", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695075803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team are moving Databricks pipelines into Snowflake/Snowpark, hoping to simplify flows and gain efficiencies. We are also exploring whether we can move pipeline orchestration from Airflow to Snowflake using Snowflake tasks. I am just wondering if anyone has experience with such a move (Airflow to Snowflake tasks for orchestration). &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16m9cej", "is_robot_indexable": true, "report_reasons": null, "author": "kali042", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16m9cej/feasibility_of_taskdag_orchestration_within/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16m9cej/feasibility_of_taskdag_orchestration_within/", "subreddit_subscribers": 129133, "created_utc": 1695075803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Trying to find resources to both learn &amp; as prep material for interviews. Bibles like System design by Alex Xu, Grokking etc exist for SWE, what resources do you use for DE specific system design questions?", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some good resources to learn DE specific system design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m90bn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695075008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to find resources to both learn &amp;amp; as prep material for interviews. Bibles like System design by Alex Xu, Grokking etc exist for SWE, what resources do you use for DE specific system design questions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16m90bn", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16m90bn/what_are_some_good_resources_to_learn_de_specific/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16m90bn/what_are_some_good_resources_to_learn_de_specific/", "subreddit_subscribers": 129133, "created_utc": 1695075008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am a newbie to airflow and tyring to inspect images at certain location at the end of DAG i.e. notify task.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/86tibhpm33pb1.png?width=514&amp;format=png&amp;auto=webp&amp;s=383b4b4e03c1d084b00fbdff575e3b63d61997c8\n\n&amp;#x200B;\n\n&gt;Click on the top-center Log button to inspect the logs, as shown in figure 2.11. The  \n&gt;  \n&gt;logs are quite verbose by default but display the number of downloaded images in  \n&gt;  \n&gt;the log. Finally, we can open the /tmp/images directory and view them. When run-  \n&gt;  \n&gt;ning in Docker, this directory only exists inside the Docker container and not on your  \n&gt;  \n&gt;host system. You must therefore first get into the Docker container:  \n&gt;  \n&gt;`docker exec -it airflow /bin/bash`  \n&gt;  \n&gt;*Data Pipelines*  \n&gt;  \n&gt;*with Apache Airflow - page 33*  \n&gt;  \n&gt;***BAS HARENSLAK***  \n&gt;  \n&gt;***AND JULIAN DE RUITER***\n\nI don't have any container named airflow when I try running docker exec as per author's instructions.. These are all I have, which one to access?\n\n    CONTAINER ID   IMAGE                            COMMAND                  CREATED       STATUS       PORTS                    NAMES\n    79fb838eeebf   apache/airflow:2.0.0-python3.8   \"/usr/bin/dumb-init \u2026\"   2 hours ago   Up 2 hours   8080/tcp                 chapter02-scheduler-1\n    50a3eca1dbbc   apache/airflow:2.0.0-python3.8   \"/usr/bin/dumb-init \u2026\"   2 hours ago   Up 2 hours   0.0.0.0:8080-&gt;8080/tcp   chapter02-webserver-1\n    aa2eba8546dd   postgres:12-alpine               \"docker-entrypoint.s\u2026\"   2 hours ago   Up 2 hours   0.0.0.0:5432-&gt;5432/tcp   chapter02-postgres-1\n\nI am trying to access images located in `/tmp/images` but can't seem to access the directory.\n\n    import json\n    import pathlib\n    \n    import airflow.utils.dates\n    import requests\n    import requests.exceptions as requests_exceptions\n    from airflow import DAG\n    from airflow.operators.bash import BashOperator\n    from airflow.operators.python import PythonOperator\n    \n    my_dag = DAG(\n        #name of the dag\n        dag_id=\"download_rocket_launches\", \n        description=\"Download rocket pictures of recently launched rockets.\",\n        #datetime at which workflow starts\n        start_date=airflow.utils.dates.days_ago(14), \n        schedule_interval=\"@daily\",\n    )\n    \n    #define operators. in this case, it is the BashOperator (runs bash command)\n    #example operators:PythonOperator (functions); SimpleHTTPOperator (HTTP endpoint); EmailOperator (sending an email)\n    #BaseOperator class inheritance given to other operators\n    download_launches = BashOperator(\n        task_id=\"download_launches\",\n        #note that this is the same command we ran directly in the terminal\n        bash_command=\"curl -o /tmp/launches.json -L 'https://ll.thespacedevs.com/2.0.0/launch/upcoming'\",  # noqa: E501\n        #reference to dag var\n        dag=my_dag, \n    )\n    \n    #pathlib\n    def _get_pictures():\n        # Ensure directory exists\n        pathlib.Path(\"/tmp/images\").mkdir(parents=True, exist_ok=True)\n    \n        # Download all pictures in launches.json\n        with open(\"/tmp/launches.json\") as f: #open from pervious task_note bash_command\n            launches = json.load(f)\n            image_urls = [launch[\"image\"] for launch in launches[\"results\"]]\n            for image_url in image_urls:\n                try:\n                    response = requests.get(image_url)\n                    image_filename = image_url.split(\"/\")[-1]\n                    target_file = f\"/tmp/images/{image_filename}\"\n                    with open(target_file, \"wb\") as f:\n                        f.write(response.content) #store each image\n                    print(f\"Downloaded {image_url} to {target_file}\") #captured in airflow log\n                except requests_exceptions.MissingSchema:\n                    print(f\"{image_url} appears to be an invalid URL.\")\n                except requests_exceptions.ConnectionError:\n                    print(f\"Could not connect to {image_url}.\")\n    \n    \n    get_pictures = PythonOperator( #instantiate pythonoperator to call py function. \n        task_id=\"get_pictures\", python_callable=_get_pictures, dag=my_dag #get_pictures can be anything\n    )\n    \n    notify = BashOperator(\n        task_id=\"notify\",\n        bash_command='echo \"There are now $(ls /tmp/images/ | wc -l) images.\"',\n        dag=my_dag,\n    )\n    \n    #setting dependencies between the tasks. note rshift binary operator is overriden in airflow\n    download_launches &gt;&gt; get_pictures &gt;&gt; notify\n\n&amp;#x200B;", "author_fullname": "t2_l9q43nb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow with docker - how to access images after DAG completion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 50, "top_awarded_type": null, "hide_score": false, "media_metadata": {"86tibhpm33pb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/86tibhpm33pb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=90f5cc069c359fff186fb344b78ac112b900b4b5"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/86tibhpm33pb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=338fff337ca2c3678f1f5211fe5d74fb5dca2a34"}, {"y": 116, "x": 320, "u": "https://preview.redd.it/86tibhpm33pb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a156fdc1029239bae1b8db8d24bd6f613f573508"}], "s": {"y": 187, "x": 514, "u": "https://preview.redd.it/86tibhpm33pb1.png?width=514&amp;format=png&amp;auto=webp&amp;s=383b4b4e03c1d084b00fbdff575e3b63d61997c8"}, "id": "86tibhpm33pb1"}}, "name": "t3_16m8d8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CSquZHDcIVq5YAYi6kopbhb3m_WxcdICfMbI79--4Zw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695073503.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a newbie to airflow and tyring to inspect images at certain location at the end of DAG i.e. notify task.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/86tibhpm33pb1.png?width=514&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=383b4b4e03c1d084b00fbdff575e3b63d61997c8\"&gt;https://preview.redd.it/86tibhpm33pb1.png?width=514&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=383b4b4e03c1d084b00fbdff575e3b63d61997c8&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Click on the top-center Log button to inspect the logs, as shown in figure 2.11. The  &lt;/p&gt;\n\n&lt;p&gt;logs are quite verbose by default but display the number of downloaded images in  &lt;/p&gt;\n\n&lt;p&gt;the log. Finally, we can open the /tmp/images directory and view them. When run-  &lt;/p&gt;\n\n&lt;p&gt;ning in Docker, this directory only exists inside the Docker container and not on your  &lt;/p&gt;\n\n&lt;p&gt;host system. You must therefore first get into the Docker container:  &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;docker exec -it airflow /bin/bash&lt;/code&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Data Pipelines&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;with Apache Airflow - page 33&lt;/em&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;BAS HARENSLAK&lt;/em&gt;&lt;/strong&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;AND JULIAN DE RUITER&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I don&amp;#39;t have any container named airflow when I try running docker exec as per author&amp;#39;s instructions.. These are all I have, which one to access?&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CONTAINER ID   IMAGE                            COMMAND                  CREATED       STATUS       PORTS                    NAMES\n79fb838eeebf   apache/airflow:2.0.0-python3.8   &amp;quot;/usr/bin/dumb-init \u2026&amp;quot;   2 hours ago   Up 2 hours   8080/tcp                 chapter02-scheduler-1\n50a3eca1dbbc   apache/airflow:2.0.0-python3.8   &amp;quot;/usr/bin/dumb-init \u2026&amp;quot;   2 hours ago   Up 2 hours   0.0.0.0:8080-&amp;gt;8080/tcp   chapter02-webserver-1\naa2eba8546dd   postgres:12-alpine               &amp;quot;docker-entrypoint.s\u2026&amp;quot;   2 hours ago   Up 2 hours   0.0.0.0:5432-&amp;gt;5432/tcp   chapter02-postgres-1\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I am trying to access images located in &lt;code&gt;/tmp/images&lt;/code&gt; but can&amp;#39;t seem to access the directory.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import json\nimport pathlib\n\nimport airflow.utils.dates\nimport requests\nimport requests.exceptions as requests_exceptions\nfrom airflow import DAG\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.python import PythonOperator\n\nmy_dag = DAG(\n    #name of the dag\n    dag_id=&amp;quot;download_rocket_launches&amp;quot;, \n    description=&amp;quot;Download rocket pictures of recently launched rockets.&amp;quot;,\n    #datetime at which workflow starts\n    start_date=airflow.utils.dates.days_ago(14), \n    schedule_interval=&amp;quot;@daily&amp;quot;,\n)\n\n#define operators. in this case, it is the BashOperator (runs bash command)\n#example operators:PythonOperator (functions); SimpleHTTPOperator (HTTP endpoint); EmailOperator (sending an email)\n#BaseOperator class inheritance given to other operators\ndownload_launches = BashOperator(\n    task_id=&amp;quot;download_launches&amp;quot;,\n    #note that this is the same command we ran directly in the terminal\n    bash_command=&amp;quot;curl -o /tmp/launches.json -L &amp;#39;https://ll.thespacedevs.com/2.0.0/launch/upcoming&amp;#39;&amp;quot;,  # noqa: E501\n    #reference to dag var\n    dag=my_dag, \n)\n\n#pathlib\ndef _get_pictures():\n    # Ensure directory exists\n    pathlib.Path(&amp;quot;/tmp/images&amp;quot;).mkdir(parents=True, exist_ok=True)\n\n    # Download all pictures in launches.json\n    with open(&amp;quot;/tmp/launches.json&amp;quot;) as f: #open from pervious task_note bash_command\n        launches = json.load(f)\n        image_urls = [launch[&amp;quot;image&amp;quot;] for launch in launches[&amp;quot;results&amp;quot;]]\n        for image_url in image_urls:\n            try:\n                response = requests.get(image_url)\n                image_filename = image_url.split(&amp;quot;/&amp;quot;)[-1]\n                target_file = f&amp;quot;/tmp/images/{image_filename}&amp;quot;\n                with open(target_file, &amp;quot;wb&amp;quot;) as f:\n                    f.write(response.content) #store each image\n                print(f&amp;quot;Downloaded {image_url} to {target_file}&amp;quot;) #captured in airflow log\n            except requests_exceptions.MissingSchema:\n                print(f&amp;quot;{image_url} appears to be an invalid URL.&amp;quot;)\n            except requests_exceptions.ConnectionError:\n                print(f&amp;quot;Could not connect to {image_url}.&amp;quot;)\n\n\nget_pictures = PythonOperator( #instantiate pythonoperator to call py function. \n    task_id=&amp;quot;get_pictures&amp;quot;, python_callable=_get_pictures, dag=my_dag #get_pictures can be anything\n)\n\nnotify = BashOperator(\n    task_id=&amp;quot;notify&amp;quot;,\n    bash_command=&amp;#39;echo &amp;quot;There are now $(ls /tmp/images/ | wc -l) images.&amp;quot;&amp;#39;,\n    dag=my_dag,\n)\n\n#setting dependencies between the tasks. note rshift binary operator is overriden in airflow\ndownload_launches &amp;gt;&amp;gt; get_pictures &amp;gt;&amp;gt; notify\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16m8d8p", "is_robot_indexable": true, "report_reasons": null, "author": "Immigrated2TakeUrJob", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16m8d8p/airflow_with_docker_how_to_access_images_after/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16m8d8p/airflow_with_docker_how_to_access_images_after/", "subreddit_subscribers": 129133, "created_utc": 1695073503.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}