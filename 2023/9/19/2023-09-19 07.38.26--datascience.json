{"kind": "Listing", "data": {"after": "t3_16m33fp", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There's been a lot of complaining about stakeholders expectations on data scientists here lately.\n\nThis is not a good mindset and it's certainly not a good influence on those here new to the field.\n\n&amp;#x200B;\n\n1. (almost) Every employer is in the business of making money. We are paid well because (presumably) what we do makes that goal happen more. It's that simple. But the work a data scientist does is not valuable if it does not end up either making more money enter the company, or making less money leave the company. If you are working on a project and you can not explain how it will result in one or both of those things happening (indirectly counts), you need to take a step back and figure that out.\n2. If sales or leadership is asking you to give them simple explanations, it's not because they need you to explain your degree in three sentences. They are asking you to explain *which actual outcome becomes different when whatever you are building is added*, so that they can *help you sell your work to customers or downstream users,* and for you to indicate *what time and resources you need to make that happen*. Again, if you can not identify the action or decision which ends up different once your solution is in place, and describe how you optimize that outcome, you should be sceptical as to whether it is actually impactful.\n3. When you are asked to outline deliverables, they are *letting you explain to them in what way you prefer to deliver your value added*. That is giving you the power. They are not asking you to do more work in a shorter time. They are asking you what will come out of your work, and what steps you (and they) will need to take to make that outcome happen. *Surely* the work you did two weeks ago (last sprint, if you will) is feeding into work you are doing now or at some point down the line. *The way it does so - is the deliverable of the work you did two weeks ago*. Even if that is a documented (positive or negative) outcome of an experiment. I refuse to believe that people with a master's degree or PhD in an engineering- or scientific field are not able to break their work down into steps if they put their mind to it.\n\n&amp;#x200B;\n\nAnyway thanks for listening to my ~~TED Talk~~ rant.\n\nGood luck out there, it'll be great!", "author_fullname": "t2_6ysyf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You all need to think more like a company when working in a company.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m7re1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 220, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 220, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695072115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s been a lot of complaining about stakeholders expectations on data scientists here lately.&lt;/p&gt;\n\n&lt;p&gt;This is not a good mindset and it&amp;#39;s certainly not a good influence on those here new to the field.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;(almost) Every employer is in the business of making money. We are paid well because (presumably) what we do makes that goal happen more. It&amp;#39;s that simple. But the work a data scientist does is not valuable if it does not end up either making more money enter the company, or making less money leave the company. If you are working on a project and you can not explain how it will result in one or both of those things happening (indirectly counts), you need to take a step back and figure that out.&lt;/li&gt;\n&lt;li&gt;If sales or leadership is asking you to give them simple explanations, it&amp;#39;s not because they need you to explain your degree in three sentences. They are asking you to explain &lt;em&gt;which actual outcome becomes different when whatever you are building is added&lt;/em&gt;, so that they can &lt;em&gt;help you sell your work to customers or downstream users,&lt;/em&gt; and for you to indicate &lt;em&gt;what time and resources you need to make that happen&lt;/em&gt;. Again, if you can not identify the action or decision which ends up different once your solution is in place, and describe how you optimize that outcome, you should be sceptical as to whether it is actually impactful.&lt;/li&gt;\n&lt;li&gt;When you are asked to outline deliverables, they are &lt;em&gt;letting you explain to them in what way you prefer to deliver your value added&lt;/em&gt;. That is giving you the power. They are not asking you to do more work in a shorter time. They are asking you what will come out of your work, and what steps you (and they) will need to take to make that outcome happen. &lt;em&gt;Surely&lt;/em&gt; the work you did two weeks ago (last sprint, if you will) is feeding into work you are doing now or at some point down the line. &lt;em&gt;The way it does so - is the deliverable of the work you did two weeks ago&lt;/em&gt;. Even if that is a documented (positive or negative) outcome of an experiment. I refuse to believe that people with a master&amp;#39;s degree or PhD in an engineering- or scientific field are not able to break their work down into steps if they put their mind to it.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyway thanks for listening to my &lt;del&gt;TED Talk&lt;/del&gt; rant.&lt;/p&gt;\n\n&lt;p&gt;Good luck out there, it&amp;#39;ll be great!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16m7re1", "is_robot_indexable": true, "report_reasons": null, "author": "MelonFace", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16m7re1/you_all_need_to_think_more_like_a_company_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16m7re1/you_all_need_to_think_more_like_a_company_when/", "subreddit_subscribers": 1051667, "created_utc": 1695072115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Recently saw a tweet which got quite some traction talking about how many people haven't used sci-kit learn in months as data scientists.\n\nThis has been replaced with PyTorch, HuggingFace, langchain, supergradients etc.\n\nThis didn't really make sense to me as the tooling mentioned isn't really comparable to sci-kit learn but I'm curious and slightly worried I might be falling behind and not up to date with things so just asking if I'm just behind the curve or what you guys think/ do.", "author_fullname": "t2_14bxtq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do people not use sci-kit learn / other traditional libraries anymore?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lu9ni", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 195, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 195, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695058932.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695040259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently saw a tweet which got quite some traction talking about how many people haven&amp;#39;t used sci-kit learn in months as data scientists.&lt;/p&gt;\n\n&lt;p&gt;This has been replaced with PyTorch, HuggingFace, langchain, supergradients etc.&lt;/p&gt;\n\n&lt;p&gt;This didn&amp;#39;t really make sense to me as the tooling mentioned isn&amp;#39;t really comparable to sci-kit learn but I&amp;#39;m curious and slightly worried I might be falling behind and not up to date with things so just asking if I&amp;#39;m just behind the curve or what you guys think/ do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16lu9ni", "is_robot_indexable": true, "report_reasons": null, "author": "15150776", "discussion_type": null, "num_comments": 88, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16lu9ni/do_people_not_use_scikit_learn_other_traditional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16lu9ni/do_people_not_use_scikit_learn_other_traditional/", "subreddit_subscribers": 1051667, "created_utc": 1695040259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Any preferred programs , databases or frameworks you commonly use?? I prefer to keep myself learning and I wanna try my hand at new things. Anyhting that helps me make models more accurate, I\u2019ll welcome. Please do feel free to share ", "author_fullname": "t2_fqc64ndb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you unravel the mysteries of data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m0x2v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 65, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 65, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695056378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any preferred programs , databases or frameworks you commonly use?? I prefer to keep myself learning and I wanna try my hand at new things. Anyhting that helps me make models more accurate, I\u2019ll welcome. Please do feel free to share &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16m0x2v", "is_robot_indexable": true, "report_reasons": null, "author": "IntenselyKnowing", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16m0x2v/how_do_you_unravel_the_mysteries_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16m0x2v/how_do_you_unravel_the_mysteries_of_data/", "subreddit_subscribers": 1051667, "created_utc": 1695056378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Data science and machine learning inherently involve experimentation. Given the dynamic nature of the work, how can anyone confidently commit to outcomes in advance? After dedicating months of work, there's a chance that no discernible relationship between the feature space and the target variable is found, making it challenging to define a clear 'deliverable.' How do consulting firms manage to secure data science contracts in the face of such uncertainty? ", "author_fullname": "t2_5fbmh3va", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you share my dislike for the word \"deliverables\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m4vxt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695065505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data science and machine learning inherently involve experimentation. Given the dynamic nature of the work, how can anyone confidently commit to outcomes in advance? After dedicating months of work, there&amp;#39;s a chance that no discernible relationship between the feature space and the target variable is found, making it challenging to define a clear &amp;#39;deliverable.&amp;#39; How do consulting firms manage to secure data science contracts in the face of such uncertainty? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16m4vxt", "is_robot_indexable": true, "report_reasons": null, "author": "Excellent_Cost170", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16m4vxt/do_you_share_my_dislike_for_the_word_deliverables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16m4vxt/do_you_share_my_dislike_for_the_word_deliverables/", "subreddit_subscribers": 1051667, "created_utc": 1695065505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks,\n\nI've been looking for a data science or adjacent job since May 2023. Because I have a dual citizenship for both the US and Austria, I could apply in both countries. I've noticed, that the job market is way harsher to get in in the US and that ghosting after follow up emails are common. Now I'm just really happy that I finally have two jobs to choose from. Do you also have similar experiences comparing application processes on different continents?\n\n&amp;#x200B;\n\nhttps://preview.redd.it/niulhk65q0pb1.png?width=3200&amp;format=png&amp;auto=webp&amp;s=94f5ec9075831646993442e2852467788e99bf0b", "author_fullname": "t2_66gywg12", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finally got job offer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 52, "top_awarded_type": null, "hide_score": false, "media_metadata": {"niulhk65q0pb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 40, "x": 108, "u": "https://preview.redd.it/niulhk65q0pb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=63d947a8fd8eff2bd0868f51d54f03b17492068b"}, {"y": 81, "x": 216, "u": "https://preview.redd.it/niulhk65q0pb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac2dab363e8ddf7d3022a95ae72b538407af2bc7"}, {"y": 120, "x": 320, "u": "https://preview.redd.it/niulhk65q0pb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf8287d9891c577eb50acf22529e2e10d1d2ca52"}, {"y": 240, "x": 640, "u": "https://preview.redd.it/niulhk65q0pb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=eacc69ffb028f649057013e49a35341e060670c0"}, {"y": 360, "x": 960, "u": "https://preview.redd.it/niulhk65q0pb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=02404eb520b2ff321d4189918f53f6ed0ff4b275"}, {"y": 405, "x": 1080, "u": "https://preview.redd.it/niulhk65q0pb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=28ef1dc8ea7aac5ee98b202e59e017bbac006c29"}], "s": {"y": 1200, "x": 3200, "u": "https://preview.redd.it/niulhk65q0pb1.png?width=3200&amp;format=png&amp;auto=webp&amp;s=94f5ec9075831646993442e2852467788e99bf0b"}, "id": "niulhk65q0pb1"}}, "name": "t3_16lvzzt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LrTQSECqY8c_h4QnA9-Cy-9UOGmbJJxuwhAtVG9zKPQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695044712.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking for a data science or adjacent job since May 2023. Because I have a dual citizenship for both the US and Austria, I could apply in both countries. I&amp;#39;ve noticed, that the job market is way harsher to get in in the US and that ghosting after follow up emails are common. Now I&amp;#39;m just really happy that I finally have two jobs to choose from. Do you also have similar experiences comparing application processes on different continents?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/niulhk65q0pb1.png?width=3200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=94f5ec9075831646993442e2852467788e99bf0b\"&gt;https://preview.redd.it/niulhk65q0pb1.png?width=3200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=94f5ec9075831646993442e2852467788e99bf0b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16lvzzt", "is_robot_indexable": true, "report_reasons": null, "author": "layzrblayzr", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16lvzzt/finally_got_job_offer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16lvzzt/finally_got_job_offer/", "subreddit_subscribers": 1051667, "created_utc": 1695044712.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Use best practices and real-world examples to demonstrate the powerful text parser library\n\nThis article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/introducing-pythons-parse-the-ultimate-alternative-to-regular-expressions/)\n\n[ The parse library is very simple to use. Photo by Amanda Jones on Unsplash ](https://preview.redd.it/504sy5vdyzob1.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;s=d747d05be9cd97e3269887c675e53337ce5a3102)\n\nThis article introduces a Python library called [parse](https://pypi.org/project/parse/?ref=dataleadsfuture.com) for quickly and conveniently parsing and extracting data from text, serving as a great alternative to [Python regular expressions](https://docs.python.org/3/library/re.html?ref=dataleadsfuture.com).\n\nAnd which covers the best practices with the [parse](https://pypi.org/project/parse/?ref=dataleadsfuture.com) library and a real-world example of parsing [nginx log text](http://nginx.org/en/docs/http/ngx_http_log_module.html?ref=dataleadsfuture.com#log_format).\n\n## Introduction\n\nI have a colleague named Wang. One day, he came to me with a worried expression, saying he encountered a complex problem: his boss wanted him to analyze the server logs from the past month and provide statistics on visitor traffic.\n\nI told him it was simple. Just use regular expressions. For example, to analyze nginx logs, use the following regular expression, and it\u2019s elementary.\n\n    content: \n    192.168.0.2 - - [04/Jan/2019:16:06:38 +0800] \"GET http://example.aliyundoc.com/_astats?application=&amp;inf.name=eth0 HTTP/1.1\" 200 273932 \n    \n    regular expression: \n    (?&lt;ip&gt;\\d+\\.\\d+\\.\\d+\\.\\d+)( - - \\[)(?&lt;datetime&gt;[\\s\\S]+)(?&lt;t1&gt;\\][\\s\"]+)(?&lt;request&gt;[A-Z]+) (?&lt;url&gt;[\\S]*) (?&lt;protocol&gt;[\\S]+)[\"] (?&lt;code&gt;\\d+) (?&lt;sendbytes&gt;\\d+)\n\nBut Wang was still worried, saying that learning regular expressions is too tricky. Although there are many ready-made examples online to learn from, he needs help with parsing uncommon text formats.\n\nMoreover, even if he could solve the problem this time, what if his boss asked for changes in the parsing rules when he submitted the analysis? Wouldn\u2019t he need to fumble around for a long time again?\n\nIs there a simpler and more convenient method?\n\nI thought about it and said, of course, there is. Let\u2019s introduce our protagonist today: the Python parse library.\n\n## Installation &amp; Setup\n\nAs described on [the parse GitHub page](https://github.com/r1chardj0n3s/parse?ref=dataleadsfuture.com), it uses [Python\u2019s format() syntax](https://docs.python.org/3/library/string.html?ref=dataleadsfuture.com#format-string-syntax) to parse text, essentially serving as a reverse operation of [Python f-strings](https://docs.python.org/3/reference/lexical_analysis.html?ref=dataleadsfuture.com#f-strings).\n\nBefore starting to use parse, let\u2019s see how to install the library.\n\nDirect installation with pip:\n\n    python -m pip install parse\n\nInstallation with conda can be more troublesome, as parse is not in the default conda channel and needs to be installed through conda-forge:\n\n    conda install -c conda-forge parse\n\nAfter installation, you can use from parse import \\* in your code to use the library\u2019s methods directly.\n\n## Features &amp; Usage\n\nThe parse API is similar to [Python Regular Expressions](https://docs.python.org/3/library/re.html?ref=dataleadsfuture.com#functions), mainly consisting of the parse, search, and findall methods. Basic usage can be learned from [the parse documentation](https://pypi.org/project/parse/?ref=dataleadsfuture.com).\n\n## Pattern format\n\nThe parse format is very similar to the Python format syntax. You can capture matched text using {}or {field\\_name}.\n\nFor example, in the following text, if I want to get the profile URL and username, I can write it like this:\n\n    content: \n    Hello everyone, my Medium profile url is https://qtalen.medium.com, and my username is @qtalen.  \n    \n    parse pattern: \n    Hello everyone, my Medium profile url is {profile}, and my username is {username}.\n\nOr you want to extract multiple phone numbers. Still, the phone numbers have different formats of country codes in front, and the phone numbers are of a fixed length of 11 digits. You can write it like this:\n\n    compiler = Parser(\"{country_code}{phone:11.11},\") \n    content = \"0085212345678901, +85212345678902, (852)12345678903,\"  \n    \n    results = compiler.findall(content) \n    \n    for result in results:     \n        print(result)\n\nOr if you need to process a piece of text in an HTML tag, but the text is preceded and followed by an indefinite length of whitespace, you can write it like this:\n\n    content: \n    &lt;div&gt;           Hello World               &lt;/div&gt;  \n    \n    pattern: \n    &lt;div&gt;{:^}&lt;/div&gt;\n\nIn the code above, {:11} refers to the width, which means to capture at least 11 characters, equivalent to the regular expression (.{11,})?. {:.11}refers to the precision, which means to capture at most 11 characters, equivalent to the regular expression (.{,11})?. So when combined, it means (.{11, 11})?. The result is:\n\n&amp;#x200B;\n\n[ Capture fixed-width characters. Image by Author ](https://preview.redd.it/8gz6ibp2zzob1.png?width=542&amp;format=png&amp;auto=webp&amp;s=c85c447fa2315ed915b5d6401c1445ba8d096ed2)\n\nThe most powerful feature of parse is its handling of time text, which can be directly parsed into Python datetime objects. For example, if we want to parse the time in an HTTP log:\n\n    content:\n    [04/Jan/2019:16:06:38 +0800]\n    \n    pattern:\n    [{:th}]\n\n## Retrieving results\n\nThere are two ways to retrieve the results:\n\n1. For capturing methods that use {} without a field name, you can directly use result.fixedto get the result as a tuple.\n2. For capturing methods that use {field\\_name}, you can use result.named to get the result as a dictionary.\n\n## Custom Type Conversions\n\nAlthough using {field\\_name} is already quite simple, the source code reveals that {field\\_name} is internally converted to (?P&lt;field\\_name&gt;.+?). So, parse still uses regular expressions for matching. .+? represents one or more random characters in non-greedy mode.\n\n&amp;#x200B;\n\n[ The transformation process of parse format to regular expressions. Image by Author ](https://preview.redd.it/50g4mp4fzzob1.png?width=720&amp;format=png&amp;auto=webp&amp;s=bdd7b41bcbd516db509874000807ebbae09145d5)\n\nHowever, often we hope to match more precisely. For example, the text \u201cmy email is [xxx@xxx.com](mailto:xxx@xxx.com)\u201d, \u201cmy email is {email}\u201dcan capture the email. Sometimes we may get dirty data, for example, \u201cmy email is xxxx@xxxx\u201d, and we don\u2019t want to grab it.\n\nIs there a way to use regular expressions for more accurate matching?\n\nThat\u2019s when the with\\_pattern decorator comes in handy.\n\nFor example, for capturing email addresses, we can write it like this:\n\n    @with_pattern(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n    def email(text: str) -&gt; str:\n        return text\n    \n    \n    compiler = Parser(\"my email address is {email:Email}\", dict(Email=email))\n    \n    legal_result = compiler.parse(\"my email address is xx@xxx.com\")  # legal email\n    illegal_result = compiler.parse(\"my email address is xx@xx\") \n\nUsing the with\\_pattern decorator, we can define a custom field type, in this case, Email which will match the email address in the text. We can also use this approach to match other complicated patterns.\n\n## A Real-world Example: Parsing Nginx Log\n\nAfter understanding the basic usage of parse, let\u2019s return to the troubles of Wang mentioned at the beginning of the article. Let\u2019s see how to parse logs if we have server log files for the past month.\n\n**Note:** We chose [NASA\u2019s HTTP log dataset](https://ita.ee.lbl.gov/html/contrib/NASA-HTTP.html?ref=dataleadsfuture.com) for this experiment, which is free to use.\n\nThe text fragment to be parsed looks like this\uff1a\n\n[ What is the text fragment look like. Screenshot by Author ](https://preview.redd.it/e660m7vrzzob1.png?width=720&amp;format=png&amp;auto=webp&amp;s=36d88e544acddb31e5b4fdd84dc622071236f765)\n\nFirst, we need to preprocess the parse expression. This way, when parsing large files, we don\u2019t have to compile the regular expression for each line of text, thus improving performance.\n\n    from parse import Parser, with_pattern\n    import pandas as pd\n    \n    # https://ita.ee.lbl.gov/html/contrib/NASA-HTTP.html\n    FILE_NAME = \"../../data/access_log_Jul95_min\"\n    compiler = Parser('{source} - - [{timestamp:th}] \"{method} {path} {version}\" {status_code} {length}\\n')\n\nNext, the parse\\_line method is the core of this example. It uses the preprocessed expression to parse the text, returning the corresponding match if there is one and an empty dictionary if not.\n\n    def process_line(text: str) -&gt; dict:\n        parse_result = compiler.parse(text)\n        return parse_result.named if parse_result else {}\n\nThen, we use the read\\_file method to process the text line by line using a generator, which can minimize memory usage. However, due to the disk\u2019s 4k capability limitations, this method may not guarantee performance.\n\n    def read_file(name: str) -&gt; list[dict]:\n        result = []\n        with open(name, 'r') as f:\n            for line in f:\n                obj: dict = process_line(line)\n                result.append(obj)\n    \n        return result\n\nSince we need to perform statistics on the log files, we must use the from\\_records method to construct a DataFrame from the matched results.\n\n    def build_dataframe(records: list[dict]) -&gt; pd.DataFrame:\n        result: pd.DataFrame = pd.DataFrame.from_records(records, index='timestamp')\n        return result\n\nFinally, in the main method, we put all the methods together and try to count the different status\\_code occurrences:\n\n    def main():\n        records: list[dict] = read_file(FILE_NAME)\n        dataframe = build_dataframe(records)\n        print(dataframe.groupby('status_code').count())\n\n[ Wang\u2019s troubles have been easily solved. Image by Author ](https://preview.redd.it/zinr2q0700pb1.png?width=528&amp;format=png&amp;auto=webp&amp;s=210be348eecd4fdf890e046c4febfb0020a6d05d)\n\nThat\u2019s it. Wang\u2019s troubles have been easily solved.\n\n## Best Practices with parse Library\n\nAlthough the parse library is so simple that I only have a little to write about in the article. There are still some best practices to follow, just like regular expressions.\n\n## Readability and maintainability\n\nTo efficiently capture text and maintain expressions, it is recommended to always use {field\\_name}instead of {}. This way, you can directly use result.named to obtain key-value results.\n\nUsing Parser(pattern) to preprocess the expression is recommended, rather than parse(pattern, text).\n\nOn the one hand, this can improve performance. On the other hand, when using Custom Type Conversions, you can keep the pattern and extra\\_type together, making it easier to maintain.\n\n## Optimizing performance for large datasets\n\nIf you look at the source code, you can see that {} and {field\\_name} use the regular expressions (.+?) and (?P&lt;field\\_name&gt;.+?) for capture, respectively. Both expressions use the [non-greedy mode](https://docs.python.org/3/library/re.html?ref=dataleadsfuture.com#regular-expression-syntax). So when you use with\\_pattern to write your own expressions, also try to use non-greedy mode.\n\nAt the same time, when writing with\\_pattern, if you use () for capture grouping, please use regex\\_group\\_count to specify the specific groups like this: [@with\\_pattern](http://twitter.com/with_pattern?ref=dataleadsfuture.com)(r\u2019((\\\\d+))\u2019, regex\\_group\\_count=2) .\n\nFinally, if a group is not needed in with\\_pattern, use (?:x) instead. u/with_pattern(r\u2019(?:&lt;input.*?&gt;)(.*?)(?:&lt;/input&gt;)\u2019, regex\\_group\\_count=1) means you want to capture the content between input tags. The input tags will not be captured.\n\n## Conclusion\n\nIn this article, I changed my usual way of writing lengthy papers. By solving a colleague\u2019s problem, I briefly introduced the use of the parse library. I hope you like this style.\n\nThis article does not cover the detailed usage methods on the official website. Still, it introduces some best practices and performance optimization solutions based on my experience.\n\nAt the same time, I explained in detail the use of the parse library to parse nginx logs with a practical example.\n\nAs the new series title suggests, besides improving code execution speed and performance, using various tools to improve work efficiency is also a performance enhancement.\n\nThis article helps data scientists simplify text parsing and spend time on more critical tasks. If you have any thoughts on this article, feel free to leave a comment and discuss.\n\n&amp;#x200B;\n\nThis article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/introducing-pythons-parse-the-ultimate-alternative-to-regular-expressions/)\n\n&amp;#x200B;", "author_fullname": "t2_9r8ft2a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing Python\u2019s Parse: The Ultimate Alternative to Regular Expressions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"50g4mp4fzzob1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 33, "x": 108, "u": "https://preview.redd.it/50g4mp4fzzob1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c300c11223bc6153314e960d166168c2aca84656"}, {"y": 66, "x": 216, "u": "https://preview.redd.it/50g4mp4fzzob1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8010db97662d5212e625ef9a5eb22538f70e16e0"}, {"y": 99, "x": 320, "u": "https://preview.redd.it/50g4mp4fzzob1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d8201f55d972b5983e430797c491f3aef232bc5"}, {"y": 198, "x": 640, "u": "https://preview.redd.it/50g4mp4fzzob1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a1079611cc8bbd0f31a310269c77ce83fb7f4de1"}], "s": {"y": 223, "x": 720, "u": "https://preview.redd.it/50g4mp4fzzob1.png?width=720&amp;format=png&amp;auto=webp&amp;s=bdd7b41bcbd516db509874000807ebbae09145d5"}, "id": "50g4mp4fzzob1"}, "zinr2q0700pb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 44, "x": 108, "u": "https://preview.redd.it/zinr2q0700pb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=33e727f6c19ffeeb7d73491a8afcb6e03f898d8e"}, {"y": 89, "x": 216, "u": "https://preview.redd.it/zinr2q0700pb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe87ff22d31b89e90c799520b60235afe6ca9fc5"}, {"y": 132, "x": 320, "u": "https://preview.redd.it/zinr2q0700pb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c61b2bde65ac88bba5a535981f702da0e1da9a97"}], "s": {"y": 219, "x": 528, "u": "https://preview.redd.it/zinr2q0700pb1.png?width=528&amp;format=png&amp;auto=webp&amp;s=210be348eecd4fdf890e046c4febfb0020a6d05d"}, "id": "zinr2q0700pb1"}, "e660m7vrzzob1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 23, "x": 108, "u": "https://preview.redd.it/e660m7vrzzob1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a20c6a939ebfdcb048f2e484fbafae1f615a5820"}, {"y": 47, "x": 216, "u": "https://preview.redd.it/e660m7vrzzob1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ed607319d3171dc249c43a7751b1a98a9d571655"}, {"y": 70, "x": 320, "u": "https://preview.redd.it/e660m7vrzzob1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5ccdfadccefd67ebf03b24423e60a6a7262ea1e4"}, {"y": 140, "x": 640, "u": "https://preview.redd.it/e660m7vrzzob1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=74b846f168fca161de277b6703c3ce6804efcfd1"}], "s": {"y": 158, "x": 720, "u": "https://preview.redd.it/e660m7vrzzob1.png?width=720&amp;format=png&amp;auto=webp&amp;s=36d88e544acddb31e5b4fdd84dc622071236f765"}, "id": "e660m7vrzzob1"}, "8gz6ibp2zzob1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 25, "x": 108, "u": "https://preview.redd.it/8gz6ibp2zzob1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c632ed06306035f19080cd7024c20657d946c1c6"}, {"y": 51, "x": 216, "u": "https://preview.redd.it/8gz6ibp2zzob1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=dd3fb859bdf67fbdc927d7d186fe5cf05be77cdf"}, {"y": 76, "x": 320, "u": "https://preview.redd.it/8gz6ibp2zzob1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1bf8ea51f312c81a397b24673d2d151505c37d6"}], "s": {"y": 130, "x": 542, "u": "https://preview.redd.it/8gz6ibp2zzob1.png?width=542&amp;format=png&amp;auto=webp&amp;s=c85c447fa2315ed915b5d6401c1445ba8d096ed2"}, "id": "8gz6ibp2zzob1"}, "504sy5vdyzob1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 72, "x": 108, "u": "https://preview.redd.it/504sy5vdyzob1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3525ea61d90ef4be54081fd1c12b665d07026605"}, {"y": 144, "x": 216, "u": "https://preview.redd.it/504sy5vdyzob1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ecf26549b1cd0a6c61d84df3c4f314033b5a19be"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/504sy5vdyzob1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fbaec945c68b581e8822c56a063d92e5dc7fde79"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/504sy5vdyzob1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c7a79c1efb10ab17db9ac86539c51b09de5b7dd9"}], "s": {"y": 480, "x": 720, "u": "https://preview.redd.it/504sy5vdyzob1.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;s=d747d05be9cd97e3269887c675e53337ce5a3102"}, "id": "504sy5vdyzob1"}}, "name": "t3_16lsuln", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/u_ZBv9Ub9_ZlIxTiEpDpCkPJTy1xphFgQGFJBLBzNqw.jpg", "edited": 1695085264.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1695036240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Use best practices and real-world examples to demonstrate the powerful text parser library&lt;/p&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/introducing-pythons-parse-the-ultimate-alternative-to-regular-expressions/\"&gt;Data Leads Future.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/504sy5vdyzob1.jpg?width=720&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d747d05be9cd97e3269887c675e53337ce5a3102\"&gt; The parse library is very simple to use. Photo by Amanda Jones on Unsplash &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This article introduces a Python library called &lt;a href=\"https://pypi.org/project/parse/?ref=dataleadsfuture.com\"&gt;parse&lt;/a&gt; for quickly and conveniently parsing and extracting data from text, serving as a great alternative to &lt;a href=\"https://docs.python.org/3/library/re.html?ref=dataleadsfuture.com\"&gt;Python regular expressions&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;And which covers the best practices with the &lt;a href=\"https://pypi.org/project/parse/?ref=dataleadsfuture.com\"&gt;parse&lt;/a&gt; library and a real-world example of parsing &lt;a href=\"http://nginx.org/en/docs/http/ngx_http_log_module.html?ref=dataleadsfuture.com#log_format\"&gt;nginx log text&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h2&gt;Introduction&lt;/h2&gt;\n\n&lt;p&gt;I have a colleague named Wang. One day, he came to me with a worried expression, saying he encountered a complex problem: his boss wanted him to analyze the server logs from the past month and provide statistics on visitor traffic.&lt;/p&gt;\n\n&lt;p&gt;I told him it was simple. Just use regular expressions. For example, to analyze nginx logs, use the following regular expression, and it\u2019s elementary.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;content: \n192.168.0.2 - - [04/Jan/2019:16:06:38 +0800] &amp;quot;GET http://example.aliyundoc.com/_astats?application=&amp;amp;inf.name=eth0 HTTP/1.1&amp;quot; 200 273932 \n\nregular expression: \n(?&amp;lt;ip&amp;gt;\\d+\\.\\d+\\.\\d+\\.\\d+)( - - \\[)(?&amp;lt;datetime&amp;gt;[\\s\\S]+)(?&amp;lt;t1&amp;gt;\\][\\s&amp;quot;]+)(?&amp;lt;request&amp;gt;[A-Z]+) (?&amp;lt;url&amp;gt;[\\S]*) (?&amp;lt;protocol&amp;gt;[\\S]+)[&amp;quot;] (?&amp;lt;code&amp;gt;\\d+) (?&amp;lt;sendbytes&amp;gt;\\d+)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;But Wang was still worried, saying that learning regular expressions is too tricky. Although there are many ready-made examples online to learn from, he needs help with parsing uncommon text formats.&lt;/p&gt;\n\n&lt;p&gt;Moreover, even if he could solve the problem this time, what if his boss asked for changes in the parsing rules when he submitted the analysis? Wouldn\u2019t he need to fumble around for a long time again?&lt;/p&gt;\n\n&lt;p&gt;Is there a simpler and more convenient method?&lt;/p&gt;\n\n&lt;p&gt;I thought about it and said, of course, there is. Let\u2019s introduce our protagonist today: the Python parse library.&lt;/p&gt;\n\n&lt;h2&gt;Installation &amp;amp; Setup&lt;/h2&gt;\n\n&lt;p&gt;As described on &lt;a href=\"https://github.com/r1chardj0n3s/parse?ref=dataleadsfuture.com\"&gt;the parse GitHub page&lt;/a&gt;, it uses &lt;a href=\"https://docs.python.org/3/library/string.html?ref=dataleadsfuture.com#format-string-syntax\"&gt;Python\u2019s format() syntax&lt;/a&gt; to parse text, essentially serving as a reverse operation of &lt;a href=\"https://docs.python.org/3/reference/lexical_analysis.html?ref=dataleadsfuture.com#f-strings\"&gt;Python f-strings&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Before starting to use parse, let\u2019s see how to install the library.&lt;/p&gt;\n\n&lt;p&gt;Direct installation with pip:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;python -m pip install parse\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Installation with conda can be more troublesome, as parse is not in the default conda channel and needs to be installed through conda-forge:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;conda install -c conda-forge parse\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;After installation, you can use from parse import * in your code to use the library\u2019s methods directly.&lt;/p&gt;\n\n&lt;h2&gt;Features &amp;amp; Usage&lt;/h2&gt;\n\n&lt;p&gt;The parse API is similar to &lt;a href=\"https://docs.python.org/3/library/re.html?ref=dataleadsfuture.com#functions\"&gt;Python Regular Expressions&lt;/a&gt;, mainly consisting of the parse, search, and findall methods. Basic usage can be learned from &lt;a href=\"https://pypi.org/project/parse/?ref=dataleadsfuture.com\"&gt;the parse documentation&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h2&gt;Pattern format&lt;/h2&gt;\n\n&lt;p&gt;The parse format is very similar to the Python format syntax. You can capture matched text using {}or {field_name}.&lt;/p&gt;\n\n&lt;p&gt;For example, in the following text, if I want to get the profile URL and username, I can write it like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;content: \nHello everyone, my Medium profile url is https://qtalen.medium.com, and my username is @qtalen.  \n\nparse pattern: \nHello everyone, my Medium profile url is {profile}, and my username is {username}.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Or you want to extract multiple phone numbers. Still, the phone numbers have different formats of country codes in front, and the phone numbers are of a fixed length of 11 digits. You can write it like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;compiler = Parser(&amp;quot;{country_code}{phone:11.11},&amp;quot;) \ncontent = &amp;quot;0085212345678901, +85212345678902, (852)12345678903,&amp;quot;  \n\nresults = compiler.findall(content) \n\nfor result in results:     \n    print(result)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Or if you need to process a piece of text in an HTML tag, but the text is preceded and followed by an indefinite length of whitespace, you can write it like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;content: \n&amp;lt;div&amp;gt;           Hello World               &amp;lt;/div&amp;gt;  \n\npattern: \n&amp;lt;div&amp;gt;{:^}&amp;lt;/div&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;In the code above, {:11} refers to the width, which means to capture at least 11 characters, equivalent to the regular expression (.{11,})?. {:.11}refers to the precision, which means to capture at most 11 characters, equivalent to the regular expression (.{,11})?. So when combined, it means (.{11, 11})?. The result is:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/8gz6ibp2zzob1.png?width=542&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c85c447fa2315ed915b5d6401c1445ba8d096ed2\"&gt; Capture fixed-width characters. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The most powerful feature of parse is its handling of time text, which can be directly parsed into Python datetime objects. For example, if we want to parse the time in an HTTP log:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;content:\n[04/Jan/2019:16:06:38 +0800]\n\npattern:\n[{:th}]\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h2&gt;Retrieving results&lt;/h2&gt;\n\n&lt;p&gt;There are two ways to retrieve the results:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;For capturing methods that use {} without a field name, you can directly use result.fixedto get the result as a tuple.&lt;/li&gt;\n&lt;li&gt;For capturing methods that use {field_name}, you can use result.named to get the result as a dictionary.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h2&gt;Custom Type Conversions&lt;/h2&gt;\n\n&lt;p&gt;Although using {field_name} is already quite simple, the source code reveals that {field_name} is internally converted to (?P&amp;lt;field\\_name&amp;gt;.+?). So, parse still uses regular expressions for matching. .+? represents one or more random characters in non-greedy mode.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/50g4mp4fzzob1.png?width=720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bdd7b41bcbd516db509874000807ebbae09145d5\"&gt; The transformation process of parse format to regular expressions. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;However, often we hope to match more precisely. For example, the text \u201cmy email is [&lt;a href=\"mailto:xxx@xxx.com\"&gt;xxx@xxx.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:xxx@xxx.com\"&gt;xxx@xxx.com&lt;/a&gt;)\u201d, \u201cmy email is {email}\u201dcan capture the email. Sometimes we may get dirty data, for example, \u201cmy email is xxxx@xxxx\u201d, and we don\u2019t want to grab it.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to use regular expressions for more accurate matching?&lt;/p&gt;\n\n&lt;p&gt;That\u2019s when the with_pattern decorator comes in handy.&lt;/p&gt;\n\n&lt;p&gt;For example, for capturing email addresses, we can write it like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;@with_pattern(r&amp;#39;\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b&amp;#39;)\ndef email(text: str) -&amp;gt; str:\n    return text\n\n\ncompiler = Parser(&amp;quot;my email address is {email:Email}&amp;quot;, dict(Email=email))\n\nlegal_result = compiler.parse(&amp;quot;my email address is xx@xxx.com&amp;quot;)  # legal email\nillegal_result = compiler.parse(&amp;quot;my email address is xx@xx&amp;quot;) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Using the with_pattern decorator, we can define a custom field type, in this case, Email which will match the email address in the text. We can also use this approach to match other complicated patterns.&lt;/p&gt;\n\n&lt;h2&gt;A Real-world Example: Parsing Nginx Log&lt;/h2&gt;\n\n&lt;p&gt;After understanding the basic usage of parse, let\u2019s return to the troubles of Wang mentioned at the beginning of the article. Let\u2019s see how to parse logs if we have server log files for the past month.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We chose &lt;a href=\"https://ita.ee.lbl.gov/html/contrib/NASA-HTTP.html?ref=dataleadsfuture.com\"&gt;NASA\u2019s HTTP log dataset&lt;/a&gt; for this experiment, which is free to use.&lt;/p&gt;\n\n&lt;p&gt;The text fragment to be parsed looks like this\uff1a&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/e660m7vrzzob1.png?width=720&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=36d88e544acddb31e5b4fdd84dc622071236f765\"&gt; What is the text fragment look like. Screenshot by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;First, we need to preprocess the parse expression. This way, when parsing large files, we don\u2019t have to compile the regular expression for each line of text, thus improving performance.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from parse import Parser, with_pattern\nimport pandas as pd\n\n# https://ita.ee.lbl.gov/html/contrib/NASA-HTTP.html\nFILE_NAME = &amp;quot;../../data/access_log_Jul95_min&amp;quot;\ncompiler = Parser(&amp;#39;{source} - - [{timestamp:th}] &amp;quot;{method} {path} {version}&amp;quot; {status_code} {length}\\n&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Next, the parse_line method is the core of this example. It uses the preprocessed expression to parse the text, returning the corresponding match if there is one and an empty dictionary if not.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def process_line(text: str) -&amp;gt; dict:\n    parse_result = compiler.parse(text)\n    return parse_result.named if parse_result else {}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then, we use the read_file method to process the text line by line using a generator, which can minimize memory usage. However, due to the disk\u2019s 4k capability limitations, this method may not guarantee performance.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def read_file(name: str) -&amp;gt; list[dict]:\n    result = []\n    with open(name, &amp;#39;r&amp;#39;) as f:\n        for line in f:\n            obj: dict = process_line(line)\n            result.append(obj)\n\n    return result\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Since we need to perform statistics on the log files, we must use the from_records method to construct a DataFrame from the matched results.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def build_dataframe(records: list[dict]) -&amp;gt; pd.DataFrame:\n    result: pd.DataFrame = pd.DataFrame.from_records(records, index=&amp;#39;timestamp&amp;#39;)\n    return result\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Finally, in the main method, we put all the methods together and try to count the different status_code occurrences:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def main():\n    records: list[dict] = read_file(FILE_NAME)\n    dataframe = build_dataframe(records)\n    print(dataframe.groupby(&amp;#39;status_code&amp;#39;).count())\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zinr2q0700pb1.png?width=528&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=210be348eecd4fdf890e046c4febfb0020a6d05d\"&gt; Wang\u2019s troubles have been easily solved. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;That\u2019s it. Wang\u2019s troubles have been easily solved.&lt;/p&gt;\n\n&lt;h2&gt;Best Practices with parse Library&lt;/h2&gt;\n\n&lt;p&gt;Although the parse library is so simple that I only have a little to write about in the article. There are still some best practices to follow, just like regular expressions.&lt;/p&gt;\n\n&lt;h2&gt;Readability and maintainability&lt;/h2&gt;\n\n&lt;p&gt;To efficiently capture text and maintain expressions, it is recommended to always use {field_name}instead of {}. This way, you can directly use result.named to obtain key-value results.&lt;/p&gt;\n\n&lt;p&gt;Using Parser(pattern) to preprocess the expression is recommended, rather than parse(pattern, text).&lt;/p&gt;\n\n&lt;p&gt;On the one hand, this can improve performance. On the other hand, when using Custom Type Conversions, you can keep the pattern and extra_type together, making it easier to maintain.&lt;/p&gt;\n\n&lt;h2&gt;Optimizing performance for large datasets&lt;/h2&gt;\n\n&lt;p&gt;If you look at the source code, you can see that {} and {field_name} use the regular expressions (.+?) and (?P&amp;lt;field\\_name&amp;gt;.+?) for capture, respectively. Both expressions use the &lt;a href=\"https://docs.python.org/3/library/re.html?ref=dataleadsfuture.com#regular-expression-syntax\"&gt;non-greedy mode&lt;/a&gt;. So when you use with_pattern to write your own expressions, also try to use non-greedy mode.&lt;/p&gt;\n\n&lt;p&gt;At the same time, when writing with_pattern, if you use () for capture grouping, please use regex_group_count to specify the specific groups like this: &lt;a href=\"http://twitter.com/with_pattern?ref=dataleadsfuture.com\"&gt;@with_pattern&lt;/a&gt;(r\u2019((\\d+))\u2019, regex_group_count=2) .&lt;/p&gt;\n\n&lt;p&gt;Finally, if a group is not needed in with_pattern, use (?:x) instead. &lt;a href=\"/u/with_pattern\"&gt;u/with_pattern&lt;/a&gt;(r\u2019(?:&amp;lt;input.*?&amp;gt;)(.*?)(?:&amp;lt;/input&amp;gt;)\u2019, regex_group_count=1) means you want to capture the content between input tags. The input tags will not be captured.&lt;/p&gt;\n\n&lt;h2&gt;Conclusion&lt;/h2&gt;\n\n&lt;p&gt;In this article, I changed my usual way of writing lengthy papers. By solving a colleague\u2019s problem, I briefly introduced the use of the parse library. I hope you like this style.&lt;/p&gt;\n\n&lt;p&gt;This article does not cover the detailed usage methods on the official website. Still, it introduces some best practices and performance optimization solutions based on my experience.&lt;/p&gt;\n\n&lt;p&gt;At the same time, I explained in detail the use of the parse library to parse nginx logs with a practical example.&lt;/p&gt;\n\n&lt;p&gt;As the new series title suggests, besides improving code execution speed and performance, using various tools to improve work efficiency is also a performance enhancement.&lt;/p&gt;\n\n&lt;p&gt;This article helps data scientists simplify text parsing and spend time on more critical tasks. If you have any thoughts on this article, feel free to leave a comment and discuss.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/introducing-pythons-parse-the-ultimate-alternative-to-regular-expressions/\"&gt;Data Leads Future.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/b3umHMo1nKzXTvE-I-l1ng49LAsWEO7W6GziCv1GETY.jpg?auto=webp&amp;s=4d74808ecb3fc2e82ac6bfb7a850df11da4d9051", "width": 720, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/b3umHMo1nKzXTvE-I-l1ng49LAsWEO7W6GziCv1GETY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=06cd9d8ed4025ed3c3e5c2562fd7cd927735e675", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/b3umHMo1nKzXTvE-I-l1ng49LAsWEO7W6GziCv1GETY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8ad0d6cce231f115a8bde4e4494eee001c367c92", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/b3umHMo1nKzXTvE-I-l1ng49LAsWEO7W6GziCv1GETY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=771cd398a0e92ac841094fe1729c2d0f914c8a24", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/b3umHMo1nKzXTvE-I-l1ng49LAsWEO7W6GziCv1GETY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=40cbe4d7f2d85d8ccf7839ce126aa9532684593e", "width": 640, "height": 426}], "variants": {}, "id": "-1qT88fL6yk1SxsIt7OERpjxhanq3QeqlYYOGBBuptY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16lsuln", "is_robot_indexable": true, "report_reasons": null, "author": "qtalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16lsuln/introducing_pythons_parse_the_ultimate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16lsuln/introducing_pythons_parse_the_ultimate/", "subreddit_subscribers": 1051667, "created_utc": 1695036240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is a bit of an unstructured thought, but the example I had in mind was Microsoft Teams noise suppression. When i first started working from home, during most calls people would complain about the sound of cars through my microphone when i had my window open. Though as time went on, the complains reduced. This is just an analogy, but it is known that Teams noise suppression has improved massively since its introduction.\n\nAt the heart of it, this is a machine learning project that has clear value, in that it is clearly a good thing for your product to be as effective as possible. Though how do you link this back to \u2018realised\u2019 value? In this case, and the scale of Microsoft, perhaps you could link it to fewer bad reviews, or negative contacts, ir maybe better feedback sfter a demo or trial - but what about a similar situation in a smaller company? Or a place where customer feedback isn\u2019t as common? How do we justify and link projects to realisable value when there isn\u2019t a clear route, but it is otherwise clear its the right direction?\n\nDoes anyone have any advise or resources on this topic?", "author_fullname": "t2_gm8b3iu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you put value on a project/task that you know is inherently good, but isn\u2019t clear how it links to business metrics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lxpvv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695048813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a bit of an unstructured thought, but the example I had in mind was Microsoft Teams noise suppression. When i first started working from home, during most calls people would complain about the sound of cars through my microphone when i had my window open. Though as time went on, the complains reduced. This is just an analogy, but it is known that Teams noise suppression has improved massively since its introduction.&lt;/p&gt;\n\n&lt;p&gt;At the heart of it, this is a machine learning project that has clear value, in that it is clearly a good thing for your product to be as effective as possible. Though how do you link this back to \u2018realised\u2019 value? In this case, and the scale of Microsoft, perhaps you could link it to fewer bad reviews, or negative contacts, ir maybe better feedback sfter a demo or trial - but what about a similar situation in a smaller company? Or a place where customer feedback isn\u2019t as common? How do we justify and link projects to realisable value when there isn\u2019t a clear route, but it is otherwise clear its the right direction?&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any advise or resources on this topic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16lxpvv", "is_robot_indexable": true, "report_reasons": null, "author": "poppycocknbalderdash", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16lxpvv/how_do_you_put_value_on_a_projecttask_that_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16lxpvv/how_do_you_put_value_on_a_projecttask_that_you/", "subreddit_subscribers": 1051667, "created_utc": 1695048813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everybody! I'll get right to the question.\n\nSo I am a university student in the US and I am going into my junior year of my Data Science program. This program is very math and statistics intensive, not as computer science intensive but I have a background in Computer Science (I know C++, have taken computational theory classes, have experience with Python etc.). I am also minoring in math currently because it only requires me to take a couple of classes to complete the minor, and I enjoy my math classes. Although I enjoy all of the math and computer science, I would not like to work in the tech industry in the future as I just have no interest in any of the jobs I have looked at. I have always had a deep interest in history, economics and writing and excel at them as well, I was even a history minor initially but the class load was too much to complete my degree on time. My question is, what kind of path could I take if I wanted to combine my data science skills (Math, computational skills, computer programming background) and social sciences (economic research, policy, even teaching!). I have more of an interest in economics over most other social sciences, I enjoy reading economic research and writing about it as well. Should I change my minor to economics, get my masters or PhD in a social science? I am just wondering how I could combine both of these skill sets into one great learning experience for me. If anybody has any tips on particular jobs to be on the lookout for or any graduate programs that would be adequate as well I would greatly appreciate that. I can also clarify if there are any questions. Thanks again!", "author_fullname": "t2_kztoe75v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I combine Data Science and Social Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m8cer", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695073447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everybody! I&amp;#39;ll get right to the question.&lt;/p&gt;\n\n&lt;p&gt;So I am a university student in the US and I am going into my junior year of my Data Science program. This program is very math and statistics intensive, not as computer science intensive but I have a background in Computer Science (I know C++, have taken computational theory classes, have experience with Python etc.). I am also minoring in math currently because it only requires me to take a couple of classes to complete the minor, and I enjoy my math classes. Although I enjoy all of the math and computer science, I would not like to work in the tech industry in the future as I just have no interest in any of the jobs I have looked at. I have always had a deep interest in history, economics and writing and excel at them as well, I was even a history minor initially but the class load was too much to complete my degree on time. My question is, what kind of path could I take if I wanted to combine my data science skills (Math, computational skills, computer programming background) and social sciences (economic research, policy, even teaching!). I have more of an interest in economics over most other social sciences, I enjoy reading economic research and writing about it as well. Should I change my minor to economics, get my masters or PhD in a social science? I am just wondering how I could combine both of these skill sets into one great learning experience for me. If anybody has any tips on particular jobs to be on the lookout for or any graduate programs that would be adequate as well I would greatly appreciate that. I can also clarify if there are any questions. Thanks again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16m8cer", "is_robot_indexable": true, "report_reasons": null, "author": "No-Pomelo7512", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16m8cer/how_can_i_combine_data_science_and_social_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16m8cer/how_can_i_combine_data_science_and_social_science/", "subreddit_subscribers": 1051667, "created_utc": 1695073447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I came across STUMPY a few days back and have been reading on and playing around with it. I think the matrix profile is an interesting take on shape-based pattern matching and recognition and the possibility of using the generated profiles as input features to other sequence-oriented models seems promising. I deal mostly with anomaly detection and have used STL, ETS, and ARIMA models successfully towards that goal but I've always felt drawn to time series clustering and shapelet analysis. Matrix profiles won't be taking the place of those models but it's a new domain in which I can further analyze a time series.\n\nHas anyone used matrix profiles in their work? In what ways was it successful? What shortcomings did it have for your use and were you able to rectify it (eg, using additional complementary models)?", "author_fullname": "t2_131bi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For those that do time series analysis, have you used STUMPY?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lxo88", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695048702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came across STUMPY a few days back and have been reading on and playing around with it. I think the matrix profile is an interesting take on shape-based pattern matching and recognition and the possibility of using the generated profiles as input features to other sequence-oriented models seems promising. I deal mostly with anomaly detection and have used STL, ETS, and ARIMA models successfully towards that goal but I&amp;#39;ve always felt drawn to time series clustering and shapelet analysis. Matrix profiles won&amp;#39;t be taking the place of those models but it&amp;#39;s a new domain in which I can further analyze a time series.&lt;/p&gt;\n\n&lt;p&gt;Has anyone used matrix profiles in their work? In what ways was it successful? What shortcomings did it have for your use and were you able to rectify it (eg, using additional complementary models)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16lxo88", "is_robot_indexable": true, "report_reasons": null, "author": "WadeEffingWilson", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16lxo88/for_those_that_do_time_series_analysis_have_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16lxo88/for_those_that_do_time_series_analysis_have_you/", "subreddit_subscribers": 1051667, "created_utc": 1695048702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm at a crossroads in my academic journey and could use some guidance. I'm contemplating pursuing a BS Economics with Data Sciences (BSEDS) degree, but I have a few questions and uncertainties.\n\nInterest in Computing: I've always been intrigued by the computing field, and the idea of combining it with economics and data science seems appealing.\n\nCareer Prospects: Can anyone shed light on the career opportunities this degree might open up? Is it a promising path with good job prospects in today's market?\n\nPersonal Experiences: If you've pursued this degree or have experience in related fields, I'd love to hear about your journey. What challenges and rewards did you encounter along the way?\n\nEconomics and Data Science Combo: Is the fusion of economics and data science a strong combination? Are there any unique advantages or challenges associated with this blend of disciplines?\n\nI'd really appreciate any insights, advice, or personal anecdotes you can share. Making this decision is a bit daunting, and your input could be a game-changer for me. Thanks in advance!", "author_fullname": "t2_89s1rm2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Considering a BS Economics with Data Sciences (BSEDS) Degree - Seeking Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lulvp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695041195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m at a crossroads in my academic journey and could use some guidance. I&amp;#39;m contemplating pursuing a BS Economics with Data Sciences (BSEDS) degree, but I have a few questions and uncertainties.&lt;/p&gt;\n\n&lt;p&gt;Interest in Computing: I&amp;#39;ve always been intrigued by the computing field, and the idea of combining it with economics and data science seems appealing.&lt;/p&gt;\n\n&lt;p&gt;Career Prospects: Can anyone shed light on the career opportunities this degree might open up? Is it a promising path with good job prospects in today&amp;#39;s market?&lt;/p&gt;\n\n&lt;p&gt;Personal Experiences: If you&amp;#39;ve pursued this degree or have experience in related fields, I&amp;#39;d love to hear about your journey. What challenges and rewards did you encounter along the way?&lt;/p&gt;\n\n&lt;p&gt;Economics and Data Science Combo: Is the fusion of economics and data science a strong combination? Are there any unique advantages or challenges associated with this blend of disciplines?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d really appreciate any insights, advice, or personal anecdotes you can share. Making this decision is a bit daunting, and your input could be a game-changer for me. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16lulvp", "is_robot_indexable": true, "report_reasons": null, "author": "GuciBanana", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16lulvp/considering_a_bs_economics_with_data_sciences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16lulvp/considering_a_bs_economics_with_data_sciences/", "subreddit_subscribers": 1051667, "created_utc": 1695041195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As the title says. For someone who's looking to I hate to say this, do DS as a hobby? I'm not trying to insult anyone here just looking for advice before committing to school etc.", "author_fullname": "t2_c4bgqzqrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What free education would you recommend", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lt9mp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695037500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says. For someone who&amp;#39;s looking to I hate to say this, do DS as a hobby? I&amp;#39;m not trying to insult anyone here just looking for advice before committing to school etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16lt9mp", "is_robot_indexable": true, "report_reasons": null, "author": "OwlDry6530", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16lt9mp/what_free_education_would_you_recommend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16lt9mp/what_free_education_would_you_recommend/", "subreddit_subscribers": 1051667, "created_utc": 1695037500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys! I(25F) am working as a QA Analyst in a Structural Engineering and Precast Solutions company. I have a Bachelors degree in Architecture. Based on my current role, I am pursuing a PG certification in Data Science and Machine Learning from MIT(US) and I\u2019m planning to get a Masters in Data Science next year from a University in Berlin. What are the odds of me getting successful jobs after my masters? Will my profile be considered for jobs in Germany? I would appreciate your replies! Thanks you! \u263a\ufe0f", "author_fullname": "t2_vi38c485", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Non technical background", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16lsa0m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695034462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys! I(25F) am working as a QA Analyst in a Structural Engineering and Precast Solutions company. I have a Bachelors degree in Architecture. Based on my current role, I am pursuing a PG certification in Data Science and Machine Learning from MIT(US) and I\u2019m planning to get a Masters in Data Science next year from a University in Berlin. What are the odds of me getting successful jobs after my masters? Will my profile be considered for jobs in Germany? I would appreciate your replies! Thanks you! \u263a\ufe0f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16lsa0m", "is_robot_indexable": true, "report_reasons": null, "author": "Ashamed_Chemical_207", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16lsa0m/non_technical_background/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16lsa0m/non_technical_background/", "subreddit_subscribers": 1051667, "created_utc": 1695034462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good day, mates! As the title have already hinted, I am a newly hired Data Scientist that will be starting in about a few days from now. For a bit of context about me, I am a career shifter and has worked previously in the academe. With that said, I don't have any prior experience as a Data Sci/Data Analyst so I was  wondering if you have any tips as to how I can best prepare myself for job. The company that I will be working for is a Telecommunications company. Any help would be very much welcome, thanks in advance!", "author_fullname": "t2_7nq0lnfz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do to Prepare for First Day as Data Scientist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mhupt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695099456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good day, mates! As the title have already hinted, I am a newly hired Data Scientist that will be starting in about a few days from now. For a bit of context about me, I am a career shifter and has worked previously in the academe. With that said, I don&amp;#39;t have any prior experience as a Data Sci/Data Analyst so I was  wondering if you have any tips as to how I can best prepare myself for job. The company that I will be working for is a Telecommunications company. Any help would be very much welcome, thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16mhupt", "is_robot_indexable": true, "report_reasons": null, "author": "ToothEffective", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16mhupt/what_to_do_to_prepare_for_first_day_as_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16mhupt/what_to_do_to_prepare_for_first_day_as_data/", "subreddit_subscribers": 1051667, "created_utc": 1695099456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm doing a time-series forecasting task and observing a weekly seasonality pattern when plotting the data. I decided to use a SARIMA (p, d, q) (P, D, Q, S) model for this with S = 7. I also observed a slight trend shaped like a downward parabola, so I applied a differencing of 1 (d = D = 1). I'm having trouble interpreting my ACF and PACF plots to determine p, q, P, Q. I would really appreciate any insights/ suggestions. \n\n**Here are the ACF and PACF plots of my differenced data:**\n\n&amp;#x200B;\n\nhttps://preview.redd.it/dsu6uotux4pb1.png?width=1184&amp;format=png&amp;auto=webp&amp;s=8eda43067eff4a751a9e7635ae4b8a787419c6aa\n\nhttps://preview.redd.it/gdcu7rtux4pb1.png?width=1168&amp;format=png&amp;auto=webp&amp;s=7a10e7b1c1fee78c9afdd8c5d6b8b291d01388ff\n\n\\- My ACF has significant spikes every 7 lags, but other than that I wasn't sure how to interpret this plot. I suspect this could be a non-seasonal MA(1) process so q = 1 and p = 0\n\n\\- For my PACF, upon looking at the early lags, I saw that there were 5 significant spikes before lag 7. Instead of a non-seasonal MA(1) from above, I then suspect a non-seasonal AR(5), so p = 5 and q = 0.\n\n\\- For the seasonal part, I decided to go with a seasonal AR(5) because there were 5 significant spikes in the PACF occurring at multiples of 7 before it cuts off to 0, so P = 5 and Q = 0\n\n**I split my data into train/test sets and tried the following combinations:** \n\n\\- (0,1,1) (0,1,0,7): model fits well to the shape of the data but gives predictions that always exceed actual values\n\n\\- (5,1,0) (5,1,0,7): model fits well to the shape of the data, has acceptable error metrics\n\n\\- (0, 1, 1) (5, 1, 0, 7): model fits well to the shape of the data, has error metrics slightly worse than (5,1,0) (5,1,0,7).\n\nI don't have a lot of experience interpreting ACF and PACF plots, so I'm not sure if my interpretation is correct. I would really appreciate feedback or explanations on the potential p, q, P, Q orders based on the plots I have.\n\n&amp;#x200B;\n\nThank you in advance", "author_fullname": "t2_8rwu4pz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is my reasoning for SARIMA orders correct based on these ACF and PACF plots? TIA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 116, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dsu6uotux4pb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 89, "x": 108, "u": "https://preview.redd.it/dsu6uotux4pb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bce20f40b413e474d7c980f363dcaacfadbcde70"}, {"y": 179, "x": 216, "u": "https://preview.redd.it/dsu6uotux4pb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=eb8e964f1abea78ca526d2fcd4a14d08f807fe32"}, {"y": 266, "x": 320, "u": "https://preview.redd.it/dsu6uotux4pb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f8cea4810d041d7815df0c2d637f6aa246b00969"}, {"y": 532, "x": 640, "u": "https://preview.redd.it/dsu6uotux4pb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7ed7651f13e89447a68ace3276c3670d76258bf2"}, {"y": 799, "x": 960, "u": "https://preview.redd.it/dsu6uotux4pb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f052901afe4e021d84b71fb109ece4bccf2bd558"}, {"y": 899, "x": 1080, "u": "https://preview.redd.it/dsu6uotux4pb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=64709ffb474a27d281e6b7ddbfe956bd4a3265a6"}], "s": {"y": 986, "x": 1184, "u": "https://preview.redd.it/dsu6uotux4pb1.png?width=1184&amp;format=png&amp;auto=webp&amp;s=8eda43067eff4a751a9e7635ae4b8a787419c6aa"}, "id": "dsu6uotux4pb1"}, "gdcu7rtux4pb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 90, "x": 108, "u": "https://preview.redd.it/gdcu7rtux4pb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=875f32bd4a4e3904c03aac6dc3f6a3755aa209ba"}, {"y": 180, "x": 216, "u": "https://preview.redd.it/gdcu7rtux4pb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=be7438f7d5d9e8c6a071d6c5ef7a1ecf6c7b9e14"}, {"y": 266, "x": 320, "u": "https://preview.redd.it/gdcu7rtux4pb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c3fda441af1f027dedbfc010a5aab63a0698fcd0"}, {"y": 533, "x": 640, "u": "https://preview.redd.it/gdcu7rtux4pb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d8e1a6cfb0fdba579a2b873e42b5e2a3b4cfcd5e"}, {"y": 800, "x": 960, "u": "https://preview.redd.it/gdcu7rtux4pb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1487d72c9c084dd35156dd3fe7c649eba5da0b4b"}, {"y": 900, "x": 1080, "u": "https://preview.redd.it/gdcu7rtux4pb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e95bb412ffdc61759ace400829a4be41466d3e8e"}], "s": {"y": 974, "x": 1168, "u": "https://preview.redd.it/gdcu7rtux4pb1.png?width=1168&amp;format=png&amp;auto=webp&amp;s=7a10e7b1c1fee78c9afdd8c5d6b8b291d01388ff"}, "id": "gdcu7rtux4pb1"}}, "name": "t3_16mh40u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/qATIgO3O4cVvGLpQg3bihEpF-rH5UmBooD0wTxmuhsU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695097027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m doing a time-series forecasting task and observing a weekly seasonality pattern when plotting the data. I decided to use a SARIMA (p, d, q) (P, D, Q, S) model for this with S = 7. I also observed a slight trend shaped like a downward parabola, so I applied a differencing of 1 (d = D = 1). I&amp;#39;m having trouble interpreting my ACF and PACF plots to determine p, q, P, Q. I would really appreciate any insights/ suggestions. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here are the ACF and PACF plots of my differenced data:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dsu6uotux4pb1.png?width=1184&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8eda43067eff4a751a9e7635ae4b8a787419c6aa\"&gt;https://preview.redd.it/dsu6uotux4pb1.png?width=1184&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8eda43067eff4a751a9e7635ae4b8a787419c6aa&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gdcu7rtux4pb1.png?width=1168&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7a10e7b1c1fee78c9afdd8c5d6b8b291d01388ff\"&gt;https://preview.redd.it/gdcu7rtux4pb1.png?width=1168&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7a10e7b1c1fee78c9afdd8c5d6b8b291d01388ff&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;- My ACF has significant spikes every 7 lags, but other than that I wasn&amp;#39;t sure how to interpret this plot. I suspect this could be a non-seasonal MA(1) process so q = 1 and p = 0&lt;/p&gt;\n\n&lt;p&gt;- For my PACF, upon looking at the early lags, I saw that there were 5 significant spikes before lag 7. Instead of a non-seasonal MA(1) from above, I then suspect a non-seasonal AR(5), so p = 5 and q = 0.&lt;/p&gt;\n\n&lt;p&gt;- For the seasonal part, I decided to go with a seasonal AR(5) because there were 5 significant spikes in the PACF occurring at multiples of 7 before it cuts off to 0, so P = 5 and Q = 0&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I split my data into train/test sets and tried the following combinations:&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;- (0,1,1) (0,1,0,7): model fits well to the shape of the data but gives predictions that always exceed actual values&lt;/p&gt;\n\n&lt;p&gt;- (5,1,0) (5,1,0,7): model fits well to the shape of the data, has acceptable error metrics&lt;/p&gt;\n\n&lt;p&gt;- (0, 1, 1) (5, 1, 0, 7): model fits well to the shape of the data, has error metrics slightly worse than (5,1,0) (5,1,0,7).&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have a lot of experience interpreting ACF and PACF plots, so I&amp;#39;m not sure if my interpretation is correct. I would really appreciate feedback or explanations on the potential p, q, P, Q orders based on the plots I have.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16mh40u", "is_robot_indexable": true, "report_reasons": null, "author": "lunalita_99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16mh40u/is_my_reasoning_for_sarima_orders_correct_based/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16mh40u/is_my_reasoning_for_sarima_orders_correct_based/", "subreddit_subscribers": 1051667, "created_utc": 1695097027.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've completed masters in comp.sci. and currently doing unpaid internship, I apply for 10-15 companies each day but didn't get any call. Feeling nervous because not earning, any suggestions how can I land a job ASAP ?", "author_fullname": "t2_fpy8jt9e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying hard but no interview calls", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mgpi6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695095766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve completed masters in comp.sci. and currently doing unpaid internship, I apply for 10-15 companies each day but didn&amp;#39;t get any call. Feeling nervous because not earning, any suggestions how can I land a job ASAP ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16mgpi6", "is_robot_indexable": true, "report_reasons": null, "author": "Count_Ak", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16mgpi6/trying_hard_but_no_interview_calls/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16mgpi6/trying_hard_but_no_interview_calls/", "subreddit_subscribers": 1051667, "created_utc": 1695095766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm currently working on a small side project (partially for fun/education) that I can hopefully maybe leverage at work if it works well, but it's uncharted territory for me and was hoping for somebody to point me in the right direction towards a potential solution.\n\nEssentially, I want to match a target company with larger companies in the same vertical for potential commercial partnerships. I already have a test dataset which has a few hundred companies in the same space with business descriptions, etc. and some general useful qualitative information (customers, products, etc.) and wondering how I could potentially approach doing so.\n\nMy initial thought was some sort of algorithm to match based on overlap/similarity of tokenized/stemmed keywords from the business description and whatnot but having some difficulty building this out and getting usable outputs.\n\nHappy to tip someone for some help here, I have some ability in python but not sure where to go from here.", "author_fullname": "t2_3nbpojqw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working on a (hopefully) simple side project, would love some suggestions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mfr6y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695092969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working on a small side project (partially for fun/education) that I can hopefully maybe leverage at work if it works well, but it&amp;#39;s uncharted territory for me and was hoping for somebody to point me in the right direction towards a potential solution.&lt;/p&gt;\n\n&lt;p&gt;Essentially, I want to match a target company with larger companies in the same vertical for potential commercial partnerships. I already have a test dataset which has a few hundred companies in the same space with business descriptions, etc. and some general useful qualitative information (customers, products, etc.) and wondering how I could potentially approach doing so.&lt;/p&gt;\n\n&lt;p&gt;My initial thought was some sort of algorithm to match based on overlap/similarity of tokenized/stemmed keywords from the business description and whatnot but having some difficulty building this out and getting usable outputs.&lt;/p&gt;\n\n&lt;p&gt;Happy to tip someone for some help here, I have some ability in python but not sure where to go from here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16mfr6y", "is_robot_indexable": true, "report_reasons": null, "author": "BickleNack_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16mfr6y/working_on_a_hopefully_simple_side_project_would/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16mfr6y/working_on_a_hopefully_simple_side_project_would/", "subreddit_subscribers": 1051667, "created_utc": 1695092969.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! \n\nA couple hours ago i was told that in a few days I will have a technical interview for the position of data analysis intern. I know a certain amount of concepts and I would consider my level as intermediate (solid) for Excel, basic in Power Bi and basic in SQL. \n\nI plan to study practical exercises before the interview such as exporting the data to power bi and making a few dashboards but I don't know, I feel a little nervous hahaha. \n\nAny advice or comments? All types are accepted\n\n A kiss to the community :*", "author_fullname": "t2_uf2io4q2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Technical interview data analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mdwld", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695087758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! &lt;/p&gt;\n\n&lt;p&gt;A couple hours ago i was told that in a few days I will have a technical interview for the position of data analysis intern. I know a certain amount of concepts and I would consider my level as intermediate (solid) for Excel, basic in Power Bi and basic in SQL. &lt;/p&gt;\n\n&lt;p&gt;I plan to study practical exercises before the interview such as exporting the data to power bi and making a few dashboards but I don&amp;#39;t know, I feel a little nervous hahaha. &lt;/p&gt;\n\n&lt;p&gt;Any advice or comments? All types are accepted&lt;/p&gt;\n\n&lt;p&gt;A kiss to the community :*&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16mdwld", "is_robot_indexable": true, "report_reasons": null, "author": "Mediocre-Complex1418", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16mdwld/technical_interview_data_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16mdwld/technical_interview_data_analysis/", "subreddit_subscribers": 1051667, "created_utc": 1695087758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry for using throwaway. \n\nSo last year I worked in an ML team for a year at an MNC, the pay was great, the facility was good, I had full WFH allowance. This was my first DS work experience.\n\nBut I wanted to go back to school and also focus my time for my family, as we\u2019ve been separated by covid for about two years (we live in different countries), as international travel became more lax last year, didn\u2019t really have much time for them whenever they came to visit me as I was working. \n\nSo I decided to leave my position at the end of the year to focus on trying to get a scholarship and spend more time with my family when they get the chance to visit. Alas none of the scholarships went through but I feel much happier that I managed to spend quality time with the family.\n\nDuring this gap year I tried to work on things I enjoy. I built up my portfolio and  took on some freelance job but I mostly lived from the money I made last year and thankfully up to this point I am still financially ok, I still have majority of my savings and all. But I started job searching again a month ago, just so that this gap year wouldn\u2019t extend beyond my set 10 months max limit.\n\nRecently I got an offer for a DS position, this is at a local company, mid-size, mostly work on government projects and some international clients. So the pay is roughly around 50% of my previous pay, not as much WFH allowance and not as much facilities as before (e.g. health reimbursement). The pay isn\u2019t actually that bad in comparison to the average wage in my local area, still roughly 4X the local average for an office job. I definitely could live with it and still have some savings left, but definitely not as much as before. I happened to be directly interviewed and offered by the CEO so I skipped the whole HR and tests. He said this was the best offer he could make and from what I heard this already 1.5X of the pay for the same position in the company. The contract is for one year and pay can be negotiated when extended. I\u2019ve received the offer letter for this. \n\nI really need some input whether this is a worthwhile job to take now or should I keep going with the job search and wait it out for another couple of months. Thanks!", "author_fullname": "t2_hudg2vcq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Advice on Whether I Should Take the Job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m1m84", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695058012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry for using throwaway. &lt;/p&gt;\n\n&lt;p&gt;So last year I worked in an ML team for a year at an MNC, the pay was great, the facility was good, I had full WFH allowance. This was my first DS work experience.&lt;/p&gt;\n\n&lt;p&gt;But I wanted to go back to school and also focus my time for my family, as we\u2019ve been separated by covid for about two years (we live in different countries), as international travel became more lax last year, didn\u2019t really have much time for them whenever they came to visit me as I was working. &lt;/p&gt;\n\n&lt;p&gt;So I decided to leave my position at the end of the year to focus on trying to get a scholarship and spend more time with my family when they get the chance to visit. Alas none of the scholarships went through but I feel much happier that I managed to spend quality time with the family.&lt;/p&gt;\n\n&lt;p&gt;During this gap year I tried to work on things I enjoy. I built up my portfolio and  took on some freelance job but I mostly lived from the money I made last year and thankfully up to this point I am still financially ok, I still have majority of my savings and all. But I started job searching again a month ago, just so that this gap year wouldn\u2019t extend beyond my set 10 months max limit.&lt;/p&gt;\n\n&lt;p&gt;Recently I got an offer for a DS position, this is at a local company, mid-size, mostly work on government projects and some international clients. So the pay is roughly around 50% of my previous pay, not as much WFH allowance and not as much facilities as before (e.g. health reimbursement). The pay isn\u2019t actually that bad in comparison to the average wage in my local area, still roughly 4X the local average for an office job. I definitely could live with it and still have some savings left, but definitely not as much as before. I happened to be directly interviewed and offered by the CEO so I skipped the whole HR and tests. He said this was the best offer he could make and from what I heard this already 1.5X of the pay for the same position in the company. The contract is for one year and pay can be negotiated when extended. I\u2019ve received the offer letter for this. &lt;/p&gt;\n\n&lt;p&gt;I really need some input whether this is a worthwhile job to take now or should I keep going with the job search and wait it out for another couple of months. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16m1m84", "is_robot_indexable": true, "report_reasons": null, "author": "Proud-Piccolo4644", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16m1m84/need_advice_on_whether_i_should_take_the_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16m1m84/need_advice_on_whether_i_should_take_the_job/", "subreddit_subscribers": 1051667, "created_utc": 1695058012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I come from the finance / fp&amp;a perspective at my company and I'm trying to educate myself on more rigorous forecasting through the Hyndman forecasting book. I'm surprised that there seems to be very little discussion about using prior year periods * (1+g) to forecast the next year's value, assuming g to be a growth rate. This seems similar to a seasonal naive method (looking [here](https://otexts.com/fpp2/simple-methods.html)) or naive with drift, but still pretty different.\n\nCan y'all  help point out where I'm missing this discussion? I've searched and found very little talk about using YoY growth as a forecast model or method, when it is BY FAR the most common model used on the finance side where I have worked (investment banking, private equity, and corporate finance\".\n\nI'm wondering if folks here model the growth rate itself as opposed to the actual value of interest, or if I need to learn more about logarithmic modeling, or something else. Any pointers would be awesome. Finance as a profession has a lot to learn from basic statistical analysis and forecasting, but I haven't had luck finding a good jumping off point from how most finance professionals I know actually forecast today.\n\nMany thanks in advance.", "author_fullname": "t2_10xuew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is YoY Growth a \"real\" Forecasting method? Asking from the perspective of a finance person / background", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m17ya", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695057057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I come from the finance / fp&amp;amp;a perspective at my company and I&amp;#39;m trying to educate myself on more rigorous forecasting through the Hyndman forecasting book. I&amp;#39;m surprised that there seems to be very little discussion about using prior year periods * (1+g) to forecast the next year&amp;#39;s value, assuming g to be a growth rate. This seems similar to a seasonal naive method (looking &lt;a href=\"https://otexts.com/fpp2/simple-methods.html\"&gt;here&lt;/a&gt;) or naive with drift, but still pretty different.&lt;/p&gt;\n\n&lt;p&gt;Can y&amp;#39;all  help point out where I&amp;#39;m missing this discussion? I&amp;#39;ve searched and found very little talk about using YoY growth as a forecast model or method, when it is BY FAR the most common model used on the finance side where I have worked (investment banking, private equity, and corporate finance&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering if folks here model the growth rate itself as opposed to the actual value of interest, or if I need to learn more about logarithmic modeling, or something else. Any pointers would be awesome. Finance as a profession has a lot to learn from basic statistical analysis and forecasting, but I haven&amp;#39;t had luck finding a good jumping off point from how most finance professionals I know actually forecast today.&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TznpMHweesGFVyr19aVyFWMbZ1H5nQ7vvQVp85DND54.jpg?auto=webp&amp;s=9dadbace8256814c968ee85a9036f1e9736cc5f9", "width": 400, "height": 582}, "resolutions": [{"url": "https://external-preview.redd.it/TznpMHweesGFVyr19aVyFWMbZ1H5nQ7vvQVp85DND54.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=647ea6e0d20245ce826f41a0fe9cfc66218ba308", "width": 108, "height": 157}, {"url": "https://external-preview.redd.it/TznpMHweesGFVyr19aVyFWMbZ1H5nQ7vvQVp85DND54.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d9e24a7f701ab7b9edd09875b06b15e108577999", "width": 216, "height": 314}, {"url": "https://external-preview.redd.it/TznpMHweesGFVyr19aVyFWMbZ1H5nQ7vvQVp85DND54.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=39d587431f54a23a1d06338a4ce2eb77778e574d", "width": 320, "height": 465}], "variants": {}, "id": "rhJppZp7nuxVr7lezINDBOXONcXhZYlDM3_mcUPhrk4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16m17ya", "is_robot_indexable": true, "report_reasons": null, "author": "xraytrey", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16m17ya/is_yoy_growth_a_real_forecasting_method_asking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16m17ya/is_yoy_growth_a_real_forecasting_method_asking/", "subreddit_subscribers": 1051667, "created_utc": 1695057057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_11sg4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CDC Data Scientist job opening - Fully remote - GS 14", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_16lykh1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/JxpqQscgdgRyj8FNVPPN5D_btCoqegevJQVNq5lAJw8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695050826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "usajobs.gov", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.usajobs.gov/job/749670900", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SimqnF6Q-HVAgwpG3SpJh5HnhX0rQXKfOsOKBTxIiSs.jpg?auto=webp&amp;s=08d2433cda44a6809b51acb15b381a337be051d0", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/SimqnF6Q-HVAgwpG3SpJh5HnhX0rQXKfOsOKBTxIiSs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7ffedccdb201a0e29c22d31fd01b1b76d170e188", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/SimqnF6Q-HVAgwpG3SpJh5HnhX0rQXKfOsOKBTxIiSs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1bee88d306085a4f8e06da868317b3948b02fdea", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/SimqnF6Q-HVAgwpG3SpJh5HnhX0rQXKfOsOKBTxIiSs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9bfc7f70c36afcdb1e39f703d22425e40dbc69c", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/SimqnF6Q-HVAgwpG3SpJh5HnhX0rQXKfOsOKBTxIiSs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4e0d3b025668f5913a0eef42d1dc6ea7093573e2", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/SimqnF6Q-HVAgwpG3SpJh5HnhX0rQXKfOsOKBTxIiSs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c09c32b46726670a22f48badd8b31a45f07c249a", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/SimqnF6Q-HVAgwpG3SpJh5HnhX0rQXKfOsOKBTxIiSs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9868d6adc48e97d18516bb3d0e0e5d219897db7c", "width": 1080, "height": 567}], "variants": {}, "id": "j7yMz_Vc1TuEmlXWVbfb0bA5TfAjw48eniV5RmVjCgM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16lykh1", "is_robot_indexable": true, "report_reasons": null, "author": "cosmic_dozen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16lykh1/cdc_data_scientist_job_opening_fully_remote_gs_14/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.usajobs.gov/job/749670900", "subreddit_subscribers": 1051667, "created_utc": 1695050826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm considering applying to a university to get a certificate in DataScience / DataAnalysis (with a possibility of continuing to earn an MS). But most of the programs I've seen (at state universities in IL) emphasize a couple of years of Java, object / data structure courses, etc.\n\nOnline schools (like DataCamp) emphasize Python, pandas, etc., with some stats / linear algebra, etc.\n\nThe former seem to be capitalizing on the skills of their current employees and courses they've been teaching for years (i.e., traditional CS curriculum with some modifications); the latter argue that what they offer is what employers are seeking, but have a vested interest in making this argument -- it's what they are selling.\n\nA third model doing something like Google's professional data engineer course (or AWS or another corporate sponsored training program).\n\nFor folks actually working in the field (and hiring people), which of these models is more attractive? How important is it to have an academic certificate degree in DS to get into the field?\n\nThanks for your feedback", "author_fullname": "t2_22fsxqwq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Academic MS/certificate in DS or certificate from Google, Amazon, etc.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16luxng", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695042090.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m considering applying to a university to get a certificate in DataScience / DataAnalysis (with a possibility of continuing to earn an MS). But most of the programs I&amp;#39;ve seen (at state universities in IL) emphasize a couple of years of Java, object / data structure courses, etc.&lt;/p&gt;\n\n&lt;p&gt;Online schools (like DataCamp) emphasize Python, pandas, etc., with some stats / linear algebra, etc.&lt;/p&gt;\n\n&lt;p&gt;The former seem to be capitalizing on the skills of their current employees and courses they&amp;#39;ve been teaching for years (i.e., traditional CS curriculum with some modifications); the latter argue that what they offer is what employers are seeking, but have a vested interest in making this argument -- it&amp;#39;s what they are selling.&lt;/p&gt;\n\n&lt;p&gt;A third model doing something like Google&amp;#39;s professional data engineer course (or AWS or another corporate sponsored training program).&lt;/p&gt;\n\n&lt;p&gt;For folks actually working in the field (and hiring people), which of these models is more attractive? How important is it to have an academic certificate degree in DS to get into the field?&lt;/p&gt;\n\n&lt;p&gt;Thanks for your feedback&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16luxng", "is_robot_indexable": true, "report_reasons": null, "author": "BeeApiary", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16luxng/academic_mscertificate_in_ds_or_certificate_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16luxng/academic_mscertificate_in_ds_or_certificate_from/", "subreddit_subscribers": 1051667, "created_utc": 1695042090.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Where are the best places to find junior graduate roles in Data Science in London? Struggling to find suitable websites and sources.\n\n(Will have an MSc in Statistics)", "author_fullname": "t2_pgihp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Graduate role websites", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m6qcp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695069750.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where are the best places to find junior graduate roles in Data Science in London? Struggling to find suitable websites and sources.&lt;/p&gt;\n\n&lt;p&gt;(Will have an MSc in Statistics)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16m6qcp", "is_robot_indexable": true, "report_reasons": null, "author": "BadTacticss", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16m6qcp/graduate_role_websites/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16m6qcp/graduate_role_websites/", "subreddit_subscribers": 1051667, "created_utc": 1695069750.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\n\nI am currently trying to pre-process data for a classification ML model. I have both categorical and continuous variables. The questions came to my mind:\n\n1. If I have a continuous variable that has a value of say 90, and then I have some categorical values with one hot encoding that has values of 0 or 1s. Wouldn't the ML model take the value of 90 as much as higher and then value this feature more? (I know I am probably asking a math question here). Note: I am comparing many different models using PyCaret.\n2. This is important because I am trying to decide how to pre-process my features. Shall I always normalize (or standarize)? If I do normalize, then wouldn't the ML model give less importance (even less than it should) to my value of 90? (Note: This value comes from a relatively important feature, I know this because of my previous understanding of my data).\n3. On the same sense: Wouldn't this give same importance (0,1) to different categories that might have difference importances? (Example: Sex might not be as important as Tumor Type).\n\nThank you very much!", "author_fullname": "t2_3abb303f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Preprocessing: Categorical vs Continuous variables [Classification]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m3px8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695062877.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I am currently trying to pre-process data for a classification ML model. I have both categorical and continuous variables. The questions came to my mind:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;If I have a continuous variable that has a value of say 90, and then I have some categorical values with one hot encoding that has values of 0 or 1s. Wouldn&amp;#39;t the ML model take the value of 90 as much as higher and then value this feature more? (I know I am probably asking a math question here). Note: I am comparing many different models using PyCaret.&lt;/li&gt;\n&lt;li&gt;This is important because I am trying to decide how to pre-process my features. Shall I always normalize (or standarize)? If I do normalize, then wouldn&amp;#39;t the ML model give less importance (even less than it should) to my value of 90? (Note: This value comes from a relatively important feature, I know this because of my previous understanding of my data).&lt;/li&gt;\n&lt;li&gt;On the same sense: Wouldn&amp;#39;t this give same importance (0,1) to different categories that might have difference importances? (Example: Sex might not be as important as Tumor Type).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16m3px8", "is_robot_indexable": true, "report_reasons": null, "author": "kolopoi0", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16m3px8/preprocessing_categorical_vs_continuous_variables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16m3px8/preprocessing_categorical_vs_continuous_variables/", "subreddit_subscribers": 1051667, "created_utc": 1695062877.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a large dataset in pgadmin 4(postgresql), I am trying to randomize all values in each row with a certain limitations for percentages amd negative numbers and so on(so that the data is within range and still understandable).\n\nThis data also has strings, boolean, and numbers.\n\nData is fully combined on pgadmin but seperated in csv files so can I randomize them in excel too ?\n\nAny suggestions, links, piece of code to try ?", "author_fullname": "t2_8a8gi2hqi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to randomize every value in a large dataset ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m3ofz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695062784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large dataset in pgadmin 4(postgresql), I am trying to randomize all values in each row with a certain limitations for percentages amd negative numbers and so on(so that the data is within range and still understandable).&lt;/p&gt;\n\n&lt;p&gt;This data also has strings, boolean, and numbers.&lt;/p&gt;\n\n&lt;p&gt;Data is fully combined on pgadmin but seperated in csv files so can I randomize them in excel too ?&lt;/p&gt;\n\n&lt;p&gt;Any suggestions, links, piece of code to try ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16m3ofz", "is_robot_indexable": true, "report_reasons": null, "author": "LearnTheTrueth", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16m3ofz/is_it_possible_to_randomize_every_value_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16m3ofz/is_it_possible_to_randomize_every_value_in_a/", "subreddit_subscribers": 1051667, "created_utc": 1695062784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Does anyone how does the process look like for data scientist interview for new grad/intern? Especially the initial phone screen?", "author_fullname": "t2_4qd3h9ep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks | Data Science Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16m33fp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695061455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone how does the process look like for data scientist interview for new grad/intern? Especially the initial phone screen?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16m33fp", "is_robot_indexable": true, "report_reasons": null, "author": "enkounter08", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16m33fp/databricks_data_science_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16m33fp/databricks_data_science_interview/", "subreddit_subscribers": 1051667, "created_utc": 1695061455.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}