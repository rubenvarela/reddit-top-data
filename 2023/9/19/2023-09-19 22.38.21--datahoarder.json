{"kind": "Listing", "data": {"after": "t3_16mqqlq", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need to buy some fresh stock for a large archive idea i'm mulling.\n\nIs there any website that shows cheapest $ per TB for drives?\n\nAny tips for getting the best bang for buck ($/TB)?", "author_fullname": "t2_6jv88", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any website that shows cheapest $ per TB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mr7x3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695130531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to buy some fresh stock for a large archive idea i&amp;#39;m mulling.&lt;/p&gt;\n\n&lt;p&gt;Is there any website that shows cheapest $ per TB for drives?&lt;/p&gt;\n\n&lt;p&gt;Any tips for getting the best bang for buck ($/TB)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16mr7x3", "is_robot_indexable": true, "report_reasons": null, "author": "omgsoftcats", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mr7x3/any_website_that_shows_cheapest_per_tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mr7x3/any_website_that_shows_cheapest_per_tb/", "subreddit_subscribers": 702819, "created_utc": 1695130531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm still a little confused on how it works. I know that on a HDD stuff stays until it's overwritten, meaning you can pretty easily get back stuff you accidentally deleted unless you've been using the HDD for years and years until that specific piece of data on the HDD decides to overwrite, or you fill the drive to the brim and it has nowhere else to put data.  \n\nI'm confused as to how \"TRIM\" works on SSD's though. My current understanding (which I feel is incorrect) is that when TRIM/garbage collection runs, it wipes out any data marked as deleted to make writing something else in its place faster, meaning lost data has to be recovered in a very short amount of time to prevent complete loss, and once a TRIM wipes the piece of the SSD that data is on, it's gone gone. Could someone ELI5 how this works, if my presumption is wrong?", "author_fullname": "t2_j52b70pj5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can someone ELI5 what TRIM or \"garbage collection\" is on an SSD, and why it makes retrieving stuff so hard?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16moy8w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695124514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m still a little confused on how it works. I know that on a HDD stuff stays until it&amp;#39;s overwritten, meaning you can pretty easily get back stuff you accidentally deleted unless you&amp;#39;ve been using the HDD for years and years until that specific piece of data on the HDD decides to overwrite, or you fill the drive to the brim and it has nowhere else to put data.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m confused as to how &amp;quot;TRIM&amp;quot; works on SSD&amp;#39;s though. My current understanding (which I feel is incorrect) is that when TRIM/garbage collection runs, it wipes out any data marked as deleted to make writing something else in its place faster, meaning lost data has to be recovered in a very short amount of time to prevent complete loss, and once a TRIM wipes the piece of the SSD that data is on, it&amp;#39;s gone gone. Could someone ELI5 how this works, if my presumption is wrong?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16moy8w", "is_robot_indexable": true, "report_reasons": null, "author": "stellerman7", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16moy8w/can_someone_eli5_what_trim_or_garbage_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16moy8w/can_someone_eli5_what_trim_or_garbage_collection/", "subreddit_subscribers": 702819, "created_utc": 1695124514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi there! I'm thinking about buying a flatbed scanner to digitize my photo collection. One of the things I've noticed in the specifications is the \"internal\" and \"external\" color bit depth. What does this mean exactly? I'm asking as I was unable to find an explanation.", "author_fullname": "t2_4m5atmj2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scanner bit depth.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mqxdu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695129800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there! I&amp;#39;m thinking about buying a flatbed scanner to digitize my photo collection. One of the things I&amp;#39;ve noticed in the specifications is the &amp;quot;internal&amp;quot; and &amp;quot;external&amp;quot; color bit depth. What does this mean exactly? I&amp;#39;m asking as I was unable to find an explanation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mqxdu", "is_robot_indexable": true, "report_reasons": null, "author": "Callistax", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mqxdu/scanner_bit_depth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mqxdu/scanner_bit_depth/", "subreddit_subscribers": 702819, "created_utc": 1695129800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "  \n Hello all.\n\nI recently purchased 4 HC560 20TB data center hard drives. I have 4 SilverStone TS07 external USB cases 12v powered which have the Asmedia ASM1051E SATA to USB chip, connected to a Raspberry Pi4B running OMV6.\n\n3 of the HDD gets recognised correctly on OMV while 1 of them do not. Unforntunately I do not have access to a SATA interface for further testing.\n\nI have tried to swap the external cases and cables from 1 of the working HDD to the 1 of the unrecognised one. I have tried to run the unrecognised HDD as the only drive connected. None of them works.\n\nThe output of dmesg whenever I connect a working drive is as follows:\n\n[Working HDD](https://preview.redd.it/on82fbhhc8pb1.png?width=960&amp;format=png&amp;auto=webp&amp;s=50204a6882fe20ab31dd558e15b156301ad930ee)\n\n The output of dmesg whenever I connect the unrecognised drive is as follows: \n\n[Faulty HDD](https://preview.redd.it/xtln60qnc8pb1.png?width=939&amp;format=png&amp;auto=webp&amp;s=64146440907b8ae85e54625d79ec7ba823e74f3f)\n\nAs you see, at half the spinning disk operation, it gest halted and removed. The HDD \"sounds\" as it is working and gets somewhat warm as the working drives, but it does not show on fdisk or OMV disk GUI. The other 3 HDD work perfectly, they got all ext4 formatted and I have them running. I assume the controller is ok but some mechanical component is not.\n\nDo I have something left to test or should I already RMA it?\n\nThanks in advance.", "author_fullname": "t2_14jgu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just bought 4x20TB, machine does not recognise external USB HDD on fdisk and got dmesg errors (DOA?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": 44, "top_awarded_type": null, "hide_score": false, "media_metadata": {"xtln60qnc8pb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/xtln60qnc8pb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e43f96d9144d4935e509c8439c8305ed60eb586d"}, {"y": 73, "x": 216, "u": "https://preview.redd.it/xtln60qnc8pb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b76184379c961f983a98f3e42df8edebfb11a2a8"}, {"y": 109, "x": 320, "u": "https://preview.redd.it/xtln60qnc8pb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0d74c8954bedaa63e8e9cd87ae9a48c1645f881b"}, {"y": 218, "x": 640, "u": "https://preview.redd.it/xtln60qnc8pb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bcb66d5e59318c4ab660bedf44a3170ba327cae7"}], "s": {"y": 320, "x": 939, "u": "https://preview.redd.it/xtln60qnc8pb1.png?width=939&amp;format=png&amp;auto=webp&amp;s=64146440907b8ae85e54625d79ec7ba823e74f3f"}, "id": "xtln60qnc8pb1"}, "on82fbhhc8pb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 34, "x": 108, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8284055b9b54f503f8469e567f9692825dc9924e"}, {"y": 68, "x": 216, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2f5b56d1208bf6f7d8a3d9b6758c72e840d17fc4"}, {"y": 101, "x": 320, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=33b7cdf9152cc8ed8697388359af363eb40e8405"}, {"y": 202, "x": 640, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0bd27a880403add91929630d6a0eecd401a5a9f7"}, {"y": 303, "x": 960, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=385df6bf00ec7efd8beb9bda5f2bf53c4d5d942e"}], "s": {"y": 303, "x": 960, "u": "https://preview.redd.it/on82fbhhc8pb1.png?width=960&amp;format=png&amp;auto=webp&amp;s=50204a6882fe20ab31dd558e15b156301ad930ee"}, "id": "on82fbhhc8pb1"}}, "name": "t3_16mtz19", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cTKsnFpROg3xX9j9TkOJq-SrBdBrgm9oD0B-FXIvzes.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695137092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all.&lt;/p&gt;\n\n&lt;p&gt;I recently purchased 4 HC560 20TB data center hard drives. I have 4 SilverStone TS07 external USB cases 12v powered which have the Asmedia ASM1051E SATA to USB chip, connected to a Raspberry Pi4B running OMV6.&lt;/p&gt;\n\n&lt;p&gt;3 of the HDD gets recognised correctly on OMV while 1 of them do not. Unforntunately I do not have access to a SATA interface for further testing.&lt;/p&gt;\n\n&lt;p&gt;I have tried to swap the external cases and cables from 1 of the working HDD to the 1 of the unrecognised one. I have tried to run the unrecognised HDD as the only drive connected. None of them works.&lt;/p&gt;\n\n&lt;p&gt;The output of dmesg whenever I connect a working drive is as follows:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/on82fbhhc8pb1.png?width=960&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=50204a6882fe20ab31dd558e15b156301ad930ee\"&gt;Working HDD&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The output of dmesg whenever I connect the unrecognised drive is as follows: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/xtln60qnc8pb1.png?width=939&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=64146440907b8ae85e54625d79ec7ba823e74f3f\"&gt;Faulty HDD&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As you see, at half the spinning disk operation, it gest halted and removed. The HDD &amp;quot;sounds&amp;quot; as it is working and gets somewhat warm as the working drives, but it does not show on fdisk or OMV disk GUI. The other 3 HDD work perfectly, they got all ext4 formatted and I have them running. I assume the controller is ok but some mechanical component is not.&lt;/p&gt;\n\n&lt;p&gt;Do I have something left to test or should I already RMA it?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mtz19", "is_robot_indexable": true, "report_reasons": null, "author": "jfromeo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mtz19/just_bought_4x20tb_machine_does_not_recognise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mtz19/just_bought_4x20tb_machine_does_not_recognise/", "subreddit_subscribers": 702819, "created_utc": 1695137092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "if you had varying budgets, what would be your dream setup that you would build yourself? And would be your use case for it?\n\n&amp;#x200B;\n\nif I had more money lying around then I knew what to do with this is what I'd get: [Supermicro SuperStorage Server 6049P-E1CR36L - 36x SATA/SAS - LSI 3008 12G SAS - Dual 10-Gigabit Ethernet](https://www.thinkmate.com/system/superstorage-server-6049p-e1cr36l), and throw 36 x 22TB drives in a RAID 6 and 2x 4TB NVMe drives in RAID 1, but at a whopping $40,700.00 it's out of reach \n\n&amp;#x200B;\n\nBut at the moment I'm just eyeing a [Define 7 XL case](https://www.fractal-design.com/products/cases/define/define-7-xl/black-tg-dark-tint/) that can house 18x 3.5\" HDD's + 5x 2.5\" SSD's + 2x NVMe's. I can transplant my current setup into this case. + a [24 port SATA PCI Card](https://www.amazon.com/gp/product/B09K3FT3ZZ/ref=ox_sc_saved_title_2?smid=A1MK2DD7C33I65&amp;th=1)  \nThe case ($235) and the PCI card ($143) aren't really that expensive to shift, then add all my current drives plus whatever else I buy in the future\n\n&amp;#x200B;\n\nI've also been eyeing a [Yottamaster 5 Bay](https://www.amazon.com/gp/product/B08DLTKXCP/ref=ox_sc_saved_title_3?smid=A3OLRMD4MBYEYY&amp;th=1) external case ($280) that can daisy chain up to 3 times and supposedly can get up 10Gbps, but I'm wary that if I'm doing things on multiple disks it'll diminish the speed on the other disks.\n\n&amp;#x200B;\n\nMy use case is mostly just Plex and arcade stuff, so the data is at rest most of the time  \n\n\nIn any case, I'm really curious as to what your guys' solutions would be.  \n\n\n&amp;#x200B;", "author_fullname": "t2_1c4sxc16", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's your dream storage configuration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mwkrj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695143326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;if you had varying budgets, what would be your dream setup that you would build yourself? And would be your use case for it?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;if I had more money lying around then I knew what to do with this is what I&amp;#39;d get: &lt;a href=\"https://www.thinkmate.com/system/superstorage-server-6049p-e1cr36l\"&gt;Supermicro SuperStorage Server 6049P-E1CR36L - 36x SATA/SAS - LSI 3008 12G SAS - Dual 10-Gigabit Ethernet&lt;/a&gt;, and throw 36 x 22TB drives in a RAID 6 and 2x 4TB NVMe drives in RAID 1, but at a whopping $40,700.00 it&amp;#39;s out of reach &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;But at the moment I&amp;#39;m just eyeing a &lt;a href=\"https://www.fractal-design.com/products/cases/define/define-7-xl/black-tg-dark-tint/\"&gt;Define 7 XL case&lt;/a&gt; that can house 18x 3.5&amp;quot; HDD&amp;#39;s + 5x 2.5&amp;quot; SSD&amp;#39;s + 2x NVMe&amp;#39;s. I can transplant my current setup into this case. + a &lt;a href=\"https://www.amazon.com/gp/product/B09K3FT3ZZ/ref=ox_sc_saved_title_2?smid=A1MK2DD7C33I65&amp;amp;th=1\"&gt;24 port SATA PCI Card&lt;/a&gt;&lt;br/&gt;\nThe case ($235) and the PCI card ($143) aren&amp;#39;t really that expensive to shift, then add all my current drives plus whatever else I buy in the future&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also been eyeing a &lt;a href=\"https://www.amazon.com/gp/product/B08DLTKXCP/ref=ox_sc_saved_title_3?smid=A3OLRMD4MBYEYY&amp;amp;th=1\"&gt;Yottamaster 5 Bay&lt;/a&gt; external case ($280) that can daisy chain up to 3 times and supposedly can get up 10Gbps, but I&amp;#39;m wary that if I&amp;#39;m doing things on multiple disks it&amp;#39;ll diminish the speed on the other disks.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My use case is mostly just Plex and arcade stuff, so the data is at rest most of the time  &lt;/p&gt;\n\n&lt;p&gt;In any case, I&amp;#39;m really curious as to what your guys&amp;#39; solutions would be.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mwkrj", "is_robot_indexable": true, "report_reasons": null, "author": "MichaeldeBlok", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mwkrj/whats_your_dream_storage_configuration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mwkrj/whats_your_dream_storage_configuration/", "subreddit_subscribers": 702819, "created_utc": 1695143326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi. I have some books about aircrafts which contain some text but mostly pictures. Some of these books are no longer available in the market, so I am thinking to scan them and have them in digital form (pdf). \n\nI am completely rookie to this, and my aim is to scan those books and not lose any quality from the images they contain. \n\n&amp;#x200B;\n\nWhat would be the best resolution to scan the pages/images ? Is 300dpi enough, or will it give me low quality pictures?\n\n&amp;#x200B;\n\nthanks in advance for the help.", "author_fullname": "t2_1s0ymi9v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resolution for Scanning books with pictures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n10sh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695154224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I have some books about aircrafts which contain some text but mostly pictures. Some of these books are no longer available in the market, so I am thinking to scan them and have them in digital form (pdf). &lt;/p&gt;\n\n&lt;p&gt;I am completely rookie to this, and my aim is to scan those books and not lose any quality from the images they contain. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What would be the best resolution to scan the pages/images ? Is 300dpi enough, or will it give me low quality pictures?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks in advance for the help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n10sh", "is_robot_indexable": true, "report_reasons": null, "author": "tripialos", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n10sh/resolution_for_scanning_books_with_pictures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n10sh/resolution_for_scanning_books_with_pictures/", "subreddit_subscribers": 702819, "created_utc": 1695154224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using FFS for over a decade and love the UI. My employer IS security team recently won't let me use FreeFileSync because they say it's a security issue. That it contains malicious files. I even tried to run it as a portable app but it's still an issue. What is a good paid alternative?", "author_fullname": "t2_4ea5v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some alternatives to FreeFileSync?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mzr3a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695151163.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using FFS for over a decade and love the UI. My employer IS security team recently won&amp;#39;t let me use FreeFileSync because they say it&amp;#39;s a security issue. That it contains malicious files. I even tried to run it as a portable app but it&amp;#39;s still an issue. What is a good paid alternative?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mzr3a", "is_robot_indexable": true, "report_reasons": null, "author": "videonerd", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mzr3a/what_are_some_alternatives_to_freefilesync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mzr3a/what_are_some_alternatives_to_freefilesync/", "subreddit_subscribers": 702819, "created_utc": 1695151163.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, I just built a system yesterday with the original goal of being a Plex Server and NAS. Using some old parts as the foundation and some new drives and case:\n\n\u2022\t\u2060Intel i7 4770K\n\u2022\t\u2060EVGA z87 FTW mobo\n\u2022\t\u206016GB Crucial Ballistix RAM\n\u2022\t\u2060EVGA 2060 KO Ultra\n\u2022\t\u2060Samsung 850 EVO 500GB SSD\n\u2022\t\u20604 x 6TB WD Red Plus: WD60EFZX\n\u2022\t\u2060EVGA 700 BQ PSU\n\u2022\t\u2060Cooler Master N400\n\nPer a recommendation from a friend, I installed Windows 10 and setup Storage Spaces. I was going to set the drives up in parity but currently they\u2019re in a simple pool. He suggested getting some bigger drives later as a backup for the 21.5TB the four drives provide. The immediate next step was just to slap Plex on there and move all my media over from my current PC.\n\nAnyway, with all of that said my actual original plan was to turn the new build into a NAS / Plex server but my friend thought that was over kill. Plus I have zero experience with building a NAS so for the moment, I\u2019ve taken the easiest path.\n\nI\u2019m hoping someone would be kind enough to offer some guidance here or suggestions of how to get the most out of the current setup. Is this a short sighted setup? Would it be better to set these drives up in RAID 10? I only have about 2TB of media so far, but I am slowly backing up my DVDs and Blu-rays. One other comment, I did just pick up the Plex pass on sale this week. Right now usage would be for my main 4K tv that is hooked up to an Apple TV 4K 2nd Gen. Wife likes to watch on her phone and my mom will sometimes watch from her account on a 1080p tv. I have a mixture of 480, 1080, and 4K content.\n\nThanks for your help! I enjoy learning, not dumb, just ignorant at the moment and looking for some help and advice navigating to a useful setup.", "author_fullname": "t2_nip8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mvwr3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695141710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I just built a system yesterday with the original goal of being a Plex Server and NAS. Using some old parts as the foundation and some new drives and case:&lt;/p&gt;\n\n&lt;p&gt;\u2022 \u2060Intel i7 4770K\n\u2022 \u2060EVGA z87 FTW mobo\n\u2022 \u206016GB Crucial Ballistix RAM\n\u2022 \u2060EVGA 2060 KO Ultra\n\u2022 \u2060Samsung 850 EVO 500GB SSD\n\u2022 \u20604 x 6TB WD Red Plus: WD60EFZX\n\u2022 \u2060EVGA 700 BQ PSU\n\u2022 \u2060Cooler Master N400&lt;/p&gt;\n\n&lt;p&gt;Per a recommendation from a friend, I installed Windows 10 and setup Storage Spaces. I was going to set the drives up in parity but currently they\u2019re in a simple pool. He suggested getting some bigger drives later as a backup for the 21.5TB the four drives provide. The immediate next step was just to slap Plex on there and move all my media over from my current PC.&lt;/p&gt;\n\n&lt;p&gt;Anyway, with all of that said my actual original plan was to turn the new build into a NAS / Plex server but my friend thought that was over kill. Plus I have zero experience with building a NAS so for the moment, I\u2019ve taken the easiest path.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m hoping someone would be kind enough to offer some guidance here or suggestions of how to get the most out of the current setup. Is this a short sighted setup? Would it be better to set these drives up in RAID 10? I only have about 2TB of media so far, but I am slowly backing up my DVDs and Blu-rays. One other comment, I did just pick up the Plex pass on sale this week. Right now usage would be for my main 4K tv that is hooked up to an Apple TV 4K 2nd Gen. Wife likes to watch on her phone and my mom will sometimes watch from her account on a 1080p tv. I have a mixture of 480, 1080, and 4K content.&lt;/p&gt;\n\n&lt;p&gt;Thanks for your help! I enjoy learning, not dumb, just ignorant at the moment and looking for some help and advice navigating to a useful setup.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mvwr3", "is_robot_indexable": true, "report_reasons": null, "author": "Hayreddin", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mvwr3/looking_for_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mvwr3/looking_for_advice/", "subreddit_subscribers": 702819, "created_utc": 1695141710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone. I would like to hear the opinion from this community about choosing disks for a new NAS. To put it simply, i want to build a tiny home NAS server, and based on my budget i can go with 2 options for the storage. A) Buy 4 new 2TB disks. B) Buy 4 used 4TB disks. (they are about 40k hours old, around 5 years of usage). What option would you go for and why? Thank you!", "author_fullname": "t2_ah3xat1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Used or new drives for a small NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n09g6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695152397.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I would like to hear the opinion from this community about choosing disks for a new NAS. To put it simply, i want to build a tiny home NAS server, and based on my budget i can go with 2 options for the storage. A) Buy 4 new 2TB disks. B) Buy 4 used 4TB disks. (they are about 40k hours old, around 5 years of usage). What option would you go for and why? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n09g6", "is_robot_indexable": true, "report_reasons": null, "author": "CamaronSantuchi", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n09g6/used_or_new_drives_for_a_small_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n09g6/used_or_new_drives_for_a_small_nas/", "subreddit_subscribers": 702819, "created_utc": 1695152397.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all,\n\nI've been trying to use various Hangouts JSON readers from GitHub (namely [this one](https://github.com/Jessecar96/hangouts-reader) and [this one](https://github.com/adrish96/Hangouts-JSON-Parser/blob/master/HangoutJsonParser.py)), but I can't for the life of me get them to work.\n\nI think the issue may be at least in part due to the fact that my files are backed up as Google Chat exports and NOT Hangouts -- is this common? I think the chat was migrated to Google Chat at some point in time, so that's why it was moved. I renamed the messages.json file to Hangouts.json, and it just spit out some errors.\n\nI don't have the skills to fix the script to work with the potentially different formatting of the Chat files, so I want to see if anybody else has had a similar issue and found a solution...", "author_fullname": "t2_107h5d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Hangouts takeout data parser for Google Chat?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mwrod", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695143813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been trying to use various Hangouts JSON readers from GitHub (namely &lt;a href=\"https://github.com/Jessecar96/hangouts-reader\"&gt;this one&lt;/a&gt; and &lt;a href=\"https://github.com/adrish96/Hangouts-JSON-Parser/blob/master/HangoutJsonParser.py\"&gt;this one&lt;/a&gt;), but I can&amp;#39;t for the life of me get them to work.&lt;/p&gt;\n\n&lt;p&gt;I think the issue may be at least in part due to the fact that my files are backed up as Google Chat exports and NOT Hangouts -- is this common? I think the chat was migrated to Google Chat at some point in time, so that&amp;#39;s why it was moved. I renamed the messages.json file to Hangouts.json, and it just spit out some errors.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have the skills to fix the script to work with the potentially different formatting of the Chat files, so I want to see if anybody else has had a similar issue and found a solution...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?auto=webp&amp;s=e2b7fa2752944a9eb0a93b7df41a029ec58cb5a6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7c28d57238c1210bf3ade3e07be822d4cf57535", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4e879461097e00945ef05a9fcb3b8aedd70ae5bb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b43862bb9b300a1d080d01c54b9756f5fde1001a", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4e0abc4d0bd5266a3530b3a4a6f9cf5e6685ca6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f82782f62519772c4a1640db1f6fcbd976f201eb", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/RtOfmULKAmpsCfkveXxx0RaqEV9hrjlrrJASm63Xb8M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6406ae84cd42000b3daf2364626b0a4055a6f711", "width": 1080, "height": 540}], "variants": {}, "id": "SiLrOgT-sA9pjgWd6-jz8kfvfIH5c34B9rAL_W4UfOk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mwrod", "is_robot_indexable": true, "report_reasons": null, "author": "gts250gamer101", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mwrod/google_hangouts_takeout_data_parser_for_google/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mwrod/google_hangouts_takeout_data_parser_for_google/", "subreddit_subscribers": 702819, "created_utc": 1695143813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Truenas Scale 23.10 - COBIA - RC.1 released with dRAID support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_16n3bpo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_jz78l", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eD9b0eW8RaWcGHLJNaQd_MCH8jTYpS-alvz4xqJwr0w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "truenas", "selftext": "", "author_fullname": "t2_jz78l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Truenas Scale 23.10 - COBIA - RC.1 released with dRAID support", "link_flair_richtext": [], "subreddit_name_prefixed": "r/truenas", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_16n2sig", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "SCALE", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eD9b0eW8RaWcGHLJNaQd_MCH8jTYpS-alvz4xqJwr0w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695158387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "truenas.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?auto=webp&amp;s=d3173fa97c4b79ffa0d7c247c564a285a3d49826", "width": 1999, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f18dee47f6658d0b8337f71005b1544365e0e2de", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb2ca363e1cb21ffd89c5ec1ec41ce65aa8dec04", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=20b7079869410a7926ef0862b30d644321ae6c6c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bafa86a81d086fe1386c4a7355b81ee29e3fe5d6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6f164ac0818c91538ce9b3259ad4e8f75dd7309", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=19c46d5c9b9f5b541d03eecbf1c207362186cecb", "width": 1080, "height": 540}], "variants": {}, "id": "DtooFloJDixg7EB9_jpX05nkPJvBxs1hrPittQcBWJk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "73c79b60-012a-11ec-84c2-3a09d751311e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_zna4k", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0090d5", "id": "16n2sig", "is_robot_indexable": true, "report_reasons": null, "author": "macvirii", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/truenas/comments/16n2sig/truenas_scale_2310_cobia_rc1_released_with_draid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "subreddit_subscribers": 26559, "created_utc": 1695158387.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1695159740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "truenas.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?auto=webp&amp;s=d3173fa97c4b79ffa0d7c247c564a285a3d49826", "width": 1999, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f18dee47f6658d0b8337f71005b1544365e0e2de", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cb2ca363e1cb21ffd89c5ec1ec41ce65aa8dec04", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=20b7079869410a7926ef0862b30d644321ae6c6c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bafa86a81d086fe1386c4a7355b81ee29e3fe5d6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6f164ac0818c91538ce9b3259ad4e8f75dd7309", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/voxzNWxVtf9oIEMxiSDYLwxsv9AyOOrXg6Rk3ldpbzM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=19c46d5c9b9f5b541d03eecbf1c207362186cecb", "width": 1080, "height": 540}], "variants": {}, "id": "DtooFloJDixg7EB9_jpX05nkPJvBxs1hrPittQcBWJk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n3bpo", "is_robot_indexable": true, "report_reasons": null, "author": "macvirii", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_16n2sig", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n3bpo/truenas_scale_2310_cobia_rc1_released_with_draid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.truenas.com/blog/truenas-scale-23-10-rc-1-introduces-draid/", "subreddit_subscribers": 702819, "created_utc": 1695159740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know it's been there decades and I've used it back in the day. But recently I've been trying to download lots of videos together and I have been having lots of issues with Internet Download Manager like downloads failing because of timeouts, security connection establishment failure, etc. so had to manually restart them by starting from scratch again. \n\nIs there anything better out there? Preferably freeware that can handle the workload of downloading lots of files at once. Also, ideally would like something that can somewhat automate the download process if I can point to it what quality of video file to capture from a login site for example 2160p, etc.\n\nWould be great to have any leads out there. I have no technical knowledge so can't do command line, unfortunately.", "author_fullname": "t2_ffjtxxr5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anything better than IDM (Internet Download Manager) out there?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n0wg6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695153936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know it&amp;#39;s been there decades and I&amp;#39;ve used it back in the day. But recently I&amp;#39;ve been trying to download lots of videos together and I have been having lots of issues with Internet Download Manager like downloads failing because of timeouts, security connection establishment failure, etc. so had to manually restart them by starting from scratch again. &lt;/p&gt;\n\n&lt;p&gt;Is there anything better out there? Preferably freeware that can handle the workload of downloading lots of files at once. Also, ideally would like something that can somewhat automate the download process if I can point to it what quality of video file to capture from a login site for example 2160p, etc.&lt;/p&gt;\n\n&lt;p&gt;Would be great to have any leads out there. I have no technical knowledge so can&amp;#39;t do command line, unfortunately.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n0wg6", "is_robot_indexable": true, "report_reasons": null, "author": "101az", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n0wg6/anything_better_than_idm_internet_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n0wg6/anything_better_than_idm_internet_download/", "subreddit_subscribers": 702819, "created_utc": 1695153936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone!\n\nI'm new to this so please go easy on me. I've been trying to digitize my Hi8 tapes from my childhood.  I recently purchased a Sony DCR-TRV315 to connect it via Firewire to my PC, since the original Handycam I have and that all the tapes were recorded on a CCD-TRV99, which doesn't support Firewire. I just bought a PCIE Firewire card and installed it to my computer with the correct drivers. I go to boot up Premiere Pro and go to the Capture tab and it says that the \"capture device is offline\". I've tried messing around in the settings, making sure that it's on DV, even trying to set the device brand and type to the closest Sony handycam. Nothing works for some reason.\n\nI've tried OBS, VirtualDub, and other software but it's not popping up on there either. The IEEE 1394 driver is on legacy and my computer recognizes the Handycam as \"61883 Class Bus Device\"\n\nIf there's anything I may have missed or any other advice that could help resolve this issue, I'd greatly appreciate it. Thank you!", "author_fullname": "t2_12d3xf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sony Digital 8 Handycam not able to record via Firewire", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mzjjd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695150632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m new to this so please go easy on me. I&amp;#39;ve been trying to digitize my Hi8 tapes from my childhood.  I recently purchased a Sony DCR-TRV315 to connect it via Firewire to my PC, since the original Handycam I have and that all the tapes were recorded on a CCD-TRV99, which doesn&amp;#39;t support Firewire. I just bought a PCIE Firewire card and installed it to my computer with the correct drivers. I go to boot up Premiere Pro and go to the Capture tab and it says that the &amp;quot;capture device is offline&amp;quot;. I&amp;#39;ve tried messing around in the settings, making sure that it&amp;#39;s on DV, even trying to set the device brand and type to the closest Sony handycam. Nothing works for some reason.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried OBS, VirtualDub, and other software but it&amp;#39;s not popping up on there either. The IEEE 1394 driver is on legacy and my computer recognizes the Handycam as &amp;quot;61883 Class Bus Device&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;If there&amp;#39;s anything I may have missed or any other advice that could help resolve this issue, I&amp;#39;d greatly appreciate it. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mzjjd", "is_robot_indexable": true, "report_reasons": null, "author": "onvang", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mzjjd/sony_digital_8_handycam_not_able_to_record_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mzjjd/sony_digital_8_handycam_not_able_to_record_via/", "subreddit_subscribers": 702819, "created_utc": 1695150632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[Demo of scraping Zillow, for sale listings](https://i.redd.it/7jkq3j48b9pb1.gif)\n\nHey everyone,\n\nMy friend and I put together a python real estate scraper that aggregates listings from Zillow, Realtor.com &amp; Redfin. It's requests-based, and quite fast (relative to the search size). You can search for rentals, properties for sale, or those recently sold. And it's super easy to output to csv /excel with to\\_csv() or to\\_excel()\n\nFeel free to give feedback in the comments, we would love to hear your suggestions.\n\nhttps://github.com/ZacharyHampton/HomeHarvest", "author_fullname": "t2_cqwm42f0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real estate scraping library for Zillow, Realtor.com &amp; Redfin", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7jkq3j48b9pb1": {"status": "valid", "e": "AnimatedImage", "m": "image/gif", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/7jkq3j48b9pb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=a3dcbbff20a22d059aa0ca4412327d8b304463a8"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/7jkq3j48b9pb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=4a772454f9e81b8469884058387a85b12bd98305"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/7jkq3j48b9pb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=0010f7c672d0bc5f7e6fb271c70671fa9e6374e4"}], "s": {"y": 338, "gif": "https://i.redd.it/7jkq3j48b9pb1.gif", "mp4": "https://preview.redd.it/7jkq3j48b9pb1.gif?format=mp4&amp;s=de3b40625ac9b5e2fde5381b2b26d783d8463c49", "x": 600}, "id": "7jkq3j48b9pb1"}}, "name": "t3_16myrgh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/pFXwO_yHx6Rx7SOoJ3QD0Io6fpTaMHmqFEdyW85D_30.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695148753.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://i.redd.it/7jkq3j48b9pb1.gif\"&gt;Demo of scraping Zillow, for sale listings&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;My friend and I put together a python real estate scraper that aggregates listings from Zillow, Realtor.com &amp;amp; Redfin. It&amp;#39;s requests-based, and quite fast (relative to the search size). You can search for rentals, properties for sale, or those recently sold. And it&amp;#39;s super easy to output to csv /excel with to_csv() or to_excel()&lt;/p&gt;\n\n&lt;p&gt;Feel free to give feedback in the comments, we would love to hear your suggestions.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ZacharyHampton/HomeHarvest\"&gt;https://github.com/ZacharyHampton/HomeHarvest&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16myrgh", "is_robot_indexable": true, "report_reasons": null, "author": "socialretro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16myrgh/real_estate_scraping_library_for_zillow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16myrgh/real_estate_scraping_library_for_zillow/", "subreddit_subscribers": 702819, "created_utc": 1695148753.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone have any advice for having two geographically seprated NAS systems on separate networks back up to each other/stay in sync? For example: if one were in Denver and one were in New York, I want to be able to add/delete/modify files in New York and the changes be synced to the one in Denver or vice versa.", "author_fullname": "t2_ea47g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sync geographcially seprated Synology NAS systems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mx7np", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695144913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any advice for having two geographically seprated NAS systems on separate networks back up to each other/stay in sync? For example: if one were in Denver and one were in New York, I want to be able to add/delete/modify files in New York and the changes be synced to the one in Denver or vice versa.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mx7np", "is_robot_indexable": true, "report_reasons": null, "author": "buhbuhbuhbary", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mx7np/sync_geographcially_seprated_synology_nas_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mx7np/sync_geographcially_seprated_synology_nas_systems/", "subreddit_subscribers": 702819, "created_utc": 1695144913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm relatively new to datahoarding. Still have a *lot* to learn on organization, automation, and hoard management (prior to this, I never touched Linux, RAID, or even basic remote SSH).\n\nI currently have 2x 8TB NVMe SSDs for my own usage, but they're starting to fill up.\n\nUltimately, my goal is to essentially create a shadow library + video server for family, so I'm estimating in the range of 500-700TB+. Probably more after factoring in backups and archiving other stuff (I've seen estimates of a true shadow library being ~500TB). I don't plan to do that all at once (probably over the next 2-4 years), but it shows the importance of having something that is expandable.\n\nWith that future plan, would it be best to just go ahead and get a rack to start with? Or should I start smaller e.g. grab a DS1821+? I may be wrong, but I believe it would be best to start relatively small so things don't get out of hand (5-6x 20TB drives?) and I can learn before just jumping straight to 500TB+.\n\nIf I chose a Synology and later go to upgrade beyond ~8 drives, what issues would I run into? When researching, it seemed like you couldn't combine multiple NAS systems into a single Plex server, or at least it will come with limitations; is that still correct?\n\nOn a somewhat related note, I'm undecided on ZFS vs unRAID vs TrueNAS Scale. Seems like those are the big 3 and what I'd be looking at. My understanding is that ZFS's biggest weakness is that expanding it requires the same number of drives as you start with and the same size or larger capacity. If I started with e.g. 5 drives, does that mean any future upgrade also has to be 5+ drives? If I upgrade with another 5 (10 total), then after that would I have to upgrade with 10 drives or still with just 5 each time? Which of these might be best for this use case?", "author_fullname": "t2_9n9m0a0h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just starting. Internal to my PC, Synology, or just get a rack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mthzm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695135968.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m relatively new to datahoarding. Still have a &lt;em&gt;lot&lt;/em&gt; to learn on organization, automation, and hoard management (prior to this, I never touched Linux, RAID, or even basic remote SSH).&lt;/p&gt;\n\n&lt;p&gt;I currently have 2x 8TB NVMe SSDs for my own usage, but they&amp;#39;re starting to fill up.&lt;/p&gt;\n\n&lt;p&gt;Ultimately, my goal is to essentially create a shadow library + video server for family, so I&amp;#39;m estimating in the range of 500-700TB+. Probably more after factoring in backups and archiving other stuff (I&amp;#39;ve seen estimates of a true shadow library being ~500TB). I don&amp;#39;t plan to do that all at once (probably over the next 2-4 years), but it shows the importance of having something that is expandable.&lt;/p&gt;\n\n&lt;p&gt;With that future plan, would it be best to just go ahead and get a rack to start with? Or should I start smaller e.g. grab a DS1821+? I may be wrong, but I believe it would be best to start relatively small so things don&amp;#39;t get out of hand (5-6x 20TB drives?) and I can learn before just jumping straight to 500TB+.&lt;/p&gt;\n\n&lt;p&gt;If I chose a Synology and later go to upgrade beyond ~8 drives, what issues would I run into? When researching, it seemed like you couldn&amp;#39;t combine multiple NAS systems into a single Plex server, or at least it will come with limitations; is that still correct?&lt;/p&gt;\n\n&lt;p&gt;On a somewhat related note, I&amp;#39;m undecided on ZFS vs unRAID vs TrueNAS Scale. Seems like those are the big 3 and what I&amp;#39;d be looking at. My understanding is that ZFS&amp;#39;s biggest weakness is that expanding it requires the same number of drives as you start with and the same size or larger capacity. If I started with e.g. 5 drives, does that mean any future upgrade also has to be 5+ drives? If I upgrade with another 5 (10 total), then after that would I have to upgrade with 10 drives or still with just 5 each time? Which of these might be best for this use case?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mthzm", "is_robot_indexable": true, "report_reasons": null, "author": "iwantout43545", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mthzm/just_starting_internal_to_my_pc_synology_or_just/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mthzm/just_starting_internal_to_my_pc_synology_or_just/", "subreddit_subscribers": 702819, "created_utc": 1695135968.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "to give a real world example, I have massive collection of screenshots from various websites. I would like to catalog them based on their websites. the logo of said website is usually visible in these screenshots so I want a program that I can search within my local library for a certain logo for example Amazon logo which appear in lots of the screenshots I take for price changes) I want to group all of these photos with Amazon logo together\n\nam I making sense here? \ud83d\ude05 I tried to explain the best I can. Hopefully there is something that works the way I want\n\nthanks", "author_fullname": "t2_bydi8piy8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A photo program that can search by image within the photo collection similar to how Google search engine does it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mrt7o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695132037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;to give a real world example, I have massive collection of screenshots from various websites. I would like to catalog them based on their websites. the logo of said website is usually visible in these screenshots so I want a program that I can search within my local library for a certain logo for example Amazon logo which appear in lots of the screenshots I take for price changes) I want to group all of these photos with Amazon logo together&lt;/p&gt;\n\n&lt;p&gt;am I making sense here? \ud83d\ude05 I tried to explain the best I can. Hopefully there is something that works the way I want&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mrt7o", "is_robot_indexable": true, "report_reasons": null, "author": "happystore1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mrt7o/a_photo_program_that_can_search_by_image_within/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mrt7o/a_photo_program_that_can_search_by_image_within/", "subreddit_subscribers": 702819, "created_utc": 1695132037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So on average I boot my hard drive around 3 to 6 times a day so let average that to 5.\n\nWould leaving your drive on 24/7 wear it more than booting it that many times or are the difference negligible?\n\nAlso when removing drive from docking station, I have to make sure the drive stops spinning completely before touching it, right?\n\nIs there a megathread on good hard drive maintenance practices?", "author_fullname": "t2_uwkgp0yf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "booting VS leaving the drive idle VS storing it unplugged", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mgiq9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.46, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695095195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So on average I boot my hard drive around 3 to 6 times a day so let average that to 5.&lt;/p&gt;\n\n&lt;p&gt;Would leaving your drive on 24/7 wear it more than booting it that many times or are the difference negligible?&lt;/p&gt;\n\n&lt;p&gt;Also when removing drive from docking station, I have to make sure the drive stops spinning completely before touching it, right?&lt;/p&gt;\n\n&lt;p&gt;Is there a megathread on good hard drive maintenance practices?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mgiq9", "is_robot_indexable": true, "report_reasons": null, "author": "bro_aggregate", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mgiq9/booting_vs_leaving_the_drive_idle_vs_storing_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mgiq9/booting_vs_leaving_the_drive_idle_vs_storing_it/", "subreddit_subscribers": 702819, "created_utc": 1695095195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a bunch of data on a miniPC that I'd like to image. It's part of an artwork, so ideally I image the entire thing in a preservation format as opposed to just copying the files wholesale .\n\nI popped it open and saw that it uses a old Samsung mSATA SSD, which I don't have any cables to connect to my write blocker for. The way I see it, I have two options:\n\n1) Purchase an mSATA to USB connector \n2) See if there's a way to image the miniPC via one of its ports (there's several USB ports)\n\nIs #2 even possible? Happy to also try any other suggedtions, or provide more info on the make of the miniPC or the mSATA SSD.\n\nThanks!", "author_fullname": "t2_7ygvo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imaging a miniPC with an mSATA SSD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16md5g1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695085649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bunch of data on a miniPC that I&amp;#39;d like to image. It&amp;#39;s part of an artwork, so ideally I image the entire thing in a preservation format as opposed to just copying the files wholesale .&lt;/p&gt;\n\n&lt;p&gt;I popped it open and saw that it uses a old Samsung mSATA SSD, which I don&amp;#39;t have any cables to connect to my write blocker for. The way I see it, I have two options:&lt;/p&gt;\n\n&lt;p&gt;1) Purchase an mSATA to USB connector \n2) See if there&amp;#39;s a way to image the miniPC via one of its ports (there&amp;#39;s several USB ports)&lt;/p&gt;\n\n&lt;p&gt;Is #2 even possible? Happy to also try any other suggedtions, or provide more info on the make of the miniPC or the mSATA SSD.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16md5g1", "is_robot_indexable": true, "report_reasons": null, "author": "CaravelClerihew", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16md5g1/imaging_a_minipc_with_an_msata_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16md5g1/imaging_a_minipc_with_an_msata_ssd/", "subreddit_subscribers": 702819, "created_utc": 1695085649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What will happen if:\n\n\n5 disk drives from a Nas like Qnap, Synology in raid 5 mode are pulled out and put in a desktop pc with Ubuntu or arch or windows.\n\nCan the data be captured for backup purpose or rescue?\n\nThreat:\nLike if the nas CPU or psu breaks down.\n\nAnd what's a good way to be able to plugin 5 disk drives as a raid array group on a desktop that only has standard 3 sata ports?\n\n Will a split pci board sata work but can all drives be powered using 1 Sata power cable in split mode?\n\n Or does it depends on my power supply?\n\nLike can I just run linux mdadm and force a rebuild and mount the array?", "author_fullname": "t2_9nueq6uq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Raid from a Nas into a desktop pc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16n0nbf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695153343.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What will happen if:&lt;/p&gt;\n\n&lt;p&gt;5 disk drives from a Nas like Qnap, Synology in raid 5 mode are pulled out and put in a desktop pc with Ubuntu or arch or windows.&lt;/p&gt;\n\n&lt;p&gt;Can the data be captured for backup purpose or rescue?&lt;/p&gt;\n\n&lt;p&gt;Threat:\nLike if the nas CPU or psu breaks down.&lt;/p&gt;\n\n&lt;p&gt;And what&amp;#39;s a good way to be able to plugin 5 disk drives as a raid array group on a desktop that only has standard 3 sata ports?&lt;/p&gt;\n\n&lt;p&gt;Will a split pci board sata work but can all drives be powered using 1 Sata power cable in split mode?&lt;/p&gt;\n\n&lt;p&gt;Or does it depends on my power supply?&lt;/p&gt;\n\n&lt;p&gt;Like can I just run linux mdadm and force a rebuild and mount the array?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16n0nbf", "is_robot_indexable": true, "report_reasons": null, "author": "Miserable-Stranger99", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16n0nbf/raid_from_a_nas_into_a_desktop_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16n0nbf/raid_from_a_nas_into_a_desktop_pc/", "subreddit_subscribers": 702819, "created_utc": 1695153343.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "After trialling the product I have just purchased WinCatalog.  I find the searching interface and parameters a little bit clunky as the parameters seem to deviate from the standard searching type that I am used to.  Can anyone recommend a quick tutorial or cheat sheet on using the Search.  Wincatalog help file is a bit wordy when you are trying to do something in a hurry.\n\n&amp;#x200B;", "author_fullname": "t2_mlorovh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WinCatalog Search", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mh31k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695096935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After trialling the product I have just purchased WinCatalog.  I find the searching interface and parameters a little bit clunky as the parameters seem to deviate from the standard searching type that I am used to.  Can anyone recommend a quick tutorial or cheat sheet on using the Search.  Wincatalog help file is a bit wordy when you are trying to do something in a hurry.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mh31k", "is_robot_indexable": true, "report_reasons": null, "author": "jjmagenta", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mh31k/wincatalog_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mh31k/wincatalog_search/", "subreddit_subscribers": 702819, "created_utc": 1695096935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Idk if im weird for this but every time the sd card gets full on my dashcam I don't let it re-write new footage, I hook it up to my pc and dump it on my hard drive.", "author_fullname": "t2_hlypar61", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you hoard dashcam footage from your car?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mcskg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695084657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Idk if im weird for this but every time the sd card gets full on my dashcam I don&amp;#39;t let it re-write new footage, I hook it up to my pc and dump it on my hard drive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "34TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16mcskg", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic_Cup_8436", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16mcskg/do_you_hoard_dashcam_footage_from_your_car/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mcskg/do_you_hoard_dashcam_footage_from_your_car/", "subreddit_subscribers": 702819, "created_utc": 1695084657.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am working on organizing a lot of my files. JohnnyDecimal is working for a lot of documents and other misc file types, but media is eluding me a bit. I have the folder structure I would like, but I'm trying to sort out how to automate collection and folder creation on the NAS.\n\nI use syncthing to pull media files from my phone (and PCs, but they aren't regularly generating like my phone). These dump into an intermediate folder based on source. I would like to have a tool that runs to copy and rename photos to YYYY-MM folders (with ISO 8601 for filenames, maybe with camera source appended), creating a new folder if necessary. This should be based on exif data. Any photo editing/album work will take place from this location, so it's just trying to get it into the right place to start. \n\nI see a lot of tools exist for this, but it appears to be done at the PC level, which is not how I want to run things. Something I can cron would be great, I just don't know enough about coding to do it myself, and I don't know how to do it based on exif. \n\nAny ideas would be great, thank you!", "author_fullname": "t2_mrtze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automated photo/file sorting on a Synology?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mrfxw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695131095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on organizing a lot of my files. JohnnyDecimal is working for a lot of documents and other misc file types, but media is eluding me a bit. I have the folder structure I would like, but I&amp;#39;m trying to sort out how to automate collection and folder creation on the NAS.&lt;/p&gt;\n\n&lt;p&gt;I use syncthing to pull media files from my phone (and PCs, but they aren&amp;#39;t regularly generating like my phone). These dump into an intermediate folder based on source. I would like to have a tool that runs to copy and rename photos to YYYY-MM folders (with ISO 8601 for filenames, maybe with camera source appended), creating a new folder if necessary. This should be based on exif data. Any photo editing/album work will take place from this location, so it&amp;#39;s just trying to get it into the right place to start. &lt;/p&gt;\n\n&lt;p&gt;I see a lot of tools exist for this, but it appears to be done at the PC level, which is not how I want to run things. Something I can cron would be great, I just don&amp;#39;t know enough about coding to do it myself, and I don&amp;#39;t know how to do it based on exif. &lt;/p&gt;\n\n&lt;p&gt;Any ideas would be great, thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mrfxw", "is_robot_indexable": true, "report_reasons": null, "author": "dimensiation", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mrfxw/automated_photofile_sorting_on_a_synology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mrfxw/automated_photofile_sorting_on_a_synology/", "subreddit_subscribers": 702819, "created_utc": 1695131095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Basically, I have a large quantity of data that I'm looking to keep safe for a long time period, like most of us here. I've been using Truenas since 2016 but am thinking about going a different route for various reasons.\n\nI'm thinking of just going to individual disks in an external multi bay usb enclosure with no raid or anything, I do have full offsite backups, but am concerned about silent corruption since if the backup gets corrupt too it's no good. I use Windows 10/11 on my computers, are there any good options for checksumming and verifying files?", "author_fullname": "t2_97alswd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Verifying file integrity or checksumming on Windows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mjzlq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695106857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically, I have a large quantity of data that I&amp;#39;m looking to keep safe for a long time period, like most of us here. I&amp;#39;ve been using Truenas since 2016 but am thinking about going a different route for various reasons.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of just going to individual disks in an external multi bay usb enclosure with no raid or anything, I do have full offsite backups, but am concerned about silent corruption since if the backup gets corrupt too it&amp;#39;s no good. I use Windows 10/11 on my computers, are there any good options for checksumming and verifying files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mjzlq", "is_robot_indexable": true, "report_reasons": null, "author": "tunafishnobread", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mjzlq/verifying_file_integrity_or_checksumming_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mjzlq/verifying_file_integrity_or_checksumming_on/", "subreddit_subscribers": 702819, "created_utc": 1695106857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My hard drives are filling up.  18 TB is my largest drive (SHR-2 with four 18 TB drives and four smaller ones (I think 2x12 and 2x8).\n\nSo it's time to upgrade the 8 TB drives.  I have time.  Can we expect larger than 22 TB drives by years end?  I can't find road maps at all.\n\n&amp;#x200B;\n\nEDIT: I can't find recent roadmaps.  Most are 2 years old saying we should be near 30 TB by now\n\n&amp;#x200B;", "author_fullname": "t2_bw3smwzz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What hard drive sizes can we expect in 2023 (by end of year)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16mqqlq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.36, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695132482.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695129332.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My hard drives are filling up.  18 TB is my largest drive (SHR-2 with four 18 TB drives and four smaller ones (I think 2x12 and 2x8).&lt;/p&gt;\n\n&lt;p&gt;So it&amp;#39;s time to upgrade the 8 TB drives.  I have time.  Can we expect larger than 22 TB drives by years end?  I can&amp;#39;t find road maps at all.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;EDIT: I can&amp;#39;t find recent roadmaps.  Most are 2 years old saying we should be near 30 TB by now&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16mqqlq", "is_robot_indexable": true, "report_reasons": null, "author": "Ragnar-Wave9002", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16mqqlq/what_hard_drive_sizes_can_we_expect_in_2023_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16mqqlq/what_hard_drive_sizes_can_we_expect_in_2023_by/", "subreddit_subscribers": 702819, "created_utc": 1695129332.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}