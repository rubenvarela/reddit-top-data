{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nThere are many DE project posts out there. But they don't explain exactly why a specific approach was chosen. If you are trying to improve your data engineering skills or are the sole data person in your company, it can be hard to know how your technical skills are developing.\n\nWith this in mind, I wrote an article that explains high-level best practices (with links to specific approaches and a project), such as:\n\n1. Using established data processing patterns\n\n2. Data quality checks &amp; code testing\n\n3. Approach to make pipelines Idempotent\n\n4. Metadata for debugging and tracking\n\nI hope the posts explain the underlying concepts behind best practices and when to use them.\n\nBlog: [https://www.startdataengineering.com/post/de\\_best\\_practices/](https://www.startdataengineering.com/post/de_best_practices/)\n\nGitHub Code: [https://github.com/josephmachado/data\\_engineering\\_best\\_practices](https://github.com/josephmachado/data_engineering_best_practices)\n\nI appreciate any questions, feedback, or comments. I hope this helps someone.\n\n&amp;#x200B;", "author_fullname": "t2_5srxspj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering project: Apache Spark, Delta Lake, &amp; Great Expectations running on Docker; Explaining some best practices!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16e4d6v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 98, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 98, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694262027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;There are many DE project posts out there. But they don&amp;#39;t explain exactly why a specific approach was chosen. If you are trying to improve your data engineering skills or are the sole data person in your company, it can be hard to know how your technical skills are developing.&lt;/p&gt;\n\n&lt;p&gt;With this in mind, I wrote an article that explains high-level best practices (with links to specific approaches and a project), such as:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Using established data processing patterns&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data quality checks &amp;amp; code testing&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Approach to make pipelines Idempotent&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Metadata for debugging and tracking&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I hope the posts explain the underlying concepts behind best practices and when to use them.&lt;/p&gt;\n\n&lt;p&gt;Blog: &lt;a href=\"https://www.startdataengineering.com/post/de_best_practices/\"&gt;https://www.startdataengineering.com/post/de_best_practices/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;GitHub Code: &lt;a href=\"https://github.com/josephmachado/data_engineering_best_practices\"&gt;https://github.com/josephmachado/data_engineering_best_practices&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I appreciate any questions, feedback, or comments. I hope this helps someone.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/wsl6YZRW6CI-kerPHLeCEYh-yPLQLYy8fcBAKEkjUc0.jpg?auto=webp&amp;s=c4451d47eef4b4c6375320f1576acbc392ccb35a", "width": 1270, "height": 716}, "resolutions": [{"url": "https://external-preview.redd.it/wsl6YZRW6CI-kerPHLeCEYh-yPLQLYy8fcBAKEkjUc0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8417a2bbe453577d5bd14f0fdfeba8e7d2f4854b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/wsl6YZRW6CI-kerPHLeCEYh-yPLQLYy8fcBAKEkjUc0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=68639fcddff9d247782ede6857b9ed0eaabb347c", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/wsl6YZRW6CI-kerPHLeCEYh-yPLQLYy8fcBAKEkjUc0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=827ee60bc82429ecea18367d295486940ef0e4cd", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/wsl6YZRW6CI-kerPHLeCEYh-yPLQLYy8fcBAKEkjUc0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a6e981978c85a35359f14f34064a9a7aab63554d", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/wsl6YZRW6CI-kerPHLeCEYh-yPLQLYy8fcBAKEkjUc0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=76e74236c097c86237ec30fd14f2820b9b99d4bb", "width": 960, "height": 541}, {"url": "https://external-preview.redd.it/wsl6YZRW6CI-kerPHLeCEYh-yPLQLYy8fcBAKEkjUc0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4f54ae7a9decb33043ce95e131b589093ac562d4", "width": 1080, "height": 608}], "variants": {}, "id": "ZRzmjlwD29o6y4DYt1M7s52D2E2DPvb1Q28Ck4Kl-zw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16e4d6v", "is_robot_indexable": true, "report_reasons": null, "author": "joseph_machado", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16e4d6v/data_engineering_project_apache_spark_delta_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16e4d6v/data_engineering_project_apache_spark_delta_lake/", "subreddit_subscribers": 127672, "created_utc": 1694262027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently a data analyst working in healthcare and looking to move to data engineering. For those of you who moved into the field from something else:\n\n1. What was your previous role?\n2. Why did you move to data engineering\n3. Pros and cons of the move compared to your previous job\n4. Do you regret moving to DE and why if you did\n\nAny info would be much appreciated", "author_fullname": "t2_1eqrbzj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone regret moving to Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16e9iqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694275721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a data analyst working in healthcare and looking to move to data engineering. For those of you who moved into the field from something else:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What was your previous role?&lt;/li&gt;\n&lt;li&gt;Why did you move to data engineering&lt;/li&gt;\n&lt;li&gt;Pros and cons of the move compared to your previous job&lt;/li&gt;\n&lt;li&gt;Do you regret moving to DE and why if you did&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any info would be much appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16e9iqw", "is_robot_indexable": true, "report_reasons": null, "author": "xyzabc123410000", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16e9iqw/does_anyone_regret_moving_to_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16e9iqw/does_anyone_regret_moving_to_data_engineering/", "subreddit_subscribers": 127672, "created_utc": 1694275721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineer at a mid-size, non-tech company, with a relatively small data team. I build pipelines, reporting all the usual stuff. \n\nI report up to a department head who is not technical, and seemingly super disconnected from all development. Really I don't think he would be able to speak to whats actually being worked on, or the commitment requirements apart from the very high level (like literally just project names he hears in scrum). \n\nWe have a packed annual corporate project plan which keeps us super busy on top of constant ad hoc requests from the business. I keep reading about leaders who support their teams by buffering out constant requests and scope creep from the business, allowing the technical team to focus on executing. Our leader does the exact opposite. \n\nThey are constantly sending 'high priority' requests on behalf of other departments etc. with really no context or understanding of whats being asked for, or the time required. As usually every business group thinks their request is *the most urgent,* and they dont temper expectations or anything. They will hop into a project meeting that they haven't been to in ages and start throwing out random ideas to the business users, saying \"we can do x, y, and z\" which are all way outside of scope and don't really make sense.   \n\nBasically, we're too damn busy to deal with this lol. Any advice on what I should do here or how I should handle this overall would be greatly appreciated. \n\n I 100% want to succeed and excel, and can definitely deal with a bit of suck it up and grind it out when needed, but this just seems so poorly planned, poorly organized, and so duuumb.\n\nLove you all \n\n&amp;#x200B;", "author_fullname": "t2_8anpx1wu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Boss is the opposite of a buffer for constant requests and scope creep, advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16dx5fj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694236631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineer at a mid-size, non-tech company, with a relatively small data team. I build pipelines, reporting all the usual stuff. &lt;/p&gt;\n\n&lt;p&gt;I report up to a department head who is not technical, and seemingly super disconnected from all development. Really I don&amp;#39;t think he would be able to speak to whats actually being worked on, or the commitment requirements apart from the very high level (like literally just project names he hears in scrum). &lt;/p&gt;\n\n&lt;p&gt;We have a packed annual corporate project plan which keeps us super busy on top of constant ad hoc requests from the business. I keep reading about leaders who support their teams by buffering out constant requests and scope creep from the business, allowing the technical team to focus on executing. Our leader does the exact opposite. &lt;/p&gt;\n\n&lt;p&gt;They are constantly sending &amp;#39;high priority&amp;#39; requests on behalf of other departments etc. with really no context or understanding of whats being asked for, or the time required. As usually every business group thinks their request is &lt;em&gt;the most urgent,&lt;/em&gt; and they dont temper expectations or anything. They will hop into a project meeting that they haven&amp;#39;t been to in ages and start throwing out random ideas to the business users, saying &amp;quot;we can do x, y, and z&amp;quot; which are all way outside of scope and don&amp;#39;t really make sense.   &lt;/p&gt;\n\n&lt;p&gt;Basically, we&amp;#39;re too damn busy to deal with this lol. Any advice on what I should do here or how I should handle this overall would be greatly appreciated. &lt;/p&gt;\n\n&lt;p&gt;I 100% want to succeed and excel, and can definitely deal with a bit of suck it up and grind it out when needed, but this just seems so poorly planned, poorly organized, and so duuumb.&lt;/p&gt;\n\n&lt;p&gt;Love you all &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16dx5fj", "is_robot_indexable": true, "report_reasons": null, "author": "Yuzuwater", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dx5fj/boss_is_the_opposite_of_a_buffer_for_constant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dx5fj/boss_is_the_opposite_of_a_buffer_for_constant/", "subreddit_subscribers": 127672, "created_utc": 1694236631.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a DE at an AWS shop writing Pyspark pipelines all day long and very much enjoy it. DEs here mostly just develop ETL code and push up their docker images. We have a separate Infra,DevOps and Developer Experience team that has set up end-to-end platform over the years. \n\nNow I want to expand my skillset into being able to write end-to-end Data platforms. Do you have good learning resource recommendations Or perhaps a project showcasing how to do this at production level? If not, I'd at least love to get a learning plan.", "author_fullname": "t2_g4v8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some good resources to learn core Data platform engineering and DataOps?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16eltza", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694305963.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a DE at an AWS shop writing Pyspark pipelines all day long and very much enjoy it. DEs here mostly just develop ETL code and push up their docker images. We have a separate Infra,DevOps and Developer Experience team that has set up end-to-end platform over the years. &lt;/p&gt;\n\n&lt;p&gt;Now I want to expand my skillset into being able to write end-to-end Data platforms. Do you have good learning resource recommendations Or perhaps a project showcasing how to do this at production level? If not, I&amp;#39;d at least love to get a learning plan.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16eltza", "is_robot_indexable": true, "report_reasons": null, "author": "swapripper", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16eltza/what_are_some_good_resources_to_learn_core_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16eltza/what_are_some_good_resources_to_learn_core_data/", "subreddit_subscribers": 127672, "created_utc": 1694305963.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, I'm a data analyst trying to strengthen my pipeline skills. Setting up an environment is tough, so I figured I'd use this as a chance to leverage docker.\n\nThe problem I'm having is looking for a good docker image to use for a data eng environment. I was hoping to do a project where I access Spotify data via and API and store it into json files in an S3 bucket and have a separate script to read clean and import it into a DW. Then have it all orchestrated by Dagster.\n\nBut I don't really know what image to use or trust. Any recommendations?", "author_fullname": "t2_qcvr2y7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Docker Images are you using for your local development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ej31k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694299046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I&amp;#39;m a data analyst trying to strengthen my pipeline skills. Setting up an environment is tough, so I figured I&amp;#39;d use this as a chance to leverage docker.&lt;/p&gt;\n\n&lt;p&gt;The problem I&amp;#39;m having is looking for a good docker image to use for a data eng environment. I was hoping to do a project where I access Spotify data via and API and store it into json files in an S3 bucket and have a separate script to read clean and import it into a DW. Then have it all orchestrated by Dagster.&lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t really know what image to use or trust. Any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ej31k", "is_robot_indexable": true, "report_reasons": null, "author": "Own_Efficiency_1443", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ej31k/what_docker_images_are_you_using_for_your_local/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ej31k/what_docker_images_are_you_using_for_your_local/", "subreddit_subscribers": 127672, "created_utc": 1694299046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I just want to use an IMAP connector and stream certain emails to block storage, while making sure to avoid any forwarded or reply emails.\n\nI figure Kafka can do this, but is Kafka the right choice? \n\nI\u2019m just trying to feel this out as I\u2019m new to stream processing and I figure I want this email project to be the first thing I do.", "author_fullname": "t2_83g1niecs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wanting to stream emails from a folder into block storage, with some filtering. Should I use Kafka?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16dxcjb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694237299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just want to use an IMAP connector and stream certain emails to block storage, while making sure to avoid any forwarded or reply emails.&lt;/p&gt;\n\n&lt;p&gt;I figure Kafka can do this, but is Kafka the right choice? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m just trying to feel this out as I\u2019m new to stream processing and I figure I want this email project to be the first thing I do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16dxcjb", "is_robot_indexable": true, "report_reasons": null, "author": "_unbanned_datum", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dxcjb/wanting_to_stream_emails_from_a_folder_into_block/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dxcjb/wanting_to_stream_emails_from_a_folder_into_block/", "subreddit_subscribers": 127672, "created_utc": 1694237299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was testing this AWS Zero-ETL Integration from Aurora-MySQL to Redshift and I am so confused and disappointed! My Aurora-MySQL db is 10TB and it would be nice if it could be pushed to Redshift through this zero-etl integration. I tried to follow the documentation (set up a redshift preview cluster and zero-etl integration) and I think I got it right. But when I tried to run the zero-etl integration, it just kept spinning and I don't know why. It is just frustrating and then I could not even delete both the zero-etl integration and redshift cluster. So, has anybody gotten this feature to work?  \n\n\n&amp;#x200B;", "author_fullname": "t2_bgia4b7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Zero-ETL Integration Feedback", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ebg51", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694280520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was testing this AWS Zero-ETL Integration from Aurora-MySQL to Redshift and I am so confused and disappointed! My Aurora-MySQL db is 10TB and it would be nice if it could be pushed to Redshift through this zero-etl integration. I tried to follow the documentation (set up a redshift preview cluster and zero-etl integration) and I think I got it right. But when I tried to run the zero-etl integration, it just kept spinning and I don&amp;#39;t know why. It is just frustrating and then I could not even delete both the zero-etl integration and redshift cluster. So, has anybody gotten this feature to work?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ebg51", "is_robot_indexable": true, "report_reasons": null, "author": "chiphelsea4", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ebg51/aws_zeroetl_integration_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ebg51/aws_zeroetl_integration_feedback/", "subreddit_subscribers": 127672, "created_utc": 1694280520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI want to learn the MLOps best practices on GCP.  \nI have gone over multiples resources Coursera/YouTube/Blogs about Tensorflow Extended and Kubeflow.  \nI feel a bit confused.\n\nI understand that the GCP way is to define the ML pipeline with TFX by using the predefined modules (such as CsvExampleGen, StatisticsGen, ExampleValidator, etc...) and then orchestrate the whole pipeline with Kubeflow.\n\nBy doing so, doesn't it mean as a MLOps person I would need to re-write all the code written by the data scientists (in Pandas) using TFX modules?   \nWouldn't it be more convenient to use \"raw\" Kubeflow and simply refactor the code break it down into Kubeflow components?   \nDoes TFX running on Vertex AI bring a lot of value compared to \"raw\" Kubeflow?\n\nI guess my question is would you suggest TFX + Kubeflow or only Kubeflow.\n\nThanks in advance!", "author_fullname": "t2_3wj092gm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MLOps on GCP Vertex AI -TFX &amp; Kubeflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ejvrw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694300979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I want to learn the MLOps best practices on GCP.&lt;br/&gt;\nI have gone over multiples resources Coursera/YouTube/Blogs about Tensorflow Extended and Kubeflow.&lt;br/&gt;\nI feel a bit confused.&lt;/p&gt;\n\n&lt;p&gt;I understand that the GCP way is to define the ML pipeline with TFX by using the predefined modules (such as CsvExampleGen, StatisticsGen, ExampleValidator, etc...) and then orchestrate the whole pipeline with Kubeflow.&lt;/p&gt;\n\n&lt;p&gt;By doing so, doesn&amp;#39;t it mean as a MLOps person I would need to re-write all the code written by the data scientists (in Pandas) using TFX modules?&lt;br/&gt;\nWouldn&amp;#39;t it be more convenient to use &amp;quot;raw&amp;quot; Kubeflow and simply refactor the code break it down into Kubeflow components?&lt;br/&gt;\nDoes TFX running on Vertex AI bring a lot of value compared to &amp;quot;raw&amp;quot; Kubeflow?&lt;/p&gt;\n\n&lt;p&gt;I guess my question is would you suggest TFX + Kubeflow or only Kubeflow.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ejvrw", "is_robot_indexable": true, "report_reasons": null, "author": "yinshangyi", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ejvrw/mlops_on_gcp_vertex_ai_tfx_kubeflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ejvrw/mlops_on_gcp_vertex_ai_tfx_kubeflow/", "subreddit_subscribers": 127672, "created_utc": 1694300979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New to the channel, maybe my probation period is over as I have a question.\n\nSimply my question is:  \n1) Has anybody experience of using Dagster Cloud and also having a backup/plan-B for on-prem?\n\n2) How do you cost running on-prem yourself compared to Cloud?\n\nMore details:\n\nI am building a new pipeline to process thousands of cXML files into a DW.  We are mostly Airflow user, but for the new project we decided to upgrade and are using Dagster. We found Dagster to be amazing for the Data Asset approach, and our team are heavily using Dagster deployments for CI/CD. The costs for Dagster Cloud right now are very small but would grow with usage.\n\nWe are thinking once the main development is done, we might not need such a powerful CI/CD tool, and then we could move Dagster to on-prem with open source and host the system ourselves. Also with EU regulations we might need to move our project to our private cloud as we scale. Also all vendor tool pricing seems unpredictable (like dbt).\n\nHas anybody done this? What would you really miss in daily work not having Dagster Cloud?  \nI need to write a cost comparison of Cloud compared to self-hosting.  How to calculate all hidden cost (time) or managing Dagster ourself?", "author_fullname": "t2_i2z3iuo98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Cloud &amp; Plan B on-prem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ec0dd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694281897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New to the channel, maybe my probation period is over as I have a question.&lt;/p&gt;\n\n&lt;p&gt;Simply my question is:&lt;br/&gt;\n1) Has anybody experience of using Dagster Cloud and also having a backup/plan-B for on-prem?&lt;/p&gt;\n\n&lt;p&gt;2) How do you cost running on-prem yourself compared to Cloud?&lt;/p&gt;\n\n&lt;p&gt;More details:&lt;/p&gt;\n\n&lt;p&gt;I am building a new pipeline to process thousands of cXML files into a DW.  We are mostly Airflow user, but for the new project we decided to upgrade and are using Dagster. We found Dagster to be amazing for the Data Asset approach, and our team are heavily using Dagster deployments for CI/CD. The costs for Dagster Cloud right now are very small but would grow with usage.&lt;/p&gt;\n\n&lt;p&gt;We are thinking once the main development is done, we might not need such a powerful CI/CD tool, and then we could move Dagster to on-prem with open source and host the system ourselves. Also with EU regulations we might need to move our project to our private cloud as we scale. Also all vendor tool pricing seems unpredictable (like dbt).&lt;/p&gt;\n\n&lt;p&gt;Has anybody done this? What would you really miss in daily work not having Dagster Cloud?&lt;br/&gt;\nI need to write a cost comparison of Cloud compared to self-hosting.  How to calculate all hidden cost (time) or managing Dagster ourself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ec0dd", "is_robot_indexable": true, "report_reasons": null, "author": "vbnotthecity", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ec0dd/dagster_cloud_plan_b_onprem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ec0dd/dagster_cloud_plan_b_onprem/", "subreddit_subscribers": 127672, "created_utc": 1694281897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Blog post is out, sharing how to solve challenges related to spark testing, including both unit and regression testing. Special Mention of spark open source testing libraries by MrPowers.\n\nhttps://www.junaideffendi.com/blog/testing-data-in-apache-spark/\n\nLet me know how you perform testing.", "author_fullname": "t2_dhgy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing Data in Apache Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16eav23", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694279047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Blog post is out, sharing how to solve challenges related to spark testing, including both unit and regression testing. Special Mention of spark open source testing libraries by MrPowers.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.junaideffendi.com/blog/testing-data-in-apache-spark/\"&gt;https://www.junaideffendi.com/blog/testing-data-in-apache-spark/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Let me know how you perform testing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/G3LkfMFa-ZT0-Ghctl_HbWIkBfQaHzYTtceghJ3WXSU.jpg?auto=webp&amp;s=8ba655d6b4e9e5ad6b6de7dc2fd5cab5f47d1ed8", "width": 2000, "height": 1333}, "resolutions": [{"url": "https://external-preview.redd.it/G3LkfMFa-ZT0-Ghctl_HbWIkBfQaHzYTtceghJ3WXSU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=97180977b6417e7cd07ed72006fc32fcbe1d8aed", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/G3LkfMFa-ZT0-Ghctl_HbWIkBfQaHzYTtceghJ3WXSU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=719cb846a641f15f6bb3eb6649340634dc0ec07c", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/G3LkfMFa-ZT0-Ghctl_HbWIkBfQaHzYTtceghJ3WXSU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5a4c7fa198c08ad34c9ae552bf107abea61bbc8d", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/G3LkfMFa-ZT0-Ghctl_HbWIkBfQaHzYTtceghJ3WXSU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e29e03a933a928ddaa6fe3b2ab0993b53a89a7db", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/G3LkfMFa-ZT0-Ghctl_HbWIkBfQaHzYTtceghJ3WXSU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=37da2d6f9ebe4e519121831c35879f978c317424", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/G3LkfMFa-ZT0-Ghctl_HbWIkBfQaHzYTtceghJ3WXSU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=439666adb80b44debf93914aa21c5cf6639574db", "width": 1080, "height": 719}], "variants": {}, "id": "s2VvemkhdM8TjWxv2oJo1YYMHh7a89FogLjqj6pTUYg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16eav23", "is_robot_indexable": true, "report_reasons": null, "author": "mjfnd", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16eav23/testing_data_in_apache_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16eav23/testing_data_in_apache_spark/", "subreddit_subscribers": 127672, "created_utc": 1694279047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got a lambda function (py310) and I use pyscopg2 which I installed using pip install aws-psycopg2 and added the layer successfully.\n\n&amp;#x200B;\n\nI'm able to import the library in my lambda function which is good, but when i try to actually connect to the postgres database that I've got in RDS I get the following error:\n\nDatabase connection failed due to SCRAM authentication requires libpq version 10 or above\n\nI never received this error before and I used py310 and the layer on a previous lambda function. I'm not sure but I think that lambda function might've gotten messed up too now... I don't know how exactly. I did tinker around a bit with VPC, subnets, security groups and all that stuff so is it possible that might've messed it up?\n\n&amp;#x200B;\n\nBecause upon searching a bit on google I found that it's the libraries problem (psycopg2) not necessarily anything related to networking. Any ideas?", "author_fullname": "t2_5692by6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Issue connecting AWS Lambda function to Postgres hosted in AWS RDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ehrab", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694295868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a lambda function (py310) and I use pyscopg2 which I installed using pip install aws-psycopg2 and added the layer successfully.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m able to import the library in my lambda function which is good, but when i try to actually connect to the postgres database that I&amp;#39;ve got in RDS I get the following error:&lt;/p&gt;\n\n&lt;p&gt;Database connection failed due to SCRAM authentication requires libpq version 10 or above&lt;/p&gt;\n\n&lt;p&gt;I never received this error before and I used py310 and the layer on a previous lambda function. I&amp;#39;m not sure but I think that lambda function might&amp;#39;ve gotten messed up too now... I don&amp;#39;t know how exactly. I did tinker around a bit with VPC, subnets, security groups and all that stuff so is it possible that might&amp;#39;ve messed it up?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Because upon searching a bit on google I found that it&amp;#39;s the libraries problem (psycopg2) not necessarily anything related to networking. Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ehrab", "is_robot_indexable": true, "report_reasons": null, "author": "anasp1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ehrab/issue_connecting_aws_lambda_function_to_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ehrab/issue_connecting_aws_lambda_function_to_postgres/", "subreddit_subscribers": 127672, "created_utc": 1694295868.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can anyone help me with best online resources to learn TALEND from Scratch...? ", "author_fullname": "t2_3x106z0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Resources to Learn TALEND", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16e10hp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694250264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone help me with best online resources to learn TALEND from Scratch...? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16e10hp", "is_robot_indexable": true, "report_reasons": null, "author": "sanjeevj11", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16e10hp/need_resources_to_learn_talend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16e10hp/need_resources_to_learn_talend/", "subreddit_subscribers": 127672, "created_utc": 1694250264.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}