{"kind": "Listing", "data": {"after": null, "dist": 18, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've read \"Fundamentals of Data Engineering\" by Reis. However, as the name says that book covers the fundamentals. There are loads of books on software engineering design patterns in general. Not for data engineering in my knowledge.\n\nI'm looking for a great book that goes through the popular data architecture patterns end-to-end. With code samples. Googled, but didn't find anything particularly exciting. Just a few blog posts. Which books do you folks suggest as essential reading for a data engineer?", "author_fullname": "t2_pblux6w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a great book on design patterns in data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rxj7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 94, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 94, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695661129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve read &amp;quot;Fundamentals of Data Engineering&amp;quot; by Reis. However, as the name says that book covers the fundamentals. There are loads of books on software engineering design patterns in general. Not for data engineering in my knowledge.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a great book that goes through the popular data architecture patterns end-to-end. With code samples. Googled, but didn&amp;#39;t find anything particularly exciting. Just a few blog posts. Which books do you folks suggest as essential reading for a data engineer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16rxj7v", "is_robot_indexable": true, "report_reasons": null, "author": "newplayer12345", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rxj7v/is_there_a_great_book_on_design_patterns_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rxj7v/is_there_a_great_book_on_design_patterns_in_data/", "subreddit_subscribers": 130479, "created_utc": 1695661129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As in title. I feel stuck in my current job. Big corp. I do little to no coding, working mainly with a custom tool on a high level, creating low-code pipelines. Of course I write SQLs, but nothing special, most of the logic is plain simple. I sometimes touch some services on a backend, but without any deep dive. Most pipelines load data to Snowflake, but I don't work too much with it, the external team does it, I am just working on data loads. A lot of formalities behind each deployment that it gets really tedious. Ad-hoc requests that I need to address, mostly some bull. A lot of manual tests for data validation.\n\nDoes it look anything like it at your side? I feel like I regress at my job. I sometimes read how much fancy stuff people are doing and I envy them somewhat, on the other hand a lot of DE jobs seem to look just like that. The market sucks and the job is stable, but I really wonder if I could do better.  \n\n\nIf you feel that you progress at your job, tell me, what are you doing?\n\n&amp;#x200B;", "author_fullname": "t2_9e7m1qmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What sort of jobs are dead-end for data engineers in terms of growth opportunities? And what jobs actually provide it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16smma8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695731520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As in title. I feel stuck in my current job. Big corp. I do little to no coding, working mainly with a custom tool on a high level, creating low-code pipelines. Of course I write SQLs, but nothing special, most of the logic is plain simple. I sometimes touch some services on a backend, but without any deep dive. Most pipelines load data to Snowflake, but I don&amp;#39;t work too much with it, the external team does it, I am just working on data loads. A lot of formalities behind each deployment that it gets really tedious. Ad-hoc requests that I need to address, mostly some bull. A lot of manual tests for data validation.&lt;/p&gt;\n\n&lt;p&gt;Does it look anything like it at your side? I feel like I regress at my job. I sometimes read how much fancy stuff people are doing and I envy them somewhat, on the other hand a lot of DE jobs seem to look just like that. The market sucks and the job is stable, but I really wonder if I could do better.  &lt;/p&gt;\n\n&lt;p&gt;If you feel that you progress at your job, tell me, what are you doing?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16smma8", "is_robot_indexable": true, "report_reasons": null, "author": "LewWariat", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16smma8/what_sort_of_jobs_are_deadend_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16smma8/what_sort_of_jobs_are_deadend_for_data_engineers/", "subreddit_subscribers": 130479, "created_utc": 1695731520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a great use case for Debezium but we don't run Kafka. Any alternatives for change data capture with mysql out there? The end goal is replication of certain changes in 1 DB to another in \"real time\".", "author_fullname": "t2_gua18k7sg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any alternatives to Debezium that don't rely on Kafka?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16sagq5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695692419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a great use case for Debezium but we don&amp;#39;t run Kafka. Any alternatives for change data capture with mysql out there? The end goal is replication of certain changes in 1 DB to another in &amp;quot;real time&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16sagq5", "is_robot_indexable": true, "report_reasons": null, "author": "alexcontrerasdppl", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16sagq5/any_alternatives_to_debezium_that_dont_rely_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16sagq5/any_alternatives_to_debezium_that_dont_rely_on/", "subreddit_subscribers": 130479, "created_utc": 1695692419.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Last time I had to worry about such a tool was almost 7 years ago, and back then I relied on Flyway for schema change management. What type of schema change management tools do you use? My requirements are basic: change, and roll back if needed. Thx", "author_fullname": "t2_5tktq9ud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What type of database versioning/schema change management tool do you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16sej06", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695704436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last time I had to worry about such a tool was almost 7 years ago, and back then I relied on Flyway for schema change management. What type of schema change management tools do you use? My requirements are basic: change, and roll back if needed. Thx&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16sej06", "is_robot_indexable": true, "report_reasons": null, "author": "zoobeezee", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16sej06/what_type_of_database_versioningschema_change/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16sej06/what_type_of_database_versioningschema_change/", "subreddit_subscribers": 130479, "created_utc": 1695704436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am doing a capstone on Log Anomaly detection for a digital sign board manufacturer. We have 17,000 log files(300GB) from over 2500 devices. The sponsor would like us to cluster them based on log patterns. how should I think modeling such data? Unfortunately I don't get access to any paid tools or services. Your suggestions would be valuable. thanks.", "author_fullname": "t2_c9dcr4wt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modeling 17k log files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16s25nl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695671889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am doing a capstone on Log Anomaly detection for a digital sign board manufacturer. We have 17,000 log files(300GB) from over 2500 devices. The sponsor would like us to cluster them based on log patterns. how should I think modeling such data? Unfortunately I don&amp;#39;t get access to any paid tools or services. Your suggestions would be valuable. thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16s25nl", "is_robot_indexable": true, "report_reasons": null, "author": "sigapuranger", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16s25nl/modeling_17k_log_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16s25nl/modeling_17k_log_files/", "subreddit_subscribers": 130479, "created_utc": 1695671889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello!\n\nAt my workplace, we have a data warehouse, and we're looking to begin using the DBT tool to manage our transformations. However, from what I've gathered, DBT seems to be primarily designed for ELT pipelines. Currently, our pipeline involves a Python script managed via Airflow, which executes some SQL directly on our production DBT.\n\nMy question is, how can I implement a form of ELT with PostgreSQL as our data warehouse? I'm not sure if there's an effective way to organize this structure within PostgreSQL, or if there's something I might be overlooking.", "author_fullname": "t2_8jc0mwfh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using postgresql data warehouse with ELT pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rwtvd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695659481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;At my workplace, we have a data warehouse, and we&amp;#39;re looking to begin using the DBT tool to manage our transformations. However, from what I&amp;#39;ve gathered, DBT seems to be primarily designed for ELT pipelines. Currently, our pipeline involves a Python script managed via Airflow, which executes some SQL directly on our production DBT.&lt;/p&gt;\n\n&lt;p&gt;My question is, how can I implement a form of ELT with PostgreSQL as our data warehouse? I&amp;#39;m not sure if there&amp;#39;s an effective way to organize this structure within PostgreSQL, or if there&amp;#39;s something I might be overlooking.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16rwtvd", "is_robot_indexable": true, "report_reasons": null, "author": "Andremallmann", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rwtvd/using_postgresql_data_warehouse_with_elt_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rwtvd/using_postgresql_data_warehouse_with_elt_pipelines/", "subreddit_subscribers": 130479, "created_utc": 1695659481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TLDR;  checking if \"streaming\" with Postgres is a reasonable idea, given the throughput ( &lt; 10 updates / second) on a small amount of data (&lt; 100 mb).  \n\n\n# Functional Requirements:\n\nMy team has a custom compiled binary that is subscribed to stream of events, computes some outputs, and dumps them to a data sink process. The business logic for the streaming computation is written in a custom DSL and represents a time series transformation. This was written way before things like flink, kafka streams etc existed and has served production well over the years, but could use a little face lift, especially in terms of provenance to understand what inputs when into calculation outputs.  \n\n\n# Non-Functional Requirements:\n\nIt's a very small workload, hardly what someone would call streaming.\n\n1. 10 events / second\n2. 10mb of data\n3. 1s p99 update delay tolerable\n4. \\~ 10 large queries (100 numeric inputs), continuously refreshing. Each query only has 1-2 inputs that are actually constantly changing.\n5. No lock contention amongst the queries. They're independent of each other.  \n\n\n# Postgres Streaming solution:\n\nMy idea is to push the computation and state into Postgres as Flink and Kafka seem like overkill. The data will be modeled as a temporal table to keep a full snapshot of the history.  That way I get the following:\n\n1. High availability out of the box instead of handwritten leader election code\n2. All of the state is persisted. I can inspect the history of the state for provenance purposes using a temporal query.\n3. Rely on mature SQL computation engine instead of an esoteric, unoptimized DSL and runtime\n4. Time partitioning to keep the hot data ( &lt;100 kb ) in memory.\n5. My event processor is now stateless and has a simple job of triggering a postgres insert + update. The query will be compiled to avoid parsing and interpretation overhead.\n6. (Bonus) I can throw away a lot of custom code for a bunch of simple dbt templates as postgres now does all the heavy lifting.\n\nIt does feel weird to use postgres as a streaming engine, but people have pushed databases to handle way more concurrency on way larger data sets. Based on my napkin math, I think this barely qualifies as streaming, as the database would spend most of it's time waiting for work.", "author_fullname": "t2_2naya68b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming on Postgres idea check", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16sazes", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695693821.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR;  checking if &amp;quot;streaming&amp;quot; with Postgres is a reasonable idea, given the throughput ( &amp;lt; 10 updates / second) on a small amount of data (&amp;lt; 100 mb).  &lt;/p&gt;\n\n&lt;h1&gt;Functional Requirements:&lt;/h1&gt;\n\n&lt;p&gt;My team has a custom compiled binary that is subscribed to stream of events, computes some outputs, and dumps them to a data sink process. The business logic for the streaming computation is written in a custom DSL and represents a time series transformation. This was written way before things like flink, kafka streams etc existed and has served production well over the years, but could use a little face lift, especially in terms of provenance to understand what inputs when into calculation outputs.  &lt;/p&gt;\n\n&lt;h1&gt;Non-Functional Requirements:&lt;/h1&gt;\n\n&lt;p&gt;It&amp;#39;s a very small workload, hardly what someone would call streaming.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;10 events / second&lt;/li&gt;\n&lt;li&gt;10mb of data&lt;/li&gt;\n&lt;li&gt;1s p99 update delay tolerable&lt;/li&gt;\n&lt;li&gt;~ 10 large queries (100 numeric inputs), continuously refreshing. Each query only has 1-2 inputs that are actually constantly changing.&lt;/li&gt;\n&lt;li&gt;No lock contention amongst the queries. They&amp;#39;re independent of each other.&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Postgres Streaming solution:&lt;/h1&gt;\n\n&lt;p&gt;My idea is to push the computation and state into Postgres as Flink and Kafka seem like overkill. The data will be modeled as a temporal table to keep a full snapshot of the history.  That way I get the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;High availability out of the box instead of handwritten leader election code&lt;/li&gt;\n&lt;li&gt;All of the state is persisted. I can inspect the history of the state for provenance purposes using a temporal query.&lt;/li&gt;\n&lt;li&gt;Rely on mature SQL computation engine instead of an esoteric, unoptimized DSL and runtime&lt;/li&gt;\n&lt;li&gt;Time partitioning to keep the hot data ( &amp;lt;100 kb ) in memory.&lt;/li&gt;\n&lt;li&gt;My event processor is now stateless and has a simple job of triggering a postgres insert + update. The query will be compiled to avoid parsing and interpretation overhead.&lt;/li&gt;\n&lt;li&gt;(Bonus) I can throw away a lot of custom code for a bunch of simple dbt templates as postgres now does all the heavy lifting.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;It does feel weird to use postgres as a streaming engine, but people have pushed databases to handle way more concurrency on way larger data sets. Based on my napkin math, I think this barely qualifies as streaming, as the database would spend most of it&amp;#39;s time waiting for work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16sazes", "is_robot_indexable": true, "report_reasons": null, "author": "shuaibot", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16sazes/streaming_on_postgres_idea_check/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16sazes/streaming_on_postgres_idea_check/", "subreddit_subscribers": 130479, "created_utc": 1695693821.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For those of us who believe in the power of event-driven architectures and data streaming, you might be interested in our new open-source project: LangStream. It is an open-source framework for building event-driven Gen AI applications that combines LLMs, vector databases, Kubernetes, and Apache Kafka.  \n\n\nLangStream supports all Kafka connectors out of the box. You can just point to the JAR for a connector and use it as part of a Gen AI pipeline.\n\nFind out more here:\n\n[https://langstream.ai/2023/09/13/introducing-langstream/](https://langstream.ai/2023/09/13/introducing-langstream/)\n\nIf you find it interesting, please star the repo: [https://github.com/LangStream/langstream](https://github.com/LangStream/langstream)", "author_fullname": "t2_8nsm8c43", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New project: LangStream for building and running event-driven LLM applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rxyye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695662103.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For those of us who believe in the power of event-driven architectures and data streaming, you might be interested in our new open-source project: LangStream. It is an open-source framework for building event-driven Gen AI applications that combines LLMs, vector databases, Kubernetes, and Apache Kafka.  &lt;/p&gt;\n\n&lt;p&gt;LangStream supports all Kafka connectors out of the box. You can just point to the JAR for a connector and use it as part of a Gen AI pipeline.&lt;/p&gt;\n\n&lt;p&gt;Find out more here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://langstream.ai/2023/09/13/introducing-langstream/\"&gt;https://langstream.ai/2023/09/13/introducing-langstream/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you find it interesting, please star the repo: &lt;a href=\"https://github.com/LangStream/langstream\"&gt;https://github.com/LangStream/langstream&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NG_01PXp8iHDS_CdGx1Yq8HNtjMg7HUOlNjPoHNF0O8.jpg?auto=webp&amp;s=7d52f2f9bf64f49aae414fb6550354d29f1df798", "width": 500, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/NG_01PXp8iHDS_CdGx1Yq8HNtjMg7HUOlNjPoHNF0O8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8201a0b8f9ad3dfaa0dd0562f736ae1f1110d64b", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/NG_01PXp8iHDS_CdGx1Yq8HNtjMg7HUOlNjPoHNF0O8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cdf3e5c6350961e9b3000a9b5f1c27665490c0e5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/NG_01PXp8iHDS_CdGx1Yq8HNtjMg7HUOlNjPoHNF0O8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b0c34ddc1ab9d49bd200f7fcac070c9b39339de0", "width": 320, "height": 320}], "variants": {}, "id": "HwttWOvzTbyp1qu4I_z2JJSOGfJjcyFvmlF5NnjzRKc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16rxyye", "is_robot_indexable": true, "report_reasons": null, "author": "Head_Reaction_6242", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rxyye/new_project_langstream_for_building_and_running/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rxyye/new_project_langstream_for_building_and_running/", "subreddit_subscribers": 130479, "created_utc": 1695662103.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for suggestions that you consider fundamental/useful to any DE.", "author_fullname": "t2_2tv9i42n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What whitepapers should every data engineer read?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16snd4x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": "#46d160", "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fd5b074e-239e-11e8-a28b-0e0f8d9eda5a", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "mod", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695733334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for suggestions that you consider fundamental/useful to any DE.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "mod | Lead Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16snd4x", "is_robot_indexable": true, "report_reasons": null, "author": "theporterhaus", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "light", "permalink": "/r/dataengineering/comments/16snd4x/what_whitepapers_should_every_data_engineer_read/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16snd4x/what_whitepapers_should_every_data_engineer_read/", "subreddit_subscribers": 130479, "created_utc": 1695733334.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have always been curious has to how different it is to be a DE in the sports industry when compared to a tech/consulting company? Do you view the usage of tools and overall architecture similarly? Do you have opportunities to learn and grow? How are your peers around you and do you have a WLB?", "author_fullname": "t2_u0ewxlrb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is it working as a DE in the sports industry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16sdlq8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695701474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have always been curious has to how different it is to be a DE in the sports industry when compared to a tech/consulting company? Do you view the usage of tools and overall architecture similarly? Do you have opportunities to learn and grow? How are your peers around you and do you have a WLB?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16sdlq8", "is_robot_indexable": true, "report_reasons": null, "author": "millenialMonkk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16sdlq8/how_is_it_working_as_a_de_in_the_sports_industry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16sdlq8/how_is_it_working_as_a_de_in_the_sports_industry/", "subreddit_subscribers": 130479, "created_utc": 1695701474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I saw Apache AirFlow, but i think it a bit overkill and not Computer vision oriented.\n\nLooking for something that is: scalabe, monitored, easy to use, and there is (FOSS) community behind it.\n\nThanks!", "author_fullname": "t2_5831rdhp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any reccomendation of python library for handling pipeline workflow for Computer vision?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16s62sf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695681075.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695680889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I saw Apache AirFlow, but i think it a bit overkill and not Computer vision oriented.&lt;/p&gt;\n\n&lt;p&gt;Looking for something that is: scalabe, monitored, easy to use, and there is (FOSS) community behind it.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16s62sf", "is_robot_indexable": true, "report_reasons": null, "author": "Expensive_Breakfast6", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16s62sf/any_reccomendation_of_python_library_for_handling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16s62sf/any_reccomendation_of_python_library_for_handling/", "subreddit_subscribers": 130479, "created_utc": 1695680889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI joined this company 2 years ago and recently got transferred to a software developer role, I have been given a project to lead about transforming our business data and the governance surrounding that. We are a manufacturing company in a highly regulated industry. We have many paper based processes, a ton of spreadsheets, and a central ERP system which connects to various Oracle databases. \n\nPeople within the company are starting to explore PowerBI more and are creating their own reports, using their own data sources in a completely distributed manner without any control... im hoping to change this. \n\nThe initial plan (before i was given the project) was to create a disconnected oracle database which the live databases back up to, this will provide a single source for all of our key data that can then be used for reports/analytics. I think that while this is feasible, we are shooting ourselves in the foot because it seems like its implementing a workaround instead of coming up with a new system to set ourselves for the future.\n\nWe have 365 E5 licenses and azure devops etc. So to me it makes sense to look at databricks or fabric. The other issue is that we are financially not in a great position atm, but I feel its worth at least investigating these options. If we go for these options then I feel like it would not only give us a space for our databases, but also a space to centralise all of our distributed data sources with which we can the report on and analyse. It will also provide a good foundation to begin implementing some machine learning. Are there any other alternatives you guys would recommend?\n\nIm a youngish guy and did some data stuff and machine learning during my masters, but this is the first time im having a look at corporate systems and processes so im a bit unfamiliar with the standards. Is there anything you guys recommend i read up on/learn?", "author_fullname": "t2_b8p76", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transforming an outdated business", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16sipel", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695719645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I joined this company 2 years ago and recently got transferred to a software developer role, I have been given a project to lead about transforming our business data and the governance surrounding that. We are a manufacturing company in a highly regulated industry. We have many paper based processes, a ton of spreadsheets, and a central ERP system which connects to various Oracle databases. &lt;/p&gt;\n\n&lt;p&gt;People within the company are starting to explore PowerBI more and are creating their own reports, using their own data sources in a completely distributed manner without any control... im hoping to change this. &lt;/p&gt;\n\n&lt;p&gt;The initial plan (before i was given the project) was to create a disconnected oracle database which the live databases back up to, this will provide a single source for all of our key data that can then be used for reports/analytics. I think that while this is feasible, we are shooting ourselves in the foot because it seems like its implementing a workaround instead of coming up with a new system to set ourselves for the future.&lt;/p&gt;\n\n&lt;p&gt;We have 365 E5 licenses and azure devops etc. So to me it makes sense to look at databricks or fabric. The other issue is that we are financially not in a great position atm, but I feel its worth at least investigating these options. If we go for these options then I feel like it would not only give us a space for our databases, but also a space to centralise all of our distributed data sources with which we can the report on and analyse. It will also provide a good foundation to begin implementing some machine learning. Are there any other alternatives you guys would recommend?&lt;/p&gt;\n\n&lt;p&gt;Im a youngish guy and did some data stuff and machine learning during my masters, but this is the first time im having a look at corporate systems and processes so im a bit unfamiliar with the standards. Is there anything you guys recommend i read up on/learn?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16sipel", "is_robot_indexable": true, "report_reasons": null, "author": "WillowSide", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16sipel/transforming_an_outdated_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16sipel/transforming_an_outdated_business/", "subreddit_subscribers": 130479, "created_utc": 1695719645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does any have experience/suggestions/resources with running ETL orchestration tools on premise? I have been looking into tools to replace the old python script + cron job.\n\nProblem is most of them like Astronomer, Perfect, Dagster, etc. are all cloud native solutions. Should I just try running Airflow on a server and deal with the hassle of configuring and securing that mess or is there a better way?", "author_fullname": "t2_kfm1982n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Orchestration Tools on Premise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16smt6b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695732009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does any have experience/suggestions/resources with running ETL orchestration tools on premise? I have been looking into tools to replace the old python script + cron job.&lt;/p&gt;\n\n&lt;p&gt;Problem is most of them like Astronomer, Perfect, Dagster, etc. are all cloud native solutions. Should I just try running Airflow on a server and deal with the hassle of configuring and securing that mess or is there a better way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16smt6b", "is_robot_indexable": true, "report_reasons": null, "author": "pip-me", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16smt6b/data_orchestration_tools_on_premise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16smt6b/data_orchestration_tools_on_premise/", "subreddit_subscribers": 130479, "created_utc": 1695732009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working in one of the WITCHR and never had a data related role. But I want to be a data engineer, and I am targeting for role of ETL developer for same.\n\nI have learnt python, SQL in previous 8 months and now I am currently learning informatica as it is mostly used in etl projects in my company. I want to get into a etl dev role in my company and that's why I am learning informatica.\nI also have learnt basic of Hadoop and spark. I have AZ-900 and DP-900, and basic understanding of cloud.\n\nI keep doubting that I am either spreading myself too thin or not focusing on right technology. I am doing DSA too in python from last few months on leetcode and I am not sure if that is required for data engineers.\n\nWhich technology should I choose? Should I be looking for data related roles other than ETL developer too like data analyst? Should I be doing DSA or not? Is informatica good or should I quit it?", "author_fullname": "t2_uz5me90b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am i on the right track?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16sgz0q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695713053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working in one of the WITCHR and never had a data related role. But I want to be a data engineer, and I am targeting for role of ETL developer for same.&lt;/p&gt;\n\n&lt;p&gt;I have learnt python, SQL in previous 8 months and now I am currently learning informatica as it is mostly used in etl projects in my company. I want to get into a etl dev role in my company and that&amp;#39;s why I am learning informatica.\nI also have learnt basic of Hadoop and spark. I have AZ-900 and DP-900, and basic understanding of cloud.&lt;/p&gt;\n\n&lt;p&gt;I keep doubting that I am either spreading myself too thin or not focusing on right technology. I am doing DSA too in python from last few months on leetcode and I am not sure if that is required for data engineers.&lt;/p&gt;\n\n&lt;p&gt;Which technology should I choose? Should I be looking for data related roles other than ETL developer too like data analyst? Should I be doing DSA or not? Is informatica good or should I quit it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16sgz0q", "is_robot_indexable": true, "report_reasons": null, "author": "iamthatmadman", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16sgz0q/am_i_on_the_right_track/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16sgz0q/am_i_on_the_right_track/", "subreddit_subscribers": 130479, "created_utc": 1695713053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Curious to hear your insights and experiences with how you may handle data discrepancies that crop up between different databases in your projects?\n\nE.g. I have one excel spreadsheet full of vendors' names and contact info and a mailchimp mailing list with their info but notice from time to time that emails between both may be different. How could I sync these without manually going through thousands of entries? \n\nDo you have any specific techniques for data reconciliation or data validation? Are there any tools that have been particularly helpful? How do you maintain data consistency and accuracy as your data ecosystem grows and evolves?\n\nHoping to find answers/tools to the above q\u2019s that would be usable by a non-technical person or don't require a dedicated programmer. ", "author_fullname": "t2_kgr62d3c0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practices for Dealing with Data Discrepancies Between Databases?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16rza4k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695665142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious to hear your insights and experiences with how you may handle data discrepancies that crop up between different databases in your projects?&lt;/p&gt;\n\n&lt;p&gt;E.g. I have one excel spreadsheet full of vendors&amp;#39; names and contact info and a mailchimp mailing list with their info but notice from time to time that emails between both may be different. How could I sync these without manually going through thousands of entries? &lt;/p&gt;\n\n&lt;p&gt;Do you have any specific techniques for data reconciliation or data validation? Are there any tools that have been particularly helpful? How do you maintain data consistency and accuracy as your data ecosystem grows and evolves?&lt;/p&gt;\n\n&lt;p&gt;Hoping to find answers/tools to the above q\u2019s that would be usable by a non-technical person or don&amp;#39;t require a dedicated programmer. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16rza4k", "is_robot_indexable": true, "report_reasons": null, "author": "Stat58372", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16rza4k/best_practices_for_dealing_with_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16rza4k/best_practices_for_dealing_with_data/", "subreddit_subscribers": 130479, "created_utc": 1695665142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Which degree would you choose &amp; why?\n\nI\u2019m currently working as a jr swe. I\u2019m looking to go back to school for a masters. I\u2019m thinking of either going for an MBA or M.S. in either data science or cybersecurity. I don\u2019t think I want to work as a swe the rest of my life and would like to use my masters to pivot into other areas when the time comes. I\u2019m also looking for something with job security/stability and would like to keep income over six figures. \n\nAlso, does the school matter for the masters? I\u2019m thinking WGU for now but still exploring other schools. I like how affordable WGU is. Which degree would you choose and why? Would love to hear people\u2019s input.", "author_fullname": "t2_mgoqraub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which masters degree would you choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16sdnxz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695701674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which degree would you choose &amp;amp; why?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently working as a jr swe. I\u2019m looking to go back to school for a masters. I\u2019m thinking of either going for an MBA or M.S. in either data science or cybersecurity. I don\u2019t think I want to work as a swe the rest of my life and would like to use my masters to pivot into other areas when the time comes. I\u2019m also looking for something with job security/stability and would like to keep income over six figures. &lt;/p&gt;\n\n&lt;p&gt;Also, does the school matter for the masters? I\u2019m thinking WGU for now but still exploring other schools. I like how affordable WGU is. Which degree would you choose and why? Would love to hear people\u2019s input.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16sdnxz", "is_robot_indexable": true, "report_reasons": null, "author": "That-Wolverine1781", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16sdnxz/which_masters_degree_would_you_choose/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16sdnxz/which_masters_degree_would_you_choose/", "subreddit_subscribers": 130479, "created_utc": 1695701674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm looking into setting up an on prem Lake House with Kubernetes compute (&gt;1k nodes) and S3 compatible object store (multi PB).  Not interested in a Hadoop based stack or cloud based.   Must be able to run Apache Spark workloads and have a Metastore (like Hive Metastore or [Nessie](https://projectnessie.org/))  bonus if it can run multiple data processing engines (Trino, Flink...)  Apache 2 License is prefered, but I'm willing to pay if I find something to solve my needs. \n\n[DataRoaster](https://github.com/cloudcheflabs/dataroaster)  looks like a great start, but I'm looking for something that is actively being developed and maybe a little bit further along.  \n\nThanks for any suggestions!\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_ind8p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for On Prem Lake House software stack using k8s and s3 compat obj.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ruspl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695654793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m looking into setting up an on prem Lake House with Kubernetes compute (&amp;gt;1k nodes) and S3 compatible object store (multi PB).  Not interested in a Hadoop based stack or cloud based.   Must be able to run Apache Spark workloads and have a Metastore (like Hive Metastore or &lt;a href=\"https://projectnessie.org/\"&gt;Nessie&lt;/a&gt;)  bonus if it can run multiple data processing engines (Trino, Flink...)  Apache 2 License is prefered, but I&amp;#39;m willing to pay if I find something to solve my needs. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/cloudcheflabs/dataroaster\"&gt;DataRoaster&lt;/a&gt;  looks like a great start, but I&amp;#39;m looking for something that is actively being developed and maybe a little bit further along.  &lt;/p&gt;\n\n&lt;p&gt;Thanks for any suggestions!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ruspl", "is_robot_indexable": true, "report_reasons": null, "author": "6nop_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ruspl/looking_for_on_prem_lake_house_software_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ruspl/looking_for_on_prem_lake_house_software_stack/", "subreddit_subscribers": 130479, "created_utc": 1695654793.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've recently been working on an easy way to spin up dashboards, scheduling, alerting, silencing, logs, etc. around some of my custom data quality Python checks. Decided this past weekend to spin that out as a standalone and simple solution that anyone can use for their checks. If it's interesting, DM me and we can talk further", "author_fullname": "t2_dcdt0mh5t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data quality checks and dashboards with a lines of Python code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16s4pxk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695677718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently been working on an easy way to spin up dashboards, scheduling, alerting, silencing, logs, etc. around some of my custom data quality Python checks. Decided this past weekend to spin that out as a standalone and simple solution that anyone can use for their checks. If it&amp;#39;s interesting, DM me and we can talk further&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16s4pxk", "is_robot_indexable": true, "report_reasons": null, "author": "gnahznavia", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16s4pxk/data_quality_checks_and_dashboards_with_a_lines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16s4pxk/data_quality_checks_and_dashboards_with_a_lines/", "subreddit_subscribers": 130479, "created_utc": 1695677718.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}