{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm starting to think about getting external drives for backup and I mentioned to a friend I wanted to get a 20TB hard drive. He said that I should get a 10TB one since the higher capacity ones are more prone to hardware failure.\n\nIs this true and is this a good reason to avoid getting the highest capacity models?\n\nWhat are your experiences?", "author_fullname": "t2_7qbkalan", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are high capacity disk drives more prone to failure than smaller ones?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168q7j9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 108, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 108, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693724883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m starting to think about getting external drives for backup and I mentioned to a friend I wanted to get a 20TB hard drive. He said that I should get a 10TB one since the higher capacity ones are more prone to hardware failure.&lt;/p&gt;\n\n&lt;p&gt;Is this true and is this a good reason to avoid getting the highest capacity models?&lt;/p&gt;\n\n&lt;p&gt;What are your experiences?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168q7j9", "is_robot_indexable": true, "report_reasons": null, "author": "SherbetTiger", "discussion_type": null, "num_comments": 96, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168q7j9/are_high_capacity_disk_drives_more_prone_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168q7j9/are_high_capacity_disk_drives_more_prone_to/", "subreddit_subscribers": 701394, "created_utc": 1693724883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Trying to start practicing cold-storage of a few TB, need proper HTL but I've gotten a couple bad batches from amazon. Where else can I buy quality discs?", "author_fullname": "t2_loxjgv3f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to buy Bluray discs? I've been getting a lot of fakes from Amazon", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168cuat", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693686401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to start practicing cold-storage of a few TB, need proper HTL but I&amp;#39;ve gotten a couple bad batches from amazon. Where else can I buy quality discs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "168cuat", "is_robot_indexable": true, "report_reasons": null, "author": "wtrbotid", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168cuat/where_to_buy_bluray_discs_ive_been_getting_a_lot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168cuat/where_to_buy_bluray_discs_ive_been_getting_a_lot/", "subreddit_subscribers": 701394, "created_utc": 1693686401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been thinking of ways to back up my data and what might happen if stuff goes wrong. Most of the time I have been using my computer I have used a small fast SSD boot drive and than a larger slower mass storage drive. But no real back up simple as my data didn't matter when I was a teen. But now a have lots of documents that matter. I have been thinking about using windows biuld in partition manager to raid 5 my largest storge. I would like to use raid 5 as it more data efficient than raid 1. \n\nWhat would happen if the boot drive for windows failed and I had my mass storage using windows biuld in raid 5? When I reinstalled windows on a new boot drive, will it be able to recognize the old mass storage raid 5 or will all the data be lost? Also what would happen if the motherboard failed? \n\n I'm sure I could avoid that risk with a motherboard raid 1 boot drive, but that would require an additional nvme drive that i dont have room for in my computer. I also wouldn't need to do raid 1 boot if I just stuck to raid 1 for my mass storage, as I know the data is readable. \n\nOf course I'm thinking of getting a NAS or home cload type thing as well. But I don't know how much that matters if the raid is done right. I would imagine most of the remaining risk wouldn't be avoided unless the backup was at a different location.", "author_fullname": "t2_a2stu2br", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What happens if you use Windows built in software raid for raid 5 and the boot drive gets corrupted?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168n527", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693714422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been thinking of ways to back up my data and what might happen if stuff goes wrong. Most of the time I have been using my computer I have used a small fast SSD boot drive and than a larger slower mass storage drive. But no real back up simple as my data didn&amp;#39;t matter when I was a teen. But now a have lots of documents that matter. I have been thinking about using windows biuld in partition manager to raid 5 my largest storge. I would like to use raid 5 as it more data efficient than raid 1. &lt;/p&gt;\n\n&lt;p&gt;What would happen if the boot drive for windows failed and I had my mass storage using windows biuld in raid 5? When I reinstalled windows on a new boot drive, will it be able to recognize the old mass storage raid 5 or will all the data be lost? Also what would happen if the motherboard failed? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure I could avoid that risk with a motherboard raid 1 boot drive, but that would require an additional nvme drive that i dont have room for in my computer. I also wouldn&amp;#39;t need to do raid 1 boot if I just stuck to raid 1 for my mass storage, as I know the data is readable. &lt;/p&gt;\n\n&lt;p&gt;Of course I&amp;#39;m thinking of getting a NAS or home cload type thing as well. But I don&amp;#39;t know how much that matters if the raid is done right. I would imagine most of the remaining risk wouldn&amp;#39;t be avoided unless the backup was at a different location.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168n527", "is_robot_indexable": true, "report_reasons": null, "author": "Material-Put-3841", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168n527/what_happens_if_you_use_windows_built_in_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168n527/what_happens_if_you_use_windows_built_in_software/", "subreddit_subscribers": 701394, "created_utc": 1693714422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm wondering if someone could please point me in the right direction. \n\nI have a small Samsung Chromebox reflashed with MrChromebox firmware, RAM upgraded to 16GB. Currently it's just hooked to a 12tb hardware raid box over a USB 3.0 mini pci-e card, running a Nextcloud setup. It also has Duplicati to mirror that to a cloud storage account.\n\n  I've been thinking recently that I'd like to set up something to have my various devices, tablets, laptops, and smartphones to sync their data to this server as a backup instead of adding files through nextcloud. But my main concern is having duplicate files. I don't really want 5 copies of some song or whatever just because I forgot I had downloaded the same file to each of these devices before syncing. \n\nI thought about using some sort of hardware level filesystem that supports deduplication but I'm not sure how well that would work out or which filesystem to go with. \n\nAny ideas?", "author_fullname": "t2_boorh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiple devices with backup to a server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168uo4f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693741217.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693740824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering if someone could please point me in the right direction. &lt;/p&gt;\n\n&lt;p&gt;I have a small Samsung Chromebox reflashed with MrChromebox firmware, RAM upgraded to 16GB. Currently it&amp;#39;s just hooked to a 12tb hardware raid box over a USB 3.0 mini pci-e card, running a Nextcloud setup. It also has Duplicati to mirror that to a cloud storage account.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been thinking recently that I&amp;#39;d like to set up something to have my various devices, tablets, laptops, and smartphones to sync their data to this server as a backup instead of adding files through nextcloud. But my main concern is having duplicate files. I don&amp;#39;t really want 5 copies of some song or whatever just because I forgot I had downloaded the same file to each of these devices before syncing. &lt;/p&gt;\n\n&lt;p&gt;I thought about using some sort of hardware level filesystem that supports deduplication but I&amp;#39;m not sure how well that would work out or which filesystem to go with. &lt;/p&gt;\n\n&lt;p&gt;Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "12TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168uo4f", "is_robot_indexable": true, "report_reasons": null, "author": "ShapeShifter499", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/168uo4f/multiple_devices_with_backup_to_a_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168uo4f/multiple_devices_with_backup_to_a_server/", "subreddit_subscribers": 701394, "created_utc": 1693740824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Sony 8mm Video8 V8 / Hi8 High8 Digtisation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "name": "t3_168hej7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "author_fullname": "t2_413nr2z7", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/z3uSn64v0PFUDsU9JmOK57bEI7NISPm77-kixIG_L1w.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "vhsdecode", "selftext": "One of the latest info graphics for the [vhs-decode projects](https://github.com/oyvindln/vhs-decode/wiki) expanded docs for the [Sony 8mm format](https://github.com/oyvindln/vhs-decode/wiki/Sony-8mm-Formats).\n\n[Sony 8mm formats Conventinal &amp; Modern FM RF Capture Overview.](https://preview.redd.it/559tk3slfxlb1.png?width=4848&amp;format=png&amp;auto=webp&amp;s=d509bb187538fd64a56db5805100fc117ae8b219)", "author_fullname": "t2_413nr2z7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modern Sony 8mm Video8 V8 / Hi8 High8 Digtisation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/vhsdecode", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 67, "top_awarded_type": null, "hide_score": false, "media_metadata": {"559tk3slfxlb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 52, "x": 108, "u": "https://preview.redd.it/559tk3slfxlb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f54f49b0bdcf8fe7fe3edbe190172a4677203da4"}, {"y": 104, "x": 216, "u": "https://preview.redd.it/559tk3slfxlb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5630bb39d913d51e22228fbe18ac60f048c9a2e9"}, {"y": 154, "x": 320, "u": "https://preview.redd.it/559tk3slfxlb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2c9206ff2cce5350ce13bea8df4b55cce8c2dd5b"}, {"y": 309, "x": 640, "u": "https://preview.redd.it/559tk3slfxlb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8efc30711c1a27632cf1376dee29bd203cd98e3b"}, {"y": 463, "x": 960, "u": "https://preview.redd.it/559tk3slfxlb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1e8b74a4da58b297a63fb48c9417f90793c1cfc2"}, {"y": 521, "x": 1080, "u": "https://preview.redd.it/559tk3slfxlb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a59f9220858bbbbbc35fa52b57ac37d67617beaf"}], "s": {"y": 2343, "x": 4848, "u": "https://preview.redd.it/559tk3slfxlb1.png?width=4848&amp;format=png&amp;auto=webp&amp;s=d509bb187538fd64a56db5805100fc117ae8b219"}, "id": "559tk3slfxlb1"}}, "name": "t3_168hded", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": "#00a6a5", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "733732ba-9566-11ed-883a-c2b6a81770fb", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/z3uSn64v0PFUDsU9JmOK57bEI7NISPm77-kixIG_L1w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693697453.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.vhsdecode", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One of the latest info graphics for the &lt;a href=\"https://github.com/oyvindln/vhs-decode/wiki\"&gt;vhs-decode projects&lt;/a&gt; expanded docs for the &lt;a href=\"https://github.com/oyvindln/vhs-decode/wiki/Sony-8mm-Formats\"&gt;Sony 8mm format&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/559tk3slfxlb1.png?width=4848&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d509bb187538fd64a56db5805100fc117ae8b219\"&gt;Sony 8mm formats Conventinal &amp;amp; Modern FM RF Capture Overview.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "The Documentor ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_5zwnn5", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "168hded", "is_robot_indexable": true, "report_reasons": null, "author": "TheRealHarrypm", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/vhsdecode/comments/168hded/modern_sony_8mm_video8_v8_hi8_high8_digtisation/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/vhsdecode/comments/168hded/modern_sony_8mm_video8_v8_hi8_high8_digtisation/", "subreddit_subscribers": 86, "created_utc": 1693697453.0, "num_crossposts": 3, "media": null, "is_video": false}], "created": 1693697529.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.vhsdecode", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/vhsdecode/comments/168hded/modern_sony_8mm_video8_v8_hi8_high8_digtisation/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "80TB \ud83c\udfe0 27TB \u2601\ufe0f 50TB \ud83d\udcfc  1TB \ud83d\udcbf", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168hej7", "is_robot_indexable": true, "report_reasons": null, "author": "TheRealHarrypm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_168hded", "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/168hej7/modern_sony_8mm_video8_v8_hi8_high8_digtisation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/vhsdecode/comments/168hded/modern_sony_8mm_video8_v8_hi8_high8_digtisation/", "subreddit_subscribers": 701394, "created_utc": 1693697529.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there!\n\nI'm looking for help in regards to selecting a Harddrive for a NAS. Right now I am torn choosing between the TOSHIBA MG10 20TB and the Seagate Exos X20 20TB drives. They're both in the same price segment(about 13.50\u20ac/TB)which is why I am looking at these two and they seem to have decent specs.\nIs there anything to go by these two at all? E.g. reliability, performance etc?\n\nWould appreciate any help about this.", "author_fullname": "t2_ffdhv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Toshiba MG10 VS Seagate EXOS X20 20TB - Which one is better?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168tk4i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693737083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for help in regards to selecting a Harddrive for a NAS. Right now I am torn choosing between the TOSHIBA MG10 20TB and the Seagate Exos X20 20TB drives. They&amp;#39;re both in the same price segment(about 13.50\u20ac/TB)which is why I am looking at these two and they seem to have decent specs.\nIs there anything to go by these two at all? E.g. reliability, performance etc?&lt;/p&gt;\n\n&lt;p&gt;Would appreciate any help about this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168tk4i", "is_robot_indexable": true, "report_reasons": null, "author": "JustRefleX", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168tk4i/toshiba_mg10_vs_seagate_exos_x20_20tb_which_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168tk4i/toshiba_mg10_vs_seagate_exos_x20_20tb_which_one/", "subreddit_subscribers": 701394, "created_utc": 1693737083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know how to just copy and paste information from one drive to another with terracopy but I'm a tad confused with cloning one drive to another (same size)\nEvery tutorial I see on YouTube are people cloning one size drive to a larger one... Never the exact same size?, is there anything I should know that differs when cloning one drive to another that's the same size, I see an option on macrium to shrink or extend to fill target disk, what does this do?", "author_fullname": "t2_evrgtr0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Further help cloning HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16914fp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693758004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know how to just copy and paste information from one drive to another with terracopy but I&amp;#39;m a tad confused with cloning one drive to another (same size)\nEvery tutorial I see on YouTube are people cloning one size drive to a larger one... Never the exact same size?, is there anything I should know that differs when cloning one drive to another that&amp;#39;s the same size, I see an option on macrium to shrink or extend to fill target disk, what does this do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16914fp", "is_robot_indexable": true, "report_reasons": null, "author": "BadFixMate", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16914fp/further_help_cloning_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16914fp/further_help_cloning_hdd/", "subreddit_subscribers": 701394, "created_utc": 1693758004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am burning my 100GB bluray M-discs.\n\nI have burned two 100GB Blu-ray M-Discs so far, and I'm wondering if I should have selected the \"finalize disc\" option\n\n I didn't choose the \"finalize disc\" option for the previous two M-Discs I burned. ", "author_fullname": "t2_hchpqvs5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I need to finalize my disc when I'm done burning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168r9jg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693729016.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693728808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am burning my 100GB bluray M-discs.&lt;/p&gt;\n\n&lt;p&gt;I have burned two 100GB Blu-ray M-Discs so far, and I&amp;#39;m wondering if I should have selected the &amp;quot;finalize disc&amp;quot; option&lt;/p&gt;\n\n&lt;p&gt;I didn&amp;#39;t choose the &amp;quot;finalize disc&amp;quot; option for the previous two M-Discs I burned. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168r9jg", "is_robot_indexable": true, "report_reasons": null, "author": "McDoonald", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168r9jg/do_i_need_to_finalize_my_disc_when_im_done_burning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168r9jg/do_i_need_to_finalize_my_disc_when_im_done_burning/", "subreddit_subscribers": 701394, "created_utc": 1693728808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Doesn't have to be \"intelligent\", like in Adobe Lightroom you can set the amount of time that you want the increment to be, so in the case of  photos I would set it to like 20 seconds, and in this case I would probably set it to 3 minutes or so, if that were possible, just moving things into folders that were created within a few minutes of each other.", "author_fullname": "t2_hv5ly9kw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a Windows program or python script to go through folders and put all files into sub-folders intelligently, basically grouping things together that were saved within a few minutes of each other. Does this exist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168mcx8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693711935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doesn&amp;#39;t have to be &amp;quot;intelligent&amp;quot;, like in Adobe Lightroom you can set the amount of time that you want the increment to be, so in the case of  photos I would set it to like 20 seconds, and in this case I would probably set it to 3 minutes or so, if that were possible, just moving things into folders that were created within a few minutes of each other.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168mcx8", "is_robot_indexable": true, "report_reasons": null, "author": "drippyneon", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168mcx8/looking_for_a_windows_program_or_python_script_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168mcx8/looking_for_a_windows_program_or_python_script_to/", "subreddit_subscribers": 701394, "created_utc": 1693711935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an existing vdev that is ~30TB usable that is mostly full, and just got disks to add an additional 50TB vdev to the pool (running ZFS on ubuntu 20.04 LTSL).\n\nMy plan is to zfs export the pool (I got an HBA so all drives would fit, need to move drives from existing mobo connection to HBA), import it back in once everything is on the HBA, then send it to a new pool on the 50TB vdev.\n\nAt that point I'd be 28TB used/50TB on the new vdev, and 0/30TB used on the old, and would add the old vdev as a second vdev to the new pool on the new disks, giving my ~80 TB useable and roughly equal free space on both vdevs, so any new data would be split accross them.\n\nIs this plan dumb/should I be doing it a different way, and are there any potential roadbumps I should anticipate?\n\nThanks!", "author_fullname": "t2_9ghxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on added vdev to ZFS pool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168ewzm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693691346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an existing vdev that is ~30TB usable that is mostly full, and just got disks to add an additional 50TB vdev to the pool (running ZFS on ubuntu 20.04 LTSL).&lt;/p&gt;\n\n&lt;p&gt;My plan is to zfs export the pool (I got an HBA so all drives would fit, need to move drives from existing mobo connection to HBA), import it back in once everything is on the HBA, then send it to a new pool on the 50TB vdev.&lt;/p&gt;\n\n&lt;p&gt;At that point I&amp;#39;d be 28TB used/50TB on the new vdev, and 0/30TB used on the old, and would add the old vdev as a second vdev to the new pool on the new disks, giving my ~80 TB useable and roughly equal free space on both vdevs, so any new data would be split accross them.&lt;/p&gt;\n\n&lt;p&gt;Is this plan dumb/should I be doing it a different way, and are there any potential roadbumps I should anticipate?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168ewzm", "is_robot_indexable": true, "report_reasons": null, "author": "MrFrisB", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168ewzm/question_on_added_vdev_to_zfs_pool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168ewzm/question_on_added_vdev_to_zfs_pool/", "subreddit_subscribers": 701394, "created_utc": 1693691346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm trying to expose a 2TB external hard drive on my local network, and am struggling to come up with the most low-maintenance mechanism to do that. I have an ISP-provided  modem at home with a USB slot that could share out a drive on the network as an ethernet device, but apparently my ISP has disabled that functionality.\n\nShould I look for a modem/router that can also expose USB over ethernet? Should I suck it up and build out a computer just for this? Hoping I could avoid the latter.", "author_fullname": "t2_gqudi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exposing external hard drive on network", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16962hv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693769794.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to expose a 2TB external hard drive on my local network, and am struggling to come up with the most low-maintenance mechanism to do that. I have an ISP-provided  modem at home with a USB slot that could share out a drive on the network as an ethernet device, but apparently my ISP has disabled that functionality.&lt;/p&gt;\n\n&lt;p&gt;Should I look for a modem/router that can also expose USB over ethernet? Should I suck it up and build out a computer just for this? Hoping I could avoid the latter.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16962hv", "is_robot_indexable": true, "report_reasons": null, "author": "ksharanam", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16962hv/exposing_external_hard_drive_on_network/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16962hv/exposing_external_hard_drive_on_network/", "subreddit_subscribers": 701394, "created_utc": 1693769794.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m planning to build a disk array for backup purposes. I plan to use a filesystem with checksums (to prevent data leak) and occasionally send some backups in there, no more often than once in two weeks.\n\nIf I understand it correctly, checksums may prevent data leak from the magnetic storage, but HDDs may nonetheless fail mechanically. Is there an estimated lifespan for HDDs under my workflow, i.e. writing to them once in 2 weeks.\n\nWhat I worry about is building an array of 5 new HDDs and having some of them fail in, say, 5 years. And I wonder, does infrequent use extend the lifespan?", "author_fullname": "t2_4cdolvhx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A question on HDD lifetime", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1695fj4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693768265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m planning to build a disk array for backup purposes. I plan to use a filesystem with checksums (to prevent data leak) and occasionally send some backups in there, no more often than once in two weeks.&lt;/p&gt;\n\n&lt;p&gt;If I understand it correctly, checksums may prevent data leak from the magnetic storage, but HDDs may nonetheless fail mechanically. Is there an estimated lifespan for HDDs under my workflow, i.e. writing to them once in 2 weeks.&lt;/p&gt;\n\n&lt;p&gt;What I worry about is building an array of 5 new HDDs and having some of them fail in, say, 5 years. And I wonder, does infrequent use extend the lifespan?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1695fj4", "is_robot_indexable": true, "report_reasons": null, "author": "kalterdev", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1695fj4/a_question_on_hdd_lifetime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1695fj4/a_question_on_hdd_lifetime/", "subreddit_subscribers": 701394, "created_utc": 1693768265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm comparing a few places in LA to digitize our Hi-8 home videos from the 90s/2000s. Is it worth springing for the HD conversion, or should I just go for standard?", "author_fullname": "t2_4jrygdeq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting some old Hi-8 tapes digitized. Is HD worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1695abs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693767921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m comparing a few places in LA to digitize our Hi-8 home videos from the 90s/2000s. Is it worth springing for the HD conversion, or should I just go for standard?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1695abs", "is_robot_indexable": true, "report_reasons": null, "author": "websiteURLdotcom", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1695abs/getting_some_old_hi8_tapes_digitized_is_hd_worth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1695abs/getting_some_old_hi8_tapes_digitized_is_hd_worth/", "subreddit_subscribers": 701394, "created_utc": 1693767921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello fellow archivists,\nI am wanting to start my storage from web scraped data I've been collecting snd thought about utilizing some RBP i have lying around. What would be a good method of using RBP's[ ie postgresql server, ELK stack ] are some ideas that I'm wanting to play around with just haven't had much experience with them before. I like the theory of using these small single boards because of the fact that for storage you could replace the mini SD card when one was full and keeping a bunch of labeled SD cards wouldn't take up space", "author_fullname": "t2_5mr7xky9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Raspberry Pi as Storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16901xr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693755323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow archivists,\nI am wanting to start my storage from web scraped data I&amp;#39;ve been collecting snd thought about utilizing some RBP i have lying around. What would be a good method of using RBP&amp;#39;s[ ie postgresql server, ELK stack ] are some ideas that I&amp;#39;m wanting to play around with just haven&amp;#39;t had much experience with them before. I like the theory of using these small single boards because of the fact that for storage you could replace the mini SD card when one was full and keeping a bunch of labeled SD cards wouldn&amp;#39;t take up space&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16901xr", "is_robot_indexable": true, "report_reasons": null, "author": "0ryX_Error404", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16901xr/raspberry_pi_as_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16901xr/raspberry_pi_as_storage/", "subreddit_subscribers": 701394, "created_utc": 1693755323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Has anyone here tried this combination?  I know that generally MD1200's will run whatever drive you throw in them but it would be great if anyone has tried one of these 20TB SAS drives in them and knows it works for sure before I drop the budget on drives!", "author_fullname": "t2_11yqnn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PowerVault MD 1200 + DELL R3G03 20TB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168pdxm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693721976.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone here tried this combination?  I know that generally MD1200&amp;#39;s will run whatever drive you throw in them but it would be great if anyone has tried one of these 20TB SAS drives in them and knows it works for sure before I drop the budget on drives!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "150TB raw", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168pdxm", "is_robot_indexable": true, "report_reasons": null, "author": "Gerkibus", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/168pdxm/powervault_md_1200_dell_r3g03_20tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168pdxm/powervault_md_1200_dell_r3g03_20tb/", "subreddit_subscribers": 701394, "created_utc": 1693721976.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can anyone tell me how to edit out specific terms and mass scrape?\n\nFor example, If I have all scenes from a website, but the file format is something like v3847_4858 actress name, how would i make it remove the random code in front so it picks up what I\u2019m trying to search for?\n\nI\u2019m trying to tell the scraper that all scenes selected are from site A.\n\nThen how do I mass save all the results?\n\nThanks", "author_fullname": "t2_9wqbhzy1s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stashapp scraping help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_169662p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693770037.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone tell me how to edit out specific terms and mass scrape?&lt;/p&gt;\n\n&lt;p&gt;For example, If I have all scenes from a website, but the file format is something like v3847_4858 actress name, how would i make it remove the random code in front so it picks up what I\u2019m trying to search for?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to tell the scraper that all scenes selected are from site A.&lt;/p&gt;\n\n&lt;p&gt;Then how do I mass save all the results?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "169662p", "is_robot_indexable": true, "report_reasons": null, "author": "Thehobbyist916", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/169662p/stashapp_scraping_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/169662p/stashapp_scraping_help/", "subreddit_subscribers": 701394, "created_utc": 1693770037.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm using this app called Tandem or Tandem app. I can't scroll down to see the older message and I can't find an equivalent for downloading information like in Fb / Ig. I was wondering if you guys know how. I'm not tech savvy so I don't know those GitHub things.", "author_fullname": "t2_s63qd3xz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Retrieve Messages", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168u577", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693739121.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using this app called Tandem or Tandem app. I can&amp;#39;t scroll down to see the older message and I can&amp;#39;t find an equivalent for downloading information like in Fb / Ig. I was wondering if you guys know how. I&amp;#39;m not tech savvy so I don&amp;#39;t know those GitHub things.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168u577", "is_robot_indexable": true, "report_reasons": null, "author": "JSHowtodraw", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168u577/retrieve_messages/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168u577/retrieve_messages/", "subreddit_subscribers": 701394, "created_utc": 1693739121.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there, \n\nTotal beginner here. I want to set up a raid array to manage large video files. At the moment I'm just running a 1tb SSD (for OS and personal files) and a single 4tb HHD, then backing that up onto multiple external hard drives. \n\nIdeally I want to buy 3 more of these 4tb drives and link them into a RAID 5 array, giving me 12tb of storage total. Fault tolerance isn't top priority for me as I'll still be backing up to external drives daily - capacity, speed and cost are more important. \n\nTwo issues I can see with this: \n\n- According to the manual, my motherboard (ASUS prime B550M-A) only supports raid 0, 1 or 10\n\n- It also only has 4 SATA ports - one less than I need\n\nWhat are my options? Can the first issue be solved with software, or would I need to get a hardware raid controller? Could I buy an adaptor and run the SSD off a different port to free up a SATA? Do I just give up and buy an external cage? Is RAID 5 even what I should be going for?\n\nAs someone with no experience it's all very confusing, but I'm determined to learn. Thanks in advance for your help!", "author_fullname": "t2_l725xn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First time RAID setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168pff2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693722113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, &lt;/p&gt;\n\n&lt;p&gt;Total beginner here. I want to set up a raid array to manage large video files. At the moment I&amp;#39;m just running a 1tb SSD (for OS and personal files) and a single 4tb HHD, then backing that up onto multiple external hard drives. &lt;/p&gt;\n\n&lt;p&gt;Ideally I want to buy 3 more of these 4tb drives and link them into a RAID 5 array, giving me 12tb of storage total. Fault tolerance isn&amp;#39;t top priority for me as I&amp;#39;ll still be backing up to external drives daily - capacity, speed and cost are more important. &lt;/p&gt;\n\n&lt;p&gt;Two issues I can see with this: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;According to the manual, my motherboard (ASUS prime B550M-A) only supports raid 0, 1 or 10&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;It also only has 4 SATA ports - one less than I need&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What are my options? Can the first issue be solved with software, or would I need to get a hardware raid controller? Could I buy an adaptor and run the SSD off a different port to free up a SATA? Do I just give up and buy an external cage? Is RAID 5 even what I should be going for?&lt;/p&gt;\n\n&lt;p&gt;As someone with no experience it&amp;#39;s all very confusing, but I&amp;#39;m determined to learn. Thanks in advance for your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168pff2", "is_robot_indexable": true, "report_reasons": null, "author": "Lschilling505", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168pff2/first_time_raid_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168pff2/first_time_raid_setup/", "subreddit_subscribers": 701394, "created_utc": 1693722113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey,\n\nI've done a bit of research but still can't find a solution and an assessment it works and makes sense.\n\nI want to build an RAID1 mirrored DAS to use exclusively and directly with macOS. It doesn't need to be remotely accessible, I just want to 1) have decent speeds during working sessions (but nothing crazy, a speed similar to a typical singular hdd is fine), 2) built-in encryption layer from macOS, 3) redundancy and maximum fault tolerance.\n\nI planned to buy 2x10 or 2x12TB WD Red Plus (CMB) and an enclosure for 2 or for 4 drives (looking at OWC Elite). I assume that I can connect it just as JBOD and then use macOS tools to create a RAID1+APFS or HFS with a built-in FileVault macOS encryption. \n\n&amp;#x200B;\n\nDoes this plan makes sense at all? \n\n\\- Will OWC Elite 2x or 4x show disks as JBOD so I can build a software RAID1 using macOS tools on M1/M2 Apple Silicon?   \n\\- Will it take ages for macOS to encrypt/decrypt a FileVault volume that big and slow upon each usage?   \n\\- Am I tripping? Should I just pick a DAS with a built-in encryption? I don't care too much about the level of encryption, but I don't want any nasty surprises or corruption of the data and any kind of lock downs.\n\n&amp;#x200B;", "author_fullname": "t2_i72ehe2z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A SW RAID1 DAS for macOS w/encryption - advises", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168ogjc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693718763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done a bit of research but still can&amp;#39;t find a solution and an assessment it works and makes sense.&lt;/p&gt;\n\n&lt;p&gt;I want to build an RAID1 mirrored DAS to use exclusively and directly with macOS. It doesn&amp;#39;t need to be remotely accessible, I just want to 1) have decent speeds during working sessions (but nothing crazy, a speed similar to a typical singular hdd is fine), 2) built-in encryption layer from macOS, 3) redundancy and maximum fault tolerance.&lt;/p&gt;\n\n&lt;p&gt;I planned to buy 2x10 or 2x12TB WD Red Plus (CMB) and an enclosure for 2 or for 4 drives (looking at OWC Elite). I assume that I can connect it just as JBOD and then use macOS tools to create a RAID1+APFS or HFS with a built-in FileVault macOS encryption. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does this plan makes sense at all? &lt;/p&gt;\n\n&lt;p&gt;- Will OWC Elite 2x or 4x show disks as JBOD so I can build a software RAID1 using macOS tools on M1/M2 Apple Silicon?&lt;br/&gt;\n- Will it take ages for macOS to encrypt/decrypt a FileVault volume that big and slow upon each usage?&lt;br/&gt;\n- Am I tripping? Should I just pick a DAS with a built-in encryption? I don&amp;#39;t care too much about the level of encryption, but I don&amp;#39;t want any nasty surprises or corruption of the data and any kind of lock downs.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168ogjc", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Teach778", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168ogjc/a_sw_raid1_das_for_macos_wencryption_advises/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168ogjc/a_sw_raid1_das_for_macos_wencryption_advises/", "subreddit_subscribers": 701394, "created_utc": 1693718763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all new here but have lurked for a while, I'm getting close to capacity on a few of my drives and have been looking to get a nice large unit. Currently bestbuy has a sale on a WD EasyShare 18TB for $349Can and think this a good deal. Anyone else use one in either its intended external or shuck it for internal use. Primary use would be for movie photo backups etc.", "author_fullname": "t2_120fyfcv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opinions on hdd sale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168dvne", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.47, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1693688828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bestbuy.ca", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all new here but have lurked for a while, I&amp;#39;m getting close to capacity on a few of my drives and have been looking to get a nice large unit. Currently bestbuy has a sale on a WD EasyShare 18TB for $349Can and think this a good deal. Anyone else use one in either its intended external or shuck it for internal use. Primary use would be for movie photo backups etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.bestbuy.ca/en-ca/product/wd-easystore-18tb-usb-3-0-desktop-external-hard-drive-wdbama0180hbk-nese-black-only-at-best-buy/14936766", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168dvne", "is_robot_indexable": true, "report_reasons": null, "author": "mutantlittleman", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168dvne/opinions_on_hdd_sale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.bestbuy.ca/en-ca/product/wd-easystore-18tb-usb-3-0-desktop-external-hard-drive-wdbama0180hbk-nese-black-only-at-best-buy/14936766", "subreddit_subscribers": 701394, "created_utc": 1693688828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_a749q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Release] Media Hoarder v1.3.0 - \"Trailer Show\" Feature", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_168ci7n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/4p_RNd9xrbA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Media Hoarder v1.3.0 - Trailer Show Feature\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Media Hoarder v1.3.0 - Trailer Show Feature", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/4p_RNd9xrbA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Media Hoarder v1.3.0 - Trailer Show Feature\"&gt;&lt;/iframe&gt;", "author_name": "Hoarder Software", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/4p_RNd9xrbA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@hoardersoftware7202"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/4p_RNd9xrbA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Media Hoarder v1.3.0 - Trailer Show Feature\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/168ci7n", "height": 200}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eiPzepeSoZc5EU1w-M1xCaG9Dy4Emm-2TB84IyslQ6o.jpg", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693685622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=4p_RNd9xrbA", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-Ac_Ttu70hFi3kdaFs4ym8IzWIvbjPv1O4Thzflszgg.jpg?auto=webp&amp;s=29d1885055e814435edf40413a30b99dddb0bc68", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/-Ac_Ttu70hFi3kdaFs4ym8IzWIvbjPv1O4Thzflszgg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=45b012551df0057659a4cd712ecbae41ce874b29", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/-Ac_Ttu70hFi3kdaFs4ym8IzWIvbjPv1O4Thzflszgg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=42c55d0df00eddac077010f4ab4ef0252ba78e26", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/-Ac_Ttu70hFi3kdaFs4ym8IzWIvbjPv1O4Thzflszgg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=459b92dff2b3c56fbf7b4268e74c9859a1a802bf", "width": 320, "height": 240}], "variants": {}, "id": "2dZqBpndhbbgntx-wiOW9nn9Ksy_gL8ibprZMG5rHa0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1.44MB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168ci7n", "is_robot_indexable": true, "report_reasons": null, "author": "MK2k", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/168ci7n/release_media_hoarder_v130_trailer_show_feature/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=4p_RNd9xrbA", "subreddit_subscribers": 701394, "created_utc": 1693685622.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Media Hoarder v1.3.0 - Trailer Show Feature", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/4p_RNd9xrbA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Media Hoarder v1.3.0 - Trailer Show Feature\"&gt;&lt;/iframe&gt;", "author_name": "Hoarder Software", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/4p_RNd9xrbA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@hoardersoftware7202"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I looked up a video on how to do this and thought it looked easy enough like anything else I have a feeling they edit that shit massively. took a credit card cut it up and the four pieces. Hey I won\u2019t spend so much money anymore. Yay, but anyways cut it up in four pieces. Well just shoving  it up and just push it open. Just push it and I\u2019it l slide out. Yeah fucking right it didn\u2019t just fucking slide out. It creaked and  cracked and I thought oh my fucking God I\u2019m breaking my Drive oh my god why the fuck did I do this but anyways, so then I was whacking it and I ended up pushing it out and I thought for sure I heard something break I\u2019m like oh fuck my drives gone, but I took it out and inspected it. Nothing was wrong they acted like you could just pop out the rubber spacers that held the drive-in. Nope bitch those are screwed in there. anyways so I unscrewed them and then carefully popped the drive out that was easy part. Thank fucking God took out the daughter board and then carefully unhooked it the drive like was WD  white label so it just popped into my new external hard drive holder and powered up. No problem. I ran it through a couple tests and it\u2019s working just fine nerve-racking as fuck", "author_fullname": "t2_4llo5xjy9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I finally shucked my first hard drive WD my book full information on what it was like", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168kf21", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.3, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693706069.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I looked up a video on how to do this and thought it looked easy enough like anything else I have a feeling they edit that shit massively. took a credit card cut it up and the four pieces. Hey I won\u2019t spend so much money anymore. Yay, but anyways cut it up in four pieces. Well just shoving  it up and just push it open. Just push it and I\u2019it l slide out. Yeah fucking right it didn\u2019t just fucking slide out. It creaked and  cracked and I thought oh my fucking God I\u2019m breaking my Drive oh my god why the fuck did I do this but anyways, so then I was whacking it and I ended up pushing it out and I thought for sure I heard something break I\u2019m like oh fuck my drives gone, but I took it out and inspected it. Nothing was wrong they acted like you could just pop out the rubber spacers that held the drive-in. Nope bitch those are screwed in there. anyways so I unscrewed them and then carefully popped the drive out that was easy part. Thank fucking God took out the daughter board and then carefully unhooked it the drive like was WD  white label so it just popped into my new external hard drive holder and powered up. No problem. I ran it through a couple tests and it\u2019s working just fine nerve-racking as fuck&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "168kf21", "is_robot_indexable": true, "report_reasons": null, "author": "gmenfromh3ll", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/168kf21/i_finally_shucked_my_first_hard_drive_wd_my_book/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/168kf21/i_finally_shucked_my_first_hard_drive_wd_my_book/", "subreddit_subscribers": 701394, "created_utc": 1693706069.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}