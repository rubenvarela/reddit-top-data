{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_s4te90xk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The state of data content on LinkedIn: you can reduce costs by just doing less! Game changing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 109, "top_awarded_type": null, "hide_score": false, "name": "t3_16frhic", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/b05wesGJLhREGk_kcRzO6_TvWwka0_rZJAHtbY5pAW4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694427062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/cg4yomx0plnb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/cg4yomx0plnb1.jpg?auto=webp&amp;s=57018188065745b50bd77364efd06d5a59e22c62", "width": 1079, "height": 844}, "resolutions": [{"url": "https://preview.redd.it/cg4yomx0plnb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=70d104ac81fb242540debb4b8978f475c921e006", "width": 108, "height": 84}, {"url": "https://preview.redd.it/cg4yomx0plnb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d4de7359dc36ec56eacf247b1a61cf7ce344091c", "width": 216, "height": 168}, {"url": "https://preview.redd.it/cg4yomx0plnb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ea27aadc46510ddb42a20b39801c07b3705283f", "width": 320, "height": 250}, {"url": "https://preview.redd.it/cg4yomx0plnb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4f0c95004fbd47faf6d469a92d4e36022250cc01", "width": 640, "height": 500}, {"url": "https://preview.redd.it/cg4yomx0plnb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f2289b4534674760fb9d2e425e56e848d323536", "width": 960, "height": 750}], "variants": {}, "id": "PDNj3pC_3dM6xzgIhUmUiJViAwv2G7rUWS8pN56jM20"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "16frhic", "is_robot_indexable": true, "report_reasons": null, "author": "dataxp-community", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16frhic/the_state_of_data_content_on_linkedin_you_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/cg4yomx0plnb1.jpg", "subreddit_subscribers": 127914, "created_utc": 1694427062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I feel stagnated at my current job. I'm an architect in the biotech industry, but my actual responsibilities are closer to a product manager if anything else. In the past 2 years I've been hardly exposed to any technical challenges and when I am it's always at such a high-level that I don't feel any growth or satisfaction when completing projects.\n\nIn general I want to leave the biotech industry for more technically mature companies like Google or Microsoft, but I feel like I need to step backward to step forward. I'm interested in joining a new company as an engineer, be exposed to new ideas and best practices, and then continue from there. However, because I don't work hands-on in my day job, it's a catch-22 to actually pass the interviews!\n\n I'd love to have hands-on experience with tools and technologies like Iceberg, Hudi, Trino, ect. that I don't get to use in my day job, and ideally I could build some sort of personal project around them. But data engineering is different than something like frontend engineering. There's more startup and cost associated with building a data project, and I'm not sure if I can actually master some of these technologies without working with *big data*. I'm curious if anyone here has any recommendations on potential data engineering personal projects? Or recommendations on switching industries when you feel overleveled in your current one :)  ", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for data engineering personal project ideas for technical growth?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16f9z4h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 42, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 42, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694375941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I feel stagnated at my current job. I&amp;#39;m an architect in the biotech industry, but my actual responsibilities are closer to a product manager if anything else. In the past 2 years I&amp;#39;ve been hardly exposed to any technical challenges and when I am it&amp;#39;s always at such a high-level that I don&amp;#39;t feel any growth or satisfaction when completing projects.&lt;/p&gt;\n\n&lt;p&gt;In general I want to leave the biotech industry for more technically mature companies like Google or Microsoft, but I feel like I need to step backward to step forward. I&amp;#39;m interested in joining a new company as an engineer, be exposed to new ideas and best practices, and then continue from there. However, because I don&amp;#39;t work hands-on in my day job, it&amp;#39;s a catch-22 to actually pass the interviews!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to have hands-on experience with tools and technologies like Iceberg, Hudi, Trino, ect. that I don&amp;#39;t get to use in my day job, and ideally I could build some sort of personal project around them. But data engineering is different than something like frontend engineering. There&amp;#39;s more startup and cost associated with building a data project, and I&amp;#39;m not sure if I can actually master some of these technologies without working with &lt;em&gt;big data&lt;/em&gt;. I&amp;#39;m curious if anyone here has any recommendations on potential data engineering personal projects? Or recommendations on switching industries when you feel overleveled in your current one :)  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16f9z4h", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16f9z4h/looking_for_data_engineering_personal_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16f9z4h/looking_for_data_engineering_personal_project/", "subreddit_subscribers": 127914, "created_utc": 1694375941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Long story short I\u2019m being put in charge of building an entire database and our entire backend infrastructure. Is this within the realm of data engineering?", "author_fullname": "t2_e0rep", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are data engineers in charge of creating database infrastructure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16fmgwu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694408547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long story short I\u2019m being put in charge of building an entire database and our entire backend infrastructure. Is this within the realm of data engineering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16fmgwu", "is_robot_indexable": true, "report_reasons": null, "author": "BiggyDeeKay", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16fmgwu/are_data_engineers_in_charge_of_creating_database/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16fmgwu/are_data_engineers_in_charge_of_creating_database/", "subreddit_subscribers": 127914, "created_utc": 1694408547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone! We currently have a series of .py files with ELT logic (load and write functions). However, we find that maintaining SQL code within these files is not elegant / best solution. What's a more elegant / best way to approach handling Spark SQL inside our elt .py files? Should we keep embedding SQL logic (say select * from table where date) inside the .py files or have .sql files in our repo and execute such .sql files inside our python elt files? Any advice/comments would be helpful!", "author_fullname": "t2_56ltry44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Elegant way of writing SQL inside of ETL .py files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16fkudt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694403417.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! We currently have a series of .py files with ELT logic (load and write functions). However, we find that maintaining SQL code within these files is not elegant / best solution. What&amp;#39;s a more elegant / best way to approach handling Spark SQL inside our elt .py files? Should we keep embedding SQL logic (say select * from table where date) inside the .py files or have .sql files in our repo and execute such .sql files inside our python elt files? Any advice/comments would be helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16fkudt", "is_robot_indexable": true, "report_reasons": null, "author": "Specific-Passage", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16fkudt/elegant_way_of_writing_sql_inside_of_etl_py_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16fkudt/elegant_way_of_writing_sql_inside_of_etl_py_files/", "subreddit_subscribers": 127914, "created_utc": 1694403417.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our current architecture is pulling all marketing data in S3 from different sources: salesforce, oracle db, FTP, APIs of marketing tools. We currently pull in all of this using talend which is pretty inefficient. One of the reasons is it takes way too much time pull all this in. What better options can I use to pull all this data in?. P.S : We also want to make this real time", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data ingestion tools/tech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16f8w3p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694373456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our current architecture is pulling all marketing data in S3 from different sources: salesforce, oracle db, FTP, APIs of marketing tools. We currently pull in all of this using talend which is pretty inefficient. One of the reasons is it takes way too much time pull all this in. What better options can I use to pull all this data in?. P.S : We also want to make this real time&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16f8w3p", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16f8w3p/data_ingestion_toolstech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16f8w3p/data_ingestion_toolstech/", "subreddit_subscribers": 127914, "created_utc": 1694373456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I am developing and testing a set of data quality guidelines for semi-structured data during the transformation layer of a data warehouse. I would like to test the proposed guidelines on a dataset. In particular, I am looking for a sample database in 3NF, along with  the raw json and xml files before it was converted into a structured database format. I have searched online but I am having a hard time finding exactly this. Does anyone know of  any open source databases resources that meets my requirements ?", "author_fullname": "t2_6g5ryjg5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mock database in 3NF along with raw semi-structured files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16f2lrh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694358531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I am developing and testing a set of data quality guidelines for semi-structured data during the transformation layer of a data warehouse. I would like to test the proposed guidelines on a dataset. In particular, I am looking for a sample database in 3NF, along with  the raw json and xml files before it was converted into a structured database format. I have searched online but I am having a hard time finding exactly this. Does anyone know of  any open source databases resources that meets my requirements ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16f2lrh", "is_robot_indexable": true, "report_reasons": null, "author": "yasteel11", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16f2lrh/mock_database_in_3nf_along_with_raw/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16f2lrh/mock_database_in_3nf_along_with_raw/", "subreddit_subscribers": 127914, "created_utc": 1694358531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hey, I have a quick question, please.\n\nI'm into the type of jobs that have more engineering side than charts and analysis for business cases\n\n So just need to know if I can get a junior and first job as a machine learning engineer or data engineer if I learn what it takes for that.\n\n I see people who say you can't work in these roles unless you come from previous data-related roles such as data analyst.", "author_fullname": "t2_8sxs7l2s1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE and ML junior roles without DA road", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16fp08c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694417639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I have a quick question, please.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m into the type of jobs that have more engineering side than charts and analysis for business cases&lt;/p&gt;\n\n&lt;p&gt;So just need to know if I can get a junior and first job as a machine learning engineer or data engineer if I learn what it takes for that.&lt;/p&gt;\n\n&lt;p&gt;I see people who say you can&amp;#39;t work in these roles unless you come from previous data-related roles such as data analyst.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16fp08c", "is_robot_indexable": true, "report_reasons": null, "author": "Guru_202399", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16fp08c/de_and_ml_junior_roles_without_da_road/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16fp08c/de_and_ml_junior_roles_without_da_road/", "subreddit_subscribers": 127914, "created_utc": 1694417639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I have a problem, I'm migrating mssql data to a data lake based on HDFS and I wanted to write a simple tool that will be able to check if the migration was successful. \n\nI have to use PySpark for this task - and here I wanted to ask for advice on how would you approached it.  \n   \nFirst, I think I'll check if the columns in one table are the same as the columns in the other, and then whether the data types in are identical \n\n  \nThis seems simple, but I wanted to ask how you would approach the very issue of comparing rows and individual values \u200b\u200b- do you have any idea what function methods to use?\n\nMaybe some hashing of records, or some kind of joins on two dataframes ?\n\nThe goal is to check what are differences, and catch them up and show in some summary or table. \n\nI think dataframes can be huge, so would be great to do it in pretty smart/lazy way. Would appreciate any help. Thanks\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n ", "author_fullname": "t2_835lb23v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark data migration - how to compare 2 data frames without using any external tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16f3w5e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694361656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I have a problem, I&amp;#39;m migrating mssql data to a data lake based on HDFS and I wanted to write a simple tool that will be able to check if the migration was successful. &lt;/p&gt;\n\n&lt;p&gt;I have to use PySpark for this task - and here I wanted to ask for advice on how would you approached it.  &lt;/p&gt;\n\n&lt;p&gt;First, I think I&amp;#39;ll check if the columns in one table are the same as the columns in the other, and then whether the data types in are identical &lt;/p&gt;\n\n&lt;p&gt;This seems simple, but I wanted to ask how you would approach the very issue of comparing rows and individual values \u200b\u200b- do you have any idea what function methods to use?&lt;/p&gt;\n\n&lt;p&gt;Maybe some hashing of records, or some kind of joins on two dataframes ?&lt;/p&gt;\n\n&lt;p&gt;The goal is to check what are differences, and catch them up and show in some summary or table. &lt;/p&gt;\n\n&lt;p&gt;I think dataframes can be huge, so would be great to do it in pretty smart/lazy way. Would appreciate any help. Thanks&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16f3w5e", "is_robot_indexable": true, "report_reasons": null, "author": "Purple_Wrap9596", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16f3w5e/pyspark_data_migration_how_to_compare_2_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16f3w5e/pyspark_data_migration_how_to_compare_2_data/", "subreddit_subscribers": 127914, "created_utc": 1694361656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Build Data Products? - Learn about Metric-Targeting, Semantic Engineering, Model Validation, and More.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16fql3e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1694423786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/how-to-build-data-products-design", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16fql3e", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16fql3e/how_to_build_data_products_learn_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/how-to-build-data-products-design", "subreddit_subscribers": 127914, "created_utc": 1694423786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview with Seth Wiesman (Materialize)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_16fgtic", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xtVs5y6S5k2xhwvSZ0dScc6hk4NytwMuA0NO--wjUgo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694392229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/hubertdulay/p/interview-with-seth-wiesman-materialize?utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zjx7Uc1hEd0B-Vwrx62AKaofgXZkZ3-6lYvhobEaHU8.jpg?auto=webp&amp;s=edb9b27fcfcb55c4b515b0a71a043b46a6b35e85", "width": 170, "height": 170}, "resolutions": [{"url": "https://external-preview.redd.it/zjx7Uc1hEd0B-Vwrx62AKaofgXZkZ3-6lYvhobEaHU8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=100dfb12fdcad3ee0349d8e78770266269a066ab", "width": 108, "height": 108}], "variants": {}, "id": "XPfoqna9Yj25waJh0iDNlNWPjCX87lqjgkiMP5ZiH5k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16fgtic", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16fgtic/interview_with_seth_wiesman_materialize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/hubertdulay/p/interview-with-seth-wiesman-materialize?utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 127914, "created_utc": 1694392229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, as the title says I am the only one at my company that is responsible, well I would not say responsible but the one who should bring some strong solutions for the data lineage of the company. The deal is that everyone at the company uses google sheets and they like that because they can manage whatever they want to manage there, most of our data sources come from third parties like GIS web apps, ARP softwares and some other project management apps. And putting this into spreadsheet and cross data in a pain. The process right now is a pull everything I need put it in s3 bucket it, read it in a lambda an return the url for the report (ya they want report, don\u2019t like visuals ). And this is not the way for many reasons I have been learning through this data journey. So I am planning implementing something that empowers teams with data and do their own reports. Because we already have google env. Was thinking keeping the lambdas and s3 and create a data warehouse in google big query which connect with google spreadsheets and looker (try to encourage to use it). But problem comes with stack tech I am the only responsible for this to come up with a solution and don\u2019t want to make a mess and generate a costly solution that no one wanted to use. What are your recommendations and thoughts? I have seen databricks to do pre-processing then DBT to help to create data structures in big query? Or just use all google environment to all this? Yeah basically I little lost here and, alone lol", "author_fullname": "t2_42yrzhea", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Overcome spreadsheet company for a one man dataeng team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16fl51g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694404364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, as the title says I am the only one at my company that is responsible, well I would not say responsible but the one who should bring some strong solutions for the data lineage of the company. The deal is that everyone at the company uses google sheets and they like that because they can manage whatever they want to manage there, most of our data sources come from third parties like GIS web apps, ARP softwares and some other project management apps. And putting this into spreadsheet and cross data in a pain. The process right now is a pull everything I need put it in s3 bucket it, read it in a lambda an return the url for the report (ya they want report, don\u2019t like visuals ). And this is not the way for many reasons I have been learning through this data journey. So I am planning implementing something that empowers teams with data and do their own reports. Because we already have google env. Was thinking keeping the lambdas and s3 and create a data warehouse in google big query which connect with google spreadsheets and looker (try to encourage to use it). But problem comes with stack tech I am the only responsible for this to come up with a solution and don\u2019t want to make a mess and generate a costly solution that no one wanted to use. What are your recommendations and thoughts? I have seen databricks to do pre-processing then DBT to help to create data structures in big query? Or just use all google environment to all this? Yeah basically I little lost here and, alone lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16fl51g", "is_robot_indexable": true, "report_reasons": null, "author": "josejo9423", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16fl51g/overcome_spreadsheet_company_for_a_one_man/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16fl51g/overcome_spreadsheet_company_for_a_one_man/", "subreddit_subscribers": 127914, "created_utc": 1694404364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nHoping to spark some healthy debate over Git workflows.\n\nDo you think experienced engineers (e.g. Senior/Lead/Principal) should be allowed to merge from `branch` --&gt; `master`/`main`** without review?\n\n**or whatever you call your production branch\n\nI'll give a couple of examples below, for context:\n- Engineer opens a hotfix merge/pull request to fix an Airflow pipeline issue which is causing a production job to fail\n- Engineer opens a maintenance/BAU change to dbt reporting model\n- Engineer opens a new feature request which is \"urgent\"\n\nWe're currently having this discussion internally, and my feeling is that every MR/PR should be reviewed and approved by another engineer before it is merged into `master`. My reasoning behind this is:\n- It's possible that mistakes have been made and the engineer who has made those changes might overlook them\n  - Often times it takes a fresh pair of eyes to see issues or give a different perspective on changes which can help to triage issues before they occur\n- Any changes that can affect production pipelines should be treated with caution either because they can break said pipelines or the data outcomes are not what was expected\n  - I see production jobs/pipelines/code as something that needs to be managed carefully given that it can cause data to be late, business-critical reports to be incorrect and data consumers to become agitated or downright pissed-off\n\nI'm curious to hear what other engineers think on this topic and get some fresh perspectives that I hadn't considered before.", "author_fullname": "t2_pctu6cby", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Git - Merging to Master", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16fsf8x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694430642.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694430317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;Hoping to spark some healthy debate over Git workflows.&lt;/p&gt;\n\n&lt;p&gt;Do you think experienced engineers (e.g. Senior/Lead/Principal) should be allowed to merge from &lt;code&gt;branch&lt;/code&gt; --&amp;gt; &lt;code&gt;master&lt;/code&gt;/&lt;code&gt;main&lt;/code&gt;** without review?&lt;/p&gt;\n\n&lt;p&gt;**or whatever you call your production branch&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll give a couple of examples below, for context:\n- Engineer opens a hotfix merge/pull request to fix an Airflow pipeline issue which is causing a production job to fail\n- Engineer opens a maintenance/BAU change to dbt reporting model\n- Engineer opens a new feature request which is &amp;quot;urgent&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re currently having this discussion internally, and my feeling is that every MR/PR should be reviewed and approved by another engineer before it is merged into &lt;code&gt;master&lt;/code&gt;. My reasoning behind this is:\n- It&amp;#39;s possible that mistakes have been made and the engineer who has made those changes might overlook them\n  - Often times it takes a fresh pair of eyes to see issues or give a different perspective on changes which can help to triage issues before they occur\n- Any changes that can affect production pipelines should be treated with caution either because they can break said pipelines or the data outcomes are not what was expected\n  - I see production jobs/pipelines/code as something that needs to be managed carefully given that it can cause data to be late, business-critical reports to be incorrect and data consumers to become agitated or downright pissed-off&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to hear what other engineers think on this topic and get some fresh perspectives that I hadn&amp;#39;t considered before.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16fsf8x", "is_robot_indexable": true, "report_reasons": null, "author": "arthur_mills", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16fsf8x/git_merging_to_master/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16fsf8x/git_merging_to_master/", "subreddit_subscribers": 127914, "created_utc": 1694430317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Based on \\[this article\\]([https://medium.com/@mikldd/the-struggles-scaling-data-teams-face-95ca8eb874f3](https://medium.com/@mikldd/the-struggles-scaling-data-teams-face-95ca8eb874f3))\n\nhttps://preview.redd.it/dc4fmwk1jlnb1.png?width=1418&amp;format=png&amp;auto=webp&amp;s=2966492f8a82b2d094c374dda5b7f3ac3d76b053\n\nI was curious to know what everyone else setup is.\n\nExample: \n\n* **Team size**: 10-50 members.\n* **Characteristics**: \n   * **Data models:** 500-3000\n   * **Commit** **frequency**: 11-100 commits per week (per team)\n   * **Data volume**: 100GB-1TB.\n   * **Environments**: 4 (e.g., development, qa, staging, and production)\n   * **Deployments**: 10 times per month.\n   * **Rollbacks**: 2 times per month.\n   * **Data warehouse**: Snowflake\n   * **Cost**: $$ ", "author_fullname": "t2_4ymkgdql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Size of the DWH and number of operations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"dc4fmwk1jlnb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 28, "x": 108, "u": "https://preview.redd.it/dc4fmwk1jlnb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c0ae3989c1bfcd21bafaebb8a760d2973beea9ab"}, {"y": 56, "x": 216, "u": "https://preview.redd.it/dc4fmwk1jlnb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9f78ccebbc5db3b406dcd403d185044f12cad985"}, {"y": 83, "x": 320, "u": "https://preview.redd.it/dc4fmwk1jlnb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9c8fcc5aecec7689054b452cd1bd159f7e6e8323"}, {"y": 167, "x": 640, "u": "https://preview.redd.it/dc4fmwk1jlnb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=11688041ce9e4ad224bcd3d10a1f5ae2e1aa9a16"}, {"y": 251, "x": 960, "u": "https://preview.redd.it/dc4fmwk1jlnb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ac99cecd92538f38e66dc2ab05d4f9565b8824fe"}, {"y": 283, "x": 1080, "u": "https://preview.redd.it/dc4fmwk1jlnb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=426651cff33440f79f12478bb47a765c58778dac"}], "s": {"y": 372, "x": 1418, "u": "https://preview.redd.it/dc4fmwk1jlnb1.png?width=1418&amp;format=png&amp;auto=webp&amp;s=2966492f8a82b2d094c374dda5b7f3ac3d76b053"}, "id": "dc4fmwk1jlnb1"}}, "name": "t3_16fqx41", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/g8IwRgufFCCil9M4dDlvCpSIvpO0eewfM65_6ZDG97M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1694425016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Based on [this article](&lt;a href=\"https://medium.com/@mikldd/the-struggles-scaling-data-teams-face-95ca8eb874f3\"&gt;https://medium.com/@mikldd/the-struggles-scaling-data-teams-face-95ca8eb874f3&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/dc4fmwk1jlnb1.png?width=1418&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2966492f8a82b2d094c374dda5b7f3ac3d76b053\"&gt;https://preview.redd.it/dc4fmwk1jlnb1.png?width=1418&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2966492f8a82b2d094c374dda5b7f3ac3d76b053&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I was curious to know what everyone else setup is.&lt;/p&gt;\n\n&lt;p&gt;Example: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Team size&lt;/strong&gt;: 10-50 members.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Characteristics&lt;/strong&gt;: \n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Data models:&lt;/strong&gt; 500-3000&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Commit&lt;/strong&gt; &lt;strong&gt;frequency&lt;/strong&gt;: 11-100 commits per week (per team)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data volume&lt;/strong&gt;: 100GB-1TB.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Environments&lt;/strong&gt;: 4 (e.g., development, qa, staging, and production)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Deployments&lt;/strong&gt;: 10 times per month.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Rollbacks&lt;/strong&gt;: 2 times per month.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data warehouse&lt;/strong&gt;: Snowflake&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Cost&lt;/strong&gt;: $$ &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1a2zgm6pcCFgOHIQc8qGAeXQjCiJX2ASfEKeFQAm_AU.jpg?auto=webp&amp;s=0107b8993ffe23cfdad945484ae508a9c1502ea8", "width": 1200, "height": 607}, "resolutions": [{"url": "https://external-preview.redd.it/1a2zgm6pcCFgOHIQc8qGAeXQjCiJX2ASfEKeFQAm_AU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a8687063420b81c7db2f239c702bd2849132ff06", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/1a2zgm6pcCFgOHIQc8qGAeXQjCiJX2ASfEKeFQAm_AU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=987eb3284fb6b755d4b30faa6a76052e0ff8cdfc", "width": 216, "height": 109}, {"url": "https://external-preview.redd.it/1a2zgm6pcCFgOHIQc8qGAeXQjCiJX2ASfEKeFQAm_AU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b570c29ad76464592b737582e60374f936cfd210", "width": 320, "height": 161}, {"url": "https://external-preview.redd.it/1a2zgm6pcCFgOHIQc8qGAeXQjCiJX2ASfEKeFQAm_AU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ffa1738bcd06eae375f3300e67f5e78acf0c4c43", "width": 640, "height": 323}, {"url": "https://external-preview.redd.it/1a2zgm6pcCFgOHIQc8qGAeXQjCiJX2ASfEKeFQAm_AU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=34bca452a598e0255d5734170fe2024b0bd448e0", "width": 960, "height": 485}, {"url": "https://external-preview.redd.it/1a2zgm6pcCFgOHIQc8qGAeXQjCiJX2ASfEKeFQAm_AU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c53f750942604715cbb415da6db3cc2237cac8f1", "width": 1080, "height": 546}], "variants": {}, "id": "nstjHH3XBaaV-9upMu5IKd0vAuvQuxju1l7E3O6dn_4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16fqx41", "is_robot_indexable": true, "report_reasons": null, "author": "SnooBeans3890", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16fqx41/size_of_the_dwh_and_number_of_operations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16fqx41/size_of_the_dwh_and_number_of_operations/", "subreddit_subscribers": 127914, "created_utc": 1694425016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow DE's: As someone who's dedicated over a decade to Data Engineering, I'm enthusiastic about disseminating my expertise on other platforms for the benefit of fellow professionals. To support this endeavor, I actively maintain a presence on Medium ([https://medium.com/@balachandar-paulraj](https://medium.com/@balachandar-paulraj)) by writing data engineering blogs and imparting my expertise to coworkers  and college students intrigued by the world of Data Engineering. However, my passion for contributing persists, and I'm excited about  participating in volunteer activities with NGOs or instructing free college-level courses. Can someone please guide me if you have details on this?", "author_fullname": "t2_jeh8zfh9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking guidelines for taking data engineering courses or helping NGOs for data related requirements", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16flqt7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694406248.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow DE&amp;#39;s: As someone who&amp;#39;s dedicated over a decade to Data Engineering, I&amp;#39;m enthusiastic about disseminating my expertise on other platforms for the benefit of fellow professionals. To support this endeavor, I actively maintain a presence on Medium (&lt;a href=\"https://medium.com/@balachandar-paulraj\"&gt;https://medium.com/@balachandar-paulraj&lt;/a&gt;) by writing data engineering blogs and imparting my expertise to coworkers  and college students intrigued by the world of Data Engineering. However, my passion for contributing persists, and I&amp;#39;m excited about  participating in volunteer activities with NGOs or instructing free college-level courses. Can someone please guide me if you have details on this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aODSq92pV7ezA7Ow8q6keExMBApORzHZRq4GQ6jiR98.jpg?auto=webp&amp;s=0da6557a73141b3b398950052650bcabce075540", "width": 2320, "height": 3088}, "resolutions": [{"url": "https://external-preview.redd.it/aODSq92pV7ezA7Ow8q6keExMBApORzHZRq4GQ6jiR98.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fd4686be82246c8eb501e831ef69a14aefd3b20c", "width": 108, "height": 143}, {"url": "https://external-preview.redd.it/aODSq92pV7ezA7Ow8q6keExMBApORzHZRq4GQ6jiR98.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7107631c4de90a486d124454cd7168a4b80b42b0", "width": 216, "height": 287}, {"url": "https://external-preview.redd.it/aODSq92pV7ezA7Ow8q6keExMBApORzHZRq4GQ6jiR98.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=affe37aedacd103bf8c18030c5dd840367781716", "width": 320, "height": 425}, {"url": "https://external-preview.redd.it/aODSq92pV7ezA7Ow8q6keExMBApORzHZRq4GQ6jiR98.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=77c2223fcefe622b1b0848e24668f8abe1fa6354", "width": 640, "height": 851}, {"url": "https://external-preview.redd.it/aODSq92pV7ezA7Ow8q6keExMBApORzHZRq4GQ6jiR98.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4ef8d7707b7ae19174a0a8581662445681ad757c", "width": 960, "height": 1277}, {"url": "https://external-preview.redd.it/aODSq92pV7ezA7Ow8q6keExMBApORzHZRq4GQ6jiR98.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=20e202976fd847b227ad36f3c3f7393668265696", "width": 1080, "height": 1437}], "variants": {}, "id": "Em4pFOPXwrEVR_nva81YFYYzWvLyRywkIAsgAq-JG1I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16flqt7", "is_robot_indexable": true, "report_reasons": null, "author": "balachandar_paulraj", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16flqt7/seeking_guidelines_for_taking_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16flqt7/seeking_guidelines_for_taking_data_engineering/", "subreddit_subscribers": 127914, "created_utc": 1694406248.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why Your Data Pipelines Need Closed-Loop Feedback Control", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_16fs97d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/j4VORkAJncX9m5jD9LQ0KLH6C1YVpYtLdt4A5ckRL8g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694429787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "towardsdatascience.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://towardsdatascience.com/why-your-data-pipelines-need-closed-loop-feedback-control-76e28e3565f", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zvE-8TlL8CDJL-rOfQIhMzSV0t-VnEb3VdwGznXmtls.jpg?auto=webp&amp;s=675ae397f7fe1cda5ac2e987d4daf34e0c9525bd", "width": 1200, "height": 798}, "resolutions": [{"url": "https://external-preview.redd.it/zvE-8TlL8CDJL-rOfQIhMzSV0t-VnEb3VdwGznXmtls.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=27e68d86c905fff335a45d18574fdceb7f2c11ec", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/zvE-8TlL8CDJL-rOfQIhMzSV0t-VnEb3VdwGznXmtls.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a9d6a24d34fb95350de0d0251336419e5eb934b3", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/zvE-8TlL8CDJL-rOfQIhMzSV0t-VnEb3VdwGznXmtls.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa72ede596ae3190ddc4ac6f15ca3c6005aa8d30", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/zvE-8TlL8CDJL-rOfQIhMzSV0t-VnEb3VdwGznXmtls.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c81e4a6a79e9066be48717d88b4c22c3736fdc69", "width": 640, "height": 425}, {"url": "https://external-preview.redd.it/zvE-8TlL8CDJL-rOfQIhMzSV0t-VnEb3VdwGznXmtls.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2dfad5afae4f0321537091e2ccd42509b977708", "width": 960, "height": 638}, {"url": "https://external-preview.redd.it/zvE-8TlL8CDJL-rOfQIhMzSV0t-VnEb3VdwGznXmtls.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b322c5aae4ad23ebd08864a601ffac598fd11f41", "width": 1080, "height": 718}], "variants": {}, "id": "dW25HndVwj2OlQgzVfMg9uRBHQ5LV_MJL3ff94Cksw8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16fs97d", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16fs97d/why_your_data_pipelines_need_closedloop_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://towardsdatascience.com/why-your-data-pipelines-need-closed-loop-feedback-control-76e28e3565f", "subreddit_subscribers": 127914, "created_utc": 1694429787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am a fresh graduate who is hoping to move into the industry side. I actually don't have any work experience. Could you please give me some tips to follow to pass the data engineering interview and get a chance to find a job. Any responses are highly appreciated.", "author_fullname": "t2_94z2yiq5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tips to pass Data Engineering interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16fuzjq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694438067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a fresh graduate who is hoping to move into the industry side. I actually don&amp;#39;t have any work experience. Could you please give me some tips to follow to pass the data engineering interview and get a chance to find a job. Any responses are highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16fuzjq", "is_robot_indexable": true, "report_reasons": null, "author": "LengthOld9943", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16fuzjq/tips_to_pass_data_engineering_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16fuzjq/tips_to_pass_data_engineering_interviews/", "subreddit_subscribers": 127914, "created_utc": 1694438067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got some spare money from a training budget in my company until the end of the year and I'd like to utilize it to learn for specific certs.  \nI've already got a GCP DE (valid until 2024), SnowPro Core (until 2025) and Azure DP-900. At my current job I work mainly with Spark, AWS and Snowflake (to some extent). My ideas so far:  \n\\- SnowPro Advanced Data Engineer - the most appealing one to me, but it seems hard and I am afraid that I don't have enough work experience with Snowflake, as I still didn't use most of its advanced functions.  \n\\- AWS Cloud Practitioner - the easiest option from a bunch but relatively low value, but I would have a cert from each major cloud provider :)  \n\\- AWS Solution Architect - well, the more ambitious approach than a previous one.  \n\\- Databricks Apache Spark Developer - the option for Spark.  \n\\- Kubernetes Application Developer (CKAD) - the hardest and possibly most non-standard one for a data engineer, but I really liked working with K8s &amp; containers.  \n\n\nI am open to hear your suggestions. Anyway, I bet a lot of folks here are in similar situation that they want to spend their outstanding training budget :p  \n", "author_fullname": "t2_9e7m1qmr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which cert to do next", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16frwhu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694428552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got some spare money from a training budget in my company until the end of the year and I&amp;#39;d like to utilize it to learn for specific certs.&lt;br/&gt;\nI&amp;#39;ve already got a GCP DE (valid until 2024), SnowPro Core (until 2025) and Azure DP-900. At my current job I work mainly with Spark, AWS and Snowflake (to some extent). My ideas so far:&lt;br/&gt;\n- SnowPro Advanced Data Engineer - the most appealing one to me, but it seems hard and I am afraid that I don&amp;#39;t have enough work experience with Snowflake, as I still didn&amp;#39;t use most of its advanced functions.&lt;br/&gt;\n- AWS Cloud Practitioner - the easiest option from a bunch but relatively low value, but I would have a cert from each major cloud provider :)&lt;br/&gt;\n- AWS Solution Architect - well, the more ambitious approach than a previous one.&lt;br/&gt;\n- Databricks Apache Spark Developer - the option for Spark.&lt;br/&gt;\n- Kubernetes Application Developer (CKAD) - the hardest and possibly most non-standard one for a data engineer, but I really liked working with K8s &amp;amp; containers.  &lt;/p&gt;\n\n&lt;p&gt;I am open to hear your suggestions. Anyway, I bet a lot of folks here are in similar situation that they want to spend their outstanding training budget :p  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16frwhu", "is_robot_indexable": true, "report_reasons": null, "author": "LewWariat", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16frwhu/which_cert_to_do_next/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16frwhu/which_cert_to_do_next/", "subreddit_subscribers": 127914, "created_utc": 1694428552.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}