{"kind": "Listing", "data": {"after": "t3_16h9x24", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Sure the Internet archive may have a lot of supporters and other non profit organizations backing them and working with them, the lawsuits come from pretty powerful companies with a lot of money. If they win this new lawsuit, I fear this could force the Internet archive to shut down. Any chances of this being real or is this an over exaggeration?", "author_fullname": "t2_2atcwqee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any chance of the Internet archive being forcefully shut down?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16grq4d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 207, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 207, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694526119.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sure the Internet archive may have a lot of supporters and other non profit organizations backing them and working with them, the lawsuits come from pretty powerful companies with a lot of money. If they win this new lawsuit, I fear this could force the Internet archive to shut down. Any chances of this being real or is this an over exaggeration?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16grq4d", "is_robot_indexable": true, "report_reasons": null, "author": "Coolkatisa2511", "discussion_type": null, "num_comments": 84, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16grq4d/is_there_any_chance_of_the_internet_archive_being/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16grq4d/is_there_any_chance_of_the_internet_archive_being/", "subreddit_subscribers": 702084, "created_utc": 1694526119.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If anyone uses this software on Linux, might want to check for the IOCs (indicators of compromise) stated in the report.", "author_fullname": "t2_6eoit", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trojanized Free Download Manager found to contain a Linux backdoor", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "name": "t3_16h8za7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-apEOTyfEeEWhYfuC57ZE110vAw2Ct5FRdvsDU0vo0A.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694567000.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "securelist.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If anyone uses this software on Linux, might want to check for the IOCs (indicators of compromise) stated in the report.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://securelist.com/backdoored-free-download-manager-linux-malware/110465/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rkwplEaEqk2jHsBt0vSWk9z3xDXidSOeXxtVphdatSA.jpg?auto=webp&amp;s=01f5cbbc04b6121fc7f631f6e09373a1454775da", "width": 2705, "height": 1478}, "resolutions": [{"url": "https://external-preview.redd.it/rkwplEaEqk2jHsBt0vSWk9z3xDXidSOeXxtVphdatSA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=387aae7f392c7818339883ca856c5dfc8ea04f4b", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/rkwplEaEqk2jHsBt0vSWk9z3xDXidSOeXxtVphdatSA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=68de4f6715596205f7a36be246d2cffabdf4d3cc", "width": 216, "height": 118}, {"url": "https://external-preview.redd.it/rkwplEaEqk2jHsBt0vSWk9z3xDXidSOeXxtVphdatSA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=867c818a9c8e372f017de2fb2406666fe490d185", "width": 320, "height": 174}, {"url": "https://external-preview.redd.it/rkwplEaEqk2jHsBt0vSWk9z3xDXidSOeXxtVphdatSA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2d8dd38be6909ab177fbe0c4794c0ca9b34e3470", "width": 640, "height": 349}, {"url": "https://external-preview.redd.it/rkwplEaEqk2jHsBt0vSWk9z3xDXidSOeXxtVphdatSA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3cf6d607172f626e66bf3e6b26527bf83f0caaf3", "width": 960, "height": 524}, {"url": "https://external-preview.redd.it/rkwplEaEqk2jHsBt0vSWk9z3xDXidSOeXxtVphdatSA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=47ddfa79ae86dd54384a01c3dec61356021919ab", "width": 1080, "height": 590}], "variants": {}, "id": "cMgCh80Jy7wmuWkEfqNC8pRfLiaDq-9FuZSLgw3i-rk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16h8za7", "is_robot_indexable": true, "report_reasons": null, "author": "hopscotchchampion", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16h8za7/trojanized_free_download_manager_found_to_contain/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://securelist.com/backdoored-free-download-manager-linux-malware/110465/", "subreddit_subscribers": 702084, "created_utc": 1694567000.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a hard time finding fitting advice because my situation/needs don't seem to be common or because people set up full LAN caches with servers which I feel would be overkill.\n\nI live in an area for which most likely there will never be high-speed internet in my lifetime. Best I can get is DSL with 50 Mbit down.\n\nIt's no longer uncommon for games to be like 150 GB in size, which take half a day to download. I used to uninstall and redownload games on my limited SSD space as needed, but this is no longer really feasible.\n\nMy idea is I would instead download games onto external hard drives and grab them from there. But I have a hard time figuring out if this is even a good idea. Would these hard drives not last long if I read so much data from them so often? Is it worth going with large 18 TB ones? What do I need to look out for in terms of read/write speeds?\n\nBasically I'm wondering if anyone stores their digital games on hard drives and if they have some advice for me because I feel kinda lost.", "author_fullname": "t2_tsxc5rct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I Want to Datahoard Games for Practical Reasons.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gp5g6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694519040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a hard time finding fitting advice because my situation/needs don&amp;#39;t seem to be common or because people set up full LAN caches with servers which I feel would be overkill.&lt;/p&gt;\n\n&lt;p&gt;I live in an area for which most likely there will never be high-speed internet in my lifetime. Best I can get is DSL with 50 Mbit down.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s no longer uncommon for games to be like 150 GB in size, which take half a day to download. I used to uninstall and redownload games on my limited SSD space as needed, but this is no longer really feasible.&lt;/p&gt;\n\n&lt;p&gt;My idea is I would instead download games onto external hard drives and grab them from there. But I have a hard time figuring out if this is even a good idea. Would these hard drives not last long if I read so much data from them so often? Is it worth going with large 18 TB ones? What do I need to look out for in terms of read/write speeds?&lt;/p&gt;\n\n&lt;p&gt;Basically I&amp;#39;m wondering if anyone stores their digital games on hard drives and if they have some advice for me because I feel kinda lost.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16gp5g6", "is_robot_indexable": true, "report_reasons": null, "author": "Idontharasspeople", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16gp5g6/i_want_to_datahoard_games_for_practical_reasons/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16gp5g6/i_want_to_datahoard_games_for_practical_reasons/", "subreddit_subscribers": 702084, "created_utc": 1694519040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/stj3o7jvownb1.jpg?width=6500&amp;format=pjpg&amp;auto=webp&amp;s=a4c5b446a74eb010b3fed4935b0772aff791d622\n\nHey everyone! We overhauled a couple of dozen computers in our company this week, and I ended up with a ton of 500 GB HDDs (3 320 GB).\n\nSadly, most of them are those small **5400rpm ones, 7\\~10 years old** (day-to-day office use), but I really don't want to get rid of them.\n\nWhat would you do with it? They're old, but people in this sub usually say, \"I'll use a 10-year-old Seagate with thousands of cycles if they still work\", so I might as well try it!\n\nI don't have much experience regarding data hoarding (4\\~5 TBs in a home lab), but these would be useful to me. **Any suggestions on RAID modes?** I'd probably use 1 or 2 PCI-e to SATA adapters and get them all into a huge case.\n\nIf the picture isn't loading properly, here's an IMGUR of it: [https://i.imgur.com/TPpXTr1.jpeg](https://i.imgur.com/TPpXTr1.jpeg)\n\nThanks again for your help!\n\n&amp;#x200B;", "author_fullname": "t2_2anukqrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you do with these? (Old HDDs)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 114, "top_awarded_type": null, "hide_score": false, "media_metadata": {"stj3o7jvownb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 88, "x": 108, "u": "https://preview.redd.it/stj3o7jvownb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec3e5c89fd0745b3414d5f87beeab954887c5214"}, {"y": 176, "x": 216, "u": "https://preview.redd.it/stj3o7jvownb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=68bb558a2f8be54a2dc4900bda820186eda4a4ab"}, {"y": 260, "x": 320, "u": "https://preview.redd.it/stj3o7jvownb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=46973ae9cd7d26eb2c82339c359ada47fd8d719a"}, {"y": 521, "x": 640, "u": "https://preview.redd.it/stj3o7jvownb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ad4de9606fb97fc7465b9d2ebfdc6af4f79d3644"}, {"y": 782, "x": 960, "u": "https://preview.redd.it/stj3o7jvownb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=64f3dee6a6d3af6556ffea06c2891e45afb75d6d"}, {"y": 880, "x": 1080, "u": "https://preview.redd.it/stj3o7jvownb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3159755fb7aad94b230fbffc5db1c7663f1ddd20"}], "s": {"y": 5301, "x": 6500, "u": "https://preview.redd.it/stj3o7jvownb1.jpg?width=6500&amp;format=pjpg&amp;auto=webp&amp;s=a4c5b446a74eb010b3fed4935b0772aff791d622"}, "id": "stj3o7jvownb1"}}, "name": "t3_16h6ev1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UBPctQzwAGY9cunbbvmbkqkLKyTxYQdH1dQ_CwIk9HI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1694560416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/stj3o7jvownb1.jpg?width=6500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a4c5b446a74eb010b3fed4935b0772aff791d622\"&gt;https://preview.redd.it/stj3o7jvownb1.jpg?width=6500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a4c5b446a74eb010b3fed4935b0772aff791d622&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hey everyone! We overhauled a couple of dozen computers in our company this week, and I ended up with a ton of 500 GB HDDs (3 320 GB).&lt;/p&gt;\n\n&lt;p&gt;Sadly, most of them are those small &lt;strong&gt;5400rpm ones, 7~10 years old&lt;/strong&gt; (day-to-day office use), but I really don&amp;#39;t want to get rid of them.&lt;/p&gt;\n\n&lt;p&gt;What would you do with it? They&amp;#39;re old, but people in this sub usually say, &amp;quot;I&amp;#39;ll use a 10-year-old Seagate with thousands of cycles if they still work&amp;quot;, so I might as well try it!&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have much experience regarding data hoarding (4~5 TBs in a home lab), but these would be useful to me. &lt;strong&gt;Any suggestions on RAID modes?&lt;/strong&gt; I&amp;#39;d probably use 1 or 2 PCI-e to SATA adapters and get them all into a huge case.&lt;/p&gt;\n\n&lt;p&gt;If the picture isn&amp;#39;t loading properly, here&amp;#39;s an IMGUR of it: &lt;a href=\"https://i.imgur.com/TPpXTr1.jpeg\"&gt;https://i.imgur.com/TPpXTr1.jpeg&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks again for your help!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/UmdwJpZ6IYLg2ARqxWft1V5IIVzK2RgVQvFjayy2BHI.jpg?auto=webp&amp;s=00250465aa8e58f47eb7355a6babca6231704a58", "width": 6500, "height": 5301}, "resolutions": [{"url": "https://external-preview.redd.it/UmdwJpZ6IYLg2ARqxWft1V5IIVzK2RgVQvFjayy2BHI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1334280ced3abc8e78249f23b6007644650b4f21", "width": 108, "height": 88}, {"url": "https://external-preview.redd.it/UmdwJpZ6IYLg2ARqxWft1V5IIVzK2RgVQvFjayy2BHI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2da1381e63d224773b0edea5348ac2d3ac9a6b66", "width": 216, "height": 176}, {"url": "https://external-preview.redd.it/UmdwJpZ6IYLg2ARqxWft1V5IIVzK2RgVQvFjayy2BHI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ace17fd9d624f94d868e6c97c52e0927f158606b", "width": 320, "height": 260}, {"url": "https://external-preview.redd.it/UmdwJpZ6IYLg2ARqxWft1V5IIVzK2RgVQvFjayy2BHI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a594f21ec30c74c6bb4da428cf17e4445508f249", "width": 640, "height": 521}, {"url": "https://external-preview.redd.it/UmdwJpZ6IYLg2ARqxWft1V5IIVzK2RgVQvFjayy2BHI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d822730bf27fdc7a05bf26a926fccf3ebc578765", "width": 960, "height": 782}, {"url": "https://external-preview.redd.it/UmdwJpZ6IYLg2ARqxWft1V5IIVzK2RgVQvFjayy2BHI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=979a3e5984b15a4ddc5d949d4518346a7bd825f3", "width": 1080, "height": 880}], "variants": {}, "id": "2yyaXm9qcbiWUojhemQtoRfXDDyBcqeaAN_zS2N6mM8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16h6ev1", "is_robot_indexable": true, "report_reasons": null, "author": "krdozo", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16h6ev1/what_would_you_do_with_these_old_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16h6ev1/what_would_you_do_with_these_old_hdds/", "subreddit_subscribers": 702084, "created_utc": 1694560416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it just anything that brings you joy? Or is it things that could be useful later?", "author_fullname": "t2_hlypar61", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of stuff do you hoard?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hfzvp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694588401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it just anything that brings you joy? Or is it things that could be useful later?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "34TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16hfzvp", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic_Cup_8436", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16hfzvp/what_kind_of_stuff_do_you_hoard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hfzvp/what_kind_of_stuff_do_you_hoard/", "subreddit_subscribers": 702084, "created_utc": 1694588401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! I like collecting sewing patterns. I already have quite a few, so if there's anyone who likes to hoard patterns too, let's do an exchange.\n\n(Not sewing books or magazines.)", "author_fullname": "t2_d697fcaow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sewing patterns", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16haxom", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694572368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I like collecting sewing patterns. I already have quite a few, so if there&amp;#39;s anyone who likes to hoard patterns too, let&amp;#39;s do an exchange.&lt;/p&gt;\n\n&lt;p&gt;(Not sewing books or magazines.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16haxom", "is_robot_indexable": true, "report_reasons": null, "author": "happy_deehee27", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16haxom/sewing_patterns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16haxom/sewing_patterns/", "subreddit_subscribers": 702084, "created_utc": 1694572368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "with ao3 instituting their new rate limit and ff still having nothing from pre 2017 archived i still think we need to do a big fanfic scrape (obviously with no ai scraping i hate that) is anyone onboard", "author_fullname": "t2_x3j2y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "fic archiving", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16haid8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694571173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;with ao3 instituting their new rate limit and ff still having nothing from pre 2017 archived i still think we need to do a big fanfic scrape (obviously with no ai scraping i hate that) is anyone onboard&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16haid8", "is_robot_indexable": true, "report_reasons": null, "author": "worthplayingfor25", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16haid8/fic_archiving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16haid8/fic_archiving/", "subreddit_subscribers": 702084, "created_utc": 1694571173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I've been looking at how to extract 3d models from an online metaverse thing called Spatial. I wanted to download a few models for preservation before they disappear because it's a limited time event but I have no idea how to rip models let alone from an online game. Is it possible and if so how can I do it?", "author_fullname": "t2_8kby4unj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to extract 3d models from an online game?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h73x9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694562173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;ve been looking at how to extract 3d models from an online metaverse thing called Spatial. I wanted to download a few models for preservation before they disappear because it&amp;#39;s a limited time event but I have no idea how to rip models let alone from an online game. Is it possible and if so how can I do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16h73x9", "is_robot_indexable": true, "report_reasons": null, "author": "crash2cool", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16h73x9/is_it_possible_to_extract_3d_models_from_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16h73x9/is_it_possible_to_extract_3d_models_from_an/", "subreddit_subscribers": 702084, "created_utc": 1694562173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Do you know if there is any updated comparison of online storage providers? I noticed that the wiki doesn't have it, so I am asking if anyone has seen anything recently online or if anyone has recently done this research for him/herself and wants to share.\n\nIn particular, I am interested in object-based storage, in other words something that can be attached as endpoint of services like Duplicati for personal cloud backup. Personally, I have a daily script that backs up my NAS remotely. At the moment, I am using OVH, but I am open to other providers.\n\nUsually, the cost is based on storage size plus some extra for network (some even distinguish between inbound and outbound traffic). I know some have linearly growing prices, others work with tiers. In my case I need a bit less than 500GB (I can't quantify network but I think it's minimal since data doesn't change frequently) and with OVH it costs me \\~3-4\u20ac/month.", "author_fullname": "t2_9mioauuf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparison of online storage providers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gq38z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694521718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you know if there is any updated comparison of online storage providers? I noticed that the wiki doesn&amp;#39;t have it, so I am asking if anyone has seen anything recently online or if anyone has recently done this research for him/herself and wants to share.&lt;/p&gt;\n\n&lt;p&gt;In particular, I am interested in object-based storage, in other words something that can be attached as endpoint of services like Duplicati for personal cloud backup. Personally, I have a daily script that backs up my NAS remotely. At the moment, I am using OVH, but I am open to other providers.&lt;/p&gt;\n\n&lt;p&gt;Usually, the cost is based on storage size plus some extra for network (some even distinguish between inbound and outbound traffic). I know some have linearly growing prices, others work with tiers. In my case I need a bit less than 500GB (I can&amp;#39;t quantify network but I think it&amp;#39;s minimal since data doesn&amp;#39;t change frequently) and with OVH it costs me ~3-4\u20ac/month.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16gq38z", "is_robot_indexable": true, "report_reasons": null, "author": "-elmuz-", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16gq38z/comparison_of_online_storage_providers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16gq38z/comparison_of_online_storage_providers/", "subreddit_subscribers": 702084, "created_utc": 1694521718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a dozen of original DVD's that I like the way they are (with official menu's all their contents), but the video and audio files are uncompressed so they take a lot of space.\n\nIs there a way to rip them in ISO while compressing the video files to something like mkv or mp4 ?", "author_fullname": "t2_hrisdzzs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to shrink/downsize a DVD movie ISO ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gprkm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694520744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dozen of original DVD&amp;#39;s that I like the way they are (with official menu&amp;#39;s all their contents), but the video and audio files are uncompressed so they take a lot of space.&lt;/p&gt;\n\n&lt;p&gt;Is there a way to rip them in ISO while compressing the video files to something like mkv or mp4 ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16gprkm", "is_robot_indexable": true, "report_reasons": null, "author": "mulambooo", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16gprkm/how_to_shrinkdownsize_a_dvd_movie_iso/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16gprkm/how_to_shrinkdownsize_a_dvd_movie_iso/", "subreddit_subscribers": 702084, "created_utc": 1694520744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "One of my NAS drive failed and i just bought a new one from Amazon (no choice to have next day shipping) but the dirve is not like the other I have (I only have Iron wolf; all the same). It is absolutely not branded iron wolf or anything else. All I have i white label with \"SEAGATE Recertified product\".  \n\n\nFrom my understanding taht's a drive that was in someone else computer, failed, got fixed and shipped to me. Should I be worried ? ", "author_fullname": "t2_4ebxc4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ordered a Seagate IronWolf and I got a recertified product. Should I return it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16hiktm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694597915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One of my NAS drive failed and i just bought a new one from Amazon (no choice to have next day shipping) but the dirve is not like the other I have (I only have Iron wolf; all the same). It is absolutely not branded iron wolf or anything else. All I have i white label with &amp;quot;SEAGATE Recertified product&amp;quot;.  &lt;/p&gt;\n\n&lt;p&gt;From my understanding taht&amp;#39;s a drive that was in someone else computer, failed, got fixed and shipped to me. Should I be worried ? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16hiktm", "is_robot_indexable": true, "report_reasons": null, "author": "oursondechine", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16hiktm/ordered_a_seagate_ironwolf_and_i_got_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hiktm/ordered_a_seagate_ironwolf_and_i_got_a/", "subreddit_subscribers": 702084, "created_utc": 1694597915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "We're using Elena batcher to write data to cards. The problem is, that it takes a while and you can only do 1 by 1. There's a \"device called EtcherPro ([https://www.balena.io/etcher-pro](https://www.balena.io/etcher-pro)), but it's expensive as hell. Is there an alternative to this?", "author_fullname": "t2_167gag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Write to multiple cards or usb disks at once?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16hig2f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694597438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re using Elena batcher to write data to cards. The problem is, that it takes a while and you can only do 1 by 1. There&amp;#39;s a &amp;quot;device called EtcherPro (&lt;a href=\"https://www.balena.io/etcher-pro\"&gt;https://www.balena.io/etcher-pro&lt;/a&gt;), but it&amp;#39;s expensive as hell. Is there an alternative to this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16hig2f", "is_robot_indexable": true, "report_reasons": null, "author": "42woba", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16hig2f/write_to_multiple_cards_or_usb_disks_at_once/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hig2f/write_to_multiple_cards_or_usb_disks_at_once/", "subreddit_subscribers": 702084, "created_utc": 1694597438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello\n\nMy SanDisk Extreme 4TB SSD failed after a short use of time. I run a macbook book pro. the ssd is used as work-drive and archive. \n\nnow I want to replace the disappointing San Disk. I'm looking for reliability before speed. (read out of photos for lightroom is the main use). \n\n&amp;#x200B;\n\nwhat I don't understand yet:\n\n1.1) is it better to use SATA over NVME for reliability, as they don't heat up as much?\n\n1.2) NVME SSDs generate a lot heat - I didnt like the rubber cover of the san disk or the samsung t7 shield. I think an aluminum case would be smarter to get the heat out or that doesn't matter?\n\n1.3) is it bad to use the APFS encryption? according to some sites this is what causedthe bitflip. should I rather use HFS+ or Exfat?\n\n1.4) should I rather go for 2x 2TB than 4TB to increase reliability and have less dense storage? + spread the risk of one failing? Here I fear of forgeting to use them and underpowering them over a longer time..\n\n1.5) is there a 5W limit in terms of power for external ssd by usb C? I read that some External Cases didn't work with higher end SSDs like the kingston fury renegade because of too high power consumption?\n\n1.6) what else should I look for in terms reliability?\n\nThank you!", "author_fullname": "t2_48erwsli", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External SSD: what to look out for to get better reliability", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hhkgh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694594203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;My SanDisk Extreme 4TB SSD failed after a short use of time. I run a macbook book pro. the ssd is used as work-drive and archive. &lt;/p&gt;\n\n&lt;p&gt;now I want to replace the disappointing San Disk. I&amp;#39;m looking for reliability before speed. (read out of photos for lightroom is the main use). &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;what I don&amp;#39;t understand yet:&lt;/p&gt;\n\n&lt;p&gt;1.1) is it better to use SATA over NVME for reliability, as they don&amp;#39;t heat up as much?&lt;/p&gt;\n\n&lt;p&gt;1.2) NVME SSDs generate a lot heat - I didnt like the rubber cover of the san disk or the samsung t7 shield. I think an aluminum case would be smarter to get the heat out or that doesn&amp;#39;t matter?&lt;/p&gt;\n\n&lt;p&gt;1.3) is it bad to use the APFS encryption? according to some sites this is what causedthe bitflip. should I rather use HFS+ or Exfat?&lt;/p&gt;\n\n&lt;p&gt;1.4) should I rather go for 2x 2TB than 4TB to increase reliability and have less dense storage? + spread the risk of one failing? Here I fear of forgeting to use them and underpowering them over a longer time..&lt;/p&gt;\n\n&lt;p&gt;1.5) is there a 5W limit in terms of power for external ssd by usb C? I read that some External Cases didn&amp;#39;t work with higher end SSDs like the kingston fury renegade because of too high power consumption?&lt;/p&gt;\n\n&lt;p&gt;1.6) what else should I look for in terms reliability?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "4TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16hhkgh", "is_robot_indexable": true, "report_reasons": null, "author": "Wide_Freedom_5199", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16hhkgh/external_ssd_what_to_look_out_for_to_get_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hhkgh/external_ssd_what_to_look_out_for_to_get_better/", "subreddit_subscribers": 702084, "created_utc": 1694594203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have two large files around 300 GB, one of which was a copy of the other. When I use Mac Finder Info to examine their file sizes, I see that both say 389,204,523,260 bytes.\n\nGiven that these two files are supposed to be the same to begin with, and that they match on byte size, could one look at whether the file sizes match for determining file equivalence?\n\nOr could it be two files which are supposed to be the same have the same file size, but different hash?", "author_fullname": "t2_nyd6v06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If two large files which are supposed to be copies of each other have the same byte size, is there a very high probability they are the same, without looking at the hash?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hgac5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694589445.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two large files around 300 GB, one of which was a copy of the other. When I use Mac Finder Info to examine their file sizes, I see that both say 389,204,523,260 bytes.&lt;/p&gt;\n\n&lt;p&gt;Given that these two files are supposed to be the same to begin with, and that they match on byte size, could one look at whether the file sizes match for determining file equivalence?&lt;/p&gt;\n\n&lt;p&gt;Or could it be two files which are supposed to be the same have the same file size, but different hash?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16hgac5", "is_robot_indexable": true, "report_reasons": null, "author": "SeparateFly", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16hgac5/if_two_large_files_which_are_supposed_to_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hgac5/if_two_large_files_which_are_supposed_to_be/", "subreddit_subscribers": 702084, "created_utc": 1694589445.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I got many external hard drives and internal harddrives, I am do not know what to get for future archiving. for my experience, i find external harddrive to fail faster, cheaper and takes up smaller space.(low on time,many on &amp; off counts) as for internal harddrives they lasted very long i even still have a hitachi hard drive that is 10 years old still going strong.\n\n&amp;#x200B;\n\nAs for people who have many internal harddrives,do you have only 1 harddrives docking stations or many harddrive enclosures?\n\n&amp;#x200B;\n\nSo I would like to ask and share your opinion and experience with me:)Thank you.", "author_fullname": "t2_6js5j0uo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internal or external hardrrive for archiving?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hfatk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694585951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got many external hard drives and internal harddrives, I am do not know what to get for future archiving. for my experience, i find external harddrive to fail faster, cheaper and takes up smaller space.(low on time,many on &amp;amp; off counts) as for internal harddrives they lasted very long i even still have a hitachi hard drive that is 10 years old still going strong.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;As for people who have many internal harddrives,do you have only 1 harddrives docking stations or many harddrive enclosures?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;So I would like to ask and share your opinion and experience with me:)Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16hfatk", "is_robot_indexable": true, "report_reasons": null, "author": "MisakaMisakaS100", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16hfatk/internal_or_external_hardrrive_for_archiving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hfatk/internal_or_external_hardrrive_for_archiving/", "subreddit_subscribers": 702084, "created_utc": 1694585951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for the rutgers vs temple sep 9th game, If anyone has this that would be awesome. \n\nThanks!", "author_fullname": "t2_x0w5n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone recording and saving college football streams?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hdv9z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694581113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for the rutgers vs temple sep 9th game, If anyone has this that would be awesome. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16hdv9z", "is_robot_indexable": true, "report_reasons": null, "author": "marcocet", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16hdv9z/anyone_recording_and_saving_college_football/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hdv9z/anyone_recording_and_saving_college_football/", "subreddit_subscribers": 702084, "created_utc": 1694581113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Ok so this is going to sound like a stupid question and it might even be one. But it also seems like a common question, so I'm hoping maybe some experienced hoarders can share their insights.\n\nMy ambition is to download libgen and other shadow libraries and maintain a personal mirror in my house. There is really no practical reason why I want to do this except that I like books and I think its possible shadow libraries won't exist in some futures. Since they exist now, I would like to make a complete copy.\n\nThere are torrents and I can download them. It's about 500 TB total. The first shard I tried to DL was an 11 TB repo. At 1 MB/s (fastest internet available to me in my area), that's ~140 days. This should have been obvious upfront, but bandwidth hasn't been a practical limitation for anything I've wanted to do since the 90s.\n\nSo I thought I had a hardware problem (how to store 500 TB in my house) and I do, but I kindof know how to solve that. What I actually have is a bandwidth problem. Where can I go to download a 11 TB file? And then do it 50 more times to get all of libgen/annas?\n\nI think the real pirates are probably still mailing drives around. Obviously that's not ideal for anyone.\n\nDo datahoarders all work at tech cos and universities with infinite bandwidth?\n\nIs there a site that I can pay money to and they will mail me a set of drives with my torrents on them (seems crazy?)", "author_fullname": "t2_3bjakm7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solving the bandwidth problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hct31", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694577773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ok so this is going to sound like a stupid question and it might even be one. But it also seems like a common question, so I&amp;#39;m hoping maybe some experienced hoarders can share their insights.&lt;/p&gt;\n\n&lt;p&gt;My ambition is to download libgen and other shadow libraries and maintain a personal mirror in my house. There is really no practical reason why I want to do this except that I like books and I think its possible shadow libraries won&amp;#39;t exist in some futures. Since they exist now, I would like to make a complete copy.&lt;/p&gt;\n\n&lt;p&gt;There are torrents and I can download them. It&amp;#39;s about 500 TB total. The first shard I tried to DL was an 11 TB repo. At 1 MB/s (fastest internet available to me in my area), that&amp;#39;s ~140 days. This should have been obvious upfront, but bandwidth hasn&amp;#39;t been a practical limitation for anything I&amp;#39;ve wanted to do since the 90s.&lt;/p&gt;\n\n&lt;p&gt;So I thought I had a hardware problem (how to store 500 TB in my house) and I do, but I kindof know how to solve that. What I actually have is a bandwidth problem. Where can I go to download a 11 TB file? And then do it 50 more times to get all of libgen/annas?&lt;/p&gt;\n\n&lt;p&gt;I think the real pirates are probably still mailing drives around. Obviously that&amp;#39;s not ideal for anyone.&lt;/p&gt;\n\n&lt;p&gt;Do datahoarders all work at tech cos and universities with infinite bandwidth?&lt;/p&gt;\n\n&lt;p&gt;Is there a site that I can pay money to and they will mail me a set of drives with my torrents on them (seems crazy?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16hct31", "is_robot_indexable": true, "report_reasons": null, "author": "Meeple-Mayor", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16hct31/solving_the_bandwidth_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hct31/solving_the_bandwidth_problem/", "subreddit_subscribers": 702084, "created_utc": 1694577773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I currently use an old reliable tower PC (circa 2013) to rip copies of all my blue rays and other disk media to my server. However I would like to downsize to something smaller and more modern. Do any mini pc exist where I could install my full sized internal optical blue ray drive (firmware is rolled back to allow for ripping so I want to keep this drive). Smallest I could find would be like an optiplex.\n\n Or I also wondered if an adapter cable would be able to seamlessly power the drive externally. Then I could just get a basic cheap mini pc. \n\nWhen I researched the external options I saw lots of issues with the sata to usb cables. Also I wasn\u2019t sure if there would be data bottle necks converting to usb as it ripped.", "author_fullname": "t2_5v3a6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mini PC with optical disk support recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hbech", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694573666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently use an old reliable tower PC (circa 2013) to rip copies of all my blue rays and other disk media to my server. However I would like to downsize to something smaller and more modern. Do any mini pc exist where I could install my full sized internal optical blue ray drive (firmware is rolled back to allow for ripping so I want to keep this drive). Smallest I could find would be like an optiplex.&lt;/p&gt;\n\n&lt;p&gt;Or I also wondered if an adapter cable would be able to seamlessly power the drive externally. Then I could just get a basic cheap mini pc. &lt;/p&gt;\n\n&lt;p&gt;When I researched the external options I saw lots of issues with the sata to usb cables. Also I wasn\u2019t sure if there would be data bottle necks converting to usb as it ripped.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16hbech", "is_robot_indexable": true, "report_reasons": null, "author": "cncjames21", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16hbech/mini_pc_with_optical_disk_support_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hbech/mini_pc_with_optical_disk_support_recommendations/", "subreddit_subscribers": 702084, "created_utc": 1694573666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm currently using Komga to manage my comics, but many duplicates need to be handled manually. For example, if a series is collected into a trade, I want to delete the single issues in favor of the trade.  \n\n\nI want to find something similar to the YAC Library interface that can more easily read metadata in the files and allow the option to have them appear in columns.   \n\n\nI tried **Calibre** but, it's pretty set on their file structure.  \n**YAC Library** isn't quite mapping the XML and I can't sort any of the columns.  \n**Komga** is fine for serving issues but there isn't a directory view.  \n\n\nI was able to do this in **ComicRack** but I'm on OSX now and ComicRack isn't getting any updates.   \nDoes anyone have any suggestions?", "author_fullname": "t2_9fjqb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comic (CBZ) Manager as a Directory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hb6rh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694573066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently using Komga to manage my comics, but many duplicates need to be handled manually. For example, if a series is collected into a trade, I want to delete the single issues in favor of the trade.  &lt;/p&gt;\n\n&lt;p&gt;I want to find something similar to the YAC Library interface that can more easily read metadata in the files and allow the option to have them appear in columns.   &lt;/p&gt;\n\n&lt;p&gt;I tried &lt;strong&gt;Calibre&lt;/strong&gt; but, it&amp;#39;s pretty set on their file structure.&lt;br/&gt;\n&lt;strong&gt;YAC Library&lt;/strong&gt; isn&amp;#39;t quite mapping the XML and I can&amp;#39;t sort any of the columns.&lt;br/&gt;\n&lt;strong&gt;Komga&lt;/strong&gt; is fine for serving issues but there isn&amp;#39;t a directory view.  &lt;/p&gt;\n\n&lt;p&gt;I was able to do this in &lt;strong&gt;ComicRack&lt;/strong&gt; but I&amp;#39;m on OSX now and ComicRack isn&amp;#39;t getting any updates.&lt;br/&gt;\nDoes anyone have any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16hb6rh", "is_robot_indexable": true, "report_reasons": null, "author": "JeddakTarkas", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16hb6rh/comic_cbz_manager_as_a_directory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hb6rh/comic_cbz_manager_as_a_directory/", "subreddit_subscribers": 702084, "created_utc": 1694573066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello hoarders,\n\nI stumbled upon this device:  **Exos E 5U84** with 84x 16TB HDDs (price: $16K). I admit I am a bit confused regarding the way to connect it to a server with a **Supermicro MBD-H12SSL-CT-O** motherboard. [This PDF](https://www.seagate.com/content/dam/seagate/en_gb/content-fragments/products/datasheets/system-rebrand/exos-e-5u84/exos-e-5u84-DS1977-6-2212US-en_GB.pdf) says \" Three universal \u00d74 12 Gb/s mini-SAS connectors (SFF-8644) per I/O module \", which, to me, as someone not versed in this kind of connectivity, doesn't tell much. Right now, I am using an  **LSI SAS 9300-16I** card with SFF-8643 SATA cables.  \nMy Google-fu led me to [this card](https://www.dolphinics.com/products/PXH832.html), but I couldn't find it for sale anywhere.\n\nIf someone could point me to documentation about how to connect that storage device to the server, or which card(s) are needed, I will greatly appreciate it!  \n\n\nThank you!", "author_fullname": "t2_ljpwp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exos E 5U84 - harwdware connection to Supermicro MBD-H12SSL-CT-O", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h00q9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694545698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello hoarders,&lt;/p&gt;\n\n&lt;p&gt;I stumbled upon this device:  &lt;strong&gt;Exos E 5U84&lt;/strong&gt; with 84x 16TB HDDs (price: $16K). I admit I am a bit confused regarding the way to connect it to a server with a &lt;strong&gt;Supermicro MBD-H12SSL-CT-O&lt;/strong&gt; motherboard. &lt;a href=\"https://www.seagate.com/content/dam/seagate/en_gb/content-fragments/products/datasheets/system-rebrand/exos-e-5u84/exos-e-5u84-DS1977-6-2212US-en_GB.pdf\"&gt;This PDF&lt;/a&gt; says &amp;quot; Three universal \u00d74 12 Gb/s mini-SAS connectors (SFF-8644) per I/O module &amp;quot;, which, to me, as someone not versed in this kind of connectivity, doesn&amp;#39;t tell much. Right now, I am using an  &lt;strong&gt;LSI SAS 9300-16I&lt;/strong&gt; card with SFF-8643 SATA cables.&lt;br/&gt;\nMy Google-fu led me to &lt;a href=\"https://www.dolphinics.com/products/PXH832.html\"&gt;this card&lt;/a&gt;, but I couldn&amp;#39;t find it for sale anywhere.&lt;/p&gt;\n\n&lt;p&gt;If someone could point me to documentation about how to connect that storage device to the server, or which card(s) are needed, I will greatly appreciate it!  &lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16h00q9", "is_robot_indexable": true, "report_reasons": null, "author": "war4peace79", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16h00q9/exos_e_5u84_harwdware_connection_to_supermicro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16h00q9/exos_e_5u84_harwdware_connection_to_supermicro/", "subreddit_subscribers": 702084, "created_utc": 1694545698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone\n\nI'm in the market for a NAS and was thinking about buying the following: \nQNAP TS-873A-8G\n8x20TB HDD \n2x256GB M.2 SSD\n\nThen install TrueNas on the M.2s and create a vDev with raidz2 for the HDDs\n\nDoes this sound like a good idea or is it too convoluted/complicated? \n\nI'll only use it for storage and maybe a backup wireguard container (I have a intel NUC for all the other stuff)", "author_fullname": "t2_zw0tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TrueNas on Qnap, good idea?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gt1tz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694529378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in the market for a NAS and was thinking about buying the following: \nQNAP TS-873A-8G\n8x20TB HDD \n2x256GB M.2 SSD&lt;/p&gt;\n\n&lt;p&gt;Then install TrueNas on the M.2s and create a vDev with raidz2 for the HDDs&lt;/p&gt;\n\n&lt;p&gt;Does this sound like a good idea or is it too convoluted/complicated? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll only use it for storage and maybe a backup wireguard container (I have a intel NUC for all the other stuff)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16gt1tz", "is_robot_indexable": true, "report_reasons": null, "author": "human437", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16gt1tz/truenas_on_qnap_good_idea/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16gt1tz/truenas_on_qnap_good_idea/", "subreddit_subscribers": 702084, "created_utc": 1694529378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I want to build a private cloud using Owncloud and a couple of large disks in RAID 1.\n\nI've been looking for options to connect the disks to the Rpi, but I'm not sure what is best.\n\nI plan on using SSD drives. Should I look for a SATA hat for the raspberry or a usb hard drive hub is just okay? Something like this [https://www.amazon.es/Sabrent-EC-HD2B-externos-Pulgadas-Clonaci%C3%B3n/dp/B0759567JT/ref=asc\\_df\\_B0759567JT/?tag=&amp;linkCode=df0&amp;hvadid=420332592147&amp;hvpos=&amp;hvnetw=g&amp;hvrand=4017170202359592970&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1005455&amp;hvtargid=pla-564037935583&amp;ref=&amp;adgrpid=98816270089&amp;th=1](https://www.amazon.es/Sabrent-EC-HD2B-externos-Pulgadas-Clonaci%C3%B3n/dp/B0759567JT/ref=asc_df_B0759567JT/?tag=&amp;linkCode=df0&amp;hvadid=420332592147&amp;hvpos=&amp;hvnetw=g&amp;hvrand=4017170202359592970&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1005455&amp;hvtargid=pla-564037935583&amp;ref=&amp;adgrpid=98816270089&amp;th=1)\n\n&amp;#x200B;\n\nI don't plan on doing large transfers. Any advice would be appreciated.\n\nThanks in advance!", "author_fullname": "t2_jfuwnamng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best option for connecting two disks in RAID 1 to a Raspberry pi?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16goahh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694516453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I want to build a private cloud using Owncloud and a couple of large disks in RAID 1.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking for options to connect the disks to the Rpi, but I&amp;#39;m not sure what is best.&lt;/p&gt;\n\n&lt;p&gt;I plan on using SSD drives. Should I look for a SATA hat for the raspberry or a usb hard drive hub is just okay? Something like this &lt;a href=\"https://www.amazon.es/Sabrent-EC-HD2B-externos-Pulgadas-Clonaci%C3%B3n/dp/B0759567JT/ref=asc_df_B0759567JT/?tag=&amp;amp;linkCode=df0&amp;amp;hvadid=420332592147&amp;amp;hvpos=&amp;amp;hvnetw=g&amp;amp;hvrand=4017170202359592970&amp;amp;hvpone=&amp;amp;hvptwo=&amp;amp;hvqmt=&amp;amp;hvdev=c&amp;amp;hvdvcmdl=&amp;amp;hvlocint=&amp;amp;hvlocphy=1005455&amp;amp;hvtargid=pla-564037935583&amp;amp;ref=&amp;amp;adgrpid=98816270089&amp;amp;th=1\"&gt;https://www.amazon.es/Sabrent-EC-HD2B-externos-Pulgadas-Clonaci%C3%B3n/dp/B0759567JT/ref=asc_df_B0759567JT/?tag=&amp;amp;linkCode=df0&amp;amp;hvadid=420332592147&amp;amp;hvpos=&amp;amp;hvnetw=g&amp;amp;hvrand=4017170202359592970&amp;amp;hvpone=&amp;amp;hvptwo=&amp;amp;hvqmt=&amp;amp;hvdev=c&amp;amp;hvdvcmdl=&amp;amp;hvlocint=&amp;amp;hvlocphy=1005455&amp;amp;hvtargid=pla-564037935583&amp;amp;ref=&amp;amp;adgrpid=98816270089&amp;amp;th=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t plan on doing large transfers. Any advice would be appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16goahh", "is_robot_indexable": true, "report_reasons": null, "author": "cheesusma", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16goahh/best_option_for_connecting_two_disks_in_raid_1_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16goahh/best_option_for_connecting_two_disks_in_raid_1_to/", "subreddit_subscribers": 702084, "created_utc": 1694516453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I will be leaving the place that granted me access to perkopolis, and I would like to extract all the discount codes before I leave.\n\nI tried HTTracks and WebCopy, but when I open the website and click on a link, I get an error message that JavaScript isn't enabled (even though it is). I tried FF, Chrome and IE with the same result. \n\nIt's behind a login wall.", "author_fullname": "t2_4yvs14lj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I backup all discount codes from Perkopolis?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hf640", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694585458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I will be leaving the place that granted me access to perkopolis, and I would like to extract all the discount codes before I leave.&lt;/p&gt;\n\n&lt;p&gt;I tried HTTracks and WebCopy, but when I open the website and click on a link, I get an error message that JavaScript isn&amp;#39;t enabled (even though it is). I tried FF, Chrome and IE with the same result. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s behind a login wall.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16hf640", "is_robot_indexable": true, "report_reasons": null, "author": "foreverpasta", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16hf640/how_do_i_backup_all_discount_codes_from_perkopolis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hf640/how_do_i_backup_all_discount_codes_from_perkopolis/", "subreddit_subscribers": 702084, "created_utc": 1694585458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello. I've been trying to copy some folders for a while with the objective of maintaining their metadata (I'm interested in maintaining the original creation date of the folders and their files. I don't know if there is any other metadata apart from that).\n\n&amp;#x200B;\n\nI first tried using the \"robocopy\" command, but I couldn't get it to work. And now I'm about to try \"FastCopy\". The problem is that I don't know this app and I'm worried that when the copy is finished, it will keep the original dates, but change or make other things worse without me noticing.\n\n&amp;#x200B;\n\nCould using this application cause me any problems? These are folders with very precious files for me and I am not interested in making the copy quickly, but in doing it well.\n\nIs there any application or tool that you think is more appropriate for the job that you can recommend?", "author_fullname": "t2_e7hilpzk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can FastCopy alter other aspects of my files without me knowing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hdu79", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694581011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I&amp;#39;ve been trying to copy some folders for a while with the objective of maintaining their metadata (I&amp;#39;m interested in maintaining the original creation date of the folders and their files. I don&amp;#39;t know if there is any other metadata apart from that).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I first tried using the &amp;quot;robocopy&amp;quot; command, but I couldn&amp;#39;t get it to work. And now I&amp;#39;m about to try &amp;quot;FastCopy&amp;quot;. The problem is that I don&amp;#39;t know this app and I&amp;#39;m worried that when the copy is finished, it will keep the original dates, but change or make other things worse without me noticing.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Could using this application cause me any problems? These are folders with very precious files for me and I am not interested in making the copy quickly, but in doing it well.&lt;/p&gt;\n\n&lt;p&gt;Is there any application or tool that you think is more appropriate for the job that you can recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16hdu79", "is_robot_indexable": true, "report_reasons": null, "author": "Juan-Cruz-Mz", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16hdu79/can_fastcopy_alter_other_aspects_of_my_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16hdu79/can_fastcopy_alter_other_aspects_of_my_files/", "subreddit_subscribers": 702084, "created_utc": 1694581011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey All,\n\nSo I'm making some changes on how I backup data and wanted to see what other people suggest and also like to know other poeples setups, rather than spending hours testing and looking into things as someone already may know or be running the perfect solution that fits my usecase!, or it'll give me ideas.  \n\nI currently have a very old synology with 2TB of important \"backed up\" data in raid 5, we are talking like 10 years old, so knowing this i want to have sort my backups in the following way\n\nLaptop - (2tb of data) -&gt; synology -&gt; B2\n\nThan if/when synology dies it'll be Laptop -&gt; B2.\n\n&amp;#x200B;\n\nI'm looking for the following features\n\nAES 256 encryption min (btw not via Veracrypt)\n\ndedupe or small updates to files in destination possible (ie not re-upload 1TB when one file changes)\n\nApp can run on windows to run backups (to both b2 in future and synology now)\n\nBackups app can run on synology NAS (or i can just use \"cloud sync\" to b2 as long as encrypted) also note i have ds414 so not option to run docker :(\n\na windows/linux app (or can run in a small VM but would prefer native app)\n\nAndriod client a plus but not essential (for photos)\n\n&amp;#x200B;\n\nI currently use hyperbackup -&gt; B2. but that is a legacy setup.\n\nI did look at backblaze pc backup but cost is higher than my bucket, so i wanna be as cheap as possible and just keep my bucket.\n\nI am a retired System Administrator, so it can be feature rich and a bit more complex, but i do want easy, i have a life now and don't want to spend a few hours on a weekend diagnosing in a commandline why something broke after a update or some rubbish.\n\nI liked all the features of nextcloud, but requires a VM and id like something simpler first. \n\nAnyway thanks for reading :).", "author_fullname": "t2_bfe4n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Re-configure backup solution (Laptop, NAS, B2)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h9x24", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694569552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All,&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m making some changes on how I backup data and wanted to see what other people suggest and also like to know other poeples setups, rather than spending hours testing and looking into things as someone already may know or be running the perfect solution that fits my usecase!, or it&amp;#39;ll give me ideas.  &lt;/p&gt;\n\n&lt;p&gt;I currently have a very old synology with 2TB of important &amp;quot;backed up&amp;quot; data in raid 5, we are talking like 10 years old, so knowing this i want to have sort my backups in the following way&lt;/p&gt;\n\n&lt;p&gt;Laptop - (2tb of data) -&amp;gt; synology -&amp;gt; B2&lt;/p&gt;\n\n&lt;p&gt;Than if/when synology dies it&amp;#39;ll be Laptop -&amp;gt; B2.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for the following features&lt;/p&gt;\n\n&lt;p&gt;AES 256 encryption min (btw not via Veracrypt)&lt;/p&gt;\n\n&lt;p&gt;dedupe or small updates to files in destination possible (ie not re-upload 1TB when one file changes)&lt;/p&gt;\n\n&lt;p&gt;App can run on windows to run backups (to both b2 in future and synology now)&lt;/p&gt;\n\n&lt;p&gt;Backups app can run on synology NAS (or i can just use &amp;quot;cloud sync&amp;quot; to b2 as long as encrypted) also note i have ds414 so not option to run docker :(&lt;/p&gt;\n\n&lt;p&gt;a windows/linux app (or can run in a small VM but would prefer native app)&lt;/p&gt;\n\n&lt;p&gt;Andriod client a plus but not essential (for photos)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I currently use hyperbackup -&amp;gt; B2. but that is a legacy setup.&lt;/p&gt;\n\n&lt;p&gt;I did look at backblaze pc backup but cost is higher than my bucket, so i wanna be as cheap as possible and just keep my bucket.&lt;/p&gt;\n\n&lt;p&gt;I am a retired System Administrator, so it can be feature rich and a bit more complex, but i do want easy, i have a life now and don&amp;#39;t want to spend a few hours on a weekend diagnosing in a commandline why something broke after a update or some rubbish.&lt;/p&gt;\n\n&lt;p&gt;I liked all the features of nextcloud, but requires a VM and id like something simpler first. &lt;/p&gt;\n\n&lt;p&gt;Anyway thanks for reading :).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16h9x24", "is_robot_indexable": true, "report_reasons": null, "author": "psyberwolf1100", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16h9x24/reconfigure_backup_solution_laptop_nas_b2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16h9x24/reconfigure_backup_solution_laptop_nas_b2/", "subreddit_subscribers": 702084, "created_utc": 1694569552.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}