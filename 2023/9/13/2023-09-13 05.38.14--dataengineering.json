{"kind": "Listing", "data": {"after": "t3_16gs63r", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(Disclosure: founder of GlareDB)\n\nHi everyone,\n\nWe've recently released GlareDB 0.5.0, and our biggest feature for this release is Hybrid Execution.\n\nFirst, what is GlareDB? GlareDB is SQL database that can read data from a variety of sources, including Postgres, Snowflake, S3, and more. Our goal is enabling running analytics across data sources without having to move data around.\n\nAnd with Hybrid Execute, we're taking that a step further. Hybrid Execution lets you connect to a GlareDB Cloud deployment from the GlareDB CLI or Python library, which  allows queries to use the combined resources of both the local and remote machines. GlareDB splits up the query during planning, and executes parts of the query locally or remotely depending on the data being referenced.\n\nThis also enables being able to join local data (parquet, csv, and json files) onto tables that exist in your cloud deployment. For example, if we have a `user_metrics` table in our cloud deployment, and a `company_users.csv` file that's just sitting on our laptop, we're able to write a single query that joins data from both:\n\n    SELECT\n      m.user_id,\n      max(m.output_rows),\n      avg(m.output_rows)::int\n    FROM\n      user_metrics m\n    INNER JOIN './company_users.csv' u on m.user_id = u.id\n    GROUP BY m.user_id\n    LIMIT 5;\n\nWe don't have to manually upload csv files, we just write a single sql query and glaredb takes care of the rest. This also works for dataframes when using our Python library.\n\nWe can go even crazier. Since GlareDB has integrations for connecting to databases like Postgres, Snowflake, and more, we're able to join local data onto remote data sources all in a single query. Here's what that could look like in Python:\n\n    import glaredb\n    import pandas as pd\n    \n    con = glaredb.connect(\"glaredb://&lt;user&gt;:&lt;pass&gt;@glaredb-better.remote.glaredb.com:6443/dogfood\")\n    \n    users = pd.DataFrame({\"email\": [\"sean@glaredb.com\"]})\n    \n    con.sql(\"\"\"\n    select count(*) as query_count,\n           max(e.elapsed_compute_ns) as max_elapsed\n      from snowflake_segment.glaredb_prod.execution_metric e\n      inner join pg_prod.public.users u on e.user_id = u.id\n      inner join users u2 on u.email = u2.email\n      where e.timestamp::timestamp &gt; now() - interval '3 day'\n    \"\"\").show()\n\nAnd as before, we're not having to do anything special with the `users` dataframe, we just reference it in the query, and glaredb will work its magic.\n\nIf you want to learn more about Hybrid Execution, check out our blog post: [https://glaredb.com/blog/hybrid-execution](https://glaredb.com/blog/hybrid-execution)\n\nAnd take a peek at our open source repo: [https://github.com/GlareDB/glaredb](https://github.com/GlareDB/glaredb)\n\nLet us know what you think!", "author_fullname": "t2_butu3hfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hybrid Execution in GlareDB: Scale your workflow with GlareDB Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gyw84", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694543082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Disclosure: founder of GlareDB)&lt;/p&gt;\n\n&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve recently released GlareDB 0.5.0, and our biggest feature for this release is Hybrid Execution.&lt;/p&gt;\n\n&lt;p&gt;First, what is GlareDB? GlareDB is SQL database that can read data from a variety of sources, including Postgres, Snowflake, S3, and more. Our goal is enabling running analytics across data sources without having to move data around.&lt;/p&gt;\n\n&lt;p&gt;And with Hybrid Execute, we&amp;#39;re taking that a step further. Hybrid Execution lets you connect to a GlareDB Cloud deployment from the GlareDB CLI or Python library, which  allows queries to use the combined resources of both the local and remote machines. GlareDB splits up the query during planning, and executes parts of the query locally or remotely depending on the data being referenced.&lt;/p&gt;\n\n&lt;p&gt;This also enables being able to join local data (parquet, csv, and json files) onto tables that exist in your cloud deployment. For example, if we have a &lt;code&gt;user_metrics&lt;/code&gt; table in our cloud deployment, and a &lt;code&gt;company_users.csv&lt;/code&gt; file that&amp;#39;s just sitting on our laptop, we&amp;#39;re able to write a single query that joins data from both:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT\n  m.user_id,\n  max(m.output_rows),\n  avg(m.output_rows)::int\nFROM\n  user_metrics m\nINNER JOIN &amp;#39;./company_users.csv&amp;#39; u on m.user_id = u.id\nGROUP BY m.user_id\nLIMIT 5;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;We don&amp;#39;t have to manually upload csv files, we just write a single sql query and glaredb takes care of the rest. This also works for dataframes when using our Python library.&lt;/p&gt;\n\n&lt;p&gt;We can go even crazier. Since GlareDB has integrations for connecting to databases like Postgres, Snowflake, and more, we&amp;#39;re able to join local data onto remote data sources all in a single query. Here&amp;#39;s what that could look like in Python:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import glaredb\nimport pandas as pd\n\ncon = glaredb.connect(&amp;quot;glaredb://&amp;lt;user&amp;gt;:&amp;lt;pass&amp;gt;@glaredb-better.remote.glaredb.com:6443/dogfood&amp;quot;)\n\nusers = pd.DataFrame({&amp;quot;email&amp;quot;: [&amp;quot;sean@glaredb.com&amp;quot;]})\n\ncon.sql(&amp;quot;&amp;quot;&amp;quot;\nselect count(*) as query_count,\n       max(e.elapsed_compute_ns) as max_elapsed\n  from snowflake_segment.glaredb_prod.execution_metric e\n  inner join pg_prod.public.users u on e.user_id = u.id\n  inner join users u2 on u.email = u2.email\n  where e.timestamp::timestamp &amp;gt; now() - interval &amp;#39;3 day&amp;#39;\n&amp;quot;&amp;quot;&amp;quot;).show()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And as before, we&amp;#39;re not having to do anything special with the &lt;code&gt;users&lt;/code&gt; dataframe, we just reference it in the query, and glaredb will work its magic.&lt;/p&gt;\n\n&lt;p&gt;If you want to learn more about Hybrid Execution, check out our blog post: &lt;a href=\"https://glaredb.com/blog/hybrid-execution\"&gt;https://glaredb.com/blog/hybrid-execution&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And take a peek at our open source repo: &lt;a href=\"https://github.com/GlareDB/glaredb\"&gt;https://github.com/GlareDB/glaredb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Let us know what you think!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?auto=webp&amp;s=4dee1b5daaf4f28142bb37367338cbcc49861006", "width": 3840, "height": 2160}, "resolutions": [{"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c9eed218c2708d33a7c12e9cf1aa2afdcdc3bedf", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=37ee0ccd27b516133613a5739ef600c91d4cb166", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a83a204550161c8771f17321a21101814cc3ba86", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=469a3f369526e393f5425a0a928ee3eb6384e46e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b13e482322f01561ac1ef9212d52947d466d6b5a", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fccb73db62b1310d319ec542101a7e956b593ea6", "width": 1080, "height": 607}], "variants": {}, "id": "fGYMbTG5G_tyhn5Hv-oYbSHPqwimRoEYC-UzkmsKqYM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16gyw84", "is_robot_indexable": true, "report_reasons": null, "author": "sean-glaredb", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gyw84/hybrid_execution_in_glaredb_scale_your_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gyw84/hybrid_execution_in_glaredb_scale_your_workflow/", "subreddit_subscribers": 128170, "created_utc": 1694543082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've been a DE for around 14 months now. I've learnt a lot and done some really cool projects. The main thing I've gotten here has been experience and mentoring getting to grips with working in cloud platforms. I've been promoted in the last year, done well etc. Though I'm currently the only engineer for the older systems.\n\nThing is I currently work for a huge multinational company. I just got an offer from a smaller company (still not tiny, but they've basically exploded in size over 5 years) who want to improve their data warehousing, automation etc and transition to being properly \"data driven\". I have no idea how i got it over 2 other candidates who likely had more experience than me. But ill be the first and for some while, only engineer. There wasn't even a real technical interview because they have nobody who could actually conduct one. I'm coming in to a fresh MS sql server and a lot of excel processes, and a team of one IT person and one BI analyst. The longer term plan is that they want to move to Azure and get some advanced analytics off the ground, but they have realistic expectations of where they are and just how far away that is.\n\nThey're also offering me a pretty massive increase over my current salary. Obviously I want to take it. I have lots of ideas, being able to do everything right myself from the start and not dealing with bad legacy systems is appealing. Though part of me is wary. I'll have no back up, nobody to ask for help if things go wrong. I'm technically a senior where I am now due to an early promotion, I run workshops for the non DE guys and have done some good work but given how fresh I am this feels like a massive step up, or taking two steps at once.\n\nWould you guys take something like that on when you're still relatively early career? It feels like a long term project that I'm committed to, and it means I'm not gonna be touching databricks or ADF for a while. Its gonna be all sql server and airflow/dagster at first.", "author_fullname": "t2_dojxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big company to solo engineer at a small one", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gscf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694527659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been a DE for around 14 months now. I&amp;#39;ve learnt a lot and done some really cool projects. The main thing I&amp;#39;ve gotten here has been experience and mentoring getting to grips with working in cloud platforms. I&amp;#39;ve been promoted in the last year, done well etc. Though I&amp;#39;m currently the only engineer for the older systems.&lt;/p&gt;\n\n&lt;p&gt;Thing is I currently work for a huge multinational company. I just got an offer from a smaller company (still not tiny, but they&amp;#39;ve basically exploded in size over 5 years) who want to improve their data warehousing, automation etc and transition to being properly &amp;quot;data driven&amp;quot;. I have no idea how i got it over 2 other candidates who likely had more experience than me. But ill be the first and for some while, only engineer. There wasn&amp;#39;t even a real technical interview because they have nobody who could actually conduct one. I&amp;#39;m coming in to a fresh MS sql server and a lot of excel processes, and a team of one IT person and one BI analyst. The longer term plan is that they want to move to Azure and get some advanced analytics off the ground, but they have realistic expectations of where they are and just how far away that is.&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;re also offering me a pretty massive increase over my current salary. Obviously I want to take it. I have lots of ideas, being able to do everything right myself from the start and not dealing with bad legacy systems is appealing. Though part of me is wary. I&amp;#39;ll have no back up, nobody to ask for help if things go wrong. I&amp;#39;m technically a senior where I am now due to an early promotion, I run workshops for the non DE guys and have done some good work but given how fresh I am this feels like a massive step up, or taking two steps at once.&lt;/p&gt;\n\n&lt;p&gt;Would you guys take something like that on when you&amp;#39;re still relatively early career? It feels like a long term project that I&amp;#39;m committed to, and it means I&amp;#39;m not gonna be touching databricks or ADF for a while. Its gonna be all sql server and airflow/dagster at first.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16gscf7", "is_robot_indexable": true, "report_reasons": null, "author": "Gartlas", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gscf7/big_company_to_solo_engineer_at_a_small_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gscf7/big_company_to_solo_engineer_at_a_small_one/", "subreddit_subscribers": 128170, "created_utc": 1694527659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you had to start over, what would be your plan to go from zero to hero in 6 months", "author_fullname": "t2_etp40tkx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you had to start over..", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gxz8v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694540935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you had to start over, what would be your plan to go from zero to hero in 6 months&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16gxz8v", "is_robot_indexable": true, "report_reasons": null, "author": "Physical_Flatworm689", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gxz8v/if_you_had_to_start_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gxz8v/if_you_had_to_start_over/", "subreddit_subscribers": 128170, "created_utc": 1694540935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jboiz9k4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Convert batch data processing to streaming in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16gk9ir", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OZ1ATulM8CMeH9mrvydMV8GgmAiYuffrKZ_pJzhlefg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694502107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/1ebj5f1pwrnb1.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?format=png8&amp;s=009087f64c6e8278489d4016970627dab34cc6a9", "width": 1138, "height": 640}, "resolutions": [{"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=6b17b6b05312f06f967f8bb74aa7ea48aad120f1", "width": 108, "height": 60}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=742d9f1c7e91734a74e7cecc3553b3c17102d01a", "width": 216, "height": 121}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=cf86d1e6caedc279c795e9084821e46989ec4680", "width": 320, "height": 179}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=91d2818e420846b0a17e789716a7fd96b38450cb", "width": 640, "height": 359}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=ec6e071c0ad995d29c79c6c5b50739b85f2ff978", "width": 960, "height": 539}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=f31634a9bd0b139db661d264eff0033cbdd97167", "width": 1080, "height": 607}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?s=fb09fc990e8f6a11c1e8bb15d2ec42d985df4cd0", "width": 1138, "height": 640}, "resolutions": [{"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=108&amp;crop=smart&amp;s=36edc80a8f8aebdc6a6a0f4dfa68be16ba080c94", "width": 108, "height": 60}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=216&amp;crop=smart&amp;s=667644ea22c684b45813927bc7c004d847e5c770", "width": 216, "height": 121}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=320&amp;crop=smart&amp;s=3aa4609acf46577a4647433fc221a881acea2a00", "width": 320, "height": 179}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=640&amp;crop=smart&amp;s=e4b25ff39dcf6abf9c49942eb5dde7209b262955", "width": 640, "height": 359}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=960&amp;crop=smart&amp;s=3a877ca83080b93e447091e79b9b2b419f7fff1b", "width": 960, "height": 539}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=1080&amp;crop=smart&amp;s=82d7173187add59594099a2a604303efa4082f6a", "width": 1080, "height": 607}]}, "mp4": {"source": {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?format=mp4&amp;s=2dcd7d6d746250f3ac2d05a3dbdb46922d9b7ca8", "width": 1138, "height": 640}, "resolutions": [{"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=108&amp;format=mp4&amp;s=3b1cd65317afbd2be3393e4ebb25c2e0e308b361", "width": 108, "height": 60}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=216&amp;format=mp4&amp;s=7e5fda99d014b0e001cc24fb1e5ca63ff0747de8", "width": 216, "height": 121}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=320&amp;format=mp4&amp;s=ceed663a07d9208d7761e54c310c58b851d7f7f6", "width": 320, "height": 179}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=640&amp;format=mp4&amp;s=d688c0f0f2b3d4ecdb06400db6eba1056c1c34e6", "width": 640, "height": 359}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=960&amp;format=mp4&amp;s=e8e4bf9aa50813f797b0de966e92968e6e15b219", "width": 960, "height": 539}, {"url": "https://preview.redd.it/1ebj5f1pwrnb1.gif?width=1080&amp;format=mp4&amp;s=bc8f359f11196763300eeeceffd9be55a7ea1289", "width": 1080, "height": 607}]}}, "id": "OgZ0qQVuUodkflbnqQYt7GKzZSOWGfzw1F3gjq2yXgE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16gk9ir", "is_robot_indexable": true, "report_reasons": null, "author": "bumurzokov", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gk9ir/convert_batch_data_processing_to_streaming_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/1ebj5f1pwrnb1.gif", "subreddit_subscribers": 128170, "created_utc": 1694502107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is anyone else having this issue?\n\n\n\n\nI've been in a data engineering for 5 years and I'm looking to move into devops or a devops-focused data engineering role in the future.  I've been employed at a pretty good and relatively stable tech company for a few years, and I have been on the job market since midway through 2022 applying for jobs.\n\n\n\n\n\n\nAlthough I came close to getting some job offers when I started applying in 2022, the job market quickly became much worse and I didn't get offers.  Since then, I've applied to jobs whenever something interesting appeared.\n\n\n\n\n\nNowadays, whenever I've made it further into a company's interview process, I would discover that the company frequently has layoffs or does PIPs.  Unfortunately, I could never continue interviewing with those companies even if I liked the role, the tech stack, and the increased salary since I do not want to risk unemployment for a long period of time.\n\n\n\n\nIs anyone else facing the same issue in their job search?  Although I enjoy my job now, I want career progression, a new tech stack, and a high total compensation but I can't risk being unemployed for a long period of time.  I wasn't the best interviewer when it comes to Leetcode, so it is harder for me to take those risks in this economy.", "author_fullname": "t2_auf0obxj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want career progression, but I don't want to leave my stable job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16goqdu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694517830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is anyone else having this issue?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been in a data engineering for 5 years and I&amp;#39;m looking to move into devops or a devops-focused data engineering role in the future.  I&amp;#39;ve been employed at a pretty good and relatively stable tech company for a few years, and I have been on the job market since midway through 2022 applying for jobs.&lt;/p&gt;\n\n&lt;p&gt;Although I came close to getting some job offers when I started applying in 2022, the job market quickly became much worse and I didn&amp;#39;t get offers.  Since then, I&amp;#39;ve applied to jobs whenever something interesting appeared.&lt;/p&gt;\n\n&lt;p&gt;Nowadays, whenever I&amp;#39;ve made it further into a company&amp;#39;s interview process, I would discover that the company frequently has layoffs or does PIPs.  Unfortunately, I could never continue interviewing with those companies even if I liked the role, the tech stack, and the increased salary since I do not want to risk unemployment for a long period of time.&lt;/p&gt;\n\n&lt;p&gt;Is anyone else facing the same issue in their job search?  Although I enjoy my job now, I want career progression, a new tech stack, and a high total compensation but I can&amp;#39;t risk being unemployed for a long period of time.  I wasn&amp;#39;t the best interviewer when it comes to Leetcode, so it is harder for me to take those risks in this economy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16goqdu", "is_robot_indexable": true, "report_reasons": null, "author": "level_126_programmer", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16goqdu/i_want_career_progression_but_i_dont_want_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16goqdu/i_want_career_progression_but_i_dont_want_to/", "subreddit_subscribers": 128170, "created_utc": 1694517830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I guess I never fully understood the love for being a contractor versus fulltime when it comes to data engineering careers. I, like many of you, are getting hit with a lot of LinkedIn recruiters right now and some of these roles they're trying to fill are \"long term contract\". I guess I see contract work as great when you want something that might pay more but is probably shorter term so you can move onto the next job and get a variety of experiences over the long term. I have a family I support so I've always prioritized fulltime roles so that I don't end up stranded at the end of a contract that may/may not get renewed. A recruiter reached out to me recently with a really great paying \"long term contract\" role but since it is contract I'm very hesitant to seriously consider it. For those of you who prefer contract roles, why exactly?", "author_fullname": "t2_556jqozb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ok, who here actually prefers working in a contract position versus being fulltime?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h0kpv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694546958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I guess I never fully understood the love for being a contractor versus fulltime when it comes to data engineering careers. I, like many of you, are getting hit with a lot of LinkedIn recruiters right now and some of these roles they&amp;#39;re trying to fill are &amp;quot;long term contract&amp;quot;. I guess I see contract work as great when you want something that might pay more but is probably shorter term so you can move onto the next job and get a variety of experiences over the long term. I have a family I support so I&amp;#39;ve always prioritized fulltime roles so that I don&amp;#39;t end up stranded at the end of a contract that may/may not get renewed. A recruiter reached out to me recently with a really great paying &amp;quot;long term contract&amp;quot; role but since it is contract I&amp;#39;m very hesitant to seriously consider it. For those of you who prefer contract roles, why exactly?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16h0kpv", "is_robot_indexable": true, "report_reasons": null, "author": "MasterKluch", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16h0kpv/ok_who_here_actually_prefers_working_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16h0kpv/ok_who_here_actually_prefers_working_in_a/", "subreddit_subscribers": 128170, "created_utc": 1694546958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I used to work with BigQuery as my org's data warehouse solution and I miss it...\n\nBelow are some of my qualms with Redshift:\n\n* It isnt magically scaleable like BigQuery\n* Doesn't have sharding\n* Doesn't have DB replication\n* Cannot query data catalogs in glue if with IAM authentication (even with the expensive nodes + extremely poor documentation around this)\n* Cannot run cross-DB queries on external schemas (extremely poor documentation around this) and to get around it you need to make an external schema in every DB if you want the functionality\n* Pay per node vs data scanned (like in BigQuery, so you are pissing money away during downtime)\n* Spectrum is slower than the resources it is querying from (slower than it would be to just use athena)\n\nAre there any other downsides besides those? Or even better am I missing any plus sides?", "author_fullname": "t2_4ffbvgzq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Does Anybody Make Good Use of Redshift?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gzu8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694545290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to work with BigQuery as my org&amp;#39;s data warehouse solution and I miss it...&lt;/p&gt;\n\n&lt;p&gt;Below are some of my qualms with Redshift:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It isnt magically scaleable like BigQuery&lt;/li&gt;\n&lt;li&gt;Doesn&amp;#39;t have sharding&lt;/li&gt;\n&lt;li&gt;Doesn&amp;#39;t have DB replication&lt;/li&gt;\n&lt;li&gt;Cannot query data catalogs in glue if with IAM authentication (even with the expensive nodes + extremely poor documentation around this)&lt;/li&gt;\n&lt;li&gt;Cannot run cross-DB queries on external schemas (extremely poor documentation around this) and to get around it you need to make an external schema in every DB if you want the functionality&lt;/li&gt;\n&lt;li&gt;Pay per node vs data scanned (like in BigQuery, so you are pissing money away during downtime)&lt;/li&gt;\n&lt;li&gt;Spectrum is slower than the resources it is querying from (slower than it would be to just use athena)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Are there any other downsides besides those? Or even better am I missing any plus sides?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16gzu8p", "is_robot_indexable": true, "report_reasons": null, "author": "ReporterNervous6822", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gzu8p/how_does_anybody_make_good_use_of_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gzu8p/how_does_anybody_make_good_use_of_redshift/", "subreddit_subscribers": 128170, "created_utc": 1694545290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DA with 5+ years experience. Mainly SQL, Tableau, and Python for some data exploration, analysis, regression models, and some web scraping.\n\nI want to break into DE, so I have been doing very basic projects. I feel like I am missing a huge piece of what to do, and what a DE really is. I need some help, please. \n\nSo far I have done three projects that have involved Pandas:\n\n1.) Taken a dataset from an API (one requiring a key, two open source)\n\n2.) Formatting that from JSON into a data frame / cleaned the data up.\n\n3.) Importing it into a SQL Database\n\n4.) Building some visualizations out of it in Tableau and PBI.\n\nI'm a bit lost. Where does the modeling, data scheduling, and all of that come in. I hear things about BigQuery, Azure, Airflow, etc. I can't imagine telling a future employer that this is what I have done, and have them believe I am capable of being a Data Engineer.\n\nWhat would you consider the next step to be?", "author_fullname": "t2_6iptp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel like I am on the edge of doing cool DE things, but I need some help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h0nvc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694568850.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694547160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DA with 5+ years experience. Mainly SQL, Tableau, and Python for some data exploration, analysis, regression models, and some web scraping.&lt;/p&gt;\n\n&lt;p&gt;I want to break into DE, so I have been doing very basic projects. I feel like I am missing a huge piece of what to do, and what a DE really is. I need some help, please. &lt;/p&gt;\n\n&lt;p&gt;So far I have done three projects that have involved Pandas:&lt;/p&gt;\n\n&lt;p&gt;1.) Taken a dataset from an API (one requiring a key, two open source)&lt;/p&gt;\n\n&lt;p&gt;2.) Formatting that from JSON into a data frame / cleaned the data up.&lt;/p&gt;\n\n&lt;p&gt;3.) Importing it into a SQL Database&lt;/p&gt;\n\n&lt;p&gt;4.) Building some visualizations out of it in Tableau and PBI.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a bit lost. Where does the modeling, data scheduling, and all of that come in. I hear things about BigQuery, Azure, Airflow, etc. I can&amp;#39;t imagine telling a future employer that this is what I have done, and have them believe I am capable of being a Data Engineer.&lt;/p&gt;\n\n&lt;p&gt;What would you consider the next step to be?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16h0nvc", "is_robot_indexable": true, "report_reasons": null, "author": "tits_mcgee_92", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16h0nvc/i_feel_like_i_am_on_the_edge_of_doing_cool_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16h0nvc/i_feel_like_i_am_on_the_edge_of_doing_cool_de/", "subreddit_subscribers": 128170, "created_utc": 1694547160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a tool or library that allows you to query an API and get the JSON response into a DB? Issue I have is with nested JSON, where a single response should probably be stored in 2+ tables. ", "author_fullname": "t2_6uawl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any JSON API responses to DB tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16guh1l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694532790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a tool or library that allows you to query an API and get the JSON response into a DB? Issue I have is with nested JSON, where a single response should probably be stored in 2+ tables. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16guh1l", "is_robot_indexable": true, "report_reasons": null, "author": "selleckh", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16guh1l/any_json_api_responses_to_db_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16guh1l/any_json_api_responses_to_db_tools/", "subreddit_subscribers": 128170, "created_utc": 1694532790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know a lot of people have said that DDIA book is the best way to learn system design, but I am personally not a good reader and I\u2019m a visual learner. I finished fundamental of data engineering but honestly have not learned much knowledge from the book lol. What are some resources that will help to learn system design? \n\nAlso when everyone talks about system design, is there any system design specifically for software engineers or data engineers?", "author_fullname": "t2_1xrjwd6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn more about system design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gynnq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694542541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know a lot of people have said that DDIA book is the best way to learn system design, but I am personally not a good reader and I\u2019m a visual learner. I finished fundamental of data engineering but honestly have not learned much knowledge from the book lol. What are some resources that will help to learn system design? &lt;/p&gt;\n\n&lt;p&gt;Also when everyone talks about system design, is there any system design specifically for software engineers or data engineers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16gynnq", "is_robot_indexable": true, "report_reasons": null, "author": "Fasthandman", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gynnq/how_to_learn_more_about_system_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gynnq/how_to_learn_more_about_system_design/", "subreddit_subscribers": 128170, "created_utc": 1694542541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What techniques do you use to create large numbers of simple ETL jobs? For example, we have thousands of tables that we want to copy from point A to B with minimum modifications (adding standardized metadata). Each job is independent so there\u2019s no dependencies to worry about. Previous developers created a job via a GUI for each one which meant months of tedious point and click hell. \n\nHow do you handle bulk job creation and management in the tool of your choice?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL job overload", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h8bi8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694565277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What techniques do you use to create large numbers of simple ETL jobs? For example, we have thousands of tables that we want to copy from point A to B with minimum modifications (adding standardized metadata). Each job is independent so there\u2019s no dependencies to worry about. Previous developers created a job via a GUI for each one which meant months of tedious point and click hell. &lt;/p&gt;\n\n&lt;p&gt;How do you handle bulk job creation and management in the tool of your choice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16h8bi8", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16h8bi8/etl_job_overload/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16h8bi8/etl_job_overload/", "subreddit_subscribers": 128170, "created_utc": 1694565277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI have come across an opportunity that has significant bigger salary but it is not traditional DE job. It\u2019s with a service based org which requires pre-sales work for data team. Be the first point of contact for data related projects and products. \n\nPlease note this is India. \n\nIs a right career move? \nPros: salary and learning. I might learn a lot with a spectrum of technologies. \nCompletely remote. \n\nCons: cannot work deep into integration and delivery. Except compensation, benefits are. Jon existent.  No people attachment. \n\nLooking forward to your questions and opinions.", "author_fullname": "t2_42i9lwic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is pre-sales data engineering good?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gya6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694541665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I have come across an opportunity that has significant bigger salary but it is not traditional DE job. It\u2019s with a service based org which requires pre-sales work for data team. Be the first point of contact for data related projects and products. &lt;/p&gt;\n\n&lt;p&gt;Please note this is India. &lt;/p&gt;\n\n&lt;p&gt;Is a right career move? \nPros: salary and learning. I might learn a lot with a spectrum of technologies. \nCompletely remote. &lt;/p&gt;\n\n&lt;p&gt;Cons: cannot work deep into integration and delivery. Except compensation, benefits are. Jon existent.  No people attachment. &lt;/p&gt;\n\n&lt;p&gt;Looking forward to your questions and opinions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16gya6e", "is_robot_indexable": true, "report_reasons": null, "author": "snapperPanda", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gya6e/is_presales_data_engineering_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gya6e/is_presales_data_engineering_good/", "subreddit_subscribers": 128170, "created_utc": 1694541665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TL;DR: need to ETL from db but primary keys get shuffled around after each migration. Wat do?\n\n\\---\n\nHey folks,\n\nI have a tricky situation and I'm not sure what's the best way to address it.\n\nBasically we have a backend in postgres managed by Django ORM. For some goddamn reason, after each migration, the PKs of (most) records get shuffled around randomly, even if there's no change in data at all.\n\nFor example, if before migration I have this:\n\n|ID (PK)|Name|Surname|\n|:-|:-|:-|\n|1|John|Wayne|\n|234|Julia|Roberts|\n\n&amp;#x200B;\n\nafter migration I can end up with:\n\n|ID (PK)|Name|Surname|\n|:-|:-|:-|\n|234|John|Wayne|\n|890|Julia|Roberts|\n\n&amp;#x200B;\n\nOn top that, for a bunch of tables, natural keys are not 100% reliable due to how they get inserted (it's a human CRUD process).\n\nGiven that I have absolutely zero control on the backend, what strategies would you recommend I apply for E(T)L and data warehousing activities?\n\nThanks in advance for your input!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL from postgres, but Django shuffles Primary Keys after each migration.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gxw34", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694540728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR: need to ETL from db but primary keys get shuffled around after each migration. Wat do?&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I have a tricky situation and I&amp;#39;m not sure what&amp;#39;s the best way to address it.&lt;/p&gt;\n\n&lt;p&gt;Basically we have a backend in postgres managed by Django ORM. For some goddamn reason, after each migration, the PKs of (most) records get shuffled around randomly, even if there&amp;#39;s no change in data at all.&lt;/p&gt;\n\n&lt;p&gt;For example, if before migration I have this:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;ID (PK)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Name&lt;/th&gt;\n&lt;th align=\"left\"&gt;Surname&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;John&lt;/td&gt;\n&lt;td align=\"left\"&gt;Wayne&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;234&lt;/td&gt;\n&lt;td align=\"left\"&gt;Julia&lt;/td&gt;\n&lt;td align=\"left\"&gt;Roberts&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;after migration I can end up with:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;ID (PK)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Name&lt;/th&gt;\n&lt;th align=\"left\"&gt;Surname&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;234&lt;/td&gt;\n&lt;td align=\"left\"&gt;John&lt;/td&gt;\n&lt;td align=\"left\"&gt;Wayne&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;890&lt;/td&gt;\n&lt;td align=\"left\"&gt;Julia&lt;/td&gt;\n&lt;td align=\"left\"&gt;Roberts&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;On top that, for a bunch of tables, natural keys are not 100% reliable due to how they get inserted (it&amp;#39;s a human CRUD process).&lt;/p&gt;\n\n&lt;p&gt;Given that I have absolutely zero control on the backend, what strategies would you recommend I apply for E(T)L and data warehousing activities?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16gxw34", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gxw34/etl_from_postgres_but_django_shuffles_primary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gxw34/etl_from_postgres_but_django_shuffles_primary/", "subreddit_subscribers": 128170, "created_utc": 1694540728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've been working on a simple API for running Python functions in the cloud. In this guide, we use three methods to process the NYC taxi dataset and compare runtimes:  \n\\- locally, 5 hr  \n\\- on a big VM in the cloud, 30 min  \n\\- parallel processing on a big VM in the cloud, 5 min\n\nThis post walks through how you can adapt your Python functions with minimal code changes using Coiled functions [https://medium.com/coiled-hq/parallel-serverless-functions-at-scale-cd6ee4a7def5](https://medium.com/coiled-hq/parallel-serverless-functions-at-scale-cd6ee4a7def5).\n\nIt'd be great to hear your thoughts!\n\nIn the interest of transparency, I work for Coiled, and a colleague of mine wrote this post.", "author_fullname": "t2_w7crvjmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working with many parquet files on S3 in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gzn4d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694544841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve been working on a simple API for running Python functions in the cloud. In this guide, we use three methods to process the NYC taxi dataset and compare runtimes:&lt;br/&gt;\n- locally, 5 hr&lt;br/&gt;\n- on a big VM in the cloud, 30 min&lt;br/&gt;\n- parallel processing on a big VM in the cloud, 5 min&lt;/p&gt;\n\n&lt;p&gt;This post walks through how you can adapt your Python functions with minimal code changes using Coiled functions &lt;a href=\"https://medium.com/coiled-hq/parallel-serverless-functions-at-scale-cd6ee4a7def5\"&gt;https://medium.com/coiled-hq/parallel-serverless-functions-at-scale-cd6ee4a7def5&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;d be great to hear your thoughts!&lt;/p&gt;\n\n&lt;p&gt;In the interest of transparency, I work for Coiled, and a colleague of mine wrote this post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?auto=webp&amp;s=048892709cccbd1b2c68896a31e04218a992e888", "width": 1200, "height": 746}, "resolutions": [{"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=968dca02548dce0e1f7fc3652d5017b006779069", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b72d5e9b0e68c4a6c19a8570d858026c7f6e7470", "width": 216, "height": 134}, {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=544bc6977f20756c3bce657c46e6a8829f59fb20", "width": 320, "height": 198}, {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17000a825a6a4920790368c7472dac300f1727e2", "width": 640, "height": 397}, {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b319f4edf6d70992e730d4fad3b19416f2db26fd", "width": 960, "height": 596}, {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=05791914c7082496c2c4442f73acf0e1643154d1", "width": 1080, "height": 671}], "variants": {}, "id": "A5iyBO5ZP8sgdDc1RsvBp2CEzZYJPo5gZlneKlSl-6Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16gzn4d", "is_robot_indexable": true, "report_reasons": null, "author": "dask-jeeves", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gzn4d/working_with_many_parquet_files_on_s3_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gzn4d/working_with_many_parquet_files_on_s3_in_python/", "subreddit_subscribers": 128170, "created_utc": 1694544841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa3mbz4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "drowning in monthly active row fees", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16gtwp7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ywjkpICKIVt7tqIGXZ0p-bUyXg9ArfKq6MCmSuk3U5k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694531442.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bcv2oi2tbunb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?auto=webp&amp;s=68afd83aca472daa2a38b71beb9f791463539d7e", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ba48af46877d9ccdc191864af2ae4726e4a61adc", "width": 108, "height": 60}, {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=31342517bf1e8cd3f490067c6c2266f587200d62", "width": 216, "height": 121}, {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=47a4b07f71d4c48be3c1ba6dce73bef6fc271bb2", "width": 320, "height": 180}, {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=76ad27ec9ef0f637b14153ccede0111f82a439c6", "width": 640, "height": 360}, {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a4ea74de00c768df821d72eddcb08fc9c534ade7", "width": 960, "height": 540}, {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eae954ab5db2dcf948330c80d40bced427cdf1f0", "width": 1080, "height": 607}], "variants": {}, "id": "Gyw-iIpC3GM7F5t_ZKp5iOqffOhePPyRQpYJKAzLTvA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "16gtwp7", "is_robot_indexable": true, "report_reasons": null, "author": "MooJerseyCreamery", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gtwp7/drowning_in_monthly_active_row_fees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bcv2oi2tbunb1.png", "subreddit_subscribers": 128170, "created_utc": 1694531442.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I'm a sophomore data engineering student and I'm looking for some courses/reading material to jumpstart my career. My university's pacing for actually important content is quite terrible and I'm stuck taking random engineering classes that would be pretty useless to me in the near future. I'm wondering if anyone has any suggestions on where I should start and some stepping stones that I can measure my progress on. Thanks a bunch &lt;3.", "author_fullname": "t2_1mc2oczr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some recommended courses for data engineers at all levels?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gke7y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694502562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m a sophomore data engineering student and I&amp;#39;m looking for some courses/reading material to jumpstart my career. My university&amp;#39;s pacing for actually important content is quite terrible and I&amp;#39;m stuck taking random engineering classes that would be pretty useless to me in the near future. I&amp;#39;m wondering if anyone has any suggestions on where I should start and some stepping stones that I can measure my progress on. Thanks a bunch &amp;lt;3.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16gke7y", "is_robot_indexable": true, "report_reasons": null, "author": "taz_ttv", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gke7y/what_are_some_recommended_courses_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gke7y/what_are_some_recommended_courses_for_data/", "subreddit_subscribers": 128170, "created_utc": 1694502562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m worried about where and how can I build a career after graduation (Bachelor of IT (Data Engineering)) if there are no junior roles. I\u2019ll be based in Australia and my Indeed searches provided almost 0 results in DE junior roles. I\u2019ll assume that I need projects to get my foot on the door. How difficult should they be? What skills should I show?", "author_fullname": "t2_5pilhaal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get a job if there are 0 junior DE roles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gjdst", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694498873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m worried about where and how can I build a career after graduation (Bachelor of IT (Data Engineering)) if there are no junior roles. I\u2019ll be based in Australia and my Indeed searches provided almost 0 results in DE junior roles. I\u2019ll assume that I need projects to get my foot on the door. How difficult should they be? What skills should I show?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16gjdst", "is_robot_indexable": true, "report_reasons": null, "author": "groovyeverywhere", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gjdst/how_to_get_a_job_if_there_are_0_junior_de_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gjdst/how_to_get_a_job_if_there_are_0_junior_de_roles/", "subreddit_subscribers": 128170, "created_utc": 1694498873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a DA whose in the early stages of my own consulting company and need to increase my DE skillset. I am interested in having someone walk through a basic data engineering project that includes gathering data in python through an API, ingesting it into a cloud instance of Snowflake, and setting it to automate the ingestion process. \n\nThis would happen via Google Meets at an agreed upon time. I am, of course, willing to pay for your time. Please DM me if interested.", "author_fullname": "t2_f5lvn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone willing to walk through a data engineering project from gathering data in python through an API to using that data to build a Snowflake database in the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h9imr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694568478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a DA whose in the early stages of my own consulting company and need to increase my DE skillset. I am interested in having someone walk through a basic data engineering project that includes gathering data in python through an API, ingesting it into a cloud instance of Snowflake, and setting it to automate the ingestion process. &lt;/p&gt;\n\n&lt;p&gt;This would happen via Google Meets at an agreed upon time. I am, of course, willing to pay for your time. Please DM me if interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16h9imr", "is_robot_indexable": true, "report_reasons": null, "author": "takemyderivative", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16h9imr/anyone_willing_to_walk_through_a_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16h9imr/anyone_willing_to_walk_through_a_data_engineering/", "subreddit_subscribers": 128170, "created_utc": 1694568478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nI\u2019ve been working on a case study where I\u2019ve to ingest text data into MongoDB(data comes in csv format). Later i have to create some triggers and another collection by utilizing the initial collection.\n\nInitially I involved cleaned this data using pandas(not too big of a dataset), and then imported the cleaned data into MongoDB. Once in MongoDB, I\u2019ve set up some triggers for updating new data with another field.\n\nHowever, I\u2019m pondering the scalability of this system. Specifically, for future data additions, would it be more efficient to handle all data cleaning and transformation directly in MongoDB using aggregations and triggers?\n\nFor those with experience in both python(pandas/spark/polars) and MongoDB, how do you decide where to place your data wrangling logic? What are the trade-offs, and what best practices do you recommend for a system that needs to be scalable and handle new data efficiently? It\u2019s not real time but i just feel adding the extra step of first cleaning in python and then importing is an extra step?\n\nAny insights or advice would be greatly appreciated!\nI\u2019m really new and never worked with MongoDB before, but here it\u2019s a compulsion to use it..\n\nTIA!", "author_fullname": "t2_51y0ecgg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practices for Data Wrangling for MongoDB: python vs. MongoDB Aggregations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gxyl5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694540889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been working on a case study where I\u2019ve to ingest text data into MongoDB(data comes in csv format). Later i have to create some triggers and another collection by utilizing the initial collection.&lt;/p&gt;\n\n&lt;p&gt;Initially I involved cleaned this data using pandas(not too big of a dataset), and then imported the cleaned data into MongoDB. Once in MongoDB, I\u2019ve set up some triggers for updating new data with another field.&lt;/p&gt;\n\n&lt;p&gt;However, I\u2019m pondering the scalability of this system. Specifically, for future data additions, would it be more efficient to handle all data cleaning and transformation directly in MongoDB using aggregations and triggers?&lt;/p&gt;\n\n&lt;p&gt;For those with experience in both python(pandas/spark/polars) and MongoDB, how do you decide where to place your data wrangling logic? What are the trade-offs, and what best practices do you recommend for a system that needs to be scalable and handle new data efficiently? It\u2019s not real time but i just feel adding the extra step of first cleaning in python and then importing is an extra step?&lt;/p&gt;\n\n&lt;p&gt;Any insights or advice would be greatly appreciated!\nI\u2019m really new and never worked with MongoDB before, but here it\u2019s a compulsion to use it..&lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16gxyl5", "is_robot_indexable": true, "report_reasons": null, "author": "ikhan0007", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gxyl5/best_practices_for_data_wrangling_for_mongodb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gxyl5/best_practices_for_data_wrangling_for_mongodb/", "subreddit_subscribers": 128170, "created_utc": 1694540889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I installed a docker for pyspark and started to play with the notebook. However I'm only interested in the data engineering side of spark, not really into the analytic part, any idea what kind of practices I can do? \n\nRight now it's just a docker but I'm fine to install spark in Linux and practice with a single node. Thanks!", "author_fullname": "t2_ldvtxo0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to practice spark for data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gtfpw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694530331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I installed a docker for pyspark and started to play with the notebook. However I&amp;#39;m only interested in the data engineering side of spark, not really into the analytic part, any idea what kind of practices I can do? &lt;/p&gt;\n\n&lt;p&gt;Right now it&amp;#39;s just a docker but I&amp;#39;m fine to install spark in Linux and practice with a single node. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16gtfpw", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway20220231", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gtfpw/how_to_practice_spark_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gtfpw/how_to_practice_spark_for_data_engineering/", "subreddit_subscribers": 128170, "created_utc": 1694530331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am basically a Swiss knife at my company initially hired as senior data scientist but also doing mlops, software engineering best practices and data analyses. So I am the person the company will turn to to industrialise kpis calculations and any data analyses.\n\n  \nThe first thing I would like to do is document the databases that we have (Postgres and mongo). I am used to do so on the python packages I create using [sphinx](https://www.sphinx-doc.org/en/master/). And so, I would like to know if there is a similar tool for database documentation. Mainly what I'm looking for is a tool that enables to write the documentation in the codebase (python, Django) and generate it in html/css files so that everyone in the company can access it via a link in a browser.\n\nDo you know of a tool like this?", "author_fullname": "t2_8kenyeuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database documentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gsndu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694528414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am basically a Swiss knife at my company initially hired as senior data scientist but also doing mlops, software engineering best practices and data analyses. So I am the person the company will turn to to industrialise kpis calculations and any data analyses.&lt;/p&gt;\n\n&lt;p&gt;The first thing I would like to do is document the databases that we have (Postgres and mongo). I am used to do so on the python packages I create using &lt;a href=\"https://www.sphinx-doc.org/en/master/\"&gt;sphinx&lt;/a&gt;. And so, I would like to know if there is a similar tool for database documentation. Mainly what I&amp;#39;m looking for is a tool that enables to write the documentation in the codebase (python, Django) and generate it in html/css files so that everyone in the company can access it via a link in a browser.&lt;/p&gt;\n\n&lt;p&gt;Do you know of a tool like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Tech Lead", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16gsndu", "is_robot_indexable": true, "report_reasons": null, "author": "btenami", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16gsndu/database_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gsndu/database_documentation/", "subreddit_subscribers": 128170, "created_utc": 1694528414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently in a role where I manage the data engineering team and of course the warehouse. We are going through some org and policy changes and one of the suggested policies is NO access to data, in OLTP or DWH. \nMy question is\u2026 is this normal? I\u2019ve been in tech (and data) for 10+ years and I\u2019ve never heard this edict before. RBAC, the concept of least access for role, data masking/obfuscation, yes\u2026 but just flat out not giving users access\u2026 I don\u2019t understand?", "author_fullname": "t2_9rbxc91v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should users have access", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hbaj7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694573365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently in a role where I manage the data engineering team and of course the warehouse. We are going through some org and policy changes and one of the suggested policies is NO access to data, in OLTP or DWH. \nMy question is\u2026 is this normal? I\u2019ve been in tech (and data) for 10+ years and I\u2019ve never heard this edict before. RBAC, the concept of least access for role, data masking/obfuscation, yes\u2026 but just flat out not giving users access\u2026 I don\u2019t understand?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16hbaj7", "is_robot_indexable": true, "report_reasons": null, "author": "AnnualDepth8843", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hbaj7/should_users_have_access/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hbaj7/should_users_have_access/", "subreddit_subscribers": 128170, "created_utc": 1694573365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " cross posting from r/datascience in hopes this community has some additional insights.\n\nhello r/dataengineering community,\n\nI am looking for some perspective on what its like to use azure synapse as a data science platform.\n\nsome background:\n\ncompany is new and just starting their data science journey. we currently do a lot of data science locally but the data is starting to become a lot bigger than what our personal computers can handle so we are looking for a cloud based solution to help us:\n\n1. be able to compute larger volumes of data. not terabytes but maybe 100-200 GB.\n2. be able to orchestrate and automate our solutions. today we manually push the buttons to run our python scripts.\n\nwe already have a separate initiative to use synapse as a data warehouse platform and the data will be available to us there as a data science team. we are mainly exploring the compute side utilizing spark.\n\ndoes anyone else use synapse this way? almost like a platform to host our python that needs to use our enterprise data and then spit out the results right back into storage.\n\nappreciate any insights, thanks!", "author_fullname": "t2_btv9z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring Azure synapse as a data science platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h6n5f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694561001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;cross posting from &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt; in hopes this community has some additional insights.&lt;/p&gt;\n\n&lt;p&gt;hello &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; community,&lt;/p&gt;\n\n&lt;p&gt;I am looking for some perspective on what its like to use azure synapse as a data science platform.&lt;/p&gt;\n\n&lt;p&gt;some background:&lt;/p&gt;\n\n&lt;p&gt;company is new and just starting their data science journey. we currently do a lot of data science locally but the data is starting to become a lot bigger than what our personal computers can handle so we are looking for a cloud based solution to help us:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;be able to compute larger volumes of data. not terabytes but maybe 100-200 GB.&lt;/li&gt;\n&lt;li&gt;be able to orchestrate and automate our solutions. today we manually push the buttons to run our python scripts.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;we already have a separate initiative to use synapse as a data warehouse platform and the data will be available to us there as a data science team. we are mainly exploring the compute side utilizing spark.&lt;/p&gt;\n\n&lt;p&gt;does anyone else use synapse this way? almost like a platform to host our python that needs to use our enterprise data and then spit out the results right back into storage.&lt;/p&gt;\n\n&lt;p&gt;appreciate any insights, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16h6n5f", "is_robot_indexable": true, "report_reasons": null, "author": "Belmeez", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16h6n5f/exploring_azure_synapse_as_a_data_science_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16h6n5f/exploring_azure_synapse_as_a_data_science_platform/", "subreddit_subscribers": 128170, "created_utc": 1694561001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mxj2oz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When to Consider Postgres Partitioning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16gw26l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3t7UMTFeNwAAb0qvUHpB519H77EgMnj-kBI7rmoJhDE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694536489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "timescale.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.timescale.com/blog/when-to-consider-postgres-partitioning/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?auto=webp&amp;s=b3b53f796407fa548ace5c9648ce48b3f7efbeed", "width": 2008, "height": 1120}, "resolutions": [{"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4621f0af69f6a3d67a7259733304793e785e51bc", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c04f57ab89736e416327ac5fe99be5da7899ea2a", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e80aebfb686368747ac939a7802a5e8c47c120aa", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d215bc74f9348de88a6ef34a5c32e4ffd67ef4a3", "width": 640, "height": 356}, {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f81e8f389196f724d5fef72296b47bfab24f37d6", "width": 960, "height": 535}, {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=269f4db1a43fb4a90ea8a6125bf5728feef4827a", "width": 1080, "height": 602}], "variants": {}, "id": "Wvykad5NtH-xlMahfFWRgIE9Y9Bu7QHbWSEbHpeXyIU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16gw26l", "is_robot_indexable": true, "report_reasons": null, "author": "carlotasoto", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gw26l/when_to_consider_postgres_partitioning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.timescale.com/blog/when-to-consider-postgres-partitioning/", "subreddit_subscribers": 128170, "created_utc": 1694536489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m doing a business intelligence cert and noticed that my company has really poor data managers systems, everything on excel etc. So I asked my boss if I could write up a hypothetical system to see if it\u2019s feasible. I said I\u2019d do it by next month and I got permission. Is this too short a time frame and is this kind of thing really difficult?. I\u2019m pretty much just trying this to see if I could since I do want to do data engineering one day.", "author_fullname": "t2_z59ef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard is it to implement a data management system in a company with barely any order?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gs63r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694527251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m doing a business intelligence cert and noticed that my company has really poor data managers systems, everything on excel etc. So I asked my boss if I could write up a hypothetical system to see if it\u2019s feasible. I said I\u2019d do it by next month and I got permission. Is this too short a time frame and is this kind of thing really difficult?. I\u2019m pretty much just trying this to see if I could since I do want to do data engineering one day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16gs63r", "is_robot_indexable": true, "report_reasons": null, "author": "Badassmcgeepmboobies", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gs63r/how_hard_is_it_to_implement_a_data_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gs63r/how_hard_is_it_to_implement_a_data_management/", "subreddit_subscribers": 128170, "created_utc": 1694527251.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}