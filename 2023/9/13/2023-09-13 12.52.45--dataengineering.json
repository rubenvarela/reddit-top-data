{"kind": "Listing", "data": {"after": "t3_16hjoc6", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(Disclosure: founder of GlareDB)\n\nHi everyone,\n\nWe've recently released GlareDB 0.5.0, and our biggest feature for this release is Hybrid Execution.\n\nFirst, what is GlareDB? GlareDB is SQL database that can read data from a variety of sources, including Postgres, Snowflake, S3, and more. Our goal is enabling running analytics across data sources without having to move data around.\n\nAnd with Hybrid Execute, we're taking that a step further. Hybrid Execution lets you connect to a GlareDB Cloud deployment from the GlareDB CLI or Python library, which  allows queries to use the combined resources of both the local and remote machines. GlareDB splits up the query during planning, and executes parts of the query locally or remotely depending on the data being referenced.\n\nThis also enables being able to join local data (parquet, csv, and json files) onto tables that exist in your cloud deployment. For example, if we have a `user_metrics` table in our cloud deployment, and a `company_users.csv` file that's just sitting on our laptop, we're able to write a single query that joins data from both:\n\n    SELECT\n      m.user_id,\n      max(m.output_rows),\n      avg(m.output_rows)::int\n    FROM\n      user_metrics m\n    INNER JOIN './company_users.csv' u on m.user_id = u.id\n    GROUP BY m.user_id\n    LIMIT 5;\n\nWe don't have to manually upload csv files, we just write a single sql query and glaredb takes care of the rest. This also works for dataframes when using our Python library.\n\nWe can go even crazier. Since GlareDB has integrations for connecting to databases like Postgres, Snowflake, and more, we're able to join local data onto remote data sources all in a single query. Here's what that could look like in Python:\n\n    import glaredb\n    import pandas as pd\n    \n    con = glaredb.connect(\"glaredb://&lt;user&gt;:&lt;pass&gt;@glaredb-better.remote.glaredb.com:6443/dogfood\")\n    \n    users = pd.DataFrame({\"email\": [\"sean@glaredb.com\"]})\n    \n    con.sql(\"\"\"\n    select count(*) as query_count,\n           max(e.elapsed_compute_ns) as max_elapsed\n      from snowflake_segment.glaredb_prod.execution_metric e\n      inner join pg_prod.public.users u on e.user_id = u.id\n      inner join users u2 on u.email = u2.email\n      where e.timestamp::timestamp &gt; now() - interval '3 day'\n    \"\"\").show()\n\nAnd as before, we're not having to do anything special with the `users` dataframe, we just reference it in the query, and glaredb will work its magic.\n\nIf you want to learn more about Hybrid Execution, check out our blog post: [https://glaredb.com/blog/hybrid-execution](https://glaredb.com/blog/hybrid-execution)\n\nAnd take a peek at our open source repo: [https://github.com/GlareDB/glaredb](https://github.com/GlareDB/glaredb)\n\nLet us know what you think!", "author_fullname": "t2_butu3hfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hybrid Execution in GlareDB: Scale your workflow with GlareDB Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gyw84", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694543082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Disclosure: founder of GlareDB)&lt;/p&gt;\n\n&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve recently released GlareDB 0.5.0, and our biggest feature for this release is Hybrid Execution.&lt;/p&gt;\n\n&lt;p&gt;First, what is GlareDB? GlareDB is SQL database that can read data from a variety of sources, including Postgres, Snowflake, S3, and more. Our goal is enabling running analytics across data sources without having to move data around.&lt;/p&gt;\n\n&lt;p&gt;And with Hybrid Execute, we&amp;#39;re taking that a step further. Hybrid Execution lets you connect to a GlareDB Cloud deployment from the GlareDB CLI or Python library, which  allows queries to use the combined resources of both the local and remote machines. GlareDB splits up the query during planning, and executes parts of the query locally or remotely depending on the data being referenced.&lt;/p&gt;\n\n&lt;p&gt;This also enables being able to join local data (parquet, csv, and json files) onto tables that exist in your cloud deployment. For example, if we have a &lt;code&gt;user_metrics&lt;/code&gt; table in our cloud deployment, and a &lt;code&gt;company_users.csv&lt;/code&gt; file that&amp;#39;s just sitting on our laptop, we&amp;#39;re able to write a single query that joins data from both:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT\n  m.user_id,\n  max(m.output_rows),\n  avg(m.output_rows)::int\nFROM\n  user_metrics m\nINNER JOIN &amp;#39;./company_users.csv&amp;#39; u on m.user_id = u.id\nGROUP BY m.user_id\nLIMIT 5;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;We don&amp;#39;t have to manually upload csv files, we just write a single sql query and glaredb takes care of the rest. This also works for dataframes when using our Python library.&lt;/p&gt;\n\n&lt;p&gt;We can go even crazier. Since GlareDB has integrations for connecting to databases like Postgres, Snowflake, and more, we&amp;#39;re able to join local data onto remote data sources all in a single query. Here&amp;#39;s what that could look like in Python:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import glaredb\nimport pandas as pd\n\ncon = glaredb.connect(&amp;quot;glaredb://&amp;lt;user&amp;gt;:&amp;lt;pass&amp;gt;@glaredb-better.remote.glaredb.com:6443/dogfood&amp;quot;)\n\nusers = pd.DataFrame({&amp;quot;email&amp;quot;: [&amp;quot;sean@glaredb.com&amp;quot;]})\n\ncon.sql(&amp;quot;&amp;quot;&amp;quot;\nselect count(*) as query_count,\n       max(e.elapsed_compute_ns) as max_elapsed\n  from snowflake_segment.glaredb_prod.execution_metric e\n  inner join pg_prod.public.users u on e.user_id = u.id\n  inner join users u2 on u.email = u2.email\n  where e.timestamp::timestamp &amp;gt; now() - interval &amp;#39;3 day&amp;#39;\n&amp;quot;&amp;quot;&amp;quot;).show()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And as before, we&amp;#39;re not having to do anything special with the &lt;code&gt;users&lt;/code&gt; dataframe, we just reference it in the query, and glaredb will work its magic.&lt;/p&gt;\n\n&lt;p&gt;If you want to learn more about Hybrid Execution, check out our blog post: &lt;a href=\"https://glaredb.com/blog/hybrid-execution\"&gt;https://glaredb.com/blog/hybrid-execution&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And take a peek at our open source repo: &lt;a href=\"https://github.com/GlareDB/glaredb\"&gt;https://github.com/GlareDB/glaredb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Let us know what you think!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?auto=webp&amp;s=4dee1b5daaf4f28142bb37367338cbcc49861006", "width": 3840, "height": 2160}, "resolutions": [{"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c9eed218c2708d33a7c12e9cf1aa2afdcdc3bedf", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=37ee0ccd27b516133613a5739ef600c91d4cb166", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a83a204550161c8771f17321a21101814cc3ba86", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=469a3f369526e393f5425a0a928ee3eb6384e46e", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b13e482322f01561ac1ef9212d52947d466d6b5a", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/q3PgN1-VoY2bx-1qIUOAVkJT5CD-KAHlUmNTVWbi5aI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fccb73db62b1310d319ec542101a7e956b593ea6", "width": 1080, "height": 607}], "variants": {}, "id": "fGYMbTG5G_tyhn5Hv-oYbSHPqwimRoEYC-UzkmsKqYM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16gyw84", "is_robot_indexable": true, "report_reasons": null, "author": "sean-glaredb", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gyw84/hybrid_execution_in_glaredb_scale_your_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gyw84/hybrid_execution_in_glaredb_scale_your_workflow/", "subreddit_subscribers": 128207, "created_utc": 1694543082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you had to start over, what would be your plan to go from zero to hero in 6 months", "author_fullname": "t2_etp40tkx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you had to start over..", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gxz8v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694540935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you had to start over, what would be your plan to go from zero to hero in 6 months&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16gxz8v", "is_robot_indexable": true, "report_reasons": null, "author": "Physical_Flatworm689", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gxz8v/if_you_had_to_start_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gxz8v/if_you_had_to_start_over/", "subreddit_subscribers": 128207, "created_utc": 1694540935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've been a DE for around 14 months now. I've learnt a lot and done some really cool projects. The main thing I've gotten here has been experience and mentoring getting to grips with working in cloud platforms. I've been promoted in the last year, done well etc. Though I'm currently the only engineer for the older systems.\n\nThing is I currently work for a huge multinational company. I just got an offer from a smaller company (still not tiny, but they've basically exploded in size over 5 years) who want to improve their data warehousing, automation etc and transition to being properly \"data driven\". I have no idea how i got it over 2 other candidates who likely had more experience than me. But ill be the first and for some while, only engineer. There wasn't even a real technical interview because they have nobody who could actually conduct one. I'm coming in to a fresh MS sql server and a lot of excel processes, and a team of one IT person and one BI analyst. The longer term plan is that they want to move to Azure and get some advanced analytics off the ground, but they have realistic expectations of where they are and just how far away that is.\n\nThey're also offering me a pretty massive increase over my current salary. Obviously I want to take it. I have lots of ideas, being able to do everything right myself from the start and not dealing with bad legacy systems is appealing. Though part of me is wary. I'll have no back up, nobody to ask for help if things go wrong. I'm technically a senior where I am now due to an early promotion, I run workshops for the non DE guys and have done some good work but given how fresh I am this feels like a massive step up, or taking two steps at once.\n\nWould you guys take something like that on when you're still relatively early career? It feels like a long term project that I'm committed to, and it means I'm not gonna be touching databricks or ADF for a while. Its gonna be all sql server and airflow/dagster at first.", "author_fullname": "t2_dojxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Big company to solo engineer at a small one", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gscf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694527659.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been a DE for around 14 months now. I&amp;#39;ve learnt a lot and done some really cool projects. The main thing I&amp;#39;ve gotten here has been experience and mentoring getting to grips with working in cloud platforms. I&amp;#39;ve been promoted in the last year, done well etc. Though I&amp;#39;m currently the only engineer for the older systems.&lt;/p&gt;\n\n&lt;p&gt;Thing is I currently work for a huge multinational company. I just got an offer from a smaller company (still not tiny, but they&amp;#39;ve basically exploded in size over 5 years) who want to improve their data warehousing, automation etc and transition to being properly &amp;quot;data driven&amp;quot;. I have no idea how i got it over 2 other candidates who likely had more experience than me. But ill be the first and for some while, only engineer. There wasn&amp;#39;t even a real technical interview because they have nobody who could actually conduct one. I&amp;#39;m coming in to a fresh MS sql server and a lot of excel processes, and a team of one IT person and one BI analyst. The longer term plan is that they want to move to Azure and get some advanced analytics off the ground, but they have realistic expectations of where they are and just how far away that is.&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;re also offering me a pretty massive increase over my current salary. Obviously I want to take it. I have lots of ideas, being able to do everything right myself from the start and not dealing with bad legacy systems is appealing. Though part of me is wary. I&amp;#39;ll have no back up, nobody to ask for help if things go wrong. I&amp;#39;m technically a senior where I am now due to an early promotion, I run workshops for the non DE guys and have done some good work but given how fresh I am this feels like a massive step up, or taking two steps at once.&lt;/p&gt;\n\n&lt;p&gt;Would you guys take something like that on when you&amp;#39;re still relatively early career? It feels like a long term project that I&amp;#39;m committed to, and it means I&amp;#39;m not gonna be touching databricks or ADF for a while. Its gonna be all sql server and airflow/dagster at first.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16gscf7", "is_robot_indexable": true, "report_reasons": null, "author": "Gartlas", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gscf7/big_company_to_solo_engineer_at_a_small_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gscf7/big_company_to_solo_engineer_at_a_small_one/", "subreddit_subscribers": 128207, "created_utc": 1694527659.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I guess I never fully understood the love for being a contractor versus fulltime when it comes to data engineering careers. I, like many of you, are getting hit with a lot of LinkedIn recruiters right now and some of these roles they're trying to fill are \"long term contract\". I guess I see contract work as great when you want something that might pay more but is probably shorter term so you can move onto the next job and get a variety of experiences over the long term. I have a family I support so I've always prioritized fulltime roles so that I don't end up stranded at the end of a contract that may/may not get renewed. A recruiter reached out to me recently with a really great paying \"long term contract\" role but since it is contract I'm very hesitant to seriously consider it. For those of you who prefer contract roles, why exactly?", "author_fullname": "t2_556jqozb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ok, who here actually prefers working in a contract position versus being fulltime?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h0kpv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694546958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I guess I never fully understood the love for being a contractor versus fulltime when it comes to data engineering careers. I, like many of you, are getting hit with a lot of LinkedIn recruiters right now and some of these roles they&amp;#39;re trying to fill are &amp;quot;long term contract&amp;quot;. I guess I see contract work as great when you want something that might pay more but is probably shorter term so you can move onto the next job and get a variety of experiences over the long term. I have a family I support so I&amp;#39;ve always prioritized fulltime roles so that I don&amp;#39;t end up stranded at the end of a contract that may/may not get renewed. A recruiter reached out to me recently with a really great paying &amp;quot;long term contract&amp;quot; role but since it is contract I&amp;#39;m very hesitant to seriously consider it. For those of you who prefer contract roles, why exactly?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16h0kpv", "is_robot_indexable": true, "report_reasons": null, "author": "MasterKluch", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16h0kpv/ok_who_here_actually_prefers_working_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16h0kpv/ok_who_here_actually_prefers_working_in_a/", "subreddit_subscribers": 128207, "created_utc": 1694546958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I used to work with BigQuery as my org's data warehouse solution and I miss it...\n\nBelow are some of my qualms with Redshift:\n\n* It isnt magically scaleable like BigQuery\n* Doesn't have sharding\n* Doesn't have DB replication\n* Cannot query data catalogs in glue if with IAM authentication (even with the expensive nodes + extremely poor documentation around this)\n* Cannot run cross-DB queries on external schemas (extremely poor documentation around this) and to get around it you need to make an external schema in every DB if you want the functionality\n* Pay per node vs data scanned (like in BigQuery, so you are pissing money away during downtime)\n* Spectrum is slower than the resources it is querying from (slower than it would be to just use athena)\n\nAre there any other downsides besides those? Or even better am I missing any plus sides?", "author_fullname": "t2_4ffbvgzq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How Does Anybody Make Good Use of Redshift?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gzu8p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694545290.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to work with BigQuery as my org&amp;#39;s data warehouse solution and I miss it...&lt;/p&gt;\n\n&lt;p&gt;Below are some of my qualms with Redshift:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It isnt magically scaleable like BigQuery&lt;/li&gt;\n&lt;li&gt;Doesn&amp;#39;t have sharding&lt;/li&gt;\n&lt;li&gt;Doesn&amp;#39;t have DB replication&lt;/li&gt;\n&lt;li&gt;Cannot query data catalogs in glue if with IAM authentication (even with the expensive nodes + extremely poor documentation around this)&lt;/li&gt;\n&lt;li&gt;Cannot run cross-DB queries on external schemas (extremely poor documentation around this) and to get around it you need to make an external schema in every DB if you want the functionality&lt;/li&gt;\n&lt;li&gt;Pay per node vs data scanned (like in BigQuery, so you are pissing money away during downtime)&lt;/li&gt;\n&lt;li&gt;Spectrum is slower than the resources it is querying from (slower than it would be to just use athena)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Are there any other downsides besides those? Or even better am I missing any plus sides?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16gzu8p", "is_robot_indexable": true, "report_reasons": null, "author": "ReporterNervous6822", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gzu8p/how_does_anybody_make_good_use_of_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gzu8p/how_does_anybody_make_good_use_of_redshift/", "subreddit_subscribers": 128207, "created_utc": 1694545290.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DA with 5+ years experience. Mainly SQL, Tableau, and Python for some data exploration, analysis, regression models, and some web scraping.\n\nI want to break into DE, so I have been doing very basic projects. I feel like I am missing a huge piece of what to do, and what a DE really is. I need some help, please. \n\nSo far I have done three projects that have involved Pandas:\n\n1.) Taken a dataset from an API (one requiring a key, two open source)\n\n2.) Formatting that from JSON into a data frame / cleaned the data up.\n\n3.) Importing it into a SQL Database\n\n4.) Building some visualizations out of it in Tableau and PBI.\n\nI'm a bit lost. Where does the modeling, data scheduling, and all of that come in. I hear things about BigQuery, Azure, Airflow, etc. I can't imagine telling a future employer that this is what I have done, and have them believe I am capable of being a Data Engineer.\n\nWhat would you consider the next step to be?", "author_fullname": "t2_6iptp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel like I am on the edge of doing cool DE things, but I need some help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h0nvc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694568850.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694547160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DA with 5+ years experience. Mainly SQL, Tableau, and Python for some data exploration, analysis, regression models, and some web scraping.&lt;/p&gt;\n\n&lt;p&gt;I want to break into DE, so I have been doing very basic projects. I feel like I am missing a huge piece of what to do, and what a DE really is. I need some help, please. &lt;/p&gt;\n\n&lt;p&gt;So far I have done three projects that have involved Pandas:&lt;/p&gt;\n\n&lt;p&gt;1.) Taken a dataset from an API (one requiring a key, two open source)&lt;/p&gt;\n\n&lt;p&gt;2.) Formatting that from JSON into a data frame / cleaned the data up.&lt;/p&gt;\n\n&lt;p&gt;3.) Importing it into a SQL Database&lt;/p&gt;\n\n&lt;p&gt;4.) Building some visualizations out of it in Tableau and PBI.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a bit lost. Where does the modeling, data scheduling, and all of that come in. I hear things about BigQuery, Azure, Airflow, etc. I can&amp;#39;t imagine telling a future employer that this is what I have done, and have them believe I am capable of being a Data Engineer.&lt;/p&gt;\n\n&lt;p&gt;What would you consider the next step to be?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16h0nvc", "is_robot_indexable": true, "report_reasons": null, "author": "tits_mcgee_92", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16h0nvc/i_feel_like_i_am_on_the_edge_of_doing_cool_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16h0nvc/i_feel_like_i_am_on_the_edge_of_doing_cool_de/", "subreddit_subscribers": 128207, "created_utc": 1694547160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a tool or library that allows you to query an API and get the JSON response into a DB? Issue I have is with nested JSON, where a single response should probably be stored in 2+ tables. ", "author_fullname": "t2_6uawl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any JSON API responses to DB tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16guh1l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694532790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a tool or library that allows you to query an API and get the JSON response into a DB? Issue I have is with nested JSON, where a single response should probably be stored in 2+ tables. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16guh1l", "is_robot_indexable": true, "report_reasons": null, "author": "selleckh", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16guh1l/any_json_api_responses_to_db_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16guh1l/any_json_api_responses_to_db_tools/", "subreddit_subscribers": 128207, "created_utc": 1694532790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know a lot of people have said that DDIA book is the best way to learn system design, but I am personally not a good reader and I\u2019m a visual learner. I finished fundamental of data engineering but honestly have not learned much knowledge from the book lol. What are some resources that will help to learn system design? \n\nAlso when everyone talks about system design, is there any system design specifically for software engineers or data engineers?", "author_fullname": "t2_1xrjwd6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to learn more about system design?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gynnq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694542541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know a lot of people have said that DDIA book is the best way to learn system design, but I am personally not a good reader and I\u2019m a visual learner. I finished fundamental of data engineering but honestly have not learned much knowledge from the book lol. What are some resources that will help to learn system design? &lt;/p&gt;\n\n&lt;p&gt;Also when everyone talks about system design, is there any system design specifically for software engineers or data engineers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16gynnq", "is_robot_indexable": true, "report_reasons": null, "author": "Fasthandman", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gynnq/how_to_learn_more_about_system_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gynnq/how_to_learn_more_about_system_design/", "subreddit_subscribers": 128207, "created_utc": 1694542541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We've been working on a simple API for running Python functions in the cloud. In this guide, we use three methods to process the NYC taxi dataset and compare runtimes:  \n\\- locally, 5 hr  \n\\- on a big VM in the cloud, 30 min  \n\\- parallel processing on a big VM in the cloud, 5 min\n\nThis post walks through how you can adapt your Python functions with minimal code changes using Coiled functions [https://medium.com/coiled-hq/parallel-serverless-functions-at-scale-cd6ee4a7def5](https://medium.com/coiled-hq/parallel-serverless-functions-at-scale-cd6ee4a7def5).\n\nIt'd be great to hear your thoughts!\n\nIn the interest of transparency, I work for Coiled, and a colleague of mine wrote this post.", "author_fullname": "t2_w7crvjmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working with many parquet files on S3 in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gzn4d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694544841.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;ve been working on a simple API for running Python functions in the cloud. In this guide, we use three methods to process the NYC taxi dataset and compare runtimes:&lt;br/&gt;\n- locally, 5 hr&lt;br/&gt;\n- on a big VM in the cloud, 30 min&lt;br/&gt;\n- parallel processing on a big VM in the cloud, 5 min&lt;/p&gt;\n\n&lt;p&gt;This post walks through how you can adapt your Python functions with minimal code changes using Coiled functions &lt;a href=\"https://medium.com/coiled-hq/parallel-serverless-functions-at-scale-cd6ee4a7def5\"&gt;https://medium.com/coiled-hq/parallel-serverless-functions-at-scale-cd6ee4a7def5&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;d be great to hear your thoughts!&lt;/p&gt;\n\n&lt;p&gt;In the interest of transparency, I work for Coiled, and a colleague of mine wrote this post.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?auto=webp&amp;s=048892709cccbd1b2c68896a31e04218a992e888", "width": 1200, "height": 746}, "resolutions": [{"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=968dca02548dce0e1f7fc3652d5017b006779069", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b72d5e9b0e68c4a6c19a8570d858026c7f6e7470", "width": 216, "height": 134}, {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=544bc6977f20756c3bce657c46e6a8829f59fb20", "width": 320, "height": 198}, {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=17000a825a6a4920790368c7472dac300f1727e2", "width": 640, "height": 397}, {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b319f4edf6d70992e730d4fad3b19416f2db26fd", "width": 960, "height": 596}, {"url": "https://external-preview.redd.it/SkQn1xF2PKPFMF5RrjYn0BaQ_AK_EKCfbwjtLmunb4Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=05791914c7082496c2c4442f73acf0e1643154d1", "width": 1080, "height": 671}], "variants": {}, "id": "A5iyBO5ZP8sgdDc1RsvBp2CEzZYJPo5gZlneKlSl-6Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16gzn4d", "is_robot_indexable": true, "report_reasons": null, "author": "dask-jeeves", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gzn4d/working_with_many_parquet_files_on_s3_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gzn4d/working_with_many_parquet_files_on_s3_in_python/", "subreddit_subscribers": 128207, "created_utc": 1694544841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TL;DR: need to ETL from db but primary keys get shuffled around after each migration. Wat do?\n\n\\---\n\nHey folks,\n\nI have a tricky situation and I'm not sure what's the best way to address it.\n\nBasically we have a backend in postgres managed by Django ORM. For some goddamn reason, after each migration, the PKs of (most) records get shuffled around randomly, even if there's no change in data at all.\n\nFor example, if before migration I have this:\n\n|ID (PK)|Name|Surname|\n|:-|:-|:-|\n|1|John|Wayne|\n|234|Julia|Roberts|\n\n&amp;#x200B;\n\nafter migration I can end up with:\n\n|ID (PK)|Name|Surname|\n|:-|:-|:-|\n|234|John|Wayne|\n|890|Julia|Roberts|\n\n&amp;#x200B;\n\nOn top that, for a bunch of tables, natural keys are not 100% reliable due to how they get inserted (it's a human CRUD process).\n\nGiven that I have absolutely zero control on the backend, what strategies would you recommend I apply for E(T)L and data warehousing activities?\n\nThanks in advance for your input!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL from postgres, but Django shuffles Primary Keys after each migration.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gxw34", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694540728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TL;DR: need to ETL from db but primary keys get shuffled around after each migration. Wat do?&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I have a tricky situation and I&amp;#39;m not sure what&amp;#39;s the best way to address it.&lt;/p&gt;\n\n&lt;p&gt;Basically we have a backend in postgres managed by Django ORM. For some goddamn reason, after each migration, the PKs of (most) records get shuffled around randomly, even if there&amp;#39;s no change in data at all.&lt;/p&gt;\n\n&lt;p&gt;For example, if before migration I have this:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;ID (PK)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Name&lt;/th&gt;\n&lt;th align=\"left\"&gt;Surname&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;John&lt;/td&gt;\n&lt;td align=\"left\"&gt;Wayne&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;234&lt;/td&gt;\n&lt;td align=\"left\"&gt;Julia&lt;/td&gt;\n&lt;td align=\"left\"&gt;Roberts&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;after migration I can end up with:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;ID (PK)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Name&lt;/th&gt;\n&lt;th align=\"left\"&gt;Surname&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;234&lt;/td&gt;\n&lt;td align=\"left\"&gt;John&lt;/td&gt;\n&lt;td align=\"left\"&gt;Wayne&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;890&lt;/td&gt;\n&lt;td align=\"left\"&gt;Julia&lt;/td&gt;\n&lt;td align=\"left\"&gt;Roberts&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;On top that, for a bunch of tables, natural keys are not 100% reliable due to how they get inserted (it&amp;#39;s a human CRUD process).&lt;/p&gt;\n\n&lt;p&gt;Given that I have absolutely zero control on the backend, what strategies would you recommend I apply for E(T)L and data warehousing activities?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16gxw34", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gxw34/etl_from_postgres_but_django_shuffles_primary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gxw34/etl_from_postgres_but_django_shuffles_primary/", "subreddit_subscribers": 128207, "created_utc": 1694540728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_sa3mbz4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "drowning in monthly active row fees", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16gtwp7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ywjkpICKIVt7tqIGXZ0p-bUyXg9ArfKq6MCmSuk3U5k.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694531442.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bcv2oi2tbunb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?auto=webp&amp;s=68afd83aca472daa2a38b71beb9f791463539d7e", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ba48af46877d9ccdc191864af2ae4726e4a61adc", "width": 108, "height": 60}, {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=31342517bf1e8cd3f490067c6c2266f587200d62", "width": 216, "height": 121}, {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=47a4b07f71d4c48be3c1ba6dce73bef6fc271bb2", "width": 320, "height": 180}, {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=76ad27ec9ef0f637b14153ccede0111f82a439c6", "width": 640, "height": 360}, {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a4ea74de00c768df821d72eddcb08fc9c534ade7", "width": 960, "height": 540}, {"url": "https://preview.redd.it/bcv2oi2tbunb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eae954ab5db2dcf948330c80d40bced427cdf1f0", "width": 1080, "height": 607}], "variants": {}, "id": "Gyw-iIpC3GM7F5t_ZKp5iOqffOhePPyRQpYJKAzLTvA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "16gtwp7", "is_robot_indexable": true, "report_reasons": null, "author": "MooJerseyCreamery", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gtwp7/drowning_in_monthly_active_row_fees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bcv2oi2tbunb1.png", "subreddit_subscribers": 128207, "created_utc": 1694531442.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a DA whose in the early stages of my own consulting company and need to increase my DE skillset. I am interested in having someone walk through a basic data engineering project that includes gathering data in python through an API, ingesting it into a cloud instance of Snowflake, and setting it to automate the ingestion process. \n\nThis would happen via Google Meets at an agreed upon time. I am, of course, willing to pay for your time. Please DM me if interested.", "author_fullname": "t2_f5lvn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone willing to walk through a data engineering project from gathering data in python through an API to using that data to build a Snowflake database in the cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h9imr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694568478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a DA whose in the early stages of my own consulting company and need to increase my DE skillset. I am interested in having someone walk through a basic data engineering project that includes gathering data in python through an API, ingesting it into a cloud instance of Snowflake, and setting it to automate the ingestion process. &lt;/p&gt;\n\n&lt;p&gt;This would happen via Google Meets at an agreed upon time. I am, of course, willing to pay for your time. Please DM me if interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16h9imr", "is_robot_indexable": true, "report_reasons": null, "author": "takemyderivative", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16h9imr/anyone_willing_to_walk_through_a_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16h9imr/anyone_willing_to_walk_through_a_data_engineering/", "subreddit_subscribers": 128207, "created_utc": 1694568478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What techniques do you use to create large numbers of simple ETL jobs? For example, we have thousands of tables that we want to copy from point A to B with minimum modifications (adding standardized metadata). Each job is independent so there\u2019s no dependencies to worry about. Previous developers created a job via a GUI for each one which meant months of tedious point and click hell. \n\nHow do you handle bulk job creation and management in the tool of your choice?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL job overload", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16h8bi8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694565277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What techniques do you use to create large numbers of simple ETL jobs? For example, we have thousands of tables that we want to copy from point A to B with minimum modifications (adding standardized metadata). Each job is independent so there\u2019s no dependencies to worry about. Previous developers created a job via a GUI for each one which meant months of tedious point and click hell. &lt;/p&gt;\n\n&lt;p&gt;How do you handle bulk job creation and management in the tool of your choice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16h8bi8", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16h8bi8/etl_job_overload/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16h8bi8/etl_job_overload/", "subreddit_subscribers": 128207, "created_utc": 1694565277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI have come across an opportunity that has significant bigger salary but it is not traditional DE job. It\u2019s with a service based org which requires pre-sales work for data team. Be the first point of contact for data related projects and products. \n\nPlease note this is India. \n\nIs a right career move? \nPros: salary and learning. I might learn a lot with a spectrum of technologies. \nCompletely remote. \n\nCons: cannot work deep into integration and delivery. Except compensation, benefits are. Jon existent.  No people attachment. \n\nLooking forward to your questions and opinions.", "author_fullname": "t2_42i9lwic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is pre-sales data engineering good?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gya6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694541665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I have come across an opportunity that has significant bigger salary but it is not traditional DE job. It\u2019s with a service based org which requires pre-sales work for data team. Be the first point of contact for data related projects and products. &lt;/p&gt;\n\n&lt;p&gt;Please note this is India. &lt;/p&gt;\n\n&lt;p&gt;Is a right career move? \nPros: salary and learning. I might learn a lot with a spectrum of technologies. \nCompletely remote. &lt;/p&gt;\n\n&lt;p&gt;Cons: cannot work deep into integration and delivery. Except compensation, benefits are. Jon existent.  No people attachment. &lt;/p&gt;\n\n&lt;p&gt;Looking forward to your questions and opinions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16gya6e", "is_robot_indexable": true, "report_reasons": null, "author": "snapperPanda", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gya6e/is_presales_data_engineering_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gya6e/is_presales_data_engineering_good/", "subreddit_subscribers": 128207, "created_utc": 1694541665.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently in a role where I manage the data engineering team and of course the warehouse. We are going through some org and policy changes and one of the suggested policies is NO access to data, in OLTP or DWH. \nMy question is\u2026 is this normal? I\u2019ve been in tech (and data) for 10+ years and I\u2019ve never heard this edict before. RBAC, the concept of least access for role, data masking/obfuscation, yes\u2026 but just flat out not giving users access\u2026 I don\u2019t understand?", "author_fullname": "t2_9rbxc91v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should users have access", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hbaj7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694573365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently in a role where I manage the data engineering team and of course the warehouse. We are going through some org and policy changes and one of the suggested policies is NO access to data, in OLTP or DWH. \nMy question is\u2026 is this normal? I\u2019ve been in tech (and data) for 10+ years and I\u2019ve never heard this edict before. RBAC, the concept of least access for role, data masking/obfuscation, yes\u2026 but just flat out not giving users access\u2026 I don\u2019t understand?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16hbaj7", "is_robot_indexable": true, "report_reasons": null, "author": "AnnualDepth8843", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hbaj7/should_users_have_access/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hbaj7/should_users_have_access/", "subreddit_subscribers": 128207, "created_utc": 1694573365.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone!\n\nI\u2019ve been working on a case study where I\u2019ve to ingest text data into MongoDB(data comes in csv format). Later i have to create some triggers and another collection by utilizing the initial collection.\n\nInitially I involved cleaned this data using pandas(not too big of a dataset), and then imported the cleaned data into MongoDB. Once in MongoDB, I\u2019ve set up some triggers for updating new data with another field.\n\nHowever, I\u2019m pondering the scalability of this system. Specifically, for future data additions, would it be more efficient to handle all data cleaning and transformation directly in MongoDB using aggregations and triggers?\n\nFor those with experience in both python(pandas/spark/polars) and MongoDB, how do you decide where to place your data wrangling logic? What are the trade-offs, and what best practices do you recommend for a system that needs to be scalable and handle new data efficiently? It\u2019s not real time but i just feel adding the extra step of first cleaning in python and then importing is an extra step?\n\nAny insights or advice would be greatly appreciated!\nI\u2019m really new and never worked with MongoDB before, but here it\u2019s a compulsion to use it..\n\nTIA!", "author_fullname": "t2_51y0ecgg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Practices for Data Wrangling for MongoDB: python vs. MongoDB Aggregations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gxyl5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694540889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been working on a case study where I\u2019ve to ingest text data into MongoDB(data comes in csv format). Later i have to create some triggers and another collection by utilizing the initial collection.&lt;/p&gt;\n\n&lt;p&gt;Initially I involved cleaned this data using pandas(not too big of a dataset), and then imported the cleaned data into MongoDB. Once in MongoDB, I\u2019ve set up some triggers for updating new data with another field.&lt;/p&gt;\n\n&lt;p&gt;However, I\u2019m pondering the scalability of this system. Specifically, for future data additions, would it be more efficient to handle all data cleaning and transformation directly in MongoDB using aggregations and triggers?&lt;/p&gt;\n\n&lt;p&gt;For those with experience in both python(pandas/spark/polars) and MongoDB, how do you decide where to place your data wrangling logic? What are the trade-offs, and what best practices do you recommend for a system that needs to be scalable and handle new data efficiently? It\u2019s not real time but i just feel adding the extra step of first cleaning in python and then importing is an extra step?&lt;/p&gt;\n\n&lt;p&gt;Any insights or advice would be greatly appreciated!\nI\u2019m really new and never worked with MongoDB before, but here it\u2019s a compulsion to use it..&lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16gxyl5", "is_robot_indexable": true, "report_reasons": null, "author": "ikhan0007", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gxyl5/best_practices_for_data_wrangling_for_mongodb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gxyl5/best_practices_for_data_wrangling_for_mongodb/", "subreddit_subscribers": 128207, "created_utc": 1694540889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I installed a docker for pyspark and started to play with the notebook. However I'm only interested in the data engineering side of spark, not really into the analytic part, any idea what kind of practices I can do? \n\nRight now it's just a docker but I'm fine to install spark in Linux and practice with a single node. Thanks!", "author_fullname": "t2_ldvtxo0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to practice spark for data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gtfpw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694530331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I installed a docker for pyspark and started to play with the notebook. However I&amp;#39;m only interested in the data engineering side of spark, not really into the analytic part, any idea what kind of practices I can do? &lt;/p&gt;\n\n&lt;p&gt;Right now it&amp;#39;s just a docker but I&amp;#39;m fine to install spark in Linux and practice with a single node. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16gtfpw", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway20220231", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gtfpw/how_to_practice_spark_for_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gtfpw/how_to_practice_spark_for_data_engineering/", "subreddit_subscribers": 128207, "created_utc": 1694530331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am basically a Swiss knife at my company initially hired as senior data scientist but also doing mlops, software engineering best practices and data analyses. So I am the person the company will turn to to industrialise kpis calculations and any data analyses.\n\n  \nThe first thing I would like to do is document the databases that we have (Postgres and mongo). I am used to do so on the python packages I create using [sphinx](https://www.sphinx-doc.org/en/master/). And so, I would like to know if there is a similar tool for database documentation. Mainly what I'm looking for is a tool that enables to write the documentation in the codebase (python, Django) and generate it in html/css files so that everyone in the company can access it via a link in a browser.\n\nDo you know of a tool like this?", "author_fullname": "t2_8kenyeuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database documentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gsndu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694528414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am basically a Swiss knife at my company initially hired as senior data scientist but also doing mlops, software engineering best practices and data analyses. So I am the person the company will turn to to industrialise kpis calculations and any data analyses.&lt;/p&gt;\n\n&lt;p&gt;The first thing I would like to do is document the databases that we have (Postgres and mongo). I am used to do so on the python packages I create using &lt;a href=\"https://www.sphinx-doc.org/en/master/\"&gt;sphinx&lt;/a&gt;. And so, I would like to know if there is a similar tool for database documentation. Mainly what I&amp;#39;m looking for is a tool that enables to write the documentation in the codebase (python, Django) and generate it in html/css files so that everyone in the company can access it via a link in a browser.&lt;/p&gt;\n\n&lt;p&gt;Do you know of a tool like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Tech Lead", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16gsndu", "is_robot_indexable": true, "report_reasons": null, "author": "btenami", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16gsndu/database_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gsndu/database_documentation/", "subreddit_subscribers": 128207, "created_utc": 1694528414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a Data Engineer located in Hong Kong with 4 years experience. Before this position I was an analyst but it's more a \"full-stacked\" position since I was involved in developing data pipeline and data modeling beside the analytic part.\n\nMy current team is small, only me and a DevOps Engineer design, develop and maintain a data platform. Although our platform are built based on AWS machines, most of components are picked from different open source projects instead of using cloud services (e.g self-managed Spark Application instead of EMR). The DevOps Engineer help setup the environment and infrastructure management. I'm responsible for pipeline development and optimization, pipeline orchestration, data modeling, data visualization. I also handle some basic DevOps jobs in case the DevOps Engineer is not available and it's really challenging. We also have a BA and a PM in the team, I need to work with team to understand the business requirement sometime.\n\nRecently I started discussion with different people and did some research in the data field in Hong Kong. It looks like my skillset is not match to the market since most of companies (around 7\\~8/10) use cloud service fully or enterprise data platform like Cloudera or Databricks. More importantly, it seems like you're not experienced if you didn't use any cloud service like AWS EMR before, even though I've a project in GitHub and profile in SO.\n\nThat makes me feel frustrated. I enjoy pipeline development and data modeling, also I wish my work can impact and contribute to the business, but i'm not sure the boundary between a Data Engineer and DevOps Engineer, especially I'm not familiar with the DevOps side like networking and IAM. On the other hand, it seems my skill set is not transferrable to my next job.\n\nI would like to ask:\n\n1. What do you think a Data Engineer should focus on? I prevent being jack of all trades but master of none.\n2. Is it worthing to spend time getting the cloud / Databricks certificates? Is it helpful when you applying the job? Should I spending more time on studying cloud service instead of the open source project?\n\nThanks for spending time on this post. I would love to know your advice and also your story on how do you grow in the role of Data Engineer.\n\nThank you.", "author_fullname": "t2_a7y0xzcr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ask for advice on the next move on Data Engineer role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16hgvlq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694591596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a Data Engineer located in Hong Kong with 4 years experience. Before this position I was an analyst but it&amp;#39;s more a &amp;quot;full-stacked&amp;quot; position since I was involved in developing data pipeline and data modeling beside the analytic part.&lt;/p&gt;\n\n&lt;p&gt;My current team is small, only me and a DevOps Engineer design, develop and maintain a data platform. Although our platform are built based on AWS machines, most of components are picked from different open source projects instead of using cloud services (e.g self-managed Spark Application instead of EMR). The DevOps Engineer help setup the environment and infrastructure management. I&amp;#39;m responsible for pipeline development and optimization, pipeline orchestration, data modeling, data visualization. I also handle some basic DevOps jobs in case the DevOps Engineer is not available and it&amp;#39;s really challenging. We also have a BA and a PM in the team, I need to work with team to understand the business requirement sometime.&lt;/p&gt;\n\n&lt;p&gt;Recently I started discussion with different people and did some research in the data field in Hong Kong. It looks like my skillset is not match to the market since most of companies (around 7~8/10) use cloud service fully or enterprise data platform like Cloudera or Databricks. More importantly, it seems like you&amp;#39;re not experienced if you didn&amp;#39;t use any cloud service like AWS EMR before, even though I&amp;#39;ve a project in GitHub and profile in SO.&lt;/p&gt;\n\n&lt;p&gt;That makes me feel frustrated. I enjoy pipeline development and data modeling, also I wish my work can impact and contribute to the business, but i&amp;#39;m not sure the boundary between a Data Engineer and DevOps Engineer, especially I&amp;#39;m not familiar with the DevOps side like networking and IAM. On the other hand, it seems my skill set is not transferrable to my next job.&lt;/p&gt;\n\n&lt;p&gt;I would like to ask:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What do you think a Data Engineer should focus on? I prevent being jack of all trades but master of none.&lt;/li&gt;\n&lt;li&gt;Is it worthing to spend time getting the cloud / Databricks certificates? Is it helpful when you applying the job? Should I spending more time on studying cloud service instead of the open source project?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thanks for spending time on this post. I would love to know your advice and also your story on how do you grow in the role of Data Engineer.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16hgvlq", "is_robot_indexable": true, "report_reasons": null, "author": "masamibb", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hgvlq/ask_for_advice_on_the_next_move_on_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hgvlq/ask_for_advice_on_the_next_move_on_data_engineer/", "subreddit_subscribers": 128207, "created_utc": 1694591596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, \n\nI am working as a Informatica Data Quality Developer and developing PowerBI reports for almost 3 years. \n\nNow my org is moving to ADF, \ni guess  there will be no transformations like Informatica so i guess we'll have to use stored procedures more.\n\ni am good at SQL  but i doubt at stored procedures. \ni am still. open to learn any tech related to data, and i can also work on python. \n\n\nShould i learn ADF and move ahead or jump to a different organization with Informatica exp.\n\nThanks in advance!!", "author_fullname": "t2_pk9muibi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Informatica / ADF (Stay / Switch)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gw5q9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694536735.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, &lt;/p&gt;\n\n&lt;p&gt;I am working as a Informatica Data Quality Developer and developing PowerBI reports for almost 3 years. &lt;/p&gt;\n\n&lt;p&gt;Now my org is moving to ADF, \ni guess  there will be no transformations like Informatica so i guess we&amp;#39;ll have to use stored procedures more.&lt;/p&gt;\n\n&lt;p&gt;i am good at SQL  but i doubt at stored procedures. \ni am still. open to learn any tech related to data, and i can also work on python. &lt;/p&gt;\n\n&lt;p&gt;Should i learn ADF and move ahead or jump to a different organization with Informatica exp.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16gw5q9", "is_robot_indexable": true, "report_reasons": null, "author": "NeighborhoodEasy814", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gw5q9/informatica_adf_stay_switch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gw5q9/informatica_adf_stay_switch/", "subreddit_subscribers": 128207, "created_utc": 1694536735.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mxj2oz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When to Consider Postgres Partitioning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16gw26l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3t7UMTFeNwAAb0qvUHpB519H77EgMnj-kBI7rmoJhDE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694536489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "timescale.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.timescale.com/blog/when-to-consider-postgres-partitioning/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?auto=webp&amp;s=b3b53f796407fa548ace5c9648ce48b3f7efbeed", "width": 2008, "height": 1120}, "resolutions": [{"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4621f0af69f6a3d67a7259733304793e785e51bc", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c04f57ab89736e416327ac5fe99be5da7899ea2a", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e80aebfb686368747ac939a7802a5e8c47c120aa", "width": 320, "height": 178}, {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d215bc74f9348de88a6ef34a5c32e4ffd67ef4a3", "width": 640, "height": 356}, {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f81e8f389196f724d5fef72296b47bfab24f37d6", "width": 960, "height": 535}, {"url": "https://external-preview.redd.it/Pjb_Lj8jqadBraoOgfdlutqb5Pst3O8i23znFMIXa6M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=269f4db1a43fb4a90ea8a6125bf5728feef4827a", "width": 1080, "height": 602}], "variants": {}, "id": "Wvykad5NtH-xlMahfFWRgIE9Y9Bu7QHbWSEbHpeXyIU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16gw26l", "is_robot_indexable": true, "report_reasons": null, "author": "carlotasoto", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gw26l/when_to_consider_postgres_partitioning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.timescale.com/blog/when-to-consider-postgres-partitioning/", "subreddit_subscribers": 128207, "created_utc": 1694536489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m doing a business intelligence cert and noticed that my company has really poor data managers systems, everything on excel etc. So I asked my boss if I could write up a hypothetical system to see if it\u2019s feasible. I said I\u2019d do it by next month and I got permission. Is this too short a time frame and is this kind of thing really difficult?. I\u2019m pretty much just trying this to see if I could since I do want to do data engineering one day.", "author_fullname": "t2_z59ef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How hard is it to implement a data management system in a company with barely any order?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16gs63r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694527251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m doing a business intelligence cert and noticed that my company has really poor data managers systems, everything on excel etc. So I asked my boss if I could write up a hypothetical system to see if it\u2019s feasible. I said I\u2019d do it by next month and I got permission. Is this too short a time frame and is this kind of thing really difficult?. I\u2019m pretty much just trying this to see if I could since I do want to do data engineering one day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16gs63r", "is_robot_indexable": true, "report_reasons": null, "author": "Badassmcgeepmboobies", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16gs63r/how_hard_is_it_to_implement_a_data_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16gs63r/how_hard_is_it_to_implement_a_data_management/", "subreddit_subscribers": 128207, "created_utc": 1694527251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, I\u2019m working on developing a no code ETL tool where user can just drag and drop to create a pipeline from any source to any destination and also do transformations on the source data through drag and drop again.   \n\nSo I needed some help in the transformation part.   \n\nWhatever transformation user selects, it needs to go in a json format as a request and then we need to write a pyspark equivalent code of that json to do the transformation in backend.  So need help with how to structure that JSON.  \n\nSo if anyone has any experience related to this or any idea on it, please do DM  ", "author_fullname": "t2_54tmiaey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help in developing a no code ETL Tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16hktbd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694605391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, I\u2019m working on developing a no code ETL tool where user can just drag and drop to create a pipeline from any source to any destination and also do transformations on the source data through drag and drop again.   &lt;/p&gt;\n\n&lt;p&gt;So I needed some help in the transformation part.   &lt;/p&gt;\n\n&lt;p&gt;Whatever transformation user selects, it needs to go in a json format as a request and then we need to write a pyspark equivalent code of that json to do the transformation in backend.  So need help with how to structure that JSON.  &lt;/p&gt;\n\n&lt;p&gt;So if anyone has any experience related to this or any idea on it, please do DM  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16hktbd", "is_robot_indexable": true, "report_reasons": null, "author": "flightofeagle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hktbd/need_help_in_developing_a_no_code_etl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hktbd/need_help_in_developing_a_no_code_etl_tool/", "subreddit_subscribers": 128207, "created_utc": 1694605391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to extract the API from Oracle Netsuite. Can someone please guide me? ", "author_fullname": "t2_dfjkwfqn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oracle Netsuite API to extract the data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16hkdig", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694604076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to extract the API from Oracle Netsuite. Can someone please guide me? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16hkdig", "is_robot_indexable": true, "report_reasons": null, "author": "Boss2508", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hkdig/oracle_netsuite_api_to_extract_the_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hkdig/oracle_netsuite_api_to_extract_the_data/", "subreddit_subscribers": 128207, "created_utc": 1694604076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am using ADF for an ETL job and I use one generic pipelines per database type (PostgreSQL, DB2, SqlServer). The data is copied from tables in respective database and saved in a data lake (which I call bronze). In a table called MetaBronze I have specified servernames, connectionsstrings and what tables to be copied as well as in which container and under what filepath in the data lake the copy should be stored. I also mark which date this was done so I can reload by updating the date to an earlier one.\n\nIt is a bit like the following approach: [https://techcommunity.microsoft.com/t5/fasttrack-for-azure/metadata-driven-pipelines-for-microsoft-fabric/ba-p/3891651](https://techcommunity.microsoft.com/t5/fasttrack-for-azure/metadata-driven-pipelines-for-microsoft-fabric/ba-p/3891651)\n\nSo far so good since I have a one-to-one relationship between source and destination. However, between my bronze layer and silver layer there is a many-to-many relationship. A specific table (table here is a parquet file copied from the source) from bronze can go to many different tables in the silver layer and multiple tables from bronze can go to one table in the silver layer.\n\nHow should I design this?\n\nBetween bronze and silver we need to keep track of the max date of the files that we used to build the tables in silver since some of the tables are updated incrementally.\n\nLastly between Silver and Gold there is a many-to-one relationship.\n\nCurrently I plan on making one table for each step: MetaBronze, MetaSilver, MetaGold and then an Mapping table that maps Id's between the steps. However I am not sure this is a good Idea.\n\nThanks In advance! Any tip on reading material would be much appreciated as well as suggestions on how this should be designed.\n\nEdit:\n\nFollowing is a rough draft on how I imagine the design should be (obviously there will be much more columns in each table, but in this draft I wanted to address the many-to-many issue). Hope this sketch makes it easier to understand what I want to achieve.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/u414cv9pr0ob1.png?width=1505&amp;format=png&amp;auto=webp&amp;s=6c2fcb893d374b23cc41546417a1ba8b3a71ddad\n\n&amp;#x200B;", "author_fullname": "t2_7ckv97pys", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to design a metadata table (or tables) to handle many-to-many relationship between source and destination", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 60, "top_awarded_type": null, "hide_score": false, "media_metadata": {"u414cv9pr0ob1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 46, "x": 108, "u": "https://preview.redd.it/u414cv9pr0ob1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=aad7b6f4a0ee92e60d53513589e3e2918f9467c5"}, {"y": 93, "x": 216, "u": "https://preview.redd.it/u414cv9pr0ob1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=48582d554781d4421c97d18359afa95a5d9467c5"}, {"y": 138, "x": 320, "u": "https://preview.redd.it/u414cv9pr0ob1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9e58d7f1a13e46fb2830a22fe0581779cefa0bbd"}, {"y": 277, "x": 640, "u": "https://preview.redd.it/u414cv9pr0ob1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f597040652b7cdbe8e1e461a7a1a99d2399344c9"}, {"y": 416, "x": 960, "u": "https://preview.redd.it/u414cv9pr0ob1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2fe524ed95dd878197548aaf4bdafed89adb9b50"}, {"y": 468, "x": 1080, "u": "https://preview.redd.it/u414cv9pr0ob1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ca4bb7e7c16043d1b3417aba60e90dc2a734b9a8"}], "s": {"y": 653, "x": 1505, "u": "https://preview.redd.it/u414cv9pr0ob1.png?width=1505&amp;format=png&amp;auto=webp&amp;s=6c2fcb893d374b23cc41546417a1ba8b3a71ddad"}, "id": "u414cv9pr0ob1"}}, "name": "t3_16hjoc6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6yNDHhukBxPTebG3Gr50l4nN9dR28VzyHUVaJ9Gbd2g.jpg", "edited": 1694609372.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694601755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am using ADF for an ETL job and I use one generic pipelines per database type (PostgreSQL, DB2, SqlServer). The data is copied from tables in respective database and saved in a data lake (which I call bronze). In a table called MetaBronze I have specified servernames, connectionsstrings and what tables to be copied as well as in which container and under what filepath in the data lake the copy should be stored. I also mark which date this was done so I can reload by updating the date to an earlier one.&lt;/p&gt;\n\n&lt;p&gt;It is a bit like the following approach: &lt;a href=\"https://techcommunity.microsoft.com/t5/fasttrack-for-azure/metadata-driven-pipelines-for-microsoft-fabric/ba-p/3891651\"&gt;https://techcommunity.microsoft.com/t5/fasttrack-for-azure/metadata-driven-pipelines-for-microsoft-fabric/ba-p/3891651&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So far so good since I have a one-to-one relationship between source and destination. However, between my bronze layer and silver layer there is a many-to-many relationship. A specific table (table here is a parquet file copied from the source) from bronze can go to many different tables in the silver layer and multiple tables from bronze can go to one table in the silver layer.&lt;/p&gt;\n\n&lt;p&gt;How should I design this?&lt;/p&gt;\n\n&lt;p&gt;Between bronze and silver we need to keep track of the max date of the files that we used to build the tables in silver since some of the tables are updated incrementally.&lt;/p&gt;\n\n&lt;p&gt;Lastly between Silver and Gold there is a many-to-one relationship.&lt;/p&gt;\n\n&lt;p&gt;Currently I plan on making one table for each step: MetaBronze, MetaSilver, MetaGold and then an Mapping table that maps Id&amp;#39;s between the steps. However I am not sure this is a good Idea.&lt;/p&gt;\n\n&lt;p&gt;Thanks In advance! Any tip on reading material would be much appreciated as well as suggestions on how this should be designed.&lt;/p&gt;\n\n&lt;p&gt;Edit:&lt;/p&gt;\n\n&lt;p&gt;Following is a rough draft on how I imagine the design should be (obviously there will be much more columns in each table, but in this draft I wanted to address the many-to-many issue). Hope this sketch makes it easier to understand what I want to achieve.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/u414cv9pr0ob1.png?width=1505&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6c2fcb893d374b23cc41546417a1ba8b3a71ddad\"&gt;https://preview.redd.it/u414cv9pr0ob1.png?width=1505&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6c2fcb893d374b23cc41546417a1ba8b3a71ddad&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16hjoc6", "is_robot_indexable": true, "report_reasons": null, "author": "Ygolopot272", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16hjoc6/how_to_design_a_metadata_table_or_tables_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16hjoc6/how_to_design_a_metadata_table_or_tables_to/", "subreddit_subscribers": 128207, "created_utc": 1694601755.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}