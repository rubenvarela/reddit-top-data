{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was top of my class in college at a state university, one of the very few people who is not only extremely passionate about data and technology, but actually follows through with it myself studying outside of school, cross training, working on projects to try and explore technology, seeing what tech stack companies are using, studying it on my free time. I've built my way up in my career from intern to project Management office, to business analyst, senior data analyst/data engineer. But it's like it's not good enough. Every company wants staff data engineer that comes from FAANG and has at least 7 years of experience, with a computer science background, at least seven different technology stacks, including SSRS, Hadoop, you name it they want it....\n\nLike, I thought we were trying to establish that experience is not the most important thing as a data engineer, passion and ability to learn and grasp what you're doing and perform was? In terms of talent I wouldn't say that I'm one of the best Like obviously not because I don't have formal experience working as an engineer, I have a muddled role like many other people do where I did a lot of data engineering and pipeline building, tons of SQL and Python.... \n\n\nBut these employers want someone who is a veteran. They want someone who has at least 7 years of experience, has seen everything there is to see, can do the job of three different people. It's insane. The requirements are absurd. It's like they don't want someone who's competent and able to do the job, they want someone who is good on paper and checks all the boxes, and that's it", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It feels impossible to get into data engineering no matter how good you are", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a6xhs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693868158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was top of my class in college at a state university, one of the very few people who is not only extremely passionate about data and technology, but actually follows through with it myself studying outside of school, cross training, working on projects to try and explore technology, seeing what tech stack companies are using, studying it on my free time. I&amp;#39;ve built my way up in my career from intern to project Management office, to business analyst, senior data analyst/data engineer. But it&amp;#39;s like it&amp;#39;s not good enough. Every company wants staff data engineer that comes from FAANG and has at least 7 years of experience, with a computer science background, at least seven different technology stacks, including SSRS, Hadoop, you name it they want it....&lt;/p&gt;\n\n&lt;p&gt;Like, I thought we were trying to establish that experience is not the most important thing as a data engineer, passion and ability to learn and grasp what you&amp;#39;re doing and perform was? In terms of talent I wouldn&amp;#39;t say that I&amp;#39;m one of the best Like obviously not because I don&amp;#39;t have formal experience working as an engineer, I have a muddled role like many other people do where I did a lot of data engineering and pipeline building, tons of SQL and Python.... &lt;/p&gt;\n\n&lt;p&gt;But these employers want someone who is a veteran. They want someone who has at least 7 years of experience, has seen everything there is to see, can do the job of three different people. It&amp;#39;s insane. The requirements are absurd. It&amp;#39;s like they don&amp;#39;t want someone who&amp;#39;s competent and able to do the job, they want someone who is good on paper and checks all the boxes, and that&amp;#39;s it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16a6xhs", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16a6xhs/it_feels_impossible_to_get_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16a6xhs/it_feels_impossible_to_get_into_data_engineering/", "subreddit_subscribers": 126932, "created_utc": 1693868158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Assume a very large (10k+) number of on premise single tenant databases spread across an arbitrary number of servers. Much of this data needs to be replicated/consolidated to a downstream data lake as quickly as possible (ideally at least twice daily).\n\nThere are obviously a number of challenges for any solution: Concurrent/overall connection limits, memory allocations, resource/object locking, intermediate storage/compute/parallel processing, etc. And that is just at the ingest, but that's the foundational problem that needs to be solved first.\n\nNow, my first instict is a migration to a multi-tenant, hybrid cloud/on-prem solution. This would co mingle data sources with lakehouse ingestion processes (AWS ecosystem) and allow easier scaling of the ingestion layer.\n\nIt is unlikely that this will be accomplished in a timely manner and will require the incentivization and coordation of many business and technical stakeholders, some of which may never be convinced/migrated. \n\nI'm trying to wrap my head around how this would be possible at scale without hitting either concurrent connection issues, untenable memory/processing requirements (on prem servers, no autoscaling), and/or deadlock issues. Current alternatives:\n\n\u2022Perform CDC via database logs (Debezium) stream to Kafka and sync to S3 (parquet files). Amazon EMR to run spark jobs to archive, merge and compress in paralell. We will assume the merged data across database instances will conform to the same schema. \n\n\u2022Each database instance performs intermediate data staging/processing for traditional ETL/ELT workloads to consume and deliver to S3.\n\n\u2022Perform some sort of on prem to cloud DB replication where it will be easier to scale data ingestion.\n\nEven assuming complete migration to a multi-tenant cloud hosted solution, there will be significant challenges scaling data ingestion to thousands of sources with petabytes of throughput and storage.\n\nCurrent plan is to layer Iceberg on top of S3 once we can land the data performantly in the lake. Hoping to avoid raw data replication to DW/ML solution, but not sure of Iceberg's performance at this scale.\n\nAny thoughts, critiques, and advice appreciated!\n\nEDIT-\nBusiness reqs:\n\u2022Source data resides in on prem MSSQL Servers. The number of servers and databases per server are  configurable to balance cost and performance (currently ~1k  DBs per server)\n\n\u2022Source tables are 20 - 30 in number, 250 - 500 GB in size per  tenant (10k+ tenants). Schemas are the same across DBs.\n\n\u2022Volume of changes is currently unknown, but could be up to 10 million rows and 10 TB of throughput per semi daily run (say every 4 hours). These are general starting requirements that will scale up. \n\n\u2022Pipelines for this data currently exist via Fivetran and take 24 hours. So, generally I'm looking to see how parallel CDC or ELT (Debeizun, Spark) could be utilized to speed up the process.\n\n\u2022Data will land in an S3 data lake to be accessed by Snowflake as the main analytics engine, and other services for AI/ML work.", "author_fullname": "t2_52sv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting from a very large amount of SQL databases.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a2c6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693887502.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693857758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Assume a very large (10k+) number of on premise single tenant databases spread across an arbitrary number of servers. Much of this data needs to be replicated/consolidated to a downstream data lake as quickly as possible (ideally at least twice daily).&lt;/p&gt;\n\n&lt;p&gt;There are obviously a number of challenges for any solution: Concurrent/overall connection limits, memory allocations, resource/object locking, intermediate storage/compute/parallel processing, etc. And that is just at the ingest, but that&amp;#39;s the foundational problem that needs to be solved first.&lt;/p&gt;\n\n&lt;p&gt;Now, my first instict is a migration to a multi-tenant, hybrid cloud/on-prem solution. This would co mingle data sources with lakehouse ingestion processes (AWS ecosystem) and allow easier scaling of the ingestion layer.&lt;/p&gt;\n\n&lt;p&gt;It is unlikely that this will be accomplished in a timely manner and will require the incentivization and coordation of many business and technical stakeholders, some of which may never be convinced/migrated. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to wrap my head around how this would be possible at scale without hitting either concurrent connection issues, untenable memory/processing requirements (on prem servers, no autoscaling), and/or deadlock issues. Current alternatives:&lt;/p&gt;\n\n&lt;p&gt;\u2022Perform CDC via database logs (Debezium) stream to Kafka and sync to S3 (parquet files). Amazon EMR to run spark jobs to archive, merge and compress in paralell. We will assume the merged data across database instances will conform to the same schema. &lt;/p&gt;\n\n&lt;p&gt;\u2022Each database instance performs intermediate data staging/processing for traditional ETL/ELT workloads to consume and deliver to S3.&lt;/p&gt;\n\n&lt;p&gt;\u2022Perform some sort of on prem to cloud DB replication where it will be easier to scale data ingestion.&lt;/p&gt;\n\n&lt;p&gt;Even assuming complete migration to a multi-tenant cloud hosted solution, there will be significant challenges scaling data ingestion to thousands of sources with petabytes of throughput and storage.&lt;/p&gt;\n\n&lt;p&gt;Current plan is to layer Iceberg on top of S3 once we can land the data performantly in the lake. Hoping to avoid raw data replication to DW/ML solution, but not sure of Iceberg&amp;#39;s performance at this scale.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts, critiques, and advice appreciated!&lt;/p&gt;\n\n&lt;p&gt;EDIT-\nBusiness reqs:\n\u2022Source data resides in on prem MSSQL Servers. The number of servers and databases per server are  configurable to balance cost and performance (currently ~1k  DBs per server)&lt;/p&gt;\n\n&lt;p&gt;\u2022Source tables are 20 - 30 in number, 250 - 500 GB in size per  tenant (10k+ tenants). Schemas are the same across DBs.&lt;/p&gt;\n\n&lt;p&gt;\u2022Volume of changes is currently unknown, but could be up to 10 million rows and 10 TB of throughput per semi daily run (say every 4 hours). These are general starting requirements that will scale up. &lt;/p&gt;\n\n&lt;p&gt;\u2022Pipelines for this data currently exist via Fivetran and take 24 hours. So, generally I&amp;#39;m looking to see how parallel CDC or ELT (Debeizun, Spark) could be utilized to speed up the process.&lt;/p&gt;\n\n&lt;p&gt;\u2022Data will land in an S3 data lake to be accessed by Snowflake as the main analytics engine, and other services for AI/ML work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16a2c6q", "is_robot_indexable": true, "report_reasons": null, "author": "Peppper", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16a2c6q/extracting_from_a_very_large_amount_of_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16a2c6q/extracting_from_a_very_large_amount_of_sql/", "subreddit_subscribers": 126932, "created_utc": 1693857758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y'all.  \nHope its been a great do so far to you all.\n\nIm currently preparing to switch from my current organization. And honestly, it hasn't been easy as Im getting little to no calls. I've finally switched from directly applying to only referrals.  \n\n\nI'm trying to find resources to practice the python coding interview questions, which are specific to a DE role but haven't come up with something that's very specific to our role. What is your goto website/resource to practice DE interview related python coding questions?  \n\n\nAny input is appreciated :)  \n", "author_fullname": "t2_462d4yf3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview preparation help needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ak4xw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693908465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all.&lt;br/&gt;\nHope its been a great do so far to you all.&lt;/p&gt;\n\n&lt;p&gt;Im currently preparing to switch from my current organization. And honestly, it hasn&amp;#39;t been easy as Im getting little to no calls. I&amp;#39;ve finally switched from directly applying to only referrals.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to find resources to practice the python coding interview questions, which are specific to a DE role but haven&amp;#39;t come up with something that&amp;#39;s very specific to our role. What is your goto website/resource to practice DE interview related python coding questions?  &lt;/p&gt;\n\n&lt;p&gt;Any input is appreciated :)  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16ak4xw", "is_robot_indexable": true, "report_reasons": null, "author": "RobotsMakingDubstep", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ak4xw/interview_preparation_help_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ak4xw/interview_preparation_help_needed/", "subreddit_subscribers": 126932, "created_utc": 1693908465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi people,\nFirst time posting on Reddit. I finished school a year ago and I\u2019m currently in a very good company that I really like as a junior DE. \nBut I wonder how is DE in other company near me? How is job market, can you find a big company that have cool DE technology and goals? How much can DE claim as salary ?", "author_fullname": "t2_9vvs3d7wq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is job market in Western Europe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a1nkj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693856202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi people,\nFirst time posting on Reddit. I finished school a year ago and I\u2019m currently in a very good company that I really like as a junior DE. \nBut I wonder how is DE in other company near me? How is job market, can you find a big company that have cool DE technology and goals? How much can DE claim as salary ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16a1nkj", "is_robot_indexable": true, "report_reasons": null, "author": "skoleboy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16a1nkj/how_is_job_market_in_western_europe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16a1nkj/how_is_job_market_in_western_europe/", "subreddit_subscribers": 126932, "created_utc": 1693856202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Its been a year since I started as DE. And recently got back from holidays and I feel so down and unproductive. I cant finish tasks and feeling so much incapable to learn or solve problems. Currently have to build some dimensions data model and nothing makes sense. \n\nWhat do you normally do during these times?", "author_fullname": "t2_56g5f4cg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling negative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16anp4o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693919022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Its been a year since I started as DE. And recently got back from holidays and I feel so down and unproductive. I cant finish tasks and feeling so much incapable to learn or solve problems. Currently have to build some dimensions data model and nothing makes sense. &lt;/p&gt;\n\n&lt;p&gt;What do you normally do during these times?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16anp4o", "is_robot_indexable": true, "report_reasons": null, "author": "9gg6", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16anp4o/feeling_negative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16anp4o/feeling_negative/", "subreddit_subscribers": 126932, "created_utc": 1693919022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At school or on leetcode you get a transformation described, you implement it and then you check the answer with the teacher.\n\nNow an engineer needs to create a table that represents something (avg daily likes etc). How do you test that this transformation is what you think it is?", "author_fullname": "t2_vm5kbtxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you validate your Transformations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ankv8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693918734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At school or on leetcode you get a transformation described, you implement it and then you check the answer with the teacher.&lt;/p&gt;\n\n&lt;p&gt;Now an engineer needs to create a table that represents something (avg daily likes etc). How do you test that this transformation is what you think it is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ankv8", "is_robot_indexable": true, "report_reasons": null, "author": "srevolve", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ankv8/how_do_you_validate_your_transformations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ankv8/how_do_you_validate_your_transformations/", "subreddit_subscribers": 126932, "created_utc": 1693918734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I can write python scripts to mainly automate some stuff. But when learning Pandas and Polars, I get really confused.   \nI am learning from Daniel Chen Pycon. Also learning Polars from Matt Harrison from PyCon.  \n\n\nBut I find it really difficult to grasp.  \nHow do I learn ? And how much time it takes to be able to write code on Pandas independently ?", "author_fullname": "t2_3k9gevl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much time to learn Pandas ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ahy02", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693900727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can write python scripts to mainly automate some stuff. But when learning Pandas and Polars, I get really confused.&lt;br/&gt;\nI am learning from Daniel Chen Pycon. Also learning Polars from Matt Harrison from PyCon.  &lt;/p&gt;\n\n&lt;p&gt;But I find it really difficult to grasp.&lt;br/&gt;\nHow do I learn ? And how much time it takes to be able to write code on Pandas independently ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ahy02", "is_robot_indexable": true, "report_reasons": null, "author": "Pillstyr", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ahy02/how_much_time_to_learn_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ahy02/how_much_time_to_learn_pandas/", "subreddit_subscribers": 126932, "created_utc": 1693900727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "my intention\n\nuse postgres to do inserts on data\n\nuse a different database for analytics based on what is constantly being inserted updated in postgres\n\nthe other db is for offloading reading of data and for the purpose of making it real-time or a fake real-time\n\nthe main database is only for insert and update i can't make use of materialize view inside the master database\n\n&amp;#x200B;", "author_fullname": "t2_9zltgu7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "i was wondering is there a way to replicate a postgres database to another different database for analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16aenrm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693889605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;my intention&lt;/p&gt;\n\n&lt;p&gt;use postgres to do inserts on data&lt;/p&gt;\n\n&lt;p&gt;use a different database for analytics based on what is constantly being inserted updated in postgres&lt;/p&gt;\n\n&lt;p&gt;the other db is for offloading reading of data and for the purpose of making it real-time or a fake real-time&lt;/p&gt;\n\n&lt;p&gt;the main database is only for insert and update i can&amp;#39;t make use of materialize view inside the master database&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16aenrm", "is_robot_indexable": true, "report_reasons": null, "author": "Exact-Yesterday-992", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16aenrm/i_was_wondering_is_there_a_way_to_replicate_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16aenrm/i_was_wondering_is_there_a_way_to_replicate_a/", "subreddit_subscribers": 126932, "created_utc": 1693889605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you are looking for an open role and are refining your LinkedIn, don's miss out on the \"Skills associated with the job post\" feature on LinkedIn job postings. It can be a great resource to tweak your profile, or identify new skills to build!  \n\n\n[https://medium.com/@seancoyne/linkedin-profile-tips-for-data-engineers-part-2-886467ba4b2d](https://medium.com/@seancoyne/linkedin-profile-tips-for-data-engineers-part-2-886467ba4b2d)", "author_fullname": "t2_4fpl974m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Best Way to Optimize Keywords on your LinkedIn Profile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a5pyb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693865339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you are looking for an open role and are refining your LinkedIn, don&amp;#39;s miss out on the &amp;quot;Skills associated with the job post&amp;quot; feature on LinkedIn job postings. It can be a great resource to tweak your profile, or identify new skills to build!  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@seancoyne/linkedin-profile-tips-for-data-engineers-part-2-886467ba4b2d\"&gt;https://medium.com/@seancoyne/linkedin-profile-tips-for-data-engineers-part-2-886467ba4b2d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zNSolW3ozTfnWyFMRpcJh-03jMpBhTEWZvjS7kPkhCM.jpg?auto=webp&amp;s=dcaafaa341389ef311bf44620f508e25d7e5f064", "width": 500, "height": 334}, "resolutions": [{"url": "https://external-preview.redd.it/zNSolW3ozTfnWyFMRpcJh-03jMpBhTEWZvjS7kPkhCM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6d3c64e4ac5ee8ca9e15582a296490bb32e3f973", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/zNSolW3ozTfnWyFMRpcJh-03jMpBhTEWZvjS7kPkhCM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c0bb2f493d91d05a94916b1a6fcad03402c0dace", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/zNSolW3ozTfnWyFMRpcJh-03jMpBhTEWZvjS7kPkhCM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c95bf0c1e5a432f7363dfa559ff1f94e0e76a2e1", "width": 320, "height": 213}], "variants": {}, "id": "lo_qxDVhJFoT7yOLN4cIFUub3FzD_UXyqb9WzBJpiII"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16a5pyb", "is_robot_indexable": true, "report_reasons": null, "author": "coyne_operated", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16a5pyb/the_best_way_to_optimize_keywords_on_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16a5pyb/the_best_way_to_optimize_keywords_on_your/", "subreddit_subscribers": 126932, "created_utc": 1693865339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have a spark ordering job that takes roughtly 24h to order a handfull of very large tables, that are ordered within partitions of anywhere between 1 and billions of elements, and I am planning to make the process continuous based on newly entering data rather than all-at-once.\n\nThe tables are written to scylla, and the last member of the clustering key is the index of the data in the subset.   \nIf I want to make that continuous, using Apache Flint instead of Spark most probably, inserting one row in one of the very large table partition will trigger a write for millions of rows below to update their index, which I want to avoid.  \nI am wondering, is there any big data oriented database (Apache Iceberg?) that makes it possible to still request rows by their index, but won't trigger millions of rewrite if I insert some rows in the middle of the large partitions ?\n\nI can definitely imagine some algorithm that can do that by either using bins or approximate ordering, and at the cost of a little computing at request time or precision, could save me some precious I/O.\n\nAny idea or suggestion for such a service ?\n\nThank you", "author_fullname": "t2_9t5s9vas", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keep Huge Tables sorted and accesible by indices.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169zi0d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693851512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have a spark ordering job that takes roughtly 24h to order a handfull of very large tables, that are ordered within partitions of anywhere between 1 and billions of elements, and I am planning to make the process continuous based on newly entering data rather than all-at-once.&lt;/p&gt;\n\n&lt;p&gt;The tables are written to scylla, and the last member of the clustering key is the index of the data in the subset.&lt;br/&gt;\nIf I want to make that continuous, using Apache Flint instead of Spark most probably, inserting one row in one of the very large table partition will trigger a write for millions of rows below to update their index, which I want to avoid.&lt;br/&gt;\nI am wondering, is there any big data oriented database (Apache Iceberg?) that makes it possible to still request rows by their index, but won&amp;#39;t trigger millions of rewrite if I insert some rows in the middle of the large partitions ?&lt;/p&gt;\n\n&lt;p&gt;I can definitely imagine some algorithm that can do that by either using bins or approximate ordering, and at the cost of a little computing at request time or precision, could save me some precious I/O.&lt;/p&gt;\n\n&lt;p&gt;Any idea or suggestion for such a service ?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169zi0d", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious_Buy_8198", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169zi0d/keep_huge_tables_sorted_and_accesible_by_indices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169zi0d/keep_huge_tables_sorted_and_accesible_by_indices/", "subreddit_subscribers": 126932, "created_utc": 1693851512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wondering if it's something I should prioritize keeping track of", "author_fullname": "t2_u7cx7908", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is it to record the contribution of each data labeler?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ao3ep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693920032.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wondering if it&amp;#39;s something I should prioritize keeping track of&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ao3ep", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Equivalent_1689", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ao3ep/how_important_is_it_to_record_the_contribution_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ao3ep/how_important_is_it_to_record_the_contribution_of/", "subreddit_subscribers": 126932, "created_utc": 1693920032.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Want to learn how to fine-tune your Donut transformer model to read text from images? Check out [this article on fine-tuning the Donut model with your own data.](https://medium.com/python-in-plain-english/empower-your-donut-model-for-receipts-with-self-annotated-data-51fc882b7229)", "author_fullname": "t2_9ssuhjvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn how to fine-tune your Donut transformer model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16agv6h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693896901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to learn how to fine-tune your Donut transformer model to read text from images? Check out &lt;a href=\"https://medium.com/python-in-plain-english/empower-your-donut-model-for-receipts-with-self-annotated-data-51fc882b7229\"&gt;this article on fine-tuning the Donut model with your own data.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZLuOVaB68GMr7MnVodshEc97P8x28z1gme0-Sm77Ymk.jpg?auto=webp&amp;s=564b07956bc7c50dfe238bad3ac9d8b7fa3d3652", "width": 611, "height": 495}, "resolutions": [{"url": "https://external-preview.redd.it/ZLuOVaB68GMr7MnVodshEc97P8x28z1gme0-Sm77Ymk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9a798cee1c661714f2cd168b5d1d4624b5070ad1", "width": 108, "height": 87}, {"url": "https://external-preview.redd.it/ZLuOVaB68GMr7MnVodshEc97P8x28z1gme0-Sm77Ymk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f97a7abd0955fa140562040e3ce8a5e29c43b960", "width": 216, "height": 174}, {"url": "https://external-preview.redd.it/ZLuOVaB68GMr7MnVodshEc97P8x28z1gme0-Sm77Ymk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ecc529113b5712ccb2d72e3a9e06fe4725397e4", "width": 320, "height": 259}], "variants": {}, "id": "X5GKy4DRjKrwntxD7EMrGJJZw6M6-kYZkTRYOAbcmPw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "16agv6h", "is_robot_indexable": true, "report_reasons": null, "author": "Artistic_Highlight_1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16agv6h/learn_how_to_finetune_your_donut_transformer_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16agv6h/learn_how_to_finetune_your_donut_transformer_model/", "subreddit_subscribers": 126932, "created_utc": 1693896901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello my friends, i recently landed a data engineering role and my team uses technologies like Hadoop, spark, scala,SQL,HIVE . I have taken a basic understanding of these technologies but now I want to implement these stuff by making a small project. As currently I am not getting any work in the team because the team is currently busy on some production so freshers are not in focus right now. So can you please suggest in what order do I need to learn these technologies and any small project or any learning resource. Would be very helpful \nThanks in advance", "author_fullname": "t2_hhggz14jx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to learn first?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16agjq3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693895814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello my friends, i recently landed a data engineering role and my team uses technologies like Hadoop, spark, scala,SQL,HIVE . I have taken a basic understanding of these technologies but now I want to implement these stuff by making a small project. As currently I am not getting any work in the team because the team is currently busy on some production so freshers are not in focus right now. So can you please suggest in what order do I need to learn these technologies and any small project or any learning resource. Would be very helpful \nThanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16agjq3", "is_robot_indexable": true, "report_reasons": null, "author": "Wrong-Supermarket206", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16agjq3/what_to_learn_first/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16agjq3/what_to_learn_first/", "subreddit_subscribers": 126932, "created_utc": 1693895814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi DEs, \nI'm eager to hear about the complex DE projects you've been involved with. What impact did they have? How did you adapt and align yourself with these projects? And what valuable insights did you gain from them?", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are few complex DE projects you worked on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ag2q2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693894184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi DEs, \nI&amp;#39;m eager to hear about the complex DE projects you&amp;#39;ve been involved with. What impact did they have? How did you adapt and align yourself with these projects? And what valuable insights did you gain from them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ag2q2", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16ag2q2/what_are_few_complex_de_projects_you_worked_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ag2q2/what_are_few_complex_de_projects_you_worked_on/", "subreddit_subscribers": 126932, "created_utc": 1693894184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey looking to refresh my feed with new content, would love for recommendations on accounts worth following :)", "author_fullname": "t2_bqjrmnud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data influencers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16am166", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693914460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey looking to refresh my feed with new content, would love for recommendations on accounts worth following :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16am166", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Bug105", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16am166/data_influencers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16am166/data_influencers/", "subreddit_subscribers": 126932, "created_utc": 1693914460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I\u2019m a Senior DE in my current company and stuck in my job. I am looking to switch to a different company but the Interview process makes me nervous. Can someone help me with tried and tested tips to achieve success? I am good with the job but the interview process sucks for me.", "author_fullname": "t2_jeu7c5mu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering interview preparation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ahozt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693899792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019m a Senior DE in my current company and stuck in my job. I am looking to switch to a different company but the Interview process makes me nervous. Can someone help me with tried and tested tips to achieve success? I am good with the job but the interview process sucks for me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16ahozt", "is_robot_indexable": true, "report_reasons": null, "author": "Distinct_Ball5932", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ahozt/data_engineering_interview_preparation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ahozt/data_engineering_interview_preparation/", "subreddit_subscribers": 126932, "created_utc": 1693899792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI would like some feedback on my teams role and see how much of it is DE. I currently work at a university affiliated research organization as sort of a senior data analyst. On our team, our main job is to intake raw data, standardize them for modelers to use. I had thought what my team does is very closely related to data engineering but we rely 85% on Python and 15% SQL Database. We also create ad-hoc Tableau visuals and maintain R Shiny interactive dashboards. \n\nThere are other teams that maintain our in house compute cluster, our file systems (3rd party), and also database management. They give us the tools and infrastructure to do our work. All we really have to do is focus on writing solid python code and leverage the computing cluster to clean all the raw datasets and send them through our pipeline to ensure they are consistent and comparable. Then we upload them all to a SQL database. Other teams maintain python functions/machinery that interact with the database for modelers to pull the data without SQL queries.\n\nOur raw data mostly comes as .csv and .dta files. We do a good job of maintaining replicability and consistency by git tracking our codebase and version tracking our pipeline inputs and dataset metadata with our own database. We are able to find root causes if our final outputs have issues and apply a fix fairly quickly. We understand how to structure and run our code so we do not overload the database and filesystems and improve overall efficiency. Although with our computation cluster, we can apply distributed computing fairly easily.\n\nOverall, I think my team has a good system in place to process all this data but just a little outdated. It also feels like some important aspects of DE are outsourced to other teams. Someone on our team recently is exploring PySpark to help with processing, someone else had implemented Dask. Its a little hard for me to explain all what my teams does in detail but what do you guys think?\n\nThanks in advance!", "author_fullname": "t2_9nvslz1w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on my teams role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a895o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693871940.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693871436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I would like some feedback on my teams role and see how much of it is DE. I currently work at a university affiliated research organization as sort of a senior data analyst. On our team, our main job is to intake raw data, standardize them for modelers to use. I had thought what my team does is very closely related to data engineering but we rely 85% on Python and 15% SQL Database. We also create ad-hoc Tableau visuals and maintain R Shiny interactive dashboards. &lt;/p&gt;\n\n&lt;p&gt;There are other teams that maintain our in house compute cluster, our file systems (3rd party), and also database management. They give us the tools and infrastructure to do our work. All we really have to do is focus on writing solid python code and leverage the computing cluster to clean all the raw datasets and send them through our pipeline to ensure they are consistent and comparable. Then we upload them all to a SQL database. Other teams maintain python functions/machinery that interact with the database for modelers to pull the data without SQL queries.&lt;/p&gt;\n\n&lt;p&gt;Our raw data mostly comes as .csv and .dta files. We do a good job of maintaining replicability and consistency by git tracking our codebase and version tracking our pipeline inputs and dataset metadata with our own database. We are able to find root causes if our final outputs have issues and apply a fix fairly quickly. We understand how to structure and run our code so we do not overload the database and filesystems and improve overall efficiency. Although with our computation cluster, we can apply distributed computing fairly easily.&lt;/p&gt;\n\n&lt;p&gt;Overall, I think my team has a good system in place to process all this data but just a little outdated. It also feels like some important aspects of DE are outsourced to other teams. Someone on our team recently is exploring PySpark to help with processing, someone else had implemented Dask. Its a little hard for me to explain all what my teams does in detail but what do you guys think?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16a895o", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Chemical4044", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16a895o/feedback_on_my_teams_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16a895o/feedback_on_my_teams_role/", "subreddit_subscribers": 126932, "created_utc": 1693871436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Until the middle of April this year, I used the SNScraper library to get tweets and replies for each tweet. But recently this library does not work. I use replies for sentiment analysis. \n\nCan you recommend a library in Python and R that is maintained and that enables the output of the reply? ,", "author_fullname": "t2_a7z87sfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitter library for scraping tweets and replies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169zoj3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693851917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Until the middle of April this year, I used the SNScraper library to get tweets and replies for each tweet. But recently this library does not work. I use replies for sentiment analysis. &lt;/p&gt;\n\n&lt;p&gt;Can you recommend a library in Python and R that is maintained and that enables the output of the reply? ,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169zoj3", "is_robot_indexable": true, "report_reasons": null, "author": "gjinokastra", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169zoj3/twitter_library_for_scraping_tweets_and_replies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169zoj3/twitter_library_for_scraping_tweets_and_replies/", "subreddit_subscribers": 126932, "created_utc": 1693851917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have lots of complaints about pandas", "author_fullname": "t2_b5ogytlij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you wish pandas/spark had a more consistent functional interface that focuses on composability and a single virtual data structure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ansva", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693919289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have lots of complaints about pandas&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ansva", "is_robot_indexable": true, "report_reasons": null, "author": "Vegetable_Sir6061", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ansva/do_you_wish_pandasspark_had_a_more_consistent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ansva/do_you_wish_pandasspark_had_a_more_consistent/", "subreddit_subscribers": 126932, "created_utc": 1693919289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_8d5mczd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "17 Things I Wish I\u2019d Done Earlier as a Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16aml3o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/l-EE9amMwDImFMIIUIDeyHwRlnM9DnHjQfRzAitfxFU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693916056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/geekculture/17-things-i-wish-id-done-earlier-as-a-data-engineer-d1aa2e4f0694", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4fq03-5Bsh1vFa-DGL7R_ke5UMVQu9LD7HH9Dv3eRAg.jpg?auto=webp&amp;s=1c8b589a19d7a9f6402c1edc8150cec476cbf799", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/4fq03-5Bsh1vFa-DGL7R_ke5UMVQu9LD7HH9Dv3eRAg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=facdf55b60940a6cfc7ab55bf69b22da53da1f50", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/4fq03-5Bsh1vFa-DGL7R_ke5UMVQu9LD7HH9Dv3eRAg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=28cdc42a8773732784bf55f98ea879beac1ec2c3", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/4fq03-5Bsh1vFa-DGL7R_ke5UMVQu9LD7HH9Dv3eRAg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=377c8052eec571a34180b37050d3596c7dd4b9dd", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/4fq03-5Bsh1vFa-DGL7R_ke5UMVQu9LD7HH9Dv3eRAg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e46dd6ededec722dde6a1a3160e3820a407a38aa", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/4fq03-5Bsh1vFa-DGL7R_ke5UMVQu9LD7HH9Dv3eRAg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=67a1a923564a558fb0d517f5200fd3514bd0a2ad", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/4fq03-5Bsh1vFa-DGL7R_ke5UMVQu9LD7HH9Dv3eRAg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2027c04c0d966e8a585e004ef587873e2d8913fe", "width": 1080, "height": 607}], "variants": {}, "id": "S_Jr5KBbHnUH-gNHck0svL6ejGzdX77BEXmSkoe1t9w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16aml3o", "is_robot_indexable": true, "report_reasons": null, "author": "sbalnojan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16aml3o/17_things_i_wish_id_done_earlier_as_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/geekculture/17-things-i-wish-id-done-earlier-as-a-data-engineer-d1aa2e4f0694", "subreddit_subscribers": 126932, "created_utc": 1693916056.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}