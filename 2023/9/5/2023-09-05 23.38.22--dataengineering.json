{"kind": "Listing", "data": {"after": "t3_16a895o", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I can write python scripts to mainly automate some stuff. But when learning Pandas and Polars, I get really confused.   \nI am learning from Daniel Chen Pycon. Also learning Polars from Matt Harrison from PyCon.  \n\n\nBut I find it really difficult to grasp.  \nHow do I learn ? And how much time it takes to be able to write code on Pandas independently ?", "author_fullname": "t2_3k9gevl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much time to learn Pandas ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ahy02", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693900727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can write python scripts to mainly automate some stuff. But when learning Pandas and Polars, I get really confused.&lt;br/&gt;\nI am learning from Daniel Chen Pycon. Also learning Polars from Matt Harrison from PyCon.  &lt;/p&gt;\n\n&lt;p&gt;But I find it really difficult to grasp.&lt;br/&gt;\nHow do I learn ? And how much time it takes to be able to write code on Pandas independently ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ahy02", "is_robot_indexable": true, "report_reasons": null, "author": "Pillstyr", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ahy02/how_much_time_to_learn_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ahy02/how_much_time_to_learn_pandas/", "subreddit_subscribers": 126999, "created_utc": 1693900727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi r/dataengineering! I recently built this CLI that allows you to compile notebooks into FastAPI apps. \n\nIt allows you to write comments like \"\"\"@HTTP\"\"\", \"\"\"@WS\"\"\", or \"\"\"@SCHEDULE\"\"\" that expose your cells as http or websockets endpoints or programatically run cells at scheduled time intervals for simple data pipelines. \n\nIt creates a /build folder containing your dockerized code for easy deployment.\n\n[https://github.com/neutrino-ai/neutrino-notebooks](https://github.com/neutrino-ai/neutrino-notebooks)\n\nI hope you find this helpful! I would appreciate any feedback\n\n&amp;#x200B;", "author_fullname": "t2_ojl1de8y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A CLI that compiles Jupyter notebooks into FastAPI apps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16aqt9v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693926610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt;! I recently built this CLI that allows you to compile notebooks into FastAPI apps. &lt;/p&gt;\n\n&lt;p&gt;It allows you to write comments like &amp;quot;&amp;quot;&amp;quot;@HTTP&amp;quot;&amp;quot;&amp;quot;, &amp;quot;&amp;quot;&amp;quot;@WS&amp;quot;&amp;quot;&amp;quot;, or &amp;quot;&amp;quot;&amp;quot;@SCHEDULE&amp;quot;&amp;quot;&amp;quot; that expose your cells as http or websockets endpoints or programatically run cells at scheduled time intervals for simple data pipelines. &lt;/p&gt;\n\n&lt;p&gt;It creates a /build folder containing your dockerized code for easy deployment.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/neutrino-ai/neutrino-notebooks\"&gt;https://github.com/neutrino-ai/neutrino-notebooks&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I hope you find this helpful! I would appreciate any feedback&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?auto=webp&amp;s=5394e103b0086b4eff4d06568f294956507f0ecb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=43271c21e8a34542bc37693cfaf1dbacc436d23f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9701d58c16fd8ce19979b7db2dc7bdd8c459dd59", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=711a7236b9019520b595a3090b2f212b668efe75", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=03ab1ab20ef97b7eff2703ac8562037562678684", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97db8e91a7af642bc87a0d9454c87ad4c0286dac", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec562818e6bf8236d636bae3338627ea6dfd4584", "width": 1080, "height": 540}], "variants": {}, "id": "h0H4QH_NNA8eb-artCZYZeYRXgCLX9TCOO7CamwnaCk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16aqt9v", "is_robot_indexable": true, "report_reasons": null, "author": "elongated_muskrat_v1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16aqt9v/a_cli_that_compiles_jupyter_notebooks_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16aqt9v/a_cli_that_compiles_jupyter_notebooks_into/", "subreddit_subscribers": 126999, "created_utc": 1693926610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Its been a year since I started as DE. And recently got back from holidays and I feel so down and unproductive. I cant finish tasks and feeling so much incapable to learn or solve problems. Currently have to build some dimensions data model and nothing makes sense. \n\nWhat do you normally do during these times?", "author_fullname": "t2_56g5f4cg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling negative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16anp4o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693919022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Its been a year since I started as DE. And recently got back from holidays and I feel so down and unproductive. I cant finish tasks and feeling so much incapable to learn or solve problems. Currently have to build some dimensions data model and nothing makes sense. &lt;/p&gt;\n\n&lt;p&gt;What do you normally do during these times?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16anp4o", "is_robot_indexable": true, "report_reasons": null, "author": "9gg6", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16anp4o/feeling_negative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16anp4o/feeling_negative/", "subreddit_subscribers": 126999, "created_utc": 1693919022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey y'all.  \nHope its been a great do so far to you all.\n\nIm currently preparing to switch from my current organization. And honestly, it hasn't been easy as Im getting little to no calls. I've finally switched from directly applying to only referrals.  \n\n\nI'm trying to find resources to practice the python coding interview questions, which are specific to a DE role but haven't come up with something that's very specific to our role. What is your goto website/resource to practice DE interview related python coding questions?  \n\n\nAny input is appreciated :)  \n", "author_fullname": "t2_462d4yf3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview preparation help needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ak4xw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693908465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all.&lt;br/&gt;\nHope its been a great do so far to you all.&lt;/p&gt;\n\n&lt;p&gt;Im currently preparing to switch from my current organization. And honestly, it hasn&amp;#39;t been easy as Im getting little to no calls. I&amp;#39;ve finally switched from directly applying to only referrals.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to find resources to practice the python coding interview questions, which are specific to a DE role but haven&amp;#39;t come up with something that&amp;#39;s very specific to our role. What is your goto website/resource to practice DE interview related python coding questions?  &lt;/p&gt;\n\n&lt;p&gt;Any input is appreciated :)  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16ak4xw", "is_robot_indexable": true, "report_reasons": null, "author": "RobotsMakingDubstep", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ak4xw/interview_preparation_help_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ak4xw/interview_preparation_help_needed/", "subreddit_subscribers": 126999, "created_utc": 1693908465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "my intention\n\nuse postgres to do inserts on data\n\nuse a different database for analytics based on what is constantly being inserted updated in postgres\n\nthe other db is for offloading reading of data and for the purpose of making it real-time or a fake real-time\n\nthe main database is only for insert and update i can't make use of materialize view inside the master database\n\n&amp;#x200B;", "author_fullname": "t2_9zltgu7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "i was wondering is there a way to replicate a postgres database to another different database for analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16aenrm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693889605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;my intention&lt;/p&gt;\n\n&lt;p&gt;use postgres to do inserts on data&lt;/p&gt;\n\n&lt;p&gt;use a different database for analytics based on what is constantly being inserted updated in postgres&lt;/p&gt;\n\n&lt;p&gt;the other db is for offloading reading of data and for the purpose of making it real-time or a fake real-time&lt;/p&gt;\n\n&lt;p&gt;the main database is only for insert and update i can&amp;#39;t make use of materialize view inside the master database&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16aenrm", "is_robot_indexable": true, "report_reasons": null, "author": "Exact-Yesterday-992", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16aenrm/i_was_wondering_is_there_a_way_to_replicate_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16aenrm/i_was_wondering_is_there_a_way_to_replicate_a/", "subreddit_subscribers": 126999, "created_utc": 1693889605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At school or on leetcode you get a transformation described, you implement it and then you check the answer with the teacher.\n\nNow an engineer needs to create a table that represents something (avg daily likes etc). How do you test that this transformation is what you think it is?", "author_fullname": "t2_vm5kbtxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you validate your Transformations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ankv8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693918734.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At school or on leetcode you get a transformation described, you implement it and then you check the answer with the teacher.&lt;/p&gt;\n\n&lt;p&gt;Now an engineer needs to create a table that represents something (avg daily likes etc). How do you test that this transformation is what you think it is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ankv8", "is_robot_indexable": true, "report_reasons": null, "author": "srevolve", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ankv8/how_do_you_validate_your_transformations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ankv8/how_do_you_validate_your_transformations/", "subreddit_subscribers": 126999, "created_utc": 1693918734.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a data analyst for just over 1 year now and have been working with DBT some python and lots of SQL. I changed careers from working in education for 3 years and definitely have imposter syndrome. \n\nAnytime I'm rushing because I feel pressured or am trying to meet a deadline or even just figure out what I'm doing with the ask from my superior I end up getting flustered and make small mistakes and there's times when it can snowball on me.\n\n I'm really trying to improve my quality of work (that was the area I was told to improve upon from my last performance review) and anytime I feel like I make progress there's another mistake, I get flustered with that feedback in the back of my mind and it snowballs.\n\n I get that learning by failure or failing forward is part of the job, but I'm having a rough two weeks rn. Anyone experience something similar, what advice do you have or am I just a lost cause?", "author_fullname": "t2_71weyfry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I keep making mistakes and feel like I'll never make it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16azftj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693946369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a data analyst for just over 1 year now and have been working with DBT some python and lots of SQL. I changed careers from working in education for 3 years and definitely have imposter syndrome. &lt;/p&gt;\n\n&lt;p&gt;Anytime I&amp;#39;m rushing because I feel pressured or am trying to meet a deadline or even just figure out what I&amp;#39;m doing with the ask from my superior I end up getting flustered and make small mistakes and there&amp;#39;s times when it can snowball on me.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m really trying to improve my quality of work (that was the area I was told to improve upon from my last performance review) and anytime I feel like I make progress there&amp;#39;s another mistake, I get flustered with that feedback in the back of my mind and it snowballs.&lt;/p&gt;\n\n&lt;p&gt;I get that learning by failure or failing forward is part of the job, but I&amp;#39;m having a rough two weeks rn. Anyone experience something similar, what advice do you have or am I just a lost cause?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16azftj", "is_robot_indexable": true, "report_reasons": null, "author": "DrunkenWhaler136", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16azftj/i_keep_making_mistakes_and_feel_like_ill_never/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16azftj/i_keep_making_mistakes_and_feel_like_ill_never/", "subreddit_subscribers": 126999, "created_utc": 1693946369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a postgres table with ~500M records on 20 columns. The table is updated / created from a spark job which use a parquet and load it to postgres. Every day, I get a new parquet file with 500M, but among all records, only 5M are new, and 5M disappear. At the moment, I overwrite all the table, but this is really long. I guess this is a classic issue and there must be a workaround to only append new rows are delete existing rows. My table does not have any primary key nor id column, but 3 columns together can form a unique id. What should I do to update my table in a better way ? (notice that I cant write the parquet file to a temp table because it would be at least as long as overwriting the table).\n\nAt the moment, the only solutions that seems to work is to create an id column with the 3 columns concatenated, index this column and use it to compare new data and old data to perform the delete. What is the common way to do ?", "author_fullname": "t2_qexqkrk6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "400M rows table : how to insert 4M and delete 4M rapidly without overwriting full table ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ayrif", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693944870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a postgres table with ~500M records on 20 columns. The table is updated / created from a spark job which use a parquet and load it to postgres. Every day, I get a new parquet file with 500M, but among all records, only 5M are new, and 5M disappear. At the moment, I overwrite all the table, but this is really long. I guess this is a classic issue and there must be a workaround to only append new rows are delete existing rows. My table does not have any primary key nor id column, but 3 columns together can form a unique id. What should I do to update my table in a better way ? (notice that I cant write the parquet file to a temp table because it would be at least as long as overwriting the table).&lt;/p&gt;\n\n&lt;p&gt;At the moment, the only solutions that seems to work is to create an id column with the 3 columns concatenated, index this column and use it to compare new data and old data to perform the delete. What is the common way to do ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ayrif", "is_robot_indexable": true, "report_reasons": null, "author": "165817566995", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ayrif/400m_rows_table_how_to_insert_4m_and_delete_4m/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ayrif/400m_rows_table_how_to_insert_4m_and_delete_4m/", "subreddit_subscribers": 126999, "created_utc": 1693944870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, say you were an intermediate-level data engineer tasked with evaluating different cloud data warehouse platforms for a small company (integrating crm/ats/google analytics/finance data from 5-10 different sources to start), as well as a potential ETL tool/ job orchestrator if needed, and then building it out. Say you're also an okay python dev and a great sql dev. You'll also be building PowerBI reports on top off this dw and with all this development - you don't have a ton of time to wear the DBA hat. Say, you'll also be solo for probably 2 years or so before you start hiring a team around you.\n\nMy question is, if these are the rough parameters, what platform would you guys choose and why? / what would be the key things you would evaluate in said platforms?\n\nCurrently evaluating: Snowflake, Redshift, BQ, Azure, Databricks\n\nEdit: None of this data is being migrated from a pre-existing data warehouse and this is their first instance of a dw for analytics", "author_fullname": "t2_3ugqxzu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a cloud dw from scratch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ay9jh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693943757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, say you were an intermediate-level data engineer tasked with evaluating different cloud data warehouse platforms for a small company (integrating crm/ats/google analytics/finance data from 5-10 different sources to start), as well as a potential ETL tool/ job orchestrator if needed, and then building it out. Say you&amp;#39;re also an okay python dev and a great sql dev. You&amp;#39;ll also be building PowerBI reports on top off this dw and with all this development - you don&amp;#39;t have a ton of time to wear the DBA hat. Say, you&amp;#39;ll also be solo for probably 2 years or so before you start hiring a team around you.&lt;/p&gt;\n\n&lt;p&gt;My question is, if these are the rough parameters, what platform would you guys choose and why? / what would be the key things you would evaluate in said platforms?&lt;/p&gt;\n\n&lt;p&gt;Currently evaluating: Snowflake, Redshift, BQ, Azure, Databricks&lt;/p&gt;\n\n&lt;p&gt;Edit: None of this data is being migrated from a pre-existing data warehouse and this is their first instance of a dw for analytics&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ay9jh", "is_robot_indexable": true, "report_reasons": null, "author": "Casdom33", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ay9jh/building_a_cloud_dw_from_scratch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ay9jh/building_a_cloud_dw_from_scratch/", "subreddit_subscribers": 126999, "created_utc": 1693943757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nI just published my book, Cost-Effective Data Pipelines, with OReilly. I wanted to offer this community a free 30 day trial to check it out:\n\n[https://learning.oreilly.com/get-learning/?code=CEDP23](https://learning.oreilly.com/get-learning/?code=CEDP23)\n\nI wrote CEDP to give people access to a lot of hard earned, experiential advice I would have really appreciated not having to learn the hard way. \ud83d\ude05 I hope you find it helpful in your work!\n\nExamples for the coding portions of the book are available [on GitHub](https://github.com/gizm00/oreilly_dataeng_book)", "author_fullname": "t2_mi2w0ian", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New book - Cost-Effective Data Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16b2ajv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693952575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I just published my book, Cost-Effective Data Pipelines, with OReilly. I wanted to offer this community a free 30 day trial to check it out:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learning.oreilly.com/get-learning/?code=CEDP23\"&gt;https://learning.oreilly.com/get-learning/?code=CEDP23&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I wrote CEDP to give people access to a lot of hard earned, experiential advice I would have really appreciated not having to learn the hard way. \ud83d\ude05 I hope you find it helpful in your work!&lt;/p&gt;\n\n&lt;p&gt;Examples for the coding portions of the book are available &lt;a href=\"https://github.com/gizm00/oreilly_dataeng_book\"&gt;on GitHub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "16b2ajv", "is_robot_indexable": true, "report_reasons": null, "author": "spruc3tip", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b2ajv/new_book_costeffective_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16b2ajv/new_book_costeffective_data_pipelines/", "subreddit_subscribers": 126999, "created_utc": 1693952575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Passed with a 716 lol just had to tell someone. \n\nStudied for about 7 days 2-3 hours a day using the a cloud guru course (free since it was thru my job) \n\nWent thru the whole course and then ran the practice exams till I only got 90% or greater 3 times in a row. (Note: absolutely none of the questions from the practice exam were on the real test) \n\nI also built a project by following a YT tutorial end to end before even starting the course tes so that kind of solidified a lot of the concepts before hand.\n\nGood luck if you have it scheduled. LFG!", "author_fullname": "t2_22q9pua0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DP-900 PASSED!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16b1zri", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693951901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Passed with a 716 lol just had to tell someone. &lt;/p&gt;\n\n&lt;p&gt;Studied for about 7 days 2-3 hours a day using the a cloud guru course (free since it was thru my job) &lt;/p&gt;\n\n&lt;p&gt;Went thru the whole course and then ran the practice exams till I only got 90% or greater 3 times in a row. (Note: absolutely none of the questions from the practice exam were on the real test) &lt;/p&gt;\n\n&lt;p&gt;I also built a project by following a YT tutorial end to end before even starting the course tes so that kind of solidified a lot of the concepts before hand.&lt;/p&gt;\n\n&lt;p&gt;Good luck if you have it scheduled. LFG!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16b1zri", "is_robot_indexable": true, "report_reasons": null, "author": "PoloParachutes", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b1zri/dp900_passed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16b1zri/dp900_passed/", "subreddit_subscribers": 126999, "created_utc": 1693951901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys, need help in what to learn now;\n I have around 4+ years of experience and have worked with snowflake, sql, python,( ssis and ssms (not in depth)) but now I am not sure what should i learn, like what can i learn along with this tech stack.\n\nCould you please help me with some learning path/guide.", "author_fullname": "t2_7qs0ir3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to learn now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16axoov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693942459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys, need help in what to learn now;\n I have around 4+ years of experience and have worked with snowflake, sql, python,( ssis and ssms (not in depth)) but now I am not sure what should i learn, like what can i learn along with this tech stack.&lt;/p&gt;\n\n&lt;p&gt;Could you please help me with some learning path/guide.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16axoov", "is_robot_indexable": true, "report_reasons": null, "author": "Own_Archer3356", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16axoov/what_to_learn_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16axoov/what_to_learn_now/", "subreddit_subscribers": 126999, "created_utc": 1693942459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All, \n\nI'm about to embark on a mission to learning everything metadata from data dictionary to semantic mapping, etc.. I'm looking for literature, websites, etc. That offer knowledge on beginner level metadata. I found a book that seems to have great reviews: Metadata by Jeffrey Pomerantz. Anyone ever read this or recommends a different book?\n\nThanks!", "author_fullname": "t2_4175mn10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Metadata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16asy1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693931560.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m about to embark on a mission to learning everything metadata from data dictionary to semantic mapping, etc.. I&amp;#39;m looking for literature, websites, etc. That offer knowledge on beginner level metadata. I found a book that seems to have great reviews: Metadata by Jeffrey Pomerantz. Anyone ever read this or recommends a different book?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16asy1q", "is_robot_indexable": true, "report_reasons": null, "author": "Antoineleduke", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16asy1q/metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16asy1q/metadata/", "subreddit_subscribers": 126999, "created_utc": 1693931560.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey fellow Redditors,\n\nI\u2019ve got an offer on the table for a role centered around \u201cno-code\u201d data engineering, primarily using [Lobster Data](https://www.lobster-world.com/en/). I\u2019m in a bit of a quandary and could really use some insights.\n\nA bit about me:\n\n\t\u2022\tTU grad (Masters).\n\t\u2022\tOn the job hunt trail for about 6 months now.\n\t\u2022\tCompleted the IBM Data Engineering Professional Certification.\n\t\u2022\tHave undertaken 4 self-projects to gain hands-on experience with a variety of tools - think Spark, Kafka, and more.\n\n       \u2022\tWrapped up an internship and a thesis at a corporate firm as a Data analytics engr.\n\n\t\u2022\tMy background is mainly in data analytics and machine learning, and I\u2019ve always had a keen interest in the nuts and bolts of data engineering.\n\nHere\u2019s the crux: Is stepping into a role that heavily focuses on a no-code approach the right move? While I appreciate the push towards making things streamlined in the industry, I can\u2019t help but wonder if this could potentially narrow down my practical experience down the line.\n\nI\u2019d always pictured my first significant gig post-uni to be something where I\u2019m deep in the trenches, coding and designing architecture. But with half a year gone and this opportunity presenting itself, I\u2019m in two minds.\n\nWould love to get your thoughts. Is this a logical first step, or should I be patient and wait for a more traditional data engineering role?\n\nThanks in advance!", "author_fullname": "t2_51y0ecgg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should i take a \u201cno-code\u201d data engineering job using Lobster Data? Need advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16aph64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693923375.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors,&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got an offer on the table for a role centered around \u201cno-code\u201d data engineering, primarily using &lt;a href=\"https://www.lobster-world.com/en/\"&gt;Lobster Data&lt;/a&gt;. I\u2019m in a bit of a quandary and could really use some insights.&lt;/p&gt;\n\n&lt;p&gt;A bit about me:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;\u2022 TU grad (Masters).\n\u2022 On the job hunt trail for about 6 months now.\n\u2022 Completed the IBM Data Engineering Professional Certification.\n\u2022 Have undertaken 4 self-projects to gain hands-on experience with a variety of tools - think Spark, Kafka, and more.\n\n   \u2022  Wrapped up an internship and a thesis at a corporate firm as a Data analytics engr.\n\n\u2022 My background is mainly in data analytics and machine learning, and I\u2019ve always had a keen interest in the nuts and bolts of data engineering.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Here\u2019s the crux: Is stepping into a role that heavily focuses on a no-code approach the right move? While I appreciate the push towards making things streamlined in the industry, I can\u2019t help but wonder if this could potentially narrow down my practical experience down the line.&lt;/p&gt;\n\n&lt;p&gt;I\u2019d always pictured my first significant gig post-uni to be something where I\u2019m deep in the trenches, coding and designing architecture. But with half a year gone and this opportunity presenting itself, I\u2019m in two minds.&lt;/p&gt;\n\n&lt;p&gt;Would love to get your thoughts. Is this a logical first step, or should I be patient and wait for a more traditional data engineering role?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16aph64", "is_robot_indexable": true, "report_reasons": null, "author": "ikhan0007", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16aph64/should_i_take_a_nocode_data_engineering_job_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16aph64/should_i_take_a_nocode_data_engineering_job_using/", "subreddit_subscribers": 126999, "created_utc": 1693923375.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Data analyst working for a SaaS startup here. I'm prepping for an analytics engineer position at marketing intel dept. at EA. The recruiter outlined the rest of the process as below. Anyone has ideas what I am expected to know in these areas? Especially in 2 and 3?\n\n1. Data Analytics - Customers - 45 mins\n2. Software Engineering principles - 45 mins\n3. Database management + Cloud environment - 45 mins\n4. Data Analytics + Problem Solving - 45 mins", "author_fullname": "t2_4sr6tzl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help for my upcoming interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16b2w17", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693953953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data analyst working for a SaaS startup here. I&amp;#39;m prepping for an analytics engineer position at marketing intel dept. at EA. The recruiter outlined the rest of the process as below. Anyone has ideas what I am expected to know in these areas? Especially in 2 and 3?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Data Analytics - Customers - 45 mins&lt;/li&gt;\n&lt;li&gt;Software Engineering principles - 45 mins&lt;/li&gt;\n&lt;li&gt;Database management + Cloud environment - 45 mins&lt;/li&gt;\n&lt;li&gt;Data Analytics + Problem Solving - 45 mins&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16b2w17", "is_robot_indexable": true, "report_reasons": null, "author": "hamiltonedward", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b2w17/help_for_my_upcoming_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16b2w17/help_for_my_upcoming_interview/", "subreddit_subscribers": 126999, "created_utc": 1693953953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "MongoDB is one of the most widely used, if not the most widely used, distributed document database. MongoDB is known for coupling a flexible document data model with powerful features such as support for ad-hoc queries, secondary indexing and real-time aggregations. Enterprises rely on MongoDB and its scale-out architecture to handle huge volumes of unstructured data to build business and web applications that evolve quickly and scale transparently. The database is offered in several different formats, and today we\u2019re going to focus on MongoDB Community Server.  \n[https://blog.min.io/accelerating-mongodb-backup-minio-jumbo/](https://blog.min.io/accelerating-mongodb-backup-minio-jumbo/)", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accelerating MongoDB Backup with MinIO Jumbo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16b29uq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693952530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;MongoDB is one of the most widely used, if not the most widely used, distributed document database. MongoDB is known for coupling a flexible document data model with powerful features such as support for ad-hoc queries, secondary indexing and real-time aggregations. Enterprises rely on MongoDB and its scale-out architecture to handle huge volumes of unstructured data to build business and web applications that evolve quickly and scale transparently. The database is offered in several different formats, and today we\u2019re going to focus on MongoDB Community Server.&lt;br/&gt;\n&lt;a href=\"https://blog.min.io/accelerating-mongodb-backup-minio-jumbo/\"&gt;https://blog.min.io/accelerating-mongodb-backup-minio-jumbo/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/30_YyIXZ8APYKxve2lEAFYDldubcWgsbz0wZyCqUGQo.jpg?auto=webp&amp;s=af0ae771163b0bd9b6032144ec052eb9cdfdd35e", "width": 2000, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/30_YyIXZ8APYKxve2lEAFYDldubcWgsbz0wZyCqUGQo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c20a9a3c5db25995407f8e5f1b83af47df6179ef", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/30_YyIXZ8APYKxve2lEAFYDldubcWgsbz0wZyCqUGQo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=abcd78cdbfbe69f1c7e6fd801d0a73140e06135f", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/30_YyIXZ8APYKxve2lEAFYDldubcWgsbz0wZyCqUGQo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=64b99b2e820fd136fd1b13461a3c9951cfde6d2c", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/30_YyIXZ8APYKxve2lEAFYDldubcWgsbz0wZyCqUGQo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7572121aa7c98f93c2050ef303b9b5d6cf512835", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/30_YyIXZ8APYKxve2lEAFYDldubcWgsbz0wZyCqUGQo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d42887c39d89488d9824ff80b3d7aab901d66342", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/30_YyIXZ8APYKxve2lEAFYDldubcWgsbz0wZyCqUGQo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d9607b4dcda6db28bc2ea200f0af18056fc2e946", "width": 1080, "height": 322}], "variants": {}, "id": "-QdJAMWNj511R24umqlMVs_iEkZyH1WgqWwao1vhFq0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16b29uq", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b29uq/accelerating_mongodb_backup_with_minio_jumbo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16b29uq/accelerating_mongodb_backup_with_minio_jumbo/", "subreddit_subscribers": 126999, "created_utc": 1693952530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, just finished a personal project and I think it could be useful for someone over here.\n\nIt\u2019s called Lasagna.\n\nhttps://github.com/gmrqs/lasagna\n\nIt\u2019s essentially a interactive development environment for PySpark, specially if you\u2019re into open table formats.\n\nIt\u2019s a docker compose template that creates the following: \n\n- Jupyter Lab instance for interactive development along with some useful extensions and magic commands (to provide a more databricks-like experience)\n- MinIO to serve as object store\n- A standalone spark cluster (1 driver + 2 workers);\n- A standalone hive metastore instance (so you can persist tables between sessions without relying in path-based matastores);\n- A Trino instance for data virtualization;\n- single-node kafka instance for small streaming simulations.\n\nThat\u2019s it, hope you like it, check the repository, check the docs and you can reach me anytime in reddit or in github.\n\ncheers", "author_fullname": "t2_5fmit0v9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lasagna - A PySpark development environment + a lot of stuff", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": true, "name": "t3_16b1mzb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pUUE7UqQ7FsX7LELd7iHyBYTjRWn3rMR1_st2dWI5LI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693951115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, just finished a personal project and I think it could be useful for someone over here.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s called Lasagna.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/gmrqs/lasagna\"&gt;https://github.com/gmrqs/lasagna&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It\u2019s essentially a interactive development environment for PySpark, specially if you\u2019re into open table formats.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s a docker compose template that creates the following: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Jupyter Lab instance for interactive development along with some useful extensions and magic commands (to provide a more databricks-like experience)&lt;/li&gt;\n&lt;li&gt;MinIO to serve as object store&lt;/li&gt;\n&lt;li&gt;A standalone spark cluster (1 driver + 2 workers);&lt;/li&gt;\n&lt;li&gt;A standalone hive metastore instance (so you can persist tables between sessions without relying in path-based matastores);&lt;/li&gt;\n&lt;li&gt;A Trino instance for data virtualization;&lt;/li&gt;\n&lt;li&gt;single-node kafka instance for small streaming simulations.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;That\u2019s it, hope you like it, check the repository, check the docs and you can reach me anytime in reddit or in github.&lt;/p&gt;\n\n&lt;p&gt;cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tqu0j81deimb1.gif", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tqu0j81deimb1.gif?format=png8&amp;s=f9884defeaa66179908c37697414b3f49383cfeb", "width": 828, "height": 597}, "resolutions": [{"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=029d31be0b99c55a4872e24b3969c65d4b131f69", "width": 108, "height": 77}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=418428d754f3b4ed1192685c8c22ece451669dce", "width": 216, "height": 155}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=d6c8282ccf28530f2dcfb916f8c92013cd0702a7", "width": 320, "height": 230}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=5e454441428ee43edb80701832ee04033ffac342", "width": 640, "height": 461}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/tqu0j81deimb1.gif?s=d7ff727ac8331ef71915718abd4f45331325cec1", "width": 828, "height": 597}, "resolutions": [{"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=108&amp;crop=smart&amp;s=d1460fa6a0f3a678327755eb9609ff7a89ade9d8", "width": 108, "height": 77}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=216&amp;crop=smart&amp;s=ab1bb12f512b89db4dbd1eba427075fe546cd081", "width": 216, "height": 155}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=320&amp;crop=smart&amp;s=befb24d70abbc0dd71b05d285bbdec6fcd74d804", "width": 320, "height": 230}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=640&amp;crop=smart&amp;s=a6b0c126f785cbe9847adeebe004edaffdf05207", "width": 640, "height": 461}]}, "mp4": {"source": {"url": "https://preview.redd.it/tqu0j81deimb1.gif?format=mp4&amp;s=f5a2e9400d08910290876833d347875e0248d83e", "width": 828, "height": 597}, "resolutions": [{"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=108&amp;format=mp4&amp;s=474ea2a212d13d235580514dd39c7c049f3fb0f7", "width": 108, "height": 77}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=216&amp;format=mp4&amp;s=7e0ea4a17cdacbd474693af56b3360d8ed6a619c", "width": 216, "height": 155}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=320&amp;format=mp4&amp;s=e34d20fee9b7f244cc8c9bc2a91cb3112f6a12f0", "width": 320, "height": 230}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=640&amp;format=mp4&amp;s=1897608647f53297d6285f55c61a831334dcb597", "width": 640, "height": 461}]}}, "id": "5a0Y9mdiqI9-fwBGhi5vP4qv06x2vgPvmj2n6Ds7hQk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "16b1mzb", "is_robot_indexable": true, "report_reasons": null, "author": "gabbom_XCII", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b1mzb/lasagna_a_pyspark_development_environment_a_lot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tqu0j81deimb1.gif", "subreddit_subscribers": 126999, "created_utc": 1693951115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey data friends\u00a0\ud83d\udc4b   \nI'm super excited to to share a preview of some new stuff I'm working on: \u2728\u00a0Turntable Discover \u2728  \n\n\nData teams struggle to keep their documentation up to date and actionable. Today they have to stitch together Notion docs, lineage tools, yaml / markdown files and maintain jobs to generate it.  \n\n\nWe\u2019ve built a seamless way to ingest, discover, and share your warehouse's documentation all in one place. Discover is integrated with Github and dbt core, so you can get setup with a magical docs experience in only a few minutes including:  \n\n\n\u26a1\ufe0f Super fast search - search across table names, column, descriptions and canonical sql to find the data you're looking for  \n\n\n\u2728\ufe0f AI-powered semantic search - can't find a substring query that matches? Use semantic search to find data models that are tricky to find (ex: \"reps\" -&gt; \"sales people\")  \n\n\n\ud83d\udd2cColumn-level lineage view - trace back the origins of a particular column and navigate across models with an inline column level lineage view  \n\n\n\ud83d\udd17\u00a0One-click sharing - share documentation in one click with other teammates on the same OAuth domain  \n\n\nWe\u2019re giving Discover to select teams in a private beta before rolling it out broadly. If you\u2019d like to try it out, you can DM, comment below, or sign up on our waitlist ([turntable.so](http://turntable.so/)) Looking forward to hearing your feedback \ud83d\ude4c\n\n&amp;#x200B;\n\nCheck out a quick demo of how it works here:\n\n[https://www.youtube.com/watch?v=sY0NefWRpKQ](https://www.youtube.com/watch?v=sY0NefWRpKQ)", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A fast, shareable and AI-powered dbt docs alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16b1lvz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693951044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey data friends\u00a0\ud83d\udc4b&lt;br/&gt;\nI&amp;#39;m super excited to to share a preview of some new stuff I&amp;#39;m working on: \u2728\u00a0Turntable Discover \u2728  &lt;/p&gt;\n\n&lt;p&gt;Data teams struggle to keep their documentation up to date and actionable. Today they have to stitch together Notion docs, lineage tools, yaml / markdown files and maintain jobs to generate it.  &lt;/p&gt;\n\n&lt;p&gt;We\u2019ve built a seamless way to ingest, discover, and share your warehouse&amp;#39;s documentation all in one place. Discover is integrated with Github and dbt core, so you can get setup with a magical docs experience in only a few minutes including:  &lt;/p&gt;\n\n&lt;p&gt;\u26a1\ufe0f Super fast search - search across table names, column, descriptions and canonical sql to find the data you&amp;#39;re looking for  &lt;/p&gt;\n\n&lt;p&gt;\u2728\ufe0f AI-powered semantic search - can&amp;#39;t find a substring query that matches? Use semantic search to find data models that are tricky to find (ex: &amp;quot;reps&amp;quot; -&amp;gt; &amp;quot;sales people&amp;quot;)  &lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd2cColumn-level lineage view - trace back the origins of a particular column and navigate across models with an inline column level lineage view  &lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd17\u00a0One-click sharing - share documentation in one click with other teammates on the same OAuth domain  &lt;/p&gt;\n\n&lt;p&gt;We\u2019re giving Discover to select teams in a private beta before rolling it out broadly. If you\u2019d like to try it out, you can DM, comment below, or sign up on our waitlist (&lt;a href=\"http://turntable.so/\"&gt;turntable.so&lt;/a&gt;) Looking forward to hearing your feedback \ud83d\ude4c&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Check out a quick demo of how it works here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=sY0NefWRpKQ\"&gt;https://www.youtube.com/watch?v=sY0NefWRpKQ&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "16b1lvz", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b1lvz/a_fast_shareable_and_aipowered_dbt_docs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16b1lvz/a_fast_shareable_and_aipowered_dbt_docs/", "subreddit_subscribers": 126999, "created_utc": 1693951044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A fast, shareable, AI-powered dbt docs alternative", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 74, "top_awarded_type": null, "hide_score": true, "name": "t3_16b1hqr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/82dart39dimb1/DASH_1080.mp4?source=fallback", "height": 1024, "width": 1920, "scrubber_media_url": "https://v.redd.it/82dart39dimb1/DASH_96.mp4", "dash_url": "https://v.redd.it/82dart39dimb1/DASHPlaylist.mpd?a=1696549101%2CNGRmYWQ1ZTBjZDkwOTEzOTg5YzBhZDcxMTUyY2MzNzE0OWNmYjA3ZjFlNDkzMzdlNzhhMTIzYmZjYzY4MWZhMQ%3D%3D&amp;v=1&amp;f=sd", "duration": 29, "hls_url": "https://v.redd.it/82dart39dimb1/HLSPlaylist.m3u8?a=1696549101%2CYzJlMWViNGM4NDk4Mjk4ZDY4ZGRmMDc5MGE1ZGUyNzM1MDIwNDRiYWQ3MDU4NGQ4YzEyNTZmMTNhZTUyYzQyYQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ke_tmGcN1JFs464kzIQhgHgF5uctyUG1DS37Nr_NhvY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693950783.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/82dart39dimb1", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vvEA8DH50B-jmeXia5J34fYJiJd3-Qy4GZ-bmPaRRkg.png?format=pjpg&amp;auto=webp&amp;s=6c109735325c7dd1e252c7088a8b82f14bd4241e", "width": 2024, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/vvEA8DH50B-jmeXia5J34fYJiJd3-Qy4GZ-bmPaRRkg.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4f68712720c953d1bf0524d5e73939089a778973", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/vvEA8DH50B-jmeXia5J34fYJiJd3-Qy4GZ-bmPaRRkg.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2bb0643d4fc3f5b67a0a2cbd4036208c3dc90fd0", "width": 216, "height": 115}, {"url": "https://external-preview.redd.it/vvEA8DH50B-jmeXia5J34fYJiJd3-Qy4GZ-bmPaRRkg.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6ea1eb3b0e15e9277217bbf7fbf9a09b8ec2fd6b", "width": 320, "height": 170}, {"url": "https://external-preview.redd.it/vvEA8DH50B-jmeXia5J34fYJiJd3-Qy4GZ-bmPaRRkg.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=898d1476b9ba19e10e9604036284e95ceb746514", "width": 640, "height": 341}, {"url": "https://external-preview.redd.it/vvEA8DH50B-jmeXia5J34fYJiJd3-Qy4GZ-bmPaRRkg.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=5d5d28bba7f12db39cee1bce5acc6add7add30f0", "width": 960, "height": 512}, {"url": "https://external-preview.redd.it/vvEA8DH50B-jmeXia5J34fYJiJd3-Qy4GZ-bmPaRRkg.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=19d0d5f19bc0a62852cdee9f45250055a988c5ce", "width": 1080, "height": 576}], "variants": {}, "id": "ZZBNloxPY273r7Ra_2uk_FgTQ2Ssv7e3Iho-ewBYMIs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "16b1hqr", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b1hqr/a_fast_shareable_aipowered_dbt_docs_alternative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/82dart39dimb1", "subreddit_subscribers": 126999, "created_utc": 1693950783.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/82dart39dimb1/DASH_1080.mp4?source=fallback", "height": 1024, "width": 1920, "scrubber_media_url": "https://v.redd.it/82dart39dimb1/DASH_96.mp4", "dash_url": "https://v.redd.it/82dart39dimb1/DASHPlaylist.mpd?a=1696549101%2CNGRmYWQ1ZTBjZDkwOTEzOTg5YzBhZDcxMTUyY2MzNzE0OWNmYjA3ZjFlNDkzMzdlNzhhMTIzYmZjYzY4MWZhMQ%3D%3D&amp;v=1&amp;f=sd", "duration": 29, "hls_url": "https://v.redd.it/82dart39dimb1/HLSPlaylist.m3u8?a=1696549101%2CYzJlMWViNGM4NDk4Mjk4ZDY4ZGRmMDc5MGE1ZGUyNzM1MDIwNDRiYWQ3MDU4NGQ4YzEyNTZmMTNhZTUyYzQyYQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/rmmb01sf7hmb1.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=73490ed2298b99d340b6e228767238e064fb3fea\n\nExclusive Invitation: Data Solution Architect Insight Roundtable\n\nWe're excited to invite you to EPAM Poland's upcoming roundtable session dedicated to the world of Data Solution Architects and their impact on large-scale data-driven solutions.\n\nAt this event, you'll have the unique opportunity to learn and engage with our esteemed panel of top data professionals:\n\n\ud83d\udd39 Uladzimir Kazakevich, technologist with over 20 years of professional experience, Head of Data &amp; Analytics Practice CEE\n\n\ud83d\udd39 Peter Kortvelyesi, IT consultant, data architect &amp; delivery lead to Fortune 500 clients\n\n\ud83d\udd39 Michal Bienkowski, solution architect in the Data/Cloud space, expert with 16+ years in the field\n\nWhen: 07.09. (Thursday)  I  Time: 17:00 CEST  I  Location: [http://datazen.top/0gaps](http://datazen.top/0gaps)\n\nYour questions and perspectives will drive the second part of the conversation. At the end, you'll also have a chance to participate in the quiz and win e-gift cards.\n\nSave your spot now by registering here: [http://datazen.top/0gaps](http://datazen.top/0gaps)", "author_fullname": "t2_8rp73p0k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Solution Architect Insight Roundtable", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"rmmb01sf7hmb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 108, "x": 108, "u": "https://preview.redd.it/rmmb01sf7hmb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5d9c9f298a0f1dfab72838ed0346e1d9fc2c0038"}, {"y": 216, "x": 216, "u": "https://preview.redd.it/rmmb01sf7hmb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=000c16c9d47ce5317ca3125c9521d20660e9d7d7"}, {"y": 320, "x": 320, "u": "https://preview.redd.it/rmmb01sf7hmb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cf2951983f3a6be314bcd69c4da3f7c3582c857b"}, {"y": 640, "x": 640, "u": "https://preview.redd.it/rmmb01sf7hmb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=53ef698a8bcff401b8df0ab78f3a9c7ffb02a591"}, {"y": 960, "x": 960, "u": "https://preview.redd.it/rmmb01sf7hmb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=84b8ca86e16bfd4d4a378d5a19ec1ae66ab7d869"}, {"y": 1080, "x": 1080, "u": "https://preview.redd.it/rmmb01sf7hmb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f0c6d34764bc3b50e1bacdc88e3c1128dbcaaac9"}], "s": {"y": 1080, "x": 1080, "u": "https://preview.redd.it/rmmb01sf7hmb1.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=73490ed2298b99d340b6e228767238e064fb3fea"}, "id": "rmmb01sf7hmb1"}}, "name": "t3_16av7fj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4_5gcC3y1730RzMQclXJmxLUbMAd0v_KaHCdtZljwmI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693936740.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rmmb01sf7hmb1.jpg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=73490ed2298b99d340b6e228767238e064fb3fea\"&gt;https://preview.redd.it/rmmb01sf7hmb1.jpg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=73490ed2298b99d340b6e228767238e064fb3fea&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Exclusive Invitation: Data Solution Architect Insight Roundtable&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re excited to invite you to EPAM Poland&amp;#39;s upcoming roundtable session dedicated to the world of Data Solution Architects and their impact on large-scale data-driven solutions.&lt;/p&gt;\n\n&lt;p&gt;At this event, you&amp;#39;ll have the unique opportunity to learn and engage with our esteemed panel of top data professionals:&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd39 Uladzimir Kazakevich, technologist with over 20 years of professional experience, Head of Data &amp;amp; Analytics Practice CEE&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd39 Peter Kortvelyesi, IT consultant, data architect &amp;amp; delivery lead to Fortune 500 clients&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd39 Michal Bienkowski, solution architect in the Data/Cloud space, expert with 16+ years in the field&lt;/p&gt;\n\n&lt;p&gt;When: 07.09. (Thursday)  I  Time: 17:00 CEST  I  Location: &lt;a href=\"http://datazen.top/0gaps\"&gt;http://datazen.top/0gaps&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Your questions and perspectives will drive the second part of the conversation. At the end, you&amp;#39;ll also have a chance to participate in the quiz and win e-gift cards.&lt;/p&gt;\n\n&lt;p&gt;Save your spot now by registering here: &lt;a href=\"http://datazen.top/0gaps\"&gt;http://datazen.top/0gaps&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16av7fj", "is_robot_indexable": true, "report_reasons": null, "author": "alexdby", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16av7fj/data_solution_architect_insight_roundtable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16av7fj/data_solution_architect_insight_roundtable/", "subreddit_subscribers": 126999, "created_utc": 1693936740.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Omitting the networking, is it sufficient to set up a Data Sync agent on AWS EC2 and connect Azure -&gt; AWS SQL Servers through that agent directly? Are there any other services or tools I should be worried about?", "author_fullname": "t2_79q5kdal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to set up ongoing replication between Azure SQL Server and AWS RDS SQL Server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16arnep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693928556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Omitting the networking, is it sufficient to set up a Data Sync agent on AWS EC2 and connect Azure -&amp;gt; AWS SQL Servers through that agent directly? Are there any other services or tools I should be worried about?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16arnep", "is_robot_indexable": true, "report_reasons": null, "author": "__hey_there", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16arnep/how_to_set_up_ongoing_replication_between_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16arnep/how_to_set_up_ongoing_replication_between_azure/", "subreddit_subscribers": 126999, "created_utc": 1693928556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nHi, I am studying for the Cloudera Data Developer Certification. The company I work for is paying for the courses, but I want more information about the questions. I haven\u2019t found anything online: how long should it take to answer the questions? What type of questions are there? Does anyone has examples?\n\nIf anyone has done the certification I would really appreciate if I could write to you with some questions.\n\nThanks!", "author_fullname": "t2_dy673utkf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloudera Data Developer Certification (CDP 3001)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16aqn40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693926195.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am studying for the Cloudera Data Developer Certification. The company I work for is paying for the courses, but I want more information about the questions. I haven\u2019t found anything online: how long should it take to answer the questions? What type of questions are there? Does anyone has examples?&lt;/p&gt;\n\n&lt;p&gt;If anyone has done the certification I would really appreciate if I could write to you with some questions.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16aqn40", "is_robot_indexable": true, "report_reasons": null, "author": "MmaappUy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16aqn40/cloudera_data_developer_certification_cdp_3001/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16aqn40/cloudera_data_developer_certification_cdp_3001/", "subreddit_subscribers": 126999, "created_utc": 1693926195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Want to learn how to fine-tune your Donut transformer model to read text from images? Check out [this article on fine-tuning the Donut model with your own data.](https://medium.com/python-in-plain-english/empower-your-donut-model-for-receipts-with-self-annotated-data-51fc882b7229)", "author_fullname": "t2_9ssuhjvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learn how to fine-tune your Donut transformer model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16agv6h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693896901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Want to learn how to fine-tune your Donut transformer model to read text from images? Check out &lt;a href=\"https://medium.com/python-in-plain-english/empower-your-donut-model-for-receipts-with-self-annotated-data-51fc882b7229\"&gt;this article on fine-tuning the Donut model with your own data.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZLuOVaB68GMr7MnVodshEc97P8x28z1gme0-Sm77Ymk.jpg?auto=webp&amp;s=564b07956bc7c50dfe238bad3ac9d8b7fa3d3652", "width": 611, "height": 495}, "resolutions": [{"url": "https://external-preview.redd.it/ZLuOVaB68GMr7MnVodshEc97P8x28z1gme0-Sm77Ymk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9a798cee1c661714f2cd168b5d1d4624b5070ad1", "width": 108, "height": 87}, {"url": "https://external-preview.redd.it/ZLuOVaB68GMr7MnVodshEc97P8x28z1gme0-Sm77Ymk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f97a7abd0955fa140562040e3ce8a5e29c43b960", "width": 216, "height": 174}, {"url": "https://external-preview.redd.it/ZLuOVaB68GMr7MnVodshEc97P8x28z1gme0-Sm77Ymk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8ecc529113b5712ccb2d72e3a9e06fe4725397e4", "width": 320, "height": 259}], "variants": {}, "id": "X5GKy4DRjKrwntxD7EMrGJJZw6M6-kYZkTRYOAbcmPw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "16agv6h", "is_robot_indexable": true, "report_reasons": null, "author": "Artistic_Highlight_1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16agv6h/learn_how_to_finetune_your_donut_transformer_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16agv6h/learn_how_to_finetune_your_donut_transformer_model/", "subreddit_subscribers": 126999, "created_utc": 1693896901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi DEs, \nI'm eager to hear about the complex DE projects you've been involved with. What impact did they have? How did you adapt and align yourself with these projects? And what valuable insights did you gain from them?", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are few complex DE projects you worked on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ag2q2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693894184.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi DEs, \nI&amp;#39;m eager to hear about the complex DE projects you&amp;#39;ve been involved with. What impact did they have? How did you adapt and align yourself with these projects? And what valuable insights did you gain from them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ag2q2", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16ag2q2/what_are_few_complex_de_projects_you_worked_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ag2q2/what_are_few_complex_de_projects_you_worked_on/", "subreddit_subscribers": 126999, "created_utc": 1693894184.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI would like some feedback on my teams role and see how much of it is DE. I currently work at a university affiliated research organization as sort of a senior data analyst. On our team, our main job is to intake raw data, standardize them for modelers to use. I had thought what my team does is very closely related to data engineering but we rely 85% on Python and 15% SQL Database. We also create ad-hoc Tableau visuals and maintain R Shiny interactive dashboards. \n\nThere are other teams that maintain our in house compute cluster, our file systems (3rd party), and also database management. They give us the tools and infrastructure to do our work. All we really have to do is focus on writing solid python code and leverage the computing cluster to clean all the raw datasets and send them through our pipeline to ensure they are consistent and comparable. Then we upload them all to a SQL database. Other teams maintain python functions/machinery that interact with the database for modelers to pull the data without SQL queries.\n\nOur raw data mostly comes as .csv and .dta files. We do a good job of maintaining replicability and consistency by git tracking our codebase and version tracking our pipeline inputs and dataset metadata with our own database. We are able to find root causes if our final outputs have issues and apply a fix fairly quickly. We understand how to structure and run our code so we do not overload the database and filesystems and improve overall efficiency. Although with our computation cluster, we can apply distributed computing fairly easily.\n\nOverall, I think my team has a good system in place to process all this data but just a little outdated. It also feels like some important aspects of DE are outsourced to other teams. Someone on our team recently is exploring PySpark to help with processing, someone else had implemented Dask. Its a little hard for me to explain all what my teams does in detail but what do you guys think?\n\nThanks in advance!", "author_fullname": "t2_9nvslz1w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on my teams role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a895o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693871940.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693871436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I would like some feedback on my teams role and see how much of it is DE. I currently work at a university affiliated research organization as sort of a senior data analyst. On our team, our main job is to intake raw data, standardize them for modelers to use. I had thought what my team does is very closely related to data engineering but we rely 85% on Python and 15% SQL Database. We also create ad-hoc Tableau visuals and maintain R Shiny interactive dashboards. &lt;/p&gt;\n\n&lt;p&gt;There are other teams that maintain our in house compute cluster, our file systems (3rd party), and also database management. They give us the tools and infrastructure to do our work. All we really have to do is focus on writing solid python code and leverage the computing cluster to clean all the raw datasets and send them through our pipeline to ensure they are consistent and comparable. Then we upload them all to a SQL database. Other teams maintain python functions/machinery that interact with the database for modelers to pull the data without SQL queries.&lt;/p&gt;\n\n&lt;p&gt;Our raw data mostly comes as .csv and .dta files. We do a good job of maintaining replicability and consistency by git tracking our codebase and version tracking our pipeline inputs and dataset metadata with our own database. We are able to find root causes if our final outputs have issues and apply a fix fairly quickly. We understand how to structure and run our code so we do not overload the database and filesystems and improve overall efficiency. Although with our computation cluster, we can apply distributed computing fairly easily.&lt;/p&gt;\n\n&lt;p&gt;Overall, I think my team has a good system in place to process all this data but just a little outdated. It also feels like some important aspects of DE are outsourced to other teams. Someone on our team recently is exploring PySpark to help with processing, someone else had implemented Dask. Its a little hard for me to explain all what my teams does in detail but what do you guys think?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16a895o", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Chemical4044", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16a895o/feedback_on_my_teams_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16a895o/feedback_on_my_teams_role/", "subreddit_subscribers": 126999, "created_utc": 1693871436.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}