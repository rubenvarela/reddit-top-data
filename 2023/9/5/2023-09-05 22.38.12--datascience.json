{"kind": "Listing", "data": {"after": "t3_16as06v", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "There's always so much criticism of hiring processes in the tech world, from hating take home tests or the recent post complaining about what looks like a \\~5 minute task if you know SQL.\n\nI'm curious how everyone would realistically redesign / create their own application process since we're so critical of the existing ones. \n\nLet's say you're the hiring manager for a Data science role that you've benchmarked as needing someone with \\~1 to 2 years experience. The job role automatically closes after it's got 1000 applicants... which you get in about a day.\n\nHow do you handle those 1000 applicants? \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_4qacn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How would YOU handle Data Science recruitment ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16aox1s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693922029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s always so much criticism of hiring processes in the tech world, from hating take home tests or the recent post complaining about what looks like a ~5 minute task if you know SQL.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious how everyone would realistically redesign / create their own application process since we&amp;#39;re so critical of the existing ones. &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say you&amp;#39;re the hiring manager for a Data science role that you&amp;#39;ve benchmarked as needing someone with ~1 to 2 years experience. The job role automatically closes after it&amp;#39;s got 1000 applicants... which you get in about a day.&lt;/p&gt;\n\n&lt;p&gt;How do you handle those 1000 applicants? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16aox1s", "is_robot_indexable": true, "report_reasons": null, "author": "Littleish", "discussion_type": null, "num_comments": 77, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16aox1s/how_would_you_handle_data_science_recruitment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16aox1s/how_would_you_handle_data_science_recruitment/", "subreddit_subscribers": 1032518, "created_utc": 1693922029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for a Fortune 500 company as a data engineer. I was promised when hired, that I would be a data scientist and get plenty of predictive modeling work. I have done some modeling work, but feel like there is no purpose to the work I am doing. We don't have much vision or leadership on the DS side and have a huge focus on DE. I have been in the position for about 1-1/2 year. It seems like we are doing a bunch of busy work to move the data into AWS, pay huge sums of money to Amazon, and get no business value out of the effort. There is a lot of talk about how great AWS is and how much of a game-changer this effort will be. Everyone on the team seems to think it's great and cool what we are doing, but I just cannot grasp the value and am extremely uninterested in the DE work. ", "author_fullname": "t2_9bjl9255", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hate my job - Waste of time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16aop0z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693928982.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693921498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a Fortune 500 company as a data engineer. I was promised when hired, that I would be a data scientist and get plenty of predictive modeling work. I have done some modeling work, but feel like there is no purpose to the work I am doing. We don&amp;#39;t have much vision or leadership on the DS side and have a huge focus on DE. I have been in the position for about 1-1/2 year. It seems like we are doing a bunch of busy work to move the data into AWS, pay huge sums of money to Amazon, and get no business value out of the effort. There is a lot of talk about how great AWS is and how much of a game-changer this effort will be. Everyone on the team seems to think it&amp;#39;s great and cool what we are doing, but I just cannot grasp the value and am extremely uninterested in the DE work. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16aop0z", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial-Lime7107", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16aop0z/hate_my_job_waste_of_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16aop0z/hate_my_job_waste_of_time/", "subreddit_subscribers": 1032518, "created_utc": 1693921498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\non Dec 19th I launched [DataAnalyst.com](https://dataanalyst.com) \\- this is the eighth update, covering performance in August, with hopefully many more to come. It'll be a shorter update this time, due to absolutely manic month at the dayjob, but it's still been a very eventful month.\n\nWant to make sure I document the journey, and keep myself honest, so each month I will be making a post about the statistics, progress, some thoughts and what are the next steps I want to be focusing on.\n\nWhile the main purpose for the post is to bring everyone along on the journey, I do think that members of r/datascience might benefit from the site, especially those looking for a new data analyst job. I'd also love to engage with people on the sub who'd like to share their data analyst career journey.\n\nSo, just a reminder that early stages vision is to become the #1 job board for data analysts - hand-picking interesting data analyst job opportunities across industries.\n\nLet's dive right in:\n\n# Statistics update\n\n|\\-|January|Feb|March|April|May|June|July|August|\n|:-|:-|:-|:-|:-|:-|:-|:-|:-|\n|Number of jobs posted|Total: 208 (US)|Total: 212 (US)|Total: 207 (US)|Total: 153 (US)|Total: 140 (US)|Total: 115 (US)|Total: 104 (US)|Total: 110 (US)|\n|Paid posts|0|0|0|0|0|0|0|1|\n|Visitors|795|3,267|3,003|4,892|5,203|4,029|3,382|4,421|\n|Apply now clicks|634|2,354|2,898|4,051|4,476|4,561|3,193|4,154|\n|Avg. session duration|3min 52sec|3min 53sec|3min 39sec|3min 44sec|3min 10sec|3min 17sec|3min 05sec|2min 53sec|\n|Pageviews|4100|16,300|15,449|26,291|28,755|24,000|18,884|23,424|\n|Avg. time on page|1min 35sec|1min 46sec|1min 45sec|1min 39sec|1min 26sec|1min 26sec|1min 30sec|1min 30sec|\n|Returning visitors|17.7%|22.4%|23.9%|23.8%|22.2%|22.5%|24.5%|21.1%|\n|Google Impressions|503|5,500|9,430|28,300|45,900|58,100|47,500|78,400|\n|Google Clicks|47|355|337|1,880|2,070|3,320|2,180|4,220|\n|Newsletter subs (total)|205|416|600|918|1,239|1,431|1,559|1,815|\n|Newsletter open rate (48hrs)|61%|67%|56%|56%|50%|60%|Skipped|53%|\n\n# 1. General Observations\n\nDataAnalyst.com has been online for just over 8 months, and we're bringing new, hand curated data analyst jobs onto the site daily - all of them including a salary range.\n\nThere's now 1,800+ people subscribed to the newsletter, and I can't thank you enough for your support and for joining us on the journey.\n\n## First job paid posting\n\nTo those who monitor the above table closely, you've probably noticed the number 1 in the paid posts cell for August.\n\nYes, it ***only*** took 7 months and 16 days to get a first paid job posting on the site. Hurray!\n\nTualatin Valley Fire &amp; Rescue purchased a fast-track job posting - it came organically, which is a great sign as well.\n\nIt also came in with a lesson learnt - after tweaking flows / forms, always double check that you didn't leave a bug behind. Unfortunately for me I did, and they couldn't complete the purchase, but fortunately they reached out and I solved the issue immediately. I've also upgraded the posting to a featured one, free of charge - I think this is particularly important.\n\nLinkedins, Indeeds of the world are too complex to ensure a human connection with each client, while as a solofounder, I want to make sure I go over and beyond each time someone puts trusts in me and the service. That's something I do believe founders should strive for, and something that will set them apart.\n\n## Stats - Bounce, numbers, bounce\n\nAfter seeing a massive dip in traffic, apply now clicks and Google impressions in July, looks like August numbers bounced back with vengeance, driven primarily by skyrocketing Google impressions / clicks.\n\nI'd be grateful if someone could please explain to me Google Search Console Clicks vs Google Analytics Visitors - shouldn't each click that comes from Google Search, leading to the site, also mean that's a visitor coming in?\n\n**Where did 4,421 people come from?**\n\n* Direct - 51%\n* Organic - 35%\n* Social - 14% (automated job postings on Twitter, Linkedin, Reddit)\n\n**SEO optimisation**\n\nI've also spent some time over the summer using tools such as SEMRush / Ahrefs / Moz to run some high level audits and understand how the site performs on the SEO front. This led to a lot of time spent on making significant on-page changes to improve keyword optimisation, rewriting meta descriptions and adding alt descriptions to all the images on the site.\n\nWhether this was something that caused the sudden Google love, I don't know, but this is probably something that could (and should) have been done a lot earlier. Having said that, it's now something that I pay attention to with each update that I make on the site.\n\n## Things on top of my mind\n\n**a) Expired Listings**\n\nThere's feedback regarding some of the jobs on the site already expiring and leading to non-existing listings. Decided to address this in two ways:\n\nFirst, I found out Ahrefs has a free \"Site Audit\" tier, which crawls the whole site and provides a report including all the issues i.e missing alt descriptions, including 404 links.\n\nSecond, on each listing I've now included a link for any visitor to report an expiring listing. Hopefully this will improve the experience. I'm still leaving listings (without apply buttons) on the site, so people can see previous open roles and salary ranges.\n\n**b) Outreach**\n\nOne of my main priorities for the coming 3 months is reaching out to organisations hiring data analysts and educating them about the niche job board, and how they can benefit by sharing their opportunities on the site.\n\nAdditionally, I did notice quite a few .edu emails signed up to the Newsletter. This could be an interesting angle to explore, reaching out to universities, sharing that their students are using the site. This could lead to both driving in visitors, as well as potentially getting a backlink that would help increase the authority of the site.\n\n**c) UX/UI**\n\nLesson learnt - do not use experimental browsers when you try to do website design - I've been using Arc browser since the start of the year, with the toolbar being on the left hand side. I've recently used various browsers and monitors to see how the site looks on various sizes, and it's an absolute mess -&gt; will need to dedicate some time to standardize sections and elements, so it's a more consistent experience.\n\n## BusinessAnalyst.com\n\nAs I've mentioned before, I recently launched BusinessAnalyst.com - where I'm looking to replicate step by step what I've done over the last 8 months with DataAnalyst. The overall idea is to create a network of sites, benefiting from the same infrastructure, serving and helping different career paths, and making a collaboration with organisations much more appealing (afterall, most companies who hire for data analysts also look for business analysts and vice versa). Arguably, this might not make much sense seeing that DA still hasn't brought any consistent revenue in, but on the other hand, I can reuse the whole tech stack and structures already in place, halve my cost per project, while doubling the surface area to catch me some luck.\n\nShared [first update](https://www.reddit.com/r/businessanalyst/comments/15r5ecq/businessanalystcom_i_launched_a_niche_job_board/) couple of weeks ago - will need to figure out how to combine, if people are interested to see the side by side view. **TLDR: site still dead**\n\n# 2. \"Day in the Life\" - a series of interviews with data analysts sharing their experience, thoughts and advice.\n\nAnother interview from our series has been published. In these interviews, we aim to share stories and experiences about the route to becoming a data analyst, keeping up with the skillset, recommendations to aspiring data analysts and much more.\n\n**Alex, who is a BI manager at AWS**, has shared some fantastic insights, and I'd love to share his  advice on building a portfolio.\n\n*\"I've been mentoring a few folks on this recently, ranging from college grads to mid-career individuals in non-tech roles. My recommendation to each is to build an end to end portfolio of work. An example is using python to web scrape information from a website and persist to a normalized data structure in a database, using SQL to write queries and analyze that information, and then use Tableau or PowerBI to visualize results and share insights. Each step of this process is important for a rockstar Data Analyst/BI Engineer and will showcase the capability to do the work for hiring managers.\"*\n\nWe also briefly cover the question of the Year: Is AI/ChatGPT a threat to data analysts? Highly recommend reading the [full interview](https://www.dataanalyst.com/blog/alex-my-data-analyst-career-journey).\n\n# Things in the pipeline\n\n* New data analyst jobs, added daily\n* Actually launching the weekly newsletter with the pick of best jobs directly to your inbox (yes, I know....)\n* Monthly US data analyst market insights\n* Improving the overall site experience (this one is a never ending activity)\n* Continuing to bring you Data Analysts across their experience levels, to share tips, tricks and their thoughts\n\n# 3 ways you could help\n\n1. Looking for a new challenge? Check out the website - I'm adding new jobs daily\n2. Looking to hire a data analyst to your team? Do you know anyone looking to hire? Shoot me a message on Reddit (or [alex@dataanalyst.com](mailto:alex@dataanalyst.com)) and I'll upgrade your first listing for free!\n3. As I mentioned, we have an ongoing \"Day of a Data Analyst\" series. For those of you who are open to do an email based interview about your data analyst career journey, please just send me a message and we'll organise something - would love to get you featured and share your experience with our readers! Also, as I thank you I will donate to a charity of your choice.\n\nIf you have any questions, concerns, come across glitches - please just reach out, happy to chat. Thank you all again, and see you in a month. Alex", "author_fullname": "t2_x8bkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataAnalyst.com - I launched a niche job board with hand curated data analyst jobs. Here's the summary of how it's going after the eight month (an eventful one!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ap9p8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693922869.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;on Dec 19th I launched &lt;a href=\"https://dataanalyst.com\"&gt;DataAnalyst.com&lt;/a&gt; - this is the eighth update, covering performance in August, with hopefully many more to come. It&amp;#39;ll be a shorter update this time, due to absolutely manic month at the dayjob, but it&amp;#39;s still been a very eventful month.&lt;/p&gt;\n\n&lt;p&gt;Want to make sure I document the journey, and keep myself honest, so each month I will be making a post about the statistics, progress, some thoughts and what are the next steps I want to be focusing on.&lt;/p&gt;\n\n&lt;p&gt;While the main purpose for the post is to bring everyone along on the journey, I do think that members of &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt; might benefit from the site, especially those looking for a new data analyst job. I&amp;#39;d also love to engage with people on the sub who&amp;#39;d like to share their data analyst career journey.&lt;/p&gt;\n\n&lt;p&gt;So, just a reminder that early stages vision is to become the #1 job board for data analysts - hand-picking interesting data analyst job opportunities across industries.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s dive right in:&lt;/p&gt;\n\n&lt;h1&gt;Statistics update&lt;/h1&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;-&lt;/th&gt;\n&lt;th align=\"left\"&gt;January&lt;/th&gt;\n&lt;th align=\"left\"&gt;Feb&lt;/th&gt;\n&lt;th align=\"left\"&gt;March&lt;/th&gt;\n&lt;th align=\"left\"&gt;April&lt;/th&gt;\n&lt;th align=\"left\"&gt;May&lt;/th&gt;\n&lt;th align=\"left\"&gt;June&lt;/th&gt;\n&lt;th align=\"left\"&gt;July&lt;/th&gt;\n&lt;th align=\"left\"&gt;August&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Number of jobs posted&lt;/td&gt;\n&lt;td align=\"left\"&gt;Total: 208 (US)&lt;/td&gt;\n&lt;td align=\"left\"&gt;Total: 212 (US)&lt;/td&gt;\n&lt;td align=\"left\"&gt;Total: 207 (US)&lt;/td&gt;\n&lt;td align=\"left\"&gt;Total: 153 (US)&lt;/td&gt;\n&lt;td align=\"left\"&gt;Total: 140 (US)&lt;/td&gt;\n&lt;td align=\"left\"&gt;Total: 115 (US)&lt;/td&gt;\n&lt;td align=\"left\"&gt;Total: 104 (US)&lt;/td&gt;\n&lt;td align=\"left\"&gt;Total: 110 (US)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Paid posts&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;0&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Visitors&lt;/td&gt;\n&lt;td align=\"left\"&gt;795&lt;/td&gt;\n&lt;td align=\"left\"&gt;3,267&lt;/td&gt;\n&lt;td align=\"left\"&gt;3,003&lt;/td&gt;\n&lt;td align=\"left\"&gt;4,892&lt;/td&gt;\n&lt;td align=\"left\"&gt;5,203&lt;/td&gt;\n&lt;td align=\"left\"&gt;4,029&lt;/td&gt;\n&lt;td align=\"left\"&gt;3,382&lt;/td&gt;\n&lt;td align=\"left\"&gt;4,421&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Apply now clicks&lt;/td&gt;\n&lt;td align=\"left\"&gt;634&lt;/td&gt;\n&lt;td align=\"left\"&gt;2,354&lt;/td&gt;\n&lt;td align=\"left\"&gt;2,898&lt;/td&gt;\n&lt;td align=\"left\"&gt;4,051&lt;/td&gt;\n&lt;td align=\"left\"&gt;4,476&lt;/td&gt;\n&lt;td align=\"left\"&gt;4,561&lt;/td&gt;\n&lt;td align=\"left\"&gt;3,193&lt;/td&gt;\n&lt;td align=\"left\"&gt;4,154&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Avg. session duration&lt;/td&gt;\n&lt;td align=\"left\"&gt;3min 52sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;3min 53sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;3min 39sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;3min 44sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;3min 10sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;3min 17sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;3min 05sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;2min 53sec&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Pageviews&lt;/td&gt;\n&lt;td align=\"left\"&gt;4100&lt;/td&gt;\n&lt;td align=\"left\"&gt;16,300&lt;/td&gt;\n&lt;td align=\"left\"&gt;15,449&lt;/td&gt;\n&lt;td align=\"left\"&gt;26,291&lt;/td&gt;\n&lt;td align=\"left\"&gt;28,755&lt;/td&gt;\n&lt;td align=\"left\"&gt;24,000&lt;/td&gt;\n&lt;td align=\"left\"&gt;18,884&lt;/td&gt;\n&lt;td align=\"left\"&gt;23,424&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Avg. time on page&lt;/td&gt;\n&lt;td align=\"left\"&gt;1min 35sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;1min 46sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;1min 45sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;1min 39sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;1min 26sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;1min 26sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;1min 30sec&lt;/td&gt;\n&lt;td align=\"left\"&gt;1min 30sec&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Returning visitors&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.7%&lt;/td&gt;\n&lt;td align=\"left\"&gt;22.4%&lt;/td&gt;\n&lt;td align=\"left\"&gt;23.9%&lt;/td&gt;\n&lt;td align=\"left\"&gt;23.8%&lt;/td&gt;\n&lt;td align=\"left\"&gt;22.2%&lt;/td&gt;\n&lt;td align=\"left\"&gt;22.5%&lt;/td&gt;\n&lt;td align=\"left\"&gt;24.5%&lt;/td&gt;\n&lt;td align=\"left\"&gt;21.1%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Google Impressions&lt;/td&gt;\n&lt;td align=\"left\"&gt;503&lt;/td&gt;\n&lt;td align=\"left\"&gt;5,500&lt;/td&gt;\n&lt;td align=\"left\"&gt;9,430&lt;/td&gt;\n&lt;td align=\"left\"&gt;28,300&lt;/td&gt;\n&lt;td align=\"left\"&gt;45,900&lt;/td&gt;\n&lt;td align=\"left\"&gt;58,100&lt;/td&gt;\n&lt;td align=\"left\"&gt;47,500&lt;/td&gt;\n&lt;td align=\"left\"&gt;78,400&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Google Clicks&lt;/td&gt;\n&lt;td align=\"left\"&gt;47&lt;/td&gt;\n&lt;td align=\"left\"&gt;355&lt;/td&gt;\n&lt;td align=\"left\"&gt;337&lt;/td&gt;\n&lt;td align=\"left\"&gt;1,880&lt;/td&gt;\n&lt;td align=\"left\"&gt;2,070&lt;/td&gt;\n&lt;td align=\"left\"&gt;3,320&lt;/td&gt;\n&lt;td align=\"left\"&gt;2,180&lt;/td&gt;\n&lt;td align=\"left\"&gt;4,220&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Newsletter subs (total)&lt;/td&gt;\n&lt;td align=\"left\"&gt;205&lt;/td&gt;\n&lt;td align=\"left\"&gt;416&lt;/td&gt;\n&lt;td align=\"left\"&gt;600&lt;/td&gt;\n&lt;td align=\"left\"&gt;918&lt;/td&gt;\n&lt;td align=\"left\"&gt;1,239&lt;/td&gt;\n&lt;td align=\"left\"&gt;1,431&lt;/td&gt;\n&lt;td align=\"left\"&gt;1,559&lt;/td&gt;\n&lt;td align=\"left\"&gt;1,815&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Newsletter open rate (48hrs)&lt;/td&gt;\n&lt;td align=\"left\"&gt;61%&lt;/td&gt;\n&lt;td align=\"left\"&gt;67%&lt;/td&gt;\n&lt;td align=\"left\"&gt;56%&lt;/td&gt;\n&lt;td align=\"left\"&gt;56%&lt;/td&gt;\n&lt;td align=\"left\"&gt;50%&lt;/td&gt;\n&lt;td align=\"left\"&gt;60%&lt;/td&gt;\n&lt;td align=\"left\"&gt;Skipped&lt;/td&gt;\n&lt;td align=\"left\"&gt;53%&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;h1&gt;1. General Observations&lt;/h1&gt;\n\n&lt;p&gt;DataAnalyst.com has been online for just over 8 months, and we&amp;#39;re bringing new, hand curated data analyst jobs onto the site daily - all of them including a salary range.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s now 1,800+ people subscribed to the newsletter, and I can&amp;#39;t thank you enough for your support and for joining us on the journey.&lt;/p&gt;\n\n&lt;h2&gt;First job paid posting&lt;/h2&gt;\n\n&lt;p&gt;To those who monitor the above table closely, you&amp;#39;ve probably noticed the number 1 in the paid posts cell for August.&lt;/p&gt;\n\n&lt;p&gt;Yes, it &lt;strong&gt;&lt;em&gt;only&lt;/em&gt;&lt;/strong&gt; took 7 months and 16 days to get a first paid job posting on the site. Hurray!&lt;/p&gt;\n\n&lt;p&gt;Tualatin Valley Fire &amp;amp; Rescue purchased a fast-track job posting - it came organically, which is a great sign as well.&lt;/p&gt;\n\n&lt;p&gt;It also came in with a lesson learnt - after tweaking flows / forms, always double check that you didn&amp;#39;t leave a bug behind. Unfortunately for me I did, and they couldn&amp;#39;t complete the purchase, but fortunately they reached out and I solved the issue immediately. I&amp;#39;ve also upgraded the posting to a featured one, free of charge - I think this is particularly important.&lt;/p&gt;\n\n&lt;p&gt;Linkedins, Indeeds of the world are too complex to ensure a human connection with each client, while as a solofounder, I want to make sure I go over and beyond each time someone puts trusts in me and the service. That&amp;#39;s something I do believe founders should strive for, and something that will set them apart.&lt;/p&gt;\n\n&lt;h2&gt;Stats - Bounce, numbers, bounce&lt;/h2&gt;\n\n&lt;p&gt;After seeing a massive dip in traffic, apply now clicks and Google impressions in July, looks like August numbers bounced back with vengeance, driven primarily by skyrocketing Google impressions / clicks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d be grateful if someone could please explain to me Google Search Console Clicks vs Google Analytics Visitors - shouldn&amp;#39;t each click that comes from Google Search, leading to the site, also mean that&amp;#39;s a visitor coming in?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Where did 4,421 people come from?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Direct - 51%&lt;/li&gt;\n&lt;li&gt;Organic - 35%&lt;/li&gt;\n&lt;li&gt;Social - 14% (automated job postings on Twitter, Linkedin, Reddit)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;SEO optimisation&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also spent some time over the summer using tools such as SEMRush / Ahrefs / Moz to run some high level audits and understand how the site performs on the SEO front. This led to a lot of time spent on making significant on-page changes to improve keyword optimisation, rewriting meta descriptions and adding alt descriptions to all the images on the site.&lt;/p&gt;\n\n&lt;p&gt;Whether this was something that caused the sudden Google love, I don&amp;#39;t know, but this is probably something that could (and should) have been done a lot earlier. Having said that, it&amp;#39;s now something that I pay attention to with each update that I make on the site.&lt;/p&gt;\n\n&lt;h2&gt;Things on top of my mind&lt;/h2&gt;\n\n&lt;p&gt;&lt;strong&gt;a) Expired Listings&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s feedback regarding some of the jobs on the site already expiring and leading to non-existing listings. Decided to address this in two ways:&lt;/p&gt;\n\n&lt;p&gt;First, I found out Ahrefs has a free &amp;quot;Site Audit&amp;quot; tier, which crawls the whole site and provides a report including all the issues i.e missing alt descriptions, including 404 links.&lt;/p&gt;\n\n&lt;p&gt;Second, on each listing I&amp;#39;ve now included a link for any visitor to report an expiring listing. Hopefully this will improve the experience. I&amp;#39;m still leaving listings (without apply buttons) on the site, so people can see previous open roles and salary ranges.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;b) Outreach&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;One of my main priorities for the coming 3 months is reaching out to organisations hiring data analysts and educating them about the niche job board, and how they can benefit by sharing their opportunities on the site.&lt;/p&gt;\n\n&lt;p&gt;Additionally, I did notice quite a few .edu emails signed up to the Newsletter. This could be an interesting angle to explore, reaching out to universities, sharing that their students are using the site. This could lead to both driving in visitors, as well as potentially getting a backlink that would help increase the authority of the site.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;c) UX/UI&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Lesson learnt - do not use experimental browsers when you try to do website design - I&amp;#39;ve been using Arc browser since the start of the year, with the toolbar being on the left hand side. I&amp;#39;ve recently used various browsers and monitors to see how the site looks on various sizes, and it&amp;#39;s an absolute mess -&amp;gt; will need to dedicate some time to standardize sections and elements, so it&amp;#39;s a more consistent experience.&lt;/p&gt;\n\n&lt;h2&gt;BusinessAnalyst.com&lt;/h2&gt;\n\n&lt;p&gt;As I&amp;#39;ve mentioned before, I recently launched BusinessAnalyst.com - where I&amp;#39;m looking to replicate step by step what I&amp;#39;ve done over the last 8 months with DataAnalyst. The overall idea is to create a network of sites, benefiting from the same infrastructure, serving and helping different career paths, and making a collaboration with organisations much more appealing (afterall, most companies who hire for data analysts also look for business analysts and vice versa). Arguably, this might not make much sense seeing that DA still hasn&amp;#39;t brought any consistent revenue in, but on the other hand, I can reuse the whole tech stack and structures already in place, halve my cost per project, while doubling the surface area to catch me some luck.&lt;/p&gt;\n\n&lt;p&gt;Shared &lt;a href=\"https://www.reddit.com/r/businessanalyst/comments/15r5ecq/businessanalystcom_i_launched_a_niche_job_board/\"&gt;first update&lt;/a&gt; couple of weeks ago - will need to figure out how to combine, if people are interested to see the side by side view. &lt;strong&gt;TLDR: site still dead&lt;/strong&gt;&lt;/p&gt;\n\n&lt;h1&gt;2. &amp;quot;Day in the Life&amp;quot; - a series of interviews with data analysts sharing their experience, thoughts and advice.&lt;/h1&gt;\n\n&lt;p&gt;Another interview from our series has been published. In these interviews, we aim to share stories and experiences about the route to becoming a data analyst, keeping up with the skillset, recommendations to aspiring data analysts and much more.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Alex, who is a BI manager at AWS&lt;/strong&gt;, has shared some fantastic insights, and I&amp;#39;d love to share his  advice on building a portfolio.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;&amp;quot;I&amp;#39;ve been mentoring a few folks on this recently, ranging from college grads to mid-career individuals in non-tech roles. My recommendation to each is to build an end to end portfolio of work. An example is using python to web scrape information from a website and persist to a normalized data structure in a database, using SQL to write queries and analyze that information, and then use Tableau or PowerBI to visualize results and share insights. Each step of this process is important for a rockstar Data Analyst/BI Engineer and will showcase the capability to do the work for hiring managers.&amp;quot;&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;We also briefly cover the question of the Year: Is AI/ChatGPT a threat to data analysts? Highly recommend reading the &lt;a href=\"https://www.dataanalyst.com/blog/alex-my-data-analyst-career-journey\"&gt;full interview&lt;/a&gt;.&lt;/p&gt;\n\n&lt;h1&gt;Things in the pipeline&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;New data analyst jobs, added daily&lt;/li&gt;\n&lt;li&gt;Actually launching the weekly newsletter with the pick of best jobs directly to your inbox (yes, I know....)&lt;/li&gt;\n&lt;li&gt;Monthly US data analyst market insights&lt;/li&gt;\n&lt;li&gt;Improving the overall site experience (this one is a never ending activity)&lt;/li&gt;\n&lt;li&gt;Continuing to bring you Data Analysts across their experience levels, to share tips, tricks and their thoughts&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;3 ways you could help&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Looking for a new challenge? Check out the website - I&amp;#39;m adding new jobs daily&lt;/li&gt;\n&lt;li&gt;Looking to hire a data analyst to your team? Do you know anyone looking to hire? Shoot me a message on Reddit (or [&lt;a href=\"mailto:alex@dataanalyst.com\"&gt;alex@dataanalyst.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:alex@dataanalyst.com\"&gt;alex@dataanalyst.com&lt;/a&gt;)) and I&amp;#39;ll upgrade your first listing for free!&lt;/li&gt;\n&lt;li&gt;As I mentioned, we have an ongoing &amp;quot;Day of a Data Analyst&amp;quot; series. For those of you who are open to do an email based interview about your data analyst career journey, please just send me a message and we&amp;#39;ll organise something - would love to get you featured and share your experience with our readers! Also, as I thank you I will donate to a charity of your choice.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If you have any questions, concerns, come across glitches - please just reach out, happy to chat. Thank you all again, and see you in a month. Alex&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WxM_DJsHZ3lNOr_LxuuckQ5KoqmblmLUQwjfjaF_Xn8.jpg?auto=webp&amp;s=aeb56ba24204e1927f64d082b5cd8418cd9091bb", "width": 2652, "height": 1732}, "resolutions": [{"url": "https://external-preview.redd.it/WxM_DJsHZ3lNOr_LxuuckQ5KoqmblmLUQwjfjaF_Xn8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=67e5ba640e12da2ad8657e576b4ddae36dac10a5", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/WxM_DJsHZ3lNOr_LxuuckQ5KoqmblmLUQwjfjaF_Xn8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc20832dd13fe186530e74f18affd5a8e2e6c45b", "width": 216, "height": 141}, {"url": "https://external-preview.redd.it/WxM_DJsHZ3lNOr_LxuuckQ5KoqmblmLUQwjfjaF_Xn8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dae45cd68327d829d1fc04001a35aec5d0a97664", "width": 320, "height": 208}, {"url": "https://external-preview.redd.it/WxM_DJsHZ3lNOr_LxuuckQ5KoqmblmLUQwjfjaF_Xn8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f8beb7199d1fec8d6f402382f7d8aed4fb40ec1f", "width": 640, "height": 417}, {"url": "https://external-preview.redd.it/WxM_DJsHZ3lNOr_LxuuckQ5KoqmblmLUQwjfjaF_Xn8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8977d5c0ea99897b6fdcfd1620b6fbb813547a60", "width": 960, "height": 626}, {"url": "https://external-preview.redd.it/WxM_DJsHZ3lNOr_LxuuckQ5KoqmblmLUQwjfjaF_Xn8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dafca3e625c90a4cdcba287b2c97d52bcfa517cd", "width": 1080, "height": 705}], "variants": {}, "id": "gl1D342pNcpBnIbm1qlopzaQaS6Cq86ueQdJblEGNmM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16ap9p8", "is_robot_indexable": true, "report_reasons": null, "author": "kirilale", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16ap9p8/dataanalystcom_i_launched_a_niche_job_board_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16ap9p8/dataanalystcom_i_launched_a_niche_job_board_with/", "subreddit_subscribers": 1032518, "created_utc": 1693922869.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Every time I've tested a SQL query and realized that some null somewhere broke my CONCAT statement, or run an R script and realized that I forgot to add \"na.rm = TRUE\" to a function somewhere, I wonder what was going through the development team's minds when they decided to build these tools these ways.\n\nWhy isn't ignoring nulls the default behavior?\n\nGenuinely curious if there's a logic to this that I haven't considered.", "author_fullname": "t2_bxdnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELI5: Why are nulls not ignored by default?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16al6h4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693911891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Every time I&amp;#39;ve tested a SQL query and realized that some null somewhere broke my CONCAT statement, or run an R script and realized that I forgot to add &amp;quot;na.rm = TRUE&amp;quot; to a function somewhere, I wonder what was going through the development team&amp;#39;s minds when they decided to build these tools these ways.&lt;/p&gt;\n\n&lt;p&gt;Why isn&amp;#39;t ignoring nulls the default behavior?&lt;/p&gt;\n\n&lt;p&gt;Genuinely curious if there&amp;#39;s a logic to this that I haven&amp;#39;t considered.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16al6h4", "is_robot_indexable": true, "report_reasons": null, "author": "takenorinvalid", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16al6h4/eli5_why_are_nulls_not_ignored_by_default/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16al6h4/eli5_why_are_nulls_not_ignored_by_default/", "subreddit_subscribers": 1032518, "created_utc": 1693911891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data science hobby projects I've built so far:\n\n\ud83c\udfda 2012 - \"Rent Scraper\" \u2014 A tool to find me the cheapest apartment to rent by scraping several websites every minute. (Bash, Python)\n\n\ud83d\uddde 2013 - \"Prionews\" \u2014 A system to summarize daily news in an unbiased manner. (Bash, SQL, Python)\n\n\ud83e\udd16 2014 - \"Jarvic\" \u2014 A self-learning chatbot. (Python)\n\n\ud83c\udfa8 2015 - \"Write-Here-Anything\" \u2014 A hard-to-describe website and art project. (JavaScript)\n\n\ud83c\udf10 2016 - \"Learn-Languages\" \u2014 A simple script that prints the top 1,000 most important words to learn in any language, based on the script of the Friends TV show. (Python)\n\n\ud83d\udda5 2017 - \"User-Generator\" \u2014 A Python script that simulates log/data creation for a mobile app, intended for educational purposes. (Python)\n\n\ud83d\udc6c 2018 - \"A/B Testing Redirect\" \u2014 Code to implement an A/B test without using third-party tools. (JavaScript + Python)\n\n\ud83d\udcc8 2019 - \"Simple User Log\" \u2014 A basic analytics tool designed to replace Google Analytics. (JavaScript + Python + Flask)\n\n\ud83d\udc68\u200d\ud83c\udfeb 2020 - \"Best Bet\" \u2014 A game that educates people about the concept of \"expected value.\" (Python + Flask + HTML)\n\n\u2618 2021 - \"Automated Gardener\" \u2014 A hardware project that automatically takes care of my plants. (Python + Bash + Raspberry Pi)\n\n\ud83d\udcb0 2022 - \"BitPanda\\_DCA\" \u2014 A simple automation tool that performs dollar-cost averaging on the Bitpanda platform for me. (Python + Bash)\n\n\ud83e\udd43 2023 - \"WhiskyReturns\" \u2014 A platform that collects data on whisky investments and displays them in a simple chart. (Python, Bash, SQL, HTML, APIs, etc.)\n\nMost of these projects are retired and offline, but they've been invaluable in teaching me about data science and coding. Building a hobby project is never a waste of time. You should start yours!", "author_fullname": "t2_11i3en", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My Last Decade of Data Science Hobby Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16aid9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693902224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data science hobby projects I&amp;#39;ve built so far:&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udfda 2012 - &amp;quot;Rent Scraper&amp;quot; \u2014 A tool to find me the cheapest apartment to rent by scraping several websites every minute. (Bash, Python)&lt;/p&gt;\n\n&lt;p&gt;\ud83d\uddde 2013 - &amp;quot;Prionews&amp;quot; \u2014 A system to summarize daily news in an unbiased manner. (Bash, SQL, Python)&lt;/p&gt;\n\n&lt;p&gt;\ud83e\udd16 2014 - &amp;quot;Jarvic&amp;quot; \u2014 A self-learning chatbot. (Python)&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udfa8 2015 - &amp;quot;Write-Here-Anything&amp;quot; \u2014 A hard-to-describe website and art project. (JavaScript)&lt;/p&gt;\n\n&lt;p&gt;\ud83c\udf10 2016 - &amp;quot;Learn-Languages&amp;quot; \u2014 A simple script that prints the top 1,000 most important words to learn in any language, based on the script of the Friends TV show. (Python)&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udda5 2017 - &amp;quot;User-Generator&amp;quot; \u2014 A Python script that simulates log/data creation for a mobile app, intended for educational purposes. (Python)&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc6c 2018 - &amp;quot;A/B Testing Redirect&amp;quot; \u2014 Code to implement an A/B test without using third-party tools. (JavaScript + Python)&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcc8 2019 - &amp;quot;Simple User Log&amp;quot; \u2014 A basic analytics tool designed to replace Google Analytics. (JavaScript + Python + Flask)&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udc68\u200d\ud83c\udfeb 2020 - &amp;quot;Best Bet&amp;quot; \u2014 A game that educates people about the concept of &amp;quot;expected value.&amp;quot; (Python + Flask + HTML)&lt;/p&gt;\n\n&lt;p&gt;\u2618 2021 - &amp;quot;Automated Gardener&amp;quot; \u2014 A hardware project that automatically takes care of my plants. (Python + Bash + Raspberry Pi)&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcb0 2022 - &amp;quot;BitPanda_DCA&amp;quot; \u2014 A simple automation tool that performs dollar-cost averaging on the Bitpanda platform for me. (Python + Bash)&lt;/p&gt;\n\n&lt;p&gt;\ud83e\udd43 2023 - &amp;quot;WhiskyReturns&amp;quot; \u2014 A platform that collects data on whisky investments and displays them in a simple chart. (Python, Bash, SQL, HTML, APIs, etc.)&lt;/p&gt;\n\n&lt;p&gt;Most of these projects are retired and offline, but they&amp;#39;ve been invaluable in teaching me about data science and coding. Building a hobby project is never a waste of time. You should start yours!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16aid9m", "is_robot_indexable": true, "report_reasons": null, "author": "mestitomi", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16aid9m/my_last_decade_of_data_science_hobby_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16aid9m/my_last_decade_of_data_science_hobby_projects/", "subreddit_subscribers": 1032518, "created_utc": 1693902224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a data science major with aspirations to be focused in software development/engineering and I\u2019m curious how useful calculus is. In my coding experience, about 6 years, I haven\u2019t needed calculus all that much, maybe a couple functions but nothing that an entire calculus course become necessary. I\u2019m asking those who are in the data science field, how used are topics of higher-end math such as calculus or similar fields?", "author_fullname": "t2_pdihfw8m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How useful is this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16augbu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693935005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data science major with aspirations to be focused in software development/engineering and I\u2019m curious how useful calculus is. In my coding experience, about 6 years, I haven\u2019t needed calculus all that much, maybe a couple functions but nothing that an entire calculus course become necessary. I\u2019m asking those who are in the data science field, how used are topics of higher-end math such as calculus or similar fields?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16augbu", "is_robot_indexable": true, "report_reasons": null, "author": "BottomLegPit", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16augbu/how_useful_is_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16augbu/how_useful_is_this/", "subreddit_subscribers": 1032518, "created_utc": 1693935005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! I am 29, working at a Fortune 50 company in their modeling department, making decent money for a MCOL area. Recently I have realized, big job title, really high compensation doesn\u2019t really motivate me anymore. I still want to switch jobs and try to work on different kind of things but work life balance and healthy work environment has started to become number 1 priority for me. So much so that when I look for job after the current one, I am not willing to compromise my wlb despite the money. One of the reasons, it\u2019s getting difficult for me to think about switching jobs since the current one is the ideal job for me. \n\nI am sharing this to understand if I ma doing something really wrong and could be a career suicide. What do you guys think? Can I keep increasing my TC while having WLB?\n\nThanks!", "author_fullname": "t2_bv171ji2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I setting myself for an unsuccessful career if I have no motivation to climb the corporate ladder?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16b194c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693950256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I am 29, working at a Fortune 50 company in their modeling department, making decent money for a MCOL area. Recently I have realized, big job title, really high compensation doesn\u2019t really motivate me anymore. I still want to switch jobs and try to work on different kind of things but work life balance and healthy work environment has started to become number 1 priority for me. So much so that when I look for job after the current one, I am not willing to compromise my wlb despite the money. One of the reasons, it\u2019s getting difficult for me to think about switching jobs since the current one is the ideal job for me. &lt;/p&gt;\n\n&lt;p&gt;I am sharing this to understand if I ma doing something really wrong and could be a career suicide. What do you guys think? Can I keep increasing my TC while having WLB?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16b194c", "is_robot_indexable": true, "report_reasons": null, "author": "quite--average", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16b194c/am_i_setting_myself_for_an_unsuccessful_career_if/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16b194c/am_i_setting_myself_for_an_unsuccessful_career_if/", "subreddit_subscribers": 1032518, "created_utc": 1693950256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have read about renewable energy supply and energy demand forecasting. However, they are usually done separately. I am wondering if it makes sense to predict both. For instance, our university campus uses solar energy and fossil fuel energy (connected to the national grid). I want to predict the solar energy supply to see if it will be able to match the demand by itself (for instance, if it's intended for the lights of one building, if it will be able to supply that), but at the same time I want to predict the demand based on occupancy, etc. Has this been done before? Will this propagate errors? Thank you very much.", "author_fullname": "t2_81iatgrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predicting both energy supply and demand in a university campus using hybrid energy source", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ac8uc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693885013.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693882320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have read about renewable energy supply and energy demand forecasting. However, they are usually done separately. I am wondering if it makes sense to predict both. For instance, our university campus uses solar energy and fossil fuel energy (connected to the national grid). I want to predict the solar energy supply to see if it will be able to match the demand by itself (for instance, if it&amp;#39;s intended for the lights of one building, if it will be able to supply that), but at the same time I want to predict the demand based on occupancy, etc. Has this been done before? Will this propagate errors? Thank you very much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16ac8uc", "is_robot_indexable": true, "report_reasons": null, "author": "severinseverine", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16ac8uc/predicting_both_energy_supply_and_demand_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16ac8uc/predicting_both_energy_supply_and_demand_in_a/", "subreddit_subscribers": 1032518, "created_utc": 1693882320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI recently created a CLI that lets you compile Jupyter notebooks into FastAPI apps. \n\nIt let\u2019s you write comments like \u201c\u201d\u201d@HTTP\u201d\u201d\u201d, \u201c\u201d\u201d@WS\u201d\u201d\u201d, and \u201c\u201d\u201d@SCHEDULE\u201d\u201d\u201d\u201d to expose your cells as http or websockets endpoints, or programmatically run your cells as scheduled time intervals for simple data pipelines.\n\nIt creates a /build folder with your dockerized code for easy running and deployment.\n\nhttps://github.com/neutrino-ai/neutrino-notebooks\n\nHope you find this helpful! I would appreciate any feedback", "author_fullname": "t2_2rm8fild", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A CLI that turns notebooks into FastAPI apps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16arf00", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693928015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I recently created a CLI that lets you compile Jupyter notebooks into FastAPI apps. &lt;/p&gt;\n\n&lt;p&gt;It let\u2019s you write comments like \u201c\u201d\u201d@HTTP\u201d\u201d\u201d, \u201c\u201d\u201d@WS\u201d\u201d\u201d, and \u201c\u201d\u201d@SCHEDULE\u201d\u201d\u201d\u201d to expose your cells as http or websockets endpoints, or programmatically run your cells as scheduled time intervals for simple data pipelines.&lt;/p&gt;\n\n&lt;p&gt;It creates a /build folder with your dockerized code for easy running and deployment.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/neutrino-ai/neutrino-notebooks\"&gt;https://github.com/neutrino-ai/neutrino-notebooks&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hope you find this helpful! I would appreciate any feedback&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?auto=webp&amp;s=5394e103b0086b4eff4d06568f294956507f0ecb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=43271c21e8a34542bc37693cfaf1dbacc436d23f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9701d58c16fd8ce19979b7db2dc7bdd8c459dd59", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=711a7236b9019520b595a3090b2f212b668efe75", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=03ab1ab20ef97b7eff2703ac8562037562678684", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=97db8e91a7af642bc87a0d9454c87ad4c0286dac", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/U8HOVmKOl15s3KWQoR3bZ3AKGrjeypS2GMMZx8AnwaU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ec562818e6bf8236d636bae3338627ea6dfd4584", "width": 1080, "height": 540}], "variants": {}, "id": "h0H4QH_NNA8eb-artCZYZeYRXgCLX9TCOO7CamwnaCk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16arf00", "is_robot_indexable": true, "report_reasons": null, "author": "gibbybutwithrandck", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16arf00/a_cli_that_turns_notebooks_into_fastapi_apps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16arf00/a_cli_that_turns_notebooks_into_fastapi_apps/", "subreddit_subscribers": 1032518, "created_utc": 1693928015.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently practicing building models and was doing EDA where I am trying to plot scatter plots between variables in my dataset related to music genre classification. But I am unable to interpret these scatterplots like what these mean really. Till now I have seen very straightforward plots, but I am having a hard time with these.\n\nAbout the dataset: It has \\~18k records, 16 features and is a multi-class classification problem having 11 classes.\n\n[Plot - 1](https://preview.redd.it/fxpc9secwbmb1.png?width=569&amp;format=png&amp;auto=webp&amp;s=a59bc947af87b3bbcb5cc16567d389356884f4f9)\n\n[Plot-2](https://preview.redd.it/69d2rmxfwbmb1.png?width=575&amp;format=png&amp;auto=webp&amp;s=7e2eefa0215641ce19dc5be789475a8e1427cacf)\n\n[Plot-3](https://preview.redd.it/mvyvf64iwbmb1.png?width=582&amp;format=png&amp;auto=webp&amp;s=7dfe3529ac34cd854c548995beb38a93ed3df7ca)\n\n[Plot-4](https://preview.redd.it/7dk8geqkwbmb1.png?width=579&amp;format=png&amp;auto=webp&amp;s=16f828cb24ff98b68fbce7eab10cd164de6ac24e)\n\n[Plot - 5](https://preview.redd.it/ndi2kihnwbmb1.png?width=566&amp;format=png&amp;auto=webp&amp;s=28ed459af4008055d5adb79b10ea0aab23322b4b)", "author_fullname": "t2_4n24sb1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help interpreting scatter plots that I am getting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 112, "top_awarded_type": null, "hide_score": false, "media_metadata": {"mvyvf64iwbmb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 84, "x": 108, "u": "https://preview.redd.it/mvyvf64iwbmb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=40b1c7b08515f703d76d3b0c3d74adda95f65835"}, {"y": 168, "x": 216, "u": "https://preview.redd.it/mvyvf64iwbmb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2b6237dae5b322f61bd086b996a9d50211082091"}, {"y": 249, "x": 320, "u": "https://preview.redd.it/mvyvf64iwbmb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ecd27ff8cb528b043403c4b8a06b462abe4aa026"}], "s": {"y": 454, "x": 582, "u": "https://preview.redd.it/mvyvf64iwbmb1.png?width=582&amp;format=png&amp;auto=webp&amp;s=7dfe3529ac34cd854c548995beb38a93ed3df7ca"}, "id": "mvyvf64iwbmb1"}, "7dk8geqkwbmb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 85, "x": 108, "u": "https://preview.redd.it/7dk8geqkwbmb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=854cc4caf2e7ec13ff76e50e2899c4e5064d1c3b"}, {"y": 170, "x": 216, "u": "https://preview.redd.it/7dk8geqkwbmb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4698b506ea1ea0ff45539d9dd93a9a161b418b39"}, {"y": 252, "x": 320, "u": "https://preview.redd.it/7dk8geqkwbmb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=698ef9fe64deadff7b3799b625fe8b60e58f68c5"}], "s": {"y": 456, "x": 579, "u": "https://preview.redd.it/7dk8geqkwbmb1.png?width=579&amp;format=png&amp;auto=webp&amp;s=16f828cb24ff98b68fbce7eab10cd164de6ac24e"}, "id": "7dk8geqkwbmb1"}, "fxpc9secwbmb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 86, "x": 108, "u": "https://preview.redd.it/fxpc9secwbmb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1defb5b6fcf9344ebcb48a7318362964efac3b98"}, {"y": 173, "x": 216, "u": "https://preview.redd.it/fxpc9secwbmb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac46a3e67e642e5c4a178298d0e5c76d6cfa91e2"}, {"y": 257, "x": 320, "u": "https://preview.redd.it/fxpc9secwbmb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e672cc7366d48988e535e7a734a509d7a04e8e05"}], "s": {"y": 458, "x": 569, "u": "https://preview.redd.it/fxpc9secwbmb1.png?width=569&amp;format=png&amp;auto=webp&amp;s=a59bc947af87b3bbcb5cc16567d389356884f4f9"}, "id": "fxpc9secwbmb1"}, "69d2rmxfwbmb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 85, "x": 108, "u": "https://preview.redd.it/69d2rmxfwbmb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b63a4b24c1292b9bd9dfcdc26b644351d437a6c"}, {"y": 171, "x": 216, "u": "https://preview.redd.it/69d2rmxfwbmb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9e8990c985d6019dbfc85f53bc2e1da8c9ffcf02"}, {"y": 253, "x": 320, "u": "https://preview.redd.it/69d2rmxfwbmb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a2053d38d63a549b4de396e5fe078b61fb1738eb"}], "s": {"y": 456, "x": 575, "u": "https://preview.redd.it/69d2rmxfwbmb1.png?width=575&amp;format=png&amp;auto=webp&amp;s=7e2eefa0215641ce19dc5be789475a8e1427cacf"}, "id": "69d2rmxfwbmb1"}, "ndi2kihnwbmb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 87, "x": 108, "u": "https://preview.redd.it/ndi2kihnwbmb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=53014e97629b280117079bbe3588a4a11fffb587"}, {"y": 174, "x": 216, "u": "https://preview.redd.it/ndi2kihnwbmb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ccbf293f126596eb8be3ab24b55a60ff072f5e01"}, {"y": 258, "x": 320, "u": "https://preview.redd.it/ndi2kihnwbmb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5bde5fb8ee2043f201b15ee825807103cfdeff11"}], "s": {"y": 458, "x": 566, "u": "https://preview.redd.it/ndi2kihnwbmb1.png?width=566&amp;format=png&amp;auto=webp&amp;s=28ed459af4008055d5adb79b10ea0aab23322b4b"}, "id": "ndi2kihnwbmb1"}}, "name": "t3_16a8p96", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/tSVbSLCjHnDzAXnHx5Ms6zpByVgmNwHbJUALLejILp0.jpg", "edited": 1693873037.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693872633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently practicing building models and was doing EDA where I am trying to plot scatter plots between variables in my dataset related to music genre classification. But I am unable to interpret these scatterplots like what these mean really. Till now I have seen very straightforward plots, but I am having a hard time with these.&lt;/p&gt;\n\n&lt;p&gt;About the dataset: It has ~18k records, 16 features and is a multi-class classification problem having 11 classes.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/fxpc9secwbmb1.png?width=569&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a59bc947af87b3bbcb5cc16567d389356884f4f9\"&gt;Plot - 1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/69d2rmxfwbmb1.png?width=575&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7e2eefa0215641ce19dc5be789475a8e1427cacf\"&gt;Plot-2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/mvyvf64iwbmb1.png?width=582&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7dfe3529ac34cd854c548995beb38a93ed3df7ca\"&gt;Plot-3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7dk8geqkwbmb1.png?width=579&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=16f828cb24ff98b68fbce7eab10cd164de6ac24e\"&gt;Plot-4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ndi2kihnwbmb1.png?width=566&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=28ed459af4008055d5adb79b10ea0aab23322b4b\"&gt;Plot - 5&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16a8p96", "is_robot_indexable": true, "report_reasons": null, "author": "ProfessorS11", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16a8p96/help_interpreting_scatter_plots_that_i_am_getting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16a8p96/help_interpreting_scatter_plots_that_i_am_getting/", "subreddit_subscribers": 1032518, "created_utc": 1693872633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My job responsibilities are way below my skill level so I\u2019m losing motivation to keep learning. Job hoping doesn\u2019t fix this as every job is underwhelming.", "author_fullname": "t2_kcl3tfwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle burnout?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16azemj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693946296.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My job responsibilities are way below my skill level so I\u2019m losing motivation to keep learning. Job hoping doesn\u2019t fix this as every job is underwhelming.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16azemj", "is_robot_indexable": true, "report_reasons": null, "author": "NewEcho2940", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16azemj/how_do_you_handle_burnout/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16azemj/how_do_you_handle_burnout/", "subreddit_subscribers": 1032518, "created_utc": 1693946296.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is a word cloud (See picture), and it gives an idea of what the most common words are in a string.\n\nI want to get a quantified version of this, i.e. 20% of people think knowledge is important. However, I also want to automatically make synonyms equal. i.e.  quick = fast, bad = horrible. At the end of the day, I want to get a breakdown of what a group of people are saying.\n\nhttps://preview.redd.it/bqixl7289fmb1.jpg?width=927&amp;format=pjpg&amp;auto=webp&amp;s=eee160f4f117c15a9afae83baa1bf9a092f069f5\n\nI'm sure there are existing techniques/ libraries out there to do this. Any thoughts?", "author_fullname": "t2_vmnhefbj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting insights from word clouds? (Sentiment Analysis)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "media_metadata": {"bqixl7289fmb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/bqixl7289fmb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a4f3319cbcb0979b9772f8fdea66e389402f69fe"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/bqixl7289fmb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7dbd1831d19b90ec6155b5ab9f2979226da87478"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/bqixl7289fmb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e688671c20eb4678ed9ca1b66574c20b8ab22af2"}, {"y": 357, "x": 640, "u": "https://preview.redd.it/bqixl7289fmb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=606bc880bcfc4ac63ad9471f378c6c6ff486b0bc"}], "s": {"y": 518, "x": 927, "u": "https://preview.redd.it/bqixl7289fmb1.jpg?width=927&amp;format=pjpg&amp;auto=webp&amp;s=eee160f4f117c15a9afae83baa1bf9a092f069f5"}, "id": "bqixl7289fmb1"}}, "name": "t3_16akhq4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CgLVIijj4i-Qzkq-Jfex_U9OGvSnLaiqSrFCzBys2Pc.jpg", "edited": 1693913066.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693909596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a word cloud (See picture), and it gives an idea of what the most common words are in a string.&lt;/p&gt;\n\n&lt;p&gt;I want to get a quantified version of this, i.e. 20% of people think knowledge is important. However, I also want to automatically make synonyms equal. i.e.  quick = fast, bad = horrible. At the end of the day, I want to get a breakdown of what a group of people are saying.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bqixl7289fmb1.jpg?width=927&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=eee160f4f117c15a9afae83baa1bf9a092f069f5\"&gt;https://preview.redd.it/bqixl7289fmb1.jpg?width=927&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=eee160f4f117c15a9afae83baa1bf9a092f069f5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure there are existing techniques/ libraries out there to do this. Any thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16akhq4", "is_robot_indexable": true, "report_reasons": null, "author": "tootieloolie", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16akhq4/getting_insights_from_word_clouds_sentiment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16akhq4/getting_insights_from_word_clouds_sentiment/", "subreddit_subscribers": 1032518, "created_utc": 1693909596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently we are discussing having a data science monorepo in our company as it will insure consistency in the deployment pipelines and it will make sharing files between projects easier.  \n\n\nHowever, we are concerned about one point, each data science project needs a lot of iterations and experiments to reach its final form. If the experiments and jupyter notebooks of all projects lie in the same repo, we are afraid it may make the repo heavy for cloning and laggy when working with it.   \n\n\nDo you think these concerns are valid? what is your experience with working with data science monorepos?", "author_fullname": "t2_42ammirh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "a question about having a monorepo for data science projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ajc39", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693905717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently we are discussing having a data science monorepo in our company as it will insure consistency in the deployment pipelines and it will make sharing files between projects easier.  &lt;/p&gt;\n\n&lt;p&gt;However, we are concerned about one point, each data science project needs a lot of iterations and experiments to reach its final form. If the experiments and jupyter notebooks of all projects lie in the same repo, we are afraid it may make the repo heavy for cloning and laggy when working with it.   &lt;/p&gt;\n\n&lt;p&gt;Do you think these concerns are valid? what is your experience with working with data science monorepos?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16ajc39", "is_robot_indexable": true, "report_reasons": null, "author": "GreyWardenMage", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16ajc39/a_question_about_having_a_monorepo_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16ajc39/a_question_about_having_a_monorepo_for_data/", "subreddit_subscribers": 1032518, "created_utc": 1693905717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Totally Confused about what to do next, Career HELP\n\nI'm working in ml/dl/data science  field previously on applied domain now working in the same domain but instead of applied working on its software stack.\n\nI am unable to figure out what i really like\n\nI'm working in ml/dl/data science  field previously on applied domain now working in the same domain but instead of applied working on its software stack.\n\nI am unable to figure out what i really like\nAreas towards which i'm biased are\n 1. HPC with a focus on ML application.\n2. ML research. \n3. Applied ml.\n\nAlso i am constantly in loop of not getting satisfaction at a job role neither getting a good mentor either at job or in open source community.\n\nThis constant dilemma makes me applying to jobs again and again hearing nothing from the ones i really like, I'm trapped in a cycle of overthinking doing nothing but feeling like i will not be able to do anything.\n\nI need guidance i need some paths some light from experienced or who have gone through the same.\n\nNOT sure to how many people this tweet will reach and how many will respond to it but if you come across this tweet and you have an idea about the same, please HELP.\n\nI want to work in the research labs or in an environment where i can grow through mentorship but seems like i made a wrong switch and here things are not what i thought it would be like. \n\nWithout phd the big research labs seems unreachable slowly i'm losing hope and feels like will be trapped in a job and eventually in a role that i do not like.", "author_fullname": "t2_a5kzhn7l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Totally Confused about what to do next", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16afsb0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693893206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Totally Confused about what to do next, Career HELP&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working in ml/dl/data science  field previously on applied domain now working in the same domain but instead of applied working on its software stack.&lt;/p&gt;\n\n&lt;p&gt;I am unable to figure out what i really like&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working in ml/dl/data science  field previously on applied domain now working in the same domain but instead of applied working on its software stack.&lt;/p&gt;\n\n&lt;p&gt;I am unable to figure out what i really like\nAreas towards which i&amp;#39;m biased are\n 1. HPC with a focus on ML application.\n2. ML research. \n3. Applied ml.&lt;/p&gt;\n\n&lt;p&gt;Also i am constantly in loop of not getting satisfaction at a job role neither getting a good mentor either at job or in open source community.&lt;/p&gt;\n\n&lt;p&gt;This constant dilemma makes me applying to jobs again and again hearing nothing from the ones i really like, I&amp;#39;m trapped in a cycle of overthinking doing nothing but feeling like i will not be able to do anything.&lt;/p&gt;\n\n&lt;p&gt;I need guidance i need some paths some light from experienced or who have gone through the same.&lt;/p&gt;\n\n&lt;p&gt;NOT sure to how many people this tweet will reach and how many will respond to it but if you come across this tweet and you have an idea about the same, please HELP.&lt;/p&gt;\n\n&lt;p&gt;I want to work in the research labs or in an environment where i can grow through mentorship but seems like i made a wrong switch and here things are not what i thought it would be like. &lt;/p&gt;\n\n&lt;p&gt;Without phd the big research labs seems unreachable slowly i&amp;#39;m losing hope and feels like will be trapped in a job and eventually in a role that i do not like.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16afsb0", "is_robot_indexable": true, "report_reasons": null, "author": "Frosty_Work4827", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16afsb0/totally_confused_about_what_to_do_next/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16afsb0/totally_confused_about_what_to_do_next/", "subreddit_subscribers": 1032518, "created_utc": 1693893206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI hope you're all doing well. I'm a passionate student currently studying Data Science at UBC and deeply interested in the field of data science. As an international student in Canada, I'm actively searching for summer 2024 internships both in data science and data analyitcs. While I've noticed a few opportunities available for the winter term (January - April 2024), there seems to be a shortage of them compared to other countries. In contrast, I've observed that other countries have already posted job opportunities for summer 2024. Furthermore, I've noticed a significant disparity between the number of opportunities available in Canada and those in other countries, particularly in the U.S. and the U.K. Despite these countries offering numerous positions, I'm encountering challenges in finding similar opportunities within Canada.\n\nGiven the growth and demand for data science, I would have expected to see more internship roles pop up, especially in tech hubs like Toronto, Vancouver, or Montreal. Does anyone have any insights into why this might be the case? Are Canadian companies just not as into hiring interns for data science roles?\n\nTo provide some context, I've attached my resume here: [My Resume](https://imgur.com/a/wbaou9x).\n\nI'm genuinely open to all forms of advice. Whether you have suggestions for improving my resume, insights into places to search for internships, or recommendations for networking opportunities, I would sincerely appreciate your assistance. If you happen to be a recruiter or a data science professional based in Canada, I'm eagerly looking forward to hearing your thoughts.\n\nThank you for taking the time to read this, and I'm excitedly anticipating responses from this incredible community!", "author_fullname": "t2_9spnm15l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Data Science Internships in Canada for Next Summer - Where Are They?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a7vbp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693870486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all doing well. I&amp;#39;m a passionate student currently studying Data Science at UBC and deeply interested in the field of data science. As an international student in Canada, I&amp;#39;m actively searching for summer 2024 internships both in data science and data analyitcs. While I&amp;#39;ve noticed a few opportunities available for the winter term (January - April 2024), there seems to be a shortage of them compared to other countries. In contrast, I&amp;#39;ve observed that other countries have already posted job opportunities for summer 2024. Furthermore, I&amp;#39;ve noticed a significant disparity between the number of opportunities available in Canada and those in other countries, particularly in the U.S. and the U.K. Despite these countries offering numerous positions, I&amp;#39;m encountering challenges in finding similar opportunities within Canada.&lt;/p&gt;\n\n&lt;p&gt;Given the growth and demand for data science, I would have expected to see more internship roles pop up, especially in tech hubs like Toronto, Vancouver, or Montreal. Does anyone have any insights into why this might be the case? Are Canadian companies just not as into hiring interns for data science roles?&lt;/p&gt;\n\n&lt;p&gt;To provide some context, I&amp;#39;ve attached my resume here: &lt;a href=\"https://imgur.com/a/wbaou9x\"&gt;My Resume&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m genuinely open to all forms of advice. Whether you have suggestions for improving my resume, insights into places to search for internships, or recommendations for networking opportunities, I would sincerely appreciate your assistance. If you happen to be a recruiter or a data science professional based in Canada, I&amp;#39;m eagerly looking forward to hearing your thoughts.&lt;/p&gt;\n\n&lt;p&gt;Thank you for taking the time to read this, and I&amp;#39;m excitedly anticipating responses from this incredible community!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/a7LdhvJxmzMeGhI49j-G8TML_GZeOVmaycB4-srGic0.jpg?auto=webp&amp;s=0967049f2e0f222e46890bb81b2d188e045c40b4", "width": 1082, "height": 1398}, "resolutions": [{"url": "https://external-preview.redd.it/a7LdhvJxmzMeGhI49j-G8TML_GZeOVmaycB4-srGic0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1dae8bf11353fb6e459c6f17ec8bbb87c1db69ac", "width": 108, "height": 139}, {"url": "https://external-preview.redd.it/a7LdhvJxmzMeGhI49j-G8TML_GZeOVmaycB4-srGic0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d82d6e744af76fb0b76765c85d8f44f853413da", "width": 216, "height": 279}, {"url": "https://external-preview.redd.it/a7LdhvJxmzMeGhI49j-G8TML_GZeOVmaycB4-srGic0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1c3665d9e4ed0dbc3a924a63c376f62f1d28dfd", "width": 320, "height": 413}, {"url": "https://external-preview.redd.it/a7LdhvJxmzMeGhI49j-G8TML_GZeOVmaycB4-srGic0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c9c390965ab0f5921b08ef486d62bf1adb0a33a", "width": 640, "height": 826}, {"url": "https://external-preview.redd.it/a7LdhvJxmzMeGhI49j-G8TML_GZeOVmaycB4-srGic0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5673f67ce9bb2ed50f6a7f2f09c9b02966df043a", "width": 960, "height": 1240}, {"url": "https://external-preview.redd.it/a7LdhvJxmzMeGhI49j-G8TML_GZeOVmaycB4-srGic0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e31f7a552cda14630632e33057431a85ae0c580d", "width": 1080, "height": 1395}], "variants": {}, "id": "fwb27YxY95wyfAyxBzoaIAVUmP2eetwrABKFrZkej6s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16a7vbp", "is_robot_indexable": true, "report_reasons": null, "author": "Elegant_Bad1311", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16a7vbp/looking_for_data_science_internships_in_canada/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16a7vbp/looking_for_data_science_internships_in_canada/", "subreddit_subscribers": 1032518, "created_utc": 1693870486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey data friends\u00a0\ud83d\udc4b\n\n  \nI'm super excited to to share a preview of some new stuff I'm working on: \u2728\u00a0Turntable Discover \u2728\n\nData teams struggle to keep their documentation up to date and actionable. Today they have to stitch together Notion docs, lineage tools, yaml / markdown files and maintain jobs to generate it.\n\nWe\u2019ve built a seamless way to ingest, discover, and share your warehouse's documentation all in one place. Discover is integrated with Github and dbt core, so you can get setup with a magical docs experience in only a few minutes including:\n\n\u26a1\ufe0f Super fast search - search across table names, column, descriptions and canonical sql to find the data you're looking for\n\n\u2728\ufe0f AI-powered semantic search - can't find a substring query that matches? Use semantic search to find data models that are tricky to find (ex: \"reps\" -&gt; \"sales people\")\n\n\ud83d\udd2cColumn-level lineage view - trace back the origins of a particular column and navigate across models with an inline column level lineage view\n\n\ud83d\udd17\u00a0One-click sharing - share documentation in one click with other teammates on the same OAuth domain\n\nWe\u2019re giving Discover to select teams in a private beta before rolling it out broadly. If you\u2019d like to try it out, you can DM, comment below, or sign up on our waitlist ([turntable.so](http://turntable.so/)) Looking forward to hearing your feedback \ud83d\ude4c\n\n&amp;#x200B;\n\nCheck out a quick demo of how it works here:\n\n[https://www.youtube.com/watch?v=sY0NefWRpKQ](https://www.youtube.com/watch?v=sY0NefWRpKQ)", "author_fullname": "t2_esppz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A fast, AI-powered data catalog for dbt Core", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16b1mnq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693951094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey data friends\u00a0\ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m super excited to to share a preview of some new stuff I&amp;#39;m working on: \u2728\u00a0Turntable Discover \u2728&lt;/p&gt;\n\n&lt;p&gt;Data teams struggle to keep their documentation up to date and actionable. Today they have to stitch together Notion docs, lineage tools, yaml / markdown files and maintain jobs to generate it.&lt;/p&gt;\n\n&lt;p&gt;We\u2019ve built a seamless way to ingest, discover, and share your warehouse&amp;#39;s documentation all in one place. Discover is integrated with Github and dbt core, so you can get setup with a magical docs experience in only a few minutes including:&lt;/p&gt;\n\n&lt;p&gt;\u26a1\ufe0f Super fast search - search across table names, column, descriptions and canonical sql to find the data you&amp;#39;re looking for&lt;/p&gt;\n\n&lt;p&gt;\u2728\ufe0f AI-powered semantic search - can&amp;#39;t find a substring query that matches? Use semantic search to find data models that are tricky to find (ex: &amp;quot;reps&amp;quot; -&amp;gt; &amp;quot;sales people&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd2cColumn-level lineage view - trace back the origins of a particular column and navigate across models with an inline column level lineage view&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd17\u00a0One-click sharing - share documentation in one click with other teammates on the same OAuth domain&lt;/p&gt;\n\n&lt;p&gt;We\u2019re giving Discover to select teams in a private beta before rolling it out broadly. If you\u2019d like to try it out, you can DM, comment below, or sign up on our waitlist (&lt;a href=\"http://turntable.so/\"&gt;turntable.so&lt;/a&gt;) Looking forward to hearing your feedback \ud83d\ude4c&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Check out a quick demo of how it works here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=sY0NefWRpKQ\"&gt;https://www.youtube.com/watch?v=sY0NefWRpKQ&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16b1mnq", "is_robot_indexable": true, "report_reasons": null, "author": "StartCompaniesNotWar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16b1mnq/a_fast_aipowered_data_catalog_for_dbt_core/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16b1mnq/a_fast_aipowered_data_catalog_for_dbt_core/", "subreddit_subscribers": 1032518, "created_utc": 1693951094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Ever wondered about the potential of R for diverse applications beyond statistics? Rafael Camargo, a Spatial Data Scientist at Quantis, deeply delves into Berlin's flourishing R User Group (RUG).\n\nThe blog also features Rafael's personal journey with R, from automating tasks to exploring machine learning, offering a rich perspective on the tool's versatility. \n\nThe Berlin RUG is actively looking for venue sponsors for their in-person events. It's a unique chance to align your brand with innovation and thought leadership in Data Science.\n\n\ud83d\udd17Read more: [https://www.r-consortium.org/blog/2023/09/05/spatial-data-science-using-r-in-berlin-germany](https://www.r-consortium.org/blog/2023/09/05/spatial-data-science-using-r-in-berlin-germany) \n\nLet's keep the spirit of collaboration and learning alive!", "author_fullname": "t2_6ow4kclla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlocking R's Potential Beyond Stats: Inside Berlin's R User Group with Rafael Camargo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16b0jp9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693948747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ever wondered about the potential of R for diverse applications beyond statistics? Rafael Camargo, a Spatial Data Scientist at Quantis, deeply delves into Berlin&amp;#39;s flourishing R User Group (RUG).&lt;/p&gt;\n\n&lt;p&gt;The blog also features Rafael&amp;#39;s personal journey with R, from automating tasks to exploring machine learning, offering a rich perspective on the tool&amp;#39;s versatility. &lt;/p&gt;\n\n&lt;p&gt;The Berlin RUG is actively looking for venue sponsors for their in-person events. It&amp;#39;s a unique chance to align your brand with innovation and thought leadership in Data Science.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd17Read more: &lt;a href=\"https://www.r-consortium.org/blog/2023/09/05/spatial-data-science-using-r-in-berlin-germany\"&gt;https://www.r-consortium.org/blog/2023/09/05/spatial-data-science-using-r-in-berlin-germany&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s keep the spirit of collaboration and learning alive!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M_7602wFXzkSJXA2lWBADY35BbVuEEi8w3O3r_rhxk0.jpg?auto=webp&amp;s=5f66f0f109e1ec1b9675818171d3cf3c3abb011a", "width": 536, "height": 322}, "resolutions": [{"url": "https://external-preview.redd.it/M_7602wFXzkSJXA2lWBADY35BbVuEEi8w3O3r_rhxk0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a1bc172172be63c21a412692c45873e62f18cabb", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/M_7602wFXzkSJXA2lWBADY35BbVuEEi8w3O3r_rhxk0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4001305e6c5c236efea8f24aa143856146258ff8", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/M_7602wFXzkSJXA2lWBADY35BbVuEEi8w3O3r_rhxk0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=80699aaf841b63637c9795be345d1c370f266f84", "width": 320, "height": 192}], "variants": {}, "id": "PbMwLAkOMtIFWEg3WA69xWXz5OQ8EkpX9n3Lh7jEQ9I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16b0jp9", "is_robot_indexable": true, "report_reasons": null, "author": "Interesting_Chance31", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16b0jp9/unlocking_rs_potential_beyond_stats_inside/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16b0jp9/unlocking_rs_potential_beyond_stats_inside/", "subreddit_subscribers": 1032518, "created_utc": 1693948747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone! I have a Master\u2019s in Industrial Engineering and entered the data analysis field after a short trainee period. I work on creating workflows using Alteryx and Tableau dashboards. While I enjoy what I do, the rapid advancements in AI worry me, and I feel the need to further develop my skills, especially given my limited background in information technology.\n\nI\u2019m willing to invest time and have a strong desire to learn, but I don\u2019t want to waste time on things that won\u2019t pay off. I also worry that self-study doesn\u2019t provide a credential to prove my skills, making me consider a second Master\u2019s degree as perhaps essential. Given my background, eagerness to grow, and concerns about credentialing, what certifications or training would best help me transition into data science or data engineering? What skills or experiences offer the most bang for the buck? Are private projects published on GitHub a viable alternative to formal education?", "author_fullname": "t2_l5mlqax", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from Data Analysis to Data Science or Engineering with a Background in Industrial Engineering. Need Advice!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16b0bjh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693948672.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693948250.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I have a Master\u2019s in Industrial Engineering and entered the data analysis field after a short trainee period. I work on creating workflows using Alteryx and Tableau dashboards. While I enjoy what I do, the rapid advancements in AI worry me, and I feel the need to further develop my skills, especially given my limited background in information technology.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m willing to invest time and have a strong desire to learn, but I don\u2019t want to waste time on things that won\u2019t pay off. I also worry that self-study doesn\u2019t provide a credential to prove my skills, making me consider a second Master\u2019s degree as perhaps essential. Given my background, eagerness to grow, and concerns about credentialing, what certifications or training would best help me transition into data science or data engineering? What skills or experiences offer the most bang for the buck? Are private projects published on GitHub a viable alternative to formal education?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16b0bjh", "is_robot_indexable": true, "report_reasons": null, "author": "benjamin_chr", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16b0bjh/transitioning_from_data_analysis_to_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16b0bjh/transitioning_from_data_analysis_to_data_science/", "subreddit_subscribers": 1032518, "created_utc": 1693948250.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently embarking on my first experience as a Data Scientist during my master's degree internship in a big and well known company, and I am also working on my thesis at the same time. As a newcomer to this field, I am facing several challenges. I persuaded my manager to let me tackle an ambitious deep learning project, but I have found myself struggling on my own to overcome various obstacles. Handling a complex project independently and dealing with structuring and managing code optimization has been challenging. I encountered difficulties collaborating with my team members and regret not seeking assistance from others.\n\nI do not have a background in computer science, and this is my very first experience in a corporate environment. This situation has been quite demotivating for me.\n\nHow can I bounce back, address my weaknesses, and position myself for success in a real Data Scientist role once I graduate?", "author_fullname": "t2_8xgr0r83", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bad first experience", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16b08p5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693948081.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently embarking on my first experience as a Data Scientist during my master&amp;#39;s degree internship in a big and well known company, and I am also working on my thesis at the same time. As a newcomer to this field, I am facing several challenges. I persuaded my manager to let me tackle an ambitious deep learning project, but I have found myself struggling on my own to overcome various obstacles. Handling a complex project independently and dealing with structuring and managing code optimization has been challenging. I encountered difficulties collaborating with my team members and regret not seeking assistance from others.&lt;/p&gt;\n\n&lt;p&gt;I do not have a background in computer science, and this is my very first experience in a corporate environment. This situation has been quite demotivating for me.&lt;/p&gt;\n\n&lt;p&gt;How can I bounce back, address my weaknesses, and position myself for success in a real Data Scientist role once I graduate?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16b08p5", "is_robot_indexable": true, "report_reasons": null, "author": "Weak_Two_6732", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16b08p5/bad_first_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16b08p5/bad_first_experience/", "subreddit_subscribers": 1032518, "created_utc": 1693948081.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All! I am currently a Data Analyst at an Investment Bank and I really want to get my masters in Data Science. I just graduated with my BS in Business Administration but concentrated in Data Analytics and currently work with tools like R and Alteryx. I absolutely love data science! \n\nHowever, money is tight for my family and I and I would like to pay down my undergrad loans rather than accumulate more during my pursuit of a masters degree.\n\nMy company will help pay for the degree as long as I continue working for them. So part time is really my only option at this point if I don\u2019t want to take out tens of thousands of more dollars in loans. \n\nThere are some professional programs out there (Northwestern, Johns Hopkins)  that allow MS in data science part time. However, I notice that these are offered through alternative schools (Northwestern SPS vs Northwestern McCormick school of engineering and JHU Engineering for professionals vs JHU Whiting School of Engineering) \n\nTo those familiar - Is the difference extreme? Like, will my MS degree be from JHU Whiting School of Engineering for professionals or will it be from JHU Whiting School of Engineering? Is the coursework as comprehensive / rigorous and are the professors experienced and accessible? \n\nHoping for some clarity as I haven\u2019t seen much discussion on these types of schools in this sub. TYIA", "author_fullname": "t2_ct0r9u9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MS in Data Science Professional Programs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16aylh9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693944489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All! I am currently a Data Analyst at an Investment Bank and I really want to get my masters in Data Science. I just graduated with my BS in Business Administration but concentrated in Data Analytics and currently work with tools like R and Alteryx. I absolutely love data science! &lt;/p&gt;\n\n&lt;p&gt;However, money is tight for my family and I and I would like to pay down my undergrad loans rather than accumulate more during my pursuit of a masters degree.&lt;/p&gt;\n\n&lt;p&gt;My company will help pay for the degree as long as I continue working for them. So part time is really my only option at this point if I don\u2019t want to take out tens of thousands of more dollars in loans. &lt;/p&gt;\n\n&lt;p&gt;There are some professional programs out there (Northwestern, Johns Hopkins)  that allow MS in data science part time. However, I notice that these are offered through alternative schools (Northwestern SPS vs Northwestern McCormick school of engineering and JHU Engineering for professionals vs JHU Whiting School of Engineering) &lt;/p&gt;\n\n&lt;p&gt;To those familiar - Is the difference extreme? Like, will my MS degree be from JHU Whiting School of Engineering for professionals or will it be from JHU Whiting School of Engineering? Is the coursework as comprehensive / rigorous and are the professors experienced and accessible? &lt;/p&gt;\n\n&lt;p&gt;Hoping for some clarity as I haven\u2019t seen much discussion on these types of schools in this sub. TYIA&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16aylh9", "is_robot_indexable": true, "report_reasons": null, "author": "NewManufacturer3888", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16aylh9/ms_in_data_science_professional_programs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16aylh9/ms_in_data_science_professional_programs/", "subreddit_subscribers": 1032518, "created_utc": 1693944489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " *Hi guys, i'm starting an email newsletter on practical uses with AI/ChatGPT. The following will be my content for my first email. Please let me know what you think! Any thoughts, refinements, etc.*\n\n[https://superpineapple.beehiiv.com/subscribe](https://superpineapple.beehiiv.com/subscribe)\n\n# Step-By-Step\n\nIt\u2019s not as simple as asking ChatGPT - \u201ctell me whether I should invest in Company A\u201d. You need a plan, and you need choose the right tools.\n\n### Getting Ready\n\n**Prerequisites**: ChatGPT Plus\n\n**Overall Objective:** You will want answers to the key questions below (\u201cObjectives\u201d), as well as anything you think are relevant to help your investment decision\n\n**Installation:** Install the following plugins with the GPT4 Model - \u201cCompany Transcript\u201d, \u201cPolygon\u201d, \u201cAI PDF\u201d, \u201cBrowser\u201d, \u201cBrowserOp\u201d\n\n### Phase 1 - First Hand Research\n\nPlugins: \u201cCompany Transcript\u201d, \u201cPolygon\u201d, \u201cAI PDF\u201d\n\n**Step 1 (Learn from Earning Transcripts):** Use \u201cCompany Transcript\u201d to get answers from recent earning calls. You can literally use prompts like *\u201cHow has X performed\u201d*, and *\u201cwhat is A\u2019s strategy for growth and profitability\u201d*\n\n**Step 2 (Learn from Annual / Quarterly Reports)**: Use \u201cPolygon\u201d pull data from recent annual/quarterly reports. Alternatively, you can use \u201cAI PDF\u201d. Get the pdf links on these company's investor relations site (e.g. [***AMD***](https://ir.amd.com/sec-filings/filter/annual-filings?utm_source=superpineapple.beehiiv.com&amp;utm_medium=newsletter&amp;utm_campaign=chatgpt-investment-research)), and query the annual/quarterly report more directly. Similar questions apply\n\nNote: You will probably need to ask follow-up and clarifying questions as you go along, but the idea is to have ChatGPT read these lengthy docs for you.\n\n### Phase 2 - Analyst Reports\n\nPlugins: \u201cBrowser and \u201cBrowserOp\u201d\n\n**Step 3 (Get your list of articles):** Use \u201cBrowser\u201d to get a list of articles from the internet that contain analyst reports and recommendations. An example - *\u201cFind me analyst articles on AMD that give an opinion on their current performance and future prospects. Summarize them\u201d*\n\n**Step 4 (Dig into the articles)**: Use \u201cBrowserOp\u201d to actually access the relevant articles and dig into details. My favorite prompt is as follows - *\u201cCan you use BrowserOp to access these articles and collate the information across all these articles. I would like the depth and reasons behind the recommendations. Present everything in a thesis / anti-thesis format as to whether I should* buy AMD stock\u201d\n\nNote: Follow up questions are definitely needed here as well. Try to have a conversation with ChatGPT to sense check the recommendations.\n\n# Objectives\n\nI like to be able to get a robust and detailed answer to these questions, to help with my investment decisions. Feel free to steal them as prompts!\n\n* **Business Model:** How does the company make money?\n* **Demand Dynamics:** Are its products or services in demand, and why?\n* **Historical Performance:** How has the company performed in the past?\n* **Leadership:** Are talented, experienced managers in charge?\n* **Growth Prospects:** Is the company positioned for growth and profitability?\n* **Financial Health:** How much debt does the company have?\n* **Industry Analysis:** How is the company\u2019s industry doing as a whole?\n* **Challenges:** What are the obstacles and challenges the company faces?\n* **Risks:** Does the company face any economic, political, or cultural risks?\n\nYou also want to know these metrics. Compare the company\u2019s metrics to the broader market, and their specific industry.\n\n* **EPS (Earnings Per Share)**\n* **P/E Ratio (Price to Earnings Ratio)**\n* **Price to Sales Ratio**\n* **Debt to Equity Ratio**", "author_fullname": "t2_8xwepztbe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ChatGPT + Investment Research", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ay5p6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693943515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;Hi guys, i&amp;#39;m starting an email newsletter on practical uses with AI/ChatGPT. The following will be my content for my first email. Please let me know what you think! Any thoughts, refinements, etc.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://superpineapple.beehiiv.com/subscribe\"&gt;https://superpineapple.beehiiv.com/subscribe&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Step-By-Step&lt;/h1&gt;\n\n&lt;p&gt;It\u2019s not as simple as asking ChatGPT - \u201ctell me whether I should invest in Company A\u201d. You need a plan, and you need choose the right tools.&lt;/p&gt;\n\n&lt;h3&gt;Getting Ready&lt;/h3&gt;\n\n&lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: ChatGPT Plus&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Overall Objective:&lt;/strong&gt; You will want answers to the key questions below (\u201cObjectives\u201d), as well as anything you think are relevant to help your investment decision&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Installation:&lt;/strong&gt; Install the following plugins with the GPT4 Model - \u201cCompany Transcript\u201d, \u201cPolygon\u201d, \u201cAI PDF\u201d, \u201cBrowser\u201d, \u201cBrowserOp\u201d&lt;/p&gt;\n\n&lt;h3&gt;Phase 1 - First Hand Research&lt;/h3&gt;\n\n&lt;p&gt;Plugins: \u201cCompany Transcript\u201d, \u201cPolygon\u201d, \u201cAI PDF\u201d&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 1 (Learn from Earning Transcripts):&lt;/strong&gt; Use \u201cCompany Transcript\u201d to get answers from recent earning calls. You can literally use prompts like &lt;em&gt;\u201cHow has X performed\u201d&lt;/em&gt;, and &lt;em&gt;\u201cwhat is A\u2019s strategy for growth and profitability\u201d&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 2 (Learn from Annual / Quarterly Reports)&lt;/strong&gt;: Use \u201cPolygon\u201d pull data from recent annual/quarterly reports. Alternatively, you can use \u201cAI PDF\u201d. Get the pdf links on these company&amp;#39;s investor relations site (e.g. &lt;a href=\"https://ir.amd.com/sec-filings/filter/annual-filings?utm_source=superpineapple.beehiiv.com&amp;amp;utm_medium=newsletter&amp;amp;utm_campaign=chatgpt-investment-research\"&gt;&lt;strong&gt;&lt;em&gt;AMD&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;), and query the annual/quarterly report more directly. Similar questions apply&lt;/p&gt;\n\n&lt;p&gt;Note: You will probably need to ask follow-up and clarifying questions as you go along, but the idea is to have ChatGPT read these lengthy docs for you.&lt;/p&gt;\n\n&lt;h3&gt;Phase 2 - Analyst Reports&lt;/h3&gt;\n\n&lt;p&gt;Plugins: \u201cBrowser and \u201cBrowserOp\u201d&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 3 (Get your list of articles):&lt;/strong&gt; Use \u201cBrowser\u201d to get a list of articles from the internet that contain analyst reports and recommendations. An example - &lt;em&gt;\u201cFind me analyst articles on AMD that give an opinion on their current performance and future prospects. Summarize them\u201d&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Step 4 (Dig into the articles)&lt;/strong&gt;: Use \u201cBrowserOp\u201d to actually access the relevant articles and dig into details. My favorite prompt is as follows - &lt;em&gt;\u201cCan you use BrowserOp to access these articles and collate the information across all these articles. I would like the depth and reasons behind the recommendations. Present everything in a thesis / anti-thesis format as to whether I should&lt;/em&gt; buy AMD stock\u201d&lt;/p&gt;\n\n&lt;p&gt;Note: Follow up questions are definitely needed here as well. Try to have a conversation with ChatGPT to sense check the recommendations.&lt;/p&gt;\n\n&lt;h1&gt;Objectives&lt;/h1&gt;\n\n&lt;p&gt;I like to be able to get a robust and detailed answer to these questions, to help with my investment decisions. Feel free to steal them as prompts!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Business Model:&lt;/strong&gt; How does the company make money?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Demand Dynamics:&lt;/strong&gt; Are its products or services in demand, and why?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Historical Performance:&lt;/strong&gt; How has the company performed in the past?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Leadership:&lt;/strong&gt; Are talented, experienced managers in charge?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Growth Prospects:&lt;/strong&gt; Is the company positioned for growth and profitability?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Financial Health:&lt;/strong&gt; How much debt does the company have?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Industry Analysis:&lt;/strong&gt; How is the company\u2019s industry doing as a whole?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Challenges:&lt;/strong&gt; What are the obstacles and challenges the company faces?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Risks:&lt;/strong&gt; Does the company face any economic, political, or cultural risks?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;You also want to know these metrics. Compare the company\u2019s metrics to the broader market, and their specific industry.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;EPS (Earnings Per Share)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;P/E Ratio (Price to Earnings Ratio)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Price to Sales Ratio&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Debt to Equity Ratio&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/h06xYMyjcTVCu9Ycv4Y3J05qgVnUDmCzfZzMiI5Zr34.jpg?auto=webp&amp;s=88c7167e5ad8150d2f429e247a76802e8a1a6148", "width": 1199, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/h06xYMyjcTVCu9Ycv4Y3J05qgVnUDmCzfZzMiI5Zr34.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e1e1bd23c89f7ad647b1de6fde23ca337ffeacca", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/h06xYMyjcTVCu9Ycv4Y3J05qgVnUDmCzfZzMiI5Zr34.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=400a1a2a825ef770ed8f56f3088f813cd2de9462", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/h06xYMyjcTVCu9Ycv4Y3J05qgVnUDmCzfZzMiI5Zr34.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e035677ebc7d242bebdf9e1b9fb8d252c9461f0", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/h06xYMyjcTVCu9Ycv4Y3J05qgVnUDmCzfZzMiI5Zr34.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=421af7e1068f8578afffb95812da82b11ae641fc", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/h06xYMyjcTVCu9Ycv4Y3J05qgVnUDmCzfZzMiI5Zr34.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5894c1be66680f613b52a21831ac258135a3159d", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/h06xYMyjcTVCu9Ycv4Y3J05qgVnUDmCzfZzMiI5Zr34.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f50e7e5a490938cb5bca5b92f55b1a2ce2614267", "width": 1080, "height": 1080}], "variants": {}, "id": "VImqdnKEmjE76MlFz5BQ0zc2dSL9Ya9-VTTUuw96kgE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16ay5p6", "is_robot_indexable": true, "report_reasons": null, "author": "saasthom", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16ay5p6/chatgpt_investment_research/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16ay5p6/chatgpt_investment_research/", "subreddit_subscribers": 1032518, "created_utc": 1693943515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\nI am working as a Data Scientist for a large pharma company\u2026 2 years experience. 1 prior year as a data analyst within real estate.\n\nI\u2019m interested to hear what industries people have pivoted in? Particularly, how people have found their skills applicable in their newfound career.\n\nMy personal interest: private equity, investments, etc.\n\nThank you", "author_fullname": "t2_86p9z6vkd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pivoting into different careers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ax6tn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693941338.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI am working as a Data Scientist for a large pharma company\u2026 2 years experience. 1 prior year as a data analyst within real estate.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m interested to hear what industries people have pivoted in? Particularly, how people have found their skills applicable in their newfound career.&lt;/p&gt;\n\n&lt;p&gt;My personal interest: private equity, investments, etc.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16ax6tn", "is_robot_indexable": true, "report_reasons": null, "author": "True_Ad5196", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16ax6tn/pivoting_into_different_careers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16ax6tn/pivoting_into_different_careers/", "subreddit_subscribers": 1032518, "created_utc": 1693941338.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\u201cMCMC vs VI\u201d is no longer a discussion about your favourite Roman numeral. If you share my trepidation for model performance in the face of data sparsity, or you simply suffer from anxiety uncertainty, you might be tempted into the Bayesian world. Years later at the precipice of your career (and mental health degeneracy) you over-engineer probabilistic models so intractable that would stress Lord Bayes himself into stomach ulcers. The solution? Approximate inference, the true antihero to model simplification. I wrote a brief primer for those who enjoy maths and those who disdain it, in both cases it's impossible to avoid using maths while discussing Bayesian statistics so I kept it as light as I could.\n\nPS - This is a Reddit-friendly copypasta from my medium article, so if you're a visual person then head over there to get the visuals.\n\n**Bayesian Modelling**\n\nA closed-form solution to a machine learning model is one that can be written down on a sheet of paper using a finite number of standard mathematical operations. For example, linear models have closed-form solutions IF the design covariance matrix is invertible, otherwise we obtain a solution using iterative optimisation.\n\nBayesian models do not typically have exact closed-form solutions for their posterior distributions. One thing that typically helps is choosing simple models, Gaussian likelihood functions and conjugate priors. A prior distribution is said to be conjugate to a likelihood function if the resulting posterior belongs to the same distribution family as the prior.\n\nBayesian linear regression is a model that typically assumes Gaussian priors over both the regression coefficients and the likelihood function. When we update the prior with the observed data (using Bayes\u2019 theorem), the resulting posterior distribution for the regression coefficients will also follow a normal distribution. This can be written down analytically and sampled using standard methods in Python.\n\nConjugacy, however, does not always guarantee tractability. High-dimensional parameter spaces, hierarchical structures, non-Gaussian likelihoods with non-linear prior interactions can give rise to intractable integrals for the normalisation constant (which involve over the entire parameter space). This actually becomes prohibitive when want to build, say, a Multivariate Gaussian Linear Regression model with many predictors, or when we want to model count data using a Poisson likelihood and control for overfitting using on using a Laplace (non-conjugate) prior. Thankfully, a solution as old as the first computers comes to the rescue: Markov Chain Monte Carlo (MCMC).\n\n**Markov Chain Monte Carlo**\n\nMarkov Chain Monte Carlo can be described with enough mathematical jargon to send one fleeing back to first-derivative optimisers, so I\u2019ll skip the stomach ulcers and give an intuitive overview instead.\n\nGiven a probabilistic model parameterised by latent continuous random variables z, and observed values x, we can write down the known form for its probability density function P(z | x). If P(z | x) is intractable, we want to to generate an empirical distribution of samples based on a Markov chain that approximates the probability distribution.\n\nThis empirical distribution can then be used in place of the analytical solution to estimate posterior means, variances, quantiles, and other probabilistic summaries of the model parameters. The most important question: who is Markov and why are we talking about his chain?\n\nIn MCMC, a Markov chain is simply a sequence of samples where each sample is \u201cmemoryless\u201d, i.e. the probability of transitioning to the next sample depends only on the current sample and not on the previous history. This helps us reach a \u201cstationary\u201d distribution over samples, i.e. when we run the chain long enough, the probability P(0 &lt; z &lt; 1 | x)\\_{n} at iteration n and P(0 &lt; z &lt; 1 | x)\\_{m} at iteration m should be equal.\n\nWhat\u2019s amazing is that the distribution over samples from our Markov chain provides asymptotic exactness; MCMC converges to the true posterior distribution in the limit of infinite samples. How is this implemented in practice?\n\n**The Metropolis-Hastings (MH) Algorithm**\n\nMetropolis-Hastings (MH) is a specific type of (MCMC) algorithm ubiquitously used in approximate inference. The idea is to build a chain of samples with a proposal distribution that selects \u201cthe next\u201d sample based only on the \u201cthe current\u201d sample (remember the Markov principle).\n\nProposed samples with higher probabilities in our posterior are accepted into the chain more frequently and those with lower probabilities are rejected more often (don\u2019t make it into the chain). How do we capture the \u201ctails\u201d of our posterior if we\u2019re busy focusing on high probability regions?\n\nThis is where Metropolis-Hastings acceptance/rejection mechanism really shines:\n\nFor any given proposed sample, we define acceptance probability = min(1, \u03b1), where \u03b1 as the ratio of target and proposal distributions at proposed and current samples.\n\nNext comes the heart of the algorithm\u2019s exploration-exploitation mechanism: We generate a random number n in the domain \\[0,1\\]. If n \u2264 \u03b1, accept the new sample in the chain; if n &gt; \u03b1, keep the current sample and don\u2019t extend the chain.\n\nThe best bit? Samples with acceptance probabilities close to 1 are more likely to move the chain towards higher probability regions. Those with low acceptance probabilities can be accepted when 0 \u2264 n \u2264 \u03b1, exploring lower probability areas and avoiding local modes.\n\nWhat diagnostics do we run to check that MH successfully converged to a stationary empirical approximation to the posterior?\n\n**Trace Plots and Chain Mixing**\n\nA \u201ctrace plot\u201d allows us to inspect the chain by plotting accepted sample values for each iteration.\n\nWhat we\u2019re looking for is low autocorrelation between successive samples, and full exploration of the sample space characterised by high variance across moving windows of the trace. Chain 1 is an example of an ideal trace. Chain 2 initially has high autocorrelation and low variance but converges to stationarity after iteration t \\~1500. We discard the head segment t &lt; 1500 (so-called burn-in samples) since they\u2019re unlikely to be part of our target distribution.\n\nWhat about Chain 3? This trace demonstrates poor chain mixing, moving slowly across the parameter space between different regions of the distribution. One problem could be that we just haven\u2019t let the algorithm run long enough; but Model complexity increases with multimodality, high dimensionality and correlated parameters the asymptotic exactness guarantee of MCMC doesn\u2019t come with a tqdm, you could be waiting for quite a while. In these cases, we present the next best thing: variational inference.\n\n**Variatonal Inference**\n\nWhile MCMC offers asymptotic exactness around high dimensional distributions, it can be computationally intensive and impractical for complex distributions. Often we\u2019re just interested in a rough approximation to the posterior that scales well for deployment.\n\nVariational Inference (VI) frames the problem of approximating the posterior as an optimisation problem. Starting with a synthetic posterior Q(z | \u03bb) built from families of simpler distributions (known as the variational family), we optimise over parameters \u03bb that minimise the distance between the variational family and the true posterior P(z | x). This sounds cool but how do we choose the variational family? What even is a distance between distributions?\n\n**KL-Divergence**\n\nThe choice of Q(z | \u03bb) depends on the degree of flexibility required (increasing with the complexity of P(z | x)), but common choices are exponential or Gaussian distributions. To compare the \u201ccloseness\u201d of P and Q, we employ a similarity measure such as the Kullback-Leibler (KL) divergence:\n\nAlthough the KL divergence is asymmetric (DKL(Q||P) =/= DKL(P||Q)), it helps to quantify the difference between Q and P.\n\n\u201cBut we don\u2019t have a closed form solution for P(z|x)!\u201d I hear you exclaiming correctly. That\u2019s why we compute something called the Evidence Lower Bound (ELBO) instead: ELBO(\u03bb) = log( P(x) ) \u2212DKL(Q(z | \u03bb)||P(z | x)). This can be rearranged as ELBO(\u03bb) = E\u200b\\[log P(x, z)\\]\u2212E\u200b\\[log Q(z\u2223\u03bb)\\] helps us avoid that pesky intractable marginal integral.\n\nThus, maximizing ELBO is equivalent to minimizing the KL divergence, serves as an objective function we optimise using standard methods like co-ordinate ascent. Once \u03bb are optimised, the approximating distribution Q(z | \u03bb) serves as a surrogate for the true posterior. This approximation can then be used for downstream tasks like prediction, data imputation, or model interpretation.", "author_fullname": "t2_7h1mi6us", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tl;dr Approximate Inference methods made easy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16awjx5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693939860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\u201cMCMC vs VI\u201d is no longer a discussion about your favourite Roman numeral. If you share my trepidation for model performance in the face of data sparsity, or you simply suffer from anxiety uncertainty, you might be tempted into the Bayesian world. Years later at the precipice of your career (and mental health degeneracy) you over-engineer probabilistic models so intractable that would stress Lord Bayes himself into stomach ulcers. The solution? Approximate inference, the true antihero to model simplification. I wrote a brief primer for those who enjoy maths and those who disdain it, in both cases it&amp;#39;s impossible to avoid using maths while discussing Bayesian statistics so I kept it as light as I could.&lt;/p&gt;\n\n&lt;p&gt;PS - This is a Reddit-friendly copypasta from my medium article, so if you&amp;#39;re a visual person then head over there to get the visuals.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Bayesian Modelling&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;A closed-form solution to a machine learning model is one that can be written down on a sheet of paper using a finite number of standard mathematical operations. For example, linear models have closed-form solutions IF the design covariance matrix is invertible, otherwise we obtain a solution using iterative optimisation.&lt;/p&gt;\n\n&lt;p&gt;Bayesian models do not typically have exact closed-form solutions for their posterior distributions. One thing that typically helps is choosing simple models, Gaussian likelihood functions and conjugate priors. A prior distribution is said to be conjugate to a likelihood function if the resulting posterior belongs to the same distribution family as the prior.&lt;/p&gt;\n\n&lt;p&gt;Bayesian linear regression is a model that typically assumes Gaussian priors over both the regression coefficients and the likelihood function. When we update the prior with the observed data (using Bayes\u2019 theorem), the resulting posterior distribution for the regression coefficients will also follow a normal distribution. This can be written down analytically and sampled using standard methods in Python.&lt;/p&gt;\n\n&lt;p&gt;Conjugacy, however, does not always guarantee tractability. High-dimensional parameter spaces, hierarchical structures, non-Gaussian likelihoods with non-linear prior interactions can give rise to intractable integrals for the normalisation constant (which involve over the entire parameter space). This actually becomes prohibitive when want to build, say, a Multivariate Gaussian Linear Regression model with many predictors, or when we want to model count data using a Poisson likelihood and control for overfitting using on using a Laplace (non-conjugate) prior. Thankfully, a solution as old as the first computers comes to the rescue: Markov Chain Monte Carlo (MCMC).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Markov Chain Monte Carlo&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Markov Chain Monte Carlo can be described with enough mathematical jargon to send one fleeing back to first-derivative optimisers, so I\u2019ll skip the stomach ulcers and give an intuitive overview instead.&lt;/p&gt;\n\n&lt;p&gt;Given a probabilistic model parameterised by latent continuous random variables z, and observed values x, we can write down the known form for its probability density function P(z | x). If P(z | x) is intractable, we want to to generate an empirical distribution of samples based on a Markov chain that approximates the probability distribution.&lt;/p&gt;\n\n&lt;p&gt;This empirical distribution can then be used in place of the analytical solution to estimate posterior means, variances, quantiles, and other probabilistic summaries of the model parameters. The most important question: who is Markov and why are we talking about his chain?&lt;/p&gt;\n\n&lt;p&gt;In MCMC, a Markov chain is simply a sequence of samples where each sample is \u201cmemoryless\u201d, i.e. the probability of transitioning to the next sample depends only on the current sample and not on the previous history. This helps us reach a \u201cstationary\u201d distribution over samples, i.e. when we run the chain long enough, the probability P(0 &amp;lt; z &amp;lt; 1 | x)_{n} at iteration n and P(0 &amp;lt; z &amp;lt; 1 | x)_{m} at iteration m should be equal.&lt;/p&gt;\n\n&lt;p&gt;What\u2019s amazing is that the distribution over samples from our Markov chain provides asymptotic exactness; MCMC converges to the true posterior distribution in the limit of infinite samples. How is this implemented in practice?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Metropolis-Hastings (MH) Algorithm&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Metropolis-Hastings (MH) is a specific type of (MCMC) algorithm ubiquitously used in approximate inference. The idea is to build a chain of samples with a proposal distribution that selects \u201cthe next\u201d sample based only on the \u201cthe current\u201d sample (remember the Markov principle).&lt;/p&gt;\n\n&lt;p&gt;Proposed samples with higher probabilities in our posterior are accepted into the chain more frequently and those with lower probabilities are rejected more often (don\u2019t make it into the chain). How do we capture the \u201ctails\u201d of our posterior if we\u2019re busy focusing on high probability regions?&lt;/p&gt;\n\n&lt;p&gt;This is where Metropolis-Hastings acceptance/rejection mechanism really shines:&lt;/p&gt;\n\n&lt;p&gt;For any given proposed sample, we define acceptance probability = min(1, \u03b1), where \u03b1 as the ratio of target and proposal distributions at proposed and current samples.&lt;/p&gt;\n\n&lt;p&gt;Next comes the heart of the algorithm\u2019s exploration-exploitation mechanism: We generate a random number n in the domain [0,1]. If n \u2264 \u03b1, accept the new sample in the chain; if n &amp;gt; \u03b1, keep the current sample and don\u2019t extend the chain.&lt;/p&gt;\n\n&lt;p&gt;The best bit? Samples with acceptance probabilities close to 1 are more likely to move the chain towards higher probability regions. Those with low acceptance probabilities can be accepted when 0 \u2264 n \u2264 \u03b1, exploring lower probability areas and avoiding local modes.&lt;/p&gt;\n\n&lt;p&gt;What diagnostics do we run to check that MH successfully converged to a stationary empirical approximation to the posterior?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Trace Plots and Chain Mixing&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;A \u201ctrace plot\u201d allows us to inspect the chain by plotting accepted sample values for each iteration.&lt;/p&gt;\n\n&lt;p&gt;What we\u2019re looking for is low autocorrelation between successive samples, and full exploration of the sample space characterised by high variance across moving windows of the trace. Chain 1 is an example of an ideal trace. Chain 2 initially has high autocorrelation and low variance but converges to stationarity after iteration t ~1500. We discard the head segment t &amp;lt; 1500 (so-called burn-in samples) since they\u2019re unlikely to be part of our target distribution.&lt;/p&gt;\n\n&lt;p&gt;What about Chain 3? This trace demonstrates poor chain mixing, moving slowly across the parameter space between different regions of the distribution. One problem could be that we just haven\u2019t let the algorithm run long enough; but Model complexity increases with multimodality, high dimensionality and correlated parameters the asymptotic exactness guarantee of MCMC doesn\u2019t come with a tqdm, you could be waiting for quite a while. In these cases, we present the next best thing: variational inference.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Variatonal Inference&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;While MCMC offers asymptotic exactness around high dimensional distributions, it can be computationally intensive and impractical for complex distributions. Often we\u2019re just interested in a rough approximation to the posterior that scales well for deployment.&lt;/p&gt;\n\n&lt;p&gt;Variational Inference (VI) frames the problem of approximating the posterior as an optimisation problem. Starting with a synthetic posterior Q(z | \u03bb) built from families of simpler distributions (known as the variational family), we optimise over parameters \u03bb that minimise the distance between the variational family and the true posterior P(z | x). This sounds cool but how do we choose the variational family? What even is a distance between distributions?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;KL-Divergence&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The choice of Q(z | \u03bb) depends on the degree of flexibility required (increasing with the complexity of P(z | x)), but common choices are exponential or Gaussian distributions. To compare the \u201ccloseness\u201d of P and Q, we employ a similarity measure such as the Kullback-Leibler (KL) divergence:&lt;/p&gt;\n\n&lt;p&gt;Although the KL divergence is asymmetric (DKL(Q||P) =/= DKL(P||Q)), it helps to quantify the difference between Q and P.&lt;/p&gt;\n\n&lt;p&gt;\u201cBut we don\u2019t have a closed form solution for P(z|x)!\u201d I hear you exclaiming correctly. That\u2019s why we compute something called the Evidence Lower Bound (ELBO) instead: ELBO(\u03bb) = log( P(x) ) \u2212DKL(Q(z | \u03bb)||P(z | x)). This can be rearranged as ELBO(\u03bb) = E\u200b[log P(x, z)]\u2212E\u200b[log Q(z\u2223\u03bb)] helps us avoid that pesky intractable marginal integral.&lt;/p&gt;\n\n&lt;p&gt;Thus, maximizing ELBO is equivalent to minimizing the KL divergence, serves as an objective function we optimise using standard methods like co-ordinate ascent. Once \u03bb are optimised, the approximating distribution Q(z | \u03bb) serves as a surrogate for the true posterior. This approximation can then be used for downstream tasks like prediction, data imputation, or model interpretation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16awjx5", "is_robot_indexable": true, "report_reasons": null, "author": "SnooPaintings5866", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16awjx5/tldr_approximate_inference_methods_made_easy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16awjx5/tldr_approximate_inference_methods_made_easy/", "subreddit_subscribers": 1032518, "created_utc": 1693939860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi  I'm geology fresh graduate and I'm taking Ai training program in Oil &amp; Gas sector, and now I'm working on a challenging dataset so the first and main issue i had is the high percentage of missing values in a list of well logs columns and each of them have a different percentage of missing values. And the other one is to achieve as high F1 score accuracy as possible using different classifications algorithms wether they were Ml or DL. So is there any certain algorithm i can use to achieve high F1 score or should i try them all?", "author_fullname": "t2_c0nfx4v9d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Missing values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16atdug", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693932565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi  I&amp;#39;m geology fresh graduate and I&amp;#39;m taking Ai training program in Oil &amp;amp; Gas sector, and now I&amp;#39;m working on a challenging dataset so the first and main issue i had is the high percentage of missing values in a list of well logs columns and each of them have a different percentage of missing values. And the other one is to achieve as high F1 score accuracy as possible using different classifications algorithms wether they were Ml or DL. So is there any certain algorithm i can use to achieve high F1 score or should i try them all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16atdug", "is_robot_indexable": true, "report_reasons": null, "author": "Many-Act6717", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16atdug/missing_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16atdug/missing_values/", "subreddit_subscribers": 1032518, "created_utc": 1693932565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI am having trouble deciding how to proceed with the data I have collected during my experiments with 20 individuals. What summary statistics, visualization methods (histogram, box plot, linear regression), and analysis methods (ANOVA, t test, correlation) would be best for my data and research question? My research question is to see how muscle fatigue affects sympathetic nervous system activity by measuring galvanic skin response (GSR), ECG, and HR. Does it increase or decrease? thats what I want to know. We gave each participant a 1kg weight and measured each variable at pre-exercise, trial 1 (holding for 1 minute), rest 1 (30 seconds), trial 2 (1 min), rest 2 (30 secs), and trial 3. Below is an example of data for one person out of 20 participants. If anyone can help I would really appreciate it!!!\n\nGalvanic Skin Response (GSR):\r  \nMinimum and Maximum GSR Values:\r  \n\r  \nPre-exercise: Min = -1.74, Max = 4.455\r  \nTrial 1: Min = 0.7275, Max = 2.4075\r  \nRest 2: Min = 0.8575, Max = 2.155\r  \nTrial 2: Min = 0.7863, Max = 4.32\r  \nRest 3: Min = 2.4475, Max = 3.87\r  \nTrial 3: Min = 3.0187, Max = 8.48\r  \nMean GSR Values:\r  \n\r  \nPre-exercise: Mean = 1.3876\r  \nTrial 1: Mean = 1.4487\r  \nRest 2: Mean = 1.3472\r  \nTrial 2: Mean = 2.1102\r  \nRest 3: Mean = 3.05\r  \nTrial 3: Mean = 5.1152\r  \nElectrocardiogram (ECG):\r  \nMinimum and Maximum ECG Values:\r  \n\r  \nPre-exercise: Min = -1.2667, Max = 1.4257\r  \nTrial 1: Min = -0.9514, Max = 1.735\r  \nRest 2: Min = -0.4217, Max = 1.4357\r  \nTrial 2: Min = -1.0982, Max = 2.0479\r  \nRest 3: Min = -1.0989, Max = 1.3881\r  \nTrial 3: Min = -1.5604, Max = 2.0478\r  \nMean ECG Values:\r  \n\r  \nPre-exercise: Mean = -0.0063\r  \nTrial 1: Mean = 0.0045\r  \nRest 2: Mean = 0.002\r  \nTrial 2: Mean = -0.0084\r  \nRest 3: Mean = -0.0176\r  \nTrial 3: Mean = 0.0028\r  \nHeart Rate (HR):\r  \nMinimum and Maximum HR Values:\r  \n\r  \nPre-exercise: Min = 66, Max = 100\r  \nTrial 1: Min = 48, Max = 103\r  \nRest 2: Min = 75, Max = 105\r  \nTrial 2: Min = 49, Max = 112\r  \nRest 3: Min = 75, Max = 98\r  \nTrial 3: Min = 31, Max = 109\r  \nMean HR Values:\r  \n\r  \nPre-exercise: Mean = 81\r  \nTrial 1: Mean = 88\r  \nRest 2: Mean = 91\r  \nTrial 2: Mean = 91\r  \nRest 3: Mean = 87\r  \nTrial 3: Mean = 80", "author_fullname": "t2_dncb8g18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "help with my data!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16as06v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693929402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am having trouble deciding how to proceed with the data I have collected during my experiments with 20 individuals. What summary statistics, visualization methods (histogram, box plot, linear regression), and analysis methods (ANOVA, t test, correlation) would be best for my data and research question? My research question is to see how muscle fatigue affects sympathetic nervous system activity by measuring galvanic skin response (GSR), ECG, and HR. Does it increase or decrease? thats what I want to know. We gave each participant a 1kg weight and measured each variable at pre-exercise, trial 1 (holding for 1 minute), rest 1 (30 seconds), trial 2 (1 min), rest 2 (30 secs), and trial 3. Below is an example of data for one person out of 20 participants. If anyone can help I would really appreciate it!!!&lt;/p&gt;\n\n&lt;p&gt;Galvanic Skin Response (GSR):&lt;/p&gt;\n\n&lt;p&gt;Minimum and Maximum GSR Values:&lt;/p&gt;\n\n&lt;p&gt;Pre-exercise: Min = -1.74, Max = 4.455&lt;/p&gt;\n\n&lt;p&gt;Trial 1: Min = 0.7275, Max = 2.4075&lt;/p&gt;\n\n&lt;p&gt;Rest 2: Min = 0.8575, Max = 2.155&lt;/p&gt;\n\n&lt;p&gt;Trial 2: Min = 0.7863, Max = 4.32&lt;/p&gt;\n\n&lt;p&gt;Rest 3: Min = 2.4475, Max = 3.87&lt;/p&gt;\n\n&lt;p&gt;Trial 3: Min = 3.0187, Max = 8.48&lt;/p&gt;\n\n&lt;p&gt;Mean GSR Values:&lt;/p&gt;\n\n&lt;p&gt;Pre-exercise: Mean = 1.3876&lt;/p&gt;\n\n&lt;p&gt;Trial 1: Mean = 1.4487&lt;/p&gt;\n\n&lt;p&gt;Rest 2: Mean = 1.3472&lt;/p&gt;\n\n&lt;p&gt;Trial 2: Mean = 2.1102&lt;/p&gt;\n\n&lt;p&gt;Rest 3: Mean = 3.05&lt;/p&gt;\n\n&lt;p&gt;Trial 3: Mean = 5.1152&lt;/p&gt;\n\n&lt;p&gt;Electrocardiogram (ECG):&lt;/p&gt;\n\n&lt;p&gt;Minimum and Maximum ECG Values:&lt;/p&gt;\n\n&lt;p&gt;Pre-exercise: Min = -1.2667, Max = 1.4257&lt;/p&gt;\n\n&lt;p&gt;Trial 1: Min = -0.9514, Max = 1.735&lt;/p&gt;\n\n&lt;p&gt;Rest 2: Min = -0.4217, Max = 1.4357&lt;/p&gt;\n\n&lt;p&gt;Trial 2: Min = -1.0982, Max = 2.0479&lt;/p&gt;\n\n&lt;p&gt;Rest 3: Min = -1.0989, Max = 1.3881&lt;/p&gt;\n\n&lt;p&gt;Trial 3: Min = -1.5604, Max = 2.0478&lt;/p&gt;\n\n&lt;p&gt;Mean ECG Values:&lt;/p&gt;\n\n&lt;p&gt;Pre-exercise: Mean = -0.0063&lt;/p&gt;\n\n&lt;p&gt;Trial 1: Mean = 0.0045&lt;/p&gt;\n\n&lt;p&gt;Rest 2: Mean = 0.002&lt;/p&gt;\n\n&lt;p&gt;Trial 2: Mean = -0.0084&lt;/p&gt;\n\n&lt;p&gt;Rest 3: Mean = -0.0176&lt;/p&gt;\n\n&lt;p&gt;Trial 3: Mean = 0.0028&lt;/p&gt;\n\n&lt;p&gt;Heart Rate (HR):&lt;/p&gt;\n\n&lt;p&gt;Minimum and Maximum HR Values:&lt;/p&gt;\n\n&lt;p&gt;Pre-exercise: Min = 66, Max = 100&lt;/p&gt;\n\n&lt;p&gt;Trial 1: Min = 48, Max = 103&lt;/p&gt;\n\n&lt;p&gt;Rest 2: Min = 75, Max = 105&lt;/p&gt;\n\n&lt;p&gt;Trial 2: Min = 49, Max = 112&lt;/p&gt;\n\n&lt;p&gt;Rest 3: Min = 75, Max = 98&lt;/p&gt;\n\n&lt;p&gt;Trial 3: Min = 31, Max = 109&lt;/p&gt;\n\n&lt;p&gt;Mean HR Values:&lt;/p&gt;\n\n&lt;p&gt;Pre-exercise: Mean = 81&lt;/p&gt;\n\n&lt;p&gt;Trial 1: Mean = 88&lt;/p&gt;\n\n&lt;p&gt;Rest 2: Mean = 91&lt;/p&gt;\n\n&lt;p&gt;Trial 2: Mean = 91&lt;/p&gt;\n\n&lt;p&gt;Rest 3: Mean = 87&lt;/p&gt;\n\n&lt;p&gt;Trial 3: Mean = 80&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16as06v", "is_robot_indexable": true, "report_reasons": null, "author": "resevoirresevoir", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16as06v/help_with_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16as06v/help_with_my_data/", "subreddit_subscribers": 1032518, "created_utc": 1693929402.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}