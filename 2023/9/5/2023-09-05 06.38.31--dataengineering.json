{"kind": "Listing", "data": {"after": "t3_169o3x4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "(Sorry for the long post\u2026.)\n\nI don\u2019t have a technical background but I started as an intern in my current company (IT Fortune 500 and my first and only professional experience since graduation) doing unrelated work.\n\nI realized that I really liked programming so I started taking Udemy courses for that since my company was offering Udemy for free. I also realized that I like data so starting working on that too.\n\nThere was an initiative from the company to start developing Data skills, but It fell short because of the lack of interest from my co-workers (we are 1000+ just in my country). I soon took notice of this and knew it was an opportunity to make my way. \nDid the courses and talked to the chapter leader and, like a miracle, there was one POC project that they were working on for a contest to win a project with a client (almost like an auction) but the guy that was the data engineer, and only member of the team, left so they immediately let me work on it. I completed the POC and the client loved it but my company\u2019s price for the whole services package was too expensive.\n\nAfter that POC I was still working on my previous role (no data or IT related) so I started applying to jobs and got an offer to be a Data Analyst in an important cosmetic company in my country that is very well known for it\u2019s great data department. I told my company about this and they told me not to leave and offered me a 50% increase in salary and the opportunity to lead the data engineering department when it\u2019s founded, so I would be one of the founders of that department, but in the meantime I was gonna be part of the automation and innovation department. I accepted the counter offer and stayed.\n\nFast forward 1 and 1/2 years and now I\u2019m part of the Data and Analytics team, actually there\u2019s not really a department but the company really wants to start offering Data Consulting services to their costumers so we have one big project that we are working on right now (Databricks, Data Factory, Power BI) and one small one (Azure functions, Docker, Azure VM and Power BI), neither of those work with more than GB\u2019s of data.\n\nThe thing is that I\u2019m the only data engineer. There\u2019s one data architect who is really great at data governance, two data analyst and many project managers. A lot of projects are coming our way with many interesting technologies like machine learning, AI, etc. and I\u2019m already burn out because of all the hours that I have to put in only in those projects where I\u2019m the sole builder of the Infra, pipelines, etc. it\u2019s really not a problem because I really like it, but I\u2019m starting to worry because of what\u2019s coming.\n\nSo today I have two offers from two different companies to join as a data engineer. None of them are as big as my current company but aren\u2019t small either, but work with bigger data.\n\nI have to make a decision whether to stay here and be one of the pioneers of the data department, be considered for everything (learning and projects) and work on interesting projects because I\u2019m the only one that is available with the skills to do those, or work for any of the other two companies that have a very mature data team that also work with cool projects and where I could also learn a lot from more experience data engineers/architects and work with bigger data.\n\nWhat path would you take?\n\nEdit: My current company is partner of the year with Google, AWS and Azure, so training and certs are covered.\n\nEdit2: For the people asking what courses did I take for Python, I took Jose portillas Python course and Automating the boring stuff. That being said, I learned more by doing. I made two projects that earned me the offers from the other companies.", "author_fullname": "t2_66knxh65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Been working as a data engineer for 2 years", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169slfu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693865728.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693835581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Sorry for the long post\u2026.)&lt;/p&gt;\n\n&lt;p&gt;I don\u2019t have a technical background but I started as an intern in my current company (IT Fortune 500 and my first and only professional experience since graduation) doing unrelated work.&lt;/p&gt;\n\n&lt;p&gt;I realized that I really liked programming so I started taking Udemy courses for that since my company was offering Udemy for free. I also realized that I like data so starting working on that too.&lt;/p&gt;\n\n&lt;p&gt;There was an initiative from the company to start developing Data skills, but It fell short because of the lack of interest from my co-workers (we are 1000+ just in my country). I soon took notice of this and knew it was an opportunity to make my way. \nDid the courses and talked to the chapter leader and, like a miracle, there was one POC project that they were working on for a contest to win a project with a client (almost like an auction) but the guy that was the data engineer, and only member of the team, left so they immediately let me work on it. I completed the POC and the client loved it but my company\u2019s price for the whole services package was too expensive.&lt;/p&gt;\n\n&lt;p&gt;After that POC I was still working on my previous role (no data or IT related) so I started applying to jobs and got an offer to be a Data Analyst in an important cosmetic company in my country that is very well known for it\u2019s great data department. I told my company about this and they told me not to leave and offered me a 50% increase in salary and the opportunity to lead the data engineering department when it\u2019s founded, so I would be one of the founders of that department, but in the meantime I was gonna be part of the automation and innovation department. I accepted the counter offer and stayed.&lt;/p&gt;\n\n&lt;p&gt;Fast forward 1 and 1/2 years and now I\u2019m part of the Data and Analytics team, actually there\u2019s not really a department but the company really wants to start offering Data Consulting services to their costumers so we have one big project that we are working on right now (Databricks, Data Factory, Power BI) and one small one (Azure functions, Docker, Azure VM and Power BI), neither of those work with more than GB\u2019s of data.&lt;/p&gt;\n\n&lt;p&gt;The thing is that I\u2019m the only data engineer. There\u2019s one data architect who is really great at data governance, two data analyst and many project managers. A lot of projects are coming our way with many interesting technologies like machine learning, AI, etc. and I\u2019m already burn out because of all the hours that I have to put in only in those projects where I\u2019m the sole builder of the Infra, pipelines, etc. it\u2019s really not a problem because I really like it, but I\u2019m starting to worry because of what\u2019s coming.&lt;/p&gt;\n\n&lt;p&gt;So today I have two offers from two different companies to join as a data engineer. None of them are as big as my current company but aren\u2019t small either, but work with bigger data.&lt;/p&gt;\n\n&lt;p&gt;I have to make a decision whether to stay here and be one of the pioneers of the data department, be considered for everything (learning and projects) and work on interesting projects because I\u2019m the only one that is available with the skills to do those, or work for any of the other two companies that have a very mature data team that also work with cool projects and where I could also learn a lot from more experience data engineers/architects and work with bigger data.&lt;/p&gt;\n\n&lt;p&gt;What path would you take?&lt;/p&gt;\n\n&lt;p&gt;Edit: My current company is partner of the year with Google, AWS and Azure, so training and certs are covered.&lt;/p&gt;\n\n&lt;p&gt;Edit2: For the people asking what courses did I take for Python, I took Jose portillas Python course and Automating the boring stuff. That being said, I learned more by doing. I made two projects that earned me the offers from the other companies.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169slfu", "is_robot_indexable": true, "report_reasons": null, "author": "WarNeverChanges1997", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169slfu/been_working_as_a_data_engineer_for_2_years/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169slfu/been_working_as_a_data_engineer_for_2_years/", "subreddit_subscribers": 126870, "created_utc": 1693835581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've worked in data since 2019. Got my to Senior level last year and being paid in the mid \u00a350K zone. Some of the practices in my current workplace I'm not happy about but I've been able to secure a small pay rise as well as a chance to start a Level 7 AI Apprenticeship coming up in October.\n\nI pushed for it as it was something that: \n\n1. I'm interested in and want to eventually open my own business doing something within AI. \n2. I'd be able to own/create a new MLOps department which will most likely stretch into developing AI solutions.\n\nHowever, for the 3rd time in the past 6 months I've been offered Senior titles with wages in the \u00a380K zone and at first i thought it was just recruiters being recruiters but this one I went through the motions and have been offered \u00a390K which is more than I asked for. This has only happened for me twice and it was in my role before my current role and now. \n\nI got myself where I am today, by sheer force and learning power. No academic background... Hell, I don't even hold a Maths GCSE. So I'm struggling to pick between the money and a masters degree equivalent in a field I'm highly interested in.\n\nMy partner says do what makes you happy, my parents say take the money, my friends have actually stopped talking to me since they revealed they earn under the \u00a330K mark and now seem to just ghost me all the time... but that's for another thread I guess. \n\nSo, i thought reaching out to people in my role and see what you would all do in this situation?", "author_fullname": "t2_al2yxww8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Been working at a business for just over a year as a Senior Data Engineer. I've been offered to take a LVL 7 AI Apprenticeship but I've been headhunted for another role closer to home for a lot more money. Struggling with which choice will be the right one so looking for some advice.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169mqdp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693817335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve worked in data since 2019. Got my to Senior level last year and being paid in the mid \u00a350K zone. Some of the practices in my current workplace I&amp;#39;m not happy about but I&amp;#39;ve been able to secure a small pay rise as well as a chance to start a Level 7 AI Apprenticeship coming up in October.&lt;/p&gt;\n\n&lt;p&gt;I pushed for it as it was something that: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I&amp;#39;m interested in and want to eventually open my own business doing something within AI. &lt;/li&gt;\n&lt;li&gt;I&amp;#39;d be able to own/create a new MLOps department which will most likely stretch into developing AI solutions.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;However, for the 3rd time in the past 6 months I&amp;#39;ve been offered Senior titles with wages in the \u00a380K zone and at first i thought it was just recruiters being recruiters but this one I went through the motions and have been offered \u00a390K which is more than I asked for. This has only happened for me twice and it was in my role before my current role and now. &lt;/p&gt;\n\n&lt;p&gt;I got myself where I am today, by sheer force and learning power. No academic background... Hell, I don&amp;#39;t even hold a Maths GCSE. So I&amp;#39;m struggling to pick between the money and a masters degree equivalent in a field I&amp;#39;m highly interested in.&lt;/p&gt;\n\n&lt;p&gt;My partner says do what makes you happy, my parents say take the money, my friends have actually stopped talking to me since they revealed they earn under the \u00a330K mark and now seem to just ghost me all the time... but that&amp;#39;s for another thread I guess. &lt;/p&gt;\n\n&lt;p&gt;So, i thought reaching out to people in my role and see what you would all do in this situation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169mqdp", "is_robot_indexable": true, "report_reasons": null, "author": "The-Engineer-93", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169mqdp/been_working_at_a_business_for_just_over_a_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169mqdp/been_working_at_a_business_for_just_over_a_year/", "subreddit_subscribers": 126870, "created_utc": 1693817335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please find a simple project I have done in the link below.\nhttps://github.com/JawaharRamis/reddit-streaming-kafka-spark-application\n\nI understand that this is not the best use-case scenario for utilizing kafka but the personal goal of this project was for me to familiarize with the kafka and spark integration. Kindly give me your feedback where and what I can do better. This subreddit has been really helpful during my learning journey and I hope it continues.", "author_fullname": "t2_67og6h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First project, Kindly give your feedback and criticisms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169l3p1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693811667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please find a simple project I have done in the link below.\n&lt;a href=\"https://github.com/JawaharRamis/reddit-streaming-kafka-spark-application\"&gt;https://github.com/JawaharRamis/reddit-streaming-kafka-spark-application&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I understand that this is not the best use-case scenario for utilizing kafka but the personal goal of this project was for me to familiarize with the kafka and spark integration. Kindly give me your feedback where and what I can do better. This subreddit has been really helpful during my learning journey and I hope it continues.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?auto=webp&amp;s=b5c797a7cbc89d32410d737e255be4271a9d94a6", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6d0f5fe2724b02f6b9354f75611f3028e786b76", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=46b9d2e701d1395e1fb3edc77053ad7329266255", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b54599afae812ed83772cd2a9d0908e0cdb0141f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c9e6c1e6ed0ce3ac92deb24e2bb082fbc0791711", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ae25156fdfae4669eb338e5e08d1fe323844d13d", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/xhQvKz3dQyggKqNe6QceDI01LF9daVsa1qe0mlsmkTs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6c0f830c434676df456cae9ba8ddadad9b82fc7f", "width": 1080, "height": 540}], "variants": {}, "id": "DaeCVLuQ0lefRgXksGWUNqrs-_dik3hYF9PGv6cMtPo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "169l3p1", "is_robot_indexable": true, "report_reasons": null, "author": "jawz96", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169l3p1/first_project_kindly_give_your_feedback_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169l3p1/first_project_kindly_give_your_feedback_and/", "subreddit_subscribers": 126870, "created_utc": 1693811667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Assume a very large (10k+) number of on premise single tenant databases spread across an arbitrary number of servers. Much of this data needs to be replicated/consolidated to a downstream data lake as quickly as possible (ideally at least twice daily).\n\nThere are obviously a number of challenges for any solution: Concurrent/overall connection limits, memory allocations, resource/object locking, intermediate storage/compute/parallel processing, etc. And that is just at the ingest, but that's the foundational problem that needs to be solved first.\n\nNow, my first instict is a migration to a multi-tenant, hybrid cloud/on-prem solution. This would co mingle data sources with lakehouse ingestion processes (AWS ecosystem) and allow easier scaling of the ingestion layer.\n\nIt is unlikely that this will be accomplished in a timely manner and will require the incentivization and coordation of many business and technical stakeholders, some of which may never be convinced/migrated. \n\nI'm trying to wrap my head around how this would be possible at scale without hitting either concurrent connection issues, untenable memory/processing requirements (on prem servers, no autoscaling), and/or deadlock issues. Current alternatives:\n\n\u2022Perform CDC via database logs (Debezium) stream to Kafka and sync to S3 (parquet files). Amazon EMR to run spark jobs to archive, merge and compress in paralell. We will assume the merged data across database instances will conform to the same schema. \n\n\u2022Each database instance performs intermediate data staging/processing for traditional ETL/ELT workloads to consume and deliver to S3.\n\n\u2022Perform some sort of on prem to cloud DB replication where it will be easier to scale data ingestion.\n\nEven assuming complete migration to a multi-tenant cloud hosted solution, there will be significant challenges scaling data ingestion to thousands of sources with petabytes of throughput and storage.\n\nCurrent plan is to layer Iceberg on top of S3 once we can land the data performantly in the lake. Hoping to avoid raw data replication to DW/ML solution, but not sure of Iceberg's performance at this scale.\n\nAny thoughts, critiques, and advice appreciated!\n\nEDIT-\nBusiness reqs:\n\u2022Source data resides in on prem MSSQL Servers. The number of servers and databases per server are  configurable to balance cost and performance (currently ~1k  DBs per server)\n\n\u2022Source tables are 20 - 30 in number, 250 - 500 GB in size per  tenant (10k+ tenants). Schemas are the same across DBs.\n\n\u2022Volume of changes is currently unknown, but could be up to 10 million rows and 10 TB of throughput per semi daily run (say every 4 hours). These are general starting requirements that will scale up. \n\n\u2022Pipelines for this data currently exist via Fivetran and take 24 hours. So, generally I'm looking to see how parallel CDC or ELT (Debeizun, Spark) could be utilized to speed up the process.\n\n\u2022Data will land in an S3 data lake to be accessed by Snowflake as the main analytics engine, and other services for AI/ML work.", "author_fullname": "t2_52sv5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extracting from a very large amount of SQL databases.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a2c6q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693887502.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693857758.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Assume a very large (10k+) number of on premise single tenant databases spread across an arbitrary number of servers. Much of this data needs to be replicated/consolidated to a downstream data lake as quickly as possible (ideally at least twice daily).&lt;/p&gt;\n\n&lt;p&gt;There are obviously a number of challenges for any solution: Concurrent/overall connection limits, memory allocations, resource/object locking, intermediate storage/compute/parallel processing, etc. And that is just at the ingest, but that&amp;#39;s the foundational problem that needs to be solved first.&lt;/p&gt;\n\n&lt;p&gt;Now, my first instict is a migration to a multi-tenant, hybrid cloud/on-prem solution. This would co mingle data sources with lakehouse ingestion processes (AWS ecosystem) and allow easier scaling of the ingestion layer.&lt;/p&gt;\n\n&lt;p&gt;It is unlikely that this will be accomplished in a timely manner and will require the incentivization and coordation of many business and technical stakeholders, some of which may never be convinced/migrated. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to wrap my head around how this would be possible at scale without hitting either concurrent connection issues, untenable memory/processing requirements (on prem servers, no autoscaling), and/or deadlock issues. Current alternatives:&lt;/p&gt;\n\n&lt;p&gt;\u2022Perform CDC via database logs (Debezium) stream to Kafka and sync to S3 (parquet files). Amazon EMR to run spark jobs to archive, merge and compress in paralell. We will assume the merged data across database instances will conform to the same schema. &lt;/p&gt;\n\n&lt;p&gt;\u2022Each database instance performs intermediate data staging/processing for traditional ETL/ELT workloads to consume and deliver to S3.&lt;/p&gt;\n\n&lt;p&gt;\u2022Perform some sort of on prem to cloud DB replication where it will be easier to scale data ingestion.&lt;/p&gt;\n\n&lt;p&gt;Even assuming complete migration to a multi-tenant cloud hosted solution, there will be significant challenges scaling data ingestion to thousands of sources with petabytes of throughput and storage.&lt;/p&gt;\n\n&lt;p&gt;Current plan is to layer Iceberg on top of S3 once we can land the data performantly in the lake. Hoping to avoid raw data replication to DW/ML solution, but not sure of Iceberg&amp;#39;s performance at this scale.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts, critiques, and advice appreciated!&lt;/p&gt;\n\n&lt;p&gt;EDIT-\nBusiness reqs:\n\u2022Source data resides in on prem MSSQL Servers. The number of servers and databases per server are  configurable to balance cost and performance (currently ~1k  DBs per server)&lt;/p&gt;\n\n&lt;p&gt;\u2022Source tables are 20 - 30 in number, 250 - 500 GB in size per  tenant (10k+ tenants). Schemas are the same across DBs.&lt;/p&gt;\n\n&lt;p&gt;\u2022Volume of changes is currently unknown, but could be up to 10 million rows and 10 TB of throughput per semi daily run (say every 4 hours). These are general starting requirements that will scale up. &lt;/p&gt;\n\n&lt;p&gt;\u2022Pipelines for this data currently exist via Fivetran and take 24 hours. So, generally I&amp;#39;m looking to see how parallel CDC or ELT (Debeizun, Spark) could be utilized to speed up the process.&lt;/p&gt;\n\n&lt;p&gt;\u2022Data will land in an S3 data lake to be accessed by Snowflake as the main analytics engine, and other services for AI/ML work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16a2c6q", "is_robot_indexable": true, "report_reasons": null, "author": "Peppper", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16a2c6q/extracting_from_a_very_large_amount_of_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16a2c6q/extracting_from_a_very_large_amount_of_sql/", "subreddit_subscribers": 126870, "created_utc": 1693857758.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was top of my class in college at a state university, one of the very few people who is not only extremely passionate about data and technology, but actually follows through with it myself studying outside of school, cross training, working on projects to try and explore technology, seeing what tech stack companies are using, studying it on my free time. I've built my way up in my career from intern to project Management office, to business analyst, senior data analyst/data engineer. But it's like it's not good enough. Every company wants staff data engineer that comes from FAANG and has at least 7 years of experience, with a computer science background, at least seven different technology stacks, including SSRS, Hadoop, you name it they want it....\n\nLike, I thought we were trying to establish that experience is not the most important thing as a data engineer, passion and ability to learn and grasp what you're doing and perform was? In terms of talent I wouldn't say that I'm one of the best Like obviously not because I don't have formal experience working as an engineer, I have a muddled role like many other people do where I did a lot of data engineering and pipeline building, tons of SQL and Python.... \n\n\nBut these employers want someone who is a veteran. They want someone who has at least 7 years of experience, has seen everything there is to see, can do the job of three different people. It's insane. The requirements are absurd. It's like they don't want someone who's competent and able to do the job, they want someone who is good on paper and checks all the boxes, and that's it", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It feels impossible to get into data engineering no matter how good you are", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a6xhs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693868158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was top of my class in college at a state university, one of the very few people who is not only extremely passionate about data and technology, but actually follows through with it myself studying outside of school, cross training, working on projects to try and explore technology, seeing what tech stack companies are using, studying it on my free time. I&amp;#39;ve built my way up in my career from intern to project Management office, to business analyst, senior data analyst/data engineer. But it&amp;#39;s like it&amp;#39;s not good enough. Every company wants staff data engineer that comes from FAANG and has at least 7 years of experience, with a computer science background, at least seven different technology stacks, including SSRS, Hadoop, you name it they want it....&lt;/p&gt;\n\n&lt;p&gt;Like, I thought we were trying to establish that experience is not the most important thing as a data engineer, passion and ability to learn and grasp what you&amp;#39;re doing and perform was? In terms of talent I wouldn&amp;#39;t say that I&amp;#39;m one of the best Like obviously not because I don&amp;#39;t have formal experience working as an engineer, I have a muddled role like many other people do where I did a lot of data engineering and pipeline building, tons of SQL and Python.... &lt;/p&gt;\n\n&lt;p&gt;But these employers want someone who is a veteran. They want someone who has at least 7 years of experience, has seen everything there is to see, can do the job of three different people. It&amp;#39;s insane. The requirements are absurd. It&amp;#39;s like they don&amp;#39;t want someone who&amp;#39;s competent and able to do the job, they want someone who is good on paper and checks all the boxes, and that&amp;#39;s it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16a6xhs", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16a6xhs/it_feels_impossible_to_get_into_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16a6xhs/it_feels_impossible_to_get_into_data_engineering/", "subreddit_subscribers": 126870, "created_utc": 1693868158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What\u2019s the purpose of the open table format databases (iceberg, hudi, delta lake) if apache doris can achieve much faster query times?\n\nSomeone mentioned cost being a factor where open table format has an advantage since doris does not store the data as efficiently as iceberg e.g. However, if we look at the setup of iceberg the compute resource is very expensive. If we were to look at the on-prem configuration for iceberg with minio:\n\n* \t8 minio, 16vcpus, 64GB ram, 8 disks in each node\n* \tspark using 16vcpus per node. Separate from minio.\n\nIf we install doris we could do with 3 FEs and 5BEs with 8vpcus on FE and 16vcpus on 5 BEs.\n\nCould someone advise on when to use apache doris and when to use open table format dbs? If doris is better why not use it everywhere?", "author_fullname": "t2_a9ji1nkf4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Doris vs Iceberg, Hudi, Delta-lake: Which one?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169rnpl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693833144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s the purpose of the open table format databases (iceberg, hudi, delta lake) if apache doris can achieve much faster query times?&lt;/p&gt;\n\n&lt;p&gt;Someone mentioned cost being a factor where open table format has an advantage since doris does not store the data as efficiently as iceberg e.g. However, if we look at the setup of iceberg the compute resource is very expensive. If we were to look at the on-prem configuration for iceberg with minio:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;  8 minio, 16vcpus, 64GB ram, 8 disks in each node&lt;/li&gt;\n&lt;li&gt;  spark using 16vcpus per node. Separate from minio.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If we install doris we could do with 3 FEs and 5BEs with 8vpcus on FE and 16vcpus on 5 BEs.&lt;/p&gt;\n\n&lt;p&gt;Could someone advise on when to use apache doris and when to use open table format dbs? If doris is better why not use it everywhere?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169rnpl", "is_robot_indexable": true, "report_reasons": null, "author": "CarefulScientist8498", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169rnpl/doris_vs_iceberg_hudi_deltalake_which_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169rnpl/doris_vs_iceberg_hudi_deltalake_which_one/", "subreddit_subscribers": 126870, "created_utc": 1693833144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would love to hear how you build data sharing api's and what tools you use?\n\nour data is of course across many tables. we need to join it and create metrics to share out. Would like to know how everyone approaches this", "author_fullname": "t2_8ijlx2ot", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you build data sharing apis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169o1uv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693821956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would love to hear how you build data sharing api&amp;#39;s and what tools you use?&lt;/p&gt;\n\n&lt;p&gt;our data is of course across many tables. we need to join it and create metrics to share out. Would like to know how everyone approaches this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169o1uv", "is_robot_indexable": true, "report_reasons": null, "author": "Itchy-Side4624", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169o1uv/how_do_you_build_data_sharing_apis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169o1uv/how_do_you_build_data_sharing_apis/", "subreddit_subscribers": 126870, "created_utc": 1693821956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi people,\nFirst time posting on Reddit. I finished school a year ago and I\u2019m currently in a very good company that I really like as a junior DE. \nBut I wonder how is DE in other company near me? How is job market, can you find a big company that have cool DE technology and goals? How much can DE claim as salary ?", "author_fullname": "t2_9vvs3d7wq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How is job market in Western Europe?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a1nkj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693856202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi people,\nFirst time posting on Reddit. I finished school a year ago and I\u2019m currently in a very good company that I really like as a junior DE. \nBut I wonder how is DE in other company near me? How is job market, can you find a big company that have cool DE technology and goals? How much can DE claim as salary ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16a1nkj", "is_robot_indexable": true, "report_reasons": null, "author": "skoleboy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16a1nkj/how_is_job_market_in_western_europe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16a1nkj/how_is_job_market_in_western_europe/", "subreddit_subscribers": 126870, "created_utc": 1693856202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Year 1\n\n* **Communication for the IT Professional**\n* **Internetworking**\n* **Virtualisation**\n* **Professional Issues in IT**\n* **Introduction to Programming**\n* **Internetworking 1**\n* **Introduction to Cyber Security**\n* **Introduction to Databases**\n\nYear 2\n\n* **Advanced data analysis**\n* **Introduction to data analysis**\n* **Network Security**\n* **Critical Thinking for the IT Professional**\n* **Project Management**\n* **Data infrastructure engineering**\n* **Machine learning**\n\nYear 3\n\n* **Data and network security**\n* **Data mining and visualisation**\n* **Emerging trends in data technology**\n* **Major Group Project**\n* **Major Individual Project**\n* **Mobile Computing and Security**\n\nElectives:\n\n* **National Data Infrastructure Security**\n* **Software defined and programmable networks**\n* **Secure Programming**\n* **Cloud Computing**\n* **Distributed computing**\n* **Computer and Network Forensics**\n* **Enterprise Security**\n* **Introduction to Cryptography**\n* **Fundamentals of computer science**\n* **Knowledge Management**\n* **Wireless Networks**\n\nAdditionally, which electives would you recommend me taking?", "author_fullname": "t2_5pilhaal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are these good courses for a Bachelor of IT (Data Engineering) degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169oy1d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693824981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Year 1&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Communication for the IT Professional&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Internetworking&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Virtualisation&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Professional Issues in IT&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Introduction to Programming&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Internetworking 1&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Introduction to Cyber Security&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Introduction to Databases&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Year 2&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Advanced data analysis&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Introduction to data analysis&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Network Security&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Critical Thinking for the IT Professional&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Project Management&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data infrastructure engineering&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Machine learning&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Year 3&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Data and network security&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data mining and visualisation&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Emerging trends in data technology&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Major Group Project&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Major Individual Project&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Mobile Computing and Security&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Electives:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;National Data Infrastructure Security&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Software defined and programmable networks&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Secure Programming&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Cloud Computing&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Distributed computing&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Computer and Network Forensics&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Enterprise Security&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Introduction to Cryptography&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fundamentals of computer science&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Knowledge Management&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Wireless Networks&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Additionally, which electives would you recommend me taking?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169oy1d", "is_robot_indexable": true, "report_reasons": null, "author": "groovyeverywhere", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169oy1d/are_these_good_courses_for_a_bachelor_of_it_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169oy1d/are_these_good_courses_for_a_bachelor_of_it_data/", "subreddit_subscribers": 126870, "created_utc": 1693824981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you are looking for an open role and are refining your LinkedIn, don's miss out on the \"Skills associated with the job post\" feature on LinkedIn job postings. It can be a great resource to tweak your profile, or identify new skills to build!  \n\n\n[https://medium.com/@seancoyne/linkedin-profile-tips-for-data-engineers-part-2-886467ba4b2d](https://medium.com/@seancoyne/linkedin-profile-tips-for-data-engineers-part-2-886467ba4b2d)", "author_fullname": "t2_4fpl974m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Best Way to Optimize Keywords on your LinkedIn Profile", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a5pyb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693865339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you are looking for an open role and are refining your LinkedIn, don&amp;#39;s miss out on the &amp;quot;Skills associated with the job post&amp;quot; feature on LinkedIn job postings. It can be a great resource to tweak your profile, or identify new skills to build!  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@seancoyne/linkedin-profile-tips-for-data-engineers-part-2-886467ba4b2d\"&gt;https://medium.com/@seancoyne/linkedin-profile-tips-for-data-engineers-part-2-886467ba4b2d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zNSolW3ozTfnWyFMRpcJh-03jMpBhTEWZvjS7kPkhCM.jpg?auto=webp&amp;s=dcaafaa341389ef311bf44620f508e25d7e5f064", "width": 500, "height": 334}, "resolutions": [{"url": "https://external-preview.redd.it/zNSolW3ozTfnWyFMRpcJh-03jMpBhTEWZvjS7kPkhCM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6d3c64e4ac5ee8ca9e15582a296490bb32e3f973", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/zNSolW3ozTfnWyFMRpcJh-03jMpBhTEWZvjS7kPkhCM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c0bb2f493d91d05a94916b1a6fcad03402c0dace", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/zNSolW3ozTfnWyFMRpcJh-03jMpBhTEWZvjS7kPkhCM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c95bf0c1e5a432f7363dfa559ff1f94e0e76a2e1", "width": 320, "height": 213}], "variants": {}, "id": "lo_qxDVhJFoT7yOLN4cIFUub3FzD_UXyqb9WzBJpiII"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16a5pyb", "is_robot_indexable": true, "report_reasons": null, "author": "coyne_operated", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16a5pyb/the_best_way_to_optimize_keywords_on_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16a5pyb/the_best_way_to_optimize_keywords_on_your/", "subreddit_subscribers": 126870, "created_utc": 1693865339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have a spark ordering job that takes roughtly 24h to order a handfull of very large tables, that are ordered within partitions of anywhere between 1 and billions of elements, and I am planning to make the process continuous based on newly entering data rather than all-at-once.\n\nThe tables are written to scylla, and the last member of the clustering key is the index of the data in the subset.   \nIf I want to make that continuous, using Apache Flint instead of Spark most probably, inserting one row in one of the very large table partition will trigger a write for millions of rows below to update their index, which I want to avoid.  \nI am wondering, is there any big data oriented database (Apache Iceberg?) that makes it possible to still request rows by their index, but won't trigger millions of rewrite if I insert some rows in the middle of the large partitions ?\n\nI can definitely imagine some algorithm that can do that by either using bins or approximate ordering, and at the cost of a little computing at request time or precision, could save me some precious I/O.\n\nAny idea or suggestion for such a service ?\n\nThank you", "author_fullname": "t2_9t5s9vas", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Keep Huge Tables sorted and accesible by indices.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169zi0d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693851512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have a spark ordering job that takes roughtly 24h to order a handfull of very large tables, that are ordered within partitions of anywhere between 1 and billions of elements, and I am planning to make the process continuous based on newly entering data rather than all-at-once.&lt;/p&gt;\n\n&lt;p&gt;The tables are written to scylla, and the last member of the clustering key is the index of the data in the subset.&lt;br/&gt;\nIf I want to make that continuous, using Apache Flint instead of Spark most probably, inserting one row in one of the very large table partition will trigger a write for millions of rows below to update their index, which I want to avoid.&lt;br/&gt;\nI am wondering, is there any big data oriented database (Apache Iceberg?) that makes it possible to still request rows by their index, but won&amp;#39;t trigger millions of rewrite if I insert some rows in the middle of the large partitions ?&lt;/p&gt;\n\n&lt;p&gt;I can definitely imagine some algorithm that can do that by either using bins or approximate ordering, and at the cost of a little computing at request time or precision, could save me some precious I/O.&lt;/p&gt;\n\n&lt;p&gt;Any idea or suggestion for such a service ?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169zi0d", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious_Buy_8198", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169zi0d/keep_huge_tables_sorted_and_accesible_by_indices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169zi0d/keep_huge_tables_sorted_and_accesible_by_indices/", "subreddit_subscribers": 126870, "created_utc": 1693851512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm wondering what projects helped you land your first job or internship in the data engineering field. Maybe they are projects showcased on your portfolio that employers often ask about? I'm interested in projects that are both challenging and relevant to the real world. For reference, I'm a complete beginner at this but my background is analytics.\n\nIf you have any suggestions, please let me know in the comments. Thanks!\n\n\n[(X-post from /r/datascience)](https://www.reddit.com/r/datascience/comments/169jwcn/data_science_projects_that_helped_land_a/?ref=share&amp;ref_source=link)", "author_fullname": "t2_hoj6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data eng projects that helped land a job/internship", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169sjjc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693835441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wondering what projects helped you land your first job or internship in the data engineering field. Maybe they are projects showcased on your portfolio that employers often ask about? I&amp;#39;m interested in projects that are both challenging and relevant to the real world. For reference, I&amp;#39;m a complete beginner at this but my background is analytics.&lt;/p&gt;\n\n&lt;p&gt;If you have any suggestions, please let me know in the comments. Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/datascience/comments/169jwcn/data_science_projects_that_helped_land_a/?ref=share&amp;amp;ref_source=link\"&gt;(X-post from /r/datascience)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169sjjc", "is_robot_indexable": true, "report_reasons": null, "author": "canopey", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169sjjc/data_eng_projects_that_helped_land_a_jobinternship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169sjjc/data_eng_projects_that_helped_land_a_jobinternship/", "subreddit_subscribers": 126870, "created_utc": 1693835441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a sole data scientist in a very small startup. The team is working on developing certain sensors and are running into issues with sensors disconnecting randomly, sometimes sending data and sometimes not. To help investigate that I'm setting up a dashboard (probably just a jupyter notebook as a first step) to visualize the missing data and find patterns and causes. We want to look at 10sec intervals, for each of those flag if we got data from each sensor, and then continue analysing and searching for patterns.\n\nWhen the sensors do work (which is about 50% of the time), they send 1000+ datapoints per second, so making this aggregation takes a while. I see two options - let me know if there are more -\n\n1. Fetch the full data to the jupyter notebook on my computer, do the aggregation there. This option is the easiest for me but is RAM intensive and not too scalable.\n\n2. Create another table in the DB for these flags and populate it as part of our (still in development) ETL process.\n\nThere must be many companies running into similar issues and tools out there to solve them. I feel like I lack the vocabulary to look into this effectively. What is this called? Availability monitoring? Data gaps detection? Any advice appreciated.", "author_fullname": "t2_dqzrp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DB and automation design for gaps in time series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169sjf7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693835433.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a sole data scientist in a very small startup. The team is working on developing certain sensors and are running into issues with sensors disconnecting randomly, sometimes sending data and sometimes not. To help investigate that I&amp;#39;m setting up a dashboard (probably just a jupyter notebook as a first step) to visualize the missing data and find patterns and causes. We want to look at 10sec intervals, for each of those flag if we got data from each sensor, and then continue analysing and searching for patterns.&lt;/p&gt;\n\n&lt;p&gt;When the sensors do work (which is about 50% of the time), they send 1000+ datapoints per second, so making this aggregation takes a while. I see two options - let me know if there are more -&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Fetch the full data to the jupyter notebook on my computer, do the aggregation there. This option is the easiest for me but is RAM intensive and not too scalable.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Create another table in the DB for these flags and populate it as part of our (still in development) ETL process.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;There must be many companies running into similar issues and tools out there to solve them. I feel like I lack the vocabulary to look into this effectively. What is this called? Availability monitoring? Data gaps detection? Any advice appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169sjf7", "is_robot_indexable": true, "report_reasons": null, "author": "PixelPixell", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169sjf7/db_and_automation_design_for_gaps_in_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169sjf7/db_and_automation_design_for_gaps_in_time_series/", "subreddit_subscribers": 126870, "created_utc": 1693835433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demystifying the Large Language Models (LLMs). For Data Engineers.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": false, "name": "t3_169ronq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7m8JD_FXkCOvZzQRnVNeOYghc72RTMICijJvu4PxrQE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693833215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/demystifying-the-large-language-models", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/skLVFJ3PimDFI-w2rLy0VzUljjhSyHGnIWFT2qnd8dM.jpg?auto=webp&amp;s=acf15a230c9a3e3b0a35f035c0a4723a8bd84f1f", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/skLVFJ3PimDFI-w2rLy0VzUljjhSyHGnIWFT2qnd8dM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=87c29e870b5f0eadb0ee8a8bd63ce1bffecd7a83", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/skLVFJ3PimDFI-w2rLy0VzUljjhSyHGnIWFT2qnd8dM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5bfacf91e5b7613cfcaf8613074a3bbf64986849", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/skLVFJ3PimDFI-w2rLy0VzUljjhSyHGnIWFT2qnd8dM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe1ca3dab9b9b5e1a72292f889b02c9871e0515a", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/skLVFJ3PimDFI-w2rLy0VzUljjhSyHGnIWFT2qnd8dM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=111ab9ac91b43896d6cf8c8e77a66db1e44d686a", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/skLVFJ3PimDFI-w2rLy0VzUljjhSyHGnIWFT2qnd8dM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2ee160a6e873517543d6eb0ae376ded6ceb63c0d", "width": 960, "height": 562}], "variants": {}, "id": "Dyezpto4F-kn1blyUEsQnbHhTtmPgrMNrrD2x5zlP0U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "169ronq", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169ronq/demystifying_the_large_language_models_llms_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/demystifying-the-large-language-models", "subreddit_subscribers": 126870, "created_utc": 1693833215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Ken jee is Data scientist. He has been doing data work from 7 years. In my opinion he is good at explaining how the data industry works and seems legitimate.\n\nAlthough I have a question to ask, Is this true the supply is very less in data engineer roles? I even heard from Mike west (who is data engineer, and working for several years with big companies, also creator), that data engineer is probably the most sexiest job than data scientist or any other tech jobs.\n\nI just want to start a discussion here regarding this. The reason is that many people complain a lot that the job market is dry and there aren't many jobs available. I genuinely believe it's because of their competence as data engineers.\n\nSource: https://youtube.com/shorts/L6lXKdP4Qbg?si=fjUKofmNk7DE75yf", "author_fullname": "t2_8i81bbqr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are the supply &amp; demand of data roles is imbalanced??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169r2hc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693831567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ken jee is Data scientist. He has been doing data work from 7 years. In my opinion he is good at explaining how the data industry works and seems legitimate.&lt;/p&gt;\n\n&lt;p&gt;Although I have a question to ask, Is this true the supply is very less in data engineer roles? I even heard from Mike west (who is data engineer, and working for several years with big companies, also creator), that data engineer is probably the most sexiest job than data scientist or any other tech jobs.&lt;/p&gt;\n\n&lt;p&gt;I just want to start a discussion here regarding this. The reason is that many people complain a lot that the job market is dry and there aren&amp;#39;t many jobs available. I genuinely believe it&amp;#39;s because of their competence as data engineers.&lt;/p&gt;\n\n&lt;p&gt;Source: &lt;a href=\"https://youtube.com/shorts/L6lXKdP4Qbg?si=fjUKofmNk7DE75yf\"&gt;https://youtube.com/shorts/L6lXKdP4Qbg?si=fjUKofmNk7DE75yf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4JBLh-yGMSKGFsBNT97ayxOu5hNuh6GfyMyCdMznDu8.jpg?auto=webp&amp;s=284c4eaad296ca46a881d8e20ae5195d46c4f76c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/4JBLh-yGMSKGFsBNT97ayxOu5hNuh6GfyMyCdMznDu8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=193cdd2d67b1693b4e5262105f518928bfccaba3", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/4JBLh-yGMSKGFsBNT97ayxOu5hNuh6GfyMyCdMznDu8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7709b97108eda8e31a2d90a9177f7cd5eca62fa1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/4JBLh-yGMSKGFsBNT97ayxOu5hNuh6GfyMyCdMznDu8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=210abbe77d05f697efcf3c28a02951ec73b4a9e3", "width": 320, "height": 240}], "variants": {}, "id": "qMhhR0bFWhCJIv4Go9Ra8jRditTLzZ8IORfOcVIAcvM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169r2hc", "is_robot_indexable": true, "report_reasons": null, "author": "trafalgar28", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169r2hc/are_the_supply_demand_of_data_roles_is_imbalanced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169r2hc/are_the_supply_demand_of_data_roles_is_imbalanced/", "subreddit_subscribers": 126870, "created_utc": 1693831567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, we currently download geographical data from various APIs and save this data in an Azure Datalake. Then, we transform this data and store it back in the Datalake. We use these transformed data as input for a forecasting algorithm, and subsequently save this forecast back into the Datalake. Lastly, we utilize these data to integrate into our portal. At present, we manually create a data warehouse using Python and PostgreSQL, attempting to log every operation conducted in our Datalake along with its metadata. This is to avoid making many API calls to the Datalake listing all the files, as our forecasting algorithms require accessing multiple data from previous days. The problem is, it feels like we're trying to reinvent the wheel and the system became complex during development. Is there an existing solution to help us with this use case of automatically cataloging our data in a Datalake? It could be a Python library or a tool that we can host on an Azure machine. I am new to this area, so I would like suggestions.", "author_fullname": "t2_9ca451os", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for data warehouse tools for my use case", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169o71m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693822448.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, we currently download geographical data from various APIs and save this data in an Azure Datalake. Then, we transform this data and store it back in the Datalake. We use these transformed data as input for a forecasting algorithm, and subsequently save this forecast back into the Datalake. Lastly, we utilize these data to integrate into our portal. At present, we manually create a data warehouse using Python and PostgreSQL, attempting to log every operation conducted in our Datalake along with its metadata. This is to avoid making many API calls to the Datalake listing all the files, as our forecasting algorithms require accessing multiple data from previous days. The problem is, it feels like we&amp;#39;re trying to reinvent the wheel and the system became complex during development. Is there an existing solution to help us with this use case of automatically cataloging our data in a Datalake? It could be a Python library or a tool that we can host on an Azure machine. I am new to this area, so I would like suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169o71m", "is_robot_indexable": true, "report_reasons": null, "author": "MiserableAstronaut77", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169o71m/looking_for_data_warehouse_tools_for_my_use_case/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169o71m/looking_for_data_warehouse_tools_for_my_use_case/", "subreddit_subscribers": 126870, "created_utc": 1693822448.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "my intention\n\nuse postgres to do inserts on data\n\nuse a different database for analytics based on what is constantly being inserted updated in postgres\n\nthe other db is for offloading reading of data and for the purpose of making it real-time or a fake real-time\n\nthe main database is only for insert and update i can't make use of materialize view inside the master database\n\n&amp;#x200B;", "author_fullname": "t2_9zltgu7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "i was wondering is there a way to replicate a postgres database to another different database for analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16aenrm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693889605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;my intention&lt;/p&gt;\n\n&lt;p&gt;use postgres to do inserts on data&lt;/p&gt;\n\n&lt;p&gt;use a different database for analytics based on what is constantly being inserted updated in postgres&lt;/p&gt;\n\n&lt;p&gt;the other db is for offloading reading of data and for the purpose of making it real-time or a fake real-time&lt;/p&gt;\n\n&lt;p&gt;the main database is only for insert and update i can&amp;#39;t make use of materialize view inside the master database&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16aenrm", "is_robot_indexable": true, "report_reasons": null, "author": "Exact-Yesterday-992", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16aenrm/i_was_wondering_is_there_a_way_to_replicate_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16aenrm/i_was_wondering_is_there_a_way_to_replicate_a/", "subreddit_subscribers": 126870, "created_utc": 1693889605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nI am an EU-National with six years of experience in the public research in Germany and would like to find a Data Engineering job in the UK for 2024. I am a bit tired with the search right now. It seems that 99% of employers there do not offer a visa sponsorship and the market is anyway bad a the moment. Is there anything productive I can do instead of just waiting that things get better? ", "author_fullname": "t2_amgmy56m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Positions in the UK and Visa Sponsorships", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169stxg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693836152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I am an EU-National with six years of experience in the public research in Germany and would like to find a Data Engineering job in the UK for 2024. I am a bit tired with the search right now. It seems that 99% of employers there do not offer a visa sponsorship and the market is anyway bad a the moment. Is there anything productive I can do instead of just waiting that things get better? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "169stxg", "is_robot_indexable": true, "report_reasons": null, "author": "Cygnus778", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169stxg/data_engineering_positions_in_the_uk_and_visa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169stxg/data_engineering_positions_in_the_uk_and_visa/", "subreddit_subscribers": 126870, "created_utc": 1693836152.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear all, \nI am trying to implement an interface between an ERP system and a MES system. \nProduction orders (po) shall be transferred when released in the erp system. Communication is done via REST.\n\nI am not sure which architektur to pick.\nOn the one hand, I could implement a trigger in the ERP system via programming that when a po is released necessary data will be transferred. On the other hand, I could implement CDC (log based change data capture) on sql server side. \n\nMy toughts: Since you can manipulate the status of an PO at many different places in the system I will need a lot of coding. I would rather try to avoid this. With the sql Solution, I would watch only one table for changes. \n\nAppreciate your thoughts!", "author_fullname": "t2_rvcqr61d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MES - ERP Interface", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169qt5h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693830798.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all, \nI am trying to implement an interface between an ERP system and a MES system. \nProduction orders (po) shall be transferred when released in the erp system. Communication is done via REST.&lt;/p&gt;\n\n&lt;p&gt;I am not sure which architektur to pick.\nOn the one hand, I could implement a trigger in the ERP system via programming that when a po is released necessary data will be transferred. On the other hand, I could implement CDC (log based change data capture) on sql server side. &lt;/p&gt;\n\n&lt;p&gt;My toughts: Since you can manipulate the status of an PO at many different places in the system I will need a lot of coding. I would rather try to avoid this. With the sql Solution, I would watch only one table for changes. &lt;/p&gt;\n\n&lt;p&gt;Appreciate your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169qt5h", "is_robot_indexable": true, "report_reasons": null, "author": "Limp_Recording3399", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169qt5h/mes_erp_interface/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169qt5h/mes_erp_interface/", "subreddit_subscribers": 126870, "created_utc": 1693830798.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Why Data Craves Product Managers Beyond Doubt\": The Data Product Manager, Product Strategies, and the Pointless War on Definitions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_169pysz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CyJSDqToa-p8X411gFwiksqFpoijnF4iWhMAXF8Mn0M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693828303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/unveiling-a-necessity-why-data-craves", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?auto=webp&amp;s=bc3e828bb0254b9dddcb46350602ea32b1ce35ec", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=91222858a7a91f974fa1ed8f5041c3059afa21a3", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1d03e9048f845f06239a80a12e2bbea5e1bdc81d", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=10dd292a124cfa0530368c0804eaa7407bfe42a0", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b8406e434fd7593c3f9d58bf2493eba70e8a2a4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=94a8623dd89033cd0a0a39c0cec1316ea6e5a770", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/xdoPK4oo5G_BNZ74vhbzWZ1_hp-jYgXXonOoxbtenhs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b8df557ea182c92f684b3f21d04a7b3b12ad8576", "width": 1080, "height": 540}], "variants": {}, "id": "nuFhIdW5-Vx-iWhaSXDeNr7dLeCdylJgzLdJOMDHyTM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "169pysz", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169pysz/why_data_craves_product_managers_beyond_doubt_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/unveiling-a-necessity-why-data-craves", "subreddit_subscribers": 126870, "created_utc": 1693828303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, \n\nChecking in to see if any of you would share some input regarding the following problem I'm currently looking into. \n\nUse case: \n\nMy departement have manually been maintaining around 100-150 SQL tables by writing insert queries to update or modify the data. The data is typically \"business knowledge\", which is not available through any of our other systems. We're now moving out of our onprem platform, and thus - need to migrate these tables as well. I'm currently looking into tooling's which can simplify this experience, but I'm struggling to find a solid candidate.\n\n&amp;#x200B;\n\nI want something that is easy to use for the business, so we can transfer the ownership back to them and not have to maintain this on our own, but rather just read the data on a need to basis. preferably I'd like to connect directly to an Azure SQL server if possible. Also, additional things like data quality rules, access management, etc. are nice to haves. \n\n&amp;#x200B;\n\nDoes anyone have any suggestions or experience to add here? The more seasoned guys are talking about MDS and Microsoft Access as potential products but have little to no experience regarding any of them.  Any input weel be much appreciated \n\n&amp;#x200B;\n\nAdditional Info:\n\n* Primarily azure stack \n* Can create some low-code/no-code solutions using PowerApps ", "author_fullname": "t2_4dzyhxpi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Experience regarding tooling for manual data entry?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169puga", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693827931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;Checking in to see if any of you would share some input regarding the following problem I&amp;#39;m currently looking into. &lt;/p&gt;\n\n&lt;p&gt;Use case: &lt;/p&gt;\n\n&lt;p&gt;My departement have manually been maintaining around 100-150 SQL tables by writing insert queries to update or modify the data. The data is typically &amp;quot;business knowledge&amp;quot;, which is not available through any of our other systems. We&amp;#39;re now moving out of our onprem platform, and thus - need to migrate these tables as well. I&amp;#39;m currently looking into tooling&amp;#39;s which can simplify this experience, but I&amp;#39;m struggling to find a solid candidate.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want something that is easy to use for the business, so we can transfer the ownership back to them and not have to maintain this on our own, but rather just read the data on a need to basis. preferably I&amp;#39;d like to connect directly to an Azure SQL server if possible. Also, additional things like data quality rules, access management, etc. are nice to haves. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any suggestions or experience to add here? The more seasoned guys are talking about MDS and Microsoft Access as potential products but have little to no experience regarding any of them.  Any input weel be much appreciated &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Additional Info:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Primarily azure stack &lt;/li&gt;\n&lt;li&gt;Can create some low-code/no-code solutions using PowerApps &lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "169puga", "is_robot_indexable": true, "report_reasons": null, "author": "ejn999", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169puga/experience_regarding_tooling_for_manual_data_entry/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169puga/experience_regarding_tooling_for_manual_data_entry/", "subreddit_subscribers": 126870, "created_utc": 1693827931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a background for this, in my current workplace we don't necessarily have a huge volume of data but the variance is high. We have a graph data model so each row of data from our customers might end up being split into 25 different nodes (or objects, it\nif you like). We have been heavily relying on Pydantic for this, in conjunction with some asyncio coding, but it's still just a simple iteration going on. We plan to do this through Redpanda or RabbitMQ down the line, for now it's just fine. Essentially this is our E and T stage in ETL.\n\nI am curious to know how others have been using schema validator like Pydantic in other usecases as well!", "author_fullname": "t2_12lkky", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you using Pydantic for data projects? (and other similar schema libraries)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169ooln", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693824102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a background for this, in my current workplace we don&amp;#39;t necessarily have a huge volume of data but the variance is high. We have a graph data model so each row of data from our customers might end up being split into 25 different nodes (or objects, it\nif you like). We have been heavily relying on Pydantic for this, in conjunction with some asyncio coding, but it&amp;#39;s still just a simple iteration going on. We plan to do this through Redpanda or RabbitMQ down the line, for now it&amp;#39;s just fine. Essentially this is our E and T stage in ETL.&lt;/p&gt;\n\n&lt;p&gt;I am curious to know how others have been using schema validator like Pydantic in other usecases as well!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Plumber", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169ooln", "is_robot_indexable": true, "report_reasons": null, "author": "ratulotron", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/169ooln/how_are_you_using_pydantic_for_data_projects_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169ooln/how_are_you_using_pydantic_for_data_projects_and/", "subreddit_subscribers": 126870, "created_utc": 1693824102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI would like some feedback on my teams role and see how much of it is DE. I currently work at a university affiliated research organization as sort of a senior data analyst. On our team, our main job is to intake raw data, standardize them for modelers to use. I had thought what my team does is very closely related to data engineering but we rely 85% on Python and 15% SQL Database. We also create ad-hoc Tableau visuals and maintain R Shiny interactive dashboards. \n\nThere are other teams that maintain our in house compute cluster, our file systems (3rd party), and also database management. They give us the tools and infrastructure to do our work. All we really have to do is focus on writing solid python code and leverage the computing cluster to clean all the raw datasets and send them through our pipeline to ensure they are consistent and comparable. Then we upload them all to a SQL database. Other teams maintain python functions/machinery that interact with the database for modelers to pull the data without SQL queries.\n\nOur raw data mostly comes as .csv and .dta files. We do a good job of maintaining replicability and consistency by git tracking our codebase and version tracking our pipeline inputs and dataset metadata with our own database. We are able to find root causes if our final outputs have issues and apply a fix fairly quickly. We understand how to structure and run our code so we do not overload the database and filesystems and improve overall efficiency. Although with our computation cluster, we can apply distributed computing fairly easily.\n\nOverall, I think my team has a good system in place to process all this data but just a little outdated. It also feels like some important aspects of DE are outsourced to other teams. Someone on our team recently is exploring PySpark to help with processing, someone else had implemented Dask. Its a little hard for me to explain all what my teams does in detail but what do you guys think?\n\nThanks in advance!", "author_fullname": "t2_9nvslz1w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on my teams role", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a895o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693871940.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693871436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I would like some feedback on my teams role and see how much of it is DE. I currently work at a university affiliated research organization as sort of a senior data analyst. On our team, our main job is to intake raw data, standardize them for modelers to use. I had thought what my team does is very closely related to data engineering but we rely 85% on Python and 15% SQL Database. We also create ad-hoc Tableau visuals and maintain R Shiny interactive dashboards. &lt;/p&gt;\n\n&lt;p&gt;There are other teams that maintain our in house compute cluster, our file systems (3rd party), and also database management. They give us the tools and infrastructure to do our work. All we really have to do is focus on writing solid python code and leverage the computing cluster to clean all the raw datasets and send them through our pipeline to ensure they are consistent and comparable. Then we upload them all to a SQL database. Other teams maintain python functions/machinery that interact with the database for modelers to pull the data without SQL queries.&lt;/p&gt;\n\n&lt;p&gt;Our raw data mostly comes as .csv and .dta files. We do a good job of maintaining replicability and consistency by git tracking our codebase and version tracking our pipeline inputs and dataset metadata with our own database. We are able to find root causes if our final outputs have issues and apply a fix fairly quickly. We understand how to structure and run our code so we do not overload the database and filesystems and improve overall efficiency. Although with our computation cluster, we can apply distributed computing fairly easily.&lt;/p&gt;\n\n&lt;p&gt;Overall, I think my team has a good system in place to process all this data but just a little outdated. It also feels like some important aspects of DE are outsourced to other teams. Someone on our team recently is exploring PySpark to help with processing, someone else had implemented Dask. Its a little hard for me to explain all what my teams does in detail but what do you guys think?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16a895o", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Chemical4044", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16a895o/feedback_on_my_teams_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16a895o/feedback_on_my_teams_role/", "subreddit_subscribers": 126870, "created_utc": 1693871436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Until the middle of April this year, I used the SNScraper library to get tweets and replies for each tweet. But recently this library does not work. I use replies for sentiment analysis. \n\nCan you recommend a library in Python and R that is maintained and that enables the output of the reply? ,", "author_fullname": "t2_a7z87sfr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Twitter library for scraping tweets and replies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169zoj3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693851917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Until the middle of April this year, I used the SNScraper library to get tweets and replies for each tweet. But recently this library does not work. I use replies for sentiment analysis. &lt;/p&gt;\n\n&lt;p&gt;Can you recommend a library in Python and R that is maintained and that enables the output of the reply? ,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "169zoj3", "is_robot_indexable": true, "report_reasons": null, "author": "gjinokastra", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169zoj3/twitter_library_for_scraping_tweets_and_replies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/169zoj3/twitter_library_for_scraping_tweets_and_replies/", "subreddit_subscribers": 126870, "created_utc": 1693851917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cb5j4xjcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Semi-structured data modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_169o3x4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3ZtDB20cZT6A3LX8fKQ-2X61VSMuNIvCuNPAt5K40ls.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693822145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "reddit.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/r/SQL/comments/169o1ts/semistructured_data_modeling_firebolt/?utm_source=share&amp;utm_medium=web2x&amp;context=3", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?auto=webp&amp;s=833f6ef5a8f5faa26b3e83468504526cd82f1695", "width": 1200, "height": 1317}, "resolutions": [{"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=67b10932c6d3d18f91c769e7cafdaf5d1cc455ff", "width": 108, "height": 118}, {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c80b3e39c2cdd1ded87008dca3e70151be3a6176", "width": 216, "height": 237}, {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f95c25186230bc3ccf34656e0b4e794400cad1a", "width": 320, "height": 351}, {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=39b57294e1d4fae5824e7540d7cdc71a13147b4e", "width": 640, "height": 702}, {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=bd6836cf9ca5e5afef430ec98b4745948ec26f02", "width": 960, "height": 1053}, {"url": "https://external-preview.redd.it/8lGMk9ML5tVAE7GVsPBvEOBWtTXb9et3JvMbg-uXAM4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=621012b93de740a58720a943ad89cb444adc3e66", "width": 1080, "height": 1185}], "variants": {}, "id": "jfZxUG5Arretfp5CC6Dl5Pxy_2XTUY2Fs_Jv4_um2tQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "169o3x4", "is_robot_indexable": true, "report_reasons": null, "author": "Numerous-Surround882", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/169o3x4/semistructured_data_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/SQL/comments/169o1ts/semistructured_data_modeling_firebolt/?utm_source=share&amp;utm_medium=web2x&amp;context=3", "subreddit_subscribers": 126870, "created_utc": 1693822145.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}