{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been looking into the differences between these 3 job titles, and am having trouble wrapping my head around the differences\n\n* Data Engineer\n* Data Platform Engineer\n* Software Engineer - Data Platform\n\nI guess for the purpose of the question, the DE title can exclude analytics engineer and focus more on the infrastructure side rather than analytics\n\nIn addition, what even is a 'data platform' :P", "author_fullname": "t2_clatkkc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the difference between a data engineer, a data platform engineer, and a software engineer - data platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16dgqgl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694194306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been looking into the differences between these 3 job titles, and am having trouble wrapping my head around the differences&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data Engineer&lt;/li&gt;\n&lt;li&gt;Data Platform Engineer&lt;/li&gt;\n&lt;li&gt;Software Engineer - Data Platform&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I guess for the purpose of the question, the DE title can exclude analytics engineer and focus more on the infrastructure side rather than analytics&lt;/p&gt;\n\n&lt;p&gt;In addition, what even is a &amp;#39;data platform&amp;#39; :P&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16dgqgl", "is_robot_indexable": true, "report_reasons": null, "author": "NFeruch", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dgqgl/what_is_the_difference_between_a_data_engineer_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dgqgl/what_is_the_difference_between_a_data_engineer_a/", "subreddit_subscribers": 127511, "created_utc": 1694194306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all!  \n\n\nI am currently a data engineer and use PySpark and Typescript daily for my job. I just started learning Rust in my free time was wondering if this language is prevalent/useful to learn in the data engineering space. If you do use Rust in your current role can you elaborate how/where you implement it in a project and why it is used over other languages/", "author_fullname": "t2_f75f3hi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rust in Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16dgor2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694194199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!  &lt;/p&gt;\n\n&lt;p&gt;I am currently a data engineer and use PySpark and Typescript daily for my job. I just started learning Rust in my free time was wondering if this language is prevalent/useful to learn in the data engineering space. If you do use Rust in your current role can you elaborate how/where you implement it in a project and why it is used over other languages/&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16dgor2", "is_robot_indexable": true, "report_reasons": null, "author": "hsimpsondata", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dgor2/rust_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dgor2/rust_in_data_engineering/", "subreddit_subscribers": 127511, "created_utc": 1694194199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My customer wants to move from a AirFlow-Python process that has a lot of flexibility to Matillion and I am helping them make that transition.  There are \\~500 excel files (\\~500 lines/5MB each) that need to be configured, transformed and there are numerous rules that need to be applied to make the data usable. My worry is that these rules will be hard to configure in Matlillion, is it better to these rules reside outside Matillion so it is easier to support and change or does Matillion provide a custom script module. Any idea on the costs of deploying Matillion.  They have quoted a flat $40K/year license fee and something like $4.80/hour for executing the data flows.  My worry is that this $4.80/hour is not very clear and transparent.  Any insights would be helpful", "author_fullname": "t2_v2liy5jt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Matillion Opinion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16do38w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694211443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My customer wants to move from a AirFlow-Python process that has a lot of flexibility to Matillion and I am helping them make that transition.  There are ~500 excel files (~500 lines/5MB each) that need to be configured, transformed and there are numerous rules that need to be applied to make the data usable. My worry is that these rules will be hard to configure in Matlillion, is it better to these rules reside outside Matillion so it is easier to support and change or does Matillion provide a custom script module. Any idea on the costs of deploying Matillion.  They have quoted a flat $40K/year license fee and something like $4.80/hour for executing the data flows.  My worry is that this $4.80/hour is not very clear and transparent.  Any insights would be helpful&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16do38w", "is_robot_indexable": true, "report_reasons": null, "author": "Acrobatic_Cell4364", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16do38w/matillion_opinion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16do38w/matillion_opinion/", "subreddit_subscribers": 127511, "created_utc": 1694211443.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\n\n**There are 2 types of developers, those who swear by mongo and those who swear AT mongo...**\n\nThere are a lot of jokes that go around about MongoDB but they are all centered around the schemaless part... MongoDB is like a box of chocolates \u2013 you never know what you're gonna get...\n\nI'm a data engineer who doesn't use Mongo for apps, but as a data source which has to be integrated into SQL with explicit schemas.\n\nI wrote an article explaining why some developers (data engineers who don't benefit from application logic) experience this pain around using mongo data.\n\nAdditionally, in the article you will find an open source python pipeline with schema evolution that can load your MongoDB collections effortlessly to an analytical SQL db.\n\n1. Read mongo data\n2. declare how to load it to SQL (replace/append/upsert)\n3. Automagically have a schema inferred, data unnested and loaded to sql.\n\nHere is the link. I tried to keep it light hearted and funny. [https://dlthub.com/docs/blog/mongo-etl](https://dlthub.com/docs/blog/mongo-etl)\n\nFeedback welcome!", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL from mongoDB - why is it hard, an open source pipeline, and a few jokes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16d4150", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694158656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;There are 2 types of developers, those who swear by mongo and those who swear AT mongo...&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;There are a lot of jokes that go around about MongoDB but they are all centered around the schemaless part... MongoDB is like a box of chocolates \u2013 you never know what you&amp;#39;re gonna get...&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a data engineer who doesn&amp;#39;t use Mongo for apps, but as a data source which has to be integrated into SQL with explicit schemas.&lt;/p&gt;\n\n&lt;p&gt;I wrote an article explaining why some developers (data engineers who don&amp;#39;t benefit from application logic) experience this pain around using mongo data.&lt;/p&gt;\n\n&lt;p&gt;Additionally, in the article you will find an open source python pipeline with schema evolution that can load your MongoDB collections effortlessly to an analytical SQL db.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Read mongo data&lt;/li&gt;\n&lt;li&gt;declare how to load it to SQL (replace/append/upsert)&lt;/li&gt;\n&lt;li&gt;Automagically have a schema inferred, data unnested and loaded to sql.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Here is the link. I tried to keep it light hearted and funny. &lt;a href=\"https://dlthub.com/docs/blog/mongo-etl\"&gt;https://dlthub.com/docs/blog/mongo-etl&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Feedback welcome!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/h6n9MCCS9sS-pVwcmTvpADnID0uuowbYig43eqRfWIY.jpg?auto=webp&amp;s=22e18b38845916a8579a32bf02aa3fec455a76c0", "width": 567, "height": 540}, "resolutions": [{"url": "https://external-preview.redd.it/h6n9MCCS9sS-pVwcmTvpADnID0uuowbYig43eqRfWIY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1c76156b8b99b1c66682fca2c6c2b91bac443bf6", "width": 108, "height": 102}, {"url": "https://external-preview.redd.it/h6n9MCCS9sS-pVwcmTvpADnID0uuowbYig43eqRfWIY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=794741b6485bab9e5b04c73985a13ec922b94876", "width": 216, "height": 205}, {"url": "https://external-preview.redd.it/h6n9MCCS9sS-pVwcmTvpADnID0uuowbYig43eqRfWIY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=621cac846c7891cc7e6f9af288acac7092c78102", "width": 320, "height": 304}], "variants": {}, "id": "h5T_cQWQK0DD5kGMFznyHF5oI5Bb6Ar0ux_4olTDRKM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16d4150", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16d4150/etl_from_mongodb_why_is_it_hard_an_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16d4150/etl_from_mongodb_why_is_it_hard_an_open_source/", "subreddit_subscribers": 127511, "created_utc": 1694158656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\n I am writing my thesis on the further development of data warehouses (in an enterprise context). The appropriate term for this would be data engineering. It's about data acquisition, data integration, and the development of the ETL process. \n\nWhat are the differences between the job of a data engineer and the job of a software engineer who develops applications? I am looking for differences and also special features that distinguish the data engineering process from the software engineering process. Do you have any opinions on this or can you recommend further literature? ", "author_fullname": "t2_hrqrf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Differences between Data Engineering and Software Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16d2bu5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694152894.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I am writing my thesis on the further development of data warehouses (in an enterprise context). The appropriate term for this would be data engineering. It&amp;#39;s about data acquisition, data integration, and the development of the ETL process. &lt;/p&gt;\n\n&lt;p&gt;What are the differences between the job of a data engineer and the job of a software engineer who develops applications? I am looking for differences and also special features that distinguish the data engineering process from the software engineering process. Do you have any opinions on this or can you recommend further literature? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16d2bu5", "is_robot_indexable": true, "report_reasons": null, "author": "m3xx4", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16d2bu5/differences_between_data_engineering_and_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16d2bu5/differences_between_data_engineering_and_software/", "subreddit_subscribers": 127511, "created_utc": 1694152894.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Edit: I don't mean SQL is trash. But my SQL abilities are trash\n\nSo I'm applying for jobs and have been using Stratascratch to practice SQL questions and I am really struggling with window functions. Especially those that use CTEs. I'm reading articles and watching videos on it to gain understanding and improve. The problem is I haven't properly been able to recognise when to use window functions or how to put it into an explanatory form for myself that makes sense. \n\nMy approach is typically try a group by and if that fails then I use a window function and determine what to aggregate by based on that. I'm not even getting into ranks and dense rank and all that. Wanna start with just basic window functions first and then get into those plus CTEs with window functions. \n\nIf anyone could give me some tips, hints, or anything that allowed this to click into place for them I am very thankful. Currently feeling like I'm stupid af. I was able to understand advanced calculus but struggling with this. I found the Stratascratch articles on window functions that I'm going to go through and try with. I'd appreciate any other resources or how someone explains it for themselves to make sense.\n\nEdit: Wanna say thanks in advance to those who've answered and will answer. About to not have phone access for a bit. But believe I'll be responding to them all with further questions. This community has truly been amazing and so informative with questions I have regarding this field. You're all absolutely awesome, thank you", "author_fullname": "t2_p5wlf0g4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL is trash", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16dktkh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694205597.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694203957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edit: I don&amp;#39;t mean SQL is trash. But my SQL abilities are trash&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m applying for jobs and have been using Stratascratch to practice SQL questions and I am really struggling with window functions. Especially those that use CTEs. I&amp;#39;m reading articles and watching videos on it to gain understanding and improve. The problem is I haven&amp;#39;t properly been able to recognise when to use window functions or how to put it into an explanatory form for myself that makes sense. &lt;/p&gt;\n\n&lt;p&gt;My approach is typically try a group by and if that fails then I use a window function and determine what to aggregate by based on that. I&amp;#39;m not even getting into ranks and dense rank and all that. Wanna start with just basic window functions first and then get into those plus CTEs with window functions. &lt;/p&gt;\n\n&lt;p&gt;If anyone could give me some tips, hints, or anything that allowed this to click into place for them I am very thankful. Currently feeling like I&amp;#39;m stupid af. I was able to understand advanced calculus but struggling with this. I found the Stratascratch articles on window functions that I&amp;#39;m going to go through and try with. I&amp;#39;d appreciate any other resources or how someone explains it for themselves to make sense.&lt;/p&gt;\n\n&lt;p&gt;Edit: Wanna say thanks in advance to those who&amp;#39;ve answered and will answer. About to not have phone access for a bit. But believe I&amp;#39;ll be responding to them all with further questions. This community has truly been amazing and so informative with questions I have regarding this field. You&amp;#39;re all absolutely awesome, thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16dktkh", "is_robot_indexable": true, "report_reasons": null, "author": "El_Cato_Crande", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dktkh/sql_is_trash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dktkh/sql_is_trash/", "subreddit_subscribers": 127511, "created_utc": 1694203957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Was wondering if you seasoned veterans wouldn't mind sharing some great books or must-reads for junior/mid level data engineers and aspirers to prep for technical interview rounds, learn new concepts, and solidify knowledge in 2023? Areas like system design, big data, ETLs which are pertinent to the data engineering realm. \n\nI know how asking direct questions like this are received, but asking as someone without a CS degree, who has ended up in data engineering with some hands on experience, but preparing for interviews in the \"big leagues\" so to speak. \n\nMuch thanks in advance. ", "author_fullname": "t2_c37nxl2c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book or article/blog recommendations for interview prep in 2023?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16dsnrc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694223251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was wondering if you seasoned veterans wouldn&amp;#39;t mind sharing some great books or must-reads for junior/mid level data engineers and aspirers to prep for technical interview rounds, learn new concepts, and solidify knowledge in 2023? Areas like system design, big data, ETLs which are pertinent to the data engineering realm. &lt;/p&gt;\n\n&lt;p&gt;I know how asking direct questions like this are received, but asking as someone without a CS degree, who has ended up in data engineering with some hands on experience, but preparing for interviews in the &amp;quot;big leagues&amp;quot; so to speak. &lt;/p&gt;\n\n&lt;p&gt;Much thanks in advance. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16dsnrc", "is_robot_indexable": true, "report_reasons": null, "author": "Rengar-Pounce", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dsnrc/book_or_articleblog_recommendations_for_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dsnrc/book_or_articleblog_recommendations_for_interview/", "subreddit_subscribers": 127511, "created_utc": 1694223251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve got a windows box that has some old software that I need to run files through occasionally. I figure why not use a prefect flow to pull the file from s3, run a command, and reupload the processed file to s3. \n\nWindows box can be a prefect worker, s3 and credentials as blocks in prefect, and logging should be sent back to the prefect api. I\u2019ve tried deploying the flow to s3 so that the worker can access it without my git repo being on this box, but I\u2019ve run into two problems.\n\n1. When I launch the process as a worker (not agent) then it says only localfilesystem is supported (wtf?)\n\n2. When I launch as an agent it\u2019s still not pulling even though I\u2019ve set the push/pull actions on the deployment. \n\nSide note, the deployment yml won\u2019t let me reference an s3 block for the bucket/folder values in the pull/push actions\u2026\n\nAnybody got this working well?", "author_fullname": "t2_1eht5os", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone figure out Prefect remote deployments?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16djcr4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694200465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve got a windows box that has some old software that I need to run files through occasionally. I figure why not use a prefect flow to pull the file from s3, run a command, and reupload the processed file to s3. &lt;/p&gt;\n\n&lt;p&gt;Windows box can be a prefect worker, s3 and credentials as blocks in prefect, and logging should be sent back to the prefect api. I\u2019ve tried deploying the flow to s3 so that the worker can access it without my git repo being on this box, but I\u2019ve run into two problems.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;When I launch the process as a worker (not agent) then it says only localfilesystem is supported (wtf?)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;When I launch as an agent it\u2019s still not pulling even though I\u2019ve set the push/pull actions on the deployment. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Side note, the deployment yml won\u2019t let me reference an s3 block for the bucket/folder values in the pull/push actions\u2026&lt;/p&gt;\n\n&lt;p&gt;Anybody got this working well?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16djcr4", "is_robot_indexable": true, "report_reasons": null, "author": "mbsquad24", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16djcr4/anyone_figure_out_prefect_remote_deployments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16djcr4/anyone_figure_out_prefect_remote_deployments/", "subreddit_subscribers": 127511, "created_utc": 1694200465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI\u2019m preparing for the Databricks Data Engineering Associate Exam.\n\nI did some practice exam I could find, some passed between 75-80, some between 85-90. After that I reviewed my wrong answers and most of them were wrong because I didn\u2019t pay enough attention to the way the question was formulated. Some of them are \u201cwhat does NOT not xyz\u201d, some are tricky, anyway. Will be more serious when it\u2019s the real exam. \n\nAnybody here with that certification that maybe has some tips on what to focus? At this point I don\u2019t know what else to study.", "author_fullname": "t2_7sauoft1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Data Engineering Associate Exam", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16dind7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694198817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m preparing for the Databricks Data Engineering Associate Exam.&lt;/p&gt;\n\n&lt;p&gt;I did some practice exam I could find, some passed between 75-80, some between 85-90. After that I reviewed my wrong answers and most of them were wrong because I didn\u2019t pay enough attention to the way the question was formulated. Some of them are \u201cwhat does NOT not xyz\u201d, some are tricky, anyway. Will be more serious when it\u2019s the real exam. &lt;/p&gt;\n\n&lt;p&gt;Anybody here with that certification that maybe has some tips on what to focus? At this point I don\u2019t know what else to study.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16dind7", "is_robot_indexable": true, "report_reasons": null, "author": "Odin217", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dind7/databricks_data_engineering_associate_exam/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dind7/databricks_data_engineering_associate_exam/", "subreddit_subscribers": 127511, "created_utc": 1694198817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6mi7burq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "All Major Data Mining Techniques Explained With Examples", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16did41", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/dUm3ptTQr0Q?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"All Major Data Mining Techniques Explained With Examples\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "All Major Data Mining Techniques Explained With Examples", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/dUm3ptTQr0Q?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"All Major Data Mining Techniques Explained With Examples\"&gt;&lt;/iframe&gt;", "author_name": "Learn with Whiteboard", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/dUm3ptTQr0Q/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@learnwithwhiteboard"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/dUm3ptTQr0Q?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"All Major Data Mining Techniques Explained With Examples\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16did41", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/IIsocjjJWbnPgg0-DzKHh2Bdn_fb6JrGa3pe9YyJ7t8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694198126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=dUm3ptTQr0Q", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hH0hRArN1pZlVYVTjRQH9iONBD7pD65NzPowwzkkXCc.jpg?auto=webp&amp;s=6d286aba480b86fda8e495896edab7640d9877fd", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/hH0hRArN1pZlVYVTjRQH9iONBD7pD65NzPowwzkkXCc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c70b3435e63d50f447be92c129515ef5705f7ff", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/hH0hRArN1pZlVYVTjRQH9iONBD7pD65NzPowwzkkXCc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e716269303a13b43025a99b09122beede29be074", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/hH0hRArN1pZlVYVTjRQH9iONBD7pD65NzPowwzkkXCc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=837e242a951fce0f9e40ed9d2fdba2a23b99e5af", "width": 320, "height": 240}], "variants": {}, "id": "mnAUcwyzPlgpAyCC-BmqOE4MipYL8KraQ3fSd5vT5ho"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16did41", "is_robot_indexable": true, "report_reasons": null, "author": "smart_brand_builder", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16did41/all_major_data_mining_techniques_explained_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=dUm3ptTQr0Q", "subreddit_subscribers": 127511, "created_utc": 1694198126.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "All Major Data Mining Techniques Explained With Examples", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/dUm3ptTQr0Q?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"All Major Data Mining Techniques Explained With Examples\"&gt;&lt;/iframe&gt;", "author_name": "Learn with Whiteboard", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/dUm3ptTQr0Q/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@learnwithwhiteboard"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys. I was just curious how many of you use Make/Makefiles to orchestrate your data pipelines? I joined my current org about a year ago and our team uses Make/Makefiles for all kinds of pipelines like feature engineering, data preparation, table transformations etc. This was new to me but I can see it's really effective. Just wondering if people here have had similar experiences with Make.", "author_fullname": "t2_16kkyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data pipelines with Make", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16dgffb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694193595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys. I was just curious how many of you use Make/Makefiles to orchestrate your data pipelines? I joined my current org about a year ago and our team uses Make/Makefiles for all kinds of pipelines like feature engineering, data preparation, table transformations etc. This was new to me but I can see it&amp;#39;s really effective. Just wondering if people here have had similar experiences with Make.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16dgffb", "is_robot_indexable": true, "report_reasons": null, "author": "remo95able", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dgffb/data_pipelines_with_make/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dgffb/data_pipelines_with_make/", "subreddit_subscribers": 127511, "created_utc": 1694193595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the necessary steps?\nI know that there can only be one metastore per region. \n\nSo I want to have one catalog per environment.\nHowever, the Data lake storage is different for each env. \nWe have dev ADLS2, qa ADLS2, prod ADLS2.\n\nHow do I move forward? Do I have to declare the catalogs for the different storages as external locations? Is there a simple approach? \n\nCan't find much info online about the actual implementation, although it sounds like a common use case.", "author_fullname": "t2_amme6r0o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Unity catalog for dev/qa/prod", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16dr8ge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694219275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the necessary steps?\nI know that there can only be one metastore per region. &lt;/p&gt;\n\n&lt;p&gt;So I want to have one catalog per environment.\nHowever, the Data lake storage is different for each env. \nWe have dev ADLS2, qa ADLS2, prod ADLS2.&lt;/p&gt;\n\n&lt;p&gt;How do I move forward? Do I have to declare the catalogs for the different storages as external locations? Is there a simple approach? &lt;/p&gt;\n\n&lt;p&gt;Can&amp;#39;t find much info online about the actual implementation, although it sounds like a common use case.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16dr8ge", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Room-713", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dr8ge/databricks_unity_catalog_for_devqaprod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dr8ge/databricks_unity_catalog_for_devqaprod/", "subreddit_subscribers": 127511, "created_utc": 1694219275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I'm looking for recommendations of a tool or technology for transforming and cleansing supplier data for Ecommerce\n\n**Background:** We often receive complex multi-page XLS spreadsheets from suppliers, formatted as human-readable printable catalogs. This makes them unsuitable for direct database import due to their visual-centric layout and data formatting. eg, a single column may be used for product data, a sub-header, a gap to denote 'next record' etc etc. It's obvious to see visually what relates to what, but processing on a computer typically relies on applying sets of complex rules.We need to clean and transform the human-readable data for use in ecommerce, but we lack efficient tools and workflows for this.\n\n**Current Workflow:**Manual processing using Excel/Google Sheets.Some success with the Knime Analytics Platform; but it's clunky and lacks easy collaboration without expensive licenses.For complex transformations, we've used Python nodes within Knime.\n\n**Requirements**:Python-Based: We are familiar with Python and have good results using Chat-GPT for coding assistance.Collaborative: Should allow team members to work together, regardless of location.Popular: So outsourcing becomes easier.Modular: Ability to create, share, and update common functions across workflows.ML &amp; Language Tools Integration: For tasks like predicting product compatibility or rewriting descriptions.Google Workspace Compatibility: A plus if it works seamlessly with Google Sheets/Docs/Drive.\n\n**Not Needed:** Real-time or automated processing.Advanced data visualization: Just need a clear interface to monitor data during processing stages.Expensive (over $2,000 a year) licensing\n\n**Question:** Google Colab seems to mostly fit the bill. Are there any better alternatives we should consider? - How about solutions like Dataprep by Trifacta as part of the process?", "author_fullname": "t2_43cfdqk2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Recommendations: Tool for Transforming and Cleansing Supplier Data for Ecommerce", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16d99nh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1694176414.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694176144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I&amp;#39;m looking for recommendations of a tool or technology for transforming and cleansing supplier data for Ecommerce&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt; We often receive complex multi-page XLS spreadsheets from suppliers, formatted as human-readable printable catalogs. This makes them unsuitable for direct database import due to their visual-centric layout and data formatting. eg, a single column may be used for product data, a sub-header, a gap to denote &amp;#39;next record&amp;#39; etc etc. It&amp;#39;s obvious to see visually what relates to what, but processing on a computer typically relies on applying sets of complex rules.We need to clean and transform the human-readable data for use in ecommerce, but we lack efficient tools and workflows for this.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Current Workflow:&lt;/strong&gt;Manual processing using Excel/Google Sheets.Some success with the Knime Analytics Platform; but it&amp;#39;s clunky and lacks easy collaboration without expensive licenses.For complex transformations, we&amp;#39;ve used Python nodes within Knime.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Requirements&lt;/strong&gt;:Python-Based: We are familiar with Python and have good results using Chat-GPT for coding assistance.Collaborative: Should allow team members to work together, regardless of location.Popular: So outsourcing becomes easier.Modular: Ability to create, share, and update common functions across workflows.ML &amp;amp; Language Tools Integration: For tasks like predicting product compatibility or rewriting descriptions.Google Workspace Compatibility: A plus if it works seamlessly with Google Sheets/Docs/Drive.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Not Needed:&lt;/strong&gt; Real-time or automated processing.Advanced data visualization: Just need a clear interface to monitor data during processing stages.Expensive (over $2,000 a year) licensing&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; Google Colab seems to mostly fit the bill. Are there any better alternatives we should consider? - How about solutions like Dataprep by Trifacta as part of the process?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16d99nh", "is_robot_indexable": true, "report_reasons": null, "author": "Jimantronic", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16d99nh/seeking_recommendations_tool_for_transforming_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16d99nh/seeking_recommendations_tool_for_transforming_and/", "subreddit_subscribers": 127511, "created_utc": 1694176144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hi all!\n\nI would like to trigger an Apache Airflow DAG when a specific file is uploaded to a specific bucket in MinIO. I've been looking into MinIO webhooks thinking that might be a solution but I haven't quite figured it out.\n\nI'm currently working locally, I have a Docker container running MinIO and others running Airflow.\n\nIf you know how to go about this I would be very grateful for your help, the more detailed, the better !\n\nThank you !", "author_fullname": "t2_9a5zvrr4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trigger Airflow DAG on MinIO file upload", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16d5qqg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694165047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all!&lt;/p&gt;\n\n&lt;p&gt;I would like to trigger an Apache Airflow DAG when a specific file is uploaded to a specific bucket in MinIO. I&amp;#39;ve been looking into MinIO webhooks thinking that might be a solution but I haven&amp;#39;t quite figured it out.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working locally, I have a Docker container running MinIO and others running Airflow.&lt;/p&gt;\n\n&lt;p&gt;If you know how to go about this I would be very grateful for your help, the more detailed, the better !&lt;/p&gt;\n\n&lt;p&gt;Thank you !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16d5qqg", "is_robot_indexable": true, "report_reasons": null, "author": "No_Storm_1500", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16d5qqg/trigger_airflow_dag_on_minio_file_upload/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16d5qqg/trigger_airflow_dag_on_minio_file_upload/", "subreddit_subscribers": 127511, "created_utc": 1694165047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have found it is best to focus on challenges that use arrays, dictionaries, sets, and flow control. I would not spend much time on trees, linked lists, graphs, or any \u201chard\u201d Leetcode challenges, unless you have found specific information that indicates the company uses those sorts of questions.\n\n&amp;#x200B;\n\n[https://medium.com/@seancoyne/what-leetcode-questions-should-a-data-engineer-practice-9ef7cbf0fc11](https://medium.com/@seancoyne/what-leetcode-questions-should-a-data-engineer-practice-9ef7cbf0fc11)", "author_fullname": "t2_4fpl974m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What LeetCode Questions Should a Data Engineer Practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16duhsc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694228516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have found it is best to focus on challenges that use arrays, dictionaries, sets, and flow control. I would not spend much time on trees, linked lists, graphs, or any \u201chard\u201d Leetcode challenges, unless you have found specific information that indicates the company uses those sorts of questions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@seancoyne/what-leetcode-questions-should-a-data-engineer-practice-9ef7cbf0fc11\"&gt;https://medium.com/@seancoyne/what-leetcode-questions-should-a-data-engineer-practice-9ef7cbf0fc11&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16duhsc", "is_robot_indexable": true, "report_reasons": null, "author": "coyne_operated", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16duhsc/what_leetcode_questions_should_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16duhsc/what_leetcode_questions_should_a_data_engineer/", "subreddit_subscribers": 127511, "created_utc": 1694228516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "SOLVED BELOW\n\nThis is data coming out of an access control system. Some users have multiple cards (up to 6!). For each card a user has, there is a new record. However, all of the card numbers values are included in each cell in each record separated by comma. Credential Format and Credential Status are also duplicated by cell and record. The only unique data per record is the Last Access and Activation Date, which corresponds to the respective card number. \n\nFor example: the first record Last Access relates to the first card number, the second record Last Access relates to the second card number, the third record Last Access relates to the third card number.\n\nI need to somehow remove all values from the first record except for the first value, remove all values from the second record except for the second value, remove all values from the third record except for the third value.\n\nIs this possible? I'm using Power BI for visualization.\n\nORIGINAL:\nhttps://ibb.co/HXDmSdD\n\nTRANSFORMED:\nhttps://ibb.co/hL2rhcC\n\nSAMPLE:\nhttps://docs.google.com/spreadsheets/d/1GJbuXfbdhSmQwLg2m0WNBscnEzKfCaXL/edit?usp=sharing&amp;ouid=105789295818941439929&amp;rtpof=true&amp;sd=true", "author_fullname": "t2_55j5c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to transform multiple records with unique and duplicate data? (sample provided)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16dmpzd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694214909.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694208299.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;SOLVED BELOW&lt;/p&gt;\n\n&lt;p&gt;This is data coming out of an access control system. Some users have multiple cards (up to 6!). For each card a user has, there is a new record. However, all of the card numbers values are included in each cell in each record separated by comma. Credential Format and Credential Status are also duplicated by cell and record. The only unique data per record is the Last Access and Activation Date, which corresponds to the respective card number. &lt;/p&gt;\n\n&lt;p&gt;For example: the first record Last Access relates to the first card number, the second record Last Access relates to the second card number, the third record Last Access relates to the third card number.&lt;/p&gt;\n\n&lt;p&gt;I need to somehow remove all values from the first record except for the first value, remove all values from the second record except for the second value, remove all values from the third record except for the third value.&lt;/p&gt;\n\n&lt;p&gt;Is this possible? I&amp;#39;m using Power BI for visualization.&lt;/p&gt;\n\n&lt;p&gt;ORIGINAL:\n&lt;a href=\"https://ibb.co/HXDmSdD\"&gt;https://ibb.co/HXDmSdD&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;TRANSFORMED:\n&lt;a href=\"https://ibb.co/hL2rhcC\"&gt;https://ibb.co/hL2rhcC&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;SAMPLE:\n&lt;a href=\"https://docs.google.com/spreadsheets/d/1GJbuXfbdhSmQwLg2m0WNBscnEzKfCaXL/edit?usp=sharing&amp;amp;ouid=105789295818941439929&amp;amp;rtpof=true&amp;amp;sd=true\"&gt;https://docs.google.com/spreadsheets/d/1GJbuXfbdhSmQwLg2m0WNBscnEzKfCaXL/edit?usp=sharing&amp;amp;ouid=105789295818941439929&amp;amp;rtpof=true&amp;amp;sd=true&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zVpa4Yk9NWONEByWfKdVkPhI2OdXpK_fvuTC-FRCfaM.jpg?auto=webp&amp;s=71adf70e330fd5960f9454bf885736e32f4cb99c", "width": 1453, "height": 206}, "resolutions": [{"url": "https://external-preview.redd.it/zVpa4Yk9NWONEByWfKdVkPhI2OdXpK_fvuTC-FRCfaM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa07f85f9dc0d7a8e3536dbd92c08c230a45262d", "width": 108, "height": 15}, {"url": "https://external-preview.redd.it/zVpa4Yk9NWONEByWfKdVkPhI2OdXpK_fvuTC-FRCfaM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=699c17d387e9ae678ca5f7475602d5b73509f305", "width": 216, "height": 30}, {"url": "https://external-preview.redd.it/zVpa4Yk9NWONEByWfKdVkPhI2OdXpK_fvuTC-FRCfaM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7414d0fd1d2055402227976c28785ad99d3d755e", "width": 320, "height": 45}, {"url": "https://external-preview.redd.it/zVpa4Yk9NWONEByWfKdVkPhI2OdXpK_fvuTC-FRCfaM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9d61995e51baa06506f68ddf60a9c833a491726d", "width": 640, "height": 90}, {"url": "https://external-preview.redd.it/zVpa4Yk9NWONEByWfKdVkPhI2OdXpK_fvuTC-FRCfaM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=64c899d6dc15ad19c1df2fa3118333372fec78d3", "width": 960, "height": 136}, {"url": "https://external-preview.redd.it/zVpa4Yk9NWONEByWfKdVkPhI2OdXpK_fvuTC-FRCfaM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=47748fd4953c5a161b9dee2706d3db504dfd17d9", "width": 1080, "height": 153}], "variants": {}, "id": "Qy8UpYM8sx_Ujbttrj7NAIGbgDvrFVgEotKV8-AcMQQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16dmpzd", "is_robot_indexable": true, "report_reasons": null, "author": "mikenew02", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dmpzd/how_to_transform_multiple_records_with_unique_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dmpzd/how_to_transform_multiple_records_with_unique_and/", "subreddit_subscribers": 127511, "created_utc": 1694208299.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "last time i asked you all about Trino and why no one was using it. you all assured me it was legit enough just not \"popular\" enough yet. im back asking about k8s crds. Custom resource definitions seem super awesome but the tutorials i found were... not great. \n\n&amp;#x200B;\n\nmy gut tells me theyre awesome. look at argo and cert-manager, those are both crd definitions that allow you to express you \"end goal\" then pass off the obligation of implementing that to the operator. i really like that idea. to play around with how that might work for me personally i wrote a crd that captures some notes about a copy job, what i want to copy, where i want it to go, which credentials to use. Argo handles the execution of my logic as the crd publishes change events. \n\n&amp;#x200B;\n\nseems like a really nice way of handling etl job metadata. is anyone doing this? am i absolutely off my rocker for overlooking a basic req? ", "author_fullname": "t2_706trkkr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "crds (custom resource definitions): what am i missing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16dwhzi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694234594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;last time i asked you all about Trino and why no one was using it. you all assured me it was legit enough just not &amp;quot;popular&amp;quot; enough yet. im back asking about k8s crds. Custom resource definitions seem super awesome but the tutorials i found were... not great. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;my gut tells me theyre awesome. look at argo and cert-manager, those are both crd definitions that allow you to express you &amp;quot;end goal&amp;quot; then pass off the obligation of implementing that to the operator. i really like that idea. to play around with how that might work for me personally i wrote a crd that captures some notes about a copy job, what i want to copy, where i want it to go, which credentials to use. Argo handles the execution of my logic as the crd publishes change events. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;seems like a really nice way of handling etl job metadata. is anyone doing this? am i absolutely off my rocker for overlooking a basic req? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16dwhzi", "is_robot_indexable": true, "report_reasons": null, "author": "Foodwithfloyd", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dwhzi/crds_custom_resource_definitions_what_am_i_missing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dwhzi/crds_custom_resource_definitions_what_am_i_missing/", "subreddit_subscribers": 127511, "created_utc": 1694234594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the best approach to make some delta tables related operations? I know that databricks-connect is the best option but I don\u2019t have Unity catalog enabled. What would be the most effective way?", "author_fullname": "t2_jat21qjwq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to use delta tables stored on databricks cluster effectively without Unity catalog enabled?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16dgsv0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694194477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the best approach to make some delta tables related operations? I know that databricks-connect is the best option but I don\u2019t have Unity catalog enabled. What would be the most effective way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16dgsv0", "is_robot_indexable": true, "report_reasons": null, "author": "Narvinya", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dgsv0/how_to_use_delta_tables_stored_on_databricks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16dgsv0/how_to_use_delta_tables_stored_on_databricks/", "subreddit_subscribers": 127511, "created_utc": 1694194477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\n&amp;#x200B;\n\nI am new to data architecting and I am discovering all the tools but am a bit lost. It would be super helpful to get some advice about what tools would you recommend for strating building a small data lake? \n\nNow, we have a S3 bucket storing data of a plateforme hosting 30K users, 10Go and around 150 tables. I need to select some tools for the ingestion phase, for the datalake, transformation and vizualisation. We are willing to change it if we scale up a lot then, but for now, we would like the whole to be setup within 2-3 months.\n\n&amp;#x200B;\n\nThanks a lot for any advice ! :)\n\n&amp;#x200B;", "author_fullname": "t2_ja2t9ro74", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice for architecting data lake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16de0u6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694187865.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am new to data architecting and I am discovering all the tools but am a bit lost. It would be super helpful to get some advice about what tools would you recommend for strating building a small data lake? &lt;/p&gt;\n\n&lt;p&gt;Now, we have a S3 bucket storing data of a plateforme hosting 30K users, 10Go and around 150 tables. I need to select some tools for the ingestion phase, for the datalake, transformation and vizualisation. We are willing to change it if we scale up a lot then, but for now, we would like the whole to be setup within 2-3 months.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot for any advice ! :)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16de0u6", "is_robot_indexable": true, "report_reasons": null, "author": "No_he7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16de0u6/need_advice_for_architecting_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16de0u6/need_advice_for_architecting_data_lake/", "subreddit_subscribers": 127511, "created_utc": 1694187865.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I am using a generic hadoop environment on my local machines and storing data in delta tables, i want to use superset to build dashboards using delta tables. I have not found a way to connect delta tables with superset. Any leads?", "author_fullname": "t2_3p3vfvzt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dashboards for delta tables using superset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16d883g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694173188.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I am using a generic hadoop environment on my local machines and storing data in delta tables, i want to use superset to build dashboards using delta tables. I have not found a way to connect delta tables with superset. Any leads?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16d883g", "is_robot_indexable": true, "report_reasons": null, "author": "Dr_Fida", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16d883g/dashboards_for_delta_tables_using_superset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16d883g/dashboards_for_delta_tables_using_superset/", "subreddit_subscribers": 127511, "created_utc": 1694173188.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3g7ch6cj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "6 key considerations for productionizing vector search", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_16dfyod", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/2uffTQ7CnqC8cw00e5K-KPf1iUlVQBLXZtncz7zXsSI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694192507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "rockset.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://rockset.com/blog/hard-problems-scaling-vector-search/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/V7TX9RnYnBNu39yF2g35xlnw3jrqAEFTSjN1IqtWBpk.jpg?auto=webp&amp;s=9ffbd31c6c04e0c0bbd0a3c6a2e11c8eb3c65658", "width": 1280, "height": 670}, "resolutions": [{"url": "https://external-preview.redd.it/V7TX9RnYnBNu39yF2g35xlnw3jrqAEFTSjN1IqtWBpk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5c8f0d76a4fdfd72fadedda9cc76a7f49450e61", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/V7TX9RnYnBNu39yF2g35xlnw3jrqAEFTSjN1IqtWBpk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5d0ffe27271ca1b96d76602fd19ed48027fc7555", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/V7TX9RnYnBNu39yF2g35xlnw3jrqAEFTSjN1IqtWBpk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf907f6ce274b220b1dcc4673531e41c5db469e6", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/V7TX9RnYnBNu39yF2g35xlnw3jrqAEFTSjN1IqtWBpk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d80dc43de48457c8aad8dac48aea91322385492", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/V7TX9RnYnBNu39yF2g35xlnw3jrqAEFTSjN1IqtWBpk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c775eae3579a6b0599a90ffc8a0c928676f83d7f", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/V7TX9RnYnBNu39yF2g35xlnw3jrqAEFTSjN1IqtWBpk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b72107806f359c669bf7140c4c4c6085617e30b8", "width": 1080, "height": 565}], "variants": {}, "id": "OgEeOyOMk6ZvIXCGhPEjgq0-ddYG16CvVYfKFhy0lks"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16dfyod", "is_robot_indexable": true, "report_reasons": null, "author": "ssb61", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16dfyod/6_key_considerations_for_productionizing_vector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://rockset.com/blog/hard-problems-scaling-vector-search/", "subreddit_subscribers": 127511, "created_utc": 1694192507.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}