{"kind": "Listing", "data": {"after": "t3_16q95bm", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a master's student rn, graduating next year and just got a return offer from the internship I did this summer. It was a cool place and I liked the people, but their salary offer isn't great - $68,000 in a high CoL city (Washington DC area). It does come with good benefits which is nice, and I've been told it's very likely my pay would go up to at least $90,000 after two years, with potential for higher. \n\nShould I accept given the current state of the job market? Or should I decline and search for a higher-paying opportunity later? Financially, I believe I could make $68,000 work, but it would be tough with student loan debt and DC rent. DC is also a considerable distance from my family and not ideally where I'd want to settle, although I generally like the area. The position does not allow WFH either which is a downside.", "author_fullname": "t2_7cpxsyw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I accept this data science job (i.e. how bad is the job market?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qaxeq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 111, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 111, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695516869.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695492007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a master&amp;#39;s student rn, graduating next year and just got a return offer from the internship I did this summer. It was a cool place and I liked the people, but their salary offer isn&amp;#39;t great - $68,000 in a high CoL city (Washington DC area). It does come with good benefits which is nice, and I&amp;#39;ve been told it&amp;#39;s very likely my pay would go up to at least $90,000 after two years, with potential for higher. &lt;/p&gt;\n\n&lt;p&gt;Should I accept given the current state of the job market? Or should I decline and search for a higher-paying opportunity later? Financially, I believe I could make $68,000 work, but it would be tough with student loan debt and DC rent. DC is also a considerable distance from my family and not ideally where I&amp;#39;d want to settle, although I generally like the area. The position does not allow WFH either which is a downside.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qaxeq", "is_robot_indexable": true, "report_reasons": null, "author": "ChipotleAccount", "discussion_type": null, "num_comments": 91, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qaxeq/should_i_accept_this_data_science_job_ie_how_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qaxeq/should_i_accept_this_data_science_job_ie_how_bad/", "subreddit_subscribers": 1058681, "created_utc": 1695492007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've noticed a trend over the past few months on this subreddit, and it's something I'd like to address in a constructive manner. It seems that a significant portion of the posts here revolves around career-related queries, job offers, and CV reviews. While I understand the value of such discussions, when they dominate 99% of the content, it can diminish the enthusiasm for the subreddit.\n\nIMHO, I believe this sub could benefit from a more diverse range of posts. I'd love to see more members sharing their projects, posting blog articles about new techniques, and discussing about technical topics. I believe we can all learn a lot from  these kind of conversations.\n\nAlso, notice that many of the common career questions have already been comprehensively addressed in previous discussions. Instead of repeating the same topics, we can work together to create a space where we can learn about new topics.\n\nWhat do you thing? Do you think the same or am I simply becoming old and grumpy?\n\nPS. Maybe we could download data from the posts on this sub and test my hypothesis, ie: test that the frequency of posts with the Flair \"Career\" are more abundant that the others ;)", "author_fullname": "t2_6nmywi2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there too many posts focused on career discussions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qc882", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 91, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 91, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695495331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve noticed a trend over the past few months on this subreddit, and it&amp;#39;s something I&amp;#39;d like to address in a constructive manner. It seems that a significant portion of the posts here revolves around career-related queries, job offers, and CV reviews. While I understand the value of such discussions, when they dominate 99% of the content, it can diminish the enthusiasm for the subreddit.&lt;/p&gt;\n\n&lt;p&gt;IMHO, I believe this sub could benefit from a more diverse range of posts. I&amp;#39;d love to see more members sharing their projects, posting blog articles about new techniques, and discussing about technical topics. I believe we can all learn a lot from  these kind of conversations.&lt;/p&gt;\n\n&lt;p&gt;Also, notice that many of the common career questions have already been comprehensively addressed in previous discussions. Instead of repeating the same topics, we can work together to create a space where we can learn about new topics.&lt;/p&gt;\n\n&lt;p&gt;What do you thing? Do you think the same or am I simply becoming old and grumpy?&lt;/p&gt;\n\n&lt;p&gt;PS. Maybe we could download data from the posts on this sub and test my hypothesis, ie: test that the frequency of posts with the Flair &amp;quot;Career&amp;quot; are more abundant that the others ;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qc882", "is_robot_indexable": true, "report_reasons": null, "author": "AM_DS", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qc882/are_there_too_many_posts_focused_on_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qc882/are_there_too_many_posts_focused_on_career/", "subreddit_subscribers": 1058681, "created_utc": 1695495331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I have called an interview for 2 days and there will be 3 person participated in interview : Talent acquisition specialist,  Data Scientist, Director. What kind of questions should I expect  from them. I need some help because I am fresh graduate and I haven't experienced it before. thanks in advance. Here is job description and requirements:\n\n**Skills Required:**\n\n* Bachelor\u2019s Degree in Computer Science, IT, or similar field; a Master\u2019s is a plus\n* Minimum 1 year experience as a data engineer/scientist or in a similar role\n* Technical expertise with data models, data mining, and segmentation techniques.\n* Ability to compose pipelines for data science models.\n* Knowledge of Machine Learning techniques, including decision tree learning, clustering, artificial neural networks, etc., and their pros and cons\n* Data Wrangling \u2013 proficiency in handling imperfections in data.\n* Programming Skills \u2013 good knowledge of statistical programming languages like R, Python, and hands on experience database query languages like SQL.\n* Statistics \u2013 Good applied statistical skills, including knowledge of statistical tests, distributions, regression, maximum likelihood estimators, etc.\n* Basic Math Skills (Linear Algebra) - understanding the fundamentals of Linear Algebra.\n* Knowledge with Timeseries data analysis and modelling.\n* Knowledge with regular expressions.\n* Knowledge with Data Visualization Tools like Power BI, Spotfire, Tableau, matplotlib, etc.\n* Great numerical and analytical skills\n* Excellent Communication Skills \u2013efficiently communicating with both a technical and non-technical audience.", "author_fullname": "t2_gswtior2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "About Junior Data Scientist Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qd0ij", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695497341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I have called an interview for 2 days and there will be 3 person participated in interview : Talent acquisition specialist,  Data Scientist, Director. What kind of questions should I expect  from them. I need some help because I am fresh graduate and I haven&amp;#39;t experienced it before. thanks in advance. Here is job description and requirements:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Skills Required:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Bachelor\u2019s Degree in Computer Science, IT, or similar field; a Master\u2019s is a plus&lt;/li&gt;\n&lt;li&gt;Minimum 1 year experience as a data engineer/scientist or in a similar role&lt;/li&gt;\n&lt;li&gt;Technical expertise with data models, data mining, and segmentation techniques.&lt;/li&gt;\n&lt;li&gt;Ability to compose pipelines for data science models.&lt;/li&gt;\n&lt;li&gt;Knowledge of Machine Learning techniques, including decision tree learning, clustering, artificial neural networks, etc., and their pros and cons&lt;/li&gt;\n&lt;li&gt;Data Wrangling \u2013 proficiency in handling imperfections in data.&lt;/li&gt;\n&lt;li&gt;Programming Skills \u2013 good knowledge of statistical programming languages like R, Python, and hands on experience database query languages like SQL.&lt;/li&gt;\n&lt;li&gt;Statistics \u2013 Good applied statistical skills, including knowledge of statistical tests, distributions, regression, maximum likelihood estimators, etc.&lt;/li&gt;\n&lt;li&gt;Basic Math Skills (Linear Algebra) - understanding the fundamentals of Linear Algebra.&lt;/li&gt;\n&lt;li&gt;Knowledge with Timeseries data analysis and modelling.&lt;/li&gt;\n&lt;li&gt;Knowledge with regular expressions.&lt;/li&gt;\n&lt;li&gt;Knowledge with Data Visualization Tools like Power BI, Spotfire, Tableau, matplotlib, etc.&lt;/li&gt;\n&lt;li&gt;Great numerical and analytical skills&lt;/li&gt;\n&lt;li&gt;Excellent Communication Skills \u2013efficiently communicating with both a technical and non-technical audience.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qd0ij", "is_robot_indexable": true, "report_reasons": null, "author": "NailaBaghir", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qd0ij/about_junior_data_scientist_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qd0ij/about_junior_data_scientist_interview/", "subreddit_subscribers": 1058681, "created_utc": 1695497341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI am currently embarking on my first web scraping project as part of my internship, and I've encountered a challenge that has left me uncertain about its feasibility. My task involves signing in to Glassdoor, conducting searches within the 'companies' section for specific countries, and then extracting salary data for all job positions within those companies in the respective countries. However, I've encountered a few complexities.\n\nFirstly, I'm faced with a scenario where I have 200 pages to navigate, each containing 5 companies. To access salary data for a company, I need to click on its profile, navigate to the 'salaries' tab, and change the location setting to match the country I'm scraping data for. This location setting is initially set to the United States for all companies.\n\nFurthermore, each company's profile may have a varying number of pages of salary data, depending on the company's size. After collecting data for one company, I need to return to the page with the list of 5 companies, select the next company, and repeat the entire process.\n\nI would like to know if this task is achievable, and if so, what steps and technologies should I familiarize myself with in order to successfully accomplish it?", "author_fullname": "t2_2yw2wk44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Glassdoor salaries scraper for all companies in a country.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qmh1x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695523514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently embarking on my first web scraping project as part of my internship, and I&amp;#39;ve encountered a challenge that has left me uncertain about its feasibility. My task involves signing in to Glassdoor, conducting searches within the &amp;#39;companies&amp;#39; section for specific countries, and then extracting salary data for all job positions within those companies in the respective countries. However, I&amp;#39;ve encountered a few complexities.&lt;/p&gt;\n\n&lt;p&gt;Firstly, I&amp;#39;m faced with a scenario where I have 200 pages to navigate, each containing 5 companies. To access salary data for a company, I need to click on its profile, navigate to the &amp;#39;salaries&amp;#39; tab, and change the location setting to match the country I&amp;#39;m scraping data for. This location setting is initially set to the United States for all companies.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, each company&amp;#39;s profile may have a varying number of pages of salary data, depending on the company&amp;#39;s size. After collecting data for one company, I need to return to the page with the list of 5 companies, select the next company, and repeat the entire process.&lt;/p&gt;\n\n&lt;p&gt;I would like to know if this task is achievable, and if so, what steps and technologies should I familiarize myself with in order to successfully accomplish it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qmh1x", "is_robot_indexable": true, "report_reasons": null, "author": "elhamoly98", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qmh1x/glassdoor_salaries_scraper_for_all_companies_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qmh1x/glassdoor_salaries_scraper_for_all_companies_in_a/", "subreddit_subscribers": 1058681, "created_utc": 1695523514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I employ existing widely used CNNs (e.g., `Xception`, `DenseNet169`, `InceptionV3`) via transfer-learning using Keras for a classification task of `10` classes. I've employed almost every available model but still experiencing overfitting as you can see via the attached accuracy-epoch graph, which was obtained during training. I re-calculate the weights of the layers that come with the existing models (*a.k.a.* base models). I've employed KerasTuner to optimize the hyperparameters such as the activation function, optimization algorithm, and learning rate. As a result of this task, `Adam` and `ReLU` were set as the optimization algorithm and activation function, respectively. To prevent overfitting, following the base model, I've added a `Dense` with `1,024` units and a `Dropout` layer with a dropout rate of `0.6` (kept that high to prevent overfitting) just before the final `Dense` layer with `softmax` activation function, which is solely responsible for the classification. I do use a 4-fold CV and the test set/train set ratio is `.3`. The total number of samples is `1,000` and each sample has a shape of `224x224x3`.\n\nHere are the scores that I've obtained on the test set:\n\nAcc: `72.5%`\n\nF1-Score: `72.287%`\n\nPrecision: `73.734%`\n\nRecall: `72.5%`\n\nAny recommendations to improve the test accuracy of the model are greatly appreciated. Please feel free to ask for any further information, which I might missed to note.\n\nMany thanks in advance for your time.\n\n*p.s. This task is a part of my own research project; not seeking help for homework or an exam.*\n\n[Accuracy-Epoch graph](https://preview.redd.it/ehqqfp1gc3qb1.png?width=750&amp;format=png&amp;auto=webp&amp;s=635ff0368530a400c271912e370aa7751b28c6de)", "author_fullname": "t2_rra8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I further improve the accuracy of my CNN based on transfer-learning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 102, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ehqqfp1gc3qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/ehqqfp1gc3qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e83284186f63764e965f0f1df35258730f30abec"}, {"y": 158, "x": 216, "u": "https://preview.redd.it/ehqqfp1gc3qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=77999a2e263abae18b930dd0d4bd9059148c39ca"}, {"y": 234, "x": 320, "u": "https://preview.redd.it/ehqqfp1gc3qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c4fe86afbcfbaf6b5bc8338dbc498e993a1fe8e"}, {"y": 469, "x": 640, "u": "https://preview.redd.it/ehqqfp1gc3qb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5607c205ed1b934a2483d8aadd85c57f1b4a3a53"}], "s": {"y": 550, "x": 750, "u": "https://preview.redd.it/ehqqfp1gc3qb1.png?width=750&amp;format=png&amp;auto=webp&amp;s=635ff0368530a400c271912e370aa7751b28c6de"}, "id": "ehqqfp1gc3qb1"}}, "name": "t3_16qj0w2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Xm8SUClvOs6tY_0MCGHEpCFV0tuZnddsM2Oy3JzO490.jpg", "edited": 1695528340.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695513126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I employ existing widely used CNNs (e.g., &lt;code&gt;Xception&lt;/code&gt;, &lt;code&gt;DenseNet169&lt;/code&gt;, &lt;code&gt;InceptionV3&lt;/code&gt;) via transfer-learning using Keras for a classification task of &lt;code&gt;10&lt;/code&gt; classes. I&amp;#39;ve employed almost every available model but still experiencing overfitting as you can see via the attached accuracy-epoch graph, which was obtained during training. I re-calculate the weights of the layers that come with the existing models (&lt;em&gt;a.k.a.&lt;/em&gt; base models). I&amp;#39;ve employed KerasTuner to optimize the hyperparameters such as the activation function, optimization algorithm, and learning rate. As a result of this task, &lt;code&gt;Adam&lt;/code&gt; and &lt;code&gt;ReLU&lt;/code&gt; were set as the optimization algorithm and activation function, respectively. To prevent overfitting, following the base model, I&amp;#39;ve added a &lt;code&gt;Dense&lt;/code&gt; with &lt;code&gt;1,024&lt;/code&gt; units and a &lt;code&gt;Dropout&lt;/code&gt; layer with a dropout rate of &lt;code&gt;0.6&lt;/code&gt; (kept that high to prevent overfitting) just before the final &lt;code&gt;Dense&lt;/code&gt; layer with &lt;code&gt;softmax&lt;/code&gt; activation function, which is solely responsible for the classification. I do use a 4-fold CV and the test set/train set ratio is &lt;code&gt;.3&lt;/code&gt;. The total number of samples is &lt;code&gt;1,000&lt;/code&gt; and each sample has a shape of &lt;code&gt;224x224x3&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Here are the scores that I&amp;#39;ve obtained on the test set:&lt;/p&gt;\n\n&lt;p&gt;Acc: &lt;code&gt;72.5%&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;F1-Score: &lt;code&gt;72.287%&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Precision: &lt;code&gt;73.734%&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Recall: &lt;code&gt;72.5%&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Any recommendations to improve the test accuracy of the model are greatly appreciated. Please feel free to ask for any further information, which I might missed to note.&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance for your time.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;p.s. This task is a part of my own research project; not seeking help for homework or an exam.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ehqqfp1gc3qb1.png?width=750&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=635ff0368530a400c271912e370aa7751b28c6de\"&gt;Accuracy-Epoch graph&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qj0w2", "is_robot_indexable": true, "report_reasons": null, "author": "talhak", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qj0w2/how_can_i_further_improve_the_accuracy_of_my_cnn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qj0w2/how_can_i_further_improve_the_accuracy_of_my_cnn/", "subreddit_subscribers": 1058681, "created_utc": 1695513126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am studying data science and from media and asking people who are already working in the field strated to be concerned about finding a DS job after graduation.\nSo I am picking a plan B besides my DS BSc but still want to work in DS in the long term so what would you recommend me \nSoftware Engineering or Data engineeing\nI know some people would say data analyst but I just don't know anything about the jobs and from reading job discribtions I feel like using excel and dashboards is a waste for all the Math and programming and ML I have been studying in the last 3 years", "author_fullname": "t2_h5su2eud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software engineering or data engineeing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qptlb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695534965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am studying data science and from media and asking people who are already working in the field strated to be concerned about finding a DS job after graduation.\nSo I am picking a plan B besides my DS BSc but still want to work in DS in the long term so what would you recommend me \nSoftware Engineering or Data engineeing\nI know some people would say data analyst but I just don&amp;#39;t know anything about the jobs and from reading job discribtions I feel like using excel and dashboards is a waste for all the Math and programming and ML I have been studying in the last 3 years&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qptlb", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional-Rhubarb725", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qptlb/software_engineering_or_data_engineeing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qptlb/software_engineering_or_data_engineeing/", "subreddit_subscribers": 1058681, "created_utc": 1695534965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys, I needed some assistance with Forecasting a Time Series dataset using Neural Nets.\n\nFor context, the data has an annual seasonality with daily records of upto 5 years. Previously, I had used Statistical Methods like TBATS and DHR along with GARCH to transform and forecast.\n\nNow, I have been attempting to do the same using RNNs. I started off with GRU and LSTM with a few Hyperparameter Optimization Algorithms for the optimum depth, lookback window etc. only to end up with an eggregious yield of approx 10 MAPE.\n\nThus, I'd appreciate your input as to what can I improve be it an industry practise, some other insightful articles on the same or even alternative ML approaches!\n\nThanks in advance :)", "author_fullname": "t2_j6sk2g9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time Series Forecasting using RNN", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qnryv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695527752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I needed some assistance with Forecasting a Time Series dataset using Neural Nets.&lt;/p&gt;\n\n&lt;p&gt;For context, the data has an annual seasonality with daily records of upto 5 years. Previously, I had used Statistical Methods like TBATS and DHR along with GARCH to transform and forecast.&lt;/p&gt;\n\n&lt;p&gt;Now, I have been attempting to do the same using RNNs. I started off with GRU and LSTM with a few Hyperparameter Optimization Algorithms for the optimum depth, lookback window etc. only to end up with an eggregious yield of approx 10 MAPE.&lt;/p&gt;\n\n&lt;p&gt;Thus, I&amp;#39;d appreciate your input as to what can I improve be it an industry practise, some other insightful articles on the same or even alternative ML approaches!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qnryv", "is_robot_indexable": true, "report_reasons": null, "author": "magic_groovin", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qnryv/time_series_forecasting_using_rnn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qnryv/time_series_forecasting_using_rnn/", "subreddit_subscribers": 1058681, "created_utc": 1695527752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR; recommend a field of research which is related to Data Science.\n\nI\u2019m graduating with a BSc in Computer Science Engineering and all my peers are taken with the flow of \u201cSoftware Development\u201d which I really despise (I really do not find this field amusing/interesting/enjoyable, I know some of us work/study something they do not like and it\u2019s normal, but it\u2019s all tastes after all so hear me out).\n\nI got introduced to the field of Data Science about 6 months ago and already fell in love. I enrolled myself in [365 Data Science](https://365datascience.com) as a start to get familiarised with the field and started the Data Analyst career path which I\u2019m almost done with. I\u2019ve decided to finish all three tracks (Data Scientist, Data Analyst, and Business Analyst) before I move on with other learning material.\n\nNow I\u2019m in the process of applying for a PhD in the US, and I want your opinion on this particular topic.\n\nI want to research something related to the field of DS and have a good opportunity to find a job after finishing my PhD (I\u2019m interested in pursuing a career in both: Academic and Industrial).\n\nI\u2019m thinking about four PhD programs and the order doesn\u2019t matter: \n\n* Mathematics: Pure or Applied\n* Statistics\n* Computer Science (Do not prefer)\n* Data Science\n\nPlease advise me on which field of the four (or if you have another recommendation) will get me well-equipped during my journey.\n\nPS. english isn\u2019t my first language, so excuse me if anything is not clear, not coherent, or grammatically incorrect.", "author_fullname": "t2_8eewpx07f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PhD Advice needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qfoc5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695505639.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695504155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR; recommend a field of research which is related to Data Science.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m graduating with a BSc in Computer Science Engineering and all my peers are taken with the flow of \u201cSoftware Development\u201d which I really despise (I really do not find this field amusing/interesting/enjoyable, I know some of us work/study something they do not like and it\u2019s normal, but it\u2019s all tastes after all so hear me out).&lt;/p&gt;\n\n&lt;p&gt;I got introduced to the field of Data Science about 6 months ago and already fell in love. I enrolled myself in &lt;a href=\"https://365datascience.com\"&gt;365 Data Science&lt;/a&gt; as a start to get familiarised with the field and started the Data Analyst career path which I\u2019m almost done with. I\u2019ve decided to finish all three tracks (Data Scientist, Data Analyst, and Business Analyst) before I move on with other learning material.&lt;/p&gt;\n\n&lt;p&gt;Now I\u2019m in the process of applying for a PhD in the US, and I want your opinion on this particular topic.&lt;/p&gt;\n\n&lt;p&gt;I want to research something related to the field of DS and have a good opportunity to find a job after finishing my PhD (I\u2019m interested in pursuing a career in both: Academic and Industrial).&lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking about four PhD programs and the order doesn\u2019t matter: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mathematics: Pure or Applied&lt;/li&gt;\n&lt;li&gt;Statistics&lt;/li&gt;\n&lt;li&gt;Computer Science (Do not prefer)&lt;/li&gt;\n&lt;li&gt;Data Science&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Please advise me on which field of the four (or if you have another recommendation) will get me well-equipped during my journey.&lt;/p&gt;\n\n&lt;p&gt;PS. english isn\u2019t my first language, so excuse me if anything is not clear, not coherent, or grammatically incorrect.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?auto=webp&amp;s=2c79ec2c452bb4d01df675d2a739bd47f221a670", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=108658d3e7925b2e114ce4a4c04d5f4e4295487d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9561ba20aaf47ba07975c9cc270feb3b83108d8a", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=82e442618be3944d045e58fadd5034487d2d6642", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f0afa3e8d4b806ab74b5d8d146baf8afd3fa7b37", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7fd653b4af836fe5c3f3e7ad731464fa007c47fb", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=070e674c45fe1ce071fffe889a90255b231bbe82", "width": 1080, "height": 564}], "variants": {}, "id": "t7A4BY9o-aX-XTyFjhKEkiEB0ueAqjclZI80A8Moy40"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qfoc5", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Community_5554", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qfoc5/phd_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qfoc5/phd_advice_needed/", "subreddit_subscribers": 1058681, "created_utc": 1695504155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I see a lot of posts on here about academic programs, resume advice, and interview tips, but not nearly as many about everyone's least favorite and arguably the most important part of career advancement - networking. \n\nNetworking looks different at different stages of your career, so how are you networking and what networking advice do you have for someone who might be:\n \n* A recent grad or someone changing careers and trying to break into the field?\n* A mid career professional trying to move up or build their reputation?\n* A senior or manager trying to connect with talented recruitment prospects?", "author_fullname": "t2_n638i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you networking?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16q9k4q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695488492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see a lot of posts on here about academic programs, resume advice, and interview tips, but not nearly as many about everyone&amp;#39;s least favorite and arguably the most important part of career advancement - networking. &lt;/p&gt;\n\n&lt;p&gt;Networking looks different at different stages of your career, so how are you networking and what networking advice do you have for someone who might be:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A recent grad or someone changing careers and trying to break into the field?&lt;/li&gt;\n&lt;li&gt;A mid career professional trying to move up or build their reputation?&lt;/li&gt;\n&lt;li&gt;A senior or manager trying to connect with talented recruitment prospects?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16q9k4q", "is_robot_indexable": true, "report_reasons": null, "author": "Prime_Director", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16q9k4q/how_are_you_networking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16q9k4q/how_are_you_networking/", "subreddit_subscribers": 1058681, "created_utc": 1695488492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Enhancing your data analysis performance with Python's Numexpr and Pandas' eval/query functions \n\n This article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/) \n\n&amp;#x200B;\n\n[ Use Numexpr to help me find the most livable city. Photo Credit: Created by Author, Canva ](https://preview.redd.it/29ec8ukgr5qb1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=238da4465da17bd301b49112d574444b16d4113c)\n\n This article will introduce you to the Python library [Numexpr](https://numexpr.readthedocs.io/en/latest/intro.html?ref=dataleadsfuture.com#), a tool that boosts the computational performance of Numpy Arrays. The eval and query methods of Pandas are also based on this library.\n\n This article also includes a hands-on weather data analysis project. \n\n By reading this article, you will understand the principles of Numexpr and how to use this powerful tool to speed up your calculations in reality. \n\n# Introduction \n\n# Recalling Numpy Arrays\n\n In a previous article discussing Numpy Arrays, I used a library example to explain why Numpy's Cache Locality is so efficient: \n\n[https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/](https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/)\n\n Each time you go to the library to search for materials, you take out a few books related to the content and place them next to your desk. \n\n This way, you can quickly check related materials without having to run to the shelf each time you need to read a book. \n\n This method saves a lot of time, especially when you need to consult many related books. \n\n In this scenario, the shelf is like your memory, the desk is equivalent to the CPU's L1 cache, and you, the reader, are the CPU's core. \n\n&amp;#x200B;\n\n[ When the CPU accesses RAM, the cache loads the entire cache line into the high-speed cache. Image by Author ](https://preview.redd.it/3k7gdxywr5qb1.png?width=625&amp;format=png&amp;auto=webp&amp;s=5e6a2ed6620cf23638d9c3f20e5f6f46a54e0049)\n\n### The limitations of Numpy\n\n Suppose you are unfortunate enough to encounter a demanding professor who wants you to take out Shakespeare and Tolstoy's works for a cross-comparison. \n\n At this point, taking out related books in advance will not work well. \n\n First, your desk space is limited and cannot hold all the books of these two masters at the same time, not to mention the reading notes that will be generated during the comparison process. \n\n Second, you're just one person, and comparing so many works would take too long. It would be nice if you could find a few more people to help. \n\n This is the current situation when we use Numpy to deal with large amounts of data: \n\n* The number of elements in the Array is too large to fit into the CPU's L1 cache.\n* Numpy's element-level operations are single-threaded and cannot utilize the computing power of multi-core CPUs.\n\n What should we do? \n\n Don't worry. When you really encounter a problem with too much data, you can call on our protagonist today, Numexpr, to help. \n\n## Understanding Numexpr: What and Why\n\n### How it works\n\n When Numpy encounters large arrays, element-wise calculations will experience two extremes. \n\n Let me give you an example to illustrate. Suppose there are two large Numpy ndarrays: \n\n    import numpy as np \n    import numexpr as ne  \n    \n    a = np.random.rand(100_000_000) \n    b = np.random.rand(100_000_000)\n\n When calculating the result of the expression a\\*\\*5 + 2 \\* b, there are generally two methods:\n\n One way is Numpy's vectorized calculation method, which uses two temporary arrays to store the results of a\\*\\*5 and 2\\*b separately.  \n\n    In: %timeit a**5 + 2 * b\n    \n    Out:2.11 s \u00b1 31.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n At this time, you have four arrays in your memory: a, b, a\\*\\*5, and 2 \\* b. This method will cause a lot of memory waste. \n\n Moreover, since each Array's size exceeds the CPU cache's capacity, it cannot use it well. \n\n Another way is to traverse each element in two arrays and calculate them separately. \n\n    c = np.empty(100_000_000, dtype=np.uint32)\n    \n    def calcu_elements(a, b, c):\n        for i in range(0, len(a), 1):\n            c[i] = a[i] ** 5 + 2 * b[i]\n            \n    %timeit calcu_elements(a, b, c)\n    \n    \n    Out: 24.6 s \u00b1 48.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n This method performs even worse. The calculation will be very slow because it cannot use vectorized calculations and only partially utilize the CPU cache. \n\n### Numexpr's calculation\n\n Numexpr commonly uses only one evaluate method. This method will receive an expression string each time and then compile it into bytecode using Python's compile method. \n\n Numexpr also has a virtual machine program. The virtual machine contains multiple vector registers, each using a chunk size of 4096. \n\n When Numexpr starts to calculate, it sends the data in one or more registers to the CPU's L1 cache each time. This way, there won't be a situation where the memory is too slow, and the CPU waits for data. \n\n At the same time, Numexpr's virtual machine is written in C, removing Python's GIL. It can utilize the computing power of multi-core CPUs. \n\n So, Numexpr is faster when calculating large arrays than using Numpy alone. We can make a comparison: \n\n    In:  %timeit ne.evaluate('a**5 + 2 * b')\n    Out: 258 ms \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n### Summary of Numexpr's working principle\n\n Let's summarize the working principle of Numexpr and see why Numexpr is so fast: \n\n **Executing bytecode through a virtual machine.** Numexpr uses bytecode to execute expressions, which can fully utilize the [branch prediction](https://en.wikipedia.org/wiki/Branch_predictor?ref=dataleadsfuture.com) ability of the CPU, which is faster than using Python expressions. \n\n **Vectorized calculation.** Numexpr will use [SIMD (Single Instruction, Multiple Data)](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data?ref=dataleadsfuture.com) technology to improve computing efficiency significantly for the same operation on the data in each register. \n\n **Multi-core parallel computing.** Numexpr's virtual machine can decompose each task into multiple subtasks. They are executed in parallel on multiple CPU cores. \n\n **Less memory usage.** Unlike Numpy, which needs to generate intermediate arrays, Numexpr only loads a small amount of data when necessary, significantly reducing memory usage. \n\n&amp;#x200B;\n\n[ Workflow diagram of Numexpr. Image by Author ](https://preview.redd.it/46plaxk6t5qb1.png?width=863&amp;format=png&amp;auto=webp&amp;s=8c0bb7311c4fc743d720c2e0cec3c28c1ff98ed3)\n\n## Numexpr and Pandas: A Powerful Combination\n\n You might be wondering: We usually do data analysis with pandas. I understand the performance improvements Numexpr offers for Numpy, but does it have the same improvement for Pandas? \n\n The answer is Yes. \n\n The eval and query methods in pandas are implemented based on Numexpr. Let's look at some examples: \n\n### Pandas.eval for Cross-DataFrame operations\n\n When you have multiple pandas DataFrames, you can use pandas.eval to perform operations between DataFrame objects, for example: \n\n    import pandas as pd\n    \n    nrows, ncols = 1_000_000, 100\n    df1, df2, df3, df4 = (pd.DataFrame(rng.random((nrows, ncols))) for i in range(4))\n\n If you calculate the sum of these DataFrames using the traditional pandas method, the time consumed is: \n\n    In:  %timeit df1+df2+df3+df4\n    Out: 1.18 s \u00b1 65.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n You can also use pandas.eval for calculation. The time consumed is: \n\n The calculation of the eval version can improve performance by 50%, and the results are precisely the same: \n\n    In:  np.allclose(df1+df2+df3+df4, pd.eval('df1+df2+df3+df4'))\n    Out: True\n\n### DataFrame.eval for column-level operations\n\n Just like pandas.eval, DataFrame also has its own eval method. We can use this method for column-level operations within DataFrame, for example: \n\n    df = pd.DataFrame(rng.random((1000, 3)), columns=['A', 'B', 'C'])\n    \n    result1 = (df['A'] + df['B']) / (df['C'] - 1)\n    result2 = df.eval('(A + B) / (C - 1)')\n\n The results of using the traditional pandas method and the eval method are precisely the same: \n\n    In:  np.allclose(result1, result2)\n    Out: True\n\n Of course, you can also directly use the eval expression to add new columns to the DataFrame, which is very convenient: \n\n    df.eval('D = (A + B) / C', inplace=True)\n    df.head()\n\n[ Directly use the eval expression to add new columns. Image by Author ](https://preview.redd.it/ykotgj0ut5qb1.png?width=495&amp;format=png&amp;auto=webp&amp;s=f005b5782e751f2f5ea90fcddd8169cfcc2c5751)\n\n### Using DataFrame.query to quickly find data\n\n If the eval method of DataFrame executes comparison expressions, the returned result is a boolean result that meets the conditions. You need to use Mask Indexing to get the desired data: \n\n    mask = df.eval('(A &lt; 0.5) &amp; (B &lt; 0.5)')\n    result1 = df[mask]\n    result\n\n[ When filtering data only with DataFrame.query, it is necessary to use a boolean mask. Image by Author ](https://preview.redd.it/izwngwizt5qb1.png?width=469&amp;format=png&amp;auto=webp&amp;s=c7f0e4806977ccdcf3c588a67a6c913255f47091)\n\n The DataFrame.query method encapsulates this process, and you can directly obtain the desired data with the query method: \n\n    In:   result2 = df.query('A &lt; 0.5 and B &lt; 0.5')\n          np.allclose(result1, result2)\n    Out:  True\n\n When you need to use scalars in expressions, you can use the @  to indicate: \n\n    In:  Cmean = df['C'].mean()\n         result1 = df[(df.A &lt; Cmean) &amp; (df.B &lt; Cmean)]\n         result2 = df.query('A &lt; @Cmean and B &lt; @Cmean')\n         np.allclose(result1, result2)\n    Out: True\n\n This article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/) ", "author_fullname": "t2_9r8ft2a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring Numexpr: A Powerful Engine Behind Pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ykotgj0ut5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=45b2ace70cdc23065c16c4c7ecb49451067d5824"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1ae1f3d972bbe64cc07341d2a7e32e66da793a7f"}, {"y": 115, "x": 320, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=04db3f2e444bdb6b7cb6c9558407dc42561b74f2"}], "s": {"y": 179, "x": 495, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=495&amp;format=png&amp;auto=webp&amp;s=f005b5782e751f2f5ea90fcddd8169cfcc2c5751"}, "id": "ykotgj0ut5qb1"}, "izwngwizt5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2dadbb151f50fa5dbfbf14272d1860c079d94f89"}, {"y": 133, "x": 216, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=184931d673c0227709ad80639f3cd20da70977d4"}, {"y": 197, "x": 320, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ce4336dee4ce5c9bbedc261e3a277e72d6fa47e"}], "s": {"y": 289, "x": 469, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=469&amp;format=png&amp;auto=webp&amp;s=c7f0e4806977ccdcf3c588a67a6c913255f47091"}, "id": "izwngwizt5qb1"}, "3k7gdxywr5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 45, "x": 108, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a502f085a43ef5ac8f1f50599161b6d8ccfe1dc5"}, {"y": 91, "x": 216, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fedccce3dc9866fbb52b62237eb1d362917e2eb3"}, {"y": 135, "x": 320, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=77080ec0cc0d4b7202892c1035780ef145694726"}], "s": {"y": 264, "x": 625, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=625&amp;format=png&amp;auto=webp&amp;s=5e6a2ed6620cf23638d9c3f20e5f6f46a54e0049"}, "id": "3k7gdxywr5qb1"}, "46plaxk6t5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8d31e4cb8f3f2da53d3c291af37ecc489c082e5d"}, {"y": 152, "x": 216, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b292a546e21eea92bccc123befff21806f751ad"}, {"y": 226, "x": 320, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e63cb3e19ed9c368e8e297b1842854b459247ac6"}, {"y": 453, "x": 640, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=059bc7da3ab967ae8670b846e24da717ccfa6bb0"}], "s": {"y": 611, "x": 863, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=863&amp;format=png&amp;auto=webp&amp;s=8c0bb7311c4fc743d720c2e0cec3c28c1ff98ed3"}, "id": "46plaxk6t5qb1"}, "29ec8ukgr5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=827a05e29b961a5494a0a7bef09e05406e2e2d0e"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7eda37aee46f7ac0e032a1d6986c84364e634243"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c421de1631ab305d9297cb110c5bc7e6f8fa84ee"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=56aac32c3c80921dcb8d1294b3284c961c3fc4f4"}, {"y": 639, "x": 960, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4bf6231e0d1b715918aa8904b0dc7a8bdae05633"}, {"y": 719, "x": 1080, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a94c2abbd9a3ade8f23648b82905877f75b5bede"}], "s": {"y": 799, "x": 1200, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=238da4465da17bd301b49112d574444b16d4113c"}, "id": "29ec8ukgr5qb1"}}, "name": "t3_16qrxs4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ARL0vsBWFf7vstunNTahhEgCBgMGr53RAUJlwDu0dAc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1695542470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Enhancing your data analysis performance with Python&amp;#39;s Numexpr and Pandas&amp;#39; eval/query functions &lt;/p&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/\"&gt;Data Leads Future.&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/29ec8ukgr5qb1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=238da4465da17bd301b49112d574444b16d4113c\"&gt; Use Numexpr to help me find the most livable city. Photo Credit: Created by Author, Canva &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This article will introduce you to the Python library &lt;a href=\"https://numexpr.readthedocs.io/en/latest/intro.html?ref=dataleadsfuture.com#\"&gt;Numexpr&lt;/a&gt;, a tool that boosts the computational performance of Numpy Arrays. The eval and query methods of Pandas are also based on this library.&lt;/p&gt;\n\n&lt;p&gt;This article also includes a hands-on weather data analysis project. &lt;/p&gt;\n\n&lt;p&gt;By reading this article, you will understand the principles of Numexpr and how to use this powerful tool to speed up your calculations in reality. &lt;/p&gt;\n\n&lt;h1&gt;Introduction&lt;/h1&gt;\n\n&lt;h1&gt;Recalling Numpy Arrays&lt;/h1&gt;\n\n&lt;p&gt;In a previous article discussing Numpy Arrays, I used a library example to explain why Numpy&amp;#39;s Cache Locality is so efficient: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/\"&gt;https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Each time you go to the library to search for materials, you take out a few books related to the content and place them next to your desk. &lt;/p&gt;\n\n&lt;p&gt;This way, you can quickly check related materials without having to run to the shelf each time you need to read a book. &lt;/p&gt;\n\n&lt;p&gt;This method saves a lot of time, especially when you need to consult many related books. &lt;/p&gt;\n\n&lt;p&gt;In this scenario, the shelf is like your memory, the desk is equivalent to the CPU&amp;#39;s L1 cache, and you, the reader, are the CPU&amp;#39;s core. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3k7gdxywr5qb1.png?width=625&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5e6a2ed6620cf23638d9c3f20e5f6f46a54e0049\"&gt; When the CPU accesses RAM, the cache loads the entire cache line into the high-speed cache. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;h3&gt;The limitations of Numpy&lt;/h3&gt;\n\n&lt;p&gt;Suppose you are unfortunate enough to encounter a demanding professor who wants you to take out Shakespeare and Tolstoy&amp;#39;s works for a cross-comparison. &lt;/p&gt;\n\n&lt;p&gt;At this point, taking out related books in advance will not work well. &lt;/p&gt;\n\n&lt;p&gt;First, your desk space is limited and cannot hold all the books of these two masters at the same time, not to mention the reading notes that will be generated during the comparison process. &lt;/p&gt;\n\n&lt;p&gt;Second, you&amp;#39;re just one person, and comparing so many works would take too long. It would be nice if you could find a few more people to help. &lt;/p&gt;\n\n&lt;p&gt;This is the current situation when we use Numpy to deal with large amounts of data: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The number of elements in the Array is too large to fit into the CPU&amp;#39;s L1 cache.&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Numpy&amp;#39;s element-level operations are single-threaded and cannot utilize the computing power of multi-core CPUs.&lt;/p&gt;\n\n&lt;p&gt;What should we do? &lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t worry. When you really encounter a problem with too much data, you can call on our protagonist today, Numexpr, to help. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Understanding Numexpr: What and Why&lt;/h2&gt;\n\n&lt;h3&gt;How it works&lt;/h3&gt;\n\n&lt;p&gt;When Numpy encounters large arrays, element-wise calculations will experience two extremes. &lt;/p&gt;\n\n&lt;p&gt;Let me give you an example to illustrate. Suppose there are two large Numpy ndarrays: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import numpy as np \nimport numexpr as ne  \n\na = np.random.rand(100_000_000) \nb = np.random.rand(100_000_000)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When calculating the result of the expression a**5 + 2 * b, there are generally two methods:&lt;/p&gt;\n\n&lt;p&gt;One way is Numpy&amp;#39;s vectorized calculation method, which uses two temporary arrays to store the results of a**5 and 2*b separately.  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In: %timeit a**5 + 2 * b\n\nOut:2.11 s \u00b1 31.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;At this time, you have four arrays in your memory: a, b, a**5, and 2 * b. This method will cause a lot of memory waste. &lt;/p&gt;\n\n&lt;p&gt;Moreover, since each Array&amp;#39;s size exceeds the CPU cache&amp;#39;s capacity, it cannot use it well. &lt;/p&gt;\n\n&lt;p&gt;Another way is to traverse each element in two arrays and calculate them separately. &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;c = np.empty(100_000_000, dtype=np.uint32)\n\ndef calcu_elements(a, b, c):\n    for i in range(0, len(a), 1):\n        c[i] = a[i] ** 5 + 2 * b[i]\n\n%timeit calcu_elements(a, b, c)\n\n\nOut: 24.6 s \u00b1 48.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This method performs even worse. The calculation will be very slow because it cannot use vectorized calculations and only partially utilize the CPU cache. &lt;/p&gt;\n\n&lt;h3&gt;Numexpr&amp;#39;s calculation&lt;/h3&gt;\n\n&lt;p&gt;Numexpr commonly uses only one evaluate method. This method will receive an expression string each time and then compile it into bytecode using Python&amp;#39;s compile method. &lt;/p&gt;\n\n&lt;p&gt;Numexpr also has a virtual machine program. The virtual machine contains multiple vector registers, each using a chunk size of 4096. &lt;/p&gt;\n\n&lt;p&gt;When Numexpr starts to calculate, it sends the data in one or more registers to the CPU&amp;#39;s L1 cache each time. This way, there won&amp;#39;t be a situation where the memory is too slow, and the CPU waits for data. &lt;/p&gt;\n\n&lt;p&gt;At the same time, Numexpr&amp;#39;s virtual machine is written in C, removing Python&amp;#39;s GIL. It can utilize the computing power of multi-core CPUs. &lt;/p&gt;\n\n&lt;p&gt;So, Numexpr is faster when calculating large arrays than using Numpy alone. We can make a comparison: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  %timeit ne.evaluate(&amp;#39;a**5 + 2 * b&amp;#39;)\nOut: 258 ms \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h3&gt;Summary of Numexpr&amp;#39;s working principle&lt;/h3&gt;\n\n&lt;p&gt;Let&amp;#39;s summarize the working principle of Numexpr and see why Numexpr is so fast: &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Executing bytecode through a virtual machine.&lt;/strong&gt; Numexpr uses bytecode to execute expressions, which can fully utilize the &lt;a href=\"https://en.wikipedia.org/wiki/Branch_predictor?ref=dataleadsfuture.com\"&gt;branch prediction&lt;/a&gt; ability of the CPU, which is faster than using Python expressions. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Vectorized calculation.&lt;/strong&gt; Numexpr will use &lt;a href=\"https://en.wikipedia.org/wiki/Single_instruction,_multiple_data?ref=dataleadsfuture.com\"&gt;SIMD (Single Instruction, Multiple Data)&lt;/a&gt; technology to improve computing efficiency significantly for the same operation on the data in each register. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Multi-core parallel computing.&lt;/strong&gt; Numexpr&amp;#39;s virtual machine can decompose each task into multiple subtasks. They are executed in parallel on multiple CPU cores. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Less memory usage.&lt;/strong&gt; Unlike Numpy, which needs to generate intermediate arrays, Numexpr only loads a small amount of data when necessary, significantly reducing memory usage. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/46plaxk6t5qb1.png?width=863&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c0bb7311c4fc743d720c2e0cec3c28c1ff98ed3\"&gt; Workflow diagram of Numexpr. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Numexpr and Pandas: A Powerful Combination&lt;/h2&gt;\n\n&lt;p&gt;You might be wondering: We usually do data analysis with pandas. I understand the performance improvements Numexpr offers for Numpy, but does it have the same improvement for Pandas? &lt;/p&gt;\n\n&lt;p&gt;The answer is Yes. &lt;/p&gt;\n\n&lt;p&gt;The eval and query methods in pandas are implemented based on Numexpr. Let&amp;#39;s look at some examples: &lt;/p&gt;\n\n&lt;h3&gt;Pandas.eval for Cross-DataFrame operations&lt;/h3&gt;\n\n&lt;p&gt;When you have multiple pandas DataFrames, you can use pandas.eval to perform operations between DataFrame objects, for example: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pandas as pd\n\nnrows, ncols = 1_000_000, 100\ndf1, df2, df3, df4 = (pd.DataFrame(rng.random((nrows, ncols))) for i in range(4))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;If you calculate the sum of these DataFrames using the traditional pandas method, the time consumed is: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  %timeit df1+df2+df3+df4\nOut: 1.18 s \u00b1 65.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;You can also use pandas.eval for calculation. The time consumed is: &lt;/p&gt;\n\n&lt;p&gt;The calculation of the eval version can improve performance by 50%, and the results are precisely the same: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  np.allclose(df1+df2+df3+df4, pd.eval(&amp;#39;df1+df2+df3+df4&amp;#39;))\nOut: True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h3&gt;DataFrame.eval for column-level operations&lt;/h3&gt;\n\n&lt;p&gt;Just like pandas.eval, DataFrame also has its own eval method. We can use this method for column-level operations within DataFrame, for example: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df = pd.DataFrame(rng.random((1000, 3)), columns=[&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;])\n\nresult1 = (df[&amp;#39;A&amp;#39;] + df[&amp;#39;B&amp;#39;]) / (df[&amp;#39;C&amp;#39;] - 1)\nresult2 = df.eval(&amp;#39;(A + B) / (C - 1)&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The results of using the traditional pandas method and the eval method are precisely the same: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  np.allclose(result1, result2)\nOut: True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Of course, you can also directly use the eval expression to add new columns to the DataFrame, which is very convenient: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df.eval(&amp;#39;D = (A + B) / C&amp;#39;, inplace=True)\ndf.head()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ykotgj0ut5qb1.png?width=495&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f005b5782e751f2f5ea90fcddd8169cfcc2c5751\"&gt; Directly use the eval expression to add new columns. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;h3&gt;Using DataFrame.query to quickly find data&lt;/h3&gt;\n\n&lt;p&gt;If the eval method of DataFrame executes comparison expressions, the returned result is a boolean result that meets the conditions. You need to use Mask Indexing to get the desired data: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;mask = df.eval(&amp;#39;(A &amp;lt; 0.5) &amp;amp; (B &amp;lt; 0.5)&amp;#39;)\nresult1 = df[mask]\nresult\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/izwngwizt5qb1.png?width=469&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c7f0e4806977ccdcf3c588a67a6c913255f47091\"&gt; When filtering data only with DataFrame.query, it is necessary to use a boolean mask. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The DataFrame.query method encapsulates this process, and you can directly obtain the desired data with the query method: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:   result2 = df.query(&amp;#39;A &amp;lt; 0.5 and B &amp;lt; 0.5&amp;#39;)\n      np.allclose(result1, result2)\nOut:  True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When you need to use scalars in expressions, you can use the @  to indicate: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  Cmean = df[&amp;#39;C&amp;#39;].mean()\n     result1 = df[(df.A &amp;lt; Cmean) &amp;amp; (df.B &amp;lt; Cmean)]\n     result2 = df.query(&amp;#39;A &amp;lt; @Cmean and B &amp;lt; @Cmean&amp;#39;)\n     np.allclose(result1, result2)\nOut: True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/\"&gt;Data Leads Future.&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?auto=webp&amp;s=4f4c5a16af6b6d5e954c2bd0d6ec11d253a3f16f", "width": 1387, "height": 924}, "resolutions": [{"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3216385c481210e323283ae6e03a16e14245f2a1", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a6a3bbf3191c78cddfbd87af49e76d6667ca85fd", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=202ec313e2baa2ef1670e9cfd24d6c2560d1cd21", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff3e49cdb7d8d0746f47c590240ce1fc893bc917", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=33dc2fd6c45c6a3cc3cbd721fe9ad6a9f5ab7779", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bf7b49d72586c5ef89b6b8f7dc0d9c7de09de4b8", "width": 1080, "height": 719}], "variants": {}, "id": "Bjw_Y7mZr_m-tfiX4fEkjjZrKlokqny6OjPxyctYkDg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qrxs4", "is_robot_indexable": true, "report_reasons": null, "author": "qtalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qrxs4/exploring_numexpr_a_powerful_engine_behind_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qrxs4/exploring_numexpr_a_powerful_engine_behind_pandas/", "subreddit_subscribers": 1058681, "created_utc": 1695542470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4j7ujk5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is test-driven development (TDD) relevant f\u00fcr Data Scientists? Do you practice it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16qfb3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/llaUBH5oayw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Test Driven Development - What? Why? And How?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Test Driven Development - What? Why? And How?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/llaUBH5oayw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Test Driven Development - What? Why? And How?\"&gt;&lt;/iframe&gt;", "author_name": "Continuous Delivery", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/llaUBH5oayw/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ContinuousDelivery"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/llaUBH5oayw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Test Driven Development - What? Why? And How?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16qfb3v", "height": 200}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XRYVur3ceoJqZRcBZrQLHi9GJm86WzbZO9dsY1-R2uw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695503228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/llaUBH5oayw", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HoXNjjz7w4TFdq1W_52c-_GyTD0PQ-Jb2azx8g4YNCc.jpg?auto=webp&amp;s=4647e0c22fb1d30d0aa25cf3e3dc427ac9e6e8c0", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/HoXNjjz7w4TFdq1W_52c-_GyTD0PQ-Jb2azx8g4YNCc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3cde985a6dada0b59a82ec27ea02a598095b655f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/HoXNjjz7w4TFdq1W_52c-_GyTD0PQ-Jb2azx8g4YNCc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6c0ccac57b30c0d45a33df9fe3d2f6302e9826c1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/HoXNjjz7w4TFdq1W_52c-_GyTD0PQ-Jb2azx8g4YNCc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a71ebce287ec6e92f92486fd762fc20cd1339c96", "width": 320, "height": 240}], "variants": {}, "id": "upp6PnY18zvYooOCDWlps7sPKuHvCHAkEeQvb8-cVvo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qfb3v", "is_robot_indexable": true, "report_reasons": null, "author": "norfkens2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qfb3v/is_testdriven_development_tdd_relevant_f\u00fcr_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/llaUBH5oayw", "subreddit_subscribers": 1058681, "created_utc": 1695503228.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Test Driven Development - What? Why? And How?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/llaUBH5oayw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Test Driven Development - What? Why? And How?\"&gt;&lt;/iframe&gt;", "author_name": "Continuous Delivery", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/llaUBH5oayw/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ContinuousDelivery"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the Masters of Statistics programs there are often elective offerings for time series analysis which are based on the prerequisite statistical theory knowledge from casella and Berger. They cover the the theory of time series models (random walks, ar models, ma models, arma models, arima, sarima, garch etc), and maybe some non stationary time series. Homework\u2019s generally consist of both a theory and application side, theory maybe some derivations, and then applied is applying time series models learned that week to datasets in rmarkdown and exploring them with packages.\n\nMy question is, would such a background be useful if one was interested in data scientist roles which are very focused on forecasting? Are there dedicated teams for forecasting at companies? They often use base R stuff for the time series packages, so we often aren\u2019t taught the prophet, or any other modern python based time series packages. Would this be a deal breaker?", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does a theoretical understanding of time series help for forecasting roles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qbdfs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695493147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the Masters of Statistics programs there are often elective offerings for time series analysis which are based on the prerequisite statistical theory knowledge from casella and Berger. They cover the the theory of time series models (random walks, ar models, ma models, arma models, arima, sarima, garch etc), and maybe some non stationary time series. Homework\u2019s generally consist of both a theory and application side, theory maybe some derivations, and then applied is applying time series models learned that week to datasets in rmarkdown and exploring them with packages.&lt;/p&gt;\n\n&lt;p&gt;My question is, would such a background be useful if one was interested in data scientist roles which are very focused on forecasting? Are there dedicated teams for forecasting at companies? They often use base R stuff for the time series packages, so we often aren\u2019t taught the prophet, or any other modern python based time series packages. Would this be a deal breaker?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qbdfs", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qbdfs/does_a_theoretical_understanding_of_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qbdfs/does_a_theoretical_understanding_of_time_series/", "subreddit_subscribers": 1058681, "created_utc": 1695493147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, \n\nI have seen some videos on youtube where people talk about their daily work in data science and programming. These videos usually give a general view (for example they say they have daily meeting and code for several hours and so on) and don't give a detailed view. \n\nI am wondering if there is any channel or website about the day to day life of a data scientist at a company. For example, showing how they start with the projects and how they collaborate with others and how they code their solutions...you know, a deeper dive. \n\nI am interested in any recommendation. Thanks", "author_fullname": "t2_kbrpw1ikq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Day to day data science work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16q9s1d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695489057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;I have seen some videos on youtube where people talk about their daily work in data science and programming. These videos usually give a general view (for example they say they have daily meeting and code for several hours and so on) and don&amp;#39;t give a detailed view. &lt;/p&gt;\n\n&lt;p&gt;I am wondering if there is any channel or website about the day to day life of a data scientist at a company. For example, showing how they start with the projects and how they collaborate with others and how they code their solutions...you know, a deeper dive. &lt;/p&gt;\n\n&lt;p&gt;I am interested in any recommendation. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16q9s1d", "is_robot_indexable": true, "report_reasons": null, "author": "iamsupercuriouss", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16q9s1d/day_to_day_data_science_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16q9s1d/day_to_day_data_science_work/", "subreddit_subscribers": 1058681, "created_utc": 1695489057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\nI am preparing session about data presentation &amp; visualizations to share with my colleagues, they wanna know what's the best visual to use depending on the data.  \n\n\nI have a visual vocabulary documentation on this but I also wanna show them the visual with test data to be more practical.  \n\n\nI'll be using MS Power BI for visualization.  \n\n\nCan you suggest me good data generator websites that I can use to generate data and import it to Power BI?  \n\n\nThanks!", "author_fullname": "t2_6or8m0hm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Generator Website", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16q63lz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695479721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I am preparing session about data presentation &amp;amp; visualizations to share with my colleagues, they wanna know what&amp;#39;s the best visual to use depending on the data.  &lt;/p&gt;\n\n&lt;p&gt;I have a visual vocabulary documentation on this but I also wanna show them the visual with test data to be more practical.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll be using MS Power BI for visualization.  &lt;/p&gt;\n\n&lt;p&gt;Can you suggest me good data generator websites that I can use to generate data and import it to Power BI?  &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16q63lz", "is_robot_indexable": true, "report_reasons": null, "author": "Judessaa", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16q63lz/data_generator_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16q63lz/data_generator_website/", "subreddit_subscribers": 1058681, "created_utc": 1695479721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone!\n\nMulti-part question.\n\n\n1. I have scraped text (I repeat, text, and not structured data such as tables or something) from a medical site, and I want to know how to clean it. And when I say clean, I don't mean removal of html tags and such. I already have the paragraphs in plain text but there is a lot of spammy stuff like \"You are not signed in; subscribe to this newsletter; by checking this box, I agree to the terms and conditions, etc.\" This text is not the exact same in all the paragraphs but there is high similarity. I would have thought there would be many tools to clean text and remove unrelated chunks like these but all I have been able to find has to do with cleaning html tags, changing date-time format and so on. Am I missing something or is this actually difficult?\n\nSecondly, the spammy text I mentioned is from just one site. I will be eventually scaling to many sites and god knows what random text I'll have to clean then.\n\n\n2. I used OpenAI embeddings and cosine similarity on the medical text to find similar paragraphs. The results were not great. Is there a way to improve the similarity search? I will be trying FAISS next but wanted to know what else I can do. It was suggested to me to use a pretrained embedding model specific to medical data. However, I found only one such model which is 20 gigs!\n\n\nI'm just getting started with these, so, appreciate any help I can get.\n\n\nThanks a ton!", "author_fullname": "t2_gaxqj6m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cleaning scraped TEXT; improving similarity search", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16q252o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695468628.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;Multi-part question.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I have scraped text (I repeat, text, and not structured data such as tables or something) from a medical site, and I want to know how to clean it. And when I say clean, I don&amp;#39;t mean removal of html tags and such. I already have the paragraphs in plain text but there is a lot of spammy stuff like &amp;quot;You are not signed in; subscribe to this newsletter; by checking this box, I agree to the terms and conditions, etc.&amp;quot; This text is not the exact same in all the paragraphs but there is high similarity. I would have thought there would be many tools to clean text and remove unrelated chunks like these but all I have been able to find has to do with cleaning html tags, changing date-time format and so on. Am I missing something or is this actually difficult?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Secondly, the spammy text I mentioned is from just one site. I will be eventually scaling to many sites and god knows what random text I&amp;#39;ll have to clean then.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I used OpenAI embeddings and cosine similarity on the medical text to find similar paragraphs. The results were not great. Is there a way to improve the similarity search? I will be trying FAISS next but wanted to know what else I can do. It was suggested to me to use a pretrained embedding model specific to medical data. However, I found only one such model which is 20 gigs!&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m just getting started with these, so, appreciate any help I can get.&lt;/p&gt;\n\n&lt;p&gt;Thanks a ton!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16q252o", "is_robot_indexable": true, "report_reasons": null, "author": "yipra97", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16q252o/cleaning_scraped_text_improving_similarity_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16q252o/cleaning_scraped_text_improving_similarity_search/", "subreddit_subscribers": 1058681, "created_utc": 1695468628.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working as a system engineer for more than 7 years in an IT company. Currently I am switching my career to data science. I have started with post graduate program on data science and business analytics. What kind of job roles should I look for in the market. I am not that good in coding.", "author_fullname": "t2_9o2ozdun", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of job I should look for DS with experience in IT.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16q1wye", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695467871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working as a system engineer for more than 7 years in an IT company. Currently I am switching my career to data science. I have started with post graduate program on data science and business analytics. What kind of job roles should I look for in the market. I am not that good in coding.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16q1wye", "is_robot_indexable": true, "report_reasons": null, "author": "Lucky-bastard-2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16q1wye/what_kind_of_job_i_should_look_for_ds_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16q1wye/what_kind_of_job_i_should_look_for_ds_with/", "subreddit_subscribers": 1058681, "created_utc": 1695467871.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am an aspiring data scientist currently pursuing a BCs in CS (2nd year). Lately, I've been actively searching for remote data science internships to gain practical experience and make my resume strong. I've come across several online virtual internship programs that are open to anyone. I am wondering if these opportunities are worth the time and if it's appropriate to include them in my work experience. Here are a few examples of such programs:\n\n1. [iNeuron](https://internship.ineuron.ai/)\n2. [OpenWeaver](https://community.openweaver.com/t/virtual-internship-in-data-science-apply-now/114521)\n3. [The Spark Foundation](https://internship.thesparksfoundation.info/)\n4. [Let's Grown More](https://letsgrowmore.in/vip/)", "author_fullname": "t2_6oagcr1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are these DS Virtual Internships good to get started?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16qt2n3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695546597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an aspiring data scientist currently pursuing a BCs in CS (2nd year). Lately, I&amp;#39;ve been actively searching for remote data science internships to gain practical experience and make my resume strong. I&amp;#39;ve come across several online virtual internship programs that are open to anyone. I am wondering if these opportunities are worth the time and if it&amp;#39;s appropriate to include them in my work experience. Here are a few examples of such programs:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://internship.ineuron.ai/\"&gt;iNeuron&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://community.openweaver.com/t/virtual-internship-in-data-science-apply-now/114521\"&gt;OpenWeaver&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://internship.thesparksfoundation.info/\"&gt;The Spark Foundation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://letsgrowmore.in/vip/\"&gt;Let&amp;#39;s Grown More&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qt2n3", "is_robot_indexable": true, "report_reasons": null, "author": "hashirbhatti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qt2n3/are_these_ds_virtual_internships_good_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qt2n3/are_these_ds_virtual_internships_good_to_get/", "subreddit_subscribers": 1058681, "created_utc": 1695546597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys are there any good certifications for data science that companies actually take seriously?", "author_fullname": "t2_887w37gq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science certification.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16qslw1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695544932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys are there any good certifications for data science that companies actually take seriously?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qslw1", "is_robot_indexable": true, "report_reasons": null, "author": "Expert-Ladder-4211", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qslw1/data_science_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qslw1/data_science_certification/", "subreddit_subscribers": 1058681, "created_utc": 1695544932.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hello everyone I am a sophomore data science student I want to learn data science online for some reason I cant rely on my uni so I am watching lectures on pandas numpy and other stuff but I am confused about practice like how do I practice to get the grasp on the skills and I want to learn statistics too so should I cover whole statistics or are there some specific topics needed for data science \n\nthanks in advance", "author_fullname": "t2_efiv4rbk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qsj8s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695544661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello everyone I am a sophomore data science student I want to learn data science online for some reason I cant rely on my uni so I am watching lectures on pandas numpy and other stuff but I am confused about practice like how do I practice to get the grasp on the skills and I want to learn statistics too so should I cover whole statistics or are there some specific topics needed for data science &lt;/p&gt;\n\n&lt;p&gt;thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qsj8s", "is_robot_indexable": true, "report_reasons": null, "author": "MNBizBot", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qsj8s/guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qsj8s/guidance/", "subreddit_subscribers": 1058681, "created_utc": 1695544661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working on reproducing results claimed by an author in a research paper. \n\nI have followed the same process and have a model training and running.\n\nSo the MAE they claim is 5. And I am able to reproduce 23. \n\nI am a bit new to this, so when talking about reproducing results; how different can they be to say \"reproduce successful\"?", "author_fullname": "t2_123jiosa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing \"claimed\" results vs \"reproduced\" results.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qpup6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695535075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on reproducing results claimed by an author in a research paper. &lt;/p&gt;\n\n&lt;p&gt;I have followed the same process and have a model training and running.&lt;/p&gt;\n\n&lt;p&gt;So the MAE they claim is 5. And I am able to reproduce 23. &lt;/p&gt;\n\n&lt;p&gt;I am a bit new to this, so when talking about reproducing results; how different can they be to say &amp;quot;reproduce successful&amp;quot;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qpup6", "is_robot_indexable": true, "report_reasons": null, "author": "Dump7", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qpup6/comparing_claimed_results_vs_reproduced_results/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qpup6/comparing_claimed_results_vs_reproduced_results/", "subreddit_subscribers": 1058681, "created_utc": 1695535075.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI\u2019ve been trying to improve my SQL skills, specifically in writing queries involving joins and subqueries. I\u2019ve gone through several SQL tutorials on YouTube and while I feel like I understand the concepts being taught, I struggle when it comes to applying them in practice.\n\nWhen given a problem, I find it difficult to write the corresponding SQL queries. This has led me to question whether I\u2019ve truly grasped the theoretical and practical aspects of SQL.\n\nHas anyone else experienced this? How did you overcome it? Any advice or resources that could help me bridge this gap between understanding and application would be greatly appreciated.\n\nThank you!", "author_fullname": "t2_k37psi1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling with SQL Queries - Need Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qplm4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695534149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been trying to improve my SQL skills, specifically in writing queries involving joins and subqueries. I\u2019ve gone through several SQL tutorials on YouTube and while I feel like I understand the concepts being taught, I struggle when it comes to applying them in practice.&lt;/p&gt;\n\n&lt;p&gt;When given a problem, I find it difficult to write the corresponding SQL queries. This has led me to question whether I\u2019ve truly grasped the theoretical and practical aspects of SQL.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else experienced this? How did you overcome it? Any advice or resources that could help me bridge this gap between understanding and application would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qplm4", "is_robot_indexable": true, "report_reasons": null, "author": "PleaseJustStayAlive", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qplm4/struggling_with_sql_queries_need_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qplm4/struggling_with_sql_queries_need_advice/", "subreddit_subscribers": 1058681, "created_utc": 1695534149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHi All,\n\nIs there a way to collect real time data regarding Packaged food and its ingredients. I'm currently focussing on Indian packaged foods. Any sugestion would be extemely helpful.\n\nThanks a lot!", "author_fullname": "t2_3dgxudc7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Packaged food related ingredients and its proportions in a dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qo5es", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695529018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;Is there a way to collect real time data regarding Packaged food and its ingredients. I&amp;#39;m currently focussing on Indian packaged foods. Any sugestion would be extemely helpful.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qo5es", "is_robot_indexable": true, "report_reasons": null, "author": "ashnel11", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qo5es/packaged_food_related_ingredients_and_its/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qo5es/packaged_food_related_ingredients_and_its/", "subreddit_subscribers": 1058681, "created_utc": 1695529018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "at work.", "author_fullname": "t2_12nt66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What pissed you off last week?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qap3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695491385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;at work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qap3h", "is_robot_indexable": true, "report_reasons": null, "author": "masc98", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qap3h/what_pissed_you_off_last_week/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qap3h/what_pissed_you_off_last_week/", "subreddit_subscribers": 1058681, "created_utc": 1695491385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello. I hope you find this post well.\n\nI have a dataset, with a categorical column of different labels. 3 labels make up 40%, while 60% is 'unknown'. I feel like they can be imputed with the known labels, but idk if that's OK to do.  Missing-data doesn't properly describe this case. It's not with NaN's or Nulls, but literally recorded in text strings as \"CATEGORY\\_UNKNOWN\" by whatever 'procedure' the dataset's makers used to populate said column (which means this can't be MCAR aka Missing completely at Random, right?) . A 'procedure' that I might add, probably isn't 100% reliable either (think like object image recognition with ConvNets). Which opens the chances that some unknowns could be knowns but was sloppily mis-recorded. I'd first have to show that some of the unknown's are actually among the known 3 labels. It's still likely some are indeed new and un-categorizable, so I'd still need to leave some unknowns un-imputed.\n\nIDK how to do this.\n\n* I could do column-by-column permutation tests for each known-label's subset of rows against the unknown rows. Those that fail null-rejection for all columns get imputed by that label.\n* Or I can split the dataset into 2 tables of knowns and unknowns, train+test a multi-class logistic reg model on the knowns, then run it on the unknowns. And to still maintain a group of \"unknowns\", I will un-impute those with low-variance softmax-prediction-vectors back into unknown. Idk how to do that in Sklearn, but I know multinomial reg's class-wise weight vectors are accessible in a  (n\\_classes x n\\_features) matrix, so I'd have to manually calculate each imputed label's sigmoid value from its coefs\\_ &amp; intercepts\\_, then judge if it's \"weak\".\n\nWhat biases am I'm over-looking?\n\nThere's still the flaw that just because something unknown is similar to a known label, doesn't mean it's of that label. But that's unimportant for the greater project task that this messy-data-issue is blocking me from advancing to.\n\nSome preliminary EDA I did:\n\n* I binarized the labels as knowns=0 vs unknowns=1. Then got the dataset's correlation matrix, and saw many columns had high abs-correlations with the binarized label column.  I've yet to do any \"known-vs-unknown\" logistic reg model, but it feels like this is missingness at Random, since the dataset internally has info that can help determine what's missing, right?\n* I also did a 2D PCA scatterplot for the other columns, and upon setting the matplotlib color variable with the binarized labels, there's 2 ostensibly separable clusters. Wouldn't this suggest  the unknowns and knowns are indeed different, meaning I \\*cannot\\* do any imputation in the first place?", "author_fullname": "t2_w594l9jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handling missing/unknown data-labels with imputation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16q9b4x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1695489293.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695487866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I hope you find this post well.&lt;/p&gt;\n\n&lt;p&gt;I have a dataset, with a categorical column of different labels. 3 labels make up 40%, while 60% is &amp;#39;unknown&amp;#39;. I feel like they can be imputed with the known labels, but idk if that&amp;#39;s OK to do.  Missing-data doesn&amp;#39;t properly describe this case. It&amp;#39;s not with NaN&amp;#39;s or Nulls, but literally recorded in text strings as &amp;quot;CATEGORY_UNKNOWN&amp;quot; by whatever &amp;#39;procedure&amp;#39; the dataset&amp;#39;s makers used to populate said column (which means this can&amp;#39;t be MCAR aka Missing completely at Random, right?) . A &amp;#39;procedure&amp;#39; that I might add, probably isn&amp;#39;t 100% reliable either (think like object image recognition with ConvNets). Which opens the chances that some unknowns could be knowns but was sloppily mis-recorded. I&amp;#39;d first have to show that some of the unknown&amp;#39;s are actually among the known 3 labels. It&amp;#39;s still likely some are indeed new and un-categorizable, so I&amp;#39;d still need to leave some unknowns un-imputed.&lt;/p&gt;\n\n&lt;p&gt;IDK how to do this.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I could do column-by-column permutation tests for each known-label&amp;#39;s subset of rows against the unknown rows. Those that fail null-rejection for all columns get imputed by that label.&lt;/li&gt;\n&lt;li&gt;Or I can split the dataset into 2 tables of knowns and unknowns, train+test a multi-class logistic reg model on the knowns, then run it on the unknowns. And to still maintain a group of &amp;quot;unknowns&amp;quot;, I will un-impute those with low-variance softmax-prediction-vectors back into unknown. Idk how to do that in Sklearn, but I know multinomial reg&amp;#39;s class-wise weight vectors are accessible in a  (n_classes x n_features) matrix, so I&amp;#39;d have to manually calculate each imputed label&amp;#39;s sigmoid value from its coefs_ &amp;amp; intercepts_, then judge if it&amp;#39;s &amp;quot;weak&amp;quot;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What biases am I&amp;#39;m over-looking?&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s still the flaw that just because something unknown is similar to a known label, doesn&amp;#39;t mean it&amp;#39;s of that label. But that&amp;#39;s unimportant for the greater project task that this messy-data-issue is blocking me from advancing to.&lt;/p&gt;\n\n&lt;p&gt;Some preliminary EDA I did:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I binarized the labels as knowns=0 vs unknowns=1. Then got the dataset&amp;#39;s correlation matrix, and saw many columns had high abs-correlations with the binarized label column.  I&amp;#39;ve yet to do any &amp;quot;known-vs-unknown&amp;quot; logistic reg model, but it feels like this is missingness at Random, since the dataset internally has info that can help determine what&amp;#39;s missing, right?&lt;/li&gt;\n&lt;li&gt;I also did a 2D PCA scatterplot for the other columns, and upon setting the matplotlib color variable with the binarized labels, there&amp;#39;s 2 ostensibly separable clusters. Wouldn&amp;#39;t this suggest  the unknowns and knowns are indeed different, meaning I *cannot* do any imputation in the first place?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16q9b4x", "is_robot_indexable": true, "report_reasons": null, "author": "Lockonon3", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16q9b4x/handling_missingunknown_datalabels_with_imputation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16q9b4x/handling_missingunknown_datalabels_with_imputation/", "subreddit_subscribers": 1058681, "created_utc": 1695487866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As everyone knows the job market for data science is incredibly competitive, even for roles in the boring sectors like insurance, etc. The constant uncertainty/effort required to secure these positions is a bit worrying - I like the work, but it feels like an insecure career path, not only due to lay-off risk but also given the fierce competition and limited job opportunities whenever you have to change job for whatever reason.\n\nI'm also looking for something that offers more flexibility in terms of the sectors I can work in, because as I said it feels like finding data science work within a boring field is already a struggle - finding it in an interesting sector seems almost impossible.\n\nI'm still really passionate about maths and coding, and I'd like to continue working with these skills. It would be ideal if I could leverage the experience I've gained in data science while pursuing a more sustainable and flexible career path.\n\nHas anyone faced a similar situation or found job opportunities that align with these criteria? I'd appreciate any insights or suggestions.", "author_fullname": "t2_m0llzgc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternatives to DS with as much maths/programming but less precariousness", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16q95bm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695487457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As everyone knows the job market for data science is incredibly competitive, even for roles in the boring sectors like insurance, etc. The constant uncertainty/effort required to secure these positions is a bit worrying - I like the work, but it feels like an insecure career path, not only due to lay-off risk but also given the fierce competition and limited job opportunities whenever you have to change job for whatever reason.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also looking for something that offers more flexibility in terms of the sectors I can work in, because as I said it feels like finding data science work within a boring field is already a struggle - finding it in an interesting sector seems almost impossible.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m still really passionate about maths and coding, and I&amp;#39;d like to continue working with these skills. It would be ideal if I could leverage the experience I&amp;#39;ve gained in data science while pursuing a more sustainable and flexible career path.&lt;/p&gt;\n\n&lt;p&gt;Has anyone faced a similar situation or found job opportunities that align with these criteria? I&amp;#39;d appreciate any insights or suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16q95bm", "is_robot_indexable": true, "report_reasons": null, "author": "Bhagafat", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16q95bm/alternatives_to_ds_with_as_much_mathsprogramming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16q95bm/alternatives_to_ds_with_as_much_mathsprogramming/", "subreddit_subscribers": 1058681, "created_utc": 1695487457.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}