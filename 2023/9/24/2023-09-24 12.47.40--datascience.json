{"kind": "Listing", "data": {"after": "t3_16qap3h", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a master's student rn, graduating next year and just got a return offer from the internship I did this summer. It was a cool place and I liked the people, but their salary offer isn't great - $68,000 in a high CoL city (Washington DC area). It does come with good benefits which is nice, and I've been told it's very likely my pay would go up to at least $90,000 after two years, with potential for higher. \n\nShould I accept given the current state of the job market? Or should I decline and search for a higher-paying opportunity later? Financially, I believe I could make $68,000 work, but it would be tough with student loan debt and DC rent. DC is also a considerable distance from my family and not ideally where I'd want to settle, although I generally like the area. The position does not allow WFH either which is a downside.", "author_fullname": "t2_7cpxsyw0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I accept this data science job (i.e. how bad is the job market?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qaxeq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 120, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 120, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695516869.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695492007.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a master&amp;#39;s student rn, graduating next year and just got a return offer from the internship I did this summer. It was a cool place and I liked the people, but their salary offer isn&amp;#39;t great - $68,000 in a high CoL city (Washington DC area). It does come with good benefits which is nice, and I&amp;#39;ve been told it&amp;#39;s very likely my pay would go up to at least $90,000 after two years, with potential for higher. &lt;/p&gt;\n\n&lt;p&gt;Should I accept given the current state of the job market? Or should I decline and search for a higher-paying opportunity later? Financially, I believe I could make $68,000 work, but it would be tough with student loan debt and DC rent. DC is also a considerable distance from my family and not ideally where I&amp;#39;d want to settle, although I generally like the area. The position does not allow WFH either which is a downside.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qaxeq", "is_robot_indexable": true, "report_reasons": null, "author": "ChipotleAccount", "discussion_type": null, "num_comments": 96, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qaxeq/should_i_accept_this_data_science_job_ie_how_bad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qaxeq/should_i_accept_this_data_science_job_ie_how_bad/", "subreddit_subscribers": 1058788, "created_utc": 1695492007.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've noticed a trend over the past few months on this subreddit, and it's something I'd like to address in a constructive manner. It seems that a significant portion of the posts here revolves around career-related queries, job offers, and CV reviews. While I understand the value of such discussions, when they dominate 99% of the content, it can diminish the enthusiasm for the subreddit.\n\nIMHO, I believe this sub could benefit from a more diverse range of posts. I'd love to see more members sharing their projects, posting blog articles about new techniques, and discussing about technical topics. I believe we can all learn a lot from  these kind of conversations.\n\nAlso, notice that many of the common career questions have already been comprehensively addressed in previous discussions. Instead of repeating the same topics, we can work together to create a space where we can learn about new topics.\n\nWhat do you thing? Do you think the same or am I simply becoming old and grumpy?\n\nPS. Maybe we could download data from the posts on this sub and test my hypothesis, ie: test that the frequency of posts with the Flair \"Career\" are more abundant that the others ;)", "author_fullname": "t2_6nmywi2j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are there too many posts focused on career discussions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qc882", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 98, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 98, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695495331.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve noticed a trend over the past few months on this subreddit, and it&amp;#39;s something I&amp;#39;d like to address in a constructive manner. It seems that a significant portion of the posts here revolves around career-related queries, job offers, and CV reviews. While I understand the value of such discussions, when they dominate 99% of the content, it can diminish the enthusiasm for the subreddit.&lt;/p&gt;\n\n&lt;p&gt;IMHO, I believe this sub could benefit from a more diverse range of posts. I&amp;#39;d love to see more members sharing their projects, posting blog articles about new techniques, and discussing about technical topics. I believe we can all learn a lot from  these kind of conversations.&lt;/p&gt;\n\n&lt;p&gt;Also, notice that many of the common career questions have already been comprehensively addressed in previous discussions. Instead of repeating the same topics, we can work together to create a space where we can learn about new topics.&lt;/p&gt;\n\n&lt;p&gt;What do you thing? Do you think the same or am I simply becoming old and grumpy?&lt;/p&gt;\n\n&lt;p&gt;PS. Maybe we could download data from the posts on this sub and test my hypothesis, ie: test that the frequency of posts with the Flair &amp;quot;Career&amp;quot; are more abundant that the others ;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qc882", "is_robot_indexable": true, "report_reasons": null, "author": "AM_DS", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qc882/are_there_too_many_posts_focused_on_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qc882/are_there_too_many_posts_focused_on_career/", "subreddit_subscribers": 1058788, "created_utc": 1695495331.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I have called an interview for 2 days and there will be 3 person participated in interview : Talent acquisition specialist,  Data Scientist, Director. What kind of questions should I expect  from them. I need some help because I am fresh graduate and I haven't experienced it before. thanks in advance. Here is job description and requirements:\n\n**Skills Required:**\n\n* Bachelor\u2019s Degree in Computer Science, IT, or similar field; a Master\u2019s is a plus\n* Minimum 1 year experience as a data engineer/scientist or in a similar role\n* Technical expertise with data models, data mining, and segmentation techniques.\n* Ability to compose pipelines for data science models.\n* Knowledge of Machine Learning techniques, including decision tree learning, clustering, artificial neural networks, etc., and their pros and cons\n* Data Wrangling \u2013 proficiency in handling imperfections in data.\n* Programming Skills \u2013 good knowledge of statistical programming languages like R, Python, and hands on experience database query languages like SQL.\n* Statistics \u2013 Good applied statistical skills, including knowledge of statistical tests, distributions, regression, maximum likelihood estimators, etc.\n* Basic Math Skills (Linear Algebra) - understanding the fundamentals of Linear Algebra.\n* Knowledge with Timeseries data analysis and modelling.\n* Knowledge with regular expressions.\n* Knowledge with Data Visualization Tools like Power BI, Spotfire, Tableau, matplotlib, etc.\n* Great numerical and analytical skills\n* Excellent Communication Skills \u2013efficiently communicating with both a technical and non-technical audience.", "author_fullname": "t2_gswtior2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "About Junior Data Scientist Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qd0ij", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695497341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I have called an interview for 2 days and there will be 3 person participated in interview : Talent acquisition specialist,  Data Scientist, Director. What kind of questions should I expect  from them. I need some help because I am fresh graduate and I haven&amp;#39;t experienced it before. thanks in advance. Here is job description and requirements:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Skills Required:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Bachelor\u2019s Degree in Computer Science, IT, or similar field; a Master\u2019s is a plus&lt;/li&gt;\n&lt;li&gt;Minimum 1 year experience as a data engineer/scientist or in a similar role&lt;/li&gt;\n&lt;li&gt;Technical expertise with data models, data mining, and segmentation techniques.&lt;/li&gt;\n&lt;li&gt;Ability to compose pipelines for data science models.&lt;/li&gt;\n&lt;li&gt;Knowledge of Machine Learning techniques, including decision tree learning, clustering, artificial neural networks, etc., and their pros and cons&lt;/li&gt;\n&lt;li&gt;Data Wrangling \u2013 proficiency in handling imperfections in data.&lt;/li&gt;\n&lt;li&gt;Programming Skills \u2013 good knowledge of statistical programming languages like R, Python, and hands on experience database query languages like SQL.&lt;/li&gt;\n&lt;li&gt;Statistics \u2013 Good applied statistical skills, including knowledge of statistical tests, distributions, regression, maximum likelihood estimators, etc.&lt;/li&gt;\n&lt;li&gt;Basic Math Skills (Linear Algebra) - understanding the fundamentals of Linear Algebra.&lt;/li&gt;\n&lt;li&gt;Knowledge with Timeseries data analysis and modelling.&lt;/li&gt;\n&lt;li&gt;Knowledge with regular expressions.&lt;/li&gt;\n&lt;li&gt;Knowledge with Data Visualization Tools like Power BI, Spotfire, Tableau, matplotlib, etc.&lt;/li&gt;\n&lt;li&gt;Great numerical and analytical skills&lt;/li&gt;\n&lt;li&gt;Excellent Communication Skills \u2013efficiently communicating with both a technical and non-technical audience.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qd0ij", "is_robot_indexable": true, "report_reasons": null, "author": "NailaBaghir", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qd0ij/about_junior_data_scientist_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qd0ij/about_junior_data_scientist_interview/", "subreddit_subscribers": 1058788, "created_utc": 1695497341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nI am currently embarking on my first web scraping project as part of my internship, and I've encountered a challenge that has left me uncertain about its feasibility. My task involves signing in to Glassdoor, conducting searches within the 'companies' section for specific countries, and then extracting salary data for all job positions within those companies in the respective countries. However, I've encountered a few complexities.\n\nFirstly, I'm faced with a scenario where I have 200 pages to navigate, each containing 5 companies. To access salary data for a company, I need to click on its profile, navigate to the 'salaries' tab, and change the location setting to match the country I'm scraping data for. This location setting is initially set to the United States for all companies.\n\nFurthermore, each company's profile may have a varying number of pages of salary data, depending on the company's size. After collecting data for one company, I need to return to the page with the list of 5 companies, select the next company, and repeat the entire process.\n\nI would like to know if this task is achievable, and if so, what steps and technologies should I familiarize myself with in order to successfully accomplish it?", "author_fullname": "t2_2yw2wk44", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Glassdoor salaries scraper for all companies in a country.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qmh1x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695523514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently embarking on my first web scraping project as part of my internship, and I&amp;#39;ve encountered a challenge that has left me uncertain about its feasibility. My task involves signing in to Glassdoor, conducting searches within the &amp;#39;companies&amp;#39; section for specific countries, and then extracting salary data for all job positions within those companies in the respective countries. However, I&amp;#39;ve encountered a few complexities.&lt;/p&gt;\n\n&lt;p&gt;Firstly, I&amp;#39;m faced with a scenario where I have 200 pages to navigate, each containing 5 companies. To access salary data for a company, I need to click on its profile, navigate to the &amp;#39;salaries&amp;#39; tab, and change the location setting to match the country I&amp;#39;m scraping data for. This location setting is initially set to the United States for all companies.&lt;/p&gt;\n\n&lt;p&gt;Furthermore, each company&amp;#39;s profile may have a varying number of pages of salary data, depending on the company&amp;#39;s size. After collecting data for one company, I need to return to the page with the list of 5 companies, select the next company, and repeat the entire process.&lt;/p&gt;\n\n&lt;p&gt;I would like to know if this task is achievable, and if so, what steps and technologies should I familiarize myself with in order to successfully accomplish it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qmh1x", "is_robot_indexable": true, "report_reasons": null, "author": "elhamoly98", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qmh1x/glassdoor_salaries_scraper_for_all_companies_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qmh1x/glassdoor_salaries_scraper_for_all_companies_in_a/", "subreddit_subscribers": 1058788, "created_utc": 1695523514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I employ existing widely used CNNs (e.g., `Xception`, `DenseNet169`, `InceptionV3`) via transfer-learning using Keras for a classification task of `10` classes. I've employed almost every available model but still experiencing overfitting as you can see via the attached accuracy-epoch graph, which was obtained during training. I re-calculate the weights of the layers that come with the existing models (*a.k.a.* base models). I've employed KerasTuner to optimize the hyperparameters such as the activation function, optimization algorithm, and learning rate. As a result of this task, `Adam` and `ReLU` were set as the optimization algorithm and activation function, respectively. To prevent overfitting, following the base model, I've added a `Dense` with `1,024` units and a `Dropout` layer with a dropout rate of `0.6` (kept that high to prevent overfitting) just before the final `Dense` layer with `softmax` activation function, which is solely responsible for the classification. I do use a 4-fold CV and the test set/train set ratio is `.3`. The total number of samples is `1,000` and each sample has a shape of `224x224x3`.\n\nHere are the scores that I've obtained on the test set:\n\nAcc: `72.5%`\n\nF1-Score: `72.287%`\n\nPrecision: `73.734%`\n\nRecall: `72.5%`\n\nAny recommendations to improve the test accuracy of the model are greatly appreciated. Please feel free to ask for any further information, which I might missed to note.\n\nMany thanks in advance for your time.\n\n*p.s. This task is a part of my own research project; not seeking help for homework or an exam.*\n\n[Accuracy-Epoch graph](https://preview.redd.it/ehqqfp1gc3qb1.png?width=750&amp;format=png&amp;auto=webp&amp;s=635ff0368530a400c271912e370aa7751b28c6de)", "author_fullname": "t2_rra8v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I further improve the accuracy of my CNN based on transfer-learning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 102, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ehqqfp1gc3qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/ehqqfp1gc3qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e83284186f63764e965f0f1df35258730f30abec"}, {"y": 158, "x": 216, "u": "https://preview.redd.it/ehqqfp1gc3qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=77999a2e263abae18b930dd0d4bd9059148c39ca"}, {"y": 234, "x": 320, "u": "https://preview.redd.it/ehqqfp1gc3qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c4fe86afbcfbaf6b5bc8338dbc498e993a1fe8e"}, {"y": 469, "x": 640, "u": "https://preview.redd.it/ehqqfp1gc3qb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5607c205ed1b934a2483d8aadd85c57f1b4a3a53"}], "s": {"y": 550, "x": 750, "u": "https://preview.redd.it/ehqqfp1gc3qb1.png?width=750&amp;format=png&amp;auto=webp&amp;s=635ff0368530a400c271912e370aa7751b28c6de"}, "id": "ehqqfp1gc3qb1"}}, "name": "t3_16qj0w2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Xm8SUClvOs6tY_0MCGHEpCFV0tuZnddsM2Oy3JzO490.jpg", "edited": 1695528340.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695513126.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I employ existing widely used CNNs (e.g., &lt;code&gt;Xception&lt;/code&gt;, &lt;code&gt;DenseNet169&lt;/code&gt;, &lt;code&gt;InceptionV3&lt;/code&gt;) via transfer-learning using Keras for a classification task of &lt;code&gt;10&lt;/code&gt; classes. I&amp;#39;ve employed almost every available model but still experiencing overfitting as you can see via the attached accuracy-epoch graph, which was obtained during training. I re-calculate the weights of the layers that come with the existing models (&lt;em&gt;a.k.a.&lt;/em&gt; base models). I&amp;#39;ve employed KerasTuner to optimize the hyperparameters such as the activation function, optimization algorithm, and learning rate. As a result of this task, &lt;code&gt;Adam&lt;/code&gt; and &lt;code&gt;ReLU&lt;/code&gt; were set as the optimization algorithm and activation function, respectively. To prevent overfitting, following the base model, I&amp;#39;ve added a &lt;code&gt;Dense&lt;/code&gt; with &lt;code&gt;1,024&lt;/code&gt; units and a &lt;code&gt;Dropout&lt;/code&gt; layer with a dropout rate of &lt;code&gt;0.6&lt;/code&gt; (kept that high to prevent overfitting) just before the final &lt;code&gt;Dense&lt;/code&gt; layer with &lt;code&gt;softmax&lt;/code&gt; activation function, which is solely responsible for the classification. I do use a 4-fold CV and the test set/train set ratio is &lt;code&gt;.3&lt;/code&gt;. The total number of samples is &lt;code&gt;1,000&lt;/code&gt; and each sample has a shape of &lt;code&gt;224x224x3&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Here are the scores that I&amp;#39;ve obtained on the test set:&lt;/p&gt;\n\n&lt;p&gt;Acc: &lt;code&gt;72.5%&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;F1-Score: &lt;code&gt;72.287%&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Precision: &lt;code&gt;73.734%&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Recall: &lt;code&gt;72.5%&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Any recommendations to improve the test accuracy of the model are greatly appreciated. Please feel free to ask for any further information, which I might missed to note.&lt;/p&gt;\n\n&lt;p&gt;Many thanks in advance for your time.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;p.s. This task is a part of my own research project; not seeking help for homework or an exam.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ehqqfp1gc3qb1.png?width=750&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=635ff0368530a400c271912e370aa7751b28c6de\"&gt;Accuracy-Epoch graph&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qj0w2", "is_robot_indexable": true, "report_reasons": null, "author": "talhak", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qj0w2/how_can_i_further_improve_the_accuracy_of_my_cnn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qj0w2/how_can_i_further_improve_the_accuracy_of_my_cnn/", "subreddit_subscribers": 1058788, "created_utc": 1695513126.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'll be having a job interview in a few days and I think this question might come up and I personally don't know how to explain it to a layperson. Black box methods may come in handy one day, but I realized just now that I can't briefly explain how it works without making it sound like magic. What's your workaround for this? Have you been in a situation where you presented your results and you had to explain how neural networks operate in detail? Any similar experiences?", "author_fullname": "t2_bmbqthh3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For people in the industry, how do you explain the poor interpretability of some ML techniques to bosses who are not data scientists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qtywk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695549905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll be having a job interview in a few days and I think this question might come up and I personally don&amp;#39;t know how to explain it to a layperson. Black box methods may come in handy one day, but I realized just now that I can&amp;#39;t briefly explain how it works without making it sound like magic. What&amp;#39;s your workaround for this? Have you been in a situation where you presented your results and you had to explain how neural networks operate in detail? Any similar experiences?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qtywk", "is_robot_indexable": true, "report_reasons": null, "author": "krabbypatty-o-fish", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qtywk/for_people_in_the_industry_how_do_you_explain_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qtywk/for_people_in_the_industry_how_do_you_explain_the/", "subreddit_subscribers": 1058788, "created_utc": 1695549905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am studying data science and from media and asking people who are already working in the field strated to be concerned about finding a DS job after graduation.\nSo I am picking a plan B besides my DS BSc but still want to work in DS in the long term so what would you recommend me \nSoftware Engineering or Data engineeing\nI know some people would say data analyst but I just don't know anything about the jobs and from reading job discribtions I feel like using excel and dashboards is a waste for all the Math and programming and ML I have been studying in the last 3 years", "author_fullname": "t2_h5su2eud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software engineering or data engineeing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qptlb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695534965.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am studying data science and from media and asking people who are already working in the field strated to be concerned about finding a DS job after graduation.\nSo I am picking a plan B besides my DS BSc but still want to work in DS in the long term so what would you recommend me \nSoftware Engineering or Data engineeing\nI know some people would say data analyst but I just don&amp;#39;t know anything about the jobs and from reading job discribtions I feel like using excel and dashboards is a waste for all the Math and programming and ML I have been studying in the last 3 years&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qptlb", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional-Rhubarb725", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qptlb/software_engineering_or_data_engineeing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qptlb/software_engineering_or_data_engineeing/", "subreddit_subscribers": 1058788, "created_utc": 1695534965.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys, I needed some assistance with Forecasting a Time Series dataset using Neural Nets.\n\nFor context, the data has an annual seasonality with daily records of upto 5 years. Previously, I had used Statistical Methods like TBATS and DHR along with GARCH to transform and forecast.\n\nNow, I have been attempting to do the same using RNNs. I started off with GRU and LSTM with a few Hyperparameter Optimization Algorithms for the optimum depth, lookback window etc. only to end up with an eggregious yield of approx 10 MAPE.\n\nThus, I'd appreciate your input as to what can I improve be it an industry practise, some other insightful articles on the same or even alternative ML approaches!\n\nThanks in advance :)", "author_fullname": "t2_j6sk2g9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time Series Forecasting using RNN", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qnryv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695527752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I needed some assistance with Forecasting a Time Series dataset using Neural Nets.&lt;/p&gt;\n\n&lt;p&gt;For context, the data has an annual seasonality with daily records of upto 5 years. Previously, I had used Statistical Methods like TBATS and DHR along with GARCH to transform and forecast.&lt;/p&gt;\n\n&lt;p&gt;Now, I have been attempting to do the same using RNNs. I started off with GRU and LSTM with a few Hyperparameter Optimization Algorithms for the optimum depth, lookback window etc. only to end up with an eggregious yield of approx 10 MAPE.&lt;/p&gt;\n\n&lt;p&gt;Thus, I&amp;#39;d appreciate your input as to what can I improve be it an industry practise, some other insightful articles on the same or even alternative ML approaches!&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qnryv", "is_robot_indexable": true, "report_reasons": null, "author": "magic_groovin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qnryv/time_series_forecasting_using_rnn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qnryv/time_series_forecasting_using_rnn/", "subreddit_subscribers": 1058788, "created_utc": 1695527752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR; recommend a field of research which is related to Data Science.\n\nI\u2019m graduating with a BSc in Computer Science Engineering and all my peers are taken with the flow of \u201cSoftware Development\u201d which I really despise (I really do not find this field amusing/interesting/enjoyable, I know some of us work/study something they do not like and it\u2019s normal, but it\u2019s all tastes after all so hear me out).\n\nI got introduced to the field of Data Science about 6 months ago and already fell in love. I enrolled myself in [365 Data Science](https://365datascience.com) as a start to get familiarised with the field and started the Data Analyst career path which I\u2019m almost done with. I\u2019ve decided to finish all three tracks (Data Scientist, Data Analyst, and Business Analyst) before I move on with other learning material.\n\nNow I\u2019m in the process of applying for a PhD in the US, and I want your opinion on this particular topic.\n\nI want to research something related to the field of DS and have a good opportunity to find a job after finishing my PhD (I\u2019m interested in pursuing a career in both: Academic and Industrial).\n\nI\u2019m thinking about four PhD programs and the order doesn\u2019t matter: \n\n* Mathematics: Pure or Applied\n* Statistics\n* Computer Science (Do not prefer)\n* Data Science\n\nPlease advise me on which field of the four (or if you have another recommendation) will get me well-equipped during my journey.\n\nPS. english isn\u2019t my first language, so excuse me if anything is not clear, not coherent, or grammatically incorrect.", "author_fullname": "t2_8eewpx07f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PhD Advice needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qfoc5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695505639.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695504155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR; recommend a field of research which is related to Data Science.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m graduating with a BSc in Computer Science Engineering and all my peers are taken with the flow of \u201cSoftware Development\u201d which I really despise (I really do not find this field amusing/interesting/enjoyable, I know some of us work/study something they do not like and it\u2019s normal, but it\u2019s all tastes after all so hear me out).&lt;/p&gt;\n\n&lt;p&gt;I got introduced to the field of Data Science about 6 months ago and already fell in love. I enrolled myself in &lt;a href=\"https://365datascience.com\"&gt;365 Data Science&lt;/a&gt; as a start to get familiarised with the field and started the Data Analyst career path which I\u2019m almost done with. I\u2019ve decided to finish all three tracks (Data Scientist, Data Analyst, and Business Analyst) before I move on with other learning material.&lt;/p&gt;\n\n&lt;p&gt;Now I\u2019m in the process of applying for a PhD in the US, and I want your opinion on this particular topic.&lt;/p&gt;\n\n&lt;p&gt;I want to research something related to the field of DS and have a good opportunity to find a job after finishing my PhD (I\u2019m interested in pursuing a career in both: Academic and Industrial).&lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking about four PhD programs and the order doesn\u2019t matter: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mathematics: Pure or Applied&lt;/li&gt;\n&lt;li&gt;Statistics&lt;/li&gt;\n&lt;li&gt;Computer Science (Do not prefer)&lt;/li&gt;\n&lt;li&gt;Data Science&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Please advise me on which field of the four (or if you have another recommendation) will get me well-equipped during my journey.&lt;/p&gt;\n\n&lt;p&gt;PS. english isn\u2019t my first language, so excuse me if anything is not clear, not coherent, or grammatically incorrect.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?auto=webp&amp;s=2c79ec2c452bb4d01df675d2a739bd47f221a670", "width": 1200, "height": 627}, "resolutions": [{"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=108658d3e7925b2e114ce4a4c04d5f4e4295487d", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9561ba20aaf47ba07975c9cc270feb3b83108d8a", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=82e442618be3944d045e58fadd5034487d2d6642", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f0afa3e8d4b806ab74b5d8d146baf8afd3fa7b37", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7fd653b4af836fe5c3f3e7ad731464fa007c47fb", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/B-U7YKipzRsegPjbhMQ2eMIFLFDTxNL0nOgNOEEBtlg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=070e674c45fe1ce071fffe889a90255b231bbe82", "width": 1080, "height": 564}], "variants": {}, "id": "t7A4BY9o-aX-XTyFjhKEkiEB0ueAqjclZI80A8Moy40"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qfoc5", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Community_5554", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qfoc5/phd_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qfoc5/phd_advice_needed/", "subreddit_subscribers": 1058788, "created_utc": 1695504155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the Masters of Statistics programs there are often elective offerings for time series analysis which are based on the prerequisite statistical theory knowledge from casella and Berger. They cover the the theory of time series models (random walks, ar models, ma models, arma models, arima, sarima, garch etc), and maybe some non stationary time series. Homework\u2019s generally consist of both a theory and application side, theory maybe some derivations, and then applied is applying time series models learned that week to datasets in rmarkdown and exploring them with packages.\n\nMy question is, would such a background be useful if one was interested in data scientist roles which are very focused on forecasting? Are there dedicated teams for forecasting at companies? They often use base R stuff for the time series packages, so we often aren\u2019t taught the prophet, or any other modern python based time series packages. Would this be a deal breaker?", "author_fullname": "t2_i69qgpqa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does a theoretical understanding of time series help for forecasting roles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qbdfs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695493147.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the Masters of Statistics programs there are often elective offerings for time series analysis which are based on the prerequisite statistical theory knowledge from casella and Berger. They cover the the theory of time series models (random walks, ar models, ma models, arma models, arima, sarima, garch etc), and maybe some non stationary time series. Homework\u2019s generally consist of both a theory and application side, theory maybe some derivations, and then applied is applying time series models learned that week to datasets in rmarkdown and exploring them with packages.&lt;/p&gt;\n\n&lt;p&gt;My question is, would such a background be useful if one was interested in data scientist roles which are very focused on forecasting? Are there dedicated teams for forecasting at companies? They often use base R stuff for the time series packages, so we often aren\u2019t taught the prophet, or any other modern python based time series packages. Would this be a deal breaker?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qbdfs", "is_robot_indexable": true, "report_reasons": null, "author": "AdFew4357", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qbdfs/does_a_theoretical_understanding_of_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qbdfs/does_a_theoretical_understanding_of_time_series/", "subreddit_subscribers": 1058788, "created_utc": 1695493147.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I see a lot of posts on here about academic programs, resume advice, and interview tips, but not nearly as many about everyone's least favorite and arguably the most important part of career advancement - networking. \n\nNetworking looks different at different stages of your career, so how are you networking and what networking advice do you have for someone who might be:\n \n* A recent grad or someone changing careers and trying to break into the field?\n* A mid career professional trying to move up or build their reputation?\n* A senior or manager trying to connect with talented recruitment prospects?", "author_fullname": "t2_n638i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are you networking?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16q9k4q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695488492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see a lot of posts on here about academic programs, resume advice, and interview tips, but not nearly as many about everyone&amp;#39;s least favorite and arguably the most important part of career advancement - networking. &lt;/p&gt;\n\n&lt;p&gt;Networking looks different at different stages of your career, so how are you networking and what networking advice do you have for someone who might be:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A recent grad or someone changing careers and trying to break into the field?&lt;/li&gt;\n&lt;li&gt;A mid career professional trying to move up or build their reputation?&lt;/li&gt;\n&lt;li&gt;A senior or manager trying to connect with talented recruitment prospects?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16q9k4q", "is_robot_indexable": true, "report_reasons": null, "author": "Prime_Director", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16q9k4q/how_are_you_networking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16q9k4q/how_are_you_networking/", "subreddit_subscribers": 1058788, "created_utc": 1695488492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am an aspiring data scientist currently pursuing a BCs in CS (2nd year). Lately, I've been actively searching for remote data science internships to gain practical experience and make my resume strong. I've come across several online virtual internship programs that are open to anyone. I am wondering if these opportunities are worth the time and if it's appropriate to include them in my work experience. Here are a few examples of such programs:\n\n1. [iNeuron](https://internship.ineuron.ai/)\n2. [OpenWeaver](https://community.openweaver.com/t/virtual-internship-in-data-science-apply-now/114521)\n3. [The Spark Foundation](https://internship.thesparksfoundation.info/)\n4. [Let's Grown More](https://letsgrowmore.in/vip/)", "author_fullname": "t2_6oagcr1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are these DS Virtual Internships good to get started?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qt2n3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695546597.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an aspiring data scientist currently pursuing a BCs in CS (2nd year). Lately, I&amp;#39;ve been actively searching for remote data science internships to gain practical experience and make my resume strong. I&amp;#39;ve come across several online virtual internship programs that are open to anyone. I am wondering if these opportunities are worth the time and if it&amp;#39;s appropriate to include them in my work experience. Here are a few examples of such programs:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;a href=\"https://internship.ineuron.ai/\"&gt;iNeuron&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://community.openweaver.com/t/virtual-internship-in-data-science-apply-now/114521\"&gt;OpenWeaver&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://internship.thesparksfoundation.info/\"&gt;The Spark Foundation&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://letsgrowmore.in/vip/\"&gt;Let&amp;#39;s Grown More&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qt2n3", "is_robot_indexable": true, "report_reasons": null, "author": "hashirbhatti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qt2n3/are_these_ds_virtual_internships_good_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qt2n3/are_these_ds_virtual_internships_good_to_get/", "subreddit_subscribers": 1058788, "created_utc": 1695546597.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Enhancing your data analysis performance with Python's Numexpr and Pandas' eval/query functions \n\n This article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/) \n\n&amp;#x200B;\n\n[ Use Numexpr to help me find the most livable city. Photo Credit: Created by Author, Canva ](https://preview.redd.it/29ec8ukgr5qb1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=238da4465da17bd301b49112d574444b16d4113c)\n\n This article will introduce you to the Python library [Numexpr](https://numexpr.readthedocs.io/en/latest/intro.html?ref=dataleadsfuture.com#), a tool that boosts the computational performance of Numpy Arrays. The eval and query methods of Pandas are also based on this library.\n\n This article also includes a hands-on weather data analysis project. \n\n By reading this article, you will understand the principles of Numexpr and how to use this powerful tool to speed up your calculations in reality. \n\n# Introduction \n\n# Recalling Numpy Arrays\n\n In a previous article discussing Numpy Arrays, I used a library example to explain why Numpy's Cache Locality is so efficient: \n\n[https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/](https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/)\n\n Each time you go to the library to search for materials, you take out a few books related to the content and place them next to your desk. \n\n This way, you can quickly check related materials without having to run to the shelf each time you need to read a book. \n\n This method saves a lot of time, especially when you need to consult many related books. \n\n In this scenario, the shelf is like your memory, the desk is equivalent to the CPU's L1 cache, and you, the reader, are the CPU's core. \n\n&amp;#x200B;\n\n[ When the CPU accesses RAM, the cache loads the entire cache line into the high-speed cache. Image by Author ](https://preview.redd.it/3k7gdxywr5qb1.png?width=625&amp;format=png&amp;auto=webp&amp;s=5e6a2ed6620cf23638d9c3f20e5f6f46a54e0049)\n\n### The limitations of Numpy\n\n Suppose you are unfortunate enough to encounter a demanding professor who wants you to take out Shakespeare and Tolstoy's works for a cross-comparison. \n\n At this point, taking out related books in advance will not work well. \n\n First, your desk space is limited and cannot hold all the books of these two masters at the same time, not to mention the reading notes that will be generated during the comparison process. \n\n Second, you're just one person, and comparing so many works would take too long. It would be nice if you could find a few more people to help. \n\n This is the current situation when we use Numpy to deal with large amounts of data: \n\n* The number of elements in the Array is too large to fit into the CPU's L1 cache.\n* Numpy's element-level operations are single-threaded and cannot utilize the computing power of multi-core CPUs.\n\n What should we do? \n\n Don't worry. When you really encounter a problem with too much data, you can call on our protagonist today, Numexpr, to help. \n\n## Understanding Numexpr: What and Why\n\n### How it works\n\n When Numpy encounters large arrays, element-wise calculations will experience two extremes. \n\n Let me give you an example to illustrate. Suppose there are two large Numpy ndarrays: \n\n    import numpy as np \n    import numexpr as ne  \n    \n    a = np.random.rand(100_000_000) \n    b = np.random.rand(100_000_000)\n\n When calculating the result of the expression a\\*\\*5 + 2 \\* b, there are generally two methods:\n\n One way is Numpy's vectorized calculation method, which uses two temporary arrays to store the results of a\\*\\*5 and 2\\*b separately.  \n\n    In: %timeit a**5 + 2 * b\n    \n    Out:2.11 s \u00b1 31.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n At this time, you have four arrays in your memory: a, b, a\\*\\*5, and 2 \\* b. This method will cause a lot of memory waste. \n\n Moreover, since each Array's size exceeds the CPU cache's capacity, it cannot use it well. \n\n Another way is to traverse each element in two arrays and calculate them separately. \n\n    c = np.empty(100_000_000, dtype=np.uint32)\n    \n    def calcu_elements(a, b, c):\n        for i in range(0, len(a), 1):\n            c[i] = a[i] ** 5 + 2 * b[i]\n            \n    %timeit calcu_elements(a, b, c)\n    \n    \n    Out: 24.6 s \u00b1 48.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n This method performs even worse. The calculation will be very slow because it cannot use vectorized calculations and only partially utilize the CPU cache. \n\n### Numexpr's calculation\n\n Numexpr commonly uses only one evaluate method. This method will receive an expression string each time and then compile it into bytecode using Python's compile method. \n\n Numexpr also has a virtual machine program. The virtual machine contains multiple vector registers, each using a chunk size of 4096. \n\n When Numexpr starts to calculate, it sends the data in one or more registers to the CPU's L1 cache each time. This way, there won't be a situation where the memory is too slow, and the CPU waits for data. \n\n At the same time, Numexpr's virtual machine is written in C, removing Python's GIL. It can utilize the computing power of multi-core CPUs. \n\n So, Numexpr is faster when calculating large arrays than using Numpy alone. We can make a comparison: \n\n    In:  %timeit ne.evaluate('a**5 + 2 * b')\n    Out: 258 ms \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n### Summary of Numexpr's working principle\n\n Let's summarize the working principle of Numexpr and see why Numexpr is so fast: \n\n **Executing bytecode through a virtual machine.** Numexpr uses bytecode to execute expressions, which can fully utilize the [branch prediction](https://en.wikipedia.org/wiki/Branch_predictor?ref=dataleadsfuture.com) ability of the CPU, which is faster than using Python expressions. \n\n **Vectorized calculation.** Numexpr will use [SIMD (Single Instruction, Multiple Data)](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data?ref=dataleadsfuture.com) technology to improve computing efficiency significantly for the same operation on the data in each register. \n\n **Multi-core parallel computing.** Numexpr's virtual machine can decompose each task into multiple subtasks. They are executed in parallel on multiple CPU cores. \n\n **Less memory usage.** Unlike Numpy, which needs to generate intermediate arrays, Numexpr only loads a small amount of data when necessary, significantly reducing memory usage. \n\n&amp;#x200B;\n\n[ Workflow diagram of Numexpr. Image by Author ](https://preview.redd.it/46plaxk6t5qb1.png?width=863&amp;format=png&amp;auto=webp&amp;s=8c0bb7311c4fc743d720c2e0cec3c28c1ff98ed3)\n\n## Numexpr and Pandas: A Powerful Combination\n\n You might be wondering: We usually do data analysis with pandas. I understand the performance improvements Numexpr offers for Numpy, but does it have the same improvement for Pandas? \n\n The answer is Yes. \n\n The eval and query methods in pandas are implemented based on Numexpr. Let's look at some examples: \n\n### Pandas.eval for Cross-DataFrame operations\n\n When you have multiple pandas DataFrames, you can use pandas.eval to perform operations between DataFrame objects, for example: \n\n    import pandas as pd\n    \n    nrows, ncols = 1_000_000, 100\n    df1, df2, df3, df4 = (pd.DataFrame(rng.random((nrows, ncols))) for i in range(4))\n\n If you calculate the sum of these DataFrames using the traditional pandas method, the time consumed is: \n\n    In:  %timeit df1+df2+df3+df4\n    Out: 1.18 s \u00b1 65.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\n You can also use pandas.eval for calculation. The time consumed is: \n\n The calculation of the eval version can improve performance by 50%, and the results are precisely the same: \n\n    In:  np.allclose(df1+df2+df3+df4, pd.eval('df1+df2+df3+df4'))\n    Out: True\n\n### DataFrame.eval for column-level operations\n\n Just like pandas.eval, DataFrame also has its own eval method. We can use this method for column-level operations within DataFrame, for example: \n\n    df = pd.DataFrame(rng.random((1000, 3)), columns=['A', 'B', 'C'])\n    \n    result1 = (df['A'] + df['B']) / (df['C'] - 1)\n    result2 = df.eval('(A + B) / (C - 1)')\n\n The results of using the traditional pandas method and the eval method are precisely the same: \n\n    In:  np.allclose(result1, result2)\n    Out: True\n\n Of course, you can also directly use the eval expression to add new columns to the DataFrame, which is very convenient: \n\n    df.eval('D = (A + B) / C', inplace=True)\n    df.head()\n\n[ Directly use the eval expression to add new columns. Image by Author ](https://preview.redd.it/ykotgj0ut5qb1.png?width=495&amp;format=png&amp;auto=webp&amp;s=f005b5782e751f2f5ea90fcddd8169cfcc2c5751)\n\n### Using DataFrame.query to quickly find data\n\n If the eval method of DataFrame executes comparison expressions, the returned result is a boolean result that meets the conditions. You need to use Mask Indexing to get the desired data: \n\n    mask = df.eval('(A &lt; 0.5) &amp; (B &lt; 0.5)')\n    result1 = df[mask]\n    result\n\n[ When filtering data only with DataFrame.query, it is necessary to use a boolean mask. Image by Author ](https://preview.redd.it/izwngwizt5qb1.png?width=469&amp;format=png&amp;auto=webp&amp;s=c7f0e4806977ccdcf3c588a67a6c913255f47091)\n\n The DataFrame.query method encapsulates this process, and you can directly obtain the desired data with the query method: \n\n    In:   result2 = df.query('A &lt; 0.5 and B &lt; 0.5')\n          np.allclose(result1, result2)\n    Out:  True\n\n When you need to use scalars in expressions, you can use the @  to indicate: \n\n    In:  Cmean = df['C'].mean()\n         result1 = df[(df.A &lt; Cmean) &amp; (df.B &lt; Cmean)]\n         result2 = df.query('A &lt; @Cmean and B &lt; @Cmean')\n         np.allclose(result1, result2)\n    Out: True\n\n This article was originally published on my personal blog [Data Leads Future.](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/) ", "author_fullname": "t2_9r8ft2a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring Numexpr: A Powerful Engine Behind Pandas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ykotgj0ut5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 39, "x": 108, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=45b2ace70cdc23065c16c4c7ecb49451067d5824"}, {"y": 78, "x": 216, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1ae1f3d972bbe64cc07341d2a7e32e66da793a7f"}, {"y": 115, "x": 320, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=04db3f2e444bdb6b7cb6c9558407dc42561b74f2"}], "s": {"y": 179, "x": 495, "u": "https://preview.redd.it/ykotgj0ut5qb1.png?width=495&amp;format=png&amp;auto=webp&amp;s=f005b5782e751f2f5ea90fcddd8169cfcc2c5751"}, "id": "ykotgj0ut5qb1"}, "izwngwizt5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2dadbb151f50fa5dbfbf14272d1860c079d94f89"}, {"y": 133, "x": 216, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=184931d673c0227709ad80639f3cd20da70977d4"}, {"y": 197, "x": 320, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ce4336dee4ce5c9bbedc261e3a277e72d6fa47e"}], "s": {"y": 289, "x": 469, "u": "https://preview.redd.it/izwngwizt5qb1.png?width=469&amp;format=png&amp;auto=webp&amp;s=c7f0e4806977ccdcf3c588a67a6c913255f47091"}, "id": "izwngwizt5qb1"}, "3k7gdxywr5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 45, "x": 108, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a502f085a43ef5ac8f1f50599161b6d8ccfe1dc5"}, {"y": 91, "x": 216, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fedccce3dc9866fbb52b62237eb1d362917e2eb3"}, {"y": 135, "x": 320, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=77080ec0cc0d4b7202892c1035780ef145694726"}], "s": {"y": 264, "x": 625, "u": "https://preview.redd.it/3k7gdxywr5qb1.png?width=625&amp;format=png&amp;auto=webp&amp;s=5e6a2ed6620cf23638d9c3f20e5f6f46a54e0049"}, "id": "3k7gdxywr5qb1"}, "46plaxk6t5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8d31e4cb8f3f2da53d3c291af37ecc489c082e5d"}, {"y": 152, "x": 216, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b292a546e21eea92bccc123befff21806f751ad"}, {"y": 226, "x": 320, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e63cb3e19ed9c368e8e297b1842854b459247ac6"}, {"y": 453, "x": 640, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=059bc7da3ab967ae8670b846e24da717ccfa6bb0"}], "s": {"y": 611, "x": 863, "u": "https://preview.redd.it/46plaxk6t5qb1.png?width=863&amp;format=png&amp;auto=webp&amp;s=8c0bb7311c4fc743d720c2e0cec3c28c1ff98ed3"}, "id": "46plaxk6t5qb1"}, "29ec8ukgr5qb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 71, "x": 108, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=827a05e29b961a5494a0a7bef09e05406e2e2d0e"}, {"y": 143, "x": 216, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7eda37aee46f7ac0e032a1d6986c84364e634243"}, {"y": 213, "x": 320, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c421de1631ab305d9297cb110c5bc7e6f8fa84ee"}, {"y": 426, "x": 640, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=56aac32c3c80921dcb8d1294b3284c961c3fc4f4"}, {"y": 639, "x": 960, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4bf6231e0d1b715918aa8904b0dc7a8bdae05633"}, {"y": 719, "x": 1080, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a94c2abbd9a3ade8f23648b82905877f75b5bede"}], "s": {"y": 799, "x": 1200, "u": "https://preview.redd.it/29ec8ukgr5qb1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=238da4465da17bd301b49112d574444b16d4113c"}, "id": "29ec8ukgr5qb1"}}, "name": "t3_16qrxs4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ARL0vsBWFf7vstunNTahhEgCBgMGr53RAUJlwDu0dAc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1695542470.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Enhancing your data analysis performance with Python&amp;#39;s Numexpr and Pandas&amp;#39; eval/query functions &lt;/p&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/\"&gt;Data Leads Future.&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/29ec8ukgr5qb1.png?width=1200&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=238da4465da17bd301b49112d574444b16d4113c\"&gt; Use Numexpr to help me find the most livable city. Photo Credit: Created by Author, Canva &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This article will introduce you to the Python library &lt;a href=\"https://numexpr.readthedocs.io/en/latest/intro.html?ref=dataleadsfuture.com#\"&gt;Numexpr&lt;/a&gt;, a tool that boosts the computational performance of Numpy Arrays. The eval and query methods of Pandas are also based on this library.&lt;/p&gt;\n\n&lt;p&gt;This article also includes a hands-on weather data analysis project. &lt;/p&gt;\n\n&lt;p&gt;By reading this article, you will understand the principles of Numexpr and how to use this powerful tool to speed up your calculations in reality. &lt;/p&gt;\n\n&lt;h1&gt;Introduction&lt;/h1&gt;\n\n&lt;h1&gt;Recalling Numpy Arrays&lt;/h1&gt;\n\n&lt;p&gt;In a previous article discussing Numpy Arrays, I used a library example to explain why Numpy&amp;#39;s Cache Locality is so efficient: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/\"&gt;https://www.dataleadsfuture.com/python-lists-vs-numpy-arrays-a-deep-dive-into-memory-layout-and-performance-benefits/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Each time you go to the library to search for materials, you take out a few books related to the content and place them next to your desk. &lt;/p&gt;\n\n&lt;p&gt;This way, you can quickly check related materials without having to run to the shelf each time you need to read a book. &lt;/p&gt;\n\n&lt;p&gt;This method saves a lot of time, especially when you need to consult many related books. &lt;/p&gt;\n\n&lt;p&gt;In this scenario, the shelf is like your memory, the desk is equivalent to the CPU&amp;#39;s L1 cache, and you, the reader, are the CPU&amp;#39;s core. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3k7gdxywr5qb1.png?width=625&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5e6a2ed6620cf23638d9c3f20e5f6f46a54e0049\"&gt; When the CPU accesses RAM, the cache loads the entire cache line into the high-speed cache. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;h3&gt;The limitations of Numpy&lt;/h3&gt;\n\n&lt;p&gt;Suppose you are unfortunate enough to encounter a demanding professor who wants you to take out Shakespeare and Tolstoy&amp;#39;s works for a cross-comparison. &lt;/p&gt;\n\n&lt;p&gt;At this point, taking out related books in advance will not work well. &lt;/p&gt;\n\n&lt;p&gt;First, your desk space is limited and cannot hold all the books of these two masters at the same time, not to mention the reading notes that will be generated during the comparison process. &lt;/p&gt;\n\n&lt;p&gt;Second, you&amp;#39;re just one person, and comparing so many works would take too long. It would be nice if you could find a few more people to help. &lt;/p&gt;\n\n&lt;p&gt;This is the current situation when we use Numpy to deal with large amounts of data: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The number of elements in the Array is too large to fit into the CPU&amp;#39;s L1 cache.&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Numpy&amp;#39;s element-level operations are single-threaded and cannot utilize the computing power of multi-core CPUs.&lt;/p&gt;\n\n&lt;p&gt;What should we do? &lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t worry. When you really encounter a problem with too much data, you can call on our protagonist today, Numexpr, to help. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Understanding Numexpr: What and Why&lt;/h2&gt;\n\n&lt;h3&gt;How it works&lt;/h3&gt;\n\n&lt;p&gt;When Numpy encounters large arrays, element-wise calculations will experience two extremes. &lt;/p&gt;\n\n&lt;p&gt;Let me give you an example to illustrate. Suppose there are two large Numpy ndarrays: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import numpy as np \nimport numexpr as ne  \n\na = np.random.rand(100_000_000) \nb = np.random.rand(100_000_000)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When calculating the result of the expression a**5 + 2 * b, there are generally two methods:&lt;/p&gt;\n\n&lt;p&gt;One way is Numpy&amp;#39;s vectorized calculation method, which uses two temporary arrays to store the results of a**5 and 2*b separately.  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In: %timeit a**5 + 2 * b\n\nOut:2.11 s \u00b1 31.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;At this time, you have four arrays in your memory: a, b, a**5, and 2 * b. This method will cause a lot of memory waste. &lt;/p&gt;\n\n&lt;p&gt;Moreover, since each Array&amp;#39;s size exceeds the CPU cache&amp;#39;s capacity, it cannot use it well. &lt;/p&gt;\n\n&lt;p&gt;Another way is to traverse each element in two arrays and calculate them separately. &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;c = np.empty(100_000_000, dtype=np.uint32)\n\ndef calcu_elements(a, b, c):\n    for i in range(0, len(a), 1):\n        c[i] = a[i] ** 5 + 2 * b[i]\n\n%timeit calcu_elements(a, b, c)\n\n\nOut: 24.6 s \u00b1 48.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This method performs even worse. The calculation will be very slow because it cannot use vectorized calculations and only partially utilize the CPU cache. &lt;/p&gt;\n\n&lt;h3&gt;Numexpr&amp;#39;s calculation&lt;/h3&gt;\n\n&lt;p&gt;Numexpr commonly uses only one evaluate method. This method will receive an expression string each time and then compile it into bytecode using Python&amp;#39;s compile method. &lt;/p&gt;\n\n&lt;p&gt;Numexpr also has a virtual machine program. The virtual machine contains multiple vector registers, each using a chunk size of 4096. &lt;/p&gt;\n\n&lt;p&gt;When Numexpr starts to calculate, it sends the data in one or more registers to the CPU&amp;#39;s L1 cache each time. This way, there won&amp;#39;t be a situation where the memory is too slow, and the CPU waits for data. &lt;/p&gt;\n\n&lt;p&gt;At the same time, Numexpr&amp;#39;s virtual machine is written in C, removing Python&amp;#39;s GIL. It can utilize the computing power of multi-core CPUs. &lt;/p&gt;\n\n&lt;p&gt;So, Numexpr is faster when calculating large arrays than using Numpy alone. We can make a comparison: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  %timeit ne.evaluate(&amp;#39;a**5 + 2 * b&amp;#39;)\nOut: 258 ms \u00b1 14.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h3&gt;Summary of Numexpr&amp;#39;s working principle&lt;/h3&gt;\n\n&lt;p&gt;Let&amp;#39;s summarize the working principle of Numexpr and see why Numexpr is so fast: &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Executing bytecode through a virtual machine.&lt;/strong&gt; Numexpr uses bytecode to execute expressions, which can fully utilize the &lt;a href=\"https://en.wikipedia.org/wiki/Branch_predictor?ref=dataleadsfuture.com\"&gt;branch prediction&lt;/a&gt; ability of the CPU, which is faster than using Python expressions. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Vectorized calculation.&lt;/strong&gt; Numexpr will use &lt;a href=\"https://en.wikipedia.org/wiki/Single_instruction,_multiple_data?ref=dataleadsfuture.com\"&gt;SIMD (Single Instruction, Multiple Data)&lt;/a&gt; technology to improve computing efficiency significantly for the same operation on the data in each register. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Multi-core parallel computing.&lt;/strong&gt; Numexpr&amp;#39;s virtual machine can decompose each task into multiple subtasks. They are executed in parallel on multiple CPU cores. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Less memory usage.&lt;/strong&gt; Unlike Numpy, which needs to generate intermediate arrays, Numexpr only loads a small amount of data when necessary, significantly reducing memory usage. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/46plaxk6t5qb1.png?width=863&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c0bb7311c4fc743d720c2e0cec3c28c1ff98ed3\"&gt; Workflow diagram of Numexpr. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Numexpr and Pandas: A Powerful Combination&lt;/h2&gt;\n\n&lt;p&gt;You might be wondering: We usually do data analysis with pandas. I understand the performance improvements Numexpr offers for Numpy, but does it have the same improvement for Pandas? &lt;/p&gt;\n\n&lt;p&gt;The answer is Yes. &lt;/p&gt;\n\n&lt;p&gt;The eval and query methods in pandas are implemented based on Numexpr. Let&amp;#39;s look at some examples: &lt;/p&gt;\n\n&lt;h3&gt;Pandas.eval for Cross-DataFrame operations&lt;/h3&gt;\n\n&lt;p&gt;When you have multiple pandas DataFrames, you can use pandas.eval to perform operations between DataFrame objects, for example: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pandas as pd\n\nnrows, ncols = 1_000_000, 100\ndf1, df2, df3, df4 = (pd.DataFrame(rng.random((nrows, ncols))) for i in range(4))\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;If you calculate the sum of these DataFrames using the traditional pandas method, the time consumed is: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  %timeit df1+df2+df3+df4\nOut: 1.18 s \u00b1 65.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;You can also use pandas.eval for calculation. The time consumed is: &lt;/p&gt;\n\n&lt;p&gt;The calculation of the eval version can improve performance by 50%, and the results are precisely the same: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  np.allclose(df1+df2+df3+df4, pd.eval(&amp;#39;df1+df2+df3+df4&amp;#39;))\nOut: True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h3&gt;DataFrame.eval for column-level operations&lt;/h3&gt;\n\n&lt;p&gt;Just like pandas.eval, DataFrame also has its own eval method. We can use this method for column-level operations within DataFrame, for example: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df = pd.DataFrame(rng.random((1000, 3)), columns=[&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;])\n\nresult1 = (df[&amp;#39;A&amp;#39;] + df[&amp;#39;B&amp;#39;]) / (df[&amp;#39;C&amp;#39;] - 1)\nresult2 = df.eval(&amp;#39;(A + B) / (C - 1)&amp;#39;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The results of using the traditional pandas method and the eval method are precisely the same: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  np.allclose(result1, result2)\nOut: True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Of course, you can also directly use the eval expression to add new columns to the DataFrame, which is very convenient: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;df.eval(&amp;#39;D = (A + B) / C&amp;#39;, inplace=True)\ndf.head()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ykotgj0ut5qb1.png?width=495&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f005b5782e751f2f5ea90fcddd8169cfcc2c5751\"&gt; Directly use the eval expression to add new columns. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;h3&gt;Using DataFrame.query to quickly find data&lt;/h3&gt;\n\n&lt;p&gt;If the eval method of DataFrame executes comparison expressions, the returned result is a boolean result that meets the conditions. You need to use Mask Indexing to get the desired data: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;mask = df.eval(&amp;#39;(A &amp;lt; 0.5) &amp;amp; (B &amp;lt; 0.5)&amp;#39;)\nresult1 = df[mask]\nresult\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/izwngwizt5qb1.png?width=469&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c7f0e4806977ccdcf3c588a67a6c913255f47091\"&gt; When filtering data only with DataFrame.query, it is necessary to use a boolean mask. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The DataFrame.query method encapsulates this process, and you can directly obtain the desired data with the query method: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:   result2 = df.query(&amp;#39;A &amp;lt; 0.5 and B &amp;lt; 0.5&amp;#39;)\n      np.allclose(result1, result2)\nOut:  True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;When you need to use scalars in expressions, you can use the @  to indicate: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  Cmean = df[&amp;#39;C&amp;#39;].mean()\n     result1 = df[(df.A &amp;lt; Cmean) &amp;amp; (df.B &amp;lt; Cmean)]\n     result2 = df.query(&amp;#39;A &amp;lt; @Cmean and B &amp;lt; @Cmean&amp;#39;)\n     np.allclose(result1, result2)\nOut: True\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/\"&gt;Data Leads Future.&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?auto=webp&amp;s=4f4c5a16af6b6d5e954c2bd0d6ec11d253a3f16f", "width": 1387, "height": 924}, "resolutions": [{"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3216385c481210e323283ae6e03a16e14245f2a1", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a6a3bbf3191c78cddfbd87af49e76d6667ca85fd", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=202ec313e2baa2ef1670e9cfd24d6c2560d1cd21", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ff3e49cdb7d8d0746f47c590240ce1fc893bc917", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=33dc2fd6c45c6a3cc3cbd721fe9ad6a9f5ab7779", "width": 960, "height": 639}, {"url": "https://external-preview.redd.it/TpHbi-LDIBl_Qie2W3bikMNbosa3_mKTOFYTA9OA7TA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bf7b49d72586c5ef89b6b8f7dc0d9c7de09de4b8", "width": 1080, "height": 719}], "variants": {}, "id": "Bjw_Y7mZr_m-tfiX4fEkjjZrKlokqny6OjPxyctYkDg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qrxs4", "is_robot_indexable": true, "report_reasons": null, "author": "qtalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qrxs4/exploring_numexpr_a_powerful_engine_behind_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qrxs4/exploring_numexpr_a_powerful_engine_behind_pandas/", "subreddit_subscribers": 1058788, "created_utc": 1695542470.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI\u2019ve been trying to improve my SQL skills, specifically in writing queries involving joins and subqueries. I\u2019ve gone through several SQL tutorials on YouTube and while I feel like I understand the concepts being taught, I struggle when it comes to applying them in practice.\n\nWhen given a problem, I find it difficult to write the corresponding SQL queries. This has led me to question whether I\u2019ve truly grasped the theoretical and practical aspects of SQL.\n\nHas anyone else experienced this? How did you overcome it? Any advice or resources that could help me bridge this gap between understanding and application would be greatly appreciated.\n\nThank you!", "author_fullname": "t2_k37psi1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Struggling with SQL Queries - Need Advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qplm4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695534149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been trying to improve my SQL skills, specifically in writing queries involving joins and subqueries. I\u2019ve gone through several SQL tutorials on YouTube and while I feel like I understand the concepts being taught, I struggle when it comes to applying them in practice.&lt;/p&gt;\n\n&lt;p&gt;When given a problem, I find it difficult to write the corresponding SQL queries. This has led me to question whether I\u2019ve truly grasped the theoretical and practical aspects of SQL.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else experienced this? How did you overcome it? Any advice or resources that could help me bridge this gap between understanding and application would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qplm4", "is_robot_indexable": true, "report_reasons": null, "author": "PleaseJustStayAlive", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qplm4/struggling_with_sql_queries_need_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qplm4/struggling_with_sql_queries_need_advice/", "subreddit_subscribers": 1058788, "created_utc": 1695534149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, \n\nI have seen some videos on youtube where people talk about their daily work in data science and programming. These videos usually give a general view (for example they say they have daily meeting and code for several hours and so on) and don't give a detailed view. \n\nI am wondering if there is any channel or website about the day to day life of a data scientist at a company. For example, showing how they start with the projects and how they collaborate with others and how they code their solutions...you know, a deeper dive. \n\nI am interested in any recommendation. Thanks", "author_fullname": "t2_kbrpw1ikq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Day to day data science work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16q9s1d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695489057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, &lt;/p&gt;\n\n&lt;p&gt;I have seen some videos on youtube where people talk about their daily work in data science and programming. These videos usually give a general view (for example they say they have daily meeting and code for several hours and so on) and don&amp;#39;t give a detailed view. &lt;/p&gt;\n\n&lt;p&gt;I am wondering if there is any channel or website about the day to day life of a data scientist at a company. For example, showing how they start with the projects and how they collaborate with others and how they code their solutions...you know, a deeper dive. &lt;/p&gt;\n\n&lt;p&gt;I am interested in any recommendation. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16q9s1d", "is_robot_indexable": true, "report_reasons": null, "author": "iamsupercuriouss", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16q9s1d/day_to_day_data_science_work/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16q9s1d/day_to_day_data_science_work/", "subreddit_subscribers": 1058788, "created_utc": 1695489057.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\nI am preparing session about data presentation &amp; visualizations to share with my colleagues, they wanna know what's the best visual to use depending on the data.  \n\n\nI have a visual vocabulary documentation on this but I also wanna show them the visual with test data to be more practical.  \n\n\nI'll be using MS Power BI for visualization.  \n\n\nCan you suggest me good data generator websites that I can use to generate data and import it to Power BI?  \n\n\nThanks!", "author_fullname": "t2_6or8m0hm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Generator Website", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16q63lz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695479721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I am preparing session about data presentation &amp;amp; visualizations to share with my colleagues, they wanna know what&amp;#39;s the best visual to use depending on the data.  &lt;/p&gt;\n\n&lt;p&gt;I have a visual vocabulary documentation on this but I also wanna show them the visual with test data to be more practical.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll be using MS Power BI for visualization.  &lt;/p&gt;\n\n&lt;p&gt;Can you suggest me good data generator websites that I can use to generate data and import it to Power BI?  &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16q63lz", "is_robot_indexable": true, "report_reasons": null, "author": "Judessaa", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16q63lz/data_generator_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16q63lz/data_generator_website/", "subreddit_subscribers": 1058788, "created_utc": 1695479721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi\nI've wrote a CRM for shipyards, and other professionals that do boat maintenance.\n\nEach customer of this software will enter data about work orders, products costs and labour...\nThose data will be tied to boat makes, end customers and so on ...\n\nI'd like to be able to provide some useful data to the shipyards from this data. I'm pretty new to data analysis and don't know of there are tools that can help me to do so ?\nI.e. I can imagine when creating a new work order for some task (let's say an engine periodical maintenance), I could provide historical data about how much time it does take for this kind of task... or even when a special engine is concerned, this one is specifically harder to work with, so the  planned hour count should be higher and so on...\n\nIs there models that could be trained against the customer data to provide those features?\n\nSorry if it's in the wrong place or If my question seems dumb !\n\nThanks", "author_fullname": "t2_u3p6b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing a CRM : how to extract valued data to customers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16qvvl0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695556386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi\nI&amp;#39;ve wrote a CRM for shipyards, and other professionals that do boat maintenance.&lt;/p&gt;\n\n&lt;p&gt;Each customer of this software will enter data about work orders, products costs and labour...\nThose data will be tied to boat makes, end customers and so on ...&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to be able to provide some useful data to the shipyards from this data. I&amp;#39;m pretty new to data analysis and don&amp;#39;t know of there are tools that can help me to do so ?\nI.e. I can imagine when creating a new work order for some task (let&amp;#39;s say an engine periodical maintenance), I could provide historical data about how much time it does take for this kind of task... or even when a special engine is concerned, this one is specifically harder to work with, so the  planned hour count should be higher and so on...&lt;/p&gt;\n\n&lt;p&gt;Is there models that could be trained against the customer data to provide those features?&lt;/p&gt;\n\n&lt;p&gt;Sorry if it&amp;#39;s in the wrong place or If my question seems dumb !&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qvvl0", "is_robot_indexable": true, "report_reasons": null, "author": "Napo7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qvvl0/writing_a_crm_how_to_extract_valued_data_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qvvl0/writing_a_crm_how_to_extract_valued_data_to/", "subreddit_subscribers": 1058788, "created_utc": 1695556386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a geotechnical engineer with 4 years of experience. 6 months ago, I started my transitioning process into data science. So far I have taken some online classes which have awarded me with certificates and I've been working on some projects to build my portfolio.\n\nI have not really started looking into DE career opportunities yet. I want to know how valuable are those online certificates if I want a serious career.", "author_fullname": "t2_jkl5fd1l7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am transitioning from another engineering field to data science. How hard is it to get into the field with only certificates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16qvpli", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695555870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a geotechnical engineer with 4 years of experience. 6 months ago, I started my transitioning process into data science. So far I have taken some online classes which have awarded me with certificates and I&amp;#39;ve been working on some projects to build my portfolio.&lt;/p&gt;\n\n&lt;p&gt;I have not really started looking into DE career opportunities yet. I want to know how valuable are those online certificates if I want a serious career.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qvpli", "is_robot_indexable": true, "report_reasons": null, "author": "Ndanan_Sky_8494", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qvpli/i_am_transitioning_from_another_engineering_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qvpli/i_am_transitioning_from_another_engineering_field/", "subreddit_subscribers": 1058788, "created_utc": 1695555870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys. I am a 24y/o from Mumbai, India. I completed my MSc in Data Science from Mumbai University in 2022 and since then I am working in a reputed organization as a Data Scientist. But I don't want to stop here.\n\nRecently I started searching for MBA courses in India or Europe/US. I was also searching for a masters degree in Computer Vision. And I am just confused. Should I go for an MBA or a computer vision course or a PhD? Can you guys please suggest me what should I do next?\n\nThanks.", "author_fullname": "t2_611b6yuf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please suggest, what should I do next?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qu10o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695550137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys. I am a 24y/o from Mumbai, India. I completed my MSc in Data Science from Mumbai University in 2022 and since then I am working in a reputed organization as a Data Scientist. But I don&amp;#39;t want to stop here.&lt;/p&gt;\n\n&lt;p&gt;Recently I started searching for MBA courses in India or Europe/US. I was also searching for a masters degree in Computer Vision. And I am just confused. Should I go for an MBA or a computer vision course or a PhD? Can you guys please suggest me what should I do next?&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qu10o", "is_robot_indexable": true, "report_reasons": null, "author": "paathyaa", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qu10o/please_suggest_what_should_i_do_next/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qu10o/please_suggest_what_should_i_do_next/", "subreddit_subscribers": 1058788, "created_utc": 1695550137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys are there any good certifications for data science that companies actually take seriously?", "author_fullname": "t2_887w37gq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science certification.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qslw1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695544932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys are there any good certifications for data science that companies actually take seriously?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qslw1", "is_robot_indexable": true, "report_reasons": null, "author": "Expert-Ladder-4211", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qslw1/data_science_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qslw1/data_science_certification/", "subreddit_subscribers": 1058788, "created_utc": 1695544932.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hello everyone I am a sophomore data science student I want to learn data science online for some reason I cant rely on my uni so I am watching lectures on pandas numpy and other stuff but I am confused about practice like how do I practice to get the grasp on the skills and I want to learn statistics too so should I cover whole statistics or are there some specific topics needed for data science \n\nthanks in advance", "author_fullname": "t2_efiv4rbk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qsj8s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695544661.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello everyone I am a sophomore data science student I want to learn data science online for some reason I cant rely on my uni so I am watching lectures on pandas numpy and other stuff but I am confused about practice like how do I practice to get the grasp on the skills and I want to learn statistics too so should I cover whole statistics or are there some specific topics needed for data science &lt;/p&gt;\n\n&lt;p&gt;thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qsj8s", "is_robot_indexable": true, "report_reasons": null, "author": "MNBizBot", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qsj8s/guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qsj8s/guidance/", "subreddit_subscribers": 1058788, "created_utc": 1695544661.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am working on reproducing results claimed by an author in a research paper. \n\nI have followed the same process and have a model training and running.\n\nSo the MAE they claim is 5. And I am able to reproduce 23. \n\nI am a bit new to this, so when talking about reproducing results; how different can they be to say \"reproduce successful\"?", "author_fullname": "t2_123jiosa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Comparing \"claimed\" results vs \"reproduced\" results.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qpup6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695535075.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on reproducing results claimed by an author in a research paper. &lt;/p&gt;\n\n&lt;p&gt;I have followed the same process and have a model training and running.&lt;/p&gt;\n\n&lt;p&gt;So the MAE they claim is 5. And I am able to reproduce 23. &lt;/p&gt;\n\n&lt;p&gt;I am a bit new to this, so when talking about reproducing results; how different can they be to say &amp;quot;reproduce successful&amp;quot;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qpup6", "is_robot_indexable": true, "report_reasons": null, "author": "Dump7", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qpup6/comparing_claimed_results_vs_reproduced_results/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qpup6/comparing_claimed_results_vs_reproduced_results/", "subreddit_subscribers": 1058788, "created_utc": 1695535075.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHi All,\n\nIs there a way to collect real time data regarding Packaged food and its ingredients. I'm currently focussing on Indian packaged foods. Any sugestion would be extemely helpful.\n\nThanks a lot!", "author_fullname": "t2_3dgxudc7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Packaged food related ingredients and its proportions in a dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qo5es", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695529018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;Is there a way to collect real time data regarding Packaged food and its ingredients. I&amp;#39;m currently focussing on Indian packaged foods. Any sugestion would be extemely helpful.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qo5es", "is_robot_indexable": true, "report_reasons": null, "author": "ashnel11", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qo5es/packaged_food_related_ingredients_and_its/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qo5es/packaged_food_related_ingredients_and_its/", "subreddit_subscribers": 1058788, "created_utc": 1695529018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_4j7ujk5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is test-driven development (TDD) relevant f\u00fcr Data Scientists? Do you practice it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16qfb3v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/llaUBH5oayw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Test Driven Development - What? Why? And How?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Test Driven Development - What? Why? And How?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/llaUBH5oayw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Test Driven Development - What? Why? And How?\"&gt;&lt;/iframe&gt;", "author_name": "Continuous Delivery", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/llaUBH5oayw/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ContinuousDelivery"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/llaUBH5oayw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Test Driven Development - What? Why? And How?\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16qfb3v", "height": 200}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XRYVur3ceoJqZRcBZrQLHi9GJm86WzbZO9dsY1-R2uw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695503228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/llaUBH5oayw", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HoXNjjz7w4TFdq1W_52c-_GyTD0PQ-Jb2azx8g4YNCc.jpg?auto=webp&amp;s=4647e0c22fb1d30d0aa25cf3e3dc427ac9e6e8c0", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/HoXNjjz7w4TFdq1W_52c-_GyTD0PQ-Jb2azx8g4YNCc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3cde985a6dada0b59a82ec27ea02a598095b655f", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/HoXNjjz7w4TFdq1W_52c-_GyTD0PQ-Jb2azx8g4YNCc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6c0ccac57b30c0d45a33df9fe3d2f6302e9826c1", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/HoXNjjz7w4TFdq1W_52c-_GyTD0PQ-Jb2azx8g4YNCc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a71ebce287ec6e92f92486fd762fc20cd1339c96", "width": 320, "height": 240}], "variants": {}, "id": "upp6PnY18zvYooOCDWlps7sPKuHvCHAkEeQvb8-cVvo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qfb3v", "is_robot_indexable": true, "report_reasons": null, "author": "norfkens2", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qfb3v/is_testdriven_development_tdd_relevant_f\u00fcr_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/llaUBH5oayw", "subreddit_subscribers": 1058788, "created_utc": 1695503228.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Test Driven Development - What? Why? And How?", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/llaUBH5oayw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Test Driven Development - What? Why? And How?\"&gt;&lt;/iframe&gt;", "author_name": "Continuous Delivery", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/llaUBH5oayw/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ContinuousDelivery"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "at work.", "author_fullname": "t2_12nt66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What pissed you off last week?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16qap3h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.46, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695491385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;at work.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16qap3h", "is_robot_indexable": true, "report_reasons": null, "author": "masc98", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16qap3h/what_pissed_you_off_last_week/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16qap3h/what_pissed_you_off_last_week/", "subreddit_subscribers": 1058788, "created_utc": 1695491385.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}