{"kind": "Listing", "data": {"after": "t3_16udeom", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am always wondering how can a data engineer know, and then convince product team or business that their architecture or design is correct? There is not exactly an exact science to data engineering. There are companies which are happy using out of the box tools and make it work, and there are engineers putting up with complex legacy codebases using microservices et al. Besides reading up and doing courses trying to get as close as possible to best practices, your architecture suggestions are subject to either lessons learnt from experience (takes 1-2 years for a big data project to take real shape) or googling and doing the best possible back of the envelope tradeoffs. While other non technical team members expect you to give them a silver bullet or quickly lose trust in you. How do you establish this confidence in a solution without seeming like a tinkerer?", "author_fullname": "t2_rov69023", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you \"know\" your architecture is correct?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16u1sxr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695862478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am always wondering how can a data engineer know, and then convince product team or business that their architecture or design is correct? There is not exactly an exact science to data engineering. There are companies which are happy using out of the box tools and make it work, and there are engineers putting up with complex legacy codebases using microservices et al. Besides reading up and doing courses trying to get as close as possible to best practices, your architecture suggestions are subject to either lessons learnt from experience (takes 1-2 years for a big data project to take real shape) or googling and doing the best possible back of the envelope tradeoffs. While other non technical team members expect you to give them a silver bullet or quickly lose trust in you. How do you establish this confidence in a solution without seeming like a tinkerer?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16u1sxr", "is_robot_indexable": true, "report_reasons": null, "author": "CutSubstantial7320", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16u1sxr/how_do_you_know_your_architecture_is_correct/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16u1sxr/how_do_you_know_your_architecture_is_correct/", "subreddit_subscribers": 130850, "created_utc": 1695862478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most of us would have observed recently that the companies are moving to cloud for data engineering. Be it Azure,  gcp AWS or databricks cloud, they provide managed cluster platforms.Since they are making the data engineers life easier by integrating job optimisation tools,  managed airflow, orchestrationservices, CI CD and what not.  But when it comes to on-premise, currently most of these are being manage by data engineers and some intermediate level coding is required.\nI would like to understand from the experienced data engineers in this group is --  in a few years down the lene, say 5 years, the dependency on data engineers will decrease for the type tasks mentioned above ?\nOf course, data engineers would be doing ETL by writing python sql scripts and that is not going to go away but if we keep this part side, what is the future of the rest of the tasks?\n I think there are some big organisations trying to move to the cloud and in the near future, they would need tremendous support from the data engineers and this theerw would be a high demand in the short run.\n\nThanks.", "author_fullname": "t2_b8ynqpo5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scope of Data Engineering in future", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16tnvsu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695829199.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most of us would have observed recently that the companies are moving to cloud for data engineering. Be it Azure,  gcp AWS or databricks cloud, they provide managed cluster platforms.Since they are making the data engineers life easier by integrating job optimisation tools,  managed airflow, orchestrationservices, CI CD and what not.  But when it comes to on-premise, currently most of these are being manage by data engineers and some intermediate level coding is required.\nI would like to understand from the experienced data engineers in this group is --  in a few years down the lene, say 5 years, the dependency on data engineers will decrease for the type tasks mentioned above ?\nOf course, data engineers would be doing ETL by writing python sql scripts and that is not going to go away but if we keep this part side, what is the future of the rest of the tasks?\n I think there are some big organisations trying to move to the cloud and in the near future, they would need tremendous support from the data engineers and this theerw would be a high demand in the short run.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16tnvsu", "is_robot_indexable": true, "report_reasons": null, "author": "ajeetyadav_", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16tnvsu/scope_of_data_engineering_in_future/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16tnvsu/scope_of_data_engineering_in_future/", "subreddit_subscribers": 130850, "created_utc": 1695829199.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good afternoon readers,\n\nWant to keep this to the point as this is a longer post so I am going to jump right in to my situation. I recently signed at a large consulting firm as a Jr. DE (perfect for me, very exiting) but my current scope of responsibility seems way over my head, maybe I had a mistach in expectations I am unsure.  \n\n\nTo get directly to the ask, our team has a Tableau enviroment that various users have eyes on. The data sources are populated from various parts of the Navy (my client). Currently, roughly 40 different excel files are used to refresh data sources and it is a completely manual process. In other words, user goes to website, user downloads more recent data, user transforms said data manually, user refreshes data source on our Tableau server. This process is repeated more or less from varoius stakeholders and many web portals.\n\nSo far, to me everything makes sense, the ask is to build a database and streamline the data management process (build data pipeline). I would say I am strong but no expert in SQL but so far within my means. Two major problems exists.\n\n**Problem 1: Moving Data from SQL to Tableau Server**\n\nSince this work is done in a secure space, Tableau does not support the functionality of connecting directly to our database (a pSQL enviroment). I have gotten Tableau techs on the phone and asked them directly, a direct connection between these two services simply cannot be done in a secure enviroment. I have also had discussions with our cloud dev team and managers and asked them how to streamline this data, they are not helpful.  More recently, I have been poking around with the Tableau Rest API. However the only data sources it can ingest are tableau files (.tds, .tde, .pbix). So I am unsure if it is possible to export data from SQL and manage that conversion.\n\nSo I am essentially at a stand still, I do not see a way to move data from my pSQL enviroment to Tableau server. This essentially makes the ask impossible, but maybe I am just young and naive. My intuition tells me surely there is a way to integrate these two programs, but I see none. Thoughts here are greatly appreicated.\n\n**Problem 2: Data Ingestion**\n\nThis is a much smaller problem for me and advise on problem 1 is more impactful, but I figure since I am posting to put this out there. I am unsure how to ingest data to a SQL enviroment. Our cloud leads tell me a transition to Azure pSQL is happening soon, so I am guessing there is some type of UI tool that I can instruct users to 'drop' excel files that I can write code against to transform/write to our SQL enviroment. But this is a guess and ideas on data ingestion would be great.\n\nI have previously tried tried to ask the owners of the raw data sources that our users are pulling data from to see if they have an API or if I can integrate with their backend, I am just left on read. \n\n**Carreer**\n\nI just do not know what to tell my manager, he wants updates and everything I explore to solve these problems leads nowhere. It feels like I am on the wrong project and that not much more optimization can be done. But I want to leave it to the experts that I am sure exists on this sub.\n\nAm I perhaps in over my head as far as problem solving/skill level? I was hoping my first gig I would have an architecture already in place that I could develop/expand on, but perhaps that expecation is wrong. \n\nShould I tell my managers I do not love this contract? This feels bad as a Jr. I want to prove myself, not fun away from the first gig they trusted me with.\n\n&amp;#x200B;\n\nMuch love to any and all readers and I appreicate your thoughts in advance.\n\nSigned,  \nA Jr. DE in need\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_2saw9ds3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jr. Data Engineer who is in over his head, looking for advice from more senior members.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16tv2io", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695846453.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good afternoon readers,&lt;/p&gt;\n\n&lt;p&gt;Want to keep this to the point as this is a longer post so I am going to jump right in to my situation. I recently signed at a large consulting firm as a Jr. DE (perfect for me, very exiting) but my current scope of responsibility seems way over my head, maybe I had a mistach in expectations I am unsure.  &lt;/p&gt;\n\n&lt;p&gt;To get directly to the ask, our team has a Tableau enviroment that various users have eyes on. The data sources are populated from various parts of the Navy (my client). Currently, roughly 40 different excel files are used to refresh data sources and it is a completely manual process. In other words, user goes to website, user downloads more recent data, user transforms said data manually, user refreshes data source on our Tableau server. This process is repeated more or less from varoius stakeholders and many web portals.&lt;/p&gt;\n\n&lt;p&gt;So far, to me everything makes sense, the ask is to build a database and streamline the data management process (build data pipeline). I would say I am strong but no expert in SQL but so far within my means. Two major problems exists.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem 1: Moving Data from SQL to Tableau Server&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Since this work is done in a secure space, Tableau does not support the functionality of connecting directly to our database (a pSQL enviroment). I have gotten Tableau techs on the phone and asked them directly, a direct connection between these two services simply cannot be done in a secure enviroment. I have also had discussions with our cloud dev team and managers and asked them how to streamline this data, they are not helpful.  More recently, I have been poking around with the Tableau Rest API. However the only data sources it can ingest are tableau files (.tds, .tde, .pbix). So I am unsure if it is possible to export data from SQL and manage that conversion.&lt;/p&gt;\n\n&lt;p&gt;So I am essentially at a stand still, I do not see a way to move data from my pSQL enviroment to Tableau server. This essentially makes the ask impossible, but maybe I am just young and naive. My intuition tells me surely there is a way to integrate these two programs, but I see none. Thoughts here are greatly appreicated.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problem 2: Data Ingestion&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;This is a much smaller problem for me and advise on problem 1 is more impactful, but I figure since I am posting to put this out there. I am unsure how to ingest data to a SQL enviroment. Our cloud leads tell me a transition to Azure pSQL is happening soon, so I am guessing there is some type of UI tool that I can instruct users to &amp;#39;drop&amp;#39; excel files that I can write code against to transform/write to our SQL enviroment. But this is a guess and ideas on data ingestion would be great.&lt;/p&gt;\n\n&lt;p&gt;I have previously tried tried to ask the owners of the raw data sources that our users are pulling data from to see if they have an API or if I can integrate with their backend, I am just left on read. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Carreer&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I just do not know what to tell my manager, he wants updates and everything I explore to solve these problems leads nowhere. It feels like I am on the wrong project and that not much more optimization can be done. But I want to leave it to the experts that I am sure exists on this sub.&lt;/p&gt;\n\n&lt;p&gt;Am I perhaps in over my head as far as problem solving/skill level? I was hoping my first gig I would have an architecture already in place that I could develop/expand on, but perhaps that expecation is wrong. &lt;/p&gt;\n\n&lt;p&gt;Should I tell my managers I do not love this contract? This feels bad as a Jr. I want to prove myself, not fun away from the first gig they trusted me with.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Much love to any and all readers and I appreicate your thoughts in advance.&lt;/p&gt;\n\n&lt;p&gt;Signed,&lt;br/&gt;\nA Jr. DE in need&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16tv2io", "is_robot_indexable": true, "report_reasons": null, "author": "likely-", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16tv2io/jr_data_engineer_who_is_in_over_his_head_looking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16tv2io/jr_data_engineer_who_is_in_over_his_head_looking/", "subreddit_subscribers": 130850, "created_utc": 1695846453.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working as data modeller for 2 yrs. It's my first job. My work is to data model for the data coming into datalake ( for migration and new ). I am not sure if I can make this as my career. Does big data data modelling have future ? Or should I have to search jobs in coding ? ( I like coding and have intermediate knowledge in python, c and begginer in Java)\n\nAny input would be appreciated \ud83d\ude2d as I don't have any senior mentor for me. I don't know if I am doing it right.", "author_fullname": "t2_77h4mj8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does data modelling have a future ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ubs3r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695895165.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working as data modeller for 2 yrs. It&amp;#39;s my first job. My work is to data model for the data coming into datalake ( for migration and new ). I am not sure if I can make this as my career. Does big data data modelling have future ? Or should I have to search jobs in coding ? ( I like coding and have intermediate knowledge in python, c and begginer in Java)&lt;/p&gt;\n\n&lt;p&gt;Any input would be appreciated \ud83d\ude2d as I don&amp;#39;t have any senior mentor for me. I don&amp;#39;t know if I am doing it right.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ubs3r", "is_robot_indexable": true, "report_reasons": null, "author": "Traditional_Trash_69", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ubs3r/does_data_modelling_have_a_future/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ubs3r/does_data_modelling_have_a_future/", "subreddit_subscribers": 130850, "created_utc": 1695895165.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At work, we work with a very  bureaucratic organization that provides data to us only in the form of scheduled emails with spreadsheets in a zip file. Attempting to convince them to connect to an API is futile. \n\nAnyways, I used python to collect all the outlook attachments, load the zipped files as temp files, read the data into data frames and push to our server database. it\u2019s janky as hell and relies on the most insecure method of data transfer(email) , but it works dammit!\n\nAnyone else put up with some seriously janky data engineering? Be honest. I cannot be the only one.", "author_fullname": "t2_6hsp2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Extremely Janky Data Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ty7xj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695853609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At work, we work with a very  bureaucratic organization that provides data to us only in the form of scheduled emails with spreadsheets in a zip file. Attempting to convince them to connect to an API is futile. &lt;/p&gt;\n\n&lt;p&gt;Anyways, I used python to collect all the outlook attachments, load the zipped files as temp files, read the data into data frames and push to our server database. it\u2019s janky as hell and relies on the most insecure method of data transfer(email) , but it works dammit!&lt;/p&gt;\n\n&lt;p&gt;Anyone else put up with some seriously janky data engineering? Be honest. I cannot be the only one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ty7xj", "is_robot_indexable": true, "report_reasons": null, "author": "suitupyo", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ty7xj/extremely_janky_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ty7xj/extremely_janky_data_pipeline/", "subreddit_subscribers": 130850, "created_utc": 1695853609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have lots of data generated by source systems that don't have their own backend OLTP database, they just push flat files out. These are easy to consume into delta tables. Delta Lake and the lake house are new territory and even the sales engineers we've been talking to from databricks have seemed a bit non-committal iffy/squirmy when I ask them about referential constraints. I know delta lake doesn't have physically enforced constraints. I assumed they just had high performance multi-step wrappers that effectively do the same thing. I'd like to NOT have to develop that myself, I'd rather just use an OLTP in that situation\n\nMy question for the community is, has anyone used the databricks implementation of ['referential' constraints](https://docs.databricks.com/en/tables/constraints.html) extensively? What were the major challenges/issues? How much custom hacking was it?\n\nOur use cases aren't very complicated. In most cases we're just bulk adding data to tables, and sometimes bulk overwriting. Tables have relations to other tables based on keys. But we don't have any situations like delete or update record from table A and then cascade that to other downstream tables etc. ", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake 'Referential' Constraints", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ttgcz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695842702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have lots of data generated by source systems that don&amp;#39;t have their own backend OLTP database, they just push flat files out. These are easy to consume into delta tables. Delta Lake and the lake house are new territory and even the sales engineers we&amp;#39;ve been talking to from databricks have seemed a bit non-committal iffy/squirmy when I ask them about referential constraints. I know delta lake doesn&amp;#39;t have physically enforced constraints. I assumed they just had high performance multi-step wrappers that effectively do the same thing. I&amp;#39;d like to NOT have to develop that myself, I&amp;#39;d rather just use an OLTP in that situation&lt;/p&gt;\n\n&lt;p&gt;My question for the community is, has anyone used the databricks implementation of &lt;a href=\"https://docs.databricks.com/en/tables/constraints.html\"&gt;&amp;#39;referential&amp;#39; constraints&lt;/a&gt; extensively? What were the major challenges/issues? How much custom hacking was it?&lt;/p&gt;\n\n&lt;p&gt;Our use cases aren&amp;#39;t very complicated. In most cases we&amp;#39;re just bulk adding data to tables, and sometimes bulk overwriting. Tables have relations to other tables based on keys. But we don&amp;#39;t have any situations like delete or update record from table A and then cascade that to other downstream tables etc. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?auto=webp&amp;s=9dd59568b8579947f05ce66ee028655ef14e64d6", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99613d282007d0bcc41947bc7f0846da94adca04", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=400ef45c57444e53fb95c1358e9a0b6419c3112e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ed83d9a6c1afb35b8be4de3f85b722298d1c3d6", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=768e111879e31b88e5a61b81d8d367edaa5e5351", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2a359111feb6e4d3ffa529f6614614a63914c4e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f6e5d40f18830851f93eb2158f465da573a5df80", "width": 1080, "height": 567}], "variants": {}, "id": "RDPFo3n-9ZSpTUT0k9sCNnHc7tSD0wBu2TyDFfITIDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ttgcz", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ttgcz/delta_lake_referential_constraints/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ttgcz/delta_lake_referential_constraints/", "subreddit_subscribers": 130850, "created_utc": 1695842702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company ingests events from IoT devices and provides services based on these data.\n\nHistorical events are stored in the cloud as Parquet files, and usually queried with Spark for one-time analyses, ETLs, dashboards etc.\n\nParquet files are currently partitioned by event date, and this is very convenient for most use-cases. But for others, it would be optimal if data were partitioned by device ID. \n\nDo I need to create two separate Parquet datasets, \"events\\_by\\_date\" and  \"events\\_by\\_deviceID\" to handle this? Are there any tools, databases, or file formats that can handle automatically the fact that I need to have multiple \"indexes\" in my big data?\n\nThanks", "author_fullname": "t2_eu3nz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best tool for \"indexing\" big data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ubawx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695893406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company ingests events from IoT devices and provides services based on these data.&lt;/p&gt;\n\n&lt;p&gt;Historical events are stored in the cloud as Parquet files, and usually queried with Spark for one-time analyses, ETLs, dashboards etc.&lt;/p&gt;\n\n&lt;p&gt;Parquet files are currently partitioned by event date, and this is very convenient for most use-cases. But for others, it would be optimal if data were partitioned by device ID. &lt;/p&gt;\n\n&lt;p&gt;Do I need to create two separate Parquet datasets, &amp;quot;events_by_date&amp;quot; and  &amp;quot;events_by_deviceID&amp;quot; to handle this? Are there any tools, databases, or file formats that can handle automatically the fact that I need to have multiple &amp;quot;indexes&amp;quot; in my big data?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ubawx", "is_robot_indexable": true, "report_reasons": null, "author": "valhallavagen", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ubawx/best_tool_for_indexing_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ubawx/best_tool_for_indexing_big_data/", "subreddit_subscribers": 130850, "created_utc": 1695893406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If I am trying to standardize KPIs for the company, what layer should they be in? I want to build a core dimensional model that can support many use cases. Should I build a generic dimensional model then create a reporting table/view that will store all the KPIs based on the fact tables? Like marketing KPI view and finance KPI view.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fact Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16to8b0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695830029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I am trying to standardize KPIs for the company, what layer should they be in? I want to build a core dimensional model that can support many use cases. Should I build a generic dimensional model then create a reporting table/view that will store all the KPIs based on the fact tables? Like marketing KPI view and finance KPI view.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16to8b0", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16to8b0/fact_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16to8b0/fact_tables/", "subreddit_subscribers": 130850, "created_utc": 1695830029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, excited to announce the addition of image embeddings for semantic similarity search to VectorFlow, the only high volume open source embedding pipeline. Now you can embed a high volume of images quickly with minimal effort and search them using Vectorflow. This will empower a wide range of applications, from e-commerce product searches to manufacturing defect detection.\n\nWe built this to support multi-modal AI applications, since LLMs don\u2019t exist in a vacuum.\n\nIf you are thinking about adding images to your LLM workflows or computer vision systems, we would love to hear from you to learn more about the problems you are facing and see if VectorFlow can help!\n\nCheck out our Open Source repo - [https://github.com/dgarnitz/vectorflow](https://github.com/dgarnitz/vectorflow)", "author_fullname": "t2_8dgpjm0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi-Modal Vector Embeddings at Scale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16u02q5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695858046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, excited to announce the addition of image embeddings for semantic similarity search to VectorFlow, the only high volume open source embedding pipeline. Now you can embed a high volume of images quickly with minimal effort and search them using Vectorflow. This will empower a wide range of applications, from e-commerce product searches to manufacturing defect detection.&lt;/p&gt;\n\n&lt;p&gt;We built this to support multi-modal AI applications, since LLMs don\u2019t exist in a vacuum.&lt;/p&gt;\n\n&lt;p&gt;If you are thinking about adding images to your LLM workflows or computer vision systems, we would love to hear from you to learn more about the problems you are facing and see if VectorFlow can help!&lt;/p&gt;\n\n&lt;p&gt;Check out our Open Source repo - &lt;a href=\"https://github.com/dgarnitz/vectorflow\"&gt;https://github.com/dgarnitz/vectorflow&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gz9goWfmEhaWr8H0ySdzVZ1JGlfab0iYbz0wgLupVr4.jpg?auto=webp&amp;s=a3924c1e78e3388c312311040c0d9588a49a552b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/gz9goWfmEhaWr8H0ySdzVZ1JGlfab0iYbz0wgLupVr4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=12668e0c9df66f8a4e36e1bbfdaae95629eb179c", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/gz9goWfmEhaWr8H0ySdzVZ1JGlfab0iYbz0wgLupVr4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=79cebafd5274a4a70f307a69d343a88277af0b4f", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/gz9goWfmEhaWr8H0ySdzVZ1JGlfab0iYbz0wgLupVr4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=90beff0d5c6b0de9c63582a34fd72a5fab7c586c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/gz9goWfmEhaWr8H0ySdzVZ1JGlfab0iYbz0wgLupVr4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f64b2da41f1bb0ee7bb7fbfee9000c3c48704020", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/gz9goWfmEhaWr8H0ySdzVZ1JGlfab0iYbz0wgLupVr4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4d4740a2e00b09c07c401ed0e0538edda00fecb7", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/gz9goWfmEhaWr8H0ySdzVZ1JGlfab0iYbz0wgLupVr4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6b2dedbc6df54bef7cca1234f1c8452b207e0420", "width": 1080, "height": 540}], "variants": {}, "id": "ihzaBOYBFOFvmz1TpFTKGK5GDTWIxDqGf83GqYavM9o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16u02q5", "is_robot_indexable": true, "report_reasons": null, "author": "Fast_Homework_3323", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16u02q5/multimodal_vector_embeddings_at_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16u02q5/multimodal_vector_embeddings_at_scale/", "subreddit_subscribers": 130850, "created_utc": 1695858046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI've been working on integrating DVC in our toolchain for a while now. But I've to say I find its flow to be a bit...bizzare.\n\n* Many of the researchers I work with are not fluent in git operation\n* Most of the commands feels redundant: I still forget steps from time to time\n* It really feels that there is an easier solution for that, probably not dependant on git\n\nI am working on building an alternative for it, but I am curious on:\n\n1. Do you use DVC? what is your experience with it so far?\n2. If not, what are you using?\n3. Are you even using data versioning in the first place? :D (there is a small part of my brain which questions the need for it)\n\n&amp;#x200B;\n\nDisclaimer: [original post appeared here](https://www.reddit.com/r/mlops/comments/16u7o2w/data_versioning_what_is_out_there/), but it seems the community is small there", "author_fullname": "t2_hwd3b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data versioning: what is out there?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16uh7bt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695910513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working on integrating DVC in our toolchain for a while now. But I&amp;#39;ve to say I find its flow to be a bit...bizzare.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Many of the researchers I work with are not fluent in git operation&lt;/li&gt;\n&lt;li&gt;Most of the commands feels redundant: I still forget steps from time to time&lt;/li&gt;\n&lt;li&gt;It really feels that there is an easier solution for that, probably not dependant on git&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am working on building an alternative for it, but I am curious on:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do you use DVC? what is your experience with it so far?&lt;/li&gt;\n&lt;li&gt;If not, what are you using?&lt;/li&gt;\n&lt;li&gt;Are you even using data versioning in the first place? :D (there is a small part of my brain which questions the need for it)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: &lt;a href=\"https://www.reddit.com/r/mlops/comments/16u7o2w/data_versioning_what_is_out_there/\"&gt;original post appeared here&lt;/a&gt;, but it seems the community is small there&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16uh7bt", "is_robot_indexable": true, "report_reasons": null, "author": "osm3000", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16uh7bt/data_versioning_what_is_out_there/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16uh7bt/data_versioning_what_is_out_there/", "subreddit_subscribers": 130850, "created_utc": 1695910513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_1bnhotlu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Jobs for Beginners to Consider", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16u9hih", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1695886306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kanger.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://kanger.dev/article/data-engineering-jobs", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16u9hih", "is_robot_indexable": true, "report_reasons": null, "author": "skj8", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16u9hih/data_engineering_jobs_for_beginners_to_consider/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://kanger.dev/article/data-engineering-jobs", "subreddit_subscribers": 130850, "created_utc": 1695886306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u9bnox3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Top 4 Azure Resources for Data Engineers to Master. Do you agree with my list or would you pick some other 4 resources?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16u8a37", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/GMBM-c9FfSA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Top Azure Resources for Data Engineers to Learn in 2023\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Top Azure Resources for Data Engineers to Learn in 2023", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/GMBM-c9FfSA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Top Azure Resources for Data Engineers to Learn in 2023\"&gt;&lt;/iframe&gt;", "author_name": "Aleksi Partanen Tech", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/GMBM-c9FfSA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@AleksiPartanenTech"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/GMBM-c9FfSA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Top Azure Resources for Data Engineers to Learn in 2023\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16u8a37", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4JcGEhs_g5syE_HM8RaqbbtxrrpIJeXFLKdVcRxpnfM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695881871.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/GMBM-c9FfSA", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/d5tVau_NnDZ7IhoDbHhelEiEFavU3ITY5OfMn1fUEwg.jpg?auto=webp&amp;s=c554e77e892e0443f2789053e0087284ba58b0ea", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/d5tVau_NnDZ7IhoDbHhelEiEFavU3ITY5OfMn1fUEwg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=97e312b8583385d1c14929870c762ab059adbca3", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/d5tVau_NnDZ7IhoDbHhelEiEFavU3ITY5OfMn1fUEwg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9de8e14f244cf0442bd3f7e58472d5e958afc899", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/d5tVau_NnDZ7IhoDbHhelEiEFavU3ITY5OfMn1fUEwg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3bac270d924d82029c26ec59c02276647b835687", "width": 320, "height": 240}], "variants": {}, "id": "43a7JKCAJFBJK7EmStSKeNTYXolETs3giYGYOKhj9Ec"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16u8a37", "is_robot_indexable": true, "report_reasons": null, "author": "aleks1ck", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16u8a37/top_4_azure_resources_for_data_engineers_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/GMBM-c9FfSA", "subreddit_subscribers": 130850, "created_utc": 1695881871.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Top Azure Resources for Data Engineers to Learn in 2023", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/GMBM-c9FfSA?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Top Azure Resources for Data Engineers to Learn in 2023\"&gt;&lt;/iframe&gt;", "author_name": "Aleksi Partanen Tech", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/GMBM-c9FfSA/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@AleksiPartanenTech"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This will be my first job as a DE (I am a data scientist specialized in the retail industry with extensive training in warehouse and ETL).\n\nThe position is security-oriented for a fintech. I don't have much info but I think they seek to comply with certain legal regulations that require deleting information from time to time as well as minimizing the risk due to PII (personally identifiable information).\n\nAny advice would be greatly appreciated.", "author_fullname": "t2_802hx5xi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice from data engineers specialized in security", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16u02bl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695858020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This will be my first job as a DE (I am a data scientist specialized in the retail industry with extensive training in warehouse and ETL).&lt;/p&gt;\n\n&lt;p&gt;The position is security-oriented for a fintech. I don&amp;#39;t have much info but I think they seek to comply with certain legal regulations that require deleting information from time to time as well as minimizing the risk due to PII (personally identifiable information).&lt;/p&gt;\n\n&lt;p&gt;Any advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16u02bl", "is_robot_indexable": true, "report_reasons": null, "author": "NationOfSheeps", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16u02bl/advice_from_data_engineers_specialized_in_security/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16u02bl/advice_from_data_engineers_specialized_in_security/", "subreddit_subscribers": 130850, "created_utc": 1695858020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am currently trying to decide if I should accept an offer that I received from my summer internship. \n\nDuring my internship, I was hired as a data engineer intern (I was specifically looking for data engineering internship as it is a field that I'm passionate about want to get into). The company where I worked is a public, global software company. I have BS in CS degree in T20 CS schools in US, as well as 4 YOE software engineering experiences, and currently pursuing MS in Data Analysis in T5 CS school - with a goal of becoming a data engineer. \n\nOnce I started my internship, I was assigned to a Business Intelligence team, and was assigned to work on dashboarding works (GCP, Looker etc). I didn't get a chance to work on data pipelinining or ingestion. I was confused but did my best to do the best I can - which I received good feedback and that turned into a full time offer to join the team. During my internship my manager also made sure with me to talk to some of the senior DEs in my team so that I can gain some insights, but the amount of technical work that I did was pretty minimal (intermediate-advanced level SQL for maintaining the data model). \n\nThe offer turned out I'll be mostly continuing the dashboarding work and sounds like the team is right now in need of me to fully devote to the data visualization projects (and also added that the current DE team is very full). In addition, the location that they're able to offer is not ideal for me as the heat in TX caused me skin rashes and overall my mood was significantly affected. \n\nMy manager left the team after my internship and the new manager seems like would prefer me to be a fully BI Developer for dashboards. I really liked working with my manager which was honestly a big factor for me to even consider BI role so I am pretty sad about it as well. \n\nI'm not sure if it is wise for me to take the offer given that 1) I'll be mostly working as a BI Developer (not able to actively develop my SWE skills / CS degree) / 2) at a location that I had such a hard time adjusting to. \n\nMy career goal is to get into data engineering and to develop my technical skills. I don't mind getting more business related works, however, the team seems to be not willing to let me explore DE works at this point. \n\nAm I getting too picky on my choice given this market? However, I am afraid this will make it even harder to advance into DE roles in the future. \n\nAny suggestions or guidance would be really appreciated!", "author_fullname": "t2_l0szgqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this job offer OK?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16tx26a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695864787.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695851034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am currently trying to decide if I should accept an offer that I received from my summer internship. &lt;/p&gt;\n\n&lt;p&gt;During my internship, I was hired as a data engineer intern (I was specifically looking for data engineering internship as it is a field that I&amp;#39;m passionate about want to get into). The company where I worked is a public, global software company. I have BS in CS degree in T20 CS schools in US, as well as 4 YOE software engineering experiences, and currently pursuing MS in Data Analysis in T5 CS school - with a goal of becoming a data engineer. &lt;/p&gt;\n\n&lt;p&gt;Once I started my internship, I was assigned to a Business Intelligence team, and was assigned to work on dashboarding works (GCP, Looker etc). I didn&amp;#39;t get a chance to work on data pipelinining or ingestion. I was confused but did my best to do the best I can - which I received good feedback and that turned into a full time offer to join the team. During my internship my manager also made sure with me to talk to some of the senior DEs in my team so that I can gain some insights, but the amount of technical work that I did was pretty minimal (intermediate-advanced level SQL for maintaining the data model). &lt;/p&gt;\n\n&lt;p&gt;The offer turned out I&amp;#39;ll be mostly continuing the dashboarding work and sounds like the team is right now in need of me to fully devote to the data visualization projects (and also added that the current DE team is very full). In addition, the location that they&amp;#39;re able to offer is not ideal for me as the heat in TX caused me skin rashes and overall my mood was significantly affected. &lt;/p&gt;\n\n&lt;p&gt;My manager left the team after my internship and the new manager seems like would prefer me to be a fully BI Developer for dashboards. I really liked working with my manager which was honestly a big factor for me to even consider BI role so I am pretty sad about it as well. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if it is wise for me to take the offer given that 1) I&amp;#39;ll be mostly working as a BI Developer (not able to actively develop my SWE skills / CS degree) / 2) at a location that I had such a hard time adjusting to. &lt;/p&gt;\n\n&lt;p&gt;My career goal is to get into data engineering and to develop my technical skills. I don&amp;#39;t mind getting more business related works, however, the team seems to be not willing to let me explore DE works at this point. &lt;/p&gt;\n\n&lt;p&gt;Am I getting too picky on my choice given this market? However, I am afraid this will make it even harder to advance into DE roles in the future. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions or guidance would be really appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16tx26a", "is_robot_indexable": true, "report_reasons": null, "author": "PythonIsGreat", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16tx26a/is_this_job_offer_ok/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16tx26a/is_this_job_offer_ok/", "subreddit_subscribers": 130850, "created_utc": 1695851034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have lots of data generated by source systems that don't have their own backend OLTP database, they just push flat files out. These are easy to consume into delta tables. Delta Lake and the lake house are new territory and even the sales engineers we've been talking to from databricks have seemed a bit non-committal iffy/squirmy when I ask them about referential constraints. I know delta lake doesn't have physically enforced constraints. I assumed they just had high performance multi-step wrappers that effectively do the same thing. I'd like to NOT have to develop that myself, I'd rather just use an OLTP in that situation\n\nMy question for the community is, has anyone used the databricks implementation of ['referential' constraints](https://docs.databricks.com/en/tables/constraints.html) extensively? What were the major challenges/issues? How much custom hacking was it?\n\nOur use cases aren't very complicated. In most cases we're just bulk adding data to tables, and sometimes bulk overwriting. Tables have relations to other tables based on keys. But we don't have any situations like delete or update record from table A and then cascade that to other downstream tables etc. ", "author_fullname": "t2_r8dyi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake 'Referential' Constraints", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ttg92", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695842695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have lots of data generated by source systems that don&amp;#39;t have their own backend OLTP database, they just push flat files out. These are easy to consume into delta tables. Delta Lake and the lake house are new territory and even the sales engineers we&amp;#39;ve been talking to from databricks have seemed a bit non-committal iffy/squirmy when I ask them about referential constraints. I know delta lake doesn&amp;#39;t have physically enforced constraints. I assumed they just had high performance multi-step wrappers that effectively do the same thing. I&amp;#39;d like to NOT have to develop that myself, I&amp;#39;d rather just use an OLTP in that situation&lt;/p&gt;\n\n&lt;p&gt;My question for the community is, has anyone used the databricks implementation of &lt;a href=\"https://docs.databricks.com/en/tables/constraints.html\"&gt;&amp;#39;referential&amp;#39; constraints&lt;/a&gt; extensively? What were the major challenges/issues? How much custom hacking was it?&lt;/p&gt;\n\n&lt;p&gt;Our use cases aren&amp;#39;t very complicated. In most cases we&amp;#39;re just bulk adding data to tables, and sometimes bulk overwriting. Tables have relations to other tables based on keys. But we don&amp;#39;t have any situations like delete or update record from table A and then cascade that to other downstream tables etc. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?auto=webp&amp;s=9dd59568b8579947f05ce66ee028655ef14e64d6", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99613d282007d0bcc41947bc7f0846da94adca04", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=400ef45c57444e53fb95c1358e9a0b6419c3112e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ed83d9a6c1afb35b8be4de3f85b722298d1c3d6", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=768e111879e31b88e5a61b81d8d367edaa5e5351", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2a359111feb6e4d3ffa529f6614614a63914c4e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f6e5d40f18830851f93eb2158f465da573a5df80", "width": 1080, "height": 567}], "variants": {}, "id": "RDPFo3n-9ZSpTUT0k9sCNnHc7tSD0wBu2TyDFfITIDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ttg92", "is_robot_indexable": true, "report_reasons": null, "author": "BoiElroy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ttg92/delta_lake_referential_constraints/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ttg92/delta_lake_referential_constraints/", "subreddit_subscribers": 130850, "created_utc": 1695842695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to execute a few notebooks in loop from a parent notebook using the dbutils.notebook.run and trying to capture the details of the child notebook like run ID and job ID. I tried using the dbutils get_context but that only gives me the context of the parent notebook. I don't know how to associate or get the details for the child notebooks. I've searched the forums but nothing seems to work. Any suggestions would be highly appreciated.", "author_fullname": "t2_5tnbm4y7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I get the execution context of a child notebook from a parent notebook in Databricks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16trv8e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695838560.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to execute a few notebooks in loop from a parent notebook using the dbutils.notebook.run and trying to capture the details of the child notebook like run ID and job ID. I tried using the dbutils get_context but that only gives me the context of the parent notebook. I don&amp;#39;t know how to associate or get the details for the child notebooks. I&amp;#39;ve searched the forums but nothing seems to work. Any suggestions would be highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16trv8e", "is_robot_indexable": true, "report_reasons": null, "author": "TheViper1994", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16trv8e/how_do_i_get_the_execution_context_of_a_child/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16trv8e/how_do_i_get_the_execution_context_of_a_child/", "subreddit_subscribers": 130850, "created_utc": 1695838560.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_jcps4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fuzzy Matching Images and Text", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_16tr1qa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/55icYUDg9a_vh8FxBoOcQCvZsBgeWUqVh9nj5NQMghs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695836486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "databricks.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.databricks.com/blog/using-images-and-metadata-product-fuzzy-matching-zingg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/H4iudY_kHprASzNavlQij4RSySMgjWwCL_sJGgiPNBI.jpg?auto=webp&amp;s=bf8e5c2c1b93f1afb1d0506255fa89366061473e", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/H4iudY_kHprASzNavlQij4RSySMgjWwCL_sJGgiPNBI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f1e11f18d5b10168513fe156f015b7dffe3219fe", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/H4iudY_kHprASzNavlQij4RSySMgjWwCL_sJGgiPNBI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5f1cd07a69024d55254c8665d619e6d56a852214", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/H4iudY_kHprASzNavlQij4RSySMgjWwCL_sJGgiPNBI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ff32ca9b9a0197e48bf7579bf2a46eec1b2adfec", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/H4iudY_kHprASzNavlQij4RSySMgjWwCL_sJGgiPNBI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d9d63b2a1dc792b84f7b26a0bfd77c3c86d2289", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/H4iudY_kHprASzNavlQij4RSySMgjWwCL_sJGgiPNBI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=23df7a72e4955e7a218a656ca4bcf9ab41c52243", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/H4iudY_kHprASzNavlQij4RSySMgjWwCL_sJGgiPNBI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0dc360080e1e154220739d39acd7e0808cd58ac3", "width": 1080, "height": 565}], "variants": {}, "id": "Y5WW65fCuqgNmZ3YIsL2Kz58c0X6q-jcV6ATBhrRJUM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16tr1qa", "is_robot_indexable": true, "report_reasons": null, "author": "sonalg", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16tr1qa/fuzzy_matching_images_and_text/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.databricks.com/blog/using-images-and-metadata-product-fuzzy-matching-zingg", "subreddit_subscribers": 130850, "created_utc": 1695836486.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\nCurrently working in a startup and I am the only one who is working in Data Science or Data Engineering task. Joined in May 2023 as an intern.\nNow,My CTO has asked me to take interview of senior DE, these guys have around 3-7 yrs of work exp, I am very much confuses what to ask!\nCan you guys tell me! What are the fundamentals need to be asked", "author_fullname": "t2_i3smbco5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fresher taking interview of senior DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16tpb3v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695832502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,\nCurrently working in a startup and I am the only one who is working in Data Science or Data Engineering task. Joined in May 2023 as an intern.\nNow,My CTO has asked me to take interview of senior DE, these guys have around 3-7 yrs of work exp, I am very much confuses what to ask!\nCan you guys tell me! What are the fundamentals need to be asked&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16tpb3v", "is_robot_indexable": true, "report_reasons": null, "author": "No_Woodpecker_3267", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16tpb3v/fresher_taking_interview_of_senior_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16tpb3v/fresher_taking_interview_of_senior_de/", "subreddit_subscribers": 130850, "created_utc": 1695832502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I was asked to create a data warehouse, and I'm leaning toward the following ELT solution.\n\n    [Read Replica of Source Database]  \n    \n    \u2193\u00a0-- using Amazon DMS  \n    \n    [S3 bucket]   \n    \n    \u2193 \u00a0-- using Snowflake  \n    \n    [Snowflake] \n\nI would first load all the data into Snowflake and do transformations and processing all within Snowflake.\n\nMy questions are:\n\n* What are your thoughts on this ELT setup?\n* If there are hundreds of tables in the source database, do I need load queries for each table?\n* How should I orchestrate the schedules? Do you use Snowflake tasks, or another service like Airflow?", "author_fullname": "t2_98ijstb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would like to get your feedback on my data warehousing solution using Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16todpd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695830387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was asked to create a data warehouse, and I&amp;#39;m leaning toward the following ELT solution.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;[Read Replica of Source Database]  \n\n\u2193\u00a0-- using Amazon DMS  \n\n[S3 bucket]   \n\n\u2193 \u00a0-- using Snowflake  \n\n[Snowflake] \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I would first load all the data into Snowflake and do transformations and processing all within Snowflake.&lt;/p&gt;\n\n&lt;p&gt;My questions are:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are your thoughts on this ELT setup?&lt;/li&gt;\n&lt;li&gt;If there are hundreds of tables in the source database, do I need load queries for each table?&lt;/li&gt;\n&lt;li&gt;How should I orchestrate the schedules? Do you use Snowflake tasks, or another service like Airflow?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16todpd", "is_robot_indexable": true, "report_reasons": null, "author": "Specialist_Dig2115", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16todpd/would_like_to_get_your_feedback_on_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16todpd/would_like_to_get_your_feedback_on_my_data/", "subreddit_subscribers": 130850, "created_utc": 1695830387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_olwmmcn8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Digger: An open source continuous deployment tool for Terraform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_16uibir", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/psqMdEGUHUIq5GhVJOXMHwH8vSKTfwFT-RpOCQ_8zZU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695913217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "http://github.com/diggerhq/digger", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XBaTjNCxm8rMV6fnVCFsOCUadW-0jbRv_wSX6Bw-tIU.jpg?auto=webp&amp;s=64b3fbe3362b19a7cfe6dc7510708a69563eeddd", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/XBaTjNCxm8rMV6fnVCFsOCUadW-0jbRv_wSX6Bw-tIU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=307ef8722666b3229dfe26c4ff2056c391878682", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/XBaTjNCxm8rMV6fnVCFsOCUadW-0jbRv_wSX6Bw-tIU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4888f08256e3c7182a1dbdcdc8e03bde8d2850a7", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/XBaTjNCxm8rMV6fnVCFsOCUadW-0jbRv_wSX6Bw-tIU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4da9212e82f63497fd1e522957a798887c98ce98", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/XBaTjNCxm8rMV6fnVCFsOCUadW-0jbRv_wSX6Bw-tIU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1fb388e4370715f0599b39f298a65af15b717717", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/XBaTjNCxm8rMV6fnVCFsOCUadW-0jbRv_wSX6Bw-tIU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a3c7274d2c43f854da6d2f6d74423bed338912cb", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/XBaTjNCxm8rMV6fnVCFsOCUadW-0jbRv_wSX6Bw-tIU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f116079d2c9b0629ee1f5fe9c51268e5762a48cb", "width": 1080, "height": 540}], "variants": {}, "id": "RWlijrEdtCEb_dzxNLuoMhXIGcSwPt8p8zSF1qSqlZE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16uibir", "is_robot_indexable": true, "report_reasons": null, "author": "utpalnadiger", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16uibir/digger_an_open_source_continuous_deployment_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "http://github.com/diggerhq/digger", "subreddit_subscribers": 130850, "created_utc": 1695913217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi I\u2019m a data analyst having 3yrs work ex. &amp; have worked with basic Python ETL jobs from S3 to Snowflake. However I wish to transition to Data engineering and Big Data. Can someone please recommend good resources? Something like how there is Odin project and free code camp for hands on web dev. I\u2019m looking for something similar that is hands on for DE and sql.Would really appreciate your help .Thanks", "author_fullname": "t2_bee9ewd34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ui4dy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695912719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I\u2019m a data analyst having 3yrs work ex. &amp;amp; have worked with basic Python ETL jobs from S3 to Snowflake. However I wish to transition to Data engineering and Big Data. Can someone please recommend good resources? Something like how there is Odin project and free code camp for hands on web dev. I\u2019m looking for something similar that is hands on for DE and sql.Would really appreciate your help .Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ui4dy", "is_robot_indexable": true, "report_reasons": null, "author": "Big_Intention6067", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ui4dy/learning_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ui4dy/learning_data_engineering/", "subreddit_subscribers": 130850, "created_utc": 1695912719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[https://www.tinybird.co/blog-posts/event-sourcing-with-kafka](https://www.tinybird.co/blog-posts/event-sourcing-with-kafka)\n\nMy colleague recently published this nice little blog post on event sourcing with a practical implementation with Kafka. Thought this sub might be interested in case event sourcing is a pattern you're curious about.", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event sourcing with Kafka: A practical example", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16uhukn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695912063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.tinybird.co/blog-posts/event-sourcing-with-kafka\"&gt;https://www.tinybird.co/blog-posts/event-sourcing-with-kafka&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My colleague recently published this nice little blog post on event sourcing with a practical implementation with Kafka. Thought this sub might be interested in case event sourcing is a pattern you&amp;#39;re curious about.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4qzRPjWJaIWP3nXtoLRNY2Jndp9-oqfeBHuwViLygO0.jpg?auto=webp&amp;s=a2736bb69fbbcdb39ab9e0b9f7eadb012d47163b", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/4qzRPjWJaIWP3nXtoLRNY2Jndp9-oqfeBHuwViLygO0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=af70b8cab83c401a2ca4dc9783eb8e6cfceba0d3", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/4qzRPjWJaIWP3nXtoLRNY2Jndp9-oqfeBHuwViLygO0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=de2909c7578462fe393fbd8e1df174a4f94cd9ba", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/4qzRPjWJaIWP3nXtoLRNY2Jndp9-oqfeBHuwViLygO0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=76a16a105ad68b63a5cd0ee62b8c1329bace814c", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/4qzRPjWJaIWP3nXtoLRNY2Jndp9-oqfeBHuwViLygO0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6dd042e4a69e73569d12402444430a3514facb95", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/4qzRPjWJaIWP3nXtoLRNY2Jndp9-oqfeBHuwViLygO0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4660427dc5148a6204ffcadae3c36c062b40f746", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/4qzRPjWJaIWP3nXtoLRNY2Jndp9-oqfeBHuwViLygO0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d236b39ef84d45bfb3de012a950276e73e4b2cc8", "width": 1080, "height": 567}], "variants": {}, "id": "aFDw2jCRBMU70NeW2N8pI_RqhNg3J_nRE-nrILkgcio"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16uhukn", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16uhukn/event_sourcing_with_kafka_a_practical_example/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16uhukn/event_sourcing_with_kafka_a_practical_example/", "subreddit_subscribers": 130850, "created_utc": 1695912063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dealing with a troll that doesn\u2019t want to post the question because he thinks he\u2019s ultimately right.\n\nI worked in IT for 5 years, during that time I\u2019d class myself as working in tech because I worked in the information technology department. Dealing with computers, mobile devices, laptops and monitors.\n\nHowever, I class myself as a Data Engineer that works with tech not in it. After all, majority of Data Teams (personal experience) don\u2019t sit in the IT department. \n\nI 100% utilise tech, but I work in retail. \n\nI don\u2019t fix technology, I don\u2019t create software, I write code using tech but I don\u2019t work in the tech industry or I\u2019d be working for companies like Apple, AWS, Google etc. \n\nHappy to go with the majority but my opinion is that we don\u2019t work in tech because it fully depends on the position of your data team and the industry that you are in.", "author_fullname": "t2_al2yxww8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would you class yourself as working \u201cIn Tech\u201d or working \u201cwith Tech\u201d?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16uhm2t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695911500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dealing with a troll that doesn\u2019t want to post the question because he thinks he\u2019s ultimately right.&lt;/p&gt;\n\n&lt;p&gt;I worked in IT for 5 years, during that time I\u2019d class myself as working in tech because I worked in the information technology department. Dealing with computers, mobile devices, laptops and monitors.&lt;/p&gt;\n\n&lt;p&gt;However, I class myself as a Data Engineer that works with tech not in it. After all, majority of Data Teams (personal experience) don\u2019t sit in the IT department. &lt;/p&gt;\n\n&lt;p&gt;I 100% utilise tech, but I work in retail. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t fix technology, I don\u2019t create software, I write code using tech but I don\u2019t work in the tech industry or I\u2019d be working for companies like Apple, AWS, Google etc. &lt;/p&gt;\n\n&lt;p&gt;Happy to go with the majority but my opinion is that we don\u2019t work in tech because it fully depends on the position of your data team and the industry that you are in.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16uhm2t", "is_robot_indexable": true, "report_reasons": null, "author": "The-Engineer-93", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16uhm2t/would_you_class_yourself_as_working_in_tech_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16uhm2t/would_you_class_yourself_as_working_in_tech_or/", "subreddit_subscribers": 130850, "created_utc": 1695911500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello.\n\nI've fallen out of love with the product management career, which I've been fulfilling last 6 (soon to be 7) years.\n\nI used to be a data scientist for 2 years, data engineer for 1 year and data architect for 1 year, before I became a Data Product Manager.\n\nI've been a data product manager (working a couple years with data infrastructure, cloud and building client-facing products), also a growth product manager for a couple years, and then finally a data product manager for close to 3 years now.\n\nI'm looking to return to the more technical/hands-off side. Do you seem this as possible?\n\nI'm making around $11K per month (besides yearly bonuses) as a PM, so the closest to $170K per year I've been since ever. I do work remotely from Peru, by the way.\n\nNot looking to make the same amount of money, I'm more willing to return doing something I can see the impact of and have fun in the process. I'm just curious how likely do you see going back to data engineering, analysis as a contractor or FTE, not sure if I will have a bigger chance just making my own consulting firm, considering the amount of experience I do have now. \n\n&amp;#x200B;\n\nAny tips are appreciated! :) ", "author_fullname": "t2_yikhi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going back to Data Engineering after 6 years as PM", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16uep9d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695904105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve fallen out of love with the product management career, which I&amp;#39;ve been fulfilling last 6 (soon to be 7) years.&lt;/p&gt;\n\n&lt;p&gt;I used to be a data scientist for 2 years, data engineer for 1 year and data architect for 1 year, before I became a Data Product Manager.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been a data product manager (working a couple years with data infrastructure, cloud and building client-facing products), also a growth product manager for a couple years, and then finally a data product manager for close to 3 years now.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to return to the more technical/hands-off side. Do you seem this as possible?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m making around $11K per month (besides yearly bonuses) as a PM, so the closest to $170K per year I&amp;#39;ve been since ever. I do work remotely from Peru, by the way.&lt;/p&gt;\n\n&lt;p&gt;Not looking to make the same amount of money, I&amp;#39;m more willing to return doing something I can see the impact of and have fun in the process. I&amp;#39;m just curious how likely do you see going back to data engineering, analysis as a contractor or FTE, not sure if I will have a bigger chance just making my own consulting firm, considering the amount of experience I do have now. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any tips are appreciated! :) &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16uep9d", "is_robot_indexable": true, "report_reasons": null, "author": "gglavida", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16uep9d/going_back_to_data_engineering_after_6_years_as_pm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16uep9d/going_back_to_data_engineering_after_6_years_as_pm/", "subreddit_subscribers": 130850, "created_utc": 1695904105.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! I appreciate any advice the community can give. I work for a Fortune 500 company and our return to office policy has resulted in employees having to move to specific cities. I'm losing half of my team because they're unable to move.\n\nI've trained one employee in particular to be a SQL Developer/Data Engineer. He's got 3 years of experience working for me in that field, building pipelines using SSIS, Python, Power Automate, Databricks, a BS in Electrical Engineering and significant experience with T-SQL, Agile, Azure. He does a ton of maintenance on our 30 databases and associated ETL jobs.\n\n**What level of data engineering job would you recommend that he look for?**", "author_fullname": "t2_1btxikf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to help my surplused employees", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16udeom", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695900420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I appreciate any advice the community can give. I work for a Fortune 500 company and our return to office policy has resulted in employees having to move to specific cities. I&amp;#39;m losing half of my team because they&amp;#39;re unable to move.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve trained one employee in particular to be a SQL Developer/Data Engineer. He&amp;#39;s got 3 years of experience working for me in that field, building pipelines using SSIS, Python, Power Automate, Databricks, a BS in Electrical Engineering and significant experience with T-SQL, Agile, Azure. He does a ton of maintenance on our 30 databases and associated ETL jobs.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What level of data engineering job would you recommend that he look for?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16udeom", "is_robot_indexable": true, "report_reasons": null, "author": "WireDog88", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16udeom/trying_to_help_my_surplused_employees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16udeom/trying_to_help_my_surplused_employees/", "subreddit_subscribers": 130850, "created_utc": 1695900420.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}