{"kind": "Listing", "data": {"after": "t3_16p5zwo", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Have 4 YOE. Current company is great but I\u2019ve plateau\u2019d. Is there a list of employers in the states that is heavily focused on Python, Docker, AWS Snowflake, Airflow? I\u2019ve had experience with many technologies and languages. Over the years I learned that I LOVE writing Python or anything Python related. Any way I can find employers that seek stack heavily focused on Python, AWS, Snowflake, Airflow, Docker? Preferably in the U.S?\nWhich data engineering titles would help me find what I\u2019m looking for? Or how can I find such roles/employers?", "author_fullname": "t2_83p02r6a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good Companies that use: Python, AWS, Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16oocc3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695323297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Have 4 YOE. Current company is great but I\u2019ve plateau\u2019d. Is there a list of employers in the states that is heavily focused on Python, Docker, AWS Snowflake, Airflow? I\u2019ve had experience with many technologies and languages. Over the years I learned that I LOVE writing Python or anything Python related. Any way I can find employers that seek stack heavily focused on Python, AWS, Snowflake, Airflow, Docker? Preferably in the U.S?\nWhich data engineering titles would help me find what I\u2019m looking for? Or how can I find such roles/employers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16oocc3", "is_robot_indexable": true, "report_reasons": null, "author": "1337codethrow", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16oocc3/good_companies_that_use_python_aws_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16oocc3/good_companies_that_use_python_aws_snowflake/", "subreddit_subscribers": 129860, "created_utc": 1695323297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When I migrated to Snowflake my costs went up like 5x. Maybe more.", "author_fullname": "t2_j13q2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone migrating away from Snowflake and back to AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16p1v2j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 53, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 53, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695360099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I migrated to Snowflake my costs went up like 5x. Maybe more.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16p1v2j", "is_robot_indexable": true, "report_reasons": null, "author": "Fitbot5000", "discussion_type": null, "num_comments": 82, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p1v2j/anyone_migrating_away_from_snowflake_and_back_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16p1v2j/anyone_migrating_away_from_snowflake_and_back_to/", "subreddit_subscribers": 129860, "created_utc": 1695360099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently working as a data analyst but for the past 6 months I have been working on building out data infrastructure for our team. \n\nNamely being the point person for our team to start using dbt, AWS, and more Data Science/Data Modeling type work.\n\nDo you think it would be fair for me to request a job title change from my boss?", "author_fullname": "t2_hhc0wpglp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job Title Change Data Analyst \u2014&gt; Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ov9k2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695339885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working as a data analyst but for the past 6 months I have been working on building out data infrastructure for our team. &lt;/p&gt;\n\n&lt;p&gt;Namely being the point person for our team to start using dbt, AWS, and more Data Science/Data Modeling type work.&lt;/p&gt;\n\n&lt;p&gt;Do you think it would be fair for me to request a job title change from my boss?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ov9k2", "is_robot_indexable": true, "report_reasons": null, "author": "Unable-Barracuda6775", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ov9k2/job_title_change_data_analyst_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ov9k2/job_title_change_data_analyst_engineer/", "subreddit_subscribers": 129860, "created_utc": 1695339885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have to start learning how to use sql through python along with pandas, etc. I was hoping you guys could tell me whats the most common option for this in the industry as of now. I saw some say SQLalchemy.", "author_fullname": "t2_8mn3m0sl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best tool/framework to pick up for SQL in python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16or26x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695329653.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have to start learning how to use sql through python along with pandas, etc. I was hoping you guys could tell me whats the most common option for this in the industry as of now. I saw some say SQLalchemy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16or26x", "is_robot_indexable": true, "report_reasons": null, "author": "PurpVan", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16or26x/best_toolframework_to_pick_up_for_sql_in_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16or26x/best_toolframework_to_pick_up_for_sql_in_python/", "subreddit_subscribers": 129860, "created_utc": 1695329653.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any good recommendations on learning how to design a data architecture for a data science project or an enterprise?", "author_fullname": "t2_61mc4jcc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Designing a Data Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16or0j9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695329543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any good recommendations on learning how to design a data architecture for a data science project or an enterprise?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16or0j9", "is_robot_indexable": true, "report_reasons": null, "author": "prtkkr", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16or0j9/designing_a_data_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16or0j9/designing_a_data_architecture/", "subreddit_subscribers": 129860, "created_utc": 1695329543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all first time poster little while lurker.\n\nI see alot of people talk about snowflake and AWS as these seem to be very popular. I don't know if there is a competitive edge or it's just happens to be the go to tool in this industry. Can I ask if many of you out there use Google Cloud Platform and Big Query or a combination of on premises and GCP or different cloud providers?", "author_fullname": "t2_4r6g4urx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP BigQuery?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16p66k3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695376617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all first time poster little while lurker.&lt;/p&gt;\n\n&lt;p&gt;I see alot of people talk about snowflake and AWS as these seem to be very popular. I don&amp;#39;t know if there is a competitive edge or it&amp;#39;s just happens to be the go to tool in this industry. Can I ask if many of you out there use Google Cloud Platform and Big Query or a combination of on premises and GCP or different cloud providers?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16p66k3", "is_robot_indexable": true, "report_reasons": null, "author": "ljsmith970", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p66k3/gcp_bigquery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16p66k3/gcp_bigquery/", "subreddit_subscribers": 129860, "created_utc": 1695376617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nin my current org, we are looking to revamp our data products. We're looking at new ELT tools as well as doing a bit of a \"reset\" for the standard approach to building data pipelines. \n\nI am struggling with pitching what I perceive as the \"modern\" solution.\n\nCurrent state:\n\nWe have an in house tool, something like Airflow, to control the workflow orchestration. For the actual code, typically my colleagues (data engineers) are writing often opaque PHP+SQL scripts. You know, scripts the create the joys of reviewing what's going wrong in 10,000+ lines of code that one colleague wrote (who happens to be on holiday when it breaks)\n\nProposed state:\n\nEssentially I am pitching that we use a [mage.ai](https://mage.ai) like solution, and build our pipelines with python+dbt+sql.\n\nI foresee [Mage.ai](https://Mage.ai) (or something similar like Airbyte) giving me the visibility over the pipeline (assuming we use granular code blocks; \\~1 for each transformation step); compared to the currently opaque PHP scripts my colleagues are producing.\n\nThen, I expect workflow orchestration to be vastly improved, thanks to dbt run. Which lets us slowly abandon the in house tool we've built up over the years.\n\nCaveat:\n\nI have come into my current \"junior manager\" role, from an analyst background, so I am quite happy to listen to the more experienced data engineering colleagues, regarding best practice.\n\nThat being said, even with less experience, I can't understand the reasoning for continuing our current path. So many of our php pipelines contain arrays being tortured to death;.....where I would just drop the data into the database and transform it in SQL. It sometimes feels like little(big) protected islands for the developer are being made, every time one of these opaque behemoth scripts is released. \n\nIs this something you have encountered in your teams? Am I on the right path? Am I fighting the good fight? If not, why?\n\n\\*We generally don't have any \\*special\\* requirements for our pipelines (streaming, big data, real time....etc)....it's often a \"regular\" ingest (from prod API) -&gt; transform -&gt; (BI) datamart type pipeline.", "author_fullname": "t2_20h89ytj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Modernizing data pipelines......organizational blockers or am I just a noob?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16p4ztz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695372162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;in my current org, we are looking to revamp our data products. We&amp;#39;re looking at new ELT tools as well as doing a bit of a &amp;quot;reset&amp;quot; for the standard approach to building data pipelines. &lt;/p&gt;\n\n&lt;p&gt;I am struggling with pitching what I perceive as the &amp;quot;modern&amp;quot; solution.&lt;/p&gt;\n\n&lt;p&gt;Current state:&lt;/p&gt;\n\n&lt;p&gt;We have an in house tool, something like Airflow, to control the workflow orchestration. For the actual code, typically my colleagues (data engineers) are writing often opaque PHP+SQL scripts. You know, scripts the create the joys of reviewing what&amp;#39;s going wrong in 10,000+ lines of code that one colleague wrote (who happens to be on holiday when it breaks)&lt;/p&gt;\n\n&lt;p&gt;Proposed state:&lt;/p&gt;\n\n&lt;p&gt;Essentially I am pitching that we use a &lt;a href=\"https://mage.ai\"&gt;mage.ai&lt;/a&gt; like solution, and build our pipelines with python+dbt+sql.&lt;/p&gt;\n\n&lt;p&gt;I foresee &lt;a href=\"https://Mage.ai\"&gt;Mage.ai&lt;/a&gt; (or something similar like Airbyte) giving me the visibility over the pipeline (assuming we use granular code blocks; ~1 for each transformation step); compared to the currently opaque PHP scripts my colleagues are producing.&lt;/p&gt;\n\n&lt;p&gt;Then, I expect workflow orchestration to be vastly improved, thanks to dbt run. Which lets us slowly abandon the in house tool we&amp;#39;ve built up over the years.&lt;/p&gt;\n\n&lt;p&gt;Caveat:&lt;/p&gt;\n\n&lt;p&gt;I have come into my current &amp;quot;junior manager&amp;quot; role, from an analyst background, so I am quite happy to listen to the more experienced data engineering colleagues, regarding best practice.&lt;/p&gt;\n\n&lt;p&gt;That being said, even with less experience, I can&amp;#39;t understand the reasoning for continuing our current path. So many of our php pipelines contain arrays being tortured to death;.....where I would just drop the data into the database and transform it in SQL. It sometimes feels like little(big) protected islands for the developer are being made, every time one of these opaque behemoth scripts is released. &lt;/p&gt;\n\n&lt;p&gt;Is this something you have encountered in your teams? Am I on the right path? Am I fighting the good fight? If not, why?&lt;/p&gt;\n\n&lt;p&gt;*We generally don&amp;#39;t have any *special* requirements for our pipelines (streaming, big data, real time....etc)....it&amp;#39;s often a &amp;quot;regular&amp;quot; ingest (from prod API) -&amp;gt; transform -&amp;gt; (BI) datamart type pipeline.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aeT7ze2BtBlIb8zZIXZIAOY3G1XXNjbJ6oVDibUpEsQ.jpg?auto=webp&amp;s=c6069afb05bd5a0610454eff205b0de0f4c7cef2", "width": 1524, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/aeT7ze2BtBlIb8zZIXZIAOY3G1XXNjbJ6oVDibUpEsQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aa478f4ea779b8ac72061216cb8a8cda7e655638", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/aeT7ze2BtBlIb8zZIXZIAOY3G1XXNjbJ6oVDibUpEsQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f1f4194503a2dbbc777d91bf043f284a7ce85b6d", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/aeT7ze2BtBlIb8zZIXZIAOY3G1XXNjbJ6oVDibUpEsQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=db595a6de5fa4afca5771571c913b2f01f4119b7", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/aeT7ze2BtBlIb8zZIXZIAOY3G1XXNjbJ6oVDibUpEsQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2a94dbbee373405a6a78a29452b9490eba644bb", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/aeT7ze2BtBlIb8zZIXZIAOY3G1XXNjbJ6oVDibUpEsQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e7f0b65ba6c15688f3916734aae188f2390a6042", "width": 960, "height": 503}, {"url": "https://external-preview.redd.it/aeT7ze2BtBlIb8zZIXZIAOY3G1XXNjbJ6oVDibUpEsQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d7425076e002cc0e60bfaa4c1a94925f12856bd8", "width": 1080, "height": 566}], "variants": {}, "id": "9-9fQOf4CbozRQb-4LsE4XBYETAYFLqieboBGJfHCFI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16p4ztz", "is_robot_indexable": true, "report_reasons": null, "author": "Lalagabor", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p4ztz/modernizing_data_pipelinesorganizational_blockers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16p4ztz/modernizing_data_pipelinesorganizational_blockers/", "subreddit_subscribers": 129860, "created_utc": 1695372162.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it better to have all your data in one database or break it into multiple databases for each stage like staging and marts? I could see it being easier to deploy different environments within the same snowflake account with one database. Or should I have one database for raw then another one for staging/analytics? Any recommendations?", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake Database Design", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16oymfs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695349598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it better to have all your data in one database or break it into multiple databases for each stage like staging and marts? I could see it being easier to deploy different environments within the same snowflake account with one database. Or should I have one database for raw then another one for staging/analytics? Any recommendations?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16oymfs", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16oymfs/snowflake_database_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16oymfs/snowflake_database_design/", "subreddit_subscribers": 129860, "created_utc": 1695349598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "One of the biggest complaints I\u2019ve heard on this subreddit with the MDS tools is around issues with data quality.\n\nTo quote a comment/sentiment that I see frequently echoed:\n\n\u201cWhat's notably lacking is some way to guarantee data quality - if anything, those quick source system -&gt; SaaS connector -&gt; data warehouse pipelines just kick the bucket down the road to the analysts. \n\nSure I can bang out an MVP in a week by hooking up Fivetran to Snowflake and using a few dbt packages to quickly model and feed to Metabase or Superset. I'll get a few tables out quickly, but after a while, reality starts to look different as the MDS tools give me nothing to effectively manage data in my organization.\n\n\nEven the numerous data cataloguing and monitoring tools are just treating the symptoms IMO: we wouldn't need them if data ingestion didn't completely disregard data quality.\u201d\n\nMy perspective on this is that you\u2019re always going to have bad data getting generated from your data sources, it\u2019s just the nature of the imperfect world we live in unfortunately. \n\nSo, my question for the folks on this subreddit is:\n\nWhat does a data ingestion tool that accounts for data quality look like?\n\n\nTLDR: What would a data ingestion tool that accounts for data quality look like, in a perfect world how would you like it to work?", "author_fullname": "t2_iu7o1yoi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Perfect Data Ingestion Tool?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16pg9hr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695403947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One of the biggest complaints I\u2019ve heard on this subreddit with the MDS tools is around issues with data quality.&lt;/p&gt;\n\n&lt;p&gt;To quote a comment/sentiment that I see frequently echoed:&lt;/p&gt;\n\n&lt;p&gt;\u201cWhat&amp;#39;s notably lacking is some way to guarantee data quality - if anything, those quick source system -&amp;gt; SaaS connector -&amp;gt; data warehouse pipelines just kick the bucket down the road to the analysts. &lt;/p&gt;\n\n&lt;p&gt;Sure I can bang out an MVP in a week by hooking up Fivetran to Snowflake and using a few dbt packages to quickly model and feed to Metabase or Superset. I&amp;#39;ll get a few tables out quickly, but after a while, reality starts to look different as the MDS tools give me nothing to effectively manage data in my organization.&lt;/p&gt;\n\n&lt;p&gt;Even the numerous data cataloguing and monitoring tools are just treating the symptoms IMO: we wouldn&amp;#39;t need them if data ingestion didn&amp;#39;t completely disregard data quality.\u201d&lt;/p&gt;\n\n&lt;p&gt;My perspective on this is that you\u2019re always going to have bad data getting generated from your data sources, it\u2019s just the nature of the imperfect world we live in unfortunately. &lt;/p&gt;\n\n&lt;p&gt;So, my question for the folks on this subreddit is:&lt;/p&gt;\n\n&lt;p&gt;What does a data ingestion tool that accounts for data quality look like?&lt;/p&gt;\n\n&lt;p&gt;TLDR: What would a data ingestion tool that accounts for data quality look like, in a perfect world how would you like it to work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16pg9hr", "is_robot_indexable": true, "report_reasons": null, "author": "YeeterSkeeter9269", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16pg9hr/the_perfect_data_ingestion_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16pg9hr/the_perfect_data_ingestion_tool/", "subreddit_subscribers": 129860, "created_utc": 1695403947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,   \n\n\nI was recently tasked with setting up real-time collection of data from our Veeva Platform, to help power our new recommendation engine POC.  \nI came up with the following architecture. I set up a simple Lambda function that pings the Veeva API, queries the logs, and transforms them to provide a list of users and their interactions. This list is then sent as a payload directly to my API Gateway, which integrates with an SQS queue. Next, I have another Lambda function triggered by SQS, which forwards this data to my Kafka servers. Currently, everything is working as expected; I receive the users' list in JSON format in real-time on my consumer server. My next step is to perform an insert-only merge of this data into our existing interactions table using Databricks. This will then be utilized by our Data Scientists to generate recommendations.  \n\n\nhttps://preview.redd.it/r7nbceyfotpb1.png?width=1288&amp;format=png&amp;auto=webp&amp;s=a79e4ffa3ba3f206860a705669f3a6713c6dd2a9\n\nHere's the issue I can't connect my databricks cluster to ingest my data in my Kafka cluster. \n\n1.I checked the docs, and the direct connection between Databricks and MSK using IAM roles and Instance Profiles is still in Public Preview. I spent 2 days trying to configure it and failed. I checked both the network aspects and the installation of the JAR files.\n\n2. If anyone knows how to connect them or point me in the right direction, I'd be so grateful!\n\n3. I spoke to my Product lead about this. He said that an acceptable time gap between querying the Veeva API and data landing in our bronze table is around 2-3 seconds. However, they want for this to be as close to real-time as possible, because the higher-ups also want to use Databricks live dashboards for business metrics, so they can take \"*real time*\" decisions.   \n\n\nTaking this into account I decided this would be the way to go, \n\n![img](pw34e4r7ttpb1 \"Have a consumer lambda that has an MSK trigger, that reads the interactions.json, writes it to an S3 bucket, and have autoloader ingest the data and run an Insert-only Merge on my existing interactions table. \n\")\n\nWould this work? keeping the time-constraint in mind\n\n&amp;#x200B;", "author_fullname": "t2_ic83gko1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Managed Service Kakfa to Databricks - Ingestion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 72, "top_awarded_type": null, "hide_score": false, "media_metadata": {"r7nbceyfotpb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/r7nbceyfotpb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b07a705af6b3ea265256238dbcc7afc3690f14a9"}, {"y": 111, "x": 216, "u": "https://preview.redd.it/r7nbceyfotpb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a5bd7da6c115a4f5925c88088311d07d9046980"}, {"y": 165, "x": 320, "u": "https://preview.redd.it/r7nbceyfotpb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5396bcd011cb36754c0498a14eaf5e849c6b6d75"}, {"y": 330, "x": 640, "u": "https://preview.redd.it/r7nbceyfotpb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=34aa52d6365592a4d2cda12c0cc477fb796325aa"}, {"y": 496, "x": 960, "u": "https://preview.redd.it/r7nbceyfotpb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a8ed0809ed8748fefd86ebeec16290c58e620492"}, {"y": 558, "x": 1080, "u": "https://preview.redd.it/r7nbceyfotpb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=08f0eb1efa60652477329e73455e119c84ebc15d"}], "s": {"y": 666, "x": 1288, "u": "https://preview.redd.it/r7nbceyfotpb1.png?width=1288&amp;format=png&amp;auto=webp&amp;s=a79e4ffa3ba3f206860a705669f3a6713c6dd2a9"}, "id": "r7nbceyfotpb1"}, "pw34e4r7ttpb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/pw34e4r7ttpb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3efe704a959f05c157a6eff7d8358e10d0bcf158"}, {"y": 73, "x": 216, "u": "https://preview.redd.it/pw34e4r7ttpb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9c0438afb4cbcd3d565897919e9b389dbccdd2b0"}, {"y": 109, "x": 320, "u": "https://preview.redd.it/pw34e4r7ttpb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e6e06ad469d76e2ab96fdada899b637357f40976"}, {"y": 218, "x": 640, "u": "https://preview.redd.it/pw34e4r7ttpb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d453a2ebfee29a48bc710dffd76516bb91b5a4d6"}, {"y": 327, "x": 960, "u": "https://preview.redd.it/pw34e4r7ttpb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=018974285eb67a015dca5492709ee9ba2bb7a0cd"}, {"y": 368, "x": 1080, "u": "https://preview.redd.it/pw34e4r7ttpb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3c82623f457fb9ff3a834986deb42da9f0520815"}], "s": {"y": 584, "x": 1712, "u": "https://preview.redd.it/pw34e4r7ttpb1.png?width=1712&amp;format=png&amp;auto=webp&amp;s=97b19b97a4368ba0bb88cdd5a0bfc812bf3a1c3f"}, "id": "pw34e4r7ttpb1"}}, "name": "t3_16pdpw0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/grQ8vi_-WT26eqUU7Dxncg-D8R6QjYHiu64wkK0s2og.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695397639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,   &lt;/p&gt;\n\n&lt;p&gt;I was recently tasked with setting up real-time collection of data from our Veeva Platform, to help power our new recommendation engine POC.&lt;br/&gt;\nI came up with the following architecture. I set up a simple Lambda function that pings the Veeva API, queries the logs, and transforms them to provide a list of users and their interactions. This list is then sent as a payload directly to my API Gateway, which integrates with an SQS queue. Next, I have another Lambda function triggered by SQS, which forwards this data to my Kafka servers. Currently, everything is working as expected; I receive the users&amp;#39; list in JSON format in real-time on my consumer server. My next step is to perform an insert-only merge of this data into our existing interactions table using Databricks. This will then be utilized by our Data Scientists to generate recommendations.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/r7nbceyfotpb1.png?width=1288&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a79e4ffa3ba3f206860a705669f3a6713c6dd2a9\"&gt;https://preview.redd.it/r7nbceyfotpb1.png?width=1288&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a79e4ffa3ba3f206860a705669f3a6713c6dd2a9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the issue I can&amp;#39;t connect my databricks cluster to ingest my data in my Kafka cluster. &lt;/p&gt;\n\n&lt;p&gt;1.I checked the docs, and the direct connection between Databricks and MSK using IAM roles and Instance Profiles is still in Public Preview. I spent 2 days trying to configure it and failed. I checked both the network aspects and the installation of the JAR files.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;If anyone knows how to connect them or point me in the right direction, I&amp;#39;d be so grateful!&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I spoke to my Product lead about this. He said that an acceptable time gap between querying the Veeva API and data landing in our bronze table is around 2-3 seconds. However, they want for this to be as close to real-time as possible, because the higher-ups also want to use Databricks live dashboards for business metrics, so they can take &amp;quot;&lt;em&gt;real time&lt;/em&gt;&amp;quot; decisions.   &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Taking this into account I decided this would be the way to go, &lt;/p&gt;\n\n&lt;p&gt;![img](pw34e4r7ttpb1 &amp;quot;Have a consumer lambda that has an MSK trigger, that reads the interactions.json, writes it to an S3 bucket, and have autoloader ingest the data and run an Insert-only Merge on my existing interactions table. \n&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;Would this work? keeping the time-constraint in mind&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16pdpw0", "is_robot_indexable": true, "report_reasons": null, "author": "Background_Debate_94", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16pdpw0/aws_managed_service_kakfa_to_databricks_ingestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16pdpw0/aws_managed_service_kakfa_to_databricks_ingestion/", "subreddit_subscribers": 129860, "created_utc": 1695397639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some background:\nI currently work for a small startup (30 employees) and we are starting to mature our data infrastructure (postgres -&gt; AWS DMS-&gt; Redshift -&gt;DBT-&gt;Redshift-&gt;PowerBi). \nWe store a large amount of information in JSONs which can sometimes be &gt;100k characters long, suprassing the 65k Byte limit for Amazon Redshift data limits for a single cell. \nThese JSONs are paramount to our reporting - what options are there to be able to utilise this json without it being truncated in redshift? We don't have a dedicated data engineer and so don't want to create too much infra to upkeep. \nIs the only option to create some custom python scripts to abstract certain keys from the JSON?\nCheers!", "author_fullname": "t2_2tntx2vs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Loading Large JSON into Redshift", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16p8no9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695384692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some background:\nI currently work for a small startup (30 employees) and we are starting to mature our data infrastructure (postgres -&amp;gt; AWS DMS-&amp;gt; Redshift -&amp;gt;DBT-&amp;gt;Redshift-&amp;gt;PowerBi). \nWe store a large amount of information in JSONs which can sometimes be &amp;gt;100k characters long, suprassing the 65k Byte limit for Amazon Redshift data limits for a single cell. \nThese JSONs are paramount to our reporting - what options are there to be able to utilise this json without it being truncated in redshift? We don&amp;#39;t have a dedicated data engineer and so don&amp;#39;t want to create too much infra to upkeep. \nIs the only option to create some custom python scripts to abstract certain keys from the JSON?\nCheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16p8no9", "is_robot_indexable": true, "report_reasons": null, "author": "casematta", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p8no9/loading_large_json_into_redshift/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16p8no9/loading_large_json_into_redshift/", "subreddit_subscribers": 129860, "created_utc": 1695384692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming Databases: Everything You Wanted to Know", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_16osaaa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GR1WqvPIIOLXNrUUsA-uQuEaf6gcpeSwaZmjjPetkBs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695332501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "risingwave.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.risingwave.com/blog/streaming-databases-everything-you-wanted-to-know/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/HHQ3bpMjQRb-01sDygTvQ3zSGP_XPceFJ5-mXnuVviw.jpg?auto=webp&amp;s=b7e4dcc20f21eb08532be4f44bcb2afd83a3598f", "width": 2560, "height": 1600}, "resolutions": [{"url": "https://external-preview.redd.it/HHQ3bpMjQRb-01sDygTvQ3zSGP_XPceFJ5-mXnuVviw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da32a5d91a292bffb6d119660b638c9e590567e6", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/HHQ3bpMjQRb-01sDygTvQ3zSGP_XPceFJ5-mXnuVviw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7353fe828c48d0f4db3187b3034190456a3dec1f", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/HHQ3bpMjQRb-01sDygTvQ3zSGP_XPceFJ5-mXnuVviw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bdb2196149d90817950922af7342f2f08e62780a", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/HHQ3bpMjQRb-01sDygTvQ3zSGP_XPceFJ5-mXnuVviw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e8121c7e1905cecc6c23cc5660a7c426e5bb4ae2", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/HHQ3bpMjQRb-01sDygTvQ3zSGP_XPceFJ5-mXnuVviw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=62cc77e8c5b58f12cdccc038f3cd16ebdf21ced9", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/HHQ3bpMjQRb-01sDygTvQ3zSGP_XPceFJ5-mXnuVviw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=60b72dad7898861032ecfe89103ca54e6a5d96e2", "width": 1080, "height": 675}], "variants": {}, "id": "hFCRvLcZo01Mnja6CckUi4AgVCLM2MZOpfNWBh4FS5U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16osaaa", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16osaaa/streaming_databases_everything_you_wanted_to_know/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.risingwave.com/blog/streaming-databases-everything-you-wanted-to-know/", "subreddit_subscribers": 129860, "created_utc": 1695332501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was working as a software developer for a mid size company for around 3 years as a PHP developer. The tech stack was pretty outdated and all I did for three years was code patches to an existing code base. Did not do a lot of new development and didn\u2019t learn much. \nThere was an opening for a Data Engineer in my company which I applied for. I have past BI experience, which helped me get this position. \nI\u2019ve been at the Data Engineering position for around an year now. And my team lead had been constantly giving me negative feedback on my code quality and coding standards. I\u2019ve tried to improve but she still seems unsatisfied with the work I\u2019ve been doing. I would like to know what are the different ways that I can improve my code quality. Are there any websites I can use to learn to get better at programming? Learning better coding standards and improving my overall code quality? Mentorship or peer review learning options would also be helpful.", "author_fullname": "t2_1reibdu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coding standards and code quality", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16phdqw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695406692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was working as a software developer for a mid size company for around 3 years as a PHP developer. The tech stack was pretty outdated and all I did for three years was code patches to an existing code base. Did not do a lot of new development and didn\u2019t learn much. \nThere was an opening for a Data Engineer in my company which I applied for. I have past BI experience, which helped me get this position. \nI\u2019ve been at the Data Engineering position for around an year now. And my team lead had been constantly giving me negative feedback on my code quality and coding standards. I\u2019ve tried to improve but she still seems unsatisfied with the work I\u2019ve been doing. I would like to know what are the different ways that I can improve my code quality. Are there any websites I can use to learn to get better at programming? Learning better coding standards and improving my overall code quality? Mentorship or peer review learning options would also be helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16phdqw", "is_robot_indexable": true, "report_reasons": null, "author": "luckykanwar", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16phdqw/coding_standards_and_code_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16phdqw/coding_standards_and_code_quality/", "subreddit_subscribers": 129860, "created_utc": 1695406692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I come from working primarily with Microsoft data tools and am now in a cloud environment supporting a dbt/Snowflake data warehouse.  In past data roles, Microsoft Master Data Services proved to be a critical tool in helping to house business definitions and hierarchies that didn't make sense to integrate into our ERP or another business tool since it was just needed for reporting.  Is there a similar tool, that won't break the bank, that I can use with our Snowflake environment to allow users to own data mappings that support reporting?  TIA for any advice ya'll can give.  We're not looking for a crazy robust MDM tool, just something that can mimic the very basic functionality that Microsoft MDS provided.", "author_fullname": "t2_i83i7un9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic MDM tool for Snowflake allowing business users to own/modify data mappings?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16p92i1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695385885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I come from working primarily with Microsoft data tools and am now in a cloud environment supporting a dbt/Snowflake data warehouse.  In past data roles, Microsoft Master Data Services proved to be a critical tool in helping to house business definitions and hierarchies that didn&amp;#39;t make sense to integrate into our ERP or another business tool since it was just needed for reporting.  Is there a similar tool, that won&amp;#39;t break the bank, that I can use with our Snowflake environment to allow users to own data mappings that support reporting?  TIA for any advice ya&amp;#39;ll can give.  We&amp;#39;re not looking for a crazy robust MDM tool, just something that can mimic the very basic functionality that Microsoft MDS provided.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16p92i1", "is_robot_indexable": true, "report_reasons": null, "author": "Dizzy_Berry3058", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p92i1/basic_mdm_tool_for_snowflake_allowing_business/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16p92i1/basic_mdm_tool_for_snowflake_allowing_business/", "subreddit_subscribers": 129860, "created_utc": 1695385885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have data that looks like this:\n\n&amp;#x200B;\n\n|Row|Hashed IP Address|Cookie|Persistent User ID|\n|:-|:-|:-|:-|\n|1|A|1||\n|2|B|1|DD|\n|3|B|2||\n|4|C|3|DD|\n|5|E|4|EE|\n|6||5|EE|\n\nTo improve attribution, we're trying to leverage three data points to find unique users: a hashed IP address, a tracking cookie, and a persistent user ID sent from the backend when a user is logged in.\n\nThe essential theory is that, if any data point shows up more than once, we know that's the same user. \n\nSo, by looking at the data, I know that rows 1 - 4 are the same person and that 5 - 6 are another person. What I don't know if how to tell a computer how to figure that out.\n\nI know other people have tackled this challenge before, but I can't find anything on it. Anyone know of any articles or videos on this challenge?\n\n*Note: There are other challenges here, like dealing with the possibility that multiple people get assigned the same IP, (e.g: through mobile networks or VPNs) or log in to multiple accounts, but we'll deal with one problem at a time here.*", "author_fullname": "t2_bxdnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tracking one user with three datapoints", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16p6fgo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695377680.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695377497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have data that looks like this:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Row&lt;/th&gt;\n&lt;th align=\"left\"&gt;Hashed IP Address&lt;/th&gt;\n&lt;th align=\"left\"&gt;Cookie&lt;/th&gt;\n&lt;th align=\"left\"&gt;Persistent User ID&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;A&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;B&lt;/td&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;DD&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;B&lt;/td&gt;\n&lt;td align=\"left\"&gt;2&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;C&lt;/td&gt;\n&lt;td align=\"left\"&gt;3&lt;/td&gt;\n&lt;td align=\"left\"&gt;DD&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;5&lt;/td&gt;\n&lt;td align=\"left\"&gt;E&lt;/td&gt;\n&lt;td align=\"left\"&gt;4&lt;/td&gt;\n&lt;td align=\"left\"&gt;EE&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;6&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;5&lt;/td&gt;\n&lt;td align=\"left\"&gt;EE&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;To improve attribution, we&amp;#39;re trying to leverage three data points to find unique users: a hashed IP address, a tracking cookie, and a persistent user ID sent from the backend when a user is logged in.&lt;/p&gt;\n\n&lt;p&gt;The essential theory is that, if any data point shows up more than once, we know that&amp;#39;s the same user. &lt;/p&gt;\n\n&lt;p&gt;So, by looking at the data, I know that rows 1 - 4 are the same person and that 5 - 6 are another person. What I don&amp;#39;t know if how to tell a computer how to figure that out.&lt;/p&gt;\n\n&lt;p&gt;I know other people have tackled this challenge before, but I can&amp;#39;t find anything on it. Anyone know of any articles or videos on this challenge?&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Note: There are other challenges here, like dealing with the possibility that multiple people get assigned the same IP, (e.g: through mobile networks or VPNs) or log in to multiple accounts, but we&amp;#39;ll deal with one problem at a time here.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16p6fgo", "is_robot_indexable": true, "report_reasons": null, "author": "takenorinvalid", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p6fgo/tracking_one_user_with_three_datapoints/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16p6fgo/tracking_one_user_with_three_datapoints/", "subreddit_subscribers": 129860, "created_utc": 1695377497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI am getting data from on premise sharepoint. Users put data into folder and I need to process them.  \nSo far I didnt found a solution how on premise sharepoint can notify that file was uploaded into folder, so I am getting folder content using sharepoint API and once there is a file, I process it and move it to another folder.\n\nIt is just set of python codes that handle file processing. \n\nHow would you schedule processing? Now it is cron job on a centos server. \n\nI can use openshift, or we are also running Airflow, but I dont think Airflow would be good match for running tasks this frequently.\n\nMany thanks for your ideas!", "author_fullname": "t2_46l1zqd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to deploy and run job that needs to be run every 2 minutes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16p59ze", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695373246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am getting data from on premise sharepoint. Users put data into folder and I need to process them.&lt;br/&gt;\nSo far I didnt found a solution how on premise sharepoint can notify that file was uploaded into folder, so I am getting folder content using sharepoint API and once there is a file, I process it and move it to another folder.&lt;/p&gt;\n\n&lt;p&gt;It is just set of python codes that handle file processing. &lt;/p&gt;\n\n&lt;p&gt;How would you schedule processing? Now it is cron job on a centos server. &lt;/p&gt;\n\n&lt;p&gt;I can use openshift, or we are also running Airflow, but I dont think Airflow would be good match for running tasks this frequently.&lt;/p&gt;\n\n&lt;p&gt;Many thanks for your ideas!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16p59ze", "is_robot_indexable": true, "report_reasons": null, "author": "pyzo_ryzo", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p59ze/where_to_deploy_and_run_job_that_needs_to_be_run/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16p59ze/where_to_deploy_and_run_job_that_needs_to_be_run/", "subreddit_subscribers": 129860, "created_utc": 1695373246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a bunch of US/Non US addresses which I need to standardize according to USPS format. Can you guys recommend me best way to do it.  Is there any Python package that I can rely?  \nOr Is there any paid/free third party endpoint where I can make a call to validate.  Google gave me [https://www.smarty.com/](https://www.smarty.com/) but I am not sure about other. Do you guys have any recommended vendor?", "author_fullname": "t2_hnxu1e2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Address verification and standardization tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16p1smy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1695359860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bunch of US/Non US addresses which I need to standardize according to USPS format. Can you guys recommend me best way to do it.  Is there any Python package that I can rely?&lt;br/&gt;\nOr Is there any paid/free third party endpoint where I can make a call to validate.  Google gave me &lt;a href=\"https://www.smarty.com/\"&gt;https://www.smarty.com/&lt;/a&gt; but I am not sure about other. Do you guys have any recommended vendor?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/59Y6KqC_f0DyQAhUrETEMD_apwihVMdNkw1bO_aRgyk.jpg?auto=webp&amp;s=5633dd3efd6979a9f065870210ba32bdb450edaf", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/59Y6KqC_f0DyQAhUrETEMD_apwihVMdNkw1bO_aRgyk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec1290b11636f849df11bcd2a9574db1d2de71ee", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/59Y6KqC_f0DyQAhUrETEMD_apwihVMdNkw1bO_aRgyk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c44367f44736bde57c7cf902bf409d31522ea58", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/59Y6KqC_f0DyQAhUrETEMD_apwihVMdNkw1bO_aRgyk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d6307f712ef2da9365026f5339c461ddbf092005", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/59Y6KqC_f0DyQAhUrETEMD_apwihVMdNkw1bO_aRgyk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fdfeaaa5bb4f017311064d21d8af2f904255001b", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/59Y6KqC_f0DyQAhUrETEMD_apwihVMdNkw1bO_aRgyk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a4249baf92f99963d4f1ec5e66bf2c47be2a5579", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/59Y6KqC_f0DyQAhUrETEMD_apwihVMdNkw1bO_aRgyk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=837281c129c8a69e452296dea9ef616ba85f177c", "width": 1080, "height": 567}], "variants": {}, "id": "RgGgH5XSBWSNjWbkX2NvcezqdVDW9PhVpc-BnehunSc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16p1smy", "is_robot_indexable": true, "report_reasons": null, "author": "boogie_woogie_100", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p1smy/address_verification_and_standardization_tools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16p1smy/address_verification_and_standardization_tools/", "subreddit_subscribers": 129860, "created_utc": 1695359860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, i was hired as a director of data engineering 6 months ago.  The issue that I am having is that my company does not give performance reviews or allow for negative feedback.  No call, no shows are constant. Some people on my team will no call, no show for multiple days in a row.  One guy admitted to calling in via his cellphone and not being by his computer...for the entire MONTH of august\n\nI have no mechanism to stop this.  This is proven by the fact that one of my employees has reputation of this and has been passed to 3 teams and is known as the departments \"problem employee\". she has been here 5 years and my manager says he hasnt seen her do a thing.  She is also my database admin.  New hire needs access to the database? too bad lol.\n\n&amp;#x200B;\n\nBasically, I have the job title and I have the pay. Its a big company, but it has a reputation for this.  Its in the advertising industry and when i posted in the r/advertising sub. I got 100 replies with 8 people wanting to quit the exact same company due to the same thing.\n\n&amp;#x200B;\n\nI have a contract job lined up.  At a MASSIVE american company.  I did the math and i will net out 5k ahead in the contract job after taxes, insurances, and loss of 401k match.\n\n&amp;#x200B;\n\nI am debating leaving the flashy job title at a big company for just a contract data engineer job though. It will break up my resume. however, it does open the door of me being able to go contract route and be independent.\n\nWhat are your thoughts?   I feel like im babysitting with no call, no shows.  I dont care that they arent doing work to be honest, i only really care at this point that im always having to argue with people about attending meetings lol.\n\nthe main downside is that if i roughed this job out for like a year or two, it would look great on my resume.\n\nthoughts?\n\n&amp;#x200B;", "author_fullname": "t2_vnvmwnbl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leaving my corporate director job for a contract?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16pifom", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1695410057.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695409341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, i was hired as a director of data engineering 6 months ago.  The issue that I am having is that my company does not give performance reviews or allow for negative feedback.  No call, no shows are constant. Some people on my team will no call, no show for multiple days in a row.  One guy admitted to calling in via his cellphone and not being by his computer...for the entire MONTH of august&lt;/p&gt;\n\n&lt;p&gt;I have no mechanism to stop this.  This is proven by the fact that one of my employees has reputation of this and has been passed to 3 teams and is known as the departments &amp;quot;problem employee&amp;quot;. she has been here 5 years and my manager says he hasnt seen her do a thing.  She is also my database admin.  New hire needs access to the database? too bad lol.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Basically, I have the job title and I have the pay. Its a big company, but it has a reputation for this.  Its in the advertising industry and when i posted in the &lt;a href=\"/r/advertising\"&gt;r/advertising&lt;/a&gt; sub. I got 100 replies with 8 people wanting to quit the exact same company due to the same thing.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have a contract job lined up.  At a MASSIVE american company.  I did the math and i will net out 5k ahead in the contract job after taxes, insurances, and loss of 401k match.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am debating leaving the flashy job title at a big company for just a contract data engineer job though. It will break up my resume. however, it does open the door of me being able to go contract route and be independent.&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts?   I feel like im babysitting with no call, no shows.  I dont care that they arent doing work to be honest, i only really care at this point that im always having to argue with people about attending meetings lol.&lt;/p&gt;\n\n&lt;p&gt;the main downside is that if i roughed this job out for like a year or two, it would look great on my resume.&lt;/p&gt;\n\n&lt;p&gt;thoughts?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16pifom", "is_robot_indexable": true, "report_reasons": null, "author": "Inevitable-Quality15", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16pifom/leaving_my_corporate_director_job_for_a_contract/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16pifom/leaving_my_corporate_director_job_for_a_contract/", "subreddit_subscribers": 129860, "created_utc": 1695409341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, i was hired as a director of data engineering 6 months ago.  The issue that I am having is that my company does not give performance reviews or allow for negative feedback.  No call, no shows are constant. Some people on my team will no call, no show for multiple days in a row.  \n\nI have no mechanism to stop this.  This is proven by the fact that one of my employees has reputation of this and has been passed to 3 teams and is known as the departments \"problem employee\". she has been here 5 years and my manager says he hasnt seen her do a thing.  She is also my database admin.  New hire needs access to the database? too bad lol.\n\n&amp;#x200B;\n\nBasically, I have the job title and I have the pay. Its a big company, but it has a reputation for this.  Its in the advertising industry and when i posted in the r/advertising sub. I got 100 replies with 8 people wanting to quit the exact same company due to the same thing.\n\n&amp;#x200B;\n\nI have a contract job lined up.  At a MASSIVE american company.  I did the math and i will net out 5k ahead in the contract job after taxes, insurances, and loss of 401k match.  \n\n&amp;#x200B;\n\nI am debating leaving the flashy job title at a big company for just a contract data engineer job though. It will break up my resume. however, it does open the door of me being able to go contract route and be independent. \n\nWhat are your thoughts?   I feel like im babysitting with no call, no shows.  I dont care that they arent doing work to be honest, i only really care at this point that im always having to argue with people about attending meetings lol.\n\nthe main downside is that if i roughed this job out for like a year or two, it would look great on my resume.\n\nthoughts?\n\n&amp;#x200B;", "author_fullname": "t2_vnvmwnbl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Leaving my corporate director job for a contract?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16pifnz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695409339.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, i was hired as a director of data engineering 6 months ago.  The issue that I am having is that my company does not give performance reviews or allow for negative feedback.  No call, no shows are constant. Some people on my team will no call, no show for multiple days in a row.  &lt;/p&gt;\n\n&lt;p&gt;I have no mechanism to stop this.  This is proven by the fact that one of my employees has reputation of this and has been passed to 3 teams and is known as the departments &amp;quot;problem employee&amp;quot;. she has been here 5 years and my manager says he hasnt seen her do a thing.  She is also my database admin.  New hire needs access to the database? too bad lol.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Basically, I have the job title and I have the pay. Its a big company, but it has a reputation for this.  Its in the advertising industry and when i posted in the &lt;a href=\"/r/advertising\"&gt;r/advertising&lt;/a&gt; sub. I got 100 replies with 8 people wanting to quit the exact same company due to the same thing.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have a contract job lined up.  At a MASSIVE american company.  I did the math and i will net out 5k ahead in the contract job after taxes, insurances, and loss of 401k match.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am debating leaving the flashy job title at a big company for just a contract data engineer job though. It will break up my resume. however, it does open the door of me being able to go contract route and be independent. &lt;/p&gt;\n\n&lt;p&gt;What are your thoughts?   I feel like im babysitting with no call, no shows.  I dont care that they arent doing work to be honest, i only really care at this point that im always having to argue with people about attending meetings lol.&lt;/p&gt;\n\n&lt;p&gt;the main downside is that if i roughed this job out for like a year or two, it would look great on my resume.&lt;/p&gt;\n\n&lt;p&gt;thoughts?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16pifnz", "is_robot_indexable": true, "report_reasons": null, "author": "Inevitable-Quality15", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16pifnz/leaving_my_corporate_director_job_for_a_contract/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16pifnz/leaving_my_corporate_director_job_for_a_contract/", "subreddit_subscribers": 129860, "created_utc": 1695409339.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Jupyter - IOPub data rate exceeded\n\nI\u2019m returning a load of JSON data and just as I have got my code to the points where its returning a load of data I get this error message using Jupyter Notebooks in Anaconda:\n \nIOPub data rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_data_rate_limit`.\n \nCurrent values:\nNotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\nThe environment is windows 11, using anaconda and jupyter notebooks. I\u2019ve tried looking for the jupyter config file but I\u2019m having difficultly finding it. I\u2019m returning 32 pages of 1000 records by REST API\n\nI\u2019ve seen this issue posted around the web and just wondered if anyone had a good fix for it? Frankly I\u2019m considering using VSCode instead as I figure it\u2019s a little more robust when it comes to dealing with relatively \u2018large\u2019 datasets\n\nAny advice would be very much appreciated", "author_fullname": "t2_hg12i599c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jupyter - IOPub data rate exceeded", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16pgd9m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695404218.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Jupyter - IOPub data rate exceeded&lt;/p&gt;\n\n&lt;p&gt;I\u2019m returning a load of JSON data and just as I have got my code to the points where its returning a load of data I get this error message using Jupyter Notebooks in Anaconda:&lt;/p&gt;\n\n&lt;p&gt;IOPub data rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n&lt;code&gt;--NotebookApp.iopub_data_rate_limit&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;Current values:\nNotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\nNotebookApp.rate_limit_window=3.0 (secs)&lt;/p&gt;\n\n&lt;p&gt;The environment is windows 11, using anaconda and jupyter notebooks. I\u2019ve tried looking for the jupyter config file but I\u2019m having difficultly finding it. I\u2019m returning 32 pages of 1000 records by REST API&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve seen this issue posted around the web and just wondered if anyone had a good fix for it? Frankly I\u2019m considering using VSCode instead as I figure it\u2019s a little more robust when it comes to dealing with relatively \u2018large\u2019 datasets&lt;/p&gt;\n\n&lt;p&gt;Any advice would be very much appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16pgd9m", "is_robot_indexable": true, "report_reasons": null, "author": "BumblyWurzle", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16pgd9m/jupyter_iopub_data_rate_exceeded/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16pgd9m/jupyter_iopub_data_rate_exceeded/", "subreddit_subscribers": 129860, "created_utc": 1695404218.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview with Timothy Sehn - Founder and CEO at DoltHub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_16p74k2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jL6LV9Dwh8e7lBY7D9sRj6_2hgi-O5lIf7OMtBIjyoM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1695379900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/hubertdulay/p/interview-with-timothy-sehn-founder?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pR25QgqElDsC75OMmvtK1nhHrEo37l35RzB4CisfPgw.jpg?auto=webp&amp;s=15db4847973a77499417be19c32ad8665d2c8e56", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/pR25QgqElDsC75OMmvtK1nhHrEo37l35RzB4CisfPgw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0e820eeece573e962d167aec961df1cfe51f29b4", "width": 108, "height": 108}], "variants": {}, "id": "nOZdT6kbraMnqTQhVbWj-y44qnThxTM0UF0oWJQpDW0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16p74k2", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p74k2/interview_with_timothy_sehn_founder_and_ceo_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/hubertdulay/p/interview-with-timothy-sehn-founder?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 129860, "created_utc": 1695379900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, \n\nI am looking for advise /reassurance on how to change jobs into a Data Engineering role within Europe. \n\nI have worked in marketing for the last 4 years, but have been hating it. In my roles, I have been gravitating towards data and tech more than the marketing elements. Recently, i was made redundant due to the company collapsing. So, I am taking this opportunity to switch. I looked into bootcamps, but I can't really afford the price of \u20ac7,000. I can probably pay about \u20ac1,000 for learning etc (gotta keep bread on the table). \n\n\nI have taken some courses in the past in python. I am not versed in object oriented programming, but have a very good understanding of the fundamentals and have created a few NLP projects. And I also have a very low level understanding of SQL and mongoDB.\n\nI am wondering if anyone else has also switched careers in the European zone and what your experience was in changing? If there are books, courses or certs that would help the switch?\n\nAlso, Is it in 2023 a bad time to change careers? (I keep being told by my friends that it's the wrong time ) \ud83d\ude2d\n\nAlso a bit off topic, but would a scrum cert benefit the role?\n\n\nAny help would be appreciated \ud83d\udc4d", "author_fullname": "t2_7lu47gxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is A European Role Change To DE hard?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16p5t70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695375237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I am looking for advise /reassurance on how to change jobs into a Data Engineering role within Europe. &lt;/p&gt;\n\n&lt;p&gt;I have worked in marketing for the last 4 years, but have been hating it. In my roles, I have been gravitating towards data and tech more than the marketing elements. Recently, i was made redundant due to the company collapsing. So, I am taking this opportunity to switch. I looked into bootcamps, but I can&amp;#39;t really afford the price of \u20ac7,000. I can probably pay about \u20ac1,000 for learning etc (gotta keep bread on the table). &lt;/p&gt;\n\n&lt;p&gt;I have taken some courses in the past in python. I am not versed in object oriented programming, but have a very good understanding of the fundamentals and have created a few NLP projects. And I also have a very low level understanding of SQL and mongoDB.&lt;/p&gt;\n\n&lt;p&gt;I am wondering if anyone else has also switched careers in the European zone and what your experience was in changing? If there are books, courses or certs that would help the switch?&lt;/p&gt;\n\n&lt;p&gt;Also, Is it in 2023 a bad time to change careers? (I keep being told by my friends that it&amp;#39;s the wrong time ) \ud83d\ude2d&lt;/p&gt;\n\n&lt;p&gt;Also a bit off topic, but would a scrum cert benefit the role?&lt;/p&gt;\n\n&lt;p&gt;Any help would be appreciated \ud83d\udc4d&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16p5t70", "is_robot_indexable": true, "report_reasons": null, "author": "Representative_Two37", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p5t70/is_a_european_role_change_to_de_hard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16p5t70/is_a_european_role_change_to_de_hard/", "subreddit_subscribers": 129860, "created_utc": 1695375237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, \nCould you guys please share some good YouTube channels to learn SQL and any visualization tool?", "author_fullname": "t2_iq9pgpb1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "You tube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16pdnzq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695397510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, \nCould you guys please share some good YouTube channels to learn SQL and any visualization tool?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16pdnzq", "is_robot_indexable": true, "report_reasons": null, "author": "Witty_Chain_2784", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16pdnzq/you_tube/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16pdnzq/you_tube/", "subreddit_subscribers": 129860, "created_utc": 1695397510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm currently working for a company where there pipelines are hosted on Google Cloud Run in a Flask application and orchestrated via Airflow. This model already existed when I joined, but it doesn't seem ideal to me.  Some of these scripts are very complex and use a lot of selenium to collect data.  Others are simpler pipelines. What do you recommend, refactor and move everything to Airflow or is there a better solution?", "author_fullname": "t2_96jab4in", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to host my pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16p6bjh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695377099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently working for a company where there pipelines are hosted on Google Cloud Run in a Flask application and orchestrated via Airflow. This model already existed when I joined, but it doesn&amp;#39;t seem ideal to me.  Some of these scripts are very complex and use a lot of selenium to collect data.  Others are simpler pipelines. What do you recommend, refactor and move everything to Airflow or is there a better solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16p6bjh", "is_robot_indexable": true, "report_reasons": null, "author": "T0ny_Corleone", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p6bjh/where_to_host_my_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16p6bjh/where_to_host_my_pipelines/", "subreddit_subscribers": 129860, "created_utc": 1695377099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "https://reddit.com/r/dataengineering/s/ZigMuAZRPP\n\nIn what order do you recommend acquiring the skills?", "author_fullname": "t2_jpnf1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Follow up question to the 80/20 Pareto skills question.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16p5zwo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1695375932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://reddit.com/r/dataengineering/s/ZigMuAZRPP\"&gt;https://reddit.com/r/dataengineering/s/ZigMuAZRPP&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;In what order do you recommend acquiring the skills?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16p5zwo", "is_robot_indexable": true, "report_reasons": null, "author": "kiwifruta", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16p5zwo/follow_up_question_to_the_8020_pareto_skills/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16p5zwo/follow_up_question_to_the_8020_pareto_skills/", "subreddit_subscribers": 129860, "created_utc": 1695375932.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}