{"kind": "Listing", "data": {"after": "t3_16bduox", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in a DE role but find myself doing about 99% of my job in SQL. I\u2019m building out dim tables and scripting the stores procs needed for the ETL. I rarely use any python and when I do it\u2019s to throw my stored proc into a really simple DAG and schedule it. \n\nMost of our data comes into a GCP bucket and I\u2019m just pulling that data from a external table.\n\nI just don\u2019t seems to have a strong use case to use python in my day to day.", "author_fullname": "t2_5ukitegd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ok to not really use any python as a DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16b3k7m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 59, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 59, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693955517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in a DE role but find myself doing about 99% of my job in SQL. I\u2019m building out dim tables and scripting the stores procs needed for the ETL. I rarely use any python and when I do it\u2019s to throw my stored proc into a really simple DAG and schedule it. &lt;/p&gt;\n\n&lt;p&gt;Most of our data comes into a GCP bucket and I\u2019m just pulling that data from a external table.&lt;/p&gt;\n\n&lt;p&gt;I just don\u2019t seems to have a strong use case to use python in my day to day.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16b3k7m", "is_robot_indexable": true, "report_reasons": null, "author": "burningburnerbern", "discussion_type": null, "num_comments": 70, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b3k7m/ok_to_not_really_use_any_python_as_a_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16b3k7m/ok_to_not_really_use_any_python_as_a_de/", "subreddit_subscribers": 127099, "created_utc": 1693955517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a postgres table with ~500M records on 20 columns. The table is updated / created from a spark job which use a parquet and load it to postgres. Every day, I get a new parquet file with 500M, but among all records, only 5M are new, and 5M disappear. At the moment, I overwrite all the table, but this is really long. I guess this is a classic issue and there must be a workaround to only append new rows are delete existing rows. My table does not have any primary key nor id column, but 3 columns together can form a unique id. What should I do to update my table in a better way ? (notice that I cant write the parquet file to a temp table because it would be at least as long as overwriting the table).\n\nAt the moment, the only solutions that seems to work is to create an id column with the 3 columns concatenated, index this column and use it to compare new data and old data to perform the delete. What is the common way to do ?", "author_fullname": "t2_qexqkrk6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "400M rows table : how to insert 4M and delete 4M rapidly without overwriting full table ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ayrif", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 56, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693944870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a postgres table with ~500M records on 20 columns. The table is updated / created from a spark job which use a parquet and load it to postgres. Every day, I get a new parquet file with 500M, but among all records, only 5M are new, and 5M disappear. At the moment, I overwrite all the table, but this is really long. I guess this is a classic issue and there must be a workaround to only append new rows are delete existing rows. My table does not have any primary key nor id column, but 3 columns together can form a unique id. What should I do to update my table in a better way ? (notice that I cant write the parquet file to a temp table because it would be at least as long as overwriting the table).&lt;/p&gt;\n\n&lt;p&gt;At the moment, the only solutions that seems to work is to create an id column with the 3 columns concatenated, index this column and use it to compare new data and old data to perform the delete. What is the common way to do ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ayrif", "is_robot_indexable": true, "report_reasons": null, "author": "165817566995", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ayrif/400m_rows_table_how_to_insert_4m_and_delete_4m/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ayrif/400m_rows_table_how_to_insert_4m_and_delete_4m/", "subreddit_subscribers": 127099, "created_utc": 1693944870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When a web dev wants to showcase their project, they can easily build one and deploy it in the cloud and a prospect employer can easily appreciate it by diving into the web application itself. While in data engineering, all I see to showcase a project is to create architectural diagrams, enrich README file (yes, in github), and creating online dashboards (a means to an end to highlight the \u201cdata\u201d part but how about the engineering part?). I mean, compared to web dev projects, DE projects will need the user/employer\u2019s time and effort to get a feel of the project.\n\nAny better way we can do to showcase our portfolio/projects?", "author_fullname": "t2_5owlarij", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Projects are Hard to Showcase than Web Development Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16be6f8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693987222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When a web dev wants to showcase their project, they can easily build one and deploy it in the cloud and a prospect employer can easily appreciate it by diving into the web application itself. While in data engineering, all I see to showcase a project is to create architectural diagrams, enrich README file (yes, in github), and creating online dashboards (a means to an end to highlight the \u201cdata\u201d part but how about the engineering part?). I mean, compared to web dev projects, DE projects will need the user/employer\u2019s time and effort to get a feel of the project.&lt;/p&gt;\n\n&lt;p&gt;Any better way we can do to showcase our portfolio/projects?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16be6f8", "is_robot_indexable": true, "report_reasons": null, "author": "_Dark_mage", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16be6f8/data_engineering_projects_are_hard_to_showcase/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16be6f8/data_engineering_projects_are_hard_to_showcase/", "subreddit_subscribers": 127099, "created_utc": 1693987222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nI just published my book, Cost-Effective Data Pipelines, with OReilly. I wanted to offer this community a free 30 day trial to check it out:\n\n[https://learning.oreilly.com/get-learning/?code=CEDP23](https://learning.oreilly.com/get-learning/?code=CEDP23)\n\nI wrote CEDP to give people access to a lot of hard earned, experiential advice I would have really appreciated not having to learn the hard way. \ud83d\ude05 I hope you find it helpful in your work!\n\nExamples for the coding portions of the book are available [on GitHub](https://github.com/gizm00/oreilly_dataeng_book)", "author_fullname": "t2_mi2w0ian", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New book - Cost-Effective Data Pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16b2ajv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693952575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;I just published my book, Cost-Effective Data Pipelines, with OReilly. I wanted to offer this community a free 30 day trial to check it out:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://learning.oreilly.com/get-learning/?code=CEDP23\"&gt;https://learning.oreilly.com/get-learning/?code=CEDP23&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I wrote CEDP to give people access to a lot of hard earned, experiential advice I would have really appreciated not having to learn the hard way. \ud83d\ude05 I hope you find it helpful in your work!&lt;/p&gt;\n\n&lt;p&gt;Examples for the coding portions of the book are available &lt;a href=\"https://github.com/gizm00/oreilly_dataeng_book\"&gt;on GitHub&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16b2ajv", "is_robot_indexable": true, "report_reasons": null, "author": "spruc3tip", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b2ajv/new_book_costeffective_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16b2ajv/new_book_costeffective_data_pipelines/", "subreddit_subscribers": 127099, "created_utc": 1693952575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a data analyst for just over 1 year now and have been working with DBT some python and lots of SQL. I changed careers from working in education for 3 years and definitely have imposter syndrome. \n\nAnytime I'm rushing because I feel pressured or am trying to meet a deadline or even just figure out what I'm doing with the ask from my superior I end up getting flustered and make small mistakes and there's times when it can snowball on me.\n\n I'm really trying to improve my quality of work (that was the area I was told to improve upon from my last performance review) and anytime I feel like I make progress there's another mistake, I get flustered with that feedback in the back of my mind and it snowballs.\n\n I get that learning by failure or failing forward is part of the job, but I'm having a rough two weeks rn. Anyone experience something similar, what advice do you have or am I just a lost cause?", "author_fullname": "t2_71weyfry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I keep making mistakes and feel like I'll never make it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16azftj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693946369.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a data analyst for just over 1 year now and have been working with DBT some python and lots of SQL. I changed careers from working in education for 3 years and definitely have imposter syndrome. &lt;/p&gt;\n\n&lt;p&gt;Anytime I&amp;#39;m rushing because I feel pressured or am trying to meet a deadline or even just figure out what I&amp;#39;m doing with the ask from my superior I end up getting flustered and make small mistakes and there&amp;#39;s times when it can snowball on me.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m really trying to improve my quality of work (that was the area I was told to improve upon from my last performance review) and anytime I feel like I make progress there&amp;#39;s another mistake, I get flustered with that feedback in the back of my mind and it snowballs.&lt;/p&gt;\n\n&lt;p&gt;I get that learning by failure or failing forward is part of the job, but I&amp;#39;m having a rough two weeks rn. Anyone experience something similar, what advice do you have or am I just a lost cause?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16azftj", "is_robot_indexable": true, "report_reasons": null, "author": "DrunkenWhaler136", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16azftj/i_keep_making_mistakes_and_feel_like_ill_never/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16azftj/i_keep_making_mistakes_and_feel_like_ill_never/", "subreddit_subscribers": 127099, "created_utc": 1693946369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, say you were an intermediate-level data engineer tasked with evaluating different cloud data warehouse platforms for a small company (integrating crm/ats/google analytics/finance data from 5-10 different sources to start), as well as a potential ETL tool/ job orchestrator if needed, and then building it out. Say you're also an okay python dev and a great sql dev. You'll also be building PowerBI reports on top off this dw and with all this development - you don't have a ton of time to wear the DBA hat. Say, you'll also be solo for probably 2 years or so before you start hiring a team around you.\n\nMy question is, if these are the rough parameters, what platform would you guys choose and why? / what would be the key things you would evaluate in said platforms?\n\nCurrently evaluating: Snowflake, Redshift, BQ, Azure, Databricks\n\nEdit: None of this data is being migrated from a pre-existing data warehouse and this is their first instance of a dw for analytics", "author_fullname": "t2_3ugqxzu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Building a cloud dw from scratch", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ay9jh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693943757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, say you were an intermediate-level data engineer tasked with evaluating different cloud data warehouse platforms for a small company (integrating crm/ats/google analytics/finance data from 5-10 different sources to start), as well as a potential ETL tool/ job orchestrator if needed, and then building it out. Say you&amp;#39;re also an okay python dev and a great sql dev. You&amp;#39;ll also be building PowerBI reports on top off this dw and with all this development - you don&amp;#39;t have a ton of time to wear the DBA hat. Say, you&amp;#39;ll also be solo for probably 2 years or so before you start hiring a team around you.&lt;/p&gt;\n\n&lt;p&gt;My question is, if these are the rough parameters, what platform would you guys choose and why? / what would be the key things you would evaluate in said platforms?&lt;/p&gt;\n\n&lt;p&gt;Currently evaluating: Snowflake, Redshift, BQ, Azure, Databricks&lt;/p&gt;\n\n&lt;p&gt;Edit: None of this data is being migrated from a pre-existing data warehouse and this is their first instance of a dw for analytics&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ay9jh", "is_robot_indexable": true, "report_reasons": null, "author": "Casdom33", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ay9jh/building_a_cloud_dw_from_scratch/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ay9jh/building_a_cloud_dw_from_scratch/", "subreddit_subscribers": 127099, "created_utc": 1693943757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been banging my head against the wall for two days, trying to get formulas to pick up column names, which seemed to have the right data type.\n\nThey came with n dashes instead of hyphens!!!!", "author_fullname": "t2_gs67ogqx6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It\u2019s an n-dash!!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bl4y2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694008960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been banging my head against the wall for two days, trying to get formulas to pick up column names, which seemed to have the right data type.&lt;/p&gt;\n\n&lt;p&gt;They came with n dashes instead of hyphens!!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16bl4y2", "is_robot_indexable": true, "report_reasons": null, "author": "LittleBiggle", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bl4y2/its_an_ndash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bl4y2/its_an_ndash/", "subreddit_subscribers": 127099, "created_utc": 1694008960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Passed with a 716 lol just had to tell someone. \n\nStudied for about 7 days 2-3 hours a day using the a cloud guru course (free since it was thru my job) \n\nWent thru the whole course and then ran the practice exams till I only got 90% or greater 3 times in a row. (Note: absolutely none of the questions from the practice exam were on the real test) \n\nI also built a project by following a YT tutorial end to end before even starting the course tes so that kind of solidified a lot of the concepts before hand.\n\nGood luck if you have it scheduled. LFG!", "author_fullname": "t2_22q9pua0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DP-900 PASSED!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16b1zri", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693951901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Passed with a 716 lol just had to tell someone. &lt;/p&gt;\n\n&lt;p&gt;Studied for about 7 days 2-3 hours a day using the a cloud guru course (free since it was thru my job) &lt;/p&gt;\n\n&lt;p&gt;Went thru the whole course and then ran the practice exams till I only got 90% or greater 3 times in a row. (Note: absolutely none of the questions from the practice exam were on the real test) &lt;/p&gt;\n\n&lt;p&gt;I also built a project by following a YT tutorial end to end before even starting the course tes so that kind of solidified a lot of the concepts before hand.&lt;/p&gt;\n\n&lt;p&gt;Good luck if you have it scheduled. LFG!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16b1zri", "is_robot_indexable": true, "report_reasons": null, "author": "PoloParachutes", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b1zri/dp900_passed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16b1zri/dp900_passed/", "subreddit_subscribers": 127099, "created_utc": 1693951901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, just finished a personal project and I think it could be useful for someone over here.\n\nIt\u2019s called Lasagna.\n\nhttps://github.com/gmrqs/lasagna\n\nIt\u2019s essentially a interactive development environment for PySpark, specially if you\u2019re into open table formats.\n\nIt\u2019s a docker compose template that creates the following: \n\n- Jupyter Lab instance for interactive development along with some useful extensions and magic commands (to provide a more databricks-like experience)\n- MinIO to serve as object store\n- A standalone spark cluster (1 driver + 2 workers);\n- A standalone hive metastore instance (so you can persist tables between sessions without relying in path-based matastores);\n- A Trino instance for data virtualization;\n- single-node kafka instance for small streaming simulations.\n\nThat\u2019s it, hope you like it, check the repository, check the docs and you can reach me anytime in reddit or in github.\n\ncheers", "author_fullname": "t2_5fmit0v9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lasagna - A PySpark development environment + a lot of stuff", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "name": "t3_16b1mzb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pUUE7UqQ7FsX7LELd7iHyBYTjRWn3rMR1_st2dWI5LI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693951115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, just finished a personal project and I think it could be useful for someone over here.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s called Lasagna.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/gmrqs/lasagna\"&gt;https://github.com/gmrqs/lasagna&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It\u2019s essentially a interactive development environment for PySpark, specially if you\u2019re into open table formats.&lt;/p&gt;\n\n&lt;p&gt;It\u2019s a docker compose template that creates the following: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Jupyter Lab instance for interactive development along with some useful extensions and magic commands (to provide a more databricks-like experience)&lt;/li&gt;\n&lt;li&gt;MinIO to serve as object store&lt;/li&gt;\n&lt;li&gt;A standalone spark cluster (1 driver + 2 workers);&lt;/li&gt;\n&lt;li&gt;A standalone hive metastore instance (so you can persist tables between sessions without relying in path-based matastores);&lt;/li&gt;\n&lt;li&gt;A Trino instance for data virtualization;&lt;/li&gt;\n&lt;li&gt;single-node kafka instance for small streaming simulations.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;That\u2019s it, hope you like it, check the repository, check the docs and you can reach me anytime in reddit or in github.&lt;/p&gt;\n\n&lt;p&gt;cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tqu0j81deimb1.gif", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tqu0j81deimb1.gif?format=png8&amp;s=f9884defeaa66179908c37697414b3f49383cfeb", "width": 828, "height": 597}, "resolutions": [{"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=029d31be0b99c55a4872e24b3969c65d4b131f69", "width": 108, "height": 77}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=418428d754f3b4ed1192685c8c22ece451669dce", "width": 216, "height": 155}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=d6c8282ccf28530f2dcfb916f8c92013cd0702a7", "width": 320, "height": 230}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=5e454441428ee43edb80701832ee04033ffac342", "width": 640, "height": 461}], "variants": {"gif": {"source": {"url": "https://preview.redd.it/tqu0j81deimb1.gif?s=d7ff727ac8331ef71915718abd4f45331325cec1", "width": 828, "height": 597}, "resolutions": [{"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=108&amp;crop=smart&amp;s=d1460fa6a0f3a678327755eb9609ff7a89ade9d8", "width": 108, "height": 77}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=216&amp;crop=smart&amp;s=ab1bb12f512b89db4dbd1eba427075fe546cd081", "width": 216, "height": 155}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=320&amp;crop=smart&amp;s=befb24d70abbc0dd71b05d285bbdec6fcd74d804", "width": 320, "height": 230}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=640&amp;crop=smart&amp;s=a6b0c126f785cbe9847adeebe004edaffdf05207", "width": 640, "height": 461}]}, "mp4": {"source": {"url": "https://preview.redd.it/tqu0j81deimb1.gif?format=mp4&amp;s=f5a2e9400d08910290876833d347875e0248d83e", "width": 828, "height": 597}, "resolutions": [{"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=108&amp;format=mp4&amp;s=474ea2a212d13d235580514dd39c7c049f3fb0f7", "width": 108, "height": 77}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=216&amp;format=mp4&amp;s=7e0ea4a17cdacbd474693af56b3360d8ed6a619c", "width": 216, "height": 155}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=320&amp;format=mp4&amp;s=e34d20fee9b7f244cc8c9bc2a91cb3112f6a12f0", "width": 320, "height": 230}, {"url": "https://preview.redd.it/tqu0j81deimb1.gif?width=640&amp;format=mp4&amp;s=1897608647f53297d6285f55c61a831334dcb597", "width": 640, "height": 461}]}}, "id": "5a0Y9mdiqI9-fwBGhi5vP4qv06x2vgPvmj2n6Ds7hQk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16b1mzb", "is_robot_indexable": true, "report_reasons": null, "author": "gabbom_XCII", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b1mzb/lasagna_a_pyspark_development_environment_a_lot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tqu0j81deimb1.gif", "subreddit_subscribers": 127099, "created_utc": 1693951115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_9ua96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Birmingham City Council goes under after Oracle disaster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_16bk4yo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/vcZxnOpZqHgDRaDOx7DN_lBgQOc42wHJleKZUPorfu4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694006412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theregister.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.theregister.com/2023/09/05/birmingham_city_council_oracle/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YQIdF1Voe-1vS2ML4At80bSKyOhPwit0rVQ9yRvZJ5Q.jpg?auto=webp&amp;s=0a305e828a30a6f0c71c29fe7128261795b84be7", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/YQIdF1Voe-1vS2ML4At80bSKyOhPwit0rVQ9yRvZJ5Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=da6738dd559dcd27f5c6395b87b24e35f9f0f90b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/YQIdF1Voe-1vS2ML4At80bSKyOhPwit0rVQ9yRvZJ5Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e13687e35641b792bc1b4618600421e2f2219c07", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/YQIdF1Voe-1vS2ML4At80bSKyOhPwit0rVQ9yRvZJ5Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2870609fd4788bdd796d62d476bd37c54e234394", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/YQIdF1Voe-1vS2ML4At80bSKyOhPwit0rVQ9yRvZJ5Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=762a32e0a6fbe457317ae2f4ca52c22a5139c69f", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/YQIdF1Voe-1vS2ML4At80bSKyOhPwit0rVQ9yRvZJ5Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=db21c86d150204fb0faf5d99a1319f2829ee8638", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/YQIdF1Voe-1vS2ML4At80bSKyOhPwit0rVQ9yRvZJ5Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fff2e47b3400ab0679156b32901cef4a6faa7a26", "width": 1080, "height": 565}], "variants": {}, "id": "x_FLdS7YQetbIrTzI0wUDbZvSjWYi10bdLE8R6sRSNA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16bk4yo", "is_robot_indexable": true, "report_reasons": null, "author": "uluvboobs", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bk4yo/birmingham_city_council_goes_under_after_oracle/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.theregister.com/2023/09/05/birmingham_city_council_oracle/", "subreddit_subscribers": 127099, "created_utc": 1694006412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know that data engineering tends to be more focused on the warehousing and pipeline side of things, but recently, being asked in a couple of interviews that I've been in about maintaining indexes of tables, creation and set up of new tables, SSRS, almost like they are looking for a database analyst or a DBA. I was wondering if anyone has any experience with that because index maintenance can be very different I think than what a typical data engineer would do, wouldn't it?", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have any resources on index maintenance, or DBA related stuff?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bi7jz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694001190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that data engineering tends to be more focused on the warehousing and pipeline side of things, but recently, being asked in a couple of interviews that I&amp;#39;ve been in about maintaining indexes of tables, creation and set up of new tables, SSRS, almost like they are looking for a database analyst or a DBA. I was wondering if anyone has any experience with that because index maintenance can be very different I think than what a typical data engineer would do, wouldn&amp;#39;t it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16bi7jz", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bi7jz/does_anyone_have_any_resources_on_index/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bi7jz/does_anyone_have_any_resources_on_index/", "subreddit_subscribers": 127099, "created_utc": 1694001190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The easy and fast way to solve dependency conflicts in Apache Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16blbc8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/mWQa5mWpMZ4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The ExternalPythonOperator: No more dependency conflicts in Apache Airflow\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The ExternalPythonOperator: No more dependency conflicts in Apache Airflow", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/mWQa5mWpMZ4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The ExternalPythonOperator: No more dependency conflicts in Apache Airflow\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/mWQa5mWpMZ4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/mWQa5mWpMZ4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The ExternalPythonOperator: No more dependency conflicts in Apache Airflow\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16blbc8", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bJm4imjkjDioNZVCTqP-RQCbA_q0pm8XRb8UonCTM_g.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1694009405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/mWQa5mWpMZ4", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/z5G-zx8FO9pgBzwwPiY1Y_SoPszozeKmAtE1VO8JAtw.jpg?auto=webp&amp;s=857265f0cde73937923b860f20e1e9003df37b1f", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/z5G-zx8FO9pgBzwwPiY1Y_SoPszozeKmAtE1VO8JAtw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=69f35dfaed80eada77c1100640d189b09527c215", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/z5G-zx8FO9pgBzwwPiY1Y_SoPszozeKmAtE1VO8JAtw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a4501a0079078a5aa7f658970dada1dbe302ae4e", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/z5G-zx8FO9pgBzwwPiY1Y_SoPszozeKmAtE1VO8JAtw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f2c06db25507e1a6c69537ca517896e605c8fc67", "width": 320, "height": 240}], "variants": {}, "id": "NUN2weHdZfK2_NtrA-azV1PCNn7Os1j7nYZCgBI9iq0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16blbc8", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16blbc8/the_easy_and_fast_way_to_solve_dependency/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/mWQa5mWpMZ4", "subreddit_subscribers": 127099, "created_utc": 1694009405.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "The ExternalPythonOperator: No more dependency conflicts in Apache Airflow", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/mWQa5mWpMZ4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"The ExternalPythonOperator: No more dependency conflicts in Apache Airflow\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/mWQa5mWpMZ4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TLDR: For those of you who use airflow to coordinate data pipelines between clouds, what are some patterns you support and what might I stay away from? \n\nHey all,\nI've been doing some orchestrator deep dives for an upcoming long haul data lake/data warehousing initiative and have evaluated a few technologies thusfar, ultimately settling on airflow for the PoC use case thanks to the tool already being in use by the enterprise in other teams. Although I was *extremely* intrigued by Dagster, the talent pool and larger code base to draw from internally made airflow the more attractive option in the near term at least. However, the issue I am facing for the organization is that the other teams that currently use airflow have had the luxury of being single cloud teams, AWS or Azure respective to where their data resides. In contrast, this project will require us to handle coordination across both providers. \n\nAs an example workflow to go off, imagine a json file landing in s3 and a different json file landing in adls from a different source at the same time. I'll need to join this data together down the line in a cloud data warehouse such as Snowflake or an extract of records from both sources. I would need to coordinate some data validity checks with great expectations or similar before promoting the data past the raw lake layer and materializing it in a columnar format such as parquet in the lake serving layer. Then, I'd need to do the insert to the data warehouse layer which may be in Azure or AWS. Is there enough IO and egress possible in such a workload that it would make sense to have both airflow coordination hubs live separately? Or would I want to create an endpoint to trigger jobs in another dag in the other instance? If the data generally lands in one cloud vs the other for serving, would this change your answer?\n\nMore generally, where do you keep your codebases and how do you fo cicd for your dags on azure vs aws? I'd imagine it must get complex if you separate the codebases to be cloud specific.\n\nLastly, is one managed airflow cloud offering better than the other? Should I just keep it as raw container deployment to kubernetes to stay cloud agnostic? Any strong opinions on other implementations such as Astronomer or other airflow SaaS offerings?\n\nAny thoughts would really help me eliminate some design choices as we start out, thanks for your insights as always.", "author_fullname": "t2_uqrd0850", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow Users: How do you best achieve cross-cloud deployment/orchestration?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16b76m5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693964790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: For those of you who use airflow to coordinate data pipelines between clouds, what are some patterns you support and what might I stay away from? &lt;/p&gt;\n\n&lt;p&gt;Hey all,\nI&amp;#39;ve been doing some orchestrator deep dives for an upcoming long haul data lake/data warehousing initiative and have evaluated a few technologies thusfar, ultimately settling on airflow for the PoC use case thanks to the tool already being in use by the enterprise in other teams. Although I was &lt;em&gt;extremely&lt;/em&gt; intrigued by Dagster, the talent pool and larger code base to draw from internally made airflow the more attractive option in the near term at least. However, the issue I am facing for the organization is that the other teams that currently use airflow have had the luxury of being single cloud teams, AWS or Azure respective to where their data resides. In contrast, this project will require us to handle coordination across both providers. &lt;/p&gt;\n\n&lt;p&gt;As an example workflow to go off, imagine a json file landing in s3 and a different json file landing in adls from a different source at the same time. I&amp;#39;ll need to join this data together down the line in a cloud data warehouse such as Snowflake or an extract of records from both sources. I would need to coordinate some data validity checks with great expectations or similar before promoting the data past the raw lake layer and materializing it in a columnar format such as parquet in the lake serving layer. Then, I&amp;#39;d need to do the insert to the data warehouse layer which may be in Azure or AWS. Is there enough IO and egress possible in such a workload that it would make sense to have both airflow coordination hubs live separately? Or would I want to create an endpoint to trigger jobs in another dag in the other instance? If the data generally lands in one cloud vs the other for serving, would this change your answer?&lt;/p&gt;\n\n&lt;p&gt;More generally, where do you keep your codebases and how do you fo cicd for your dags on azure vs aws? I&amp;#39;d imagine it must get complex if you separate the codebases to be cloud specific.&lt;/p&gt;\n\n&lt;p&gt;Lastly, is one managed airflow cloud offering better than the other? Should I just keep it as raw container deployment to kubernetes to stay cloud agnostic? Any strong opinions on other implementations such as Astronomer or other airflow SaaS offerings?&lt;/p&gt;\n\n&lt;p&gt;Any thoughts would really help me eliminate some design choices as we start out, thanks for your insights as always.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16b76m5", "is_robot_indexable": true, "report_reasons": null, "author": "IncognitoEmployee", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b76m5/airflow_users_how_do_you_best_achieve_crosscloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16b76m5/airflow_users_how_do_you_best_achieve_crosscloud/", "subreddit_subscribers": 127099, "created_utc": 1693964790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys, need help in what to learn now;\n I have around 4+ years of experience and have worked with snowflake, sql, python,( ssis and ssms (not in depth)) but now I am not sure what should i learn, like what can i learn along with this tech stack.\n\nCould you please help me with some learning path/guide.", "author_fullname": "t2_7qs0ir3r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to learn now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16axoov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693942459.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys, need help in what to learn now;\n I have around 4+ years of experience and have worked with snowflake, sql, python,( ssis and ssms (not in depth)) but now I am not sure what should i learn, like what can i learn along with this tech stack.&lt;/p&gt;\n\n&lt;p&gt;Could you please help me with some learning path/guide.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16axoov", "is_robot_indexable": true, "report_reasons": null, "author": "Own_Archer3356", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16axoov/what_to_learn_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16axoov/what_to_learn_now/", "subreddit_subscribers": 127099, "created_utc": 1693942459.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Here's my usecase.  \n\n* We have a highly concurrent transactional workload on our DBs.\n* Data in different DBs are related to each other in some way or the other and communication between DBs is done via APIs. \n* Right now, we perform CDC via AWS DMS and store an exact replica of all our dbs in a separate DB [lets call this master]. Due to the nature of our data we aren't able to capture/recreate PK/FK or indexes on the master db.\n* We've build 100's of dashboards and reports on top of this master DB. \n* We need a more performant system than our current master db for dashboarding purposes / application backend purposes   \n   \n\n\n\n\nHere's what I've tried so far.     \n\n*  Hybrid OLAP/OLTP solutions like CitusData -&gt; didn't work for us due to the extra management required to maintain the shards and more importantly the \"No foreign keys across distributed schemas.\" restriction. \n* Hydra DB [Link to Github](https://github.com/hydradatabase/hydra) -&gt; Worked well for aggregated query usecases but not for queries that build reports. Also, data insertion and updation is abyssmal on columnar dbs. \n* Clickhouse -&gt; loaded bulk data onto clickhouse and things work well but a large portion of the reports will have to be rebuilt.\n\n\nAny insights as to what I can do here?\n\n\nedit:   \nEnd Goal:   We need a more performant system than our current master db", "author_fullname": "t2_lrdo4bnz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CDC from postgres to postgres.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bf3a4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693993925.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693990633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Here&amp;#39;s my usecase.  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;We have a highly concurrent transactional workload on our DBs.&lt;/li&gt;\n&lt;li&gt;Data in different DBs are related to each other in some way or the other and communication between DBs is done via APIs. &lt;/li&gt;\n&lt;li&gt;Right now, we perform CDC via AWS DMS and store an exact replica of all our dbs in a separate DB [lets call this master]. Due to the nature of our data we aren&amp;#39;t able to capture/recreate PK/FK or indexes on the master db.&lt;/li&gt;\n&lt;li&gt;We&amp;#39;ve build 100&amp;#39;s of dashboards and reports on top of this master DB. &lt;/li&gt;\n&lt;li&gt;We need a more performant system than our current master db for dashboarding purposes / application backend purposes&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Here&amp;#39;s what I&amp;#39;ve tried so far.     &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt; Hybrid OLAP/OLTP solutions like CitusData -&amp;gt; didn&amp;#39;t work for us due to the extra management required to maintain the shards and more importantly the &amp;quot;No foreign keys across distributed schemas.&amp;quot; restriction. &lt;/li&gt;\n&lt;li&gt;Hydra DB &lt;a href=\"https://github.com/hydradatabase/hydra\"&gt;Link to Github&lt;/a&gt; -&amp;gt; Worked well for aggregated query usecases but not for queries that build reports. Also, data insertion and updation is abyssmal on columnar dbs. &lt;/li&gt;\n&lt;li&gt;Clickhouse -&amp;gt; loaded bulk data onto clickhouse and things work well but a large portion of the reports will have to be rebuilt.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any insights as to what I can do here?&lt;/p&gt;\n\n&lt;p&gt;edit:&lt;br/&gt;\nEnd Goal:   We need a more performant system than our current master db&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NAftzDs_QZTTYoNQDmOEcnmdBhfCsvMABzECAlBXz0E.jpg?auto=webp&amp;s=cb8fae1e4bd021364cb7d63509619278c16cdaa7", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/NAftzDs_QZTTYoNQDmOEcnmdBhfCsvMABzECAlBXz0E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8d5eca145b2c18ace24d22857718d5115f6be9d7", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/NAftzDs_QZTTYoNQDmOEcnmdBhfCsvMABzECAlBXz0E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b15c6918e67eeb0558b3a23d499f30e80e45e8a0", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/NAftzDs_QZTTYoNQDmOEcnmdBhfCsvMABzECAlBXz0E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cbb148b5b93ca592a12966cbe469585fd964cf36", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/NAftzDs_QZTTYoNQDmOEcnmdBhfCsvMABzECAlBXz0E.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=dc0b8db3fe878e6dc834a9e75fda707bd2be9838", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/NAftzDs_QZTTYoNQDmOEcnmdBhfCsvMABzECAlBXz0E.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0915cd9c9696aee370edbf6eebc38d87ab269cdd", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/NAftzDs_QZTTYoNQDmOEcnmdBhfCsvMABzECAlBXz0E.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b15ea48853321892d85e65756e3bb40060c90765", "width": 1080, "height": 540}], "variants": {}, "id": "j3a7KYMSc5BpKUsERA6h0wMphrco9B7kT4Uv5TEizKA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16bf3a4", "is_robot_indexable": true, "report_reasons": null, "author": "WhollyConfused96", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bf3a4/cdc_from_postgres_to_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bf3a4/cdc_from_postgres_to_postgres/", "subreddit_subscribers": 127099, "created_utc": 1693990633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm doing some data orchestration and have tried numerous approaches for data manipulation and querying. The most \"user-friendly\" I've found for moderate-sized data (up to a few 10s of GB per table) is Duckdb. I use parquet files with views over them to establish and maintain a schema. However, a significant downside of this approach is that the database allows only one writer at a time. The alternative I've been using is a :memory: database, but then I lose the visibility into the schema. An additional challenge is that with performant data orchestration, accessing a database file can be a devops challenge (eg., for multiple kubernetes jobs). Systems like Trino rely on external systems like a hive metadata catalog. How do you use duckdb to build a data warehouse/access a data lake, but avoid the single database living on disk challenges?  \n\n\nAs background, I'm a researcher and use this work to support my biomedical data science work. I'm not looking to build a production environment and want to support minimal infrastructure (within reason). ", "author_fullname": "t2_66wcvsmn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "With all the possibilities for storage, compute, and catalog separation, what works for you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bliex", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1694010136.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694009908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m doing some data orchestration and have tried numerous approaches for data manipulation and querying. The most &amp;quot;user-friendly&amp;quot; I&amp;#39;ve found for moderate-sized data (up to a few 10s of GB per table) is Duckdb. I use parquet files with views over them to establish and maintain a schema. However, a significant downside of this approach is that the database allows only one writer at a time. The alternative I&amp;#39;ve been using is a :memory: database, but then I lose the visibility into the schema. An additional challenge is that with performant data orchestration, accessing a database file can be a devops challenge (eg., for multiple kubernetes jobs). Systems like Trino rely on external systems like a hive metadata catalog. How do you use duckdb to build a data warehouse/access a data lake, but avoid the single database living on disk challenges?  &lt;/p&gt;\n\n&lt;p&gt;As background, I&amp;#39;m a researcher and use this work to support my biomedical data science work. I&amp;#39;m not looking to build a production environment and want to support minimal infrastructure (within reason). &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16bliex", "is_robot_indexable": true, "report_reasons": null, "author": "Snoo-56267", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bliex/with_all_the_possibilities_for_storage_compute/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bliex/with_all_the_possibilities_for_storage_compute/", "subreddit_subscribers": 127099, "created_utc": 1694009908.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, I have transitioned from an analyst to DE role over the last 4 years thanks to this amazing community and have been working as a DE (more of an analytics engineer) for around a year. My organization uses airflow on GKE. While working on a project recently, our team ran into some dependency problems and were recommended the use of KubernetesPodOperator. I dont know much about Kubernetes and want to learn it fast to at least get up and running with the operator first and then to learn more about kubernetes eventually. \n\n&amp;#x200B;\n\nHere is what I am trying to learn first: \n\n1. Hosting a container image on a private repo. \n2. Use this image in the podoperator. \n3. handling authentication to gcp so i can read from and write to bigquery tables.\n\nHow would you guys recommend to get up and running? Also I learn best via videos but I couldn't find something in video format around what I am trying to do.", "author_fullname": "t2_na539", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need resource recommendations for learning Kubernetes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bhwo5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694000263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I have transitioned from an analyst to DE role over the last 4 years thanks to this amazing community and have been working as a DE (more of an analytics engineer) for around a year. My organization uses airflow on GKE. While working on a project recently, our team ran into some dependency problems and were recommended the use of KubernetesPodOperator. I dont know much about Kubernetes and want to learn it fast to at least get up and running with the operator first and then to learn more about kubernetes eventually. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is what I am trying to learn first: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Hosting a container image on a private repo. &lt;/li&gt;\n&lt;li&gt;Use this image in the podoperator. &lt;/li&gt;\n&lt;li&gt;handling authentication to gcp so i can read from and write to bigquery tables.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;How would you guys recommend to get up and running? Also I learn best via videos but I couldn&amp;#39;t find something in video format around what I am trying to do.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16bhwo5", "is_robot_indexable": true, "report_reasons": null, "author": "acid4207", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bhwo5/need_resource_recommendations_for_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bhwo5/need_resource_recommendations_for_learning/", "subreddit_subscribers": 127099, "created_utc": 1694000263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Join for season 2 of the #TrueDataOps Podcast with Bob Muglia, formerly the Chief Executive Officer of Snowflake. We will cover his new book, The DataPreneurs (https://www.thedatapreneurs.com/), the new age of AI, and all things Data related! \n\nRSVP via LinkedIn Live - [https://www.linkedin.com/events/bobmugila-truedataopspodcastep-7085395129217269760/theater/](https://www.linkedin.com/events/bobmugila-truedataopspodcastep-7085395129217269760/theater/)\n\n[#TrueDataOps Podcast - Bob Muglia](https://preview.redd.it/2uur4rx3rimb1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=0ca15941f9458a3b339393e7316bd469e0134692)", "author_fullname": "t2_12li6zgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bob Muglia (Ex Snowflake CEO) - #TrueDataOps Podcast Ep.19", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 76, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2uur4rx3rimb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/2uur4rx3rimb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8d21ae9e2ddc33a750c613bdab30afdd35075139"}, {"y": 121, "x": 216, "u": "https://preview.redd.it/2uur4rx3rimb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=81b6d71953eb8276f4c5743ecc093aaa1d3c4c3f"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/2uur4rx3rimb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2997a49f3809009266a0f7ad482861536b0e79e"}, {"y": 360, "x": 640, "u": "https://preview.redd.it/2uur4rx3rimb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a72e3b6fecb7e6f4913474cebcdb6f817da1a21e"}, {"y": 540, "x": 960, "u": "https://preview.redd.it/2uur4rx3rimb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e87ce199af00ab6cc1b9bba523694069bac0f95d"}, {"y": 607, "x": 1080, "u": "https://preview.redd.it/2uur4rx3rimb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1c110eb5abf9fb4c6f0ac7bcf278b36ebafd5c2"}], "s": {"y": 900, "x": 1600, "u": "https://preview.redd.it/2uur4rx3rimb1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=0ca15941f9458a3b339393e7316bd469e0134692"}, "id": "2uur4rx3rimb1"}}, "name": "t3_16b3jjq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/58InnkA3WbrVCj3BZIGpEYIYDUlN7T1ZJr8tuU3axqs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1693955475.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Join for season 2 of the #TrueDataOps Podcast with Bob Muglia, formerly the Chief Executive Officer of Snowflake. We will cover his new book, The DataPreneurs (&lt;a href=\"https://www.thedatapreneurs.com/\"&gt;https://www.thedatapreneurs.com/&lt;/a&gt;), the new age of AI, and all things Data related! &lt;/p&gt;\n\n&lt;p&gt;RSVP via LinkedIn Live - &lt;a href=\"https://www.linkedin.com/events/bobmugila-truedataopspodcastep-7085395129217269760/theater/\"&gt;https://www.linkedin.com/events/bobmugila-truedataopspodcastep-7085395129217269760/theater/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2uur4rx3rimb1.png?width=1600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0ca15941f9458a3b339393e7316bd469e0134692\"&gt;#TrueDataOps Podcast - Bob Muglia&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vTru9LL2A6HmvxeDP56YGkiWud19_6vaUIV6aTIP7W8.jpg?auto=webp&amp;s=b847f4d4561d784bc5504344e1a94d587bd05af8", "width": 972, "height": 534}, "resolutions": [{"url": "https://external-preview.redd.it/vTru9LL2A6HmvxeDP56YGkiWud19_6vaUIV6aTIP7W8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8a868661a2f3cb34107398dfc5beb27265732895", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/vTru9LL2A6HmvxeDP56YGkiWud19_6vaUIV6aTIP7W8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d21d937457e41e4560e07026cdc45c9cbeb1f05a", "width": 216, "height": 118}, {"url": "https://external-preview.redd.it/vTru9LL2A6HmvxeDP56YGkiWud19_6vaUIV6aTIP7W8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=253bd866b12d8311b987df11d9d369e78a22864f", "width": 320, "height": 175}, {"url": "https://external-preview.redd.it/vTru9LL2A6HmvxeDP56YGkiWud19_6vaUIV6aTIP7W8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=66a30a53f3625613d8c9fd8bc752fd9449545d67", "width": 640, "height": 351}, {"url": "https://external-preview.redd.it/vTru9LL2A6HmvxeDP56YGkiWud19_6vaUIV6aTIP7W8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=afe802cee5f0bda3ca42aa29b4a080953ec1839c", "width": 960, "height": 527}], "variants": {}, "id": "0yKiW0Shi4BtF95uLveiAbO0hqnEy2jZ9SzigMFMWLQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16b3jjq", "is_robot_indexable": true, "report_reasons": null, "author": "Dkreig", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16b3jjq/bob_muglia_ex_snowflake_ceo_truedataops_podcast/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16b3jjq/bob_muglia_ex_snowflake_ceo_truedataops_podcast/", "subreddit_subscribers": 127099, "created_utc": 1693955475.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any better way to convert (my)SQL dump to parquet than spinning up fresh db instance, restoring the dump and then using something like pyarrow to query and store the data to parquet? We are getting sql dumps but would like to create a parquet for easier analysis", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL dump to parquet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16bqtnu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694022521.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any better way to convert (my)SQL dump to parquet than spinning up fresh db instance, restoring the dump and then using something like pyarrow to query and store the data to parquet? We are getting sql dumps but would like to create a parquet for easier analysis&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16bqtnu", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bqtnu/sql_dump_to_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bqtnu/sql_dump_to_parquet/", "subreddit_subscribers": 127099, "created_utc": 1694022521.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I regularly work with a variety of data sources and provide static plots to internal customers.  \n\nI'm familiar with tools like Plotly to create interactive html files, but this requires my handling of the data. I'd like to automate this a bit, but I'm not sure what tools are available for interactive plotting AND data selection. \n\nBasically, I have data that may come from \\*.sie files, \\*.blf, \\*.asc files, \\*.csv files, or other assorted data acquisition tools. Pretty much all of it is time series data.\n\nI think I'd like to create a web interface to view this, but I'm not sure what interactive tools exist to manipulate the channels. A single file may have 50 channels of data. \n\nItems that have crossed my mind:\n\n* An sql server with a database for each datafile. PowerBI to view?\n* Auto-generated web pages from Bokeh, but how do I get user selectable channels?\n* Jupyterhub/Jupyterlab notebooks? \n\n&amp;#x200B;\n\nWhat paid tools exist for engineering?\n\n* I've seen [Aqira](https://www.hbkworld.com/en/products/software/analysis-simulation/durability/aqira-standardize-global-engineering-processes) , but most tools seem to be standalone. \n\nFor reference, an idea of the data source might be a DAQ (data acquisition) tool like\n\n[https://astronovainc.com/our-businesses/test-measurement/](https://astronovainc.com/our-businesses/test-measurement/) \n\n&amp;#x200B;\n\nIf I'm posted in the wrong thread, my apologies. I'm just not really sure where to ask this.", "author_fullname": "t2_3si1p2jc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Providing interactive plots to internal customers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16bpt8i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694020198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I regularly work with a variety of data sources and provide static plots to internal customers.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m familiar with tools like Plotly to create interactive html files, but this requires my handling of the data. I&amp;#39;d like to automate this a bit, but I&amp;#39;m not sure what tools are available for interactive plotting AND data selection. &lt;/p&gt;\n\n&lt;p&gt;Basically, I have data that may come from *.sie files, *.blf, *.asc files, *.csv files, or other assorted data acquisition tools. Pretty much all of it is time series data.&lt;/p&gt;\n\n&lt;p&gt;I think I&amp;#39;d like to create a web interface to view this, but I&amp;#39;m not sure what interactive tools exist to manipulate the channels. A single file may have 50 channels of data. &lt;/p&gt;\n\n&lt;p&gt;Items that have crossed my mind:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;An sql server with a database for each datafile. PowerBI to view?&lt;/li&gt;\n&lt;li&gt;Auto-generated web pages from Bokeh, but how do I get user selectable channels?&lt;/li&gt;\n&lt;li&gt;Jupyterhub/Jupyterlab notebooks? &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What paid tools exist for engineering?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I&amp;#39;ve seen &lt;a href=\"https://www.hbkworld.com/en/products/software/analysis-simulation/durability/aqira-standardize-global-engineering-processes\"&gt;Aqira&lt;/a&gt; , but most tools seem to be standalone. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For reference, an idea of the data source might be a DAQ (data acquisition) tool like&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://astronovainc.com/our-businesses/test-measurement/\"&gt;https://astronovainc.com/our-businesses/test-measurement/&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If I&amp;#39;m posted in the wrong thread, my apologies. I&amp;#39;m just not really sure where to ask this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?auto=webp&amp;s=3a7ccc4fed70f5fe339e0cd18b0f298f562a0dfb", "width": 1200, "height": 645}, "resolutions": [{"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ed7e248fa443fbf4a40cf842d4a3550c1e9c4f2b", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d974297f87b1449299a9ff49a4fbe2b7c19cad3", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=71b78ff8bd0bdf95c43fe90bdcd56d413f6f38e8", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c7476c27f219886ac57aafaa693750c5eee321ad", "width": 640, "height": 344}, {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=487c05c704ee6414bc406fe96d59fafdf86ebc0b", "width": 960, "height": 516}, {"url": "https://external-preview.redd.it/4eLZD7HyxLM1_DBss6OI4a7ojEFIxsv3AZmJhUH6VVg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1b253fbe84c01e1aab3039c90fb616770eb90b2f", "width": 1080, "height": 580}], "variants": {}, "id": "VMbu5D8d3p88J0L0CDm3qmZUYWV6_kEFk-qS4gJuykM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16bpt8i", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial_Coyote91", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bpt8i/providing_interactive_plots_to_internal_customers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bpt8i/providing_interactive_plots_to_internal_customers/", "subreddit_subscribers": 127099, "created_utc": 1694020198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I'm new to Airflow and I just want to know if I'm on the right track.  \nI have an ETL project, with each step in its directory (extract, transform, load), and each directory has a Python script that runs in a Docker container. In other words, I have a docker-compose.yml for each stage, and I simply run 'docker-compose up' one by one to run each stage.  \nNow I want to automate this with Airflow. To do that, I'm running Airflow in Docker as shown in the documentation.  \nThen, to execute each stage, I was planning to use DockerOperators. However, in all the examples and tutorials I've seen, they call a pre-built image and then run it. What I wanted to do is to execute 'docker-compose up --build' for each directory without the need to build the image beforehand and publish it.  \nBut it seems that I need to mount the docker socket inside the Airflow container for this to make it work.  \nDoes that make sense, or am I making it too complicated? ", "author_fullname": "t2_y5ux0rs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "inquiry about Apache Airflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16bp0iq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694018306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I&amp;#39;m new to Airflow and I just want to know if I&amp;#39;m on the right track.&lt;br/&gt;\nI have an ETL project, with each step in its directory (extract, transform, load), and each directory has a Python script that runs in a Docker container. In other words, I have a docker-compose.yml for each stage, and I simply run &amp;#39;docker-compose up&amp;#39; one by one to run each stage.&lt;br/&gt;\nNow I want to automate this with Airflow. To do that, I&amp;#39;m running Airflow in Docker as shown in the documentation.&lt;br/&gt;\nThen, to execute each stage, I was planning to use DockerOperators. However, in all the examples and tutorials I&amp;#39;ve seen, they call a pre-built image and then run it. What I wanted to do is to execute &amp;#39;docker-compose up --build&amp;#39; for each directory without the need to build the image beforehand and publish it.&lt;br/&gt;\nBut it seems that I need to mount the docker socket inside the Airflow container for this to make it work.&lt;br/&gt;\nDoes that make sense, or am I making it too complicated? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16bp0iq", "is_robot_indexable": true, "report_reasons": null, "author": "johnthepostman", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bp0iq/inquiry_about_apache_airflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bp0iq/inquiry_about_apache_airflow/", "subreddit_subscribers": 127099, "created_utc": 1694018306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone able to help to compile the list of mirena IUD complaints by category &amp; # to the FDA? Is this a public doc record request? Pls &amp; Thank you!", "author_fullname": "t2_7t3g1vqch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data help\u2014FDA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bo28a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1694016096.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone able to help to compile the list of mirena IUD complaints by category &amp;amp; # to the FDA? Is this a public doc record request? Pls &amp;amp; Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16bo28a", "is_robot_indexable": true, "report_reasons": null, "author": "NYCBoston", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bo28a/data_helpfda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bo28a/data_helpfda/", "subreddit_subscribers": 127099, "created_utc": 1694016096.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Saw this on LinkedIn, it is simple, but seems handy when trying to figure out the arguments for dbt-utils macros\n\nhttps://datacoves.com/post/dbt-utils-cheatsheet", "author_fullname": "t2_vx67of8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt-utils macros cheat sheet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bnjw2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1694014895.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Saw this on LinkedIn, it is simple, but seems handy when trying to figure out the arguments for dbt-utils macros&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://datacoves.com/post/dbt-utils-cheatsheet\"&gt;https://datacoves.com/post/dbt-utils-cheatsheet&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?auto=webp&amp;s=c72294a445c689d26088117fc5fff4bb905f488d", "width": 2400, "height": 1254}, "resolutions": [{"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7997828bba9f07448ccf1bc5fc04e76033b71944", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7195abbc2a5d6cdc443796e0ed5f9086f845e24d", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=33d24d3f4487eaf5c747d62b56db72b2c8b84ebf", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=545aeb79a24b1e25d483c5cd733b6ca413f25389", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7207869fedc316bad07e0b593dcb7995e5baae33", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/MR_Bvoy9qfm0qvUoHBj721WQcnmlyH-U6UzwBgkw76U.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=42828b93ff9d50484b7639ebe782f4de5c04e40c", "width": 1080, "height": 564}], "variants": {}, "id": "fRjQkbaAYceSqHYVE-NBwTYR2ZoPUS8MUARvVnek75k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16bnjw2", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Map_7868", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bnjw2/dbtutils_macros_cheat_sheet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bnjw2/dbtutils_macros_cheat_sheet/", "subreddit_subscribers": 127099, "created_utc": 1694014895.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Semantic layers itself is a new tool I've only just found out about.\n\nI'm working on a small project where most of us are fairly inexperienced in data engineering. My boss has asked me to look into the use of semantic layers (specially cube dev). From my knowledge, a BI tool can simply query from a database without needing one. \n\nThe benefits I see from semantic layers all look like things that can also be done without a semantic layer and would have negligible performance impacts on small datasets/visualizations. \n\nI've checked out a few and most of them are trying to advertise their service and thus don't really cover the situations when a semantic layer is not needed or overkill. ", "author_fullname": "t2_mdkpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do small data projects require use of a semantic layer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bf299", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693990515.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Semantic layers itself is a new tool I&amp;#39;ve only just found out about.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a small project where most of us are fairly inexperienced in data engineering. My boss has asked me to look into the use of semantic layers (specially cube dev). From my knowledge, a BI tool can simply query from a database without needing one. &lt;/p&gt;\n\n&lt;p&gt;The benefits I see from semantic layers all look like things that can also be done without a semantic layer and would have negligible performance impacts on small datasets/visualizations. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve checked out a few and most of them are trying to advertise their service and thus don&amp;#39;t really cover the situations when a semantic layer is not needed or overkill. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16bf299", "is_robot_indexable": true, "report_reasons": null, "author": "WaifuMasterRace", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bf299/do_small_data_projects_require_use_of_a_semantic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bf299/do_small_data_projects_require_use_of_a_semantic/", "subreddit_subscribers": 127099, "created_utc": 1693990515.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an SQL query that I have written, and would like to test in somewhere online for practice. It includes creation of a database. Is there any online free platform I can do this? Create a db then call some SELECT queries and a few more stuff? Thank you in advance", "author_fullname": "t2_7w9il3uc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need of a free online platform to test SQL query", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16bduox", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693986022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an SQL query that I have written, and would like to test in somewhere online for practice. It includes creation of a database. Is there any online free platform I can do this? Create a db then call some SELECT queries and a few more stuff? Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16bduox", "is_robot_indexable": true, "report_reasons": null, "author": "Kelvinmwendwa", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16bduox/need_of_a_free_online_platform_to_test_sql_query/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16bduox/need_of_a_free_online_platform_to_test_sql_query/", "subreddit_subscribers": 127099, "created_utc": 1693986022.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}