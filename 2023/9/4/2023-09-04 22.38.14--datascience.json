{"kind": "Listing", "data": {"after": "t3_169lywu", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_a3kj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "you know, i'm something of a scientist myself", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 122, "top_awarded_type": null, "hide_score": false, "name": "t3_169trua", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 911, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 911, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JoVkTgMlgsK-G206DefdNcDEbj6lLri8ek-52KR9BcQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693838434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/36i59kiy09mb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/36i59kiy09mb1.png?auto=webp&amp;s=34b758b527ae0a51d05c0498bfd45f0100bd708c", "width": 1409, "height": 1231}, "resolutions": [{"url": "https://preview.redd.it/36i59kiy09mb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e0b77c50885e5aafdedb9c5c2f6043ceade7c0c", "width": 108, "height": 94}, {"url": "https://preview.redd.it/36i59kiy09mb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2be885a9e568b64cc3f3e31f3c013c0ce4375a82", "width": 216, "height": 188}, {"url": "https://preview.redd.it/36i59kiy09mb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b78d72415c9e72157363780e09e5f723cfeb8fb7", "width": 320, "height": 279}, {"url": "https://preview.redd.it/36i59kiy09mb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9b9b297ef386b48b024c601e74462f13551e193e", "width": 640, "height": 559}, {"url": "https://preview.redd.it/36i59kiy09mb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1b2545eb927016f1d207ec98c063ae49d0902180", "width": 960, "height": 838}, {"url": "https://preview.redd.it/36i59kiy09mb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d138b5ded29e085265428664e7dd014a73000f5f", "width": 1080, "height": 943}], "variants": {}, "id": "N-HmB1-sgL1yTswPOevK-Y_2gGCyxNETi21oO5jvLjs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "169trua", "is_robot_indexable": true, "report_reasons": null, "author": "Kickass_Wizard", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169trua/you_know_im_something_of_a_scientist_myself/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/36i59kiy09mb1.png", "subreddit_subscribers": 1031076, "created_utc": 1693838434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been using AI models for time series forecasting, and while there is definitely potential, there are several difficulties I'm running into. Particularly, it has proven to be more difficult than expected to fine-tune the models and choose the appropriate features to capture the intricate patterns in my data. The learning curve in navigating the waters of overfitting and underfitting has been steep, and I\u2019m finding it pretty daunting atm.\n\nI'm interested to know whether any of you have used AI-powered time series forecasting, and what strategies you found to be successful? and how do you handle model adjustment to achieve the ideal balance between specificity and generality?", "author_fullname": "t2_bc5a438r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "struggles with ai-powered time series forcasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169sk9p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 98, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 98, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693835495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been using AI models for time series forecasting, and while there is definitely potential, there are several difficulties I&amp;#39;m running into. Particularly, it has proven to be more difficult than expected to fine-tune the models and choose the appropriate features to capture the intricate patterns in my data. The learning curve in navigating the waters of overfitting and underfitting has been steep, and I\u2019m finding it pretty daunting atm.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested to know whether any of you have used AI-powered time series forecasting, and what strategies you found to be successful? and how do you handle model adjustment to achieve the ideal balance between specificity and generality?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169sk9p", "is_robot_indexable": true, "report_reasons": null, "author": "Vokellec420", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169sk9p/struggles_with_aipowered_time_series_forcasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169sk9p/struggles_with_aipowered_time_series_forcasting/", "subreddit_subscribers": 1031076, "created_utc": 1693835495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hi everyone,\n\nI'm looking for a job or internship in the data science/analytics field. I'm quite comfortable with scikit-learn and PyTorch.\n\nI'm wondering what projects helped you land your first job or internship in the data science field. I'm interested in projects that are both challenging and relevant to the real world.\n\nIf you have any suggestions, please let me know in the comments. Thanks!", "author_fullname": "t2_ab1ofisk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science projects that helped land a job/internship", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169jwcn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 63, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 63, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693807759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a job or internship in the data science/analytics field. I&amp;#39;m quite comfortable with scikit-learn and PyTorch.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wondering what projects helped you land your first job or internship in the data science field. I&amp;#39;m interested in projects that are both challenging and relevant to the real world.&lt;/p&gt;\n\n&lt;p&gt;If you have any suggestions, please let me know in the comments. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169jwcn", "is_robot_indexable": true, "report_reasons": null, "author": "AccomplishedCraft897", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169jwcn/data_science_projects_that_helped_land_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169jwcn/data_science_projects_that_helped_land_a/", "subreddit_subscribers": 1031076, "created_utc": 1693807759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m a reporting manager for a healthcare insurance company. I manage a team of 11 in which we gather requirements, and develop ad-hoc reporting using sql and excel or more permanent reporting using visual studio to develop RDLs and publish to a share point server. \n\nI recognize times are changing. I started a certification course for data science from MIT but I\u2019m wondering best supplemental learning videos or reads do you suggest? \n\nAlso, from experience, how useful is my SQL knowledge for future employment endeavors? I believe I\u2019m a good manager as well as pulling in business needs of the owners; great at business relationships. But thinking I\u2019m a dinosaur at this point if I don\u2019t start working in Python, tableau or R? \n\nAny advice is appreciated.", "author_fullname": "t2_4nbke95r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Growing my skills from SQL/RDL developer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169f6sp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693793304.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a reporting manager for a healthcare insurance company. I manage a team of 11 in which we gather requirements, and develop ad-hoc reporting using sql and excel or more permanent reporting using visual studio to develop RDLs and publish to a share point server. &lt;/p&gt;\n\n&lt;p&gt;I recognize times are changing. I started a certification course for data science from MIT but I\u2019m wondering best supplemental learning videos or reads do you suggest? &lt;/p&gt;\n\n&lt;p&gt;Also, from experience, how useful is my SQL knowledge for future employment endeavors? I believe I\u2019m a good manager as well as pulling in business needs of the owners; great at business relationships. But thinking I\u2019m a dinosaur at this point if I don\u2019t start working in Python, tableau or R? &lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169f6sp", "is_robot_indexable": true, "report_reasons": null, "author": "Onyxpurr", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169f6sp/growing_my_skills_from_sqlrdl_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169f6sp/growing_my_skills_from_sqlrdl_developer/", "subreddit_subscribers": 1031076, "created_utc": 1693793304.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This is what it feels like being in between jobs here in the USA as a data professional", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16a2b62", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AbYQls3ufuL3ayMpiJEE4EVZQSCUGE_fbYqfWc_avHw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693857703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/6e7mo2xloamb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/6e7mo2xloamb1.jpg?auto=webp&amp;s=ef4196962d99efbe08b024601d3757cba6b3c69f", "width": 300, "height": 168}, "resolutions": [{"url": "https://preview.redd.it/6e7mo2xloamb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c302f576bba661b5a68ade3dab001b7d6be77187", "width": 108, "height": 60}, {"url": "https://preview.redd.it/6e7mo2xloamb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=af5f1ac3851bd5be483670491a47beb77814944b", "width": 216, "height": 120}], "variants": {}, "id": "_WJ6RnxuPlYwYnrZzey8mulaNI0GMpTQp7_lH7JNQ2E"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16a2b62", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16a2b62/this_is_what_it_feels_like_being_in_between_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/6e7mo2xloamb1.jpg", "subreddit_subscribers": 1031076, "created_utc": 1693857703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Don\u2019t crucify me please, I have a thing I want to do and I sincerely don\u2019t have the slightest clue on how to google this.\n\nI made an awesome dataset. I\u2019m gonna abstract some parts to make the explanation easier. This data set has 150+ attributes, it has one row per user per day, some of the attributes are numerical, some Boolean and some just text. There is a \u201ckey\u201d attribute called \u201cdid_something\u201d, which for me is the most important one, it is Boolean.\n\nNow, what I want is some sort of model, function or whatever, that can tell me something along the lines of:\n\n\u201cHey, on this date we noticed an unusual amount of people have \u2018did_something\u2019 set true and I suspect it\u2019s because they had these other attributes change to a new value the day before\u201d.\n\nBasically, to be able to tell if the change of a string value on some people, or a trend in the change of an numerical value in some people might have contributed in the change of \u201cdid_something\u201d using data from previous days.\n\nWhat is this called? Does something straight forward already exist for this?\n\nMy average stack is a combination of regular software engineering + dev ops + data engineering, all in AWS if you have any suggestions.", "author_fullname": "t2_dt2eqjvu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer looking for help in terminology", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169bzlr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693784192.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Don\u2019t crucify me please, I have a thing I want to do and I sincerely don\u2019t have the slightest clue on how to google this.&lt;/p&gt;\n\n&lt;p&gt;I made an awesome dataset. I\u2019m gonna abstract some parts to make the explanation easier. This data set has 150+ attributes, it has one row per user per day, some of the attributes are numerical, some Boolean and some just text. There is a \u201ckey\u201d attribute called \u201cdid_something\u201d, which for me is the most important one, it is Boolean.&lt;/p&gt;\n\n&lt;p&gt;Now, what I want is some sort of model, function or whatever, that can tell me something along the lines of:&lt;/p&gt;\n\n&lt;p&gt;\u201cHey, on this date we noticed an unusual amount of people have \u2018did_something\u2019 set true and I suspect it\u2019s because they had these other attributes change to a new value the day before\u201d.&lt;/p&gt;\n\n&lt;p&gt;Basically, to be able to tell if the change of a string value on some people, or a trend in the change of an numerical value in some people might have contributed in the change of \u201cdid_something\u201d using data from previous days.&lt;/p&gt;\n\n&lt;p&gt;What is this called? Does something straight forward already exist for this?&lt;/p&gt;\n\n&lt;p&gt;My average stack is a combination of regular software engineering + dev ops + data engineering, all in AWS if you have any suggestions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169bzlr", "is_robot_indexable": true, "report_reasons": null, "author": "ksco92", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169bzlr/data_engineer_looking_for_help_in_terminology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169bzlr/data_engineer_looking_for_help_in_terminology/", "subreddit_subscribers": 1031076, "created_utc": 1693784192.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Overcoming present challenges in text-to-image models, DenseDiffusion is the latest advancement ensuring enhanced image quality based on scene descriptions. Developed specifically to handle complex captions, it brings a new era in dense captioning.\n\nhttps://preview.redd.it/vrbz92zvfamb1.png?width=2000&amp;format=png&amp;auto=webp&amp;s=926d1c351a9561f6b59fec784a0ce2e9c9b56c7d\n\nIf you want to stay on top of the latest trends and insights in AI, [look here first.](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=densediffusion&amp;utm_campaign=campaign)\n\n**Why is it noteworthy?**\n\n* **It addresses the issues with existing techniques** where users face inconsistencies when dictating the arrangement of elements within generated images using textual prompts.\n* **DenseDiffusion is training-free**, unlike existing methods like \"Make-aScene\" and \"Latent Diffusion Models,\" which are computationally intensive and require retraining for new user conditions or domains.\n* **It introduces a robust attention modulation process**, which adjusts intermediate attention maps based on layout conditions, significantly improving image quality.\n\n**Here's how DenseDiffusion works**\n\n* Like other diffusion models, it begins image production with sequential denoising steps starting from random noise.\n* Its unique blocks, the self-attention and cross-attention layers, create globally consistent structures while employing a CLIP text encoder for encoding based on textual features obtained from input captions.\n\n**The Implication**\n\n* **Firstly, this sheds light on the potential of tooling models towards precise output without the associated strain on computational resources.**\n* **Secondly, the philosophy behind DenseDiffusion could drive the creation of adaptable models in other AI niches**, such as voice synthesis or robotic movement design.\n* **Most importantly, it poses a new direction for AI research**, rethinking the importance of training in generating high-quality, flexible AI models.\n\n**P.S. If you like this kind of analysis,** you\u2019ll love [my free newsletter](https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=densediffusion&amp;utm_campaign=campaign) that tracks the most relevant news and research in AI and tech.\n\n[(arXiv)](https://arxiv.org/abs/2308.12964) [(github)](https://github.com/naver-ai/densediffusion)", "author_fullname": "t2_h4jb4maul", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DenseDiffusion: The Game-changing, Training-free Technique in Text-to-Image Generation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 98, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vrbz92zvfamb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 76, "x": 108, "u": "https://preview.redd.it/vrbz92zvfamb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b80ccb3b92216443f0f61d0493694ea34f66144"}, {"y": 152, "x": 216, "u": "https://preview.redd.it/vrbz92zvfamb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c9fb804effdadec685fd2ea40a834da0b4d01c76"}, {"y": 225, "x": 320, "u": "https://preview.redd.it/vrbz92zvfamb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec9a0f53c5acc42224a3582ff0f65378405ce798"}, {"y": 451, "x": 640, "u": "https://preview.redd.it/vrbz92zvfamb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=45eee1d81cc1035b4cf9ccfe0efd350646a8e8ed"}, {"y": 676, "x": 960, "u": "https://preview.redd.it/vrbz92zvfamb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=711a0db38e58fdabd9ba75ddb68758715f08cec6"}, {"y": 761, "x": 1080, "u": "https://preview.redd.it/vrbz92zvfamb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=61caa8def49e847681368a0eb844ae0b5f1d5645"}], "s": {"y": 1410, "x": 2000, "u": "https://preview.redd.it/vrbz92zvfamb1.png?width=2000&amp;format=png&amp;auto=webp&amp;s=926d1c351a9561f6b59fec784a0ce2e9c9b56c7d"}, "id": "vrbz92zvfamb1"}}, "name": "t3_16a10xv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/2Nv_VnSRA97J5S7iNXE52325OwUWWL19rTpM8gOLFD4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693854807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Overcoming present challenges in text-to-image models, DenseDiffusion is the latest advancement ensuring enhanced image quality based on scene descriptions. Developed specifically to handle complex captions, it brings a new era in dense captioning.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vrbz92zvfamb1.png?width=2000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=926d1c351a9561f6b59fec784a0ce2e9c9b56c7d\"&gt;https://preview.redd.it/vrbz92zvfamb1.png?width=2000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=926d1c351a9561f6b59fec784a0ce2e9c9b56c7d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you want to stay on top of the latest trends and insights in AI, &lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=densediffusion&amp;amp;utm_campaign=campaign\"&gt;look here first.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why is it noteworthy?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;It addresses the issues with existing techniques&lt;/strong&gt; where users face inconsistencies when dictating the arrangement of elements within generated images using textual prompts.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;DenseDiffusion is training-free&lt;/strong&gt;, unlike existing methods like &amp;quot;Make-aScene&amp;quot; and &amp;quot;Latent Diffusion Models,&amp;quot; which are computationally intensive and require retraining for new user conditions or domains.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;It introduces a robust attention modulation process&lt;/strong&gt;, which adjusts intermediate attention maps based on layout conditions, significantly improving image quality.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Here&amp;#39;s how DenseDiffusion works&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Like other diffusion models, it begins image production with sequential denoising steps starting from random noise.&lt;/li&gt;\n&lt;li&gt;Its unique blocks, the self-attention and cross-attention layers, create globally consistent structures while employing a CLIP text encoder for encoding based on textual features obtained from input captions.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;The Implication&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Firstly, this sheds light on the potential of tooling models towards precise output without the associated strain on computational resources.&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Secondly, the philosophy behind DenseDiffusion could drive the creation of adaptable models in other AI niches&lt;/strong&gt;, such as voice synthesis or robotic movement design.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Most importantly, it poses a new direction for AI research&lt;/strong&gt;, rethinking the importance of training in generating high-quality, flexible AI models.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;P.S. If you like this kind of analysis,&lt;/strong&gt; you\u2019ll love &lt;a href=\"https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;amp;utm_medium=densediffusion&amp;amp;utm_campaign=campaign\"&gt;my free newsletter&lt;/a&gt; that tracks the most relevant news and research in AI and tech.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://arxiv.org/abs/2308.12964\"&gt;(arXiv)&lt;/a&gt; &lt;a href=\"https://github.com/naver-ai/densediffusion\"&gt;(github)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16a10xv", "is_robot_indexable": true, "report_reasons": null, "author": "AIsupercharged", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16a10xv/densediffusion_the_gamechanging_trainingfree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16a10xv/densediffusion_the_gamechanging_trainingfree/", "subreddit_subscribers": 1031076, "created_utc": 1693854807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I see a lot of job seekers here. Anyone able to develop  \u2018non-logistic regression\u2019 origination models where adverse action is provided with the score? For those that know how to calculate AA on an xgboost model, for instance, there is work out there for you. I am not here to tell you how\u2026i am just asking the question and stating a niche.", "author_fullname": "t2_26x9dvju", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Consumer Credit Risk", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169qk0w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693830056.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see a lot of job seekers here. Anyone able to develop  \u2018non-logistic regression\u2019 origination models where adverse action is provided with the score? For those that know how to calculate AA on an xgboost model, for instance, there is work out there for you. I am not here to tell you how\u2026i am just asking the question and stating a niche.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169qk0w", "is_robot_indexable": true, "report_reasons": null, "author": "brznby", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169qk0w/consumer_credit_risk/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169qk0w/consumer_credit_risk/", "subreddit_subscribers": 1031076, "created_utc": 1693830056.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does Macbook Air M2 run the KNIME Analytics Platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169kpfq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_a4f6hemy", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "macbookair", "selftext": "If it does, how well does it run? Thanks in advance.", "author_fullname": "t2_a4f6hemy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does Macbook Air M2 run the KNIME Analytics Platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/macbookair", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169ko6l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693812491.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693810274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.macbookair", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If it does, how well does it run? Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "87ea3d2e-dc41-11e9-8e5a-0ec0e18a86cc", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2wojj", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#edeff1", "id": "169ko6l", "is_robot_indexable": true, "report_reasons": null, "author": "ThunderingTyphoon_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/macbookair/comments/169ko6l/does_macbook_air_m2_run_the_knime_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/macbookair/comments/169ko6l/does_macbook_air_m2_run_the_knime_analytics/", "subreddit_subscribers": 41797, "created_utc": 1693810274.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1693810394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.macbookair", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/macbookair/comments/169ko6l/does_macbook_air_m2_run_the_knime_analytics/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169kpfq", "is_robot_indexable": true, "report_reasons": null, "author": "ThunderingTyphoon_", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_169ko6l", "author_flair_text_color": null, "permalink": "/r/datascience/comments/169kpfq/does_macbook_air_m2_run_the_knime_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/macbookair/comments/169ko6l/does_macbook_air_m2_run_the_knime_analytics/", "subreddit_subscribers": 1031076, "created_utc": 1693810394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I heard the job market for MLEs in FAANG and other big tech companies has gotten better. Can anyone confirm this?\n\nIf so, is this only for Sr-level and above? Would I be considered for that if I have an MS, 2 YOE in distributed systems at a big tech company, and 3 YOE working on image processing and deep learning (model development/training/etc but no deployment) at a no-name company?", "author_fullname": "t2_rzqt3mgj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job market for MLEs in big tech?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16a5gwp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693864785.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I heard the job market for MLEs in FAANG and other big tech companies has gotten better. Can anyone confirm this?&lt;/p&gt;\n\n&lt;p&gt;If so, is this only for Sr-level and above? Would I be considered for that if I have an MS, 2 YOE in distributed systems at a big tech company, and 3 YOE working on image processing and deep learning (model development/training/etc but no deployment) at a no-name company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16a5gwp", "is_robot_indexable": true, "report_reasons": null, "author": "No_Flow_9668", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16a5gwp/job_market_for_mles_in_big_tech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16a5gwp/job_market_for_mles_in_big_tech/", "subreddit_subscribers": 1031076, "created_utc": 1693864785.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is a field in the APPLICATION. Not a follow up email, literally in the application. The wicked programmer in me has half a mind to DDOS their application out of spite....\n\nhttps://preview.redd.it/2yr3ah508bmb1.png?width=831&amp;format=png&amp;auto=webp&amp;s=3f48ce5a9fab18369798759098ed7de2b9a1e82a", "author_fullname": "t2_1zkrsyfq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Now I've seen it all....", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 33, "top_awarded_type": null, "hide_score": true, "media_metadata": {"2yr3ah508bmb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 26, "x": 108, "u": "https://preview.redd.it/2yr3ah508bmb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3a24709bf43b1d6cc05fc3fd3ff338bdc06e4aef"}, {"y": 52, "x": 216, "u": "https://preview.redd.it/2yr3ah508bmb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=aaf698f24a3ee154b7c35652a5de66f8326e1099"}, {"y": 77, "x": 320, "u": "https://preview.redd.it/2yr3ah508bmb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6fdcbc65e3617e70f82a350feb53d9e21fec32bf"}, {"y": 154, "x": 640, "u": "https://preview.redd.it/2yr3ah508bmb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ede02e18cabefec7c97c082d8ff7e891f8964d79"}], "s": {"y": 201, "x": 831, "u": "https://preview.redd.it/2yr3ah508bmb1.png?width=831&amp;format=png&amp;auto=webp&amp;s=3f48ce5a9fab18369798759098ed7de2b9a1e82a"}, "id": "2yr3ah508bmb1"}}, "name": "t3_16a59sj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/aq9Eao-uQBaKblsx7p6XcH2NYer8mrszrrw7CR485_U.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693864321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a field in the APPLICATION. Not a follow up email, literally in the application. The wicked programmer in me has half a mind to DDOS their application out of spite....&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2yr3ah508bmb1.png?width=831&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3f48ce5a9fab18369798759098ed7de2b9a1e82a\"&gt;https://preview.redd.it/2yr3ah508bmb1.png?width=831&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3f48ce5a9fab18369798759098ed7de2b9a1e82a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16a59sj", "is_robot_indexable": true, "report_reasons": null, "author": "Any-Fig-921", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16a59sj/now_ive_seen_it_all/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16a59sj/now_ive_seen_it_all/", "subreddit_subscribers": 1031076, "created_utc": 1693864321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, all. I (US based) currently feel like I'm stuck without many options given my current resume to stay competitive enough to pass an HR filter if I were to apply for other data science jobs.\n\nI have a bachelor's in statistics, but I have no technical masters degree. So many of the job listings I see say that they want at minimum a master's in CS or a related field. I'm at the stage in my life where going for a CS master's would be too hard because I have a weak CS background and would need to take at least 2 years of full time CS courses to be eligible for a CS masters. I could go for a masters in statistics starting the very next semester (albeit at a local lower ranked state school) and finish it part time in 2-3 years, but I don't know if that makes me even more of a square peg trying to fit in a round hole.\n\nMy work experience, entirely in the logistics industry, is data analytics for 2 years with SQL and BI tools and data science for 2 years with a focus on developing and deploying machine learning algorithms from open source libraries in Python. Because of my lack of skills on the CS side, I have been working exclusively on predictive and forecasting models for data with quantitative outputs so that I can leverage my statistics background. The other data scientists on my team handle more CS-heavy projects like recommendation, NLP, and AI algorithms.\n\nAll this in mind, I feel like I wouldn't get the time of day on any application I send out to some of the larger companies that are in the tech, finance, healthcare, etc space. Should I go or a technical masters? If not, what would you recommend I focus on to get my foot in the door for interviews? If I should go for a masters, is an MS in statistics good enough or does it have to be CS-related?", "author_fullname": "t2_2uajbxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feel stuck in my career trajectory, need some help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16a58hw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693864238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, all. I (US based) currently feel like I&amp;#39;m stuck without many options given my current resume to stay competitive enough to pass an HR filter if I were to apply for other data science jobs.&lt;/p&gt;\n\n&lt;p&gt;I have a bachelor&amp;#39;s in statistics, but I have no technical masters degree. So many of the job listings I see say that they want at minimum a master&amp;#39;s in CS or a related field. I&amp;#39;m at the stage in my life where going for a CS master&amp;#39;s would be too hard because I have a weak CS background and would need to take at least 2 years of full time CS courses to be eligible for a CS masters. I could go for a masters in statistics starting the very next semester (albeit at a local lower ranked state school) and finish it part time in 2-3 years, but I don&amp;#39;t know if that makes me even more of a square peg trying to fit in a round hole.&lt;/p&gt;\n\n&lt;p&gt;My work experience, entirely in the logistics industry, is data analytics for 2 years with SQL and BI tools and data science for 2 years with a focus on developing and deploying machine learning algorithms from open source libraries in Python. Because of my lack of skills on the CS side, I have been working exclusively on predictive and forecasting models for data with quantitative outputs so that I can leverage my statistics background. The other data scientists on my team handle more CS-heavy projects like recommendation, NLP, and AI algorithms.&lt;/p&gt;\n\n&lt;p&gt;All this in mind, I feel like I wouldn&amp;#39;t get the time of day on any application I send out to some of the larger companies that are in the tech, finance, healthcare, etc space. Should I go or a technical masters? If not, what would you recommend I focus on to get my foot in the door for interviews? If I should go for a masters, is an MS in statistics good enough or does it have to be CS-related?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16a58hw", "is_robot_indexable": true, "report_reasons": null, "author": "penpapermouse", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16a58hw/feel_stuck_in_my_career_trajectory_need_some_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16a58hw/feel_stuck_in_my_career_trajectory_need_some_help/", "subreddit_subscribers": 1031076, "created_utc": 1693864238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve taken on a personal project to improve our companies forecasts for income statement/balance sheet lines. I\u2019ve been able to build a few models but I\u2019m wondering what other similar projects are using as impacts/regressor datasets (ex. GDP, CPI, major currency exchange rates, BoC rate, etc). Basically I\u2019m wondering if I\u2019m in the right ballpark with my examples or if I need to be looking for other datasets to improve my predictions\n\nData:\nWe have existing historical to present datasets that include our planned, forecast, and actual reported amounts for each line on our IS &amp; BS. We also have planned figures for the current year, and manually forecasted figures for the next 5 years. In order to build the dataflow I\u2019ve used mockup data for impact/regressors but now I\u2019m looking for actual datasets\n\nI\u2019ve used ChatGPT and experimented with building a few different models (ARIMA, fbprophet). I just have doubts if my logic on impacts/aggressors makes sense\n\nThanks!", "author_fullname": "t2_3vjvt7ak", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series forecasting of income statement/balance sheet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16a4sin", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693863229.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve taken on a personal project to improve our companies forecasts for income statement/balance sheet lines. I\u2019ve been able to build a few models but I\u2019m wondering what other similar projects are using as impacts/regressor datasets (ex. GDP, CPI, major currency exchange rates, BoC rate, etc). Basically I\u2019m wondering if I\u2019m in the right ballpark with my examples or if I need to be looking for other datasets to improve my predictions&lt;/p&gt;\n\n&lt;p&gt;Data:\nWe have existing historical to present datasets that include our planned, forecast, and actual reported amounts for each line on our IS &amp;amp; BS. We also have planned figures for the current year, and manually forecasted figures for the next 5 years. In order to build the dataflow I\u2019ve used mockup data for impact/regressors but now I\u2019m looking for actual datasets&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve used ChatGPT and experimented with building a few different models (ARIMA, fbprophet). I just have doubts if my logic on impacts/aggressors makes sense&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16a4sin", "is_robot_indexable": true, "report_reasons": null, "author": "2016YamR6", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16a4sin/time_series_forecasting_of_income/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16a4sin/time_series_forecasting_of_income/", "subreddit_subscribers": 1031076, "created_utc": 1693863229.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been banging my head against the wall for a few days with a problem. So i thought, where do people find help if there isn't a team / colleague to ask?\n\nChatGPT is a good rubber ducky for me, but it isn't great if I myself don't fully know how to tackle a problem.", "author_fullname": "t2_3w5z8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you get help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a38r9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693859782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been banging my head against the wall for a few days with a problem. So i thought, where do people find help if there isn&amp;#39;t a team / colleague to ask?&lt;/p&gt;\n\n&lt;p&gt;ChatGPT is a good rubber ducky for me, but it isn&amp;#39;t great if I myself don&amp;#39;t fully know how to tackle a problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16a38r9", "is_robot_indexable": true, "report_reasons": null, "author": "kingrandow", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16a38r9/where_do_you_get_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16a38r9/where_do_you_get_help/", "subreddit_subscribers": 1031076, "created_utc": 1693859782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m looking to evaluate a dataset that consists primarily of natural language-code snippets in a single programming language. \n\nThe overall goal is to provide some metric/s for understanding the uniqueness and variety of the dataset. \n\nRogue scoring doesn\u2019t work; I\u2019ve even produced a custom Rogue metric attempting to understand the granularity of a programming language\u2026 and it just doesn\u2019t work. It flags everything as the same - reducing a 48,000 record dataset to 10 records\u2026 and that was the best case. \n\nIf I just evaluate it at face value - reading and analyzing any two samples manually - it\u2019s about 95% unique. I just don\u2019t feel great about human evaluation here. It\u2019s too important.\n\nLet\u2019s say one sample says \u201cExplain the origins of C++\u201d - \u201cOrigins of C++\u201d and the next sample says \u201cCorrect the origin story for C++ in the following: Incorrect origin story\u201d - \u201cCorrected origin story\u201d.\n\nHow can I find some real metric that captures the nuance required to evaluate this as useful and unique? \n\nI\u2019m happy to bring someone onboard - full Arxiv credits and endorsement; all recognition for the metrics we build publicly and academically/professionally. \n\nAppreciate the help! Cheers.", "author_fullname": "t2_ufzvkub2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evaluating Code-Based Datasets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16a151t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693855052.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to evaluate a dataset that consists primarily of natural language-code snippets in a single programming language. &lt;/p&gt;\n\n&lt;p&gt;The overall goal is to provide some metric/s for understanding the uniqueness and variety of the dataset. &lt;/p&gt;\n\n&lt;p&gt;Rogue scoring doesn\u2019t work; I\u2019ve even produced a custom Rogue metric attempting to understand the granularity of a programming language\u2026 and it just doesn\u2019t work. It flags everything as the same - reducing a 48,000 record dataset to 10 records\u2026 and that was the best case. &lt;/p&gt;\n\n&lt;p&gt;If I just evaluate it at face value - reading and analyzing any two samples manually - it\u2019s about 95% unique. I just don\u2019t feel great about human evaluation here. It\u2019s too important.&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s say one sample says \u201cExplain the origins of C++\u201d - \u201cOrigins of C++\u201d and the next sample says \u201cCorrect the origin story for C++ in the following: Incorrect origin story\u201d - \u201cCorrected origin story\u201d.&lt;/p&gt;\n\n&lt;p&gt;How can I find some real metric that captures the nuance required to evaluate this as useful and unique? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m happy to bring someone onboard - full Arxiv credits and endorsement; all recognition for the metrics we build publicly and academically/professionally. &lt;/p&gt;\n\n&lt;p&gt;Appreciate the help! Cheers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16a151t", "is_robot_indexable": true, "report_reasons": null, "author": "LoadingALIAS", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16a151t/evaluating_codebased_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16a151t/evaluating_codebased_datasets/", "subreddit_subscribers": 1031076, "created_utc": 1693855052.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi r/datascience,\n\n&amp;#x200B;\n\n**TL;DR**: I am asked by my employer to work on a DS project and was offered \u20ac1,500 to get some courses and learn the best practices, but I feel really lacking Statistics knowledge. What Statistics or DS online courses would you recommend me?\n\n&amp;#x200B;\n\nMy current employer offers a yearly growth budget of \u20ac1,500 and my manager suggested me to enroll in a Data Science course, given that I will be working soon on the very first DS project of the company (there are no Data Scientists in the company and I was chosen among the Analysts to embark in this topic).\n\n&amp;#x200B;\n\nI only did a couple of projects in school when getting the MSc in Data Analytics and covered superficially many classification and regression aspects, but I lack the real Statistic understanding of the Does and Don'ts in applying Machine Learning to real-life scenarios (which I am aware is something that is mainly developed with work experience).\n\n&amp;#x200B;\n\nFor this reasons, I would prefer a comprehensive but deep online Statistical course I could enroll with the company's budget.\n\n&amp;#x200B;\n\nWhat course would you recommend?\n\n&amp;#x200B;\n\nI have only considered so far the following ones:\n\n[https://www.udemy.com/course/statistics-for-data-science-data-analytics/](https://www.udemy.com/course/statistics-for-data-science-data-analytics/)\n\n[https://www.deeplearning.ai/courses/machine-learning-specialization/](https://www.deeplearning.ai/courses/machine-learning-specialization/)\n\n[https://www.deeplearning.ai/courses/mathematics-for-machine-learning-and-data-science-specialization/](https://www.deeplearning.ai/courses/mathematics-for-machine-learning-and-data-science-specialization/)\n\nHowever, I feel that they either cover superficially Statistics and do not go deep enough into real cases.\n\n&amp;#x200B;\n\nThank you for the attention!", "author_fullname": "t2_1jndvd85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestions of online Statisics or DS course with \u20ac1,500 company budget", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169zoi0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693851915.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: I am asked by my employer to work on a DS project and was offered \u20ac1,500 to get some courses and learn the best practices, but I feel really lacking Statistics knowledge. What Statistics or DS online courses would you recommend me?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My current employer offers a yearly growth budget of \u20ac1,500 and my manager suggested me to enroll in a Data Science course, given that I will be working soon on the very first DS project of the company (there are no Data Scientists in the company and I was chosen among the Analysts to embark in this topic).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I only did a couple of projects in school when getting the MSc in Data Analytics and covered superficially many classification and regression aspects, but I lack the real Statistic understanding of the Does and Don&amp;#39;ts in applying Machine Learning to real-life scenarios (which I am aware is something that is mainly developed with work experience).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;For this reasons, I would prefer a comprehensive but deep online Statistical course I could enroll with the company&amp;#39;s budget.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What course would you recommend?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have only considered so far the following ones:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.udemy.com/course/statistics-for-data-science-data-analytics/\"&gt;https://www.udemy.com/course/statistics-for-data-science-data-analytics/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.deeplearning.ai/courses/machine-learning-specialization/\"&gt;https://www.deeplearning.ai/courses/machine-learning-specialization/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.deeplearning.ai/courses/mathematics-for-machine-learning-and-data-science-specialization/\"&gt;https://www.deeplearning.ai/courses/mathematics-for-machine-learning-and-data-science-specialization/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;However, I feel that they either cover superficially Statistics and do not go deep enough into real cases.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for the attention!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169zoi0", "is_robot_indexable": true, "report_reasons": null, "author": "stexo92", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169zoi0/suggestions_of_online_statisics_or_ds_course_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169zoi0/suggestions_of_online_statisics_or_ds_course_with/", "subreddit_subscribers": 1031076, "created_utc": 1693851915.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Assuming we deploy an AutoArima model on the same time series data with the default configurations, we would get different performance metrics when using pmdarima as opposed to, statsforecast, for example. \n\nMy understanding is that, big picture, AutoArima tries to fit the best differencing order to the time series. So if that process is universal and the underlying data is the same, why wouldn\u2019t all return the same output regardless of what package you use?", "author_fullname": "t2_p3oo7xu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When using AutoArima, why isn\u2019t performance universal across packages?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169pbnm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693826226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Assuming we deploy an AutoArima model on the same time series data with the default configurations, we would get different performance metrics when using pmdarima as opposed to, statsforecast, for example. &lt;/p&gt;\n\n&lt;p&gt;My understanding is that, big picture, AutoArima tries to fit the best differencing order to the time series. So if that process is universal and the underlying data is the same, why wouldn\u2019t all return the same output regardless of what package you use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169pbnm", "is_robot_indexable": true, "report_reasons": null, "author": "knavishly_vibrant38", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169pbnm/when_using_autoarima_why_isnt_performance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169pbnm/when_using_autoarima_why_isnt_performance/", "subreddit_subscribers": 1031076, "created_utc": 1693826226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the possible ways to create fixed-length vectors that could be used for comparing similarities (i.e. cosine similarity) between items...\n\nWhere the items are encoded as hex strings, they are variable in length, and can be as short as 24 characters, or as long as any amount. So zero padding is not efficient for this use-case. \n\nExample of inputs:\n```\n- d8799f00001a068e7780ff\n- d8799fd8799f581c0825874bc726bc7a4f1a2da132c20b4da6598472f41b241c41fdbf30d8799f581c603d5d775406e96025767f72564924d8bd1f0c870923c0782f80ff2affffd87980ff\n- d8799fd8799f581c0825874bc726bc7a4f1a2da132c20b4da6598472f41b241c41fdbf30d8799f581c603d5d775406e96025767f72564924d8bd1f0c870923c0782f80ff2affffd87a80ff\n```\n\nEach hex string contains a certain JSON structure and it defines \"type\"/\"schema\" of object. So objective is to cluster these hex strings into a high-dimension space.\n\nYou can see that items #2 and #3 are similar, both in length and in the prefix of the hex string, as such, these should be close together.\n\nInterested to find out how you will approach this problem.", "author_fullname": "t2_2z0d0jc2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for converting from variable-length hex string to fixed-length vector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169m4t1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693819703.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693815220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the possible ways to create fixed-length vectors that could be used for comparing similarities (i.e. cosine similarity) between items...&lt;/p&gt;\n\n&lt;p&gt;Where the items are encoded as hex strings, they are variable in length, and can be as short as 24 characters, or as long as any amount. So zero padding is not efficient for this use-case. &lt;/p&gt;\n\n&lt;p&gt;Example of inputs:\n&lt;code&gt;\n- d8799f00001a068e7780ff\n- d8799fd8799f581c0825874bc726bc7a4f1a2da132c20b4da6598472f41b241c41fdbf30d8799f581c603d5d775406e96025767f72564924d8bd1f0c870923c0782f80ff2affffd87980ff\n- d8799fd8799f581c0825874bc726bc7a4f1a2da132c20b4da6598472f41b241c41fdbf30d8799f581c603d5d775406e96025767f72564924d8bd1f0c870923c0782f80ff2affffd87a80ff\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Each hex string contains a certain JSON structure and it defines &amp;quot;type&amp;quot;/&amp;quot;schema&amp;quot; of object. So objective is to cluster these hex strings into a high-dimension space.&lt;/p&gt;\n\n&lt;p&gt;You can see that items #2 and #3 are similar, both in length and in the prefix of the hex string, as such, these should be close together.&lt;/p&gt;\n\n&lt;p&gt;Interested to find out how you will approach this problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169m4t1", "is_robot_indexable": true, "report_reasons": null, "author": "ErmJustSaying", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169m4t1/ideas_for_converting_from_variablelength_hex/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169m4t1/ideas_for_converting_from_variablelength_hex/", "subreddit_subscribers": 1031076, "created_utc": 1693815220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Suppose there are features {a, b, c . . . z}. Features {a, b, c . . . j} are unlikely to be sparse. Features {k, l m . . . z} are highly likely to be sparse. Ideally, I could tell it to learn hyperparameters differently for different feature sets without doing complicated splitting/recombining of dataframes.", "author_fullname": "t2_jwvnpdbl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle the case where different sets of features have different sparsities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169j84n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693806761.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693805592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Suppose there are features {a, b, c . . . z}. Features {a, b, c . . . j} are unlikely to be sparse. Features {k, l m . . . z} are highly likely to be sparse. Ideally, I could tell it to learn hyperparameters differently for different feature sets without doing complicated splitting/recombining of dataframes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169j84n", "is_robot_indexable": true, "report_reasons": null, "author": "COVID19_is_over", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169j84n/how_do_you_handle_the_case_where_different_sets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169j84n/how_do_you_handle_the_case_where_different_sets/", "subreddit_subscribers": 1031076, "created_utc": 1693805592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 04 Sep, 2023 - 11 Sep, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169hh4p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693800106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169hh4p", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169hh4p/weekly_entering_transitioning_thread_04_sep_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/169hh4p/weekly_entering_transitioning_thread_04_sep_2023/", "subreddit_subscribers": 1031076, "created_utc": 1693800106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_v8n3a1nm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Intro to Vertex AI - 100 seconds", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16a1mqz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Rp86bgmHmt4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Intro to Vertex AI - 100 seconds\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Intro to Vertex AI - 100 seconds", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Rp86bgmHmt4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Intro to Vertex AI - 100 seconds\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/Rp86bgmHmt4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Rp86bgmHmt4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Intro to Vertex AI - 100 seconds\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16a1mqz", "height": 200}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/JzlfLuIDli3HLBdZi00YSZ3F46ReWroa818lnBLRfog.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1693856153.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/Rp86bgmHmt4?si=v11BkuRiRdcr8x3e", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mLfxOND0Yu80-oanrGL2nAumpzrDmez59QChE4LnhZY.jpg?auto=webp&amp;s=8344b27e2b6bab29338e9c18d9edfc45079483ce", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/mLfxOND0Yu80-oanrGL2nAumpzrDmez59QChE4LnhZY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=82460cfa81c48ef952271684694046598abbd4fd", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/mLfxOND0Yu80-oanrGL2nAumpzrDmez59QChE4LnhZY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83205209df6f18d482fbe119fff4eb819385ca68", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/mLfxOND0Yu80-oanrGL2nAumpzrDmez59QChE4LnhZY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c3626db8c2ffe3bfb6b8e447577fe39e59654233", "width": 320, "height": 240}], "variants": {}, "id": "FFpNQpVnQzAaGVAoX_rpB21S_1KZyEwE28keonfpGbk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "16a1mqz", "is_robot_indexable": true, "report_reasons": null, "author": "fancypigollo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16a1mqz/intro_to_vertex_ai_100_seconds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/Rp86bgmHmt4?si=v11BkuRiRdcr8x3e", "subreddit_subscribers": 1031076, "created_utc": 1693856153.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Intro to Vertex AI - 100 seconds", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/Rp86bgmHmt4?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Intro to Vertex AI - 100 seconds\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/Rp86bgmHmt4/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone!\n\nI'm John, and I'm new here. I recently completed the Google Data Analytics Professional Certificate. Currently, I hold the position of Associate Quality Senior at a bus company, but I'm excited to make a transition into a data-related role within the company.\n\nA bit about my background: I've been on a journey to discover my passion, and along the way, I've acquired a range of technical and soft skills. Being a technology enthusiast, I dived into Excel, data manipulation, and dashboard creation by following YouTube tutorials. Shortly after joining my current company, I had the opportunity to contribute to the Quality department by creating a dashboard for closed cases. This dashboard provided valuable insights into recurring issues and work metrics, catching the attention of my direct manager, supervisor, and the ROM. As a result, I was entrusted with more data-related projects, helping us gain a clearer picture of our day-to-day challenges and issues with our partners.\n\nThis experience triggered my long-sought passion for data, and I'm eager to dedicate my time to it. While I've completed the mentioned certificate, I admit I'm feeling a bit lost on where to start. I'd greatly appreciate the chance to connect with fellow data enthusiasts, learn from their experiences, and seek guidance.\n\nLet's chat!\n\nBest regards,", "author_fullname": "t2_cm1pa7jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From Quality to Data: My Expedition into Analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169wkkw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693844882.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m John, and I&amp;#39;m new here. I recently completed the Google Data Analytics Professional Certificate. Currently, I hold the position of Associate Quality Senior at a bus company, but I&amp;#39;m excited to make a transition into a data-related role within the company.&lt;/p&gt;\n\n&lt;p&gt;A bit about my background: I&amp;#39;ve been on a journey to discover my passion, and along the way, I&amp;#39;ve acquired a range of technical and soft skills. Being a technology enthusiast, I dived into Excel, data manipulation, and dashboard creation by following YouTube tutorials. Shortly after joining my current company, I had the opportunity to contribute to the Quality department by creating a dashboard for closed cases. This dashboard provided valuable insights into recurring issues and work metrics, catching the attention of my direct manager, supervisor, and the ROM. As a result, I was entrusted with more data-related projects, helping us gain a clearer picture of our day-to-day challenges and issues with our partners.&lt;/p&gt;\n\n&lt;p&gt;This experience triggered my long-sought passion for data, and I&amp;#39;m eager to dedicate my time to it. While I&amp;#39;ve completed the mentioned certificate, I admit I&amp;#39;m feeling a bit lost on where to start. I&amp;#39;d greatly appreciate the chance to connect with fellow data enthusiasts, learn from their experiences, and seek guidance.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s chat!&lt;/p&gt;\n\n&lt;p&gt;Best regards,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169wkkw", "is_robot_indexable": true, "report_reasons": null, "author": "Entrepreneur_Guy92", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169wkkw/from_quality_to_data_my_expedition_into_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169wkkw/from_quality_to_data_my_expedition_into_analytics/", "subreddit_subscribers": 1031076, "created_utc": 1693844882.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Plz suggest me some html template look as professional. I can buy it if need. I will use it in github page. Language : English. \n\nI have already a portfolio but want to upgarde it.\nMy existing [portfolio link](https://mehadisaki.github.io/)", "author_fullname": "t2_sf9a5nnx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need a html portfolio template for my Data science project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169s37b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693834263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Plz suggest me some html template look as professional. I can buy it if need. I will use it in github page. Language : English. &lt;/p&gt;\n\n&lt;p&gt;I have already a portfolio but want to upgarde it.\nMy existing &lt;a href=\"https://mehadisaki.github.io/\"&gt;portfolio link&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169s37b", "is_robot_indexable": true, "report_reasons": null, "author": "shah-i-bangla", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169s37b/need_a_html_portfolio_template_for_my_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169s37b/need_a_html_portfolio_template_for_my_data/", "subreddit_subscribers": 1031076, "created_utc": 1693834263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, so I am looking to learn and use my first open LLM for a project (rather than using closed LLMs like GPT/Bard).\n\nI am aware of the open LLM leaderboard in Hugginface here: https://huggingface.co/spaces/ludwigstumpp/llm-leaderboard\n\nIf I wanted an LLM which has the capacity to take in the highest number of input/output tokens (sorry if this is a stupid question for open models) and one which has reasonably good accuracy, from your experience which one would you recommend?\n\nMany thanks for your input!", "author_fullname": "t2_hjlrj5fp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which is a suitable first open LLM to pick up and learn?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169n2av", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1693819522.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1693818487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, so I am looking to learn and use my first open LLM for a project (rather than using closed LLMs like GPT/Bard).&lt;/p&gt;\n\n&lt;p&gt;I am aware of the open LLM leaderboard in Hugginface here: &lt;a href=\"https://huggingface.co/spaces/ludwigstumpp/llm-leaderboard\"&gt;https://huggingface.co/spaces/ludwigstumpp/llm-leaderboard&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If I wanted an LLM which has the capacity to take in the highest number of input/output tokens (sorry if this is a stupid question for open models) and one which has reasonably good accuracy, from your experience which one would you recommend?&lt;/p&gt;\n\n&lt;p&gt;Many thanks for your input!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l6BMP7xLoe1EH1UQOhVd3CHtcHWSJZCOV7e1cmrTsBk.jpg?auto=webp&amp;s=b4dc0907839747ce138363031929535cce22f5ab", "width": 1200, "height": 648}, "resolutions": [{"url": "https://external-preview.redd.it/l6BMP7xLoe1EH1UQOhVd3CHtcHWSJZCOV7e1cmrTsBk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cbb6d7075173f5bbb29635598acd7148dcc07a11", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/l6BMP7xLoe1EH1UQOhVd3CHtcHWSJZCOV7e1cmrTsBk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f2520ddc8f926e325d8f0dce49d1a540cd46ad67", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/l6BMP7xLoe1EH1UQOhVd3CHtcHWSJZCOV7e1cmrTsBk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6a015e36c1c7bdc1f416001ab64b2ea21505f8cb", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/l6BMP7xLoe1EH1UQOhVd3CHtcHWSJZCOV7e1cmrTsBk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=12cbce823b38a5200510599c1717eb22b33e7493", "width": 640, "height": 345}, {"url": "https://external-preview.redd.it/l6BMP7xLoe1EH1UQOhVd3CHtcHWSJZCOV7e1cmrTsBk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=77e70b8a31382c755cd4ed9667352185d1329510", "width": 960, "height": 518}, {"url": "https://external-preview.redd.it/l6BMP7xLoe1EH1UQOhVd3CHtcHWSJZCOV7e1cmrTsBk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=760ad90a83d494961856c8bbde52a13279b58387", "width": 1080, "height": 583}], "variants": {}, "id": "32cFnmMSOnF0W3tgRwFTzx2CSyjgLu2ST20yL5u1DcQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169n2av", "is_robot_indexable": true, "report_reasons": null, "author": "--leockl--", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/169n2av/which_is_a_suitable_first_open_llm_to_pick_up_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/169n2av/which_is_a_suitable_first_open_llm_to_pick_up_and/", "subreddit_subscribers": 1031076, "created_utc": 1693818487.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions about data presentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_169lywu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_pov72lum", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "analytics", "selftext": "Hi. I have a goal in mind to enter the data analytics field as it\u2019s something I can see myself doing in the next few years. Currently, I am preparing for next year\u2019s university admission exercise and would like to create a few projects to showcase my self-taught programming skills in Python, sql, and R, while displaying my understanding of both descriptive and inferential statistics. However, I realize that most data on the net have been summarized and could be just used for displaying graph and causal inference. There isn\u2019t really much I can do to display my statistical knowledge. \n\nAs I\u2019m not in the field and have lacked actual experience in this field, may I know:\n1. Apart from producing graphs and predictive analysis via linear regression, what other parts of statistics can I use?\n2.What\u2019s the most important information that I need to have when creating a data analytics report/ presentation?\n\nI really appreciate any information that I can receive from you all. I hope that with all of your help, I can enter this exciting career and contribute more to this group. Thank you in advance\ud83d\ude0a.", "author_fullname": "t2_pov72lum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions about data presentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/analytics", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_168zdta", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1693753665.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.analytics", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I have a goal in mind to enter the data analytics field as it\u2019s something I can see myself doing in the next few years. Currently, I am preparing for next year\u2019s university admission exercise and would like to create a few projects to showcase my self-taught programming skills in Python, sql, and R, while displaying my understanding of both descriptive and inferential statistics. However, I realize that most data on the net have been summarized and could be just used for displaying graph and causal inference. There isn\u2019t really much I can do to display my statistical knowledge. &lt;/p&gt;\n\n&lt;p&gt;As I\u2019m not in the field and have lacked actual experience in this field, may I know:\n1. Apart from producing graphs and predictive analysis via linear regression, what other parts of statistics can I use?\n2.What\u2019s the most important information that I need to have when creating a data analytics report/ presentation?&lt;/p&gt;\n\n&lt;p&gt;I really appreciate any information that I can receive from you all. I hope that with all of your help, I can enter this exciting career and contribute more to this group. Thank you in advance\ud83d\ude0a.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "f48f7eba-c677-11e9-b8c9-0e4f41e428f2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rhz9", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "168zdta", "is_robot_indexable": true, "report_reasons": null, "author": "Physical_Yellow_6743", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/analytics/comments/168zdta/questions_about_data_presentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/analytics/comments/168zdta/questions_about_data_presentation/", "subreddit_subscribers": 140922, "created_utc": 1693753665.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1693814633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.analytics", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/analytics/comments/168zdta/questions_about_data_presentation/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "169lywu", "is_robot_indexable": true, "report_reasons": null, "author": "Physical_Yellow_6743", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_168zdta", "author_flair_text_color": null, "permalink": "/r/datascience/comments/169lywu/questions_about_data_presentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/analytics/comments/168zdta/questions_about_data_presentation/", "subreddit_subscribers": 1031076, "created_utc": 1693814633.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}